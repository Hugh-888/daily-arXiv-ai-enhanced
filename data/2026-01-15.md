<div id=toc></div>

# Table of Contents

- [quant-ph](#quant-ph) [Total: 40]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [gr-qc](#gr-qc) [Total: 15]
- [cs.LG](#cs.LG) [Total: 61]


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [1] [Nonclassicality of multi-photon-added cat states](https://arxiv.org/abs/2601.08894)
*Jhordan Santiago,Petr Steindl*

Main category: quant-ph

TL;DR: 多光子添加猫态是通过在猫态上重复应用产生算符构造的，研究显示光子添加会改变奇偶性配置，使状态进入亚泊松分布，适用于量子成像


<details>
  <summary>Details</summary>
Motivation: 研究多光子添加猫态的特性，探索其在量子信息处理中的潜在应用价值，特别是作为量子成像资源的可能性

Method: 通过理论分析研究多光子添加猫态的光子数分布、Q参数、压缩特性和Wigner函数，探讨光子添加对状态性质的影响

Result: 光子添加会导致原始奇偶性配置发生π相移，使状态进入亚泊松分布，失去正交压缩但获得振幅平方压缩，这些状态可用现有硬件生成

Conclusion: 多光子添加猫态具有独特的量子特性，特别是亚泊松分布性质，使其成为量子成像的宝贵资源，且实验上可实现

Abstract: Multi-photon-added cat states are constructed by repeatedly applying the creation operator to a cat state. We study in detail their photon-number distribution, $Q$ parameter, squeezing properties, and Wigner function. We show that photon addition induces a $π$ phase shift in the original parity configuration whenever an odd number of photons is added, reflected as swapped vanishing probabilities and phase space displacements at the origin. Remarkably, the same process drives these states into a sub-Poissonian regime regardless of the relative phase between their coherent state components, making them valuable resources for quantum imaging, at the cost of losing quadrature squeezing, but gaining amplitude-squared one. We also discuss how these states can be generated using existing hardware.

</details>


### [2] [A 10 Megahertz Spatial Light Modulator](https://arxiv.org/abs/2601.08906)
*Xin Wei,Zeyang Li,Abhishek V. Karve,Adam L. Shaw,David I. Schuster,Jonathan Simon*

Main category: quant-ph

TL;DR: 提出新型空间光调制器，结合2D像素几何与高速性能，实现MHz速率、连续运动、可重构的衍射极限光斑控制


<details>
  <summary>Details</summary>
Motivation: 现有波前整形技术存在根本性矛盾：空间光调制器像素数高但刷新率低，声光偏转器速度中等但光束几何受限，缺乏同时具备MHz速率、连续运动和可重构控制能力的工具

Method: 通过宽带光学相位调制器在频率仓中编码空间信息，并通过首创的高分辨率2D光谱仪解码；光谱仪采用重新成像相控阵架构，利用长光程实现高灵敏度

Result: 演示了44纳秒上升时间的光学脉冲（对应超过1000万帧/秒的帧率），以及任意可重构的2D寻址和多点操作，包括异步独立光束运动、分裂和重组

Conclusion: 该技术为快速光学操控开辟了新视野，可应用于量子处理器中接近原子惯性和辐射极限的快速可扩展控制，以及显微镜和神经生物学成像中的动态可编程微秒分辨率照明

Abstract: Rapid and programmable shaping of light fields is central to modern microscopy, display technologies, optical communications and sensing, quantum engineering, and quantum information processing. Current wavefront shaping technologies face a fundamental dichotomy: spatial light modulators (SLMs) offer high pixel count but suffer from low refresh rates, while acousto-optic deflectors (AODs) provide moderate speed with restricted optical beam geometries. Though recent advances in photonic integrated circuits achieve fast switching, there is currently no tool that provides MHz-rate, continuous motion, and arbitrarily reconfigurable control over a set of diffraction-limited spots. Here we introduce a new class of spatial light modulator that provides both 2D pixel geometry and high speed. The device operates by encoding spatial information in frequency bins via a broadband optical phase modulator, and decoding them via a first-of-its-kind, high-resolution 2D spectrometer. The spectrometer, based on the architecture which we call the Re-Imaging Phased Array (RIPA), achieves its sensitivity through long path-lengths, enabled by intra-spectrometer re-imaging lens-guides. We demonstrate site-resolved optical pulsing with a 44(1)~ns rise time, corresponding to frame rates exceeding 10 million frames per second, as well as arbitrary, reconfigurable 2D addressing and multi-site operations, including asynchronous, independent beam motion, splitting, and recombination. Leveraging these tools opens new horizons in rapid optical manipulation of matter across science, from fast, scalable control that approaches the inertial and radiation limits of atoms in quantum processors, to dynamically programmable, microsecond-resolved illumination in microscopy and neuro-biological imaging.

</details>


### [3] [Superadditivity of Zero-Error Capacity in Noisy Classical and Perfect Quantum Channel Pairs](https://arxiv.org/abs/2601.08913)
*Ambuj,Anushko Chattopadhyay,Kunika Agarwal,Rakesh Das,Amit Mukherjee*

Main category: quant-ph

TL;DR: 量子通道与噪声经典通道并行使用时，单次零误差经典容量表现出超加性，传输消息数超过各自容量乘积，这一量子优势源于Kochen-Specker语境性。


<details>
  <summary>Details</summary>
Motivation: 研究量子通道在通信中的独特优势，探索量子资源如何增强经典通信能力，特别是在零误差通信场景下。

Method: 在不对称通信设置中，将噪声经典通道与完美量子通道并行使用，构建显式方案实现容量增强，并与完美经典通道对比。

Result: 联合使用噪声经典通道和完美量子通道能传输严格多于各自容量乘积的消息数，而用完美经典通道替换量子通道则消除该效应。

Conclusion: 量子通道在增强经典通信容量方面具有独特优势，该优势受噪声通道结构特性影响，其根源在于Kochen-Specker语境性。

Abstract: We demonstrate superadditivity of one-shot zero-error classical capacity in an asymmetric communication setting where a noisy classical channel is used in parallel with a perfect quantum channel. Each channel individually supports only a fixed number of perfectly distinguishable messages. Their joint use enables transmission of strictly more messages than permitted by the product of the individual capacities. We present explicit constructions achieving this enhancement and establish that replacing the perfect quantum channel with a perfect classical channel eliminates the effect. Finally, we identify a structural criterion on the noisy channel governing this effect and show that the quantum advantage is rooted in Kochen-Specker contextuality.

</details>


### [4] [Simultaneous nondestructive measurement of many polar molecules using Rydberg atoms](https://arxiv.org/abs/2601.08921)
*Jeremy T. Young,Kang-Kuen Ni,Alexey V. Gorshkov*

Main category: quant-ph

TL;DR: 提出利用里德堡原子非破坏性测量分子量子比特内部状态的方法


<details>
  <summary>Details</summary>
Motivation: 当前极性分子阵列中的内部态测量方案通常是破坏性的，这限制了量子科学和量子信息应用的发展

Method: 通过微波调控分子和里德堡原子的能级，调节相互作用强度，最小化里德堡-里德堡相互作用，实现同时进行多次测量

Result: 以²³Na¹³³Cs和⁸⁷Rb¹³³Cs分子与¹³³Cs原子为例展示了实验可行性，并讨论了多种串扰抑制策略

Conclusion: 该方法为极性分子量子比特的非破坏性测量提供了有效解决方案，有望推动分子量子信息处理的发展

Abstract: Tweezer arrays of polar molecules present new opportunities for quantum science and quantum information. However, a major challenge, especially in bialkali molecule platforms, is the fact that current measurement schemes for the internal states are destructive. In this work, we present a method to use Rydberg atoms to nondestructively measure the internal state of a molecular qubit. We achieve this via microwave dressing of both molecules and Rydberg atoms, allowing us to tune the interactions so that there are minimal Rydberg-Rydberg interactions and many measurements can take place simultaneously. We consider two experimentally-motivated examples of detecting $^{23}$Na$^{133}$Cs and $^{87}$Rb$^{133}$Cs with $^{133}$Cs atoms. Finally, we discuss several strategies for mitigating various sources of crosstalk.

</details>


### [5] [Exploring Bell Nonlocality with Extremal Non-Signaling Boxes](https://arxiv.org/abs/2601.08924)
*Emmanuel Zambrini Cruzeiro,Junior R. Gonzales-Ureta,Raman Choudhary,Hugo Abreu,Adán Cabello,Sébastien Designolle*

Main category: quant-ph

TL;DR: ENS（极值无信号）盒子是非定域性研究中的关键工具，本文系统研究了任意二分贝尔场景中的ENS盒子，并利用它们重新审视了多个基础问题。


<details>
  <summary>Details</summary>
Motivation: ENS盒子虽然根据量子理论是非物理的，但在贝尔非定域性研究中至关重要。目前对ENS盒子的系统研究不足，特别是在多个未探索的场景中。

Method: 1. 在任意二分贝尔场景中获取ENS盒子；2. 为多个未探索的场景提供完整的ENS盒子列表；3. 利用这些盒子重新审视基础问题，包括排他性原则、Specker原理、魔方关联的分解，以及通信模拟的局限性。

Result: 1. 获得了任意二分贝尔场景中的ENS盒子；2. 发现任意ENS盒子的两个副本都会违反排他性原则和Specker原理；3. 提供了魔方关联在ENS盒子中的最小分解；4. 确定了通信模拟ENS盒子的最小场景（d<6时不足）。

Conclusion: ENS盒子方法能够产生新结果并开辟新的研究方向，展示了这一理论工具在基础物理研究中的重要性。

Abstract: Extremal non-signaling (ENS) boxes are correlations that correspond to vertices of the non-signaling polytope of a Bell scenario. Neither quantum theory nor any theory for ideal measurements allows for ENS boxes. That is, according to quantum theory, ENS boxes are nonphysical. Still, ENS boxes are crucial for addressing a number of problems in Bell nonlocality. Here, we obtain ENS boxes in arbitrary bipartite Bell scenarios and present the complete list of ENS boxes for several unexplored scenarios. Equipped with the boxes, we revisit several foundational questions. We find that already two copies of any ENS box violate the exclusivity (or local orthogonality) and Specker's principles. We provide the minimal decomposition of the magic square correlation - the simplest known perfect correlation in nature - in terms of ENS boxes. We identify the minimal scenario in which a dit of communication (with d < 6) is insufficient to simulate ENS boxes. Our results show that the ENS boxes approach leads to new results and opens new avenues for research.

</details>


### [6] [Plutarch: Toward Scalable Operational Parallelism on Racetrack-Shaped Trapped-Ion Processors](https://arxiv.org/abs/2601.08930)
*Enhyeok Jang,Hyungseok Kim,Yongju Lee,Jaewon Kwon,Yipeng Huang,Won Woo Ro*

Main category: quant-ph

TL;DR: 量子计算中，racetrack处理器在认证随机性方面展现优势，但本文研究发现增加zone数量反而可能降低运行时效率，因此提出Plutarch策略来优化通用程序的执行性能。


<details>
  <summary>Details</summary>
Motivation: 虽然racetrack处理器在量子计算中展示了认证随机性的优势，但其在通用程序执行效率方面的表现尚不清楚。需要研究如何优化这种架构的运行时性能，特别是当增加并行区域（zones）时可能出现的效率下降问题。

Method: 首先通过变分程序评估增加zone对运行时效率的影响，发现现有调度策略下扩展zone可能降低性能。然后提出Plutarch策略，包含三个关键技术：1）幺正分解和翻译以最大化zone利用率；2）优先执行邻近门操作而非离子循环；3）实现快捷路径提供替代路径。

Result: 评估显示，增加zone数量可能因轨道长度增加导致的离子循环开销而降低运行时性能，这与直觉相反。Plutarch策略通过优化调度和路径选择来缓解这一问题。

Conclusion: racetrack处理器在通用程序执行中存在效率挑战，特别是zone扩展可能带来性能下降。Plutarch提出的三种策略能有效优化运行时性能，为量子计算架构设计提供了重要见解。

Abstract: A recent advancement in quantum computing shows a quantum advantage of certified randomness on the racetrack processor. This work investigates the execution efficiency of this architecture for general-purpose programs. We first explore the impact of increasing zones on runtime efficiency. Counterintuitively, our evaluations using variational programs reveal that expanding zones may degrade runtime performance under the existing scheduling policy. This degradation may be attributed to the increase in track length, which increases ion circulation overhead, offsetting the benefits of enhanced parallelism. To mitigate this, the proposed \textit{Plutarch} exploits 3 strategies: (i) unitary decomposition and translation to maximize zone utilization, (ii) prioritizing the execution of nearby gates over ion circulation, and (iii) implementing shortcuts to provide the alternative path.

</details>


### [7] [Demonstration Of A Quantum Magnetometer Chip Based On Proprietary And Scalable 4H-Silicon Carbide Technology](https://arxiv.org/abs/2601.08945)
*P. A. Stuermer,D. Wirtitsch,T. Steidl,R. Wörnle,J. Körber,W. Schustereder,C. Zmoelnig,P. Urlesberger,F. Chiapolino,S. Meinardi,K. Edelmann,M. Kern,J. Anders,S. Krainer,H. Heiss,M. Trupke,J. Wrachtrup*

Main category: quant-ph

TL;DR: 基于4H-SiC技术的工业级量子磁强计芯片，通过晶圆级制造优化V2色心，集成平面波导实现高效激发和荧光收集，灵敏度比传统共焦技术高2-3个数量级。


<details>
  <summary>Details</summary>
Motivation: 开发可工业规模化生产、功耗低、高性能的量子磁强计芯片，简化量子传感器架构，提高灵敏度，为下一代SiC量子传感技术铺平道路。

Method: 采用专有4H-SiC技术，通过晶圆级制造工艺优化V2硅空位色心的深度和密度；将色心集成到平面SiC波导中，实现高效激发和荧光收集；使用连续波光学检测磁共振测量，配合Rabi、Ramsey和Hahn-echo序列。

Result: 器件表现出传感器散粒噪声限制的灵敏度，比传统共焦技术低2-3个数量级；展示了大规模V2色心集合的相干能力；简化了光学激发和收集过程。

Conclusion: 该工作展示了工业可扩展、功耗低、高性能的量子磁强计芯片，通过简化架构和增强灵敏度，为下一代SiC量子传感技术的发展奠定了基础。

Abstract: This work presents an industrially scalable, power-efficient and high-performance quantum magnetometer chip based on proprietary 4H-silicon carbide (SiC) technology, leveraging wafer-scale fabrication techniques to optimize V2 silicon vacancy color centers for highly reproducible, industry-grade fabrication with precise control of depth and density. The integration of these color center ensembles into a planar silicon carbide waveguide enables efficient excitation of a large ensemble and simplifies fluorescence extraction compared to standard confocal methods. We report continuous-wave (CW) optically detected magnetic resonance measurements, complemented by Rabi, Ramsey, and Hahn-echo sequences, which demonstrate coherent capabilities of the large embedded ensemble of V2 centers. Based on the data, our device exhibits sensor shot-noise limited sensitivities 2-3 orders of magnitude lower compared to more complex confocal techniques. Collectively, these advancements simplify the quantum sensor architecture, enhance sensitivity, and streamline optical excitation and collection, thereby paving the way for the development of next-generation SiC-quantum sensing technologies.

</details>


### [8] [Obfuscation of Arbitrary Quantum Circuits](https://arxiv.org/abs/2601.08969)
*Miryam Mi-Ying Huang,Er-Cheng Tang*

Main category: quant-ph

TL;DR: 首次构造了支持量子输入输出的任意量子电路的理想混淆方案，解决了Bartusek等人提出的开放问题


<details>
  <summary>Details</summary>
Motivation: 量子混淆的核心开放问题是能否为任意量子电路构造混淆方案。先前工作只能混淆伪确定性函数或酉变换，但许多重要量子任务（如状态准备、量子纠错）属于更一般的完全正定保迹映射

Method: 在经典预言机模型下，基于后量子单向函数，引入新的原语：子空间保持强伪随机酉（spsPRU）。该原语在给定线性子空间上保持向量不变，在正交补空间上表现为Haar随机酉

Result: 成功构造了第一个支持量子输入输出的任意量子电路的理想混淆方案，解决了Bartusek等人提出的开放问题。通过将经典预言机实例化为Jain等人的理想混淆方案，该方案也可在量子可访问伪随机预言机模型中实现

Conclusion: 首次实现了对任意量子电路的理想混淆，为量子混淆领域提供了突破性进展，并引入了具有理论价值的新原语spsPRU

Abstract: Program obfuscation aims to conceal a program's internal structure while preserving its functionality. A central open problem is whether an obfuscation scheme for arbitrary quantum circuits exists. Despite several efforts having been made toward this goal, prior works have succeeded only in obfuscating quantum circuits that implement either pseudo-deterministic functions or unitary transformations. Although unitary transformations already include a broad class of quantum computation, many important quantum tasks, such as state preparation and quantum error-correction, go beyond unitaries and fall within general completely positive trace-preserving maps.
  In this work, we construct the first quantum ideal obfuscation scheme for arbitrary quantum circuits that support quantum inputs and outputs in the classical oracle model assuming post-quantum one-way functions, thereby resolving an open problem posed in Bartusek et al. (STOC 2023), Bartusek, Brakerski, and Vaikuntanathan (STOC 2024), and Huang and Tang (FOCS 2025). At the core of our construction lies a novel primitive that we introduce, called the subspace-preserving strong pseudorandom unitary (spsPRU). An spsPRU is a family of efficient unitaries that fix every vector in a given linear subspace $S$, while acting as a Haar random unitary on the orthogonal complement $S^\perp$ under both forward and inverse oracle queries. Furthermore, by instantiating the classical oracle model with the ideal obfuscation scheme for classical circuits proposed by Jain et al. (CRYPTO 2023) and later enhanced by Bartusek et al. (arxiv:2510.05316), our obfuscation scheme can also be realized in the quantumly accessible pseudorandom oracle model.

</details>


### [9] [Collective inhibition of light scattering from atoms into an optical cavity at a magic frequency](https://arxiv.org/abs/2601.08978)
*Á. Kurkó,B. Gábor,D. Varga,A. Simon,T. Barmashova,A. Dombi,T. W. Clark,F. I. B. Williams,D. Nagy,A. Vukics,P. Domokos*

Main category: quant-ph

TL;DR: 在铷-87原子的D2线超精细结构中发现了新的"魔法频率"，在该频率下光散射到高精细度腔中被抑制，这是量子干涉和原子与腔强集体耦合共同作用的结果。


<details>
  <summary>Details</summary>
Motivation: 研究在原子-光子强耦合系统中量子干涉如何影响光散射过程，探索新的频率点（魔法频率）下散射抑制现象。

Method: 使用激光驱动的冷原子云，通过偏振敏感方式测量光散射到近共振腔模式的过程，分析不同频率下的散射光谱。

Result: 发现了两个魔法频率：在F=2↔F'=3跃迁频率以下185MHz处，瑞利和拉曼散射都被抑制；在-506MHz处，只有拉曼散射被抑制。前者源于强耦合系统的极化子激发中的量子干涉，后者源于单原子水平的量子干涉。

Conclusion: 在原子-腔强耦合系统中，量子干涉可以导致特定频率下的光散射抑制，这为量子光学和量子信息处理提供了新的调控手段。

Abstract: We report on the observation of a new magic frequency within the hyperfine structure of the D2 line of ${}^{87}$Rb atoms at which the scattering of light into a high-finesse cavity is suppressed by an interplay between quantum interference and the strong collective coupling of atoms to the cavity. Scattering from a cloud of laser-driven cold atoms into the cavity was measured in a polarization sensitive way. We have found that both the Rayleigh and Raman scattering processes into the near-resonant cavity modes are extinguished at 185 MHz below the F=2$\leftrightarrow$F'=3 transition frequency. This coincidence together with the shape of the observed spectral dip imply that the effect relies on a quantum interference in the polariton excitations of the strongly coupled combined atom-photon system. We have also demonstrated the existence of a magic frequency around -506 MHz, where only the Raman scattering is suppressed due to a quantum interference effect at the single-atom level.

</details>


### [10] [Impact of control signal phase noise on qubit fidelity](https://arxiv.org/abs/2601.09014)
*Agata Barsotti,Paolo Marconcini,Gregorio Procissi,Massimo Macucci*

Main category: quant-ph

TL;DR: 研究相位噪声对量子比特控制脉冲序列保真度的影响，通过数值模拟分析参考振荡器相位噪声对量子门操作性能的退化效应。


<details>
  <summary>Details</summary>
Motivation: 随着量子比特退相干时间延长和读出技术改进，控制信号中的非理想特性（如相位噪声）将成为限制复杂控制脉冲序列保真度的主要因素，需要系统研究其对量子门操作性能的影响。

Method: 使用数值模拟方法，生成符合给定功率谱密度的相位噪声实现，将其应用于脉冲载波，利用Qiskit-Dynamics模拟量子比特的时间演化，通过比较理想情况和噪声情况下的最终状态来评估保真度退化。

Result: 通过多次噪声实现的平均，量化了相位噪声导致的保真度退化，并利用相位波动载波的近似解析表示，分析了不同频谱分量对保真度的影响。

Conclusion: 相位噪声对量子比特控制脉冲序列的保真度有显著影响，需要系统评估和优化参考振荡器的相位噪声特性，以提高量子门操作的性能。

Abstract: As qubit decoherence times are increased and readout technologies are improved, nonidealities in the drive signals, such as phase noise, are going to represent a growing limitation to the fidelity achievable at the end of complex control pulse sequencies. Here we study the impact on fidelity of phase noise affecting reference oscillators with the help of numerical simulations, which allow us to directly take into account the interaction between the phase fluctuations in the control signals and the evolution of the qubit state. Our method is based on the generation of phase noise realizations consistent with a given power spectral density, that are then applied to the pulse carrier in simulations, with Qiskit-Dynamics, of the qubit temporal evolution. By comparing the final state obtained at the end of a noisy pulse sequence with that in the ideal case and averaging over multiple noise realizations, we estimate the resulting degradation in fidelity, and exploiting an approximate analytical representation of a carrier affected by phase fluctuations, we discuss the contributions of the different spectral components of phase noise.

</details>


### [11] [Casimir effect with dielectric matter in salted water and implications at the cell scale](https://arxiv.org/abs/2601.09020)
*Larissa Inácio,Felipe S. S. Rosa,Astrid Lambrecht,Paulo A. Maia Neto,Serge Reynaud*

Main category: quant-ph

TL;DR: 盐水中卡西米尔相互作用包含电磁涨落的普适贡献，使其作用范围比先前认为的更远，在细胞尺度上具有重要影响


<details>
  <summary>Details</summary>
Motivation: 研究盐水中卡西米尔相互作用的普适贡献，特别是在细胞内部肌动蛋白纤维相关距离尺度上的重要性

Method: 使用模拟生物物质的模型，分析卡西米尔相互作用中的普适和非普适贡献

Result: 发现普适贡献在细胞内部肌动蛋白纤维相关距离尺度上占主导地位，且作用范围比先前认为的更远

Conclusion: 普适卡西米尔效应在细胞尺度上具有重要影响，对理解细胞内部相互作用机制有重要意义

Abstract: The Casimir interaction in salted water contains a universal contribution of electromagnetic fluctuations that makes it of a longer range than previously thought. The universal contribution dominates non universal ones at the distances relevant for actin fibers inside the cell. We discuss universal and non-universal contributions with a model mimicking biological matter. We also show that the universal Casimir effect should have important implications at the cell scale.

</details>


### [12] [Mechanistic principles of exciton-polariton relaxation](https://arxiv.org/abs/2601.09068)
*Ian Haines,Arshath Manjalingal,Logan Blackham,Saeed Rahamanian Koshkaki,Arkajit Mandal*

Main category: quant-ph

TL;DR: 该研究揭示了激子极化激元弛豫的微观机制：上极化激元通过两步过程弛豫到下极化激元，包括垂直带间跃迁和带内Fröhlich散射，并发现有限厚度材料中声子诱导的散射因极化激元空间离域而显著抑制。


<details>
  <summary>Details</summary>
Motivation: 激子极化激元作为光-物质混合准粒子在量子技术和材料工程中具有重要应用，但其动力学和弛豫的基本机制原理尚不清楚。本研究旨在提供上极化激元激发后弛豫过程的微观机制理解。

Method: 采用混合量子-经典模拟和理论分析相结合的方法，研究激子极化激元弛豫过程。通过模拟揭示弛豫步骤，并通过分析推导材料有限厚度与弛豫速率常数的关系。

Result: 发现声子诱导的上-下极化激元弛豫通过两步进行：1) 垂直带间跃迁；2) 下极化激元带内的Fröhlich散射。在有限厚度材料中，声子诱导的极化激元带内Fröhlich散射显著抑制，其微观起源是极化激元在量子化方向的空间离域导致的声子涨落同步效应。

Conclusion: 该研究阐明了激子极化激元弛豫的微观机制，揭示了声子涨落同步效应在极化激元弛豫途径中的核心作用，并建立了材料有限厚度与弛豫速率常数关系的解析表达式，为设计极化激元器件提供了理论基础。

Abstract: Exciton-polaritons are light-matter hybrid quasi-particles that have emerged as a flexible platform for developing quantum technologies and engineering material properties. However, the fundamental mechanistic principles that govern their dynamics and relaxation remain elusive. In this work, we provide the microscopic mechanistic understanding of the exciton-polariton relaxation process that follows from an excitation in the upper polariton. Using both mixed quantum-classical simulations and analytical analysis, we reveal that phonon-induced upper-to-lower polariton relaxation proceeds via two steps: the first step is a vertical inter-band transition from the upper to the lower polariton, which is followed by a second step that is a phonon-induced Fröhlich scattering within the lower polariton. We find that in materials of finite thickness (which include filled cavities), phonon-induced polaritonic intraband Fröhlich scattering is significantly suppressed. We show that the microscopic origin of this suppression is phonon-fluctuations synchronization (or self-averaging) due to the polaritonic spatial delocalization in the quantization direction. Finally, we show that the same phonon fluctuation-synchronization effect plays a central role across polaritonic relaxation pathways, and we derive simple analytical expressions that relate a material's finite thickness to the corresponding relaxation rate constants.

</details>


### [13] [Displacement-Squeeze receiver for BPSK displaced squeezed vacuum states surpassing the coherent-states Helstrom bound under imperfect conditions](https://arxiv.org/abs/2601.09073)
*Enhao Bai,Jian Peng,Tianyi Wu,Kai Wen,Fengkai Sun,Chun Zhou,Yaping Li,Zhenrong Zhang,Chen Dong*

Main category: quant-ph

TL;DR: 提出位移-压缩接收器(DSR)用于区分BPSK位移压缩真空态(S-BPSK)，通过位移和旋转π/2的压缩操作增强态的可区分性，在低能量区域超越SQL并接近Helstrom界。


<details>
  <summary>Details</summary>
Motivation: 传统BPSK量子态区分存在性能限制，需要开发新的接收器设计来提升在低能量区域的区分性能，特别是在压缩态场景下超越标准量子极限。

Method: 采用位移-压缩接收器(DSR)：先进行位移操作，再进行旋转π/2的压缩操作，最后使用光子数分辨探测和最大后验概率阈值决策，通过增加相空间距离和减少Fock基重叠来增强态的可区分性。

Result: 在所有信号能量N下，DSR错误率在[DSS-HB, 2×DSS-HB]范围内；在低能量区域(N≈0.3)超越S-BPSK SQL，在N≈0.4时低于C-BPSK Helstrom界，在N≈0.6时错误率<1%；在非理想条件下通过MAP阈值自适应保持鲁棒性。

Conclusion: DSR接收器为BPSK位移压缩真空态提供了一种有效的区分方案，在低能量区域显著提升性能，并在各种非理想条件下保持鲁棒性，为量子通信和传感应用提供了实用工具。

Abstract: We propose a displacement-squeeze receiver (DSR) for discriminating BPSK displaced squeezed vacuum states (S-BPSK). The receiver applies a displacement followed by a squeezing operation with the squeezing axis rotated by $\fracπ{2}$, and performs photon-number-resolving detection with a MAP threshold decision. This processing effectively increases the distinguishability of the input states by elongating their distance in phase space and reducing their population overlap in Fock basis. We show that for all signal energy N, $P_\text{err}^\text{DSR} \in \left[P_\text{HB}^\text{DSS}, 2P_\text{HB}^\text{DSS}\right]$, under equal priors and ideal condition. In the low-energy regime, DSR beats the S-BPSK SQL at $N \approx 0.3$ and drops below the coherent-state BPSK (C-BPSK) Helstrom bound at $N \approx 0.4$, reaching $P_\text{err}^\text{DSR} < 1\%$ near $N \approx 0.6$. Finally, we quantify performance under non-unit efficiency and dark counts, phase diffusion, and receiver thermal noise, with MAP threshold adaptation providing robustness across these nonidealities.

</details>


### [14] [Learning Volterra Kernels for Non-Markovian Open Quantum Systems](https://arxiv.org/abs/2601.09075)
*Jimmie Adriazola,Katarzyna Roszak*

Main category: quant-ph

TL;DR: 开发了一个数据驱动的框架，用于识别开放量子系统的非马尔可夫动力学方程，基于Nakajima-Zwanzig形式，将约化密度矩阵向量化，并将动力学建模为具有算子值记忆核的Volterra积分微分方程。


<details>
  <summary>Details</summary>
Motivation: 开放量子系统的非马尔可夫动力学建模具有挑战性，传统方法难以处理复杂的记忆效应。需要开发数据驱动的方法来从观测数据中直接识别动力学方程。

Method: 基于Nakajima-Zwanzig形式，将约化密度矩阵向量化为四维状态向量，将动力学建模为Volterra积分微分方程。通过约束优化问题学习算子值记忆核，使用Padé近似将相关函数近似为有理函数。

Result: 建立了学习问题的适定性，表明该方法能够从数据中可靠地识别非马尔可夫动力学方程。

Conclusion: 提出的数据驱动框架为开放量子系统的非马尔可夫动力学建模提供了有效方法，能够从观测数据中识别复杂的记忆效应。

Abstract: We develop a data-driven framework for identifying non-Markovian dynamical equations of motion for open quantum systems. Starting from the Nakajima--Zwanzig formalism, we vectorize the reduced density matrix into a four-dimensional state vector and cast the dynamics as a Volterra integro-differential equation with an operator-valued memory kernel. The learning task is then formulated as a constrained optimization problem over the admissible operator space, where correlation functions are approximated by rational functions using Padé approximants. We establish well-posedness of the learnin

</details>


### [15] [A saturation-absorption rubidium magnetometer with multilevel optical Bloch-equation modeling for intermediate-to-high fields](https://arxiv.org/abs/2601.09115)
*Mayand Dangi,Prateek Rajan Gupta,Joseph Kasti,Nivedan Vishwanath,Michael Zepp,David Smith,Benedikt Geiger,Jennifer T. Choy*

Main category: quant-ph

TL;DR: SASHMAG是一种用于0.2T以上中高磁场精确测量的原子磁力计，基于铷-87饱和吸收光谱，在超精细帕邢-巴克区工作，通过物理约束优化实现±0.0017T的测量精度。


<details>
  <summary>Details</summary>
Motivation: 开发能够在中间到高磁场区域（>0.2T）进行精确磁场测量的原子传感器，为MRI、聚变反应堆等应用提供高精度磁场监测能力。

Method: 使用铷-87原子在超精细帕邢-巴克区工作，采用法拉第几何中的反向传播泵浦-探测配置，建立多级光学布洛赫方程模型，通过物理约束优化算法从实验谱线中心推断磁场。

Result: 在0.2T到0.4T磁场范围内实现了±0.0017T的测量精度，验证的仿真模型为生成合成训练数据集奠定了基础。

Conclusion: SASHMAG系统成功实现了中高磁场的精确测量，为自主机器学习增强磁力计的发展铺平了道路，在医学成像和聚变能源等领域具有应用前景。

Abstract: We present SASHMAG (Saturated Absorption Spectroscopy High-field MAGnetometer), an atomic sensor designed for precision magnetic-field measurements in the intermediate-to-high field regime ($>0.2\,\text{T}$) using Rubidium-87 ($^{87}Rb$). The sensor operates in the hyperfine Paschen-Back regime, where the hyperfine and Zeeman interactions decouple, and utilizes counter-propagating pump-probe configuration in Faraday geometry to resolve isolated, Doppler-free Zeeman transitions. To interpret the resulting spectra in this strongly field-dependent regime, we developed a comprehensive multilevel optical Bloch-equation model solved explicitly in the uncoupled $\ket{m_I, m_J}$ basis, capturing state mixing and nonlinear saturation dynamics. This model reproduces measured spectra at sub-Doppler resolution and is consistent with analytical expectations for power broadening and thermal Doppler scaling. Magnetic field estimation is performed using a physics-constrained optimization routine that infers the magnetic field by minimizing the residual between experimentally extracted line centers and calculated transition frequencies from the field-dependent Hamiltonian. We demonstrate magnetic field retrieval from $0.2\,\text{T}$ to $0.4\,\text{T}$ with a precision of $\pm 0.0017 \,\text{T}$). Furthermore, the validated simulation establishes a foundation for generating synthetic training datasets, paving the way for autonomous, Machine Learning-enhanced magnetometry in applications ranging from MRI to fusion reactors.

</details>


### [16] [Distributed Exact Quantum Amplitude Amplification Algorithm for Arbitrary Quantum States](https://arxiv.org/abs/2601.09128)
*Xu Zhou,Wenxuan Tao,Keren Li,Shenggen Zheng*

Main category: quant-ph

TL;DR: 提出分布式精确量子振幅放大算法(DEQAAA)，支持任意节点划分，实现任意振幅分布量子态的多目标精确放大，显著减少量子门数量和电路深度。


<details>
  <summary>Details</summary>
Motivation: 在NISQ时代，分布式量子计算能克服单设备架构的物理限制，实现可扩展的量子信息处理。现有方法在处理任意振幅分布量子态的精确振幅放大方面存在挑战。

Method: 提出分布式精确量子振幅放大算法(DEQAAA)：1)支持2≤t≤n个节点的任意划分；2)单节点最大量子比特数为max(n_j)；3)实现任意振幅分布量子态的多目标精确放大；4)通过分解C^{n-1}PS门优化电路。

Result: 在MindSpore Quantum上验证了DEQAAA的有效性，测试了4、6、8、10量子比特系统。在10量子比特场景下，相比QAAA和EQAAA，量子门数量和电路深度均减少超过97%，展现出卓越的资源节省性能。

Conclusion: DEQAAA算法在分布式量子计算中实现了任意振幅分布量子态的精确振幅放大，通过优化电路结构显著减少了资源消耗，增强了噪声鲁棒性，为NISQ时代的可扩展量子计算提供了有效解决方案。

Abstract: In the noisy intermediate-scale quantum (NISQ) era, distributed quantum computation has garnered considerable interest, as it overcomes the physical limitations of single-device architectures and enables scalable quantum information processing. In this study, we focus on the challenge of achieving exact amplitude amplification for quantum states with arbitrary amplitude distributions and subsequently propose a Distributed Exact Quantum Amplitude Amplification Algorithm (DEQAAA). Specifically, (1) it supports partitioning across any number of nodes $t$ within the range $2 \leq t \leq n$; (2) the maximum qubit count required for any single node is expressed as $\max \left(n_0,n_1,\dots,n_{t-1} \right) $, where $n_j$ represents the number of qubits at the $j$-th node, with $\sum_{j=0}^{t-1} n_j =n$; (3) it can realize exact amplitude amplification for multiple targets of a quantum state with arbitrary amplitude distributions; (4) we verify the effectiveness of DEQAAA by resolving a specific exact amplitude amplification task involving two targets (8 and 14 in decimal) via MindSpore Quantum, a quantum simulation software, with tests conducted on 4-qubit, 6-qubit, 8-qubit and 10-qubit systems. Notably, through the decomposition of $C^{n-1}PS$ gates, DEQAAA demonstrates remarkable advantages in both quantum gate count and circuit depth as the qubit number scales, thereby boosting its noise resilience. In the 10-qubit scenario, for instance, it achieves a reduction of over $97\%$ in both indicators compared to QAAA and EQAAA, underscoring its outstanding resource-saving performance.

</details>


### [17] [Bidirectional Decoding for Concatenated Quantum Hamming Codes](https://arxiv.org/abs/2601.09131)
*Chao Zhang,Zipeng Wu,Jiahui Wu,Shilin Huang*

Main category: quant-ph

TL;DR: 提出了一种用于级联量子汉明码的双向硬判决译码器，通过利用高层校验信息修正低层恢复决策，显著提高了译码阈值和逻辑错误抑制速度。


<details>
  <summary>Details</summary>
Motivation: 高速率级联量子码是实现容错量子计算的有前途途径，但设计能够充分利用其纠错能力的高效译码器仍然是一个重大挑战。传统局部译码方法存在局限性，需要更有效的译码策略。

Method: 提出了双向译码器，这是一种用于级联量子汉明码的硬判决译码器，具有多项式时间复杂度。该方法通过利用高层校验信息来修正低层的恢复决策，克服了传统局部译码的局限性。

Result: 对于独立比特翻转噪声下的级联[[15,7,3]]量子汉明码，双向译码器将译码阈值从约1.56%提高到4.35%。此外，译码器在至少三级级联中保持了完整的3^L码距缩放，比局部译码器的2^{L+1}缩放提供了更快的逻辑错误抑制。

Conclusion: 双向译码器显著提高了级联量子码的译码性能，增强了级联码架构在低开销容错量子计算中的竞争力，为实现高效量子计算提供了有前景的解决方案。

Abstract: High-rate concatenated quantum codes offer a promising pathway toward fault-tolerant quantum computation, yet designing efficient decoders that fully exploit their error-correction capability remains a significant challenge. In this work, we introduce a hard-decision decoder for concatenated quantum Hamming codes with time complexity polynomial in the block length. This decoder overcomes the limitations of conventional local decoding by leveraging higher-level syndrome information to revise lower-level recovery decisions -- a strategy we refer to as bidirectional decoding. For the concatenated $[[15,7,3]]$ quantum Hamming code under independent bit-flip noise, the bidirectional decoder improves the threshold from approximately $1.56\%$ to $4.35\%$ compared with standard local decoding. Moreover, the decoder empirically preserves the full $3^{L}$ code-distance scaling for at least three levels of concatenation, resulting in substantially faster logical-error suppression than the $2^{L+1}$ scaling offered by local decoders. Our results can enhance the competitiveness of concatenated-code architectures for low-overhead fault-tolerant quantum computation.

</details>


### [18] [Quantum Latin squares of order $6m$ with all possible cardinalities](https://arxiv.org/abs/2601.09132)
*Ying Zhang,Lijun Ji*

Main category: quant-ph

TL;DR: 证明了对于任意整数 m≥2 和任意 c∈[6m,36m²]∖{6m+1}，都存在一个量子拉丁方 QLS(6m) 其基数为 c。


<details>
  <summary>Details</summary>
Motivation: 研究量子拉丁方中不同向量的数量（基数）的存在性问题，探索量子拉丁方结构的多样性。

Method: 使用子量子拉丁方 sub-QLS(6) 来构造 QLS(6m)，通过组合方法证明基数 c 的存在性。

Result: 对于任意 m≥2 和 c∈[6m,36m²]∖{6m+1}，都存在一个 QLS(6m) 其基数为 c，填补了量子拉丁方基数存在性的空白。

Conclusion: 量子拉丁方的基数存在范围很广，除了一个例外值 6m+1 外，在区间 [6m,36m²] 内的所有整数都可以作为 QLS(6m) 的基数。

Abstract: A quantum Latin square of order $n$ (denoted as QLS$(n)$) is an $n\times n$ array whose entries are unit column vectors from the $n$-dimensional Hilbert space $\mathcal{H}_n$, such that each row and column forms an orthonormal basis. Two unit vectors $|u\rangle, |v\rangle\in \mathcal{H}_n$ are regarded as identical if there exists a real number $θ$ such that $|u\rangle=e^{iθ}|v\rangle$; otherwise, they are considered distinct. The cardinality $c$ of a QLS$(n)$ is the number of distinct vectors in the array. In this note,we use sub-QLS$(6)$ to prove that for any integer $m\geq 2$ and any $c\in [6m,36m^2]\setminus \{6m+1\}$, there is a QLS$(6m)$ with cardinality $c$.

</details>


### [19] [Transient fields in oblique scattering from an infinite planar dielectric interface -- a qubit lattice simulation](https://arxiv.org/abs/2601.09135)
*Min Soe,George Vahala,Linda Vahala,Efstratios Koukoutsis,Abhay K. Ram,Kyriakos Hizanidis*

Main category: quant-ph

TL;DR: 使用初值算法研究有限脉冲从无限平面介质界面斜散射时电磁场的时变演化，发现反射脉冲保持高斯形状，而透射脉冲呈现高斯包络与惠更斯波前混合的特征。


<details>
  <summary>Details</summary>
Motivation: 研究有限脉冲在介质界面斜散射时的电磁场时变演化特性，特别是脉冲形状变化和能量守恒问题。

Method: 采用初值算法和量子比特晶格算法（QLA），分析高斯包络脉冲在入射角小于全反射角情况下的散射过程。

Result: 反射脉冲保持整体高斯形状，透射脉冲呈现高斯包络与从碰撞点发出的惠更斯波前混合特征，且惠更斯波前强度取决于入射脉冲宽度。

Conclusion: QLA算法能很好保持电磁能量守恒，有限脉冲在介质界面散射会产生复杂的透射波前结构，脉冲宽度影响惠更斯波前强度。

Abstract: An initial value algorithm is utilized to examine the time dependent evolution of the electromagnetic fields arising from oblique scattering of bounded pulses from an infinite planar dielectric interface. Since the qubit lattice algorithm (QLA) is almost fully unitary, one finds excellent conservation of electromagnetic energy. Various Gaussian envelope pulses are considered in regimes where the incident angle is below that needed for total internal reflection. While the reflected pulse retains its overall Gaussian shape, the transmitted pulse exhibits a combination of a Gaussian envelope along with Huygen-like emitted wave fronts from the collision point of the initial pulse with the infinite dielectric interface. The strength of these Huygen wavefronts depends on the width of the incident pulse.

</details>


### [20] [Many-Body Effects in Dark-State Laser Cooling](https://arxiv.org/abs/2601.09180)
*Muhammad Miskeen Khan,David Wellnitz,Bhuvanesh Sundar,Haoqing Zhang,Allison Carter,John J. Bollinger,Athreya Shankar,Ana Maria Rey*

Main category: quant-ph

TL;DR: 该论文建立了统一的多体理论来分析两光子暗态激光冷却，揭示了离子数量对冷却速率和最终温度的交叉影响，为优化大型离子晶体冷却提供了理论指导。


<details>
  <summary>Details</summary>
Motivation: 开发一个统一的多体理论来理解两光子暗态激光冷却机制，这是将囚禁离子制备到运动量子基态附近的关键技术。需要解释离子数量如何影响冷却性能，为可扩展的囚禁离子量子技术提供优化指导。

Method: 采用统一的多体理论框架，分析具有Λ能级结构的离子在拉曼激光驱动下的冷却过程。在弱耦合和强耦合两种极限情况下推导解析解，并与精确数值模拟进行比较验证。

Result: 发现了离子数量依赖的弱耦合与强耦合交叉点，在该点冷却速率和最终温度同时优化。弱耦合极限下冷却速率和最终占据数与离子数量无关；强耦合极限下集体动力学导致冷却速率随离子数量增加而增强。

Conclusion: 理论解析结果与数值模拟高度一致，为优化大型离子晶体冷却提供了实验可操作的指导，这是实现可扩展、高保真囚禁离子量子技术的关键步骤。

Abstract: We develop a unified many-body theory of two-photon dark-state laser cooling, the workhorse for preparing trapped ions close to their motional quantum ground state. For ions with a $Λ$ level structure, driven by Raman lasers, we identify an ion-number-dependent crossover between weak and strong coupling where both the cooling rate and final temperature are simultaneously optimized. We obtain simple analytic results in both extremes: In the weak coupling limit, we show a Lorentzian spin-absorption spectrum determines the cooling rate and final occupation of the motional state, which are both independent of the number of ions. We also highlight the benefit of including an additional spin dependent force in this case. In the strong coupling regime, our theory reveals the role of collective dynamics arising from phonon exchange between dark and bright states, allowing us to explain the enhancement of the cooling rate with increasing ion number. Our analytic results agree closely with exact numerical simulations and provide experimentally accessible guidelines for optimizing cooling in large ion crystals, a key step toward scalable, high-fidelity trapped-ion quantum technologies.

</details>


### [21] [Ascertaining higher-order quantum correlations in high energy physics](https://arxiv.org/abs/2601.09203)
*Ao-Xiang Liu,Cong-Feng Qiao*

Main category: quant-ph

TL;DR: 该研究探索了超子-反超子系统中的高阶量子关联，提出了基于统计累积量和中心矩的新型Clauser-Horne不等式，发现三阶约束存在显著违反，表明存在高阶量子关联，可在BESIII和Belle II等高能物理实验中观测。


<details>
  <summary>Details</summary>
Motivation: 量子非定域性作为重要的量子资源，目前主要研究其线性特性（一阶矩）。注意到高阶领域尚未充分探索，本研究旨在研究超子-反超子纠缠系统中的高阶量子关联，这些系统可在粲偶素衰变中大量产生。

Method: 提出了基于统计累积量和中心矩的新型Clauser-Horne不等式，用于检测高阶量子关联。研究聚焦于超子-反超子系统，特别是ΛΛ̅对，分析其在高能物理实验环境下的行为。

Result: 发现三阶约束存在显著违反，表明超子-反超子系统中存在高阶量子关联。特别值得注意的是，ΛΛ̅对在更高能量系统中，相对于类时事件的运动学污染，违反现象更为明显。

Conclusion: 高阶量子关联在超子-反超子系统中确实存在，可通过新型不等式检测。这些发现为在高能物理实验（如BESIII和Belle II）中观测高阶量子非定域性提供了理论基础，拓展了量子关联研究的维度。

Abstract: Nonlocality is a peculiar nature of quanta and it stands as an important quantum resource in application. Yet mere linear property of it, viz. the first order in moment, has been explored through various inequalities. Noticing the vast higher-order regime unexplored, in this study we investigate the higher-order quantum correlations in entangled hyperon-antihyperon system, which may be generated massively in charmonium decays. A new type of Clauser-Horne inequality for statistical cumulants and central moments is formulated. We find that a significant violation of the third-order constraint, indicating the existence of higher-order correlation, exists in hyperon-antihyperon system and can be observed in high energy physics experiments, like BESIII and Belle II. Notably, the violation manifests more in higher energy systems of the $Λ\barΛ$ pair against the kinematic contamination of timelike events.

</details>


### [22] [Scale Invariance Breaking and Discrete Phase Invariance in Few-Body Problems](https://arxiv.org/abs/2601.09266)
*Satoshi Ohya*

Main category: quant-ph

TL;DR: 连续标度不变性可以破缺为离散相位不变性，这是一种新的对称性破缺模式，在特定耦合常数窗口出现，并在S矩阵的黎曼面上表现为圆形分布的简单极点。


<details>
  <summary>Details</summary>
Motivation: 研究量子力学中标度不变性的破缺方式，除了已知的连续标度不变性破缺为离散标度不变性（如Efimov效应），探索是否存在其他离散对称性破缺模式。

Method: 首先在半直线上的一体问题中研究逆平方势，分析连续标度不变性如何破缺为离散相位不变性；然后通过S矩阵的黎曼面结构分析；最后给出三个具体例子：Aharonov-Bohm一体问题、二维非全同粒子的二体问题、一维非全同粒子的三体问题。

Result: 发现在特定耦合常数窗口内，连续标度不变性确实可以破缺为离散相位不变性；这种对称性破缺在S矩阵的黎曼面上表现为圆形分布的简单极点；三个具体例子都展示了这种离散相位不变性。

Conclusion: 连续标度不变性可以破缺为离散相位不变性，这是一种新的对称性破缺模式，出现在包含"磁通量"的配置空间中，为量子力学中的标度不变性研究提供了新的视角。

Abstract: Scale invariance in quantum mechanics can be broken in several ways. A well-known example is the breakdown of continuous scale invariance to discrete scale invariance, whose typical realization is the Efimov effect of three-body problems. Here we discuss yet another discrete symmetry to which continuous scale invariance can be broken: discrete phase invariance. We first revisit the one-body problem on the half line in the presence of an inverse-square potential -- the simplest example of nontrivial scale-invariant quantum mechanics -- and show that continuous scale invariance can be broken to discrete phase invariance in a small window of coupling constant. We also show that discrete phase invariance manifests itself as circularly distributed simple poles on Riemann sheets of the S-matrix. We then present three examples of few-body problems that exhibit discrete phase invariance. These examples are the one-body Aharonov-Bohm problem, a two-body problem of nonidentical particles in two dimensions, and a three-body problem of nonidentical particles in one dimension, all of which contain a codimension-two ``magnetic'' flux in configuration spaces.

</details>


### [23] [Geometric Hybrid Poincaré Sphere with Variable Poles](https://arxiv.org/abs/2601.09279)
*Chihiro Tago,Takashi Kakue,Ken Morita*

Main category: quant-ph

TL;DR: 提出几何混合庞加莱球(GHPS)作为统一几何框架，用于描述具有独立可控自旋角动量(SAM)和轨道角动量(OAM)的结构化光子态。


<details>
  <summary>Details</summary>
Motivation: 传统高阶庞加莱球中SAM和OAM通过固定基态固有耦合，限制了结构化光场的灵活控制。需要一种能够独立控制SAM和OAM的统一几何框架。

Method: 通过定义GHPS的极点为庞加莱球(PS)和轨道庞加莱球(OPS)上任意正交基的直接乘积，并叠加这些极点态来构建GHPS框架。使用数值模拟分析代表性GHPS态。

Result: GHPS球坐标控制极点基之间的振幅比和相对相位，能够实现空间不均匀的偏振分布和强度模式，包括偏振和强度固有交织的非可分离结构。

Conclusion: GHPS为先进结构化光场的相干几何控制提供了系统的态空间描述框架，实现了SAM和OAM的独立控制。

Abstract: We propose a geometric hybrid Poincaré sphere (GHPS) as a unified geometrical framework for describing structured photon states with independently controllable spin angular momentum (SAM) and orbital angular momentum (OAM). Unlike the conventional higher-order Poincaré sphere, in which the SAM and OAM are intrinsically coupled through fixed basis states, the GHPS is constructed by defining its poles as direct products of arbitrary orthogonal bases on the Poincaré sphere (PS) and orbital Poincaré sphere (OPS) and by superposing these pole states. Using numerical simulations, we analyze representative GHPS states and show that the GHPS spherical coordinates govern the amplitude ratio and relative phase between the pole bases. This framework enables spatially inhomogeneous polarization distributions and intensity patterns, including nonseparable structures in which polarization and intensity are intrinsically intertwined, and provides a systematic state-space description for the coherent geometrical control of advanced structured light fields.

</details>


### [24] [A Posteriori Certification Framework for Generalized Quantum Arimoto-Blahut Algorithms](https://arxiv.org/abs/2601.09301)
*Geng Liu,Masahito Hayashi*

Main category: quant-ph

TL;DR: 提出一种后验认证的广义量子Arimoto-Blahut算法，通过检查迭代轨迹验证收敛性，应用于量子信道相对熵计算，相比SDP方法更高效可扩展。


<details>
  <summary>Details</summary>
Motivation: 现有量子Arimoto-Blahut算法的收敛性证明依赖过于严格或难以验证的先验条件，限制了其实际应用。需要一种更实用的认证方法来确保算法收敛和结果可靠性。

Method: 引入后验认证视角：不依赖先验可验证假设，而是通过检查算法迭代轨迹中的显式不等式来认证全局最优性和界定次优性。结合凸性和数值可验证条件，证明广义全局收敛定理。

Result: 建立了实用的认证程序，通过检查计算轨迹中的不等式可以认证全局最优性并界定次优性。开发了计算量子信道相对熵的认证迭代方案，数值实验显示相比基于SDP的方法具有更快的收敛速度、更好的可扩展性和适应性。

Conclusion: 后验认证方法克服了量子Arimoto-Blahut算法收敛性证明的障碍，提供了一种实用可靠的认证框架。该方法特别适用于量子信道相对熵等复杂量子信息量的计算，避免了梯度法和SDP方法的瓶颈。

Abstract: The generalized quantum Arimoto--Blahut (QAB) algorithm is a powerful derivative-free iterative method in quantum information theory. A key obstacle to its broader use is that existing convergence guarantees typically rely on analytical conditions that are either overly restrictive or difficult to verify for concrete problems. We address this issue by introducing an a posteriori certification viewpoint: instead of requiring fully a priori verifiable assumptions, we provide convergence and error guarantees that can be validated directly from the iterates produced by the algorithm. Specifically, we prove a generalized global convergence theorem showing that, under convexity and a substantially weaker numerically verifiable condition, the QAB iteration converges to the global minimizer. This theorem yields a practical certification procedure: by checking explicit inequalities along the computed trajectory, one can certify global optimality and bound the suboptimality of the obtained value. As an application, we develop a certified iterative scheme for computing the quantum relative entropy of channels, a fundamental measure of distinguishability in quantum dynamics. This quantity is notoriously challenging to evaluate numerically: gradient-based methods are impeded by the complexity of matrix functions such as square roots and logarithms, while recent semidefinite programming approaches can become computationally and memory intensive at high precision. Our method avoids these bottlenecks by combining the QAB iteration with a posteriori certification, yielding an efficient and scalable algorithm. Numerical experiments demonstrate rapid convergence and improved scalability and adaptivity compared with SDP-based approaches.

</details>


### [25] [A game-theoretic probability approach to loopholes in CHSH experiments](https://arxiv.org/abs/2601.09339)
*Takara Nomura,Koichi Yamagata,Akio Fujiwara*

Main category: quant-ph

TL;DR: 使用博弈论概率从信息论和时间敏感视角研究CHSH不等式，避免假设基础概率空间。将定域性漏洞和测量依赖性漏洞重新表述为科学家与自然之间序贯隐藏变量博弈的结构约束，构建了漏洞闭合的博弈，证明自然无法同时满足两个资本过程的收敛性，为科学家提供了可操作的获胜策略。


<details>
  <summary>Details</summary>
Motivation: 传统CHSH不等式分析通常基于概率空间假设，存在定域性漏洞和测量依赖性漏洞。本文旨在从信息论和博弈论角度重新审视这些漏洞，避免对基础概率结构的假设，为实验观察到的CHSH违反提供更坚实的理论基础。

Method: 采用博弈论概率方法，将CHSH实验建模为科学家与自然之间的序贯隐藏变量博弈。将定域性漏洞和测量依赖性漏洞重新表述为博弈的结构约束，构建包含两个资本过程的漏洞闭合博弈：一个测试经验条件频率向CHSH相关性的收敛，另一个测试测量设置与自然隐藏变量分配之间系统相关性的缺失。

Result: 证明自然无法同时满足两个资本过程的收敛性：至少一个资本过程必须发散。这为科学家提供了可操作的获胜策略，并为实验观察到的CHSH违反提供了博弈论概率解释。

Conclusion: 通过博弈论概率框架，成功将CHSH不等式分析从传统概率空间假设中解放出来，为量子非定域性实验提供了更严格的漏洞闭合验证方法，同时为科学家提供了明确的实验验证策略。

Abstract: We study the CHSH inequality from an informational, timing-sensitive viewpoint using game-theoretic probability, which avoids assuming an underlying probability space. The locality loophole and the measurement-dependence (``freedom-of-choice'') loophole are reformulated as structural constraints in a sequential hidden-variable game between Scientists and Nature. We construct a loopholes-closed game with capital processes that test (i) convergence of empirical conditional frequencies to the CHSH correlations and (ii) the absence of systematic correlations between measurement settings and Nature's hidden-variable assignments, and prove that Nature cannot satisfy both simultaneously: at least one capital process must diverge. This yields an operational winning strategy for Scientists and a game-theoretic probabilistic interpretation of experimentally observed CHSH violations.

</details>


### [26] [Eigenstate Thermalization and Spectral Imprints of the Hamiltonian in Local Observables](https://arxiv.org/abs/2601.09340)
*Shivam Mishra,C Jisha,Ravi Prakash*

Main category: quant-ph

TL;DR: 该研究通过分析XXZ自旋链中局部可观测量在能量本征基下的子矩阵结构，建立了哈密顿量谱关联与可观测量矩阵特征之间的对应关系，揭示了从可积到混沌的交叉过程中局部结构如何编码混沌特征。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解从可积性到混沌的交叉过程中，本征态热化假说如何解释孤立量子系统的热化现象，特别是探索哈密顿量的谱关联与局部可观测量在能量本征基下的统计性质之间的直接对应关系。

Method: 引入局部扰动驱动系统从可积到混沌，追踪标准ETH指标和本征态纠缠熵。提出基于子矩阵的框架分析局部可观测量在能量本征基下的表示，通过提取沿对角线的实对称块，研究这些子矩阵如何展现哈密顿量的短程和长程谱特征。

Result: 研究发现局部可观测量在能量本征基下的子矩阵确实展现了哈密顿量的谱关联特征，即使在部分遍历区域这种对应关系仍然存在，表明混沌的出现已经编码在可观测量矩阵的局部结构中，且小尺寸块就足以捕捉底层谱关联。

Conclusion: 该研究建立了哈密顿量谱关联与局部可观测量矩阵结构之间的直接对应关系，表明从可积到混沌的交叉过程中，混沌特征已经局部编码在可观测量矩阵结构中，这为理解遍历性破缺提供了新的视角。

Abstract: The Eigenstate Thermalization Hypothesis explains thermalization in isolated quantum systems through the statistical properties of observables in the energy eigenbasis. We investigate the crossover from integrability to chaos in the spin-$1/2$ XXZ chain, establishing a direct correspondence between the spectral correlations of the Hamiltonian and local observables expressed in the energy eigenbasis as a signature of ergodicity breaking. By introducing a local perturbation that drives the system from integrability to chaos, we track the standard ETH indicators and the eigenstate entanglement entropy. We introduce a submatrix-based framework for analyzing local observables in the energy eigenbasis. By extracting real-symmetric blocks along the diagonal of the local observables represented in eigenbasis, we show that these submatrices exhibit both the short-range and long-range spectral features of the Hamiltonian. Remarkably, this correspondence persists even in a partially ergodic regime, indicating that the emergence of chaos is already encoded locally within the observables' matrix structure and that small blocks are sufficient to capture the underlying spectral correlations.

</details>


### [27] [Herzberg-Teller coupling in coherent multidimensional spectroscopy: analytical response functions for multilevel systems](https://arxiv.org/abs/2601.09346)
*Filippo Troiani*

Main category: quant-ph

TL;DR: 该研究推导了存在Herzberg-Teller（非康登）耦合时多维非线性响应函数的解析表达式，揭示了非康登耦合会在时域响应函数中引入额外振荡因子，导致多维光谱出现振动频率整数倍的复制峰。


<details>
  <summary>Details</summary>
Motivation: 多维相干光谱技术能够详细研究分子和固态系统中的振动电子效应，但现有理论框架主要基于康登近似。Herzberg-Teller（非康登）耦合在光-物质相互作用中具有重要意义，需要建立更一般的解析框架来理解和解释非康登效应在多维光谱中的表现。

Method: 在位移谐振子模型框架下，推导了存在Herzberg-Teller耦合时多维非线性响应函数的显式解析表达式。该方法适用于任意数量N的电子态系统，以及任意阶数M的光-物质相互作用响应函数。

Result: 研究发现Herzberg-Teller耦合会在时域响应函数中引入额外的振荡因子，通过傅里叶变换后，会在弗兰克-康登多维光谱的基础上产生振动频率整数倍的复制峰。这为非康登效应在多维相干光谱中的解释提供了系统的理论框架。

Conclusion: 该研究建立了一个通用的解析框架，用于解释多维相干光谱中的非康登效应，为理解振动电子耦合在光-物质相互作用中的复杂行为提供了理论基础，有助于更准确地分析和解释实验观测到的多维光谱特征。

Abstract: Coherent multidimensional spectroscopy enables detailed investigations of vibronic effects in molecular and solid-state systems. We present explicit analytical expressions for multidimensional nonlinear response functions in the presence of Herzberg-Teller (non-Condon) coupling, within the displaced harmonic oscillator model. The formulation applies to electronic systems with an arbitrary number N of electronic states and to response functions of arbitrary order M in the light-matter interaction. We show that Herzberg-Teller coupling introduces additional oscillatory factors in the time-domain response functions, leading, upon Fourier transformation, to replicas of the Franck-Condon multidimensional spectra shifted by integer multiples of the vibrational frequencies. The present results provide a general analytical framework for the interpretation of non-Condon effects in coherent multidimensional spectroscopies.

</details>


### [28] [Efficient State Preparation for Quantum Machine Learning](https://arxiv.org/abs/2601.09363)
*Chris Nakhl,Maxwell West,Muhammad Usman*

Main category: quant-ph

TL;DR: 使用矩阵乘积态表示构建量子机器学习数据编码电路，实现低深度近似编码，保持分类精度并增强对抗攻击鲁棒性


<details>
  <summary>Details</summary>
Motivation: 量子机器学习协议开发的关键考虑因素之一是将经典数据编码到量子设备上。需要找到既能有效编码数据，又能保持机器学习性能的方法。

Method: 引入矩阵乘积态表示量子系统，利用该表示构建编码所需状态的电路。在QML背景下，修改此过程以实现低深度近似编码。

Result: 这种编码方法不会降低分类精度，反而展现出对经典对抗攻击的增强鲁棒性。通过MNIST和FMNIST数据集的对抗鲁棒变分量子分类器演示，以及在超导量子设备上的小规模实验验证。

Conclusion: 矩阵乘积态表示提供了一种有效的量子数据编码方法，既能实现低深度近似编码，又能增强对抗攻击鲁棒性，为量子机器学习协议的开发提供了实用解决方案。

Abstract: One of the key considerations in the development of Quantum Machine Learning (QML) protocols is the encoding of classical data onto a quantum device. In this chapter we introduce the Matrix Product State representation of quantum systems and show how it may be used to construct circuits which encode a desired state. Putting this in the context of QML we show how this process may be modified to give a low depth approximate encoding and crucially that this encoding does not hinder classification accuracy and is indeed exhibits an increased robustness against classical adversarial attacks. This is illustrated by demonstrations of adversarially robust variational quantum classifiers for the MNIST and FMNIST dataset, as well as a small-scale experimental demonstration on a superconducting quantum device.

</details>


### [29] [Network-Based Quantum Computing: an efficient design framework for many-small-node distributed fault-tolerant quantum computing](https://arxiv.org/abs/2601.09374)
*Soshun Naito,Yasunari Suzuki,Yuuki Tokunaga*

Main category: quant-ph

TL;DR: 提出网络化量子计算（NBQC）方法，通过让计算数据在网络中持续移动来实现分布式容错量子计算，相比传统方法具有更短的执行时间和更高的节点效率。


<details>
  <summary>Details</summary>
Motivation: 在容错量子计算中，单个逻辑量子比特需要大量物理量子比特构建，而单个量子节点只能容纳少量逻辑量子比特。分布式容错量子计算（DFTQC）对于利用小规模节点实现大规模量子计算至关重要，但目前针对每个节点只能存储1-2个逻辑量子比特的小规模节点的分布式系统设计尚未充分探索。

Method: 提出网络化量子计算（NBQC）方法，核心思想是让计算数据在网络中持续移动，同时保持与其他节点的连接性。该方法专门针对小规模节点设计，可以适应量子程序的结构特征（如访问频率峰值）。

Result: 数值模拟显示，对于实际基准任务，NBQC相比基于电路的策略具有更短的执行时间，相比基于测量的量子计算具有更高的节点效率。如果能够根据量子程序结构（如访问频率峰值）专门设计网络，节点数量可以显著减少。

Conclusion: NBQC方法为设计利用多个小规模容错节点冗余性的DFTQC架构提供了基础，能够有效实现分布式容错量子计算。

Abstract: In fault-tolerant quantum computing, a large number of physical qubits are required to construct a single logical qubit, and a single quantum node may be able to hold only a small number of logical qubits. In such a case, the idea of distributed fault-tolerant quantum computing (DFTQC) is important to demonstrate large-scale quantum computation using small-scale nodes. However, the design of distributed systems on small-scale nodes, where each node can store only one or a few logical qubits for computation, has not been explored well yet. In this paper, we propose network-based quantum computation (NBQC) to efficiently realize distributed fault-tolerant quantum computation using many small-scale nodes. A key idea of NBQC is to let computational data continuously move throughout the network while maintaining the connectivity to other nodes. We numerically show that, for practical benchmark tasks, our method achieves shorter execution times than circuit-based strategies and more node-efficient constructions than measurement-based quantum computing. Also, if we are allowed to specialize the network to the structure of quantum programs, such as peak access frequencies, the number of nodes can be significantly reduced. Thus, our methods provide a foundation in designing DFTQC architecture exploiting the redundancy of many small fault-tolerant nodes.

</details>


### [30] [Sparse quantum state preparation with improved Toffoli cost](https://arxiv.org/abs/2601.09388)
*Felix Rupprecht,Sabine Wölk*

Main category: quant-ph

TL;DR: 本文提出了一种更高效的稀疏量子态制备方法，通过优化等距映射电路设计，将Toffoli门数量从现有技术的约s log(s)减少到约2s，在随机态上甚至接近s，实现了约log(s)/2的改进因子。


<details>
  <summary>Details</summary>
Motivation: 量子态制备是量子计算的基本任务，在量子模拟和线性系统求解等应用中特别需要稀疏量子态（仅包含少量非零基态）。现有方法中，等距映射步骤成本较高，需要改进以降低Toffoli门数量。

Method: 采用两阶段框架：1）在⌈log(s)⌉量子比特子寄存器上制备稠密态；2）通过等距映射将稠密态映射到目标稀疏态。主要创新在于设计了高效的等距映射算法，可视为Malvetti等人方法的批处理版本。对于纯实数系数的目标态，通过将部分子任务从稠密态制备外包到等距映射来优化联合成本。

Result: 最坏情况下等距映射电路的Toffoli成本约为2s（对于足够大的n），比现有技术提升约log(s)/2倍。在随机选择的态上进行数值基准测试时，成本更接近s。对于纯实数系数的目标态，通过联合优化进一步降低了总成本。

Conclusion: 本文提出的方法显著降低了稀疏量子态制备的Toffoli门数量，特别是在大规模系统中。通过优化等距映射电路设计，实现了约log(s)/2的改进因子，为量子模拟和线性系统求解等应用提供了更高效的量子态制备方案。

Abstract: The preparation of quantum states is one of the most fundamental tasks in quantum computing, and a key primitive in many quantum algorithms. Of particular interest to areas such as quantum simulation and linear-system solvers are sparse quantum states, which contain only a small number $s$ of non-zero computational basis states compared to a generic state. In this work, we present an approach that prepares $s$-sparse states on $n$ qubits, reducing the number of Toffoli gates required compared to prior art. We work in the established framework of first preparing a dense state on a $\lceil{\log(s)}\rceil$-qubit sub-register, and then mapping this state to the target state via an isometry, with the latter step dominating the cost of the full algorithm. The speed-up is achieved by designing an efficient algorithm for finding and implementing the isometry. The worst-case Toffoli cost of our isometry circuit, which may be viewed as a batched version of an approach by Malvetti et al., is essentially $2s$ for sufficiently large values of $n$, yielding roughly a $\log(s)/2$ improvement factor over the state-of-the-art. In numerical benchmarks on randomly chosen states, the cost is closer to $s$. With the improved isometry circuit, we examine the dense-state preparation step and present ways to optimize the joint cost of both steps, particularly in the case of target states with purely real coefficients, by outsourcing some sub-tasks from the dense-state preparation to the isometry.

</details>


### [31] [Overcoming the No-Go Theorem Yields a Rich Dissipative Phase Diagram in the Open Quantum Rabi Model](https://arxiv.org/abs/2601.09414)
*Jun-Ling Wang,Qing-Hu Chen*

Main category: quant-ph

TL;DR: 开放量子Rabi模型中包含A²项，各向异性克服了耗散量子系统的no-go定理，建立了耗散相变的真实平台，产生了更丰富的稳态相图。


<details>
  <summary>Details</summary>
Motivation: 研究开放量子Rabi模型中包含A²项的影响，探索各向异性如何克服耗散量子系统中的no-go定理，为实验研究非平衡临界现象提供现实途径。

Method: 在开放量子Rabi模型中明确包含A²项（满足Thomas-Reich-Kuhn求和规则），研究各向异性对系统的影响，分析稳态相图的结构和临界行为。

Result: 各向异性提供了克服耗散量子系统no-go定理的通用机制，A²项产生了更丰富、不对称的稳态相图，包含正常相、超辐射相和双稳态相，在临界线分支交点处A²项显著改变了光子数涨落的标度行为。

Conclusion: A²项在光-物质相互作用中具有固有作用，这些发现为实验研究和动态控制实际开放量子平台中的非平衡临界现象开辟了现实途径。

Abstract: The open quantum Rabi model is studied in this work, with the explicit $\mathbf{A}^{2}$ term incorporated as required by the Thomas-Reich-Kuhn sum rule. It is shown that anisotropy provides a generic and robust mechanism for overcoming the no-go theorem in dissipative quantum systems, thereby establishing a genuine platform for observing dissipative phase transitions. The inclusion of the $\mathbf{A}^{2}$ term yields a significantly richer and asymmetric steady-state phase diagram, consisting of normal, superradiant, and bistable phases that intersect at tricritical points, while isolated bistable phases also emerge and the number of tricritical points is reduced. Notably, it is near the intersection of the two critical-line branches enclosing the superradiant phases, rather than at the tricritical points, that the $\mathbf{A}^{2}$ term fundamentally alters the scaling of photon-number fluctuations. Given the inherent role of the $\mathbf{A}^{2}$ term in light-matter interactions, our findings open a realistic route toward the experimental investigation and dynamical control of nonequilibrium critical phenomena in practical open quantum platforms.

</details>


### [32] [A measurement-based protocol for the generation of delocalised quantum states of a mechanical system](https://arxiv.org/abs/2601.09431)
*Matteo Bordin*

Main category: quant-ph

TL;DR: 提出基于测量的协议，通过Geiger光电探测光输出，来预示机械振子的非高斯态，分析斯托克斯诱导的光力学纠缠如何产生负Wigner函数，比较脉冲和连续波方案


<details>
  <summary>Details</summary>
Motivation: 非高斯机械态是量子增强传感和宏观量子物理测试的关键资源，需要有效的方法来产生和检测机械振子的非经典态

Method: 提出基于测量的预示协议，通过Geiger光电探测光输出条件化，分析斯托克斯诱导的光力学纠缠产生负Wigner函数的条件，开发并比较蓝失谐脉冲方案和采用时间模式滤波的连续波稳态方案

Result: 量化了在现实探测效率下的预示速率和对有限温度的鲁棒性，分析了两种方案在不同条件下的性能表现

Conclusion: 该协议为在腔光力学系统中产生和检测机械振子的非高斯态提供了一种有效方法，脉冲和连续波方案各有优势，为量子增强传感和宏观量子物理测试提供了重要工具

Abstract: Non-Gaussian mechanical states are a key resource for quantum-enhanced sensing and tests of macroscopic quantum physics. We propose a measurement-based protocol to herald delocalized, nonclassical states of a mechanical oscillator in cavity optomechanics by conditioning on Geiger photodetection of the optical output. We analyse under which conditions Stokes-induced optomechanical entanglement give rise to mechanical Wigner Function negativity upon detection. We develop and compare a blue-detuned pulsed scheme and a continuous-wave steady-state scheme employing temporal-mode filtering, and we quantify heralding rates and robustness to finite temperature under realistic detection efficiencies.

</details>


### [33] [Toward Spectral Engineering of Squeezed Light in High-Gain PDC](https://arxiv.org/abs/2601.09511)
*Jatin Kumar,Aleksa Krstić,Sina Saravi,Frank Setzpfandt*

Main category: quant-ph

TL;DR: 研究高增益参量下转换产生压缩光的光谱特性，发现未加窗和加窗色散工程波导的光谱纯度随增益变化趋势不同，色散条件是主要影响因素。


<details>
  <summary>Details</summary>
Motivation: 研究压缩光源的光谱模式结构对于量子应用优化至关重要，需要理解色散工程和参量增益如何共同影响光谱纯度。

Method: 通过施密特模式分析和群速度解释，研究未加窗和加窗色散工程波导中压缩光的光谱特性，从低增益到高增益分析演化过程。

Result: 未加窗配置的光谱纯度随增益单调增加，而加窗配置呈现非单调依赖关系（先降低后恢复）。当泵浦群速度位于信号和闲频之间时，净化过程最快。

Conclusion: 光谱纯度的演化主要由波导的色散特性决定，色散工程和参量增益可以联合优化压缩光源的光谱模式结构，适用于广泛的量子应用。

Abstract: We investigated the spectral properties of squeezed light generated via parametric down-conversion in the high-gain regime, considering both unapodized and apodized dispersion-engineered waveguides. The gain-dependent evolution of these states is examined starting from the low-gain regime, which includes both highly correlated and nearly uncorrelated cases. For the unapodized configuration, we observe a monotonic increase in spectral purity with gain, whereas the apodized configuration exhibits a nonmonotonic dependence, initially decreasing and then recovering at higher gain. By combining Schmidt-mode analysis with a group-velocity-based interpretation, we explain why different dispersion conditions exhibit distinct gain-dependent behavior, specifically that rapid purification occurs when the pump group velocity lies between those of the signal and idler. Our study shows that the evolution of spectral purity is governed primarily by the underlying dispersion of the waveguide. These results demonstrate that dispersion engineering and parametric gain can be jointly exploited to tailor the spectral-mode structure of squeezed-light sources, enabling their optimization for a broad range of quantum applications.

</details>


### [34] [Reservoir-Engineered Refrigeration of a Superconducting Cavity with Double-Quantum-Dot Spin Qubits](https://arxiv.org/abs/2601.09516)
*Daryoosh Vashaee,Jahanfar Abouie*

Main category: quant-ph

TL;DR: 该论文提出了一种基于双量子点自旋量子点的可调谐工程库来冷却超导微波腔的理论框架，通过控制量子点参数实现腔的光子生死过程，达到毫开尔文级别的冷却效果。


<details>
  <summary>Details</summary>
Motivation: 为超导微波腔开发一种基于固态量子点的可调谐制冷方案，解决传统制冷方法在低温电路量子电动力学架构中的限制，实现低于环境温度和量子点设定温度的冷却。

Method: 将双量子点自旋量子点视为可调谐工程库而非光谱元件，通过门控控制量子点的布居、相干性、线宽和失谐，建立有效的光子生死过程模型，分析刷新型和持久型库机制。

Result: 获得了腔稳态的闭式表达式，确定了冷却界限和失谐相关的制冷谷，展示了腔温度可低于环境温度和量子点设定温度的情况，数值模拟证实了毫开尔文级别的冷却效果。

Conclusion: 该理论框架为超导微波腔的量子点基制冷提供了分析工具，揭示了存储器效应、饱和和暗态形成对冷却的限制，同时表明双量子点配置中的集体亮模式耦合可增强制冷性能。

Abstract: We present an analytically tractable theory of reservoir-engineered refrigeration of a superconducting microwave cavity and map it onto a realistic solid-state implementation based on gate-defined double-quantum-dot (DQD) spin qubits. Treating the DQD not as a spectroscopic element but as a tunable engineered reservoir, we show how gate control of populations, coherences, linewidths, and detuning defines an effective photon birth-death process with predictable detailed balance. This framework yields closed-form expressions for the cavity steady state, identifies cooling bounds and detuning-dependent refrigeration valleys, and clarifies when refrigeration can drive the cavity below both the bath temperature and the DQD setpoint. By distinguishing refreshed (collision-like) and persistent reservoir regimes, we show how memory effects, saturation, and dark-state formation constrain cooling in realistic devices, while collective bright-mode coupling in a two-dot configuration can enhance refrigeration subject to mismatch and dephasing, as confirmed by numerical Lindblad simulations demonstrating targeted millikelvin cavity cooling relevant for cryogenic circuit-QED architectures.

</details>


### [35] [Geometry- and Topology-Informed Quantum Computing: From States to Real-Time Control with FPGA Prototypes](https://arxiv.org/abs/2601.09556)
*Gunhee Cho*

Main category: quant-ph

TL;DR: 一本将量子信息工作流几何化、硬件感知的书籍，通过几何视角连接量子态、电路、测量与经典控制流水线，实现混合量子系统的确定性运行。


<details>
  <summary>Details</summary>
Motivation: 传统量子信息处理常缺乏硬件实现视角，本书旨在建立几何化、硬件感知的框架，将量子态演化、测量与经典控制流水线紧密结合，实现可实际部署的混合量子系统。

Method: 采用几何优先方法：1) 建立线性代数、Bloch球、微分几何、量子Fisher信息几何基础；2) 将电路重构为数据流图，实现测量结果的实时解析与脉冲调度；3) 将多量子比特结构与纠缠视为几何与计算；4) 专注于拓扑纠错与实时解码的硬件实现。

Result: 构建了从量子原理到可实施系统的完整框架，涵盖几何化量子信息处理、实时控制流水线、硬件约束下的纠错解码，以及可视化实验平台，实现理论与实践的结合。

Conclusion: 本书提供了从几何视角理解量子信息、硬件感知的电路设计到实际系统实现的完整路径，强调低延迟流处理、确定性控制与可验证性，为混合量子系统的工程化部署奠定基础。

Abstract: This book gives a geometry-first, hardware-aware route through quantum-information workflows, with one goal: connect states, circuits, and measurement to deterministic classical pipelines that make hybrid quantum systems run. Part 1 develops the backbone (essential linear algebra, the Bloch-sphere viewpoint, differential-geometric intuition, and quantum Fisher information geometry) so evolution can be read as motion on curved spaces and measurement as statistics. Part 2 reframes circuits as dataflow graphs: measurement outcomes are parsed, aggregated, and reduced to small linear-algebra updates that schedule the next pulses, highlighting why low-latency, low-jitter streaming matters. Part 3 treats multi-qubit structure and entanglement as geometry and computation, including teleportation, superdense coding, entanglement detection, and Shor's algorithm via quantum phase estimation. Part 4 focuses on topological error correction and real-time decoding (Track A): stabilizer codes, surface-code decoding as "topology -> graph -> algorithm", and Union-Find decoders down to microarchitectural/RTL constraints, with verification, fault injection, and host/control-stack integration under product metrics (bounded latency, p99 tails, fail-closed policies, observability). Optional Track C covers quantum cryptography and streaming post-processing (BB84/E91, QBER/abort rules, privacy amplification, and zero-knowledge/post-quantum themes), emphasizing FSMs, counters, and hash pipelines. Appendices provide visualization-driven iCEstick labs (switch-to-bit conditioning, fixed-point phase arithmetic, FSM sequencing, minimal control ISAs), bridging principles to implementable systems.

</details>


### [36] [Genuine multipartite Rains entanglement](https://arxiv.org/abs/2601.09590)
*Hailey S. Murray,Sagnik Bhattacharya,M. Cerezo,Liuke Lyu,Mark M. Wilde*

Main category: quant-ph

TL;DR: 提出了一种可计算的多体纠缠度量——真实多体Rains纠缠(GMRE)，它是Rains相对熵的多体推广，可用半定规划计算，并具有纠缠单调性。


<details>
  <summary>Details</summary>
Motivation: 现有Rains相对熵仅适用于两体系统，需要将其推广到多体情形以量化真实多体纠缠，同时保持可计算性和理论性质。

Method: 通过半定规划定义真实多体Rains纠缠(GMRE)，证明其在保持部分转置正性的选择性量子操作下具有单调性，并推广到包含量子Renyi相对熵等熵的广义形式。

Result: GMRE是真实多体纠缠单调，可从上方限制单次标准近似和概率近似GHZ可蒸馏纠缠，并成功推广到包含其他熵的广义形式。

Conclusion: GMRE为多体纠缠提供了可计算的度量工具，建立了与GHZ态蒸馏的联系，其广义形式为进一步研究多体纠缠度量开辟了新途径。

Abstract: We introduce the genuine multipartite Rains entanglement (GMRE) as a measure of genuine multipartite entanglement that can be computed using semi-definite programming. Similar to the Rains relative entropy (its bipartite counterpart), the GMRE is monotone under selective quantum operations that completely preserve the positivity of the partial transpose, implying that it is a multipartite entanglement monotone. As a consequence, we show that the GMRE bounds both the one-shot standard and probabilistic approximate GHZ-distillable entanglement from above. We also develop a generalization of this quantity that incorporates other entropies, including quantum Renyi relative entropies.

</details>


### [37] [Dissipative State Engineering of Complex Entanglement with Markovian Dynamics](https://arxiv.org/abs/2601.09597)
*Manish Chaudhary*

Main category: quant-ph

TL;DR: 论文研究了通过工程化的马尔可夫耗散动力学在伊辛耦合自旋系统中生成复杂纠缠结构（如簇态）的方法，展示了利用耗散主导实现稳定簇态的可能性。


<details>
  <summary>Details</summary>
Motivation: 高度多体纠缠态在量子计算任务中具有重要作用，但如何有效生成复杂纠缠结构（如簇态）是一个重要问题。传统方法通常需要复杂的门操作，而本文探索通过工程化耗散动力学实现稳定纠缠态的新途径。

Method: 使用Lindblad主方程设计基于投影的耗散通道，通过移除正交态的贡献，驱动系统达到对应于理想簇态的纯稳态。在完整的2^N维希尔伯特空间中显式构造Liouvillian超算符，计算稳态密度矩阵、Liouvillian谱隙、纠缠见证和与理想簇态的保真度。

Result: 当工程化的Liouvillian耗散主导自旋间的局域伊辛相互作用时，簇态作为稳态出现。保真度和Liouvillian谱隙在达到与量子比特数线性相关的饱和耗散后，对系统尺寸相对不敏感。

Conclusion: 该分析展示了在自旋系统中利用工程化耗散实现稳态纠缠生成的物理可行路径，为量子信息处理中的纠缠制备提供了新方法。

Abstract: Highly multipartite entangled states play an important role in various quantum computing tasks. We investigate the dissipative generation of a complex entanglement structure as in a cluster state through engineered Markovian dynamics in the spin systems coupled via Ising interactions. Using the Lindblad master equation, we design a projection based dissipative channel that drives the system toward a unique pure steady state corresponding to the desired cluster state. This is done by removing the contribution of the orthogonal states. By explicitly constructing the Liouvillian superoperator in the full $2^N$-dimensional Hilbert space, we compute the steady-state density matrix, the Liouvillian spectral gap, entanglement witness and the fidelity with respect to the ideal cluster state. The results demonstrate that the cluster state emerges as the steady state when the engineered Liouvillian dissipation dominates over the local Ising interaction between spins. Moreover, we find that the fidelity and Liouvillian spectral gap is relatively insensitive to the system size once the saturation dissipation has been achieved that scales linearly with the qubit number. This analysis illustrates a physically realizable path towards steady-state entanglement generation in the spin systems using engineered dissipation.

</details>


### [38] [A perturbative non-Markovian treatment to low-temperature spin decoherence](https://arxiv.org/abs/2601.09651)
*Timothy J. Krogmeier,Anthony W. Schlimgen,Kade Head-Marsden*

Main category: quant-ph

TL;DR: 开发非马尔可夫时间卷积主方程，将电子结构参数与退相干动力学直接关联，预测分子自旋量子比特在低温下的退相干趋势。


<details>
  <summary>Details</summary>
Motivation: 分子自旋在量子信息科学中具有潜力，但电子自旋退相干（由核自旋相互作用引起）阻碍了实际应用，预测退相干动力学具有挑战性。

Method: 开发非马尔可夫时间卷积主方程，处理电子自旋与核自旋浴的耦合，将从头算电子结构参数直接关联到退相干动力学，考虑低温极限下的纯退相。

Result: 应用于一系列分子量子比特候选体系，与实验弛豫趋势表现出良好的一致性。

Conclusion: 该方法为预测分子自旋系统低温退相干趋势提供了计算高效的途径。

Abstract: Molecular spins are promising candidates for quantum information science, leveraging coherent electronic spin states for quantum sensing and computation. However, the practical application of these systems is hindered by electronic spin decoherence, driven by interactions with nuclear spins in the molecule and the surrounding environment at low temperatures. Predicting dephasing dynamics remains a formidable challenge due to the complexity of the spin bath. In this work, we develop a non-Markovian time-convolutionless master equation to treat an electronic spin coupled to a nuclear-spin bath. By relating ab initio electronic structure parameters directly to the decoherence dynamics, we provide a framework that accounts for pure dephasing in the low-temperature limit. We apply this method to a series of molecular qubit candidates and demonstrate good agreement with experimental relaxation trends. This approach offers a computationally efficient path for the prediction of low-temperature decoherence trends in molecular spin systems.

</details>


### [39] [Generation of Large Coherent-State Superpositions in Free-Space Optical Pulses](https://arxiv.org/abs/2601.09672)
*Lucas Caron,Hector Simon,Hugo Basset,Romaric Journet,Rosa Tualle-Brouri*

Main category: quant-ph

TL;DR: 实验生成了大振幅压缩猫态（α=2.47），通过混合Fock态|1⟩和|2⟩并采用零差探测后选择，实现了Wigner函数三个负区域和0.53保真度


<details>
  <summary>Details</summary>
Motivation: 非高斯量子态的生成是实现通用连续变量量子信息处理的关键要求，特别是大振幅压缩猫态对可扩展容错光子量子架构至关重要

Method: 通过可调分束器混合Fock态|1⟩和|2⟩，然后使用零差探测进行后选择，生成压缩相干态叠加（压缩猫态）

Result: 实现了振幅α=2.47的压缩猫态，创下最高记录；Wigner函数显示三个清晰负区域；与目标态保真度达0.53（α=2.47，压缩参数z=0.56）

Conclusion: 这是时间育种协议和迭代生成光学GKP态的重要里程碑，为可扩展容错光子量子架构开辟了新前景

Abstract: The generation of non-Gaussian quantum states is a key requirement for universal continuous-variable quantum information processing. We report the experimental generation of large-amplitude squeezed coherent-state superpositions (squeezed cat states) on free-space optical pulses, reaching an amplitude of $α= 2.47$, which, to our knowledge, exceeds all previously reported values. Our protocol relies on the controlled mixing of the Fock states $|1\rangle$ and $|2\rangle$ through a tunable beam splitter, followed by heralding via homodyne detection. The resulting state displays three well-resolved negative regions in its Wigner function and achieves a fidelity of $0.53$ with the target state $\propto \hat{S}(z)(|α\rangle - |-α\rangle)$, with $α= 2.47$ and squeezing parameter $z = 0.56$. These results constitute a significant milestone for temporal breeding protocols and for the iterative generation of optical GKP states, opening new perspectives for scalable and fault-tolerant photonic quantum architectures.

</details>


### [40] [Quantum graphs of homomorphisms](https://arxiv.org/abs/2601.09685)
*Andre Kornell,Bert Lindenhovius*

Main category: quant-ph

TL;DR: 该论文引入了量子图范畴，建立了量子图之间的同态构造，证明了量子同态存在性与量子策略获胜的等价性，并解决了量子通道混淆图的问题。


<details>
  <summary>Details</summary>
Motivation: 从非交换几何的角度定义量子图，建立量子图的范畴理论，研究量子图之间的同态关系及其与量子博弈策略的联系。

Method: 引入量子图范畴qGph，构造量子图之间的同态量子图[G,H]，证明该范畴是闭对称幺半范畴，分析有限量子图的性质和态射结构。

Result: 证明了量子图同态存在性等价于(G,H)-同态博弈的量子策略获胜；有限量子图具有迹、实、自伴性质；Weaver的两种CP态射概念在此一致；每个有限自反量子图都是某个量子通道的混淆图。

Conclusion: 成功建立了量子图的范畴框架，将经典图同态理论推广到量子情形，解决了量子通道混淆图的构造问题，为量子图论和非交换几何提供了新工具。

Abstract: We introduce a category $\mathsf{qGph}$ of quantum graphs, whose definition is motivated entirely from noncommutative geometry. For all quantum graphs $G$ and $H$ in $\mathsf{qGph}$, we then construct a quantum graph $[G,H]$ of homomorphisms from $G$ to $H$, making $\mathsf{qGph}$ a closed symmetric monoidal category. We prove that for all finite graphs $G$ and $H$, the quantum graph $[G,H]$ is nonempty iff the $(G,H)$-homomorphism game has a winning quantum strategy, directly generalizing the classical case.
  The finite quantum graphs in $\mathsf{qGph}$ are tracial, real, and self-adjoint, and the morphisms between them are CP morphisms that are adjoint to a unital $*$-homomorphism. We show that Weaver's two notions of a CP morphism coincide in this context. We also show that every finite reflexive quantum graph is the confusability quantum graph of a quantum channel, answering a question of Daws.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [41] [An $O(\log N)$ Monte Carlo method for periodic Coulomb systems](https://arxiv.org/abs/2601.09288)
*Xuanzhao Gao,Shidong Jiang,Jiuyang Liang,Qi Zhou*

Main category: physics.comp-ph

TL;DR: DMK-MC是一种加速的蒙特卡洛方法，通过双空间多级核分裂框架实现单粒子Metropolis更新，将库仑核分解为三个部分，实现每步移动O(log N)的计算复杂度，相比现有FMM方法有数倍加速。


<details>
  <summary>Details</summary>
Motivation: 在周期性边界条件下，具有长程静电相互作用的多体系统的蒙特卡洛采样通常受限于每次移动的能量差计算成本，需要更高效的方法来加速采样过程。

Method: 采用双空间多级核分裂（DMK）框架，将库仑核分解为三个部分：全局周期化平滑部分、多级平滑差分核序列（仅在同级相邻盒子间相互作用）、奇异残差核（短程直接计算）。在单粒子Metropolis更新中，以O(1)工作量更新每个树级的平面波场，实现整体O(log N)的预期工作量。

Result: 在均匀、高度非均匀和隐式溶剂电解质及胶体配置的基准测试中，DMK-MC始终优于最近的基于FMM的O(log N)蒙特卡洛方法，在可比容差下提供数倍的加速。

Conclusion: DMK-MC是一种高效的蒙特卡洛采样方法，通过创新的核分裂策略显著降低了长程静电相互作用系统的计算成本，为复杂多体系统的模拟提供了实用的加速方案。

Abstract: Efficient Monte Carlo (MC) sampling of many-body systems with long-range electrostatics is often limited by the cost of per-move energy-difference evaluation under periodic boundary conditions. We present DMK-MC, an accelerated MC method that adapts the dual-space multilevel kernel-splitting (DMK) framework to single-particle Metropolis updates. DMK-MC computes the energy change and, upon acceptance, updates the stored incoming plane-wave fields with $O(1)$ work per tree level, yielding an overall $O(\log N)$ expected work per trial move for fixed accuracy. The method decomposes the Coulomb kernel into three components: a global, periodized smooth part; a multilevel sequence of smooth difference kernels whose interactions are restricted to same-level colleague boxes; and a singular residual kernel whose short-range interactions are evaluated directly. Benchmarks on uniform, highly nonuniform, and implicit-solvent electrolyte and colloidal configurations show that DMK-MC consistently outperforms a recent FMM-based $O(\log N)$ Monte Carlo method, delivering several-fold speedups at comparable tolerances.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [42] [BRST Symmetry Violation and Fundamental Limitations of Asymptotic Safety in Quantum Gravity](https://arxiv.org/abs/2601.08886)
*Farrukh A. Chishtie*

Main category: gr-qc

TL;DR: 该论文认为渐近安全方案存在根本性对称性破坏问题，导致度规张量在引力截断能标以上无法作为有效的量子自由度存在，使得基于度规的紫外固定点搜索存在基础物理问题。


<details>
  <summary>Details</summary>
Motivation: 论文旨在揭示渐近安全量子引力方案中的基本对称性破坏问题。作者认为该方案在多个独立标准下都违反了基本对称性，特别是广义协变性和BRST对称性在引力截断能标以上的破坏，这从根本上质疑了渐近安全方案的物理基础。

Method: 采用多种分析方法：1）严格的规范量子化证明广义协变性在二维以上无法量子力学地保持；2）路径积分计算显示量子引力修正中存在持续的规范参数依赖性，表明BRST对称性破坏；3）综合分析了渐近安全方案在规范参数依赖性、截断方案收敛性、实验检验、物质内容兼容性、幺正性、Wick旋转等方面的系统性缺陷。

Result: 研究发现渐近安全方案存在多重根本问题：1）固定点性质随任意规范选择而变化；2）35阶截断方案不收敛；3）与电弱精密实验存在数量级上的矛盾；4）物质内容要求与标准模型不兼容；5）由于规范和截断依赖性无法给出具体的引力子预言；6）存在幺正性问题（鬼场不稳定性和传播子负性）；7）Wick旋转障碍阻碍了欧几里得计算与物理洛伦兹时空的可靠联系。

Conclusion: 论文得出结论：渐近安全方案存在根本性的对称性破坏问题，度规张量在约10^18 GeV以上的引力截断能标处无法作为有效的量子自由度存在。作者提出"统一标准模型与涌现引力"框架作为替代方案，能够系统性地避免所有渐近安全方案的病态问题。

Abstract: The asymptotic safety program assumes that quantum gravity becomes renormalizable through ultraviolet fixed points in metric-based couplings. We demonstrate that this approach {encounters fundamental symmetry violations} across multiple independent criteria, all traceable to a single fundamental cause: the breakdown of general covariance and BRST symmetries above the gravitational cutoff scale. Rigorous canonical quantization proves that general covariance cannot be maintained quantum mechanically in dimensions greater than two, while recent path integral calculations reveal persistent gauge parameter dependence in quantum gravitational corrections, signaling BRST symmetry violation. These dual proofs establish that the metric tensor ceases to exist as a valid quantum degree of freedom above $Λ_{\text{grav}}$$\sim$$10^{18}$ GeV, rendering the search for ultraviolet fixed points in metric-based theories {problematic from a foundational physical perspective}. We provide comprehensive analysis demonstrating that asymptotic safety exhibits persistent gauge parameter dependence where fixed-point properties vary with arbitrary gauge choices, non-convergent truncation schemes extending to the 35th order showing no approach to stable values, experimental {tensions} with electroweak precision tests by orders of magnitude, matter content requirements incompatible with the Standard Model, absence of concrete graviton predictions due to gauge and truncation dependence, unitarity {challenges} through ghost instabilities and propagator negativity, and fundamental Wick rotation obstructions preventing reliable connection between Euclidean calculations and physical Lorentzian spacetime. We contrast this with the Unified Standard Model with Emergent Gravity framework that systematically avoids all asymptotic safety pathologies.

</details>


### [43] [Traversable Wormhole Solutions in f (Q, Lm) Gravity](https://arxiv.org/abs/2601.08888)
*K. Suhasini,G. Ravi Kiran,N. S. Kavya,C. S. Varsha,V. Venkatesha*

Main category: gr-qc

TL;DR: 在f(Q,L_m)引力框架下研究可穿越虫洞解，采用线性函数形式，考虑四种不同形状函数，验证几何可行性，分析能量条件，使用嵌入图可视化空间几何


<details>
  <summary>Details</summary>
Motivation: 探索在具有几何与物质非最小耦合的对称远平行理论f(Q,L_m)引力框架下构建可穿越虫洞的可能性，研究非最小耦合对虫洞几何和物质分布的影响

Method: 采用线性函数形式f(Q,L_m) = -αQ + 2L_m + β，推导静态球对称Morris-Thorne虫洞几何的场方程，考虑四种形状函数：b(r)=√(r_0 r)、b(r)=r_0(r/r_0)^γ（0<γ<1）、b(r)=r_0 ln(r+1)/ln(r_0+1)，验证几何可行性条件，分析能量条件，使用嵌入图可视化空间几何

Result: 所有虫洞构型都满足标准的可穿越性条件（包括喇叭口要求和渐近平坦性），在喉部附近零能量条件被违反，表明存在奇异物质，嵌入图清晰地展示了喉部喇叭口条件的几何解释

Conclusion: f(Q,L_m)引力为构建可穿越虫洞提供了可行的理论框架，几何与物质的非最小耦合同时影响虫洞的几何结构和物质分布

Abstract: We investigate traversable wormhole solutions within the framework of $f(\mathscr{Q},\mathscr{L}_m)$ gravity, a symmetric teleparallel theory featuring non-minimal coupling between geometry and matter. Adopting a linear functional form $f(\mathscr{Q},\mathscr{L}_m) = -α\mathscr{Q} + 2\mathscr{L}_m + β$, we derive the field equations for a static, spherically symmetric Morris-Thorne wormhole geometry with vanishing redshift function. Four distinct shape functions are considered: $b(r)=\sqrt{r_0 r}$, $b(r)=r_0\left(\dfrac{r}{r_0}\right)^γ$ (with $0<γ<1$), and $b(r)=\dfrac{r_0 \ln (r+1)}{\ln (r_0+1)}$. The geometric viability of each configuration is verified through standard traversability conditions, including the flaring-out requirement and asymptotic flatness. We analyze the energy conditions and demonstrate that, consistent with known results in wormhole physics, the null energy condition is violated in the vicinity of the throat, indicating the presence of exotic matter. In addition, we employ embedding diagrams to visualize the spatial geometry of the wormhole solutions, providing a clear geometric interpretation of the flaring-out condition at the throat. Our results suggest that $f(\mathscr{Q},\mathscr{L}_m)$ gravity provides a viable framework for constructing traversable wormholes, with the non-minimal matter-geometry coupling influencing both the geometry and the matter sector.

</details>


### [44] [Liouville theory on a horizon: point particle/scalar field duality and Page-like curve](https://arxiv.org/abs/2601.08895)
*J-B. Roux*

Main category: gr-qc

TL;DR: 该论文展示了量子引力研究的三项重要结果：点粒子与标量传播子的对偶性、黑洞熵的EFT形式恢复，以及霍金辐射的量子修正与Page曲线。


<details>
  <summary>Details</summary>
Motivation: 研究量子引力理论中信息守恒问题，特别是黑洞信息悖论，探索边界信息如何编码到霍金辐射中。

Method: 采用边界信息编码方法，将边界内部信息直接映射到边界上，使信息通过霍金辐射从视界泄漏到体空间。

Result: 1) 发现点粒子与有质量标量传播子的对偶性；2) 以EFT量子引力相同形式恢复边界（黑洞）熵；3) 获得霍金辐射的量子修正和Page-like曲线。

Conclusion: 该量子引力方法成功解决了信息守恒问题，表明信息通过霍金辐射从视界直接泄漏到体空间，为黑洞信息悖论提供了新视角。

Abstract: We show that the consequences of a recent paper on quantum gravity are 1) a duality between point particles and massive scalar propagators, 2) the recovery of the entropy of a boundary (a black hole) in the same form as that of the EFT approach to Quantum Gravity and 3) a quantum correction to Hawking radiations and a Page-like curve. In this recent paper, information about what lies inside a boundary is encoded onto it, meaning that in this approach the information directly leaks from the horizon to the bulk in the form of Hawking radiations.

</details>


### [45] [Dirac Sources for Nonmetricity and Torsion in Metric-affine Gravity](https://arxiv.org/abs/2601.09013)
*James T. Wheeler*

Main category: gr-qc

TL;DR: 论文提出了一种将度量仿射引力(GL(4)规范理论)与狄拉克旋量场耦合的新方法，通过利用gl(4)李代数与Clifford代数Cl(3,1)和Cl(2,2)的同构关系，解决了GL(4)不包含洛伦兹群旋量表示的问题。


<details>
  <summary>Details</summary>
Motivation: 传统的GL(4)规范理论不包含洛伦兹群的旋量表示，这限制了它与狄拉克旋量场的直接耦合。论文旨在解决这一基本问题，为度量仿射引力理论提供与旋量物质场耦合的数学框架。

Method: 利用gl(4)李代数与Clifford代数Cl(3,1)和Cl(2,2)的同构关系。通过简单变换将Cl(3,1)生成元与Cl(2,2)的实表示联系起来，而Cl(2,2)的实表示直接作为gl(4)的基。在Cl(2,2)基中展开gl(4)李代数，得到具有明确定义的狄拉克旋量耦合的Clifford值联络。

Result: 成功建立了GL(4)规范理论与狄拉克旋量场的耦合机制。通过展开系数的变分，得到了新的狄拉克源项，这些源项分别对应于挠率和非度量性，并通过在gl(4)基中识别so(3,1)基来分离。

Conclusion: 该方法克服了GL(4)不包含旋量表示的限制，为度量仿射引力理论提供了与旋量物质场耦合的完整数学框架，开启了研究挠率和非度量性的狄拉克源项的新途径。

Abstract: Metric-affine gravity (GL(4) gauge theory) in 4-dimensions is coupled to a spacetime Dirac source field using the isomorphisms of the Lie algebra gl(4) to the Clifford algebras Cl(3,1) and Cl(2,2). A simple transformation relates the generators of Cl(3,1) to a real representation of Cl(2,2), while the real representation of Cl(2,2) serves directly as a basis for the Lie algebra gl(4). Therefore, although GL(4) does not contain a spinor representation of the Lorentz group, expanding its Lie algebra in the Cl(2,2) basis gives a Clifford valued connection with well-defined coupling to Dirac spinors. Variation of the expansion coefficients gives new Dirac sources for both torsion and nonmetricity, separated by identifying the so(3,1) basis within the gl(4) basis.

</details>


### [46] [Wada Boundaries in Generic Polynomial PP-Wave Spacetimes](https://arxiv.org/abs/2601.09101)
*Pedro Henrique Barboza Rossetto,Vanessa Carvalho de Andrade,Daniel Müller*

Main category: gr-qc

TL;DR: 研究pp-wave时空测地线动力学，发现所有多项式度数的逃逸盆地都具有Wada性质，盆地熵随多项式度数增加而单调增长，表明系统最终状态不可预测性增强。


<details>
  <summary>Details</summary>
Motivation: 研究pp-wave时空（具有3≤n≤10次多项式轮廓）中测地线的动力学行为，这些动力学等价于经典粒子在二维调和多项式势中的运动。通过分析不同渐近结果的逃逸盆地，探索系统的混沌特性和最终状态的可预测性。

Method: 分析不同渐近结果相关的逃逸盆地，证明所有考虑的盆地都具有Wada性质。计算盆地熵Sb和边界盆地熵Sbb，使用ln(2)准则验证盆地边界的分形特性。

Result: 所有多项式度数（3≤n≤10）的盆地都表现出Wada性质。盆地熵Sb随多项式度数单调增加，表明系统最终状态的不可预测性增强。边界盆地熵Sbb的ln(2)准则证实当n>3时盆地边界是分形的。

Conclusion: pp-wave时空测地线动力学表现出强烈的混沌特性，所有多项式度数的盆地都具有Wada性质，且不可预测性随多项式度数增加而增强。推测Wada性质在n>10的多项式度数中仍然存在。

Abstract: We study the dynamics of the geodesics of pp-wave spacetimes with polynomial profiles of degrees $3\leq n\leq10$, which are dynamically equivalent to the motion of a classical particle in a two-dimensional harmonic polynomial potential. By analysing the escape basins associated with different asymptotic outcomes, we show that all basins exhibit the Wada property for every polynomial degree considered. We further compute the basin entropy $S_{b}$, finding that it increases monotonically with the polynomial degree, indicating enhanced unpredictability of the final state of the system. The boundary basin entropy $S_{bb}$ is also evaluated, and the $\ln(2)$ criterion confirms that the basin boundaries are fractal for $n>3$. We conjecture that the Wada property persists for polynomial degrees $n>10$.

</details>


### [47] [Healthy scalar-tensor theories with third-order derivatives: Generalized disformal Horndeski and beyond](https://arxiv.org/abs/2601.09164)
*Masaki Michiwaki,Tsutomu Kobayashi*

Main category: gr-qc

TL;DR: 构建了无鬼标量-张量理论，其拉格朗日量包含标量场的三阶导数，通过ADM变量和退化条件确保只传播一个标量自由度，扩展了广义disformal Horndeski和U-DHOST理论。


<details>
  <summary>Details</summary>
Motivation: 构建包含高阶导数但无额外自由度的标量-张量理论，扩展现有理论框架，研究广义disformal变换下的性质。

Method: 使用ADM变量构建空间协变作用量，施加退化条件和一致性条件以确保只传播一个标量自由度，系统构造包含三阶导数的理论。

Result: 成功构建了包含三阶导数的无鬼标量-张量理论，扩展了广义disformal Horndeski和U-DHOST理论，并分析了其在广义disformal变换下的性质。

Conclusion: 提出了包含三阶导数的标量-张量理论新框架，通过退化条件控制自由度传播，为高阶导数引力理论提供了系统构造方法。

Abstract: We systematically construct ghost-free scalar-tensor theories whose Lagrangian includes up to third-order derivatives of the scalar field. Using a spatially covariant action written in terms of the ADM variables, we impose degeneracy and consistency conditions that ensure the propagation of only one scalar and two tensor degrees of freedom. The resultant theories extend the generalized disformal Horndeski and U-DHOST theories. We discuss the transformation properties of these theories under generalized disformal transformations.

</details>


### [48] [Chiellini-Integrable Cosmologies with Phantom Divide Crossing](https://arxiv.org/abs/2601.09271)
*Soumya Chakrabarti,Nandan Roy*

Main category: gr-qc

TL;DR: 该论文研究了具有质量标量场的精确宇宙学解，发现Chiellini可积标量宇宙学能为晚期宇宙加速和幻影分界线穿越提供解析框架，缓解H₀张力。


<details>
  <summary>Details</summary>
Motivation: 研究广义相对论中最小耦合质量标量场的精确宇宙学解，探索能否描述晚期宇宙加速现象，特别是幻影分界线穿越，同时缓解ΛCDM宇宙学中的H₀张力问题。

Method: 采用扩展的类希格斯标量自相互作用，将场方程化为阻尼Ermakov-Painlevé II类方程，利用Chiellini可积性条件构造解析解，并结合BAO、CMB、宇宙钟和Pantheon+SHOES超新星数据集进行统计分析。

Result: 成功构造了新颖的解析解，能够平滑地实现暗能量状态方程的幻影分界线穿越而无病态不稳定性。重建得到当前哈勃参数H₀≳70 km/s/Mpc，相对于ΛCDM宇宙学的张力有所降低。

Conclusion: Chiellini可积标量宇宙学为建模晚期宇宙加速和幻影分界线穿越提供了稳健且解析可控的框架，是现象学暗能量参数化的可行替代方案。

Abstract: We investigate exact cosmological solutions with a massive scalar field minimally coupled to the Einstein-Hilbert action in General Relativity. For an extended Higgs-like scalar self-interaction, we find that the resulting field equations belong to the damped Ermakov-Painlevé II class and construct novel analytical solutions within the framework of the Chiellini integrability condition. We analyze whether the expanding branch of the solutions can describe a late-time cosmic acceleration, using a combined statistical analysis of BAO, CMB, cosmic chronometer and Pantheon+SHOES supernova datasets. A crucial outcome of this exercise is the analytical emergence of a smooth phantom divide crossing in the dark energy equation of state, achieved without introducing any pathological instabilities. The reconstruction yields a present-day Hubble parameter $H_0 \gtrsim 70 \,\mathrm{km\,s^{-1}\,Mpc^{-1}}$, with a reduced tension relative to the $Λ$CDM cosmology. The results indicate that Chiellini-integrable scalar cosmologies are capable of providing a robust and analytically controlled framework for modeling late-time cosmic acceleration and phantom divide crossing, offering a viable alternative to phenomenological dark-energy parametrizations.

</details>


### [49] [Sub-Leading Logarithms for Scalar Potential Models on de Sitter](https://arxiv.org/abs/2601.09309)
*S. P. Miao,N. C. Tsamis,R. P. Woodard*

Main category: gr-qc

TL;DR: 本文展示了随机形式主义如何捕捉暴胀中量子场论环修正的首个次领头对数项，通过将其应用于1圈有效势的特定部分，并在德西特背景上验证了无质量最小耦合四次标量场模型。


<details>
  <summary>Details</summary>
Motivation: 暴胀期间长波长标量子和引力子的持续产生会导致环修正中出现平直空间中没有的长期增长。通常每个环计数参数因子最多可诱导一定数量的尺度因子对数，达到此数量的称为"领头对数"，较少的称为次领头对数。随机形式主义已知能重现标量势模型的领头对数，但能否捕捉次领头对数尚不清楚。

Method: 将随机形式主义应用于1圈有效势的特定部分来捕捉首个次领头对数项。在德西特背景上，针对无质量最小耦合四次自相互作用标量场模型，在2圈水平上进行了验证。

Result: 研究表明，随机形式主义确实能够捕捉到首个次领头对数项，这通过将其应用于1圈有效势的特定部分实现，并在2圈水平上对具体模型进行了成功验证。

Conclusion: 随机形式主义不仅能重现暴胀中量子场论环修正的领头对数，还能通过适当应用于有效势来捕捉次领头对数，这扩展了该形式主义在暴胀宇宙学量子效应研究中的应用范围。

Abstract: The continual production of long wavelength scalars and gravitons during inflation injects secular growth into loop corrections which would be constant in flat space. One typically finds that each additional factor of the loop counting parameter can induce up to a certain number of logarithms of the scale factor. Loop corrections that attain this number are known as ``leading logarithms''; those with fewer are sub-leading. Starobinsky's stochastic formalism has long been known to reproduce the leading logarithms of scalar potential models. We show that the first sub-leading logarithm is captured by applying the stochastic formalism to a certain part of the 1-loop effective potential. This is checked at 2-loops for a massless, minimally coupled scalar with a quartic self-interaction on de Sitter background.

</details>


### [50] [Probing dynamical embeddings in a five-dimensional spacetime in light of DESI BAO](https://arxiv.org/abs/2601.09429)
*Abraão J. S. Capistrano,Emanuelly Silva,Rafael C. Nunes,Orlando Luongo*

Main category: gr-qc

TL;DR: Nash引力作为ΛCDM的替代模型，基于Nash嵌入定理，通过外曲率变化产生标量型度规扰动，无需额外场。观测数据拟合良好，H₀值略高，S₈值较低，可能缓解H₀和S₈张力。


<details>
  <summary>Details</summary>
Motivation: 研究Nash引力作为标准ΛCDM宇宙学的替代模型，探索其观测可行性，特别是能否缓解当前宇宙学中的H₀张力和S₈张力问题。

Method: 基于Nash嵌入定理，通过外曲率变化引入正交扰动，直接从几何产生标量型度规扰动。使用当前观测数据（Planck CMB、DESI DR2 BAO、SN Ia）进行模型拟合分析。

Result: Nash引力对数据拟合良好，得到H₀ = 69.32±0.72 km/s/Mpc（略高于ΛCDM），S₈ ≈ 0.76（结构增长受抑制）。在某些情况下，拟合优度比ΛCDM好2σ水平。

Conclusion: Nash引力作为ΛCDM的可行替代模型，可能同时缓解H₀张力和S₈张力，为宇宙学模型提供了新的几何框架。

Abstract: We here investigate the observational viability of Nash gravity as an alternative to the standard $Λ$CDM cosmology. Based on Nash's embedding theorem, the model introduces orthogonal perturbations via variations in the extrinsic curvature, generating scalar-type metric perturbations directly from geometry, without the need to introduce additional fields. We confront the model with current observational data, including Cosmic Microwave Background (CMB) measurements from Planck, Baryon Acoustic Oscillations (BAO) from DESI DR2, and recent Type Ia supernova (SN Ia) compilations. Our analysis shows that Nash gravity provides a good fit to the data, yielding a slightly higher value for the Hubble constant, $H_0 = 69.32 \pm 0.72$ km/s/Mpc, compared to the $Λ$CDM model, thus offering a potential alleviation of the $H_0$ tension. Furthermore, the model naturally predicts a suppressed growth of structure, with $S_8 \approx 0.76$ across various joint analyses, potentially alleviating the so-called $S_8$ tension, assuming that this discrepancy is not solely due to systematic effects in other independent measurements. In some cases, Nash gravity achieves a better fit to the data than the $Λ$CDM paradigm at the $2σ$ level.

</details>


### [51] [Tidal dynamics and stellar disruption in charged Kalb-Ramond black holes in nonlinear electrodynamics](https://arxiv.org/abs/2601.09482)
*Ednaldo L. B. Junior,Herlan N. Lemos,Marcos V. de S. Silva*

Main category: gr-qc

TL;DR: 研究Kalb-Ramond-ModMax黑洞时空中潮汐力、测地线偏离和潮汐瓦解现象，分析电磁非线性参数γ和洛伦兹对称性破缺参数l的影响。


<details>
  <summary>Details</summary>
Motivation: 探索在Kalb-Ramond-ModMax解描述的黑洞时空中，电磁非线性（参数γ）和洛伦兹对称性破缺（参数l）如何影响潮汐力、测地线偏离和潮汐瓦解现象，为强场区域中的洛伦兹破缺和非线性电动力学提供间接探测方法。

Method: 在正则扇区（α=1）和幻影扇区（α=-1）分别分析径向和角向潮汐力，研究参数l和γ对潮汐力特征、测地线偏离以及潮汐瓦解半径与视界半径关系的影响。

Result: 在正则扇区，径向潮汐力在视界r-和r+之间发生符号反转，l控制转变强度和位置，γ调节非线性电磁贡献；角向潮汐力主要为压缩性。在幻影扇区，潮汐力和测地线偏离发散，显示潮汐不稳定性。参数l改变潮汐瓦解半径与视界半径的关系，从而修改临界质量。对于超大质量黑洞，Kalb-Ramon-ModMax效应被抑制，但对中等质量系统和可观测潮汐瓦解事件可能相关。

Conclusion: Kalb-Ramon-ModMax效应在超大质量黑洞中被抑制，但在中等质量黑洞系统和可观测潮汐瓦解事件中可能相关，为强场区域中的洛伦兹破缺和非线性电动力学提供了间接探测途径。

Abstract: We investigate tidal forces, geodesic deviation, and tidal disruption in the black hole spacetime described by the Kalb-Ramond-ModMax solution, where electromagnetic nonlinearity is governed by the parameter $γ$ and Lorentz symmetry violation by the parameter $l$. In the canonical sector ($α=1$), the radial tidal force exhibits a transition marked by a sign inversion between the horizons $r_{-}$ and $r_+$, signaling internal regimes of radial compression analogous to those of charged black holes; the parameter $l$ controls the strength and location of this transition, while $γ$ regulates the nonlinear electromagnetic contribution. The angular tidal force is predominantly compressive, $l$ shaping the effective geometry, and $γ$ acting as a damping factor. In the phantom sector ($α=-1$), tidal forces and geodesic deviation diverge, indicating a tidal instability, with $l$ and $γ$ affecting only the magnitude of the response. We further show that $l$ shifts the relation between the horizon radius $r_+$ and the tidal disruption radius $r_{\rm Roche}$, thereby modifying the critical (Hills) mass defined by $r_{\rm Roche}=r_+$. Tidal disruption of neutron stars occurs inside the horizon for supermassive black holes, whereas Sun-like stars are disrupted outside the horizon, with $γ$ becoming relevant only for ultramassive black holes with masses $\sim 10^{8}M_{\odot}$. Our results demonstrate that Kalb-Ramon-ModMax effects are largely suppressed for supermassive black holes, but may be relevant for intermediate-mass systems and observable tidal disruption events, offering an indirect probe of Lorentz violation and nonlinear electrodynamics in the strong-field regime.

</details>


### [52] [The pseudo-complex Friedmann Lemaitre Robertson Walker model and the time dependence of the Hubble constant](https://arxiv.org/abs/2601.09593)
*L. Maghlaoui,P. O. Hess,F. Weber,C. A. Zen vasconcellos*

Main category: gr-qc

TL;DR: 伪复FLRW模型在伪复广义相对论框架下提出，暗能量作为伪复结构的几何结果出现，导致哈勃参数随时间变化而非恒定。使用DESI BAO数据拟合几何参数β得到最佳值1.0426，对应减速参数q=-0.9361，预测红移漂移与ΛCDM模型一致，但非零的H0导数是几何预测，为未来高精度观测提供可检验目标。


<details>
  <summary>Details</summary>
Motivation: 研究伪复广义相对论框架下的宇宙学模型，探索暗能量的几何起源，提供不同于标准ΛCDM模型的解释，并建立可检验的预测。

Method: 在伪复广义相对论框架下构建伪复FLRW模型，推导哈勃参数导数与几何参数β的关系，使用DESI BAO数据约束参数，计算减速参数和哈勃加速度，通过精确的Sandage-Loeb关系预测红移漂移。

Result: 最佳拟合β=1.0426，对应减速参数q=-0.9361，当前哈勃加速度H0≈0.94×10⁻¹⁷ (km/s²)/Mpc，预测z=4源在20年内的红移漂移Δv≈-11.1 cm/s，与ΛCDM预测接近，但非零H0导数是几何预测而非假设。

Conclusion: 伪复广义相对论为暗能量提供几何解释，预测随时间变化的哈勃参数，与观测数据一致，非零的H0导数是该理论的可检验预测，为未来高精度光谱观测提供明确目标。

Abstract: The pseudocomplex version of the FLRW model is presented within the framework of pseudocomplex General Relativity (pcGR). In this approach, dark energy arises as a geometric consequence of the pseudocomplex structure, leading to a time dependent Hubble parameter rather than a strictly constant H0. The relation between the tiderived and constrained using recent DESI BAO data. Fitting beta yields a best-fit value beta = 1.0426, corresponding to a deceleration parameter q = -0.9361 and a present day Hubble acceleration me derivative of the Hubble parameter and a single geometric parameter beta in the effective dark energy equation of state is derived and constrained using recent DESI BAO data. Fitting beta yields a best-fit value beta = 1.0426, corresponding to a deceleration parameter q = -0.9361 and a present day Hubble acceleration H0 sim 0.94 x10-17 (km/s2)/Mpc. Using the exact Sandage Loeb relation, the predicted redshift drift over 20 years for a source at z = 4 is Delta-v sim -11.1 cm/s, in close agreement with the Lambda CDM prediction. In pcGR, however, the non-vanishing H0 is a direct geometric prediction, providing a clear and testable target for future high-precision spectroscopic observations.

</details>


### [53] [Confronting eikonal and post-Kerr methods with numerical evolution of scalar field perturbations in spacetimes beyond Kerr](https://arxiv.org/abs/2601.09607)
*Ciro De Simone,Sebastian H. Völkel,Kostas D. Kokkotas,Vittorio De Falco,Salvatore Capozziello*

Main category: gr-qc

TL;DR: 评估eikonal近似和后Kerr近似在预测变形Kerr时空标量场准正规模谱的准确性，使用数值模拟量化理论误差，并与统计不确定性对比，探索高精度黑洞光谱学中近似方法的有效域。


<details>
  <summary>Details</summary>
Motivation: 精确计算超越广义相对论的旋转黑洞准正规模对于用引力波测试基础物理至关重要。需要评估近似方法的准确性，为高精度黑洞光谱学提供理论指导。

Method: 1) 评估eikonal近似和后Kerr近似在变形Kerr时空的准确性；2) 使用2+1维数值时间演化框架获得基准结果并分析一般扰动的环降动力学；3) 系统量化理论不确定性，涵盖多个角谐波、宽范围自旋参数和逐渐增强的Kerr几何偏离；4) 将建模误差与准正规模频率统计不确定性预测对比。

Result: 1) 系统量化了近似方法的理论误差；2) 发现近地平线变形对顺行和逆行模式的影响不同，并提供了几何解释；3) 探索了近似方法在高精度黑洞光谱学中的有效域。

Conclusion: 该研究为评估近似方法在变形Kerr时空准正规模计算中的准确性提供了系统框架，揭示了近地平线变形的非对称效应，并为未来高精度黑洞光谱学实验中的理论不确定性量化提供了指导。

Abstract: The accurate computation of quasinormal modes from rotating black holes beyond general relativity is crucial for testing fundamental physics with gravitational waves. In this study, we assess the accuracy of the eikonal and post-Kerr approximations in predicting the quasinormal mode spectrum of a scalar field on a deformed Kerr spacetime. To obtain benchmark results and to analyze the ringdown dynamics from generic perturbations, we further employ a 2+1-dimensional numerical time-evolution framework. This approach enables a systematic quantification of theoretical uncertainties across multiple angular harmonics, a broad range of spin parameters, and progressively stronger deviations from the Kerr geometry. We then confront these modeling errors with simple projections of statistical uncertainties in quasinormal mode frequencies as a function of the signal-to-noise ratio, thereby exploring the domain of validity of approximate methods for prospective high-precision black-hole spectroscopy. We also report that near-horizon deformations can affect prograde and retrograde modes differently and provide a geometrical explanation.

</details>


### [54] [A Closed-Form Surrogate for the Equivalent Diameter of the Kerr Shadow](https://arxiv.org/abs/2601.09655)
*Arseny Pantsialei*

Main category: gr-qc

TL;DR: 提出了一个闭合形式的代理模型，用于计算克尔黑洞阴影的等效直径，该模型通过分离解析计算的极向贡献和紧凑的多项式校正，实现了亚百分比的精度。


<details>
  <summary>Details</summary>
Motivation: 现有的克尔黑洞阴影尺寸计算需要数值光线追踪，这在参数推断和快速模型比较中需要大量重复调用时效率低下。需要一个快速、准确的闭合形式表达式来替代数值计算。

Method: 通过分离解析计算的极向贡献（基于球面光子轨道分支）和剩余倾角依赖关系，后者用一个紧凑的15参数多项式嵌入指数校正中捕获。系数通过普通最小二乘法在确定性参考网格上确定。

Result: 在自旋参数0到0.998、倾角从略高于0度到90度的实用域内，代理模型达到亚百分比精度：训练网格中绝对百分比误差中位数为0.0105%，最差情况为0.782%；验证集中误差中位数为0.023%，95百分位数为0.471%，最差情况为1.64%。

Conclusion: 该闭合形式表达式无需数值光线追踪即可快速评估阴影尺寸，适用于参数推断中的重复调用和快速模型比较，显著提高了计算效率。

Abstract: We present a closed-form surrogate for the equivalent diameter of the Kerr black-hole shadow, defined as the diameter of the circle with the same area as the shadow's critical curve. The construction enforces the exact face-on (polar) limit by explicitly separating an analytically computed polar contribution based on the spherical photon-orbit branch where the horizontal impact parameter vanishes. The remaining inclination dependence is captured by a compact 15-parameter polynomial placed inside an exponential correction. The coefficients are determined by ordinary least squares on a deterministic reference grid generated from the Kerr critical-curve area. Over the practical domain of dimensionless spin from 0 to 0.998 and inclination from just above 0 degrees up to 90 degrees (with the exactly polar point treated analytically), the surrogate achieves sub-percent accuracy. On the training grid the median absolute percent error is 0.0105 percent with a worst case of 0.782 percent, and on a denser out-of-sample validation set (including inclinations down to 0.5 degrees) the median, 95th-percentile, and worst-case errors are 0.023 percent, 0.471 percent, and 1.64 percent, respectively. The resulting expression provides fast evaluations of the shadow size without numerical ray tracing, making it convenient for repeated calls in parameter inference and rapid model comparisons.

</details>


### [55] [Constant-roll $β$-exponential inflation: Palatini formalism](https://arxiv.org/abs/2601.09664)
*Ozan Sargın*

Main category: gr-qc

TL;DR: 研究β指数势模型在二次(R+R²)引力下的暴胀动力学，采用Palatini形式推导爱因斯坦框架下的广义k-暴胀有效理论，在常滚条件下分析参数空间，寻找与ACT DR6观测一致的暴胀预测


<details>
  <summary>Details</summary>
Motivation: 探索标量场与二次引力耦合的暴胀模型，其中暴胀子决定额外维度大小，旨在建立与最新宇宙学观测一致的暴胀理论

Method: 采用Palatini形式推导爱因斯坦框架下的广义k-暴胀有效理论，在常滚条件下扫描参数空间，计算谱指数n_s和张标比r，与ACT DR6和Planck观测数据对比

Result: 在合适的参数范围内，模型预测的暴胀可观测量与ACT和Planck的最新观测结果一致，展示了与观测数据兼容的参数区域

Conclusion: β指数势模型与二次引力耦合在Palatini形式下能够产生与当前宇宙学观测一致的暴胀预测，为构建可行的暴胀理论提供了新途径

Abstract: In this paper, we explore the inflationary dynamics of the $β$-exponential potential model, where a scalar field couples to quadratic $(R + R^2)$ gravity. In this model, the inflaton is the field that determines the size of the extra dimension. We employ the Palatini formalism to derive the resulting Einstein-frame generalized $k$-inflation effective theory, which we analyze under the assumption that the constant-roll condition is satisfied.
  We scan the parameter space for inflationary predictions, specifically the spectral index $n_s$ and the tensor-to-scalar ratio $r$, ensuring consistency with the results from ACT DR6. The compliant regions are depicted accordingly. For a suitable range of the model parameters, the values obtained for the inflationary observables align with the most recent observations by the Atacama Cosmology Telescope (ACT) collaboration and/or the Planck mission.

</details>


### [56] [The impact of waveform systematics and Gaussian noise on the interpretation of GW231123](https://arxiv.org/abs/2601.09678)
*Sophie Bini,Krzysztof Król,Katerina Chatziioannou,Maximiliano Isi*

Main category: gr-qc

TL;DR: GW231123引力波事件参数推断存在模型系统性差异，但通过数值相对论模拟验证，其高质量、高自旋的核心物理性质是稳健的。


<details>
  <summary>Details</summary>
Motivation: GW231123是双大质量、高自旋黑洞并合事件，但信号周期少且不同模型给出系统性不同参数，需要验证其物理解释是否稳健。

Method: 使用数值相对论替代模型NRSur7dq4模拟信号，在无噪声和不同高斯噪声实现下进行参数推断，并与实际观测结果比较。

Result: 模拟信号能复现实际观测中的模型系统性差异；在不同噪声实现下，大质量、高自旋幅度和高自旋进动性质一致稳健，仅有效自旋χ_eff波动较大；单探测器间的差异统计不显著。

Conclusion: GW231123的核心物理性质（特别是NRSur7dq4推断的高质量和自旋幅度）是稳健的，不受模型系统性和高斯噪声的显著影响。

Abstract: GW231123 is an exceptional gravitational-wave event consistent with the merger of two massive, highly-spinning black holes. Reliable inference of the source properties is crucial for accurate interpretation of its astrophysical implications. However, characterization of GW231123 is challenging: only few signal cycles are observed and different signal models result in systematically different parameters. We investigate whether the interpretation of GW231123 is robust against model systematics and Gaussian detector noise. We show that the model systematics observed in GW231123 can be reproduced for a simulated signal based on the numerical-relativity surrogate model NRSur7dq4. Simulating data using the maximum-likelihood NRSur7dq4 waveform for GW231123 and no noise realization, we closely recover the systematics observed for the real signal. We then explore how the headline properties of GW231123 are impacted by Gaussian detector noise. Using the NRSur7dq4 maximum-likelihood waveform and different noise realizations, we consistently find support for large masses, high spin magnitudes (median $χ_1\geq 0.7$), and high spin precession (median $χ_\mathrm{p}\geq 0.68$). The spin in the direction of the angular momentum ($χ_\mathrm{eff}$) fluctuates more. Finally, again comparing to simulated signals, we show that any differences in the GW231123 inference based on each separate detector are not statistically significant. These results show that the properties of GW231123, and most importantly the high mass and high spin magnitudes inferred by NRSur7dq4, are robust.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [57] [Attention Consistency Regularization for Interpretable Early-Exit Neural Networks](https://arxiv.org/abs/2601.08891)
*Yanhua Zhao*

Main category: cs.LG

TL;DR: EGT框架通过注意力一致性损失提升早期退出网络的解释性和一致性，在保持准确率的同时实现1.97倍推理加速和18.5%注意力一致性提升。


<details>
  <summary>Details</summary>
Motivation: 早期退出神经网络虽然能减少计算成本，但缺乏解释性，且不同层关注的特征不一致，限制了其在可解释AI应用中的可信度。

Method: 提出Explanation-Guided Training (EGT)多目标框架，通过注意力一致性损失对齐早期退出和最终退出的注意力图，联合优化分类准确率和注意力一致性。

Result: 在真实图像分类数据集上，EGT达到98.97%总体准确率（与基线相当），通过早期退出实现1.97倍推理加速，注意力一致性比基线提升18.5%。

Conclusion: EGT使早期退出网络在所有退出点提供更可解释和一致的说明，更适合资源受限环境中的可解释AI应用。

Abstract: Early-exit neural networks enable adaptive inference by allowing predictions at intermediate layers, reducing computational cost. However, early exits often lack interpretability and may focus on different features than deeper layers, limiting trust and explainability. This paper presents Explanation-Guided Training (EGT), a multi-objective framework that improves interpretability and consistency in early-exit networks through attention-based regularization. EGT introduces an attention consistency loss that aligns early-exit attention maps with the final exit. The framework jointly optimizes classification accuracy and attention consistency through a weighted combination of losses. Experiments on a real-world image classification dataset demonstrate that EGT achieves up to 98.97% overall accuracy (matching baseline performance) with a 1.97x inference speedup through early exits, while improving attention consistency by up to 18.5% compared to baseline models. The proposed method provides more interpretable and consistent explanations across all exit points, making early-exit networks more suitable for explainable AI applications in resource-constrained environments.

</details>


### [58] [Discrete Solution Operator Learning for Geometry-Dependent PDEs](https://arxiv.org/abs/2601.09143)
*Jinshuai Bai,Haolin Li,Zahra Sharif Khodaei,M. H. Aliabadi,YuanTong Gu,Xi-Qiao Feng*

Main category: cs.LG

TL;DR: DiSOL提出离散解算子学习范式，通过模拟经典离散化过程学习离散求解程序而非连续函数空间算子，能处理几何变化引起的拓扑突变等不连续问题。


<details>
  <summary>Details</summary>
Motivation: 传统神经算子学习基于连续函数空间映射，但在工程实际中几何变化常导致离散结构突变（如拓扑变化、边界条件突变、计算域变化），破坏了光滑变化的前提假设。

Method: DiSOL将求解器分解为可学习的阶段：局部贡献编码、多尺度组装、嵌入网格上的隐式解重构，这些阶段模拟经典离散化过程，保持程序级一致性同时适应几何相关的离散结构。

Result: 在几何相关的泊松方程、对流扩散、线性弹性以及时空热传导问题中，DiSOL在分布内和强分布外几何（包括不连续边界和拓扑变化）下都能产生稳定准确的预测。

Conclusion: 研究强调了在几何主导区域中程序化算子表示的必要性，并将离散解算子学习定位为科学机器学习中一个独特且互补的方向。

Abstract: Neural operator learning accelerates PDE solution by approximating operators as mappings between continuous function spaces. Yet in many engineering settings, varying geometry induces discrete structural changes, including topological changes, abrupt changes in boundary conditions or boundary types, and changes in the effective computational domain, which break the smooth-variation premise. Here we introduce Discrete Solution Operator Learning (DiSOL), a complementary paradigm that learns discrete solution procedures rather than continuous function-space operators. DiSOL factorizes the solver into learnable stages that mirror classical discretizations: local contribution encoding, multiscale assembly, and implicit solution reconstruction on an embedded grid, thereby preserving procedure-level consistency while adapting to geometry-dependent discrete structures. Across geometry-dependent Poisson, advection-diffusion, linear elasticity, as well as spatiotemporal heat-conduction problems, DiSOL produces stable and accurate predictions under both in-distribution and strongly out-of-distribution geometries, including discontinuous boundaries and topological changes. These results highlight the need for procedural operator representations in geometry-dominated regimes and position discrete solution operator learning as a distinct, complementary direction in scientific machine learning.

</details>


### [59] [Spectral Generative Flow Models: A Physics-Inspired Replacement for Vectorized Large Language Models](https://arxiv.org/abs/2601.08893)
*Andrew Kiruluta*

Main category: cs.LG

TL;DR: SGFMs是一种基于物理启发的生成模型，用连续场演化替代离散token序列，通过多尺度小波基中的约束随机动力学处理文本和视频生成。


<details>
  <summary>Details</summary>
Motivation: 提出一种替代transformer的物理启发方法，旨在解决传统模型在长程一致性、多模态通用性和物理结构归纳偏置方面的限制，为下一代生成模型提供更原则性的路径。

Method: 采用场论本体论，将文本和视频统一为随机偏微分方程的轨迹；使用小波域表示实现稀疏性和尺度分离；设计约束随机流确保稳定性和一致性传播；用局部算子、谱投影和Navier-Stokes类输运替代全局注意力机制。

Result: 提出了一个从根本上区别于自回归建模和扩散方法的生成架构，能够实现长程一致性、多模态通用性和物理结构归纳偏置，为下一代生成模型提供了新方向。

Conclusion: SGFMs为生成建模提供了物理启发的创新框架，通过连续场演化、小波表示和约束动力学，有望在长程一致性、多模态能力和物理结构理解方面超越传统transformer模型。

Abstract: We introduce Spectral Generative Flow Models (SGFMs), a physics-inspired alternative to transformer-based large language models. Instead of representing text or video as sequences of discrete tokens processed by attention, SGFMs treat generation as the evolution of a continuous field governed by constrained stochastic dynamics in a multiscale wavelet basis. This formulation replaces global attention with local operators, spectral projections, and Navier--Stokes-like transport, yielding a generative mechanism grounded in continuity, geometry, and physical structure.
  Our framework provides three key innovations: (i) a field-theoretic ontology in which text and video are unified as trajectories of a stochastic partial differential equation; (ii) a wavelet-domain representation that induces sparsity, scale separation, and computational efficiency; and (iii) a constrained stochastic flow that enforces stability, coherence, and uncertainty propagation. Together, these components define a generative architecture that departs fundamentally from autoregressive modeling and diffusion-based approaches. SGFMs offer a principled path toward long-range coherence, multimodal generality, and physically structured inductive bias in next-generation generative models.

</details>


### [60] [XGBoost Forecasting of NEPSE Index Log Returns with Walk Forward Validation](https://arxiv.org/abs/2601.08896)
*Sahaj Raj Malla,Shreeyash Kayastha,Rumi Suwal,Harish Chandra Bhandari,Rajendra Adhikari*

Main category: cs.LG

TL;DR: 使用XGBoost回归器开发尼泊尔股市指数日对数收益率一步预测框架，通过特征工程和超参数优化，在滚动窗口验证中优于ARIMA和Ridge回归基准模型。


<details>
  <summary>Details</summary>
Motivation: 针对尼泊尔股市指数（NEPSE）这一新兴市场的波动性时间序列，开发稳健的机器学习框架来预测日对数收益率，以捕捉非线性动态关系并建立可复现的基准。

Method: 使用XGBoost回归器，构建包含滞后对数收益率（最多30天）、滚动波动率指标和相对强弱指数（RSI）的综合特征集。通过Optuna进行超参数优化，采用时间序列交叉验证和滚动窗口验证（扩展窗口和固定长度窗口）来避免前瞻偏差。

Result: 最优配置（20个滞后的扩展窗口）在样本外测试中表现最佳，对数收益率的RMSE为0.013450，MAE为0.009814，方向准确率达到65.15%，优于调优的ARIMA和Ridge回归基准模型。

Conclusion: 梯度提升集成方法能有效建模新兴市场波动时间序列的非线性动态，为NEPSE指数预测建立了可复现的基准，尽管R²值有限（符合金融收益率的噪声特性），但在相对误差减少和方向预测方面表现突出。

Abstract: This study develops a robust machine learning framework for one-step-ahead forecasting of daily log-returns in the Nepal Stock Exchange (NEPSE) Index using the XGBoost regressor. A comprehensive feature set is engineered, including lagged log-returns (up to 30 days) and established technical indicators such as short- and medium-term rolling volatility measures and the 14-period Relative Strength Index. Hyperparameter optimization is performed using Optuna with time-series cross-validation on the initial training segment. Out-of-sample performance is rigorously assessed via walk-forward validation under both expanding and fixed-length rolling window schemes across multiple lag configurations, simulating real-world deployment and avoiding lookahead bias. Predictive accuracy is evaluated using root mean squared error, mean absolute error, coefficient of determination (R-squared), and directional accuracy on both log-returns and reconstructed closing prices. Empirical results show that the optimal configuration, an expanding window with 20 lags, outperforms tuned ARIMA and Ridge regression benchmarks, achieving the lowest log-return RMSE (0.013450) and MAE (0.009814) alongside a directional accuracy of 65.15%. While the R-squared remains modest, consistent with the noisy nature of financial returns, primary emphasis is placed on relative error reduction and directional prediction. Feature importance analysis and visual inspection further enhance interpretability. These findings demonstrate the effectiveness of gradient boosting ensembles in modeling nonlinear dynamics in volatile emerging market time series and establish a reproducible benchmark for NEPSE Index forecasting.

</details>


### [61] [DriftGuard: A Hierarchical Framework for Concept Drift Detection and Remediation in Supply Chain Forecasting](https://arxiv.org/abs/2601.08928)
*Shahnawaz Alam,Mohammed Abdul Rahman,Bareera Sadeqa*

Main category: cs.LG

TL;DR: DriftGuard是一个端到端的供应链预测漂移管理系统，通过多方法检测、分层传播分析、SHAP根因诊断和成本感知重训练，解决概念漂移问题。


<details>
  <summary>Details</summary>
Motivation: 供应链预测模型会随时间退化（概念漂移），导致库存问题。现有方法仅关注检测，缺乏诊断和修复，且忽略供应链数据的层次结构。需要完整的端到端系统。

Method: 提出DriftGuard五模块框架：1) 四种互补检测方法集成（误差监控、统计测试、自编码器异常检测、CUSUM变点分析）；2) 分层传播分析定位产品线漂移位置；3) SHAP分析诊断根因；4) 成本感知重训练策略选择性更新受影响模型；5) 端到端系统实现。

Result: 在M5零售数据集的30,000+时间序列上评估，DriftGuard在4.2天内达到97.8%的检测召回率，通过针对性修复实现高达417的投资回报率。

Conclusion: DriftGuard解决了供应链预测中概念漂移的完整生命周期管理问题，提供早期检测、根因诊断和自动修复，显著优于当前行业实践和学术方法。

Abstract: Supply chain forecasting models degrade over time as real-world conditions change. Promotions shift, consumer preferences evolve, and supply disruptions alter demand patterns, causing what is known as concept drift. This silent degradation leads to stockouts or excess inventory without triggering any system warnings. Current industry practice relies on manual monitoring and scheduled retraining every 3-6 months, which wastes computational resources during stable periods while missing rapid drift events. Existing academic methods focus narrowly on drift detection without addressing diagnosis or remediation, and they ignore the hierarchical structure inherent in supply chain data. What retailers need is an end-to-end system that detects drift early, explains its root causes, and automatically corrects affected models. We propose DriftGuard, a five-module framework that addresses the complete drift lifecycle. The system combines an ensemble of four complementary detection methods, namely error-based monitoring, statistical tests, autoencoder anomaly detection, and Cumulative Sum (CUSUM) change-point analysis, with hierarchical propagation analysis to identify exactly where drift occurs across product lines. Once detected, Shapley Additive Explanations (SHAP) analysis diagnoses the root causes, and a cost-aware retraining strategy selectively updates only the most affected models. Evaluated on over 30,000 time series from the M5 retail dataset, DriftGuard achieves 97.8% detection recall within 4.2 days and delivers up to 417 return on investment through targeted remediation.

</details>


### [62] [Breaking the Bottlenecks: Scalable Diffusion Models for 3D Molecular Generation](https://arxiv.org/abs/2601.08963)
*Adrita Das,Peiran Jiang,Dantong Zhu,Barnabas Poczos,Jose Lugo-Martinez*

Main category: cs.LG

TL;DR: 本文通过Reverse Transition Kernel框架重新解释DDDM，将确定性去噪统一到概率形式中，解决了分子扩散模型采样慢、随机方差大等问题，实现了更高效稳定的分子生成。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在分子设计中表现出强大能力，但存在采样轨迹长、反向过程随机方差大、去噪动态结构意识有限等问题。DDDM通过确定性去噪步骤减少了推理时间，但其理论基础不明确。

Method: 使用Huang等人2024年提出的Reverse Transition Kernel框架，将DDDM的反向过程重新解释为近似核算子，表明直接去噪过程隐式优化了噪声样本与干净样本之间的结构化传输映射。

Result: RTK引导的确定性去噪比随机扩散模型收敛更快、结构保真度更高，在GEOM-DRUGS数据集上保持了化学有效性，同时确保了数值稳定性、消除了随机方差、实现了可扩展且保持SE(3)等变性的去噪器。

Conclusion: 通过RTK框架为确定性去噪提供了理论依据，统一了确定性和随机性扩散，解决了分子扩散中的多个长期瓶颈，实现了更高效稳定的分子生成。

Abstract: Diffusion models have emerged as a powerful class of generative models for molecular design, capable of capturing complex structural distributions and achieving high fidelity in 3D molecule generation. However, their widespread use remains constrained by long sampling trajectories, stochastic variance in the reverse process, and limited structural awareness in denoising dynamics. The Directly Denoising Diffusion Model (DDDM) mitigates these inefficiencies by replacing stochastic reverse MCMC updates with deterministic denoising step, substantially reducing inference time. Yet, the theoretical underpinnings of such deterministic updates have remained opaque. In this work, we provide a principled reinterpretation of DDDM through the lens of the Reverse Transition Kernel (RTK) framework by Huang et al. 2024, unifying deterministic and stochastic diffusion under a shared probabilistic formalism. By expressing the DDDM reverse process as an approximate kernel operator, we show that the direct denoising process implicitly optimizes a structured transport map between noisy and clean samples. This perspective elucidates why deterministic denoising achieves efficient inference. Beyond theoretical clarity, this reframing resolves several long-standing bottlenecks in molecular diffusion. The RTK view ensures numerical stability by enforcing well-conditioned reverse kernels, improves sample consistency by eliminating stochastic variance, and enables scalable and symmetry-preserving denoisers that respect SE(3) equivariance. Empirically, we demonstrate that RTK-guided deterministic denoising achieves faster convergence and higher structural fidelity than stochastic diffusion models, while preserving chemical validity across GEOM-DRUGS dataset. Code, models, and datasets are publicly available in our project repository.

</details>


### [63] [Continuous Fairness On Data Streams](https://arxiv.org/abs/2601.08976)
*Subhodeep Ghosh,Zhihui Du,Angela Bonifati,Manish Kumar,David Bader,Senjuti Basu Roy*

Main category: cs.LG

TL;DR: 提出了一种在数据流滑动窗口中实现连续组公平性的新模型，通过更细粒度的块级公平性监控和重新排序算法，在实时处理中显著提升公平性表现。


<details>
  <summary>Details</summary>
Motivation: 当滑动窗口较大时，仅保证窗口级别的组公平性可能不够精细，需要在窗口内部实现更细粒度的公平性控制，以应对实际应用中更复杂的公平性需求。

Method: 设计了基于草图的数据结构来高效监控滑动窗口中的块级组公平性，并开发了具有理论保证的最优重新排序算法，当检测到公平性违规时能够有效重新排列当前窗口。

Result: 在四个真实世界流式场景中验证了方法的有效性：平均处理速度达到毫秒级，吞吐量约30,000查询/秒；重新排序算法在某些情况下将块级组公平性提升高达95%，平均提升50-60%。

Conclusion: 块级公平性相比窗口级公平性具有明显优势，提出的监控和重新排序方法能够在实时数据流处理中有效实施连续组公平性，满足实际应用需求。

Abstract: We study the problem of enforcing continuous group fairness over windows in data streams. We propose a novel fairness model that ensures group fairness at a finer granularity level (referred to as block) within each sliding window. This formulation is particularly useful when the window size is large, making it desirable to enforce fairness at a finer granularity. Within this framework, we address two key challenges: efficiently monitoring whether each sliding window satisfies block-level group fairness, and reordering the current window as effectively as possible when fairness is violated. To enable real-time monitoring, we design sketch-based data structures that maintain attribute distributions with minimal overhead. We also develop optimal, efficient algorithms for the reordering task, supported by rigorous theoretical guarantees. Our evaluation on four real-world streaming scenarios demonstrates the practical effectiveness of our approach. We achieve millisecond-level processing and a throughput of approximately 30,000 queries per second on average, depending on system parameters. The stream reordering algorithm improves block-level group fairness by up to 95% in certain cases, and by 50-60% on average across datasets. A qualitative study further highlights the advantages of block-level fairness compared to window-level fairness.

</details>


### [64] [Optimising for Energy Efficiency and Performance in Machine Learning](https://arxiv.org/abs/2601.08991)
*Emile Dos Santos Ferreira,Neil D. Lawrence,Andrei Paleyes*

Main category: cs.LG

TL;DR: ECOpt是一个超参数调优器，专门优化机器学习模型的能源效率和性能，通过帕累托前沿量化两者权衡，帮助用户做出能源消耗与模型性能的平衡决策。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型日益增大导致能源消耗和环境问题加剧，但现有研究主要关注训练成本而忽略更大的推理成本，且缺乏提供可操作反馈的能源测量工具。

Method: 开发了能源消耗优化器（ECOpt），这是一个超参数调优器，通过量化能源效率与模型性能之间的权衡关系，生成可解释的帕累托前沿，帮助用户做出明智决策。

Result: 发现参数数量和浮点运算次数不能可靠地代表能源消耗；Transformer文本生成模型的能源效率在不同硬件上相对一致；使用ECOpt发现了7个在CIFAR-10上同时考虑准确率和能源效率时优于现有技术的模型。

Conclusion: ECOpt能够产生净正面的环境影响，强调需要测量和发布机器学习模型的能源指标，为平衡模型性能与能源效率提供了实用工具。

Abstract: The ubiquity of machine learning (ML) and the demand for ever-larger models bring an increase in energy consumption and environmental impact. However, little is known about the energy scaling laws in ML, and existing research focuses on training cost -- ignoring the larger cost of inference. Furthermore, tools for measuring the energy consumption of ML do not provide actionable feedback.
  To address these gaps, we developed Energy Consumption Optimiser (ECOpt): a hyperparameter tuner that optimises for energy efficiency and model performance. ECOpt quantifies the trade-off between these metrics as an interpretable Pareto frontier. This enables ML practitioners to make informed decisions about energy cost and environmental impact, while maximising the benefit of their models and complying with new regulations.
  Using ECOpt, we show that parameter and floating-point operation counts can be unreliable proxies for energy consumption, and observe that the energy efficiency of Transformer models for text generation is relatively consistent across hardware. These findings motivate measuring and publishing the energy metrics of ML models. We further show that ECOpt can have a net positive environmental impact and use it to uncover seven models for CIFAR-10 that improve upon the state of the art, when considering accuracy and energy efficiency together.

</details>


### [65] [Physics-Guided Counterfactual Explanations for Large-Scale Multivariate Time Series: Application in Scalable and Interpretable SEP Event Prediction](https://arxiv.org/abs/2601.08999)
*Pranjal Patil,Anli Ji,Berkay Aydin*

Main category: cs.LG

TL;DR: 提出物理引导的反事实解释框架，用于太阳高能粒子事件预测，在保持物理合理性的同时提升解释质量与效率。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习模型在太阳高能粒子事件预测中虽表现良好，但缺乏对领域特定物理约束的考虑，现有反事实解释方法很少强制执行物理合理性，限制了其在科学领域的实用性。

Method: 提出物理引导的反事实解释框架，在时间序列分类任务中生成符合基础物理原理的反事实解释，应用于太阳高能粒子预测，通过物理约束确保解释的合理性。

Result: 相比DiCE等先进基线方法，该框架将动态时间规整距离减少80%以上（提高邻近性），生成更高稀疏性的反事实解释，并将运行时间减少近50%。

Conclusion: 该框架生成既有效又物理一致的反事实解释，为大数据环境中的可扩展反事实生成奠定基础，确保解释在科学领域中具有物理合理性和可操作性。

Abstract: Accurate prediction of solar energetic particle events is vital for safeguarding satellites, astronauts, and space-based infrastructure. Modern space weather monitoring generates massive volumes of high-frequency, multivariate time series (MVTS) data from sources such as the Geostationary perational Environmental Satellites (GOES). Machine learning (ML) models trained on this data show strong predictive power, but most existing methods overlook domain-specific feasibility constraints. Counterfactual explanations have emerged as a key tool for improving model interpretability, yet existing approaches rarely enforce physical plausibility. This work introduces a Physics-Guided Counterfactual Explanation framework, a novel method for generating counterfactual explanations in time series classification tasks that remain consistent with underlying physical principles. Applied to solar energetic particles (SEP) forecasting, this framework achieves over 80% reduction in Dynamic Time Warping (DTW) distance increasing the proximity, produces counterfactual explanations with higher sparsity, and reduces runtime by nearly 50% compared to state-of-the-art baselines such as DiCE. Beyond numerical improvements, this framework ensures that generated counterfactual explanations are physically plausible and actionable in scientific domains. In summary, the framework generates counterfactual explanations that are both valid and physically consistent, while laying the foundation for scalable counterfactual generation in big data environments.

</details>


### [66] [Universal Dynamics of Warmup Stable Decay: understanding WSD beyond Transformers](https://arxiv.org/abs/2601.09000)
*Annalisa Belloni,Lorenzo Noci,Antonio Orvieto*

Main category: cs.LG

TL;DR: WSD学习率调度器在语言模型中表现出色，但这是否是Transformer特有的现象？本文比较了WSD在语言模型和CNN上的表现，发现两者训练信号、优化路径和锐度动态相似，表明不同非凸问题的损失景观具有共享的几何特性。


<details>
  <summary>Details</summary>
Motivation: 研究WSD学习率调度器的优异性能是否仅限于Transformer语言模型，还是反映了更普遍的优化几何特性。通过比较不同架构的训练动态，探索高维非凸优化问题的共享几何特征。

Method: 比较WSD调度器在Adam优化器下，在Pythia-like语言模型和CIFAR10图像分类的小型CNN上的优化路径。分析训练信号、优化路径特征和锐度动态的相似性。

Result: 观察到两种架构在大多数训练信号、优化路径特征和锐度动态方面具有定性相似性。这表明新旧非凸问题的损失景观具有共享的几何特性。

Conclusion: WSD的性能优势不是Transformer特有的现象，而是反映了更普遍的优化几何特性。这为理解高维优化问题的几何结构提供了新视角，并提出了未来研究方向。

Abstract: The Warmup Stable Decay (WSD) learning rate scheduler has recently become popular, largely due to its good performance and flexibility when training large language models. It remains an open question whether the remarkable performance of WSD - using a decaying learning rate for only a fraction of training compared to cosine decay - is a phenomenon specific to transformer-based language models that can potentially offer new theoretical insights into their training dynamics. Inspired by the usage of learning rate schedulers as a new lens into understanding landscape geometry (e.g., river valley, connected minima, progressive sharpening), in this work we compare the WSD path of the Adam optimizer on a Pythia-like language model to that of a small CNN trained to classify CIFAR10 images. We observe most training signals, optimizer path features, and sharpness dynamics to be qualitatively similar in such architectures. This consistency points to shared geometric characteristics of the loss landscapes of old and new nonconvex problems, and hints to future research questions around the geometry of high dimensional optimization problems.

</details>


### [67] [Meta-learning to Address Data Shift in Time Series Classification](https://arxiv.org/abs/2601.09018)
*Samuel Myren,Nidhi Parikh,Natalie Klein*

Main category: cs.LG

TL;DR: 该论文系统比较了传统深度学习与元学习在时间序列分类中应对数据漂移的能力，发现元学习在小数据量和简单模型时表现更好，但随着数据量和模型容量增加，传统深度学习微调表现相当。作者还引入了SeisTask地震基准数据集。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据具有动态变化特性（数据漂移），传统深度学习模型在训练和测试数据分布不同时性能会快速下降，需要昂贵的重新标注和低效的重新训练。元学习能够快速适应新数据，为解决这一问题提供了有前景的替代方案。

Method: 系统比较传统深度学习（带微调）与基于优化的元学习算法在时间序列分类中应对数据漂移的能力。引入受控的任务导向地震基准数据集SeisTask，评估不同数据量、模型容量和任务多样性条件下的性能。

Result: 元学习通常在数据稀缺情况下和较小模型架构中实现更快、更稳定的适应，且过拟合较少。随着数据可用性和模型容量增加，其优势减弱，传统深度学习微调表现相当。任务多样性对元学习的影响表明，训练和测试分布的对齐比多样性本身更能驱动性能提升。

Conclusion: 该研究系统评估了元学习在数据漂移条件下何时以及为何优于传统深度学习，为时间序列领域的自适应学习研究提供了SeisTask基准数据集，有助于推进该领域的研究进展。

Abstract: Across engineering and scientific domains, traditional deep learning (TDL) models perform well when training and test data share the same distribution. However, the dynamic nature of real-world data, broadly termed \textit{data shift}, renders TDL models prone to rapid performance degradation, requiring costly relabeling and inefficient retraining. Meta-learning, which enables models to adapt quickly to new data with few examples, offers a promising alternative for mitigating these challenges. Here, we systematically compare TDL with fine-tuning and optimization-based meta-learning algorithms to assess their ability to address data shift in time-series classification. We introduce a controlled, task-oriented seismic benchmark (SeisTask) and show that meta-learning typically achieves faster and more stable adaptation with reduced overfitting in data-scarce regimes and smaller model architectures. As data availability and model capacity increase, its advantages diminish, with TDL with fine-tuning performing comparably. Finally, we examine how task diversity influences meta-learning and find that alignment between training and test distributions, rather than diversity alone, drives performance gains. Overall, this work provides a systematic evaluation of when and why meta-learning outperforms TDL under data shift and contributes SeisTask as a benchmark for advancing adaptive learning research in time-series domains.

</details>


### [68] [Layer-Parallel Training for Transformers](https://arxiv.org/abs/2601.09026)
*Shuai Jiang,Marc Salvado,Eric C. Cyr,Alena Kopaničáková,Rolf Krause,Jacob B. Schroder*

Main category: cs.LG

TL;DR: 提出一种基于神经ODE的多层次层并行训练方法，通过并行时间算法加速transformer训练，在深度增加时显著提升并行可扩展性，但需处理梯度偏差问题以保持收敛性。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型规模不断增大，网络深度增加导致传统串行训练面临并行可扩展性瓶颈。需要开发新的训练方法来解决transformer模型在深度增加时的并行加速问题。

Method: 将transformer建模为神经ODE，应用多层次并行时间算法进行前向和反向传播训练。通过检测临界转换点，在接近最小值时切换到串行训练或提高层并行训练精度。

Result: 在BERT、GPT2、ViT和机器翻译架构上验证了并行加速效果，同时保持了与串行预训练相当的精度，且微调过程不受影响。

Conclusion: 提出的多层次层并行训练方法能够显著提升transformer模型的并行可扩展性，特别是在深度增加时，同时通过算法控制梯度偏差问题，保持了模型的收敛性和精度。

Abstract: We present a new training methodology for transformers using a multilevel, layer-parallel approach. Through a neural ODE formulation of transformers, our application of a multilevel parallel-in-time algorithm for the forward and backpropagation phases of training achieves parallel acceleration over the layer dimension. This dramatically enhances parallel scalability as the network depth increases, which is particularly useful for increasingly large foundational models. However, achieving this introduces errors that cause systematic bias in the gradients, which in turn reduces convergence when closer to the minima. We develop an algorithm to detect this critical transition and either switch to serial training or systematically increase the accuracy of layer-parallel training. Results, including BERT, GPT2, ViT, and machine translation architectures, demonstrate parallel-acceleration as well as accuracy commensurate with serial pre-training while fine-tuning is unaffected.

</details>


### [69] [SCaLE: Switching Cost aware Learning and Exploration](https://arxiv.org/abs/2601.09042)
*Neelkamal Bhuyan,Debankur Mukherjee,Adam Wierman*

Main category: cs.LG

TL;DR: 论文提出SCaLE算法，解决带无界度量移动成本的强盗在线凸优化问题，在随机环境中实现分布无关的次线性动态遗憾


<details>
  <summary>Details</summary>
Motivation: 解决强盗在线凸优化中无界度量移动成本的基本问题，特别是在高维动态二次命中成本和ℓ₂范数切换成本的噪声强盗反馈模型中

Method: 提出SCaLE算法，采用新颖的谱遗憾分析，分别量化特征值误差驱动的遗憾和特征基扰动驱动的遗憾

Result: 在一般随机环境中，SCaLE算法首次实现分布无关的次线性动态遗憾，无需命中成本结构知识；数值实验验证了算法的统计一致性

Conclusion: 该工作为带无界度量移动成本的强盗在线凸优化问题提供了首个理论保证的算法，谱分析方法为高维动态优化提供了新工具

Abstract: This work addresses the fundamental problem of unbounded metric movement costs in bandit online convex optimization, by considering high-dimensional dynamic quadratic hitting costs and $\ell_2$-norm switching costs in a noisy bandit feedback model. For a general class of stochastic environments, we provide the first algorithm SCaLE that provably achieves a distribution-agnostic sub-linear dynamic regret, without the knowledge of hitting cost structure. En-route, we present a novel spectral regret analysis that separately quantifies eigenvalue-error driven regret and eigenbasis-perturbation driven regret. Extensive numerical experiments, against online-learning baselines, corroborate our claims, and highlight statistical consistency of our algorithm.

</details>


### [70] [Deep Incomplete Multi-View Clustering via Hierarchical Imputation and Alignment](https://arxiv.org/abs/2601.09051)
*Yiming Du,Ziyu Wang,Jian Li,Rui Ning,Lusi Li*

Main category: cs.LG

TL;DR: DIMVC-HIA：一种新颖的深度不完整多视图聚类框架，通过分层插补和对齐机制，在视图缺失情况下实现优越的聚类性能。


<details>
  <summary>Details</summary>
Motivation: 不完整多视图聚类（IMVC）需要从部分观测的多视图数据中发现共享的聚类结构。核心挑战在于：1）准确插补缺失视图而不引入偏差；2）保持跨视图的语义一致性；3）维持聚类内的紧凑性。

Method: 提出DIMVC-HIA框架，包含四个关键组件：1）视图特定自编码器提取潜在特征，配合视图共享聚类预测器生成软聚类分配；2）分层插补模块：先基于跨视图对比相似性估计缺失聚类分配，再利用视图内、聚类内统计重建缺失特征；3）基于能量的语义对齐模块：通过最小化低能量聚类锚点周围的能量方差来促进聚类内紧凑性；4）对比分配对齐模块：增强跨视图一致性并鼓励自信、分离良好的聚类预测。

Result: 在基准测试上的实验表明，该框架在不同缺失水平下实现了优越的性能。

Conclusion: DIMVC-HIA通过分层插补和对齐机制有效解决了不完整多视图聚类的核心挑战，在视图缺失情况下实现了准确且鲁棒的聚类性能。

Abstract: Incomplete multi-view clustering (IMVC) aims to discover shared cluster structures from multi-view data with partial observations. The core challenges lie in accurately imputing missing views without introducing bias, while maintaining semantic consistency across views and compactness within clusters. To address these challenges, we propose DIMVC-HIA, a novel deep IMVC framework that integrates hierarchical imputation and alignment with four key components: (1) view-specific autoencoders for latent feature extraction, coupled with a view-shared clustering predictor to produce soft cluster assignments; (2) a hierarchical imputation module that first estimates missing cluster assignments based on cross-view contrastive similarity, and then reconstructs missing features using intra-view, intra-cluster statistics; (3) an energy-based semantic alignment module, which promotes intra-cluster compactness by minimizing energy variance around low-energy cluster anchors; and (4) a contrastive assignment alignment module, which enhances cross-view consistency and encourages confident, well-separated cluster predictions. Experiments on benchmarks demonstrate that our framework achieves superior performance under varying levels of missingness.

</details>


### [71] [Resolving Predictive Multiplicity for the Rashomon Set](https://arxiv.org/abs/2601.09071)
*Parian Haghighat,Hadis Anahideh,Cynthia Rudin*

Main category: cs.LG

TL;DR: 提出三种减少预测多重性（Rashomon集合中模型预测不一致）的方法：异常值校正、局部修补和成对调和，这些方法能降低预测分歧同时保持准确率。


<details>
  <summary>Details</summary>
Motivation: 在预测任务中，存在多个准确率相近但预测不一致的模型（Rashomon集合），这种预测多重性在高风险应用中会损害信任度，需要减少模型间的不一致性。

Method: 1. 异常值校正：识别并修正那些所有好模型都无法正确预测的异常值，这些异常值会导致局部区域预测方差增大；2. 局部修补：在测试点周围局部区域，检测并修正模型偏差；3. 成对调和：识别在测试点周围区域存在分歧的模型对，修改不一致的预测以减少偏差。三种方法可单独或组合使用。

Result: 在多个数据集上的实验表明，这些方法能有效降低预测分歧指标，同时保持有竞争力的准确率。调和后的预测可蒸馏为单个可解释模型用于实际部署。

Conclusion: 提出的三种方法能有效减少Rashomon集合中模型的预测不一致性，提高预测可靠性，为高风险应用提供更一致的预测结果。

Abstract: The existence of multiple, equally accurate models for a given predictive task leads to predictive multiplicity, where a ``Rashomon set'' of models achieve similar accuracy but diverges in their individual predictions. This inconsistency undermines trust in high-stakes applications where we want consistent predictions. We propose three approaches to reduce inconsistency among predictions for the members of the Rashomon set. The first approach is \textbf{outlier correction}. An outlier has a label that none of the good models are capable of predicting correctly. Outliers can cause the Rashomon set to have high variance predictions in a local area, so fixing them can lower variance. Our second approach is local patching. In a local region around a test point, models may disagree with each other because some of them are biased. We can detect and fix such biases using a validation set, which also reduces multiplicity. Our third approach is pairwise reconciliation, where we find pairs of models that disagree on a region around the test point. We modify predictions that disagree, making them less biased. These three approaches can be used together or separately, and they each have distinct advantages. The reconciled predictions can then be distilled into a single interpretable model for real-world deployment. In experiments across multiple datasets, our methods reduce disagreement metrics while maintaining competitive accuracy.

</details>


### [72] [Lean Clients, Full Accuracy: Hybrid Zeroth- and First-Order Split Federated Learning](https://arxiv.org/abs/2601.09076)
*Zhoubin Kou,Zihan Chen,Jing Yang,Cong Shen*

Main category: cs.LG

TL;DR: HERON-SFL 提出了一种混合优化框架，结合零阶优化在客户端和一阶优化在服务器端，显著降低客户端计算和内存需求，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 分割联邦学习中客户端计算资源受限，反向传播需要大量内存和计算成本，限制了边缘设备可支持的模型规模。需要更高效的客户端计算方案。

Method: 提出HERON-SFL混合优化框架：客户端使用零阶优化进行本地训练（通过扰动前向评估近似梯度），服务器端保留一阶优化。结合辅助网络减少通信开销。

Result: 理论证明收敛率与模型维度无关；实验在ResNet训练和语言模型微调任务中，匹配基准精度，客户端峰值内存降低64%，计算成本降低33%。

Conclusion: HERON-SFL显著扩展了资源受限设备上可训练或适配的模型范围，解决了分割联邦学习中客户端计算瓶颈问题。

Abstract: Split Federated Learning (SFL) enables collaborative training between resource-constrained edge devices and a compute-rich server. Communication overhead is a central issue in SFL and can be mitigated with auxiliary networks. Yet, the fundamental client-side computation challenge remains, as back-propagation requires substantial memory and computation costs, severely limiting the scale of models that edge devices can support. To enable more resource-efficient client computation and reduce the client-server communication, we propose HERON-SFL, a novel hybrid optimization framework that integrates zeroth-order (ZO) optimization for local client training while retaining first-order (FO) optimization on the server. With the assistance of auxiliary networks, ZO updates enable clients to approximate local gradients using perturbed forward-only evaluations per step, eliminating memory-intensive activation caching and avoiding explicit gradient computation in the traditional training process. Leveraging the low effective rank assumption, we theoretically prove that HERON-SFL's convergence rate is independent of model dimensionality, addressing a key scalability concern common to ZO algorithms. Empirically, on ResNet training and language model (LM) fine-tuning tasks, HERON-SFL matches benchmark accuracy while reducing client peak memory by up to 64% and client-side compute cost by up to 33% per step, substantially expanding the range of models that can be trained or adapted on resource-limited devices.

</details>


### [73] [SRT: Accelerating Reinforcement Learning via Speculative Rollout with Tree-Structured Cache](https://arxiv.org/abs/2601.09083)
*Chi-Chih Chang,Siqi Zhu,Zhichen Zeng,Haibin Lin,Jiaxuan You,Mohamed S. Abdelfattah,Ziheng Jiang,Xuehai Qian*

Main category: cs.LG

TL;DR: SRT是一种利用树状缓存加速语言模型强化学习的无模型方法，通过存储历史生成内容作为草稿模型进行推测解码，实现2.08倍加速


<details>
  <summary>Details</summary>
Motivation: 解决语言模型强化学习中策略rollout生成速度慢、计算成本高的问题，同时保持分布正确性

Method: 为每个提示构建树状缓存存储历史生成内容，作为草稿模型进行推测解码；在线更新缓存，利用GPU空闲时间进行前瞻生成

Result: 在PPO、GRPO、DAPO等标准RL流程和多轮对话中，减少生成和步骤延迟，降低单token推理成本，实现最高2.08倍实时加速

Conclusion: SRT是一种简单有效的加速方法，能在不牺牲分布正确性的前提下显著提升语言模型强化学习的训练效率

Abstract: We present Speculative Rollout with Tree-Structured Cache (SRT), a simple, model-free approach to accelerate on-policy reinforcement learning (RL) for language models without sacrificing distributional correctness. SRT exploits the empirical similarity of rollouts for the same prompt across training steps by storing previously generated continuations in a per-prompt tree-structured cache. During generation, the current policy uses this tree as the draft model for performing speculative decoding. To keep the cache fresh and improve draft model quality, SRT updates trees online from ongoing rollouts and proactively performs run-ahead generation during idle GPU bubbles. Integrated into standard RL pipelines (\textit{e.g.}, PPO, GRPO and DAPO) and multi-turn settings, SRT consistently reduces generation and step latency and lowers per-token inference cost, achieving up to 2.08x wall-clock time speedup during rollout.

</details>


### [74] [MMR-GRPO: Accelerating GRPO-Style Training through Diversity-Aware Reward Reweighting](https://arxiv.org/abs/2601.09085)
*Kangda Wei,Ruihong Huang*

Main category: cs.LG

TL;DR: MMR-GRPO通过集成最大边际相关性来基于完成多样性重新加权奖励，减少训练步骤47.9%和训练时间70.2%，同时保持性能


<details>
  <summary>Details</summary>
Motivation: GRPO训练数学推理模型需要每个提示多个完成，计算成本高。虽然最近工作减少了达到峰值性能所需的训练步骤，但每步成本增加导致总体训练时间不变甚至增加

Method: 提出MMR-GRPO，集成最大边际相关性（MMR）基于完成多样性重新加权奖励。核心洞察是语义冗余的完成贡献有限的学习信号，优先考虑多样化的解决方案能产生更多信息化的更新并加速收敛

Result: 在三个模型规模（1.5B、7B、8B）、三个GRPO变体和五个数学推理基准上的广泛评估显示，MMR-GRPO实现可比的峰值性能，同时平均需要减少47.9%的训练步骤和70.2%的训练时间

Conclusion: MMR-GRPO通过优先考虑多样化的解决方案显著加速GRPO训练，减少计算成本同时保持性能，这些收益在模型、方法和基准测试中保持一致

Abstract: Group Relative Policy Optimization (GRPO) has become a standard approach for training mathematical reasoning models; however, its reliance on multiple completions per prompt makes training computationally expensive. Although recent work has reduced the number of training steps required to reach peak performance, the overall wall-clock training time often remains unchanged or even increases due to higher per-step cost. We propose MMR-GRPO, which integrates Maximal Marginal Relevance to reweigh rewards based on completion diversity. Our key insight is that semantically redundant completions contribute limited marginal learning signal; prioritizing diverse solutions yields more informative updates and accelerates convergence. Extensive evaluations across three model sizes (1.5B, 7B, 8B), three GRPO variants, and five mathematical reasoning benchmarks show that MMR-GRPO achieves comparable peak performance while requiring on average 47.9% fewer training steps and 70.2% less wall-clock time. These gains are consistent across models, methods, and benchmarks. We will release our code, trained models, and experimental protocols.

</details>


### [75] [Distribution-Aligned Sequence Distillation for Superior Long-CoT Reasoning](https://arxiv.org/abs/2601.09088)
*Shaotian Yan,Kaiyuan Liu,Chen Shen,Bing Wang,Sinan Fan,Jun Zhang,Yue Wu,Zheng Wang,Jieping Ye*

Main category: cs.LG

TL;DR: DASD-4B-Thinking是一个轻量级但能力强大的开源推理模型，在数学、科学推理和代码生成基准测试中达到SOTA性能，仅使用44.8万训练样本，远少于现有开源模型。


<details>
  <summary>Details</summary>
Motivation: 当前基于教师生成响应的SFT蒸馏方法虽然效率高，但主要从SFT视角出发，忽略了蒸馏的核心原则：让学生模型学习教师的完整输出分布以继承其泛化能力。现有方法存在三个关键局限：教师序列级分布表示不足、教师输出分布与学生学习能力不匹配、教师强制训练与自回归推理之间的暴露偏差。

Method: 提出增强的序列级蒸馏训练流程，通过方法创新解决现有蒸馏方法的三个局限。具体包括改进教师分布表示、调整教师输出以适应学生学习能力、缓解暴露偏差问题，从而建立更有效的师生交互机制。

Result: DASD-4B-Thinking在可比规模的开源模型中达到SOTA性能，在数学、科学推理和代码生成基准测试中表现出色，甚至超越了一些更大的模型。仅使用44.8万训练样本就获得竞争性结果，比大多数现有开源工作少一个数量级。

Conclusion: 通过重新审视序列级蒸馏范式并解决其核心局限，提出的增强蒸馏方法能够用极少的训练数据训练出高性能的轻量级推理模型。该方法有效利用了蒸馏的本质，建立了更好的师生交互机制，为社区提供了高质量的开源模型和训练数据集。

Abstract: In this report, we introduce DASD-4B-Thinking, a lightweight yet highly capable, fully open-source reasoning model. It achieves SOTA performance among open-source models of comparable scale across challenging benchmarks in mathematics, scientific reasoning, and code generation -- even outperforming several larger models. We begin by critically reexamining a widely adopted distillation paradigm in the community: SFT on teacher-generated responses, also known as sequence-level distillation. Although a series of recent works following this scheme have demonstrated remarkable efficiency and strong empirical performance, they are primarily grounded in the SFT perspective. Consequently, these approaches focus predominantly on designing heuristic rules for SFT data filtering, while largely overlooking the core principle of distillation itself -- enabling the student model to learn the teacher's full output distribution so as to inherit its generalization capability. Specifically, we identify three critical limitations in current practice: i) Inadequate representation of the teacher's sequence-level distribution; ii) Misalignment between the teacher's output distribution and the student's learning capacity; and iii) Exposure bias arising from teacher-forced training versus autoregressive inference. In summary, these shortcomings reflect a systemic absence of explicit teacher-student interaction throughout the distillation process, leaving the essence of distillation underexploited. To address these issues, we propose several methodological innovations that collectively form an enhanced sequence-level distillation training pipeline. Remarkably, DASD-4B-Thinking obtains competitive results using only 448K training samples -- an order of magnitude fewer than those employed by most existing open-source efforts. To support community research, we publicly release our models and the training dataset.

</details>


### [76] [Hidden States as Early Signals: Step-level Trace Evaluation and Pruning for Efficient Test-Time Scaling](https://arxiv.org/abs/2601.09093)
*Zhixiang Liang,Beichen Huang,Zheng Wang,Minjia Zhang*

Main category: cs.LG

TL;DR: STEP：基于步骤级评估和剪枝的推理加速框架，通过隐藏状态评估推理步骤质量，动态剪枝低质量推理轨迹，在保持准确性的同时显著降低延迟


<details>
  <summary>Details</summary>
Motivation: 大语言模型通过生成多个推理轨迹来增强推理能力，但长推理轨迹和多采样导致计算量大、延迟高。现有基于相似性或置信度的剪枝方法无法可靠评估轨迹质量，需要更有效的加速方案

Method: 提出STEP框架：1) 训练轻量级步骤评分器，利用隐藏状态评估推理步骤质量；2) 设计GPU内存感知剪枝策略，在KV缓存饱和时动态剪枝低质量轨迹；3) 在推理过程中实时评估和剪枝

Result: 在多个挑战性推理基准测试中，STEP相比self-consistency方法平均减少45%-70%的端到端推理延迟，同时还能提高推理准确性

Conclusion: STEP通过步骤级评估和动态剪枝有效解决了多轨迹推理的计算效率问题，在显著降低延迟的同时保持甚至提升推理准确性，为LLM推理加速提供了新思路

Abstract: Large Language Models (LLMs) can enhance reasoning capabilities through test-time scaling by generating multiple traces. However, the combination of lengthy reasoning traces with multiple sampling introduces substantial computation and high end-to-end latency. Prior work on accelerating this process has relied on similarity-based or confidence-based pruning, but these signals do not reliably indicate trace quality. To address these limitations, we propose STEP: Step-level Trace Evaluation and Pruning, a novel pruning framework that evaluates reasoning steps using hidden states and dynamically prunes unpromising traces during generation. We train a lightweight step scorer to estimate trace quality, and design a GPU memory-aware pruning strategy that triggers pruning as the GPU memory is saturated by KV cache to reduce end-to-end latency. Experiments across challenging reasoning benchmarks demonstrate that STEP reduces end-to-end inference latency by 45%-70% on average compared to self-consistency while also improving reasoning accuracy. Our code is released at: https://github.com/Supercomputing-System-AI-Lab/STEP

</details>


### [77] [Comparative Assessment of Concrete Compressive Strength Prediction at Industry Scale Using Embedding-based Neural Networks, Transformers, and Traditional Machine Learning Approaches](https://arxiv.org/abs/2601.09096)
*Md Asiful Islam,Md Ahmed Al Muzaddid,Afia Jahin Prema,Sreenath Reddy Vuske*

Main category: cs.LG

TL;DR: 本研究利用约7万条抗压强度测试记录，评估了多种预测方法，发现基于嵌入的神经网络在预测混凝土28天抗压强度方面表现最佳，平均误差约2.5%，接近常规实验室测试的变异水平。


<details>
  <summary>Details</summary>
Motivation: 混凝土作为全球最广泛使用的建筑材料，其抗压强度预测因材料异质性、配合比变化以及对现场和环境条件的敏感性而具有挑战性。人工智能的进展为支持施工质量控制中的自动化决策提供了数据驱动建模框架的可能性。

Method: 使用包含约70,000条抗压强度测试记录的工业规模数据集，评估和比较了多种预测方法：线性回归、决策树、随机森林、基于Transformer的神经网络和基于嵌入的神经网络。模型包含了水灰比、胶凝材料含量、坍落度、含气量、温度和浇筑条件等关键配合比设计和施工变量。

Result: 基于嵌入的神经网络在预测28天抗压强度方面表现最佳，平均误差约为2.5%。这一精度水平与常规实验室测试的变异相当，优于传统机器学习方法和基于Transformer的模型。

Conclusion: 基于嵌入的学习框架具有在大规模施工运营中实现自动化、数据驱动的质量控制和决策支持的潜力，其预测精度接近实验室测试的可靠性水平。

Abstract: Concrete is the most widely used construction material worldwide; however, reliable prediction of compressive strength remains challenging due to material heterogeneity, variable mix proportions, and sensitivity to field and environmental conditions. Recent advances in artificial intelligence enable data-driven modeling frameworks capable of supporting automated decision-making in construction quality control. This study leverages an industry-scale dataset consisting of approximately 70,000 compressive strength test records to evaluate and compare multiple predictive approaches, including linear regression, decision trees, random forests, transformer-based neural networks, and embedding-based neural networks. The models incorporate key mixture design and placement variables such as water cement ratio, cementitious material content, slump, air content, temperature, and placement conditions. Results indicate that the embedding-based neural network consistently outperforms traditional machine learning and transformer-based models, achieving a mean 28-day prediction error of approximately 2.5%. This level of accuracy is comparable to routine laboratory testing variability, demonstrating the potential of embedding-based learning frameworks to enable automated, data-driven quality control and decision support in large-scale construction operations.

</details>


### [78] [Enhancing Imbalanced Electrocardiogram Classification: A Novel Approach Integrating Data Augmentation through Wavelet Transform and Interclass Fusion](https://arxiv.org/abs/2601.09103)
*Haijian Shao,Wei Liu,Xing Deng,Daze Lu*

Main category: cs.LG

TL;DR: 提出基于小波变换特征融合的ECG分类方法，同时解决类别不平衡和噪声问题，在CPSC 2018数据集上取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 心电图数据存在类别不平衡问题（某些心脏疾病样本稀少）和噪声干扰，这限制了深度学习ECG分类算法的效果和鲁棒性。

Method: 采用小波变换进行特征融合，特别是基于小波变换的类间融合，生成训练和测试特征库，然后将原始数据与特征库合并以平衡数据集。

Result: 在CPSC 2018数据集上，对Normal、AF、I-AVB、LBBB、RBBB、PAC、PVC、STD、STE等类别的识别准确率分别达到99%、98%、97%、98%、96%、92%、93%，平均准确率在92%-98%之间。

Conclusion: 提出的数据融合方法在ECG分类准确率上超越了已知算法，有效解决了类别不平衡和噪声问题，显著提升了心电图自动诊断的性能。

Abstract: Imbalanced electrocardiogram (ECG) data hampers the efficacy and resilience of algorithms in the automated processing and interpretation of cardiovascular diagnostic information, which in turn impedes deep learning-based ECG classification. Notably, certain cardiac conditions that are infrequently encountered are disproportionately underrepresented in these datasets. Although algorithmic generation and oversampling of specific ECG signal types can mitigate class skew, there is a lack of consensus regarding the effectiveness of such techniques in ECG classification. Furthermore, the methodologies and scenarios of ECG acquisition introduce noise, further complicating the processing of ECG data. This paper presents a significantly enhanced ECG classifier that simultaneously addresses both class imbalance and noise-related challenges in ECG analysis, as observed in the CPSC 2018 dataset. Specifically, we propose the application of feature fusion based on the wavelet transform, with a focus on wavelet transform-based interclass fusion, to generate the training feature library and the test set feature library. Subsequently, the original training and test data are amalgamated with their respective feature databases, resulting in more balanced training and test datasets. Employing this approach, our ECG model achieves recognition accuracies of up to 99%, 98%, 97%, 98%, 96%, 92%, and 93% for Normal, AF, I-AVB, LBBB, RBBB, PAC, PVC, STD, and STE, respectively. Furthermore, the average recognition accuracy for these categories ranges between 92\% and 98\%. Notably, our proposed data fusion methodology surpasses any known algorithms in terms of ECG classification accuracy in the CPSC 2018 dataset.

</details>


### [79] [EvasionBench: Detecting Evasive Answers in Financial Q&A via Multi-Model Consensus and LLM-as-Judge](https://arxiv.org/abs/2601.09142)
*Shijian Ma,Yan Lin,Yi Yang*

Main category: cs.LG

TL;DR: 该论文提出了EvasionBench，一个用于检测财报电话会议中规避性回答的大规模基准数据集，包含30,000个训练样本和1,000个人工标注测试样本。通过多模型标注框架挖掘边界案例，训练出的Eva-4B模型达到81.3%准确率。


<details>
  <summary>Details</summary>
Motivation: 检测财报电话会议中的规避性回答对金融透明度至关重要，但缺乏大规模基准数据集阻碍了研究进展。

Method: 提出多模型标注框架：利用前沿LLM之间的分歧识别困难样本，通过法官模型解决标注冲突，挖掘边界案例用于训练。

Result: 该方法比单模型蒸馏性能提升2.4%，法官解决的样本提高了泛化能力。训练的Eva-4B模型（40亿参数）达到81.3%准确率，比基础模型提升25个百分点，接近前沿LLM性能但推理成本低得多。

Conclusion: 分歧挖掘作为隐式正则化有效提升模型性能，EvasionBench为检测规避性回答提供了高质量基准，Eva-4B模型在性能和效率间取得良好平衡。

Abstract: Detecting evasive answers in earnings calls is critical for financial transparency, yet progress is hindered by the lack of large-scale benchmarks. We introduce EvasionBench, comprising 30,000 training samples and 1,000 human-annotated test samples (Cohen's Kappa 0.835) across three evasion levels. Our key contribution is a multi-model annotation framework leveraging a core insight: disagreement between frontier LLMs signals hard examples most valuable for training. We mine boundary cases where two strong annotators conflict, using a judge to resolve labels. This approach outperforms single-model distillation by 2.4 percent, with judge-resolved samples improving generalization despite higher training loss (0.421 vs 0.393) - evidence that disagreement mining acts as implicit regularization. Our trained model Eva-4B (4B parameters) achieves 81.3 percent accuracy, outperforming its base by 25 percentage points and approaching frontier LLM performance at a fraction of inference cost.

</details>


### [80] [Interpretable Probability Estimation with LLMs via Shapley Reconstruction](https://arxiv.org/abs/2601.09151)
*Yang Nan,Qihao Wen,Jiahao Wang,Pengfei He,Ravi Tandon,Yong Ge,Han Xu*

Main category: cs.LG

TL;DR: PRISM框架通过Shapley值分解LLM预测，量化各输入因素的边际贡献，重构校准的概率估计，提高透明度和准确性。


<details>
  <summary>Details</summary>
Motivation: LLMs在概率估计方面有潜力，但直接提示存在输出噪声大、预测过程不透明的问题，需要提高透明度和精度。

Method: 提出PRISM框架：使用Shapley值量化每个输入因素的边际贡献，然后聚合这些因素级贡献来重构校准的最终估计。

Result: PRISM在金融、医疗、农业等多个领域优于直接提示和其他基线方法，提高了预测准确性，并提供透明的预测管道。

Conclusion: PRISM通过Shapley值分解为LLM概率估计带来了透明度和精度，有助于建立对LLM决策支持系统的信任。

Abstract: Large Language Models (LLMs) demonstrate potential to estimate the probability of uncertain events, by leveraging their extensive knowledge and reasoning capabilities. This ability can be applied to support intelligent decision-making across diverse fields, such as financial forecasting and preventive healthcare. However, directly prompting LLMs for probability estimation faces significant challenges: their outputs are often noisy, and the underlying predicting process is opaque. In this paper, we propose PRISM: Probability Reconstruction via Shapley Measures, a framework that brings transparency and precision to LLM-based probability estimation. PRISM decomposes an LLM's prediction by quantifying the marginal contribution of each input factor using Shapley values. These factor-level contributions are then aggregated to reconstruct a calibrated final estimate. In our experiments, we demonstrate PRISM improves predictive accuracy over direct prompting and other baselines, across multiple domains including finance, healthcare, and agriculture. Beyond performance, PRISM provides a transparent prediction pipeline: our case studies visualize how individual factors shape the final estimate, helping build trust in LLM-based decision support systems.

</details>


### [81] [KTCF: Actionable Recourse in Knowledge Tracing via Counterfactual Explanations for Education](https://arxiv.org/abs/2601.09156)
*Woojin Kim,Changkwon Lee,Hyeoncheol Kim*

Main category: cs.LG

TL;DR: 该论文提出KTCF方法，为知识追踪生成反事实解释，并将其转化为教育指导序列，以提升AI在教育中的可解释性和实用性。


<details>
  <summary>Details</summary>
Motivation: 利用人工智能改善教学需要更好的适应性和可扩展性。知识追踪在教育中具有优越性能和应用潜力，但需要可解释的AI方法。反事实解释具有可操作性、因果性和本地性，易于非专业的教育利益相关者理解。

Method: 提出KTCF方法，为知识追踪生成反事实解释，考虑知识概念关系，并通过后处理方案将反事实解释转化为教育指导序列。

Result: 在大规模教育数据集上实验显示，KTCF方法在各项指标上比现有方法提升5.7%到34%，表现出优越且稳健的性能。定性评估表明，生成的教育指导有助于减轻学习负担。

Conclusion: 反事实解释有潜力推动AI在教育中的负责任和实际应用。未来可解释AI研究应基于教育基础概念化，并开发以利益相关者为中心的方法。

Abstract: Using Artificial Intelligence to improve teaching and learning benefits greater adaptivity and scalability in education. Knowledge Tracing (KT) is recognized for student modeling task due to its superior performance and application potential in education. To this end, we conceptualize and investigate counterfactual explanation as the connection from XAI for KT to education. Counterfactual explanations offer actionable recourse, are inherently causal and local, and easy for educational stakeholders to understand who are often non-experts. We propose KTCF, a counterfactual explanation generation method for KT that accounts for knowledge concept relationships, and a post-processing scheme that converts a counterfactual explanation into a sequence of educational instructions. We experiment on a large-scale educational dataset and show our KTCF method achieves superior and robust performance over existing methods, with improvements ranging from 5.7% to 34% across metrics. Additionally, we provide a qualitative evaluation of our post-processing scheme, demonstrating that the resulting educational instructions help in reducing large study burden. We show that counterfactuals have the potential to advance the responsible and practical use of AI in education. Future works on XAI for KT may benefit from educationally grounded conceptualization and developing stakeholder-centered methods.

</details>


### [82] [Efficient Clustering in Stochastic Bandits](https://arxiv.org/abs/2601.09162)
*G Dhinesh Chandran,Kota Srinivas Reddy,Srikrishna Bhashyam*

Main category: cs.LG

TL;DR: 提出EBC和EBC-H两种高效的赌博机聚类算法，在固定置信度设置下实现渐近最优，相比现有方法显著降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有赌博机聚类算法在固定置信度设置下存在两个主要问题：1) 仅适用于高斯分布假设，限制了应用范围；2) 每次采样都需要求解完整优化问题，计算成本高昂。

Method: 提出EBC算法，采用向量参数化分布模型，每次采样时只向最优值迈进一步而非求解完整优化问题；进一步提出EBC-H启发式变体，利用停止规则中的计算量进行臂选择，进一步简化采样规则。

Result: EBC和EBC-H在保持渐近最优性的同时显著提升计算效率；在合成和真实数据集上的实验表明，相比现有方法有性能提升；EBC的渐近最优性在合成数据集上得到验证。

Conclusion: EBC和EBC-H算法在固定置信度赌博机聚类问题中实现了计算效率与渐近最优性的平衡，扩展了适用分布范围，为实际应用提供了高效解决方案。

Abstract: We study the Bandit Clustering (BC) problem under the fixed confidence setting, where the objective is to group a collection of data sequences (arms) into clusters through sequential sampling from adaptively selected arms at each time step while ensuring a fixed error probability at the stopping time. We consider a setting where arms in a cluster may have different distributions. Unlike existing results in this setting, which assume Gaussian-distributed arms, we study a broader class of vector-parametric distributions that satisfy mild regularity conditions. Existing asymptotically optimal BC algorithms require solving an optimization problem as part of their sampling rule at each step, which is computationally costly. We propose an Efficient Bandit Clustering algorithm (EBC), which, instead of solving the full optimization problem, takes a single step toward the optimal value at each time step, making it computationally efficient while remaining asymptotically optimal. We also propose a heuristic variant of EBC, called EBC-H, which further simplifies the sampling rule, with arm selection based on quantities computed as part of the stopping rule. We highlight the computational efficiency of EBC and EBC-H by comparing their per-sample run time with that of existing algorithms. The asymptotic optimality of EBC is supported through simulations on the synthetic datasets. Through simulations on both synthetic and real-world datasets, we show the performance gain of EBC and EBC-H over existing approaches.

</details>


### [83] [Multi-Teacher Ensemble Distillation: A Mathematical Framework for Probability-Domain Knowledge Aggregation](https://arxiv.org/abs/2601.09165)
*Aaron R. Flouro,Shawn P. Chadwick*

Main category: cs.LG

TL;DR: 提出基于概率域蒸馏的算子理论框架，通过五个公理定义多教师知识聚合算子，证明存在多种满足公理的聚合机制，并建立理论保证。


<details>
  <summary>Details</summary>
Motivation: 为多教师集成知识蒸馏提供理论基础，避免规定具体聚合公式，而是建立公理化框架，为从多样化前沿模型进行知识蒸馏提供理论支撑。

Method: 基于Sparse-KD的概率域蒸馏框架，发展算子理论框架，定义五个核心公理（凸性、正性、连续性、权重单调性、温度相干性）来约束有效的知识聚合算子。

Result: 证明了满足这些公理的算子族存在且不唯一，建立了算子无关的理论保证：多教师聚合能减少随机方差和系统性监督偏差，提供Jensen型边界、对数损失保证和安全衰减特性。

Conclusion: 该框架为从多样化前沿模型进行多教师蒸馏提供了理论基础，同时允许多种有效的实现策略，为知识蒸馏的聚合机制提供了公理化的理论支撑。

Abstract: Building on the probability-domain distillation framework of Sparse-KD, we develop an axiomatic, operator-theoretic framework for multi-teacher ensemble knowledge distillation. Rather than prescribing a specific aggregation formula, we define five core axioms governing valid knowledge aggregation operators, encompassing convexity, positivity, continuity, weight monotonicity, and temperature coherence. We prove the existence and non-uniqueness of operator families satisfying these axioms, establishing that multiple distinct aggregation mechanisms conform to the same foundational principles.
  Within this framework, we establish operator-agnostic guarantees showing that multi-teacher aggregation reduces both stochastic variance and systematic supervisory bias under heterogeneous teachers, while providing Jensen-type bounds, log-loss guarantees, and safety attenuation properties. For aggregation operators linear in teacher weights, we further establish classical ensemble variance-reduction results under standard independence assumptions, with extensions to correlated-error regimes. The framework provides theoretical grounding for multi-teacher distillation from diverse frontier models while admitting multiple valid implementation strategies.

</details>


### [84] [DP-FEDSOFIM: Differentially Private Federated Stochastic Optimization using Regularized Fisher Information Matrix](https://arxiv.org/abs/2601.09166)
*Sidhant R. Nair,Tanmay Sen,Mrinmay Sen*

Main category: cs.LG

TL;DR: DP-FedSOFIM：一种服务器端二阶优化框架，通过Fisher信息矩阵作为自然梯度预处理器，在差分隐私联邦学习中实现O(d)内存和计算复杂度，显著提升收敛速度。


<details>
  <summary>Details</summary>
Motivation: 差分隐私联邦学习在严格隐私预算下收敛缓慢，现有二阶方法需要O(d²)内存，不适用于高维模型。需要一种既保持二阶优化优势又降低内存需求的方法。

Method: 提出DP-FedSOFIM框架，利用Fisher信息矩阵作为自然梯度预处理器，通过Sherman-Morrison公式实现高效矩阵求逆，客户端仅需O(d)内存，服务器端进行预处理器更新。

Result: 在CIFAR-10数据集上，DP-FedSOFIM在多个隐私机制下相比一阶基线方法获得更优的测试精度，同时通过后处理定理保持(ε,δ)-差分隐私。

Conclusion: DP-FedSOFIM成功解决了差分隐私联邦学习中二阶方法内存开销大的问题，在保持隐私保护的同时显著提升了收敛性能，为高维模型的实际部署提供了可行方案。

Abstract: Differentially private federated learning (DP-FL) suffers from slow convergence under tight privacy budgets due to the overwhelming noise introduced to preserve privacy. While adaptive optimizers can accelerate convergence, existing second-order methods such as DP-FedNew require O(d^2) memory at each client to maintain local feature covariance matrices, making them impractical for high-dimensional models. We propose DP-FedSOFIM, a server-side second-order optimization framework that leverages the Fisher Information Matrix (FIM) as a natural gradient preconditioner while requiring only O(d) memory per client. By employing the Sherman-Morrison formula for efficient matrix inversion, DP-FedSOFIM achieves O(d) computational complexity per round while maintaining the convergence benefits of second-order methods. Our analysis proves that the server-side preconditioning preserves (epsilon, delta)-differential privacy through the post-processing theorem. Empirical evaluation on CIFAR-10 demonstrates that DP-FedSOFIM achieves superior test accuracy compared to first-order baselines across multiple privacy regimes.

</details>


### [85] [BalDRO: A Distributionally Robust Optimization based Framework for Large Language Model Unlearning](https://arxiv.org/abs/2601.09172)
*Pengyang Shao,Naixin Zhai,Lei Chen,Yonghui Yang,Fengbin Zhu,Xun Yang,Meng Wang*

Main category: cs.LG

TL;DR: BalDRO：一种平衡的LLM遗忘框架，通过min-sup过程解决遗忘集样本不平衡问题，包含离散和连续两种变体，在TOFU和MUSE数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着LLM日益影响在线内容，从训练好的LLM中移除特定信息（遗忘）对网络治理至关重要。主要挑战在于遗忘集中的样本不平衡：不同样本的遗忘难度差异巨大，导致异步遗忘——有些知识删除不足，有些则过度遗忘。

Method: 提出BalDRO框架，将遗忘建模为min-sup过程：内层步骤识别最坏情况数据分布（强调难遗忘样本），外层步骤在该分布下更新模型参数。实现两种高效变体：BalDRO-G（基于离散GroupDRO，关注高损失子集）和BalDRO-DV（基于连续Donsker-Varadhan对偶方法，支持平滑自适应加权）。

Result: 在TOFU和MUSE数据集上的实验表明，BalDRO在遗忘质量和模型效用方面显著优于现有方法。

Conclusion: BalDRO有效解决了LLM遗忘中的样本不平衡问题，通过平衡的遗忘过程提升了遗忘效果和模型性能，为LLM遗忘提供了新框架。

Abstract: As Large Language Models (LLMs) increasingly shape online content, removing targeted information from well-trained LLMs (also known as LLM unlearning) has become critical for web governance. A key challenge lies in sample-wise imbalance within the forget set: different samples exhibit widely varying unlearning difficulty, leading to asynchronous forgetting where some knowledge remains insufficiently erased while others become over-forgotten. To address this, we propose BalDRO, a novel and efficient framework for balanced LLM unlearning. BalDRO formulates unlearning as a min-sup process: an inner step identifies a worst-case data distribution that emphasizes hard-to-unlearn samples, while an outer step updates model parameters under this distribution. We instantiate BalDRO via two efficient variants: BalDRO-G, a discrete GroupDRO-based approximation focusing on high-loss subsets, and BalDRO-DV, a continuous Donsker-Varadhan dual method enabling smooth adaptive weighting within standard training pipelines. Experiments on TOFU and MUSE show that BalDRO significantly improves both forgetting quality and model utility over existing methods, and we release code for reproducibility.

</details>


### [86] [Geometric Stability: The Missing Axis of Representations](https://arxiv.org/abs/2601.09173)
*Prashant C. Raju*

Main category: cs.LG

TL;DR: 论文提出几何稳定性作为表示分析的新维度，与相似性正交，用于量化表示在扰动下的鲁棒性，并开发了Shesha框架进行测量。


<details>
  <summary>Details</summary>
Motivation: 现有表示分析主要关注相似性（表示与外部参考的对齐程度），但相似性只能揭示表示了什么，不能评估表示结构的鲁棒性。需要一个新的维度来量化表示在扰动下保持几何结构的能力。

Method: 提出几何稳定性概念，开发Shesha框架进行测量。在七个领域的2,463个配置中进行实验，比较稳定性与相似性的关系，分析两者在机制上的差异（如移除主成分后的表现）。

Result: 稳定性与相似性在经验上几乎不相关（ρ≈0.01），机制上不同：相似性在移除主成分后崩溃，而稳定性对精细流形结构保持敏感。稳定性在安全监控中比CKA敏感近2倍，能过滤非功能性噪声；在可控性预测中与线性可操纵性高度相关（ρ=0.89-0.96）；在模型选择中揭示迁移优化带来的几何代价。

Conclusion: 几何稳定性作为相似性的必要补充，通过量化系统如何可靠地保持结构，为生物和计算系统中的表示审计提供了新工具，在安全监控、可控性预测、模型选择等领域具有实际应用价值。

Abstract: Analysis of learned representations has a blind spot: it focuses on $similarity$, measuring how closely embeddings align with external references, but similarity reveals only what is represented, not whether that structure is robust. We introduce $geometric$ $stability$, a distinct dimension that quantifies how reliably representational geometry holds under perturbation, and present $Shesha$, a framework for measuring it. Across 2,463 configurations in seven domains, we show that stability and similarity are empirically uncorrelated ($ρ\approx 0.01$) and mechanistically distinct: similarity metrics collapse after removing the top principal components, while stability retains sensitivity to fine-grained manifold structure. This distinction yields actionable insights: for safety monitoring, stability acts as a functional geometric canary, detecting structural drift nearly 2$\times$ more sensitively than CKA while filtering out the non-functional noise that triggers false alarms in rigid distance metrics; for controllability, supervised stability predicts linear steerability ($ρ= 0.89$-$0.96$); for model selection, stability dissociates from transferability, revealing a geometric tax that transfer optimization incurs. Beyond machine learning, stability predicts CRISPR perturbation coherence and neural-behavioral coupling. By quantifying $how$ $reliably$ systems maintain structure, geometric stability provides a necessary complement to similarity for auditing representations across biological and computational systems.

</details>


### [87] [$D^2Prune$: Sparsifying Large Language Models via Dual Taylor Expansion and Attention Distribution Awareness](https://arxiv.org/abs/2601.09176)
*Lang Xiong,Ning Liu,Ao Ren,Yuheng Bai,Haining Fang,BinYan Zhang,Zhe Jiang,Yujuan Tan,Duo Liu*

Main category: cs.LG

TL;DR: D²Prune：一种针对大语言模型的新型剪枝方法，通过双泰勒展开联合建模权重和激活扰动进行精确误差估计，并采用注意力感知的动态更新策略保留注意力长尾分布，在多种LLM和ViT模型上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有剪枝方法存在两个关键局限：1）忽略校准数据和测试数据之间的激活分布偏移，导致误差估计不准确；2）忽视注意力模块中激活的长尾分布特性。这些限制影响了剪枝效果和模型性能。

Method: 提出D²Prune方法：1）使用双泰勒展开联合建模权重和激活扰动，实现精确误差估计，指导剪枝掩码选择和权重更新；2）设计注意力感知的动态更新策略，通过联合最小化注意力分布的KL散度和重构误差来保留长尾注意力模式。

Result: 实验表明D²Prune在多种LLM（OPT-125M、LLaMA2/3、Qwen3）上持续优于最先进方法。注意力动态更新机制也很好地推广到ViT视觉模型（如DeiT），在ImageNet-1K上取得了优越的准确率。

Conclusion: D²Prune通过解决现有剪枝方法的两个关键局限，实现了更精确的误差估计和更好的注意力模式保留，为LLM的高效部署提供了有效的压缩解决方案，并具有良好的跨模态泛化能力。

Abstract: Large language models (LLMs) face significant deployment challenges due to their massive computational demands. % While pruning offers a promising compression solution, existing methods suffer from two critical limitations: (1) They neglect activation distribution shifts between calibration data and test data, resulting in inaccurate error estimations; (2) They overlook the long-tail distribution characteristics of activations in the attention module. To address these limitations, this paper proposes a novel pruning method, $D^2Prune$. First, we propose a dual Taylor expansion-based method that jointly models weight and activation perturbations for precise error estimation, leading to precise pruning mask selection and weight updating and facilitating error minimization during pruning. % Second, we propose an attention-aware dynamic update strategy that preserves the long-tail attention pattern by jointly minimizing the KL divergence of attention distributions and the reconstruction error. Extensive experiments show that $D^2Prune$ consistently outperforms SOTA methods across various LLMs (e.g., OPT-125M, LLaMA2/3, and Qwen3). Moreover, the dynamic attention update mechanism also generalizes well to ViT-based vision models like DeiT, achieving superior accuracy on ImageNet-1K.

</details>


### [88] [From Hawkes Processes to Attention: Time-Modulated Mechanisms for Event Sequences](https://arxiv.org/abs/2601.09220)
*Xinzi Tan,Kejian Zhang,Junhan Yu,Doudou Zhou*

Main category: cs.LG

TL;DR: 提出Hawkes Attention，一种基于多元Hawkes过程理论的新型注意力机制，用于标记时间点过程，通过可学习的类型特定神经核来统一事件时间和内容交互。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的方法主要通过位置编码注入时间信息，依赖共享或参数化衰减结构，限制了捕捉异构和类型特定时间效应的能力。

Method: 从多元Hawkes过程理论推导出Hawkes Attention，使用可学习的类型特定神经核来调制查询、键和值投影，替代传统注意力中的相应部分。

Result: 实验结果显示该方法相比基线取得了更好的性能，除了通用MTPP外，该注意力机制也能轻松应用于特定时间结构如时间序列预测。

Conclusion: Hawkes Attention能够统一事件时间和内容交互，从数据中学习时间相关行为和类型特定激发模式，为MTPP提供了更有效的建模方法。

Abstract: Marked Temporal Point Processes (MTPPs) arise naturally in medical, social, commercial, and financial domains. However, existing Transformer-based methods mostly inject temporal information only via positional encodings, relying on shared or parametric decay structures, which limits their ability to capture heterogeneous and type-specific temporal effects. Inspired by this observation, we derive a novel attention operator called Hawkes Attention from the multivariate Hawkes process theory for MTPP, using learnable per-type neural kernels to modulate query, key and value projections, thereby replacing the corresponding parts in the traditional attention. Benefited from the design, Hawkes Attention unifies event timing and content interaction, learning both the time-relevant behavior and type-specific excitation patterns from the data. The experimental results show that our method achieves better performance compared to the baselines. In addition to the general MTPP, our attention mechanism can also be easily applied to specific temporal structures, such as time series forecasting.

</details>


### [89] [GIFT: Unlocking Global Optimality in Post-Training via Finite-Temperature Gibbs Initialization](https://arxiv.org/abs/2601.09233)
*Zhengyang Zhao,Lu Ma,Yizhen Jiang,Xiaochen Ma,Zimo Meng,Chengyu Shen,Lexiang Tang,Haoze Sun,Peng Pei,Wentao Zhang*

Main category: cs.LG

TL;DR: 提出GIFT方法解决大推理模型后训练中SFT与RL之间的优化不匹配问题，通过有限温度吉布斯初始化建立分布桥梁，显著提升RL初始化效果。


<details>
  <summary>Details</summary>
Motivation: 当前大推理模型的后训练范式（SFT后接RL）存在内在优化不匹配：SFT的刚性监督导致分布坍缩，耗尽后续RL所需的探索空间。

Method: 将SFT重新表述为统一后训练框架，提出有限温度吉布斯初始化（GIFT）。将标准SFT视为抑制基础先验的零温度极限退化情况，而GIFT将监督作为有限温度能量势能，建立确保后训练流程中目标一致性的分布桥梁。

Result: 实验表明，GIFT在用于RL初始化时显著优于标准SFT和其他竞争基线，为后训练实现全局最优提供了数学上合理的方法。

Conclusion: GIFT通过有限温度框架解决后训练中的优化不匹配问题，为大推理模型的后训练提供了数学原理更严谨的路径。

Abstract: The prevailing post-training paradigm for Large Reasoning Models (LRMs)--Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL)--suffers from an intrinsic optimization mismatch: the rigid supervision inherent in SFT induces distributional collapse, thereby exhausting the exploration space necessary for subsequent RL. In this paper, we reformulate SFT within a unified post-training framework and propose Gibbs Initialization with Finite Temperature (GIFT). We characterize standard SFT as a degenerate zero-temperature limit that suppresses base priors. Conversely, GIFT incorporates supervision as a finite-temperature energy potential, establishing a distributional bridge that ensures objective consistency throughout the post-training pipeline. Our experiments demonstrate that GIFT significantly outperforms standard SFT and other competitive baselines when utilized for RL initialization, providing a mathematically principled pathway toward achieving global optimality in post-training. Our code is available at https://github.com/zzy1127/GIFT.

</details>


### [90] [Reward Learning through Ranking Mean Squared Error](https://arxiv.org/abs/2601.09236)
*Chaitanya Kharyal,Calarina Muslimani,Matthew E. Taylor*

Main category: cs.LG

TL;DR: R4是一种新的基于评分的强化学习方法，使用排序均方误差损失函数，将人类提供的评分作为序数目标，在机器人运动任务中优于现有方法且需要更少反馈。


<details>
  <summary>Details</summary>
Motivation: 奖励设计是强化学习应用于现实问题的瓶颈。虽然奖励学习可以从人类反馈中推断奖励函数，但传统二元偏好反馈有限。评分反馈能提供更丰富且认知负担更低的监督信息，因此需要开发有效的评分强化学习方法。

Method: R4使用新颖的排序均方误差损失函数，将教师提供的评分作为序数目标。方法从轨迹-评分对数据集中学习，采样轨迹集合并预测其回报，使用可微分排序算子（软排名）进行排序，然后优化软排名与教师评分之间的均方误差损失。

Result: R4在OpenAI Gym和DeepMind Control Suite的机器人运动基准测试中，使用模拟人类反馈，始终匹配或优于现有的评分和基于偏好的强化学习方法，同时需要显著更少的反馈。

Conclusion: R4提供形式化保证：在温和假设下其解集被证明是最小且完备的。该方法为从评分反馈中学习奖励函数提供了有效的解决方案，在性能和反馈效率方面优于现有方法。

Abstract: Reward design remains a significant bottleneck in applying reinforcement learning (RL) to real-world problems. A popular alternative is reward learning, where reward functions are inferred from human feedback rather than manually specified. Recent work has proposed learning reward functions from human feedback in the form of ratings, rather than traditional binary preferences, enabling richer and potentially less cognitively demanding supervision. Building on this paradigm, we introduce a new rating-based RL method, Ranked Return Regression for RL (R4). At its core, R4 employs a novel ranking mean squared error (rMSE) loss, which treats teacher-provided ratings as ordinal targets. Our approach learns from a dataset of trajectory-rating pairs, where each trajectory is labeled with a discrete rating (e.g., "bad," "neutral," "good"). At each training step, we sample a set of trajectories, predict their returns, and rank them using a differentiable sorting operator (soft ranks). We then optimize a mean squared error loss between the resulting soft ranks and the teacher's ratings. Unlike prior rating-based approaches, R4 offers formal guarantees: its solution set is provably minimal and complete under mild assumptions. Empirically, using simulated human feedback, we demonstrate that R4 consistently matches or outperforms existing rating and preference-based RL methods on robotic locomotion benchmarks from OpenAI Gym and the DeepMind Control Suite, while requiring significantly less feedback.

</details>


### [91] [XLinear: A Lightweight and Accurate MLP-Based Model for Long-Term Time Series Forecasting with Exogenous Inputs](https://arxiv.org/abs/2601.09237)
*Xinyang Chen,Huidong Jin,Yu Huang,Zaiwen Feng*

Main category: cs.LG

TL;DR: XLinear是一种轻量级时间序列预测模型，利用MLP和全局token有效整合内生变量和外生变量信息，在保持高效的同时提升预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测模型通常假设变量重要性均匀，但实际应用中存在不对称因果关系和不同数据获取成本。低成本外生数据（如本地天气）可以单向影响内生变量（如湖面温度），有效利用这些关系可以提升预测效果。Transformer模型计算成本高且存在排列不变性问题，基于patch的变体虽然效率提升但可能错过局部时间模式。

Method: 提出XLinear模型，基于多层感知机(MLP)构建。使用内生变量衍生的全局token作为与外部变量交互的枢纽，采用带sigmoid激活的MLP提取时间模式和变量间依赖关系。预测头整合这些信号来预测内生序列。

Result: 在7个标准基准和5个带外生输入的真实世界数据集上评估XLinear。相比最先进模型，XLinear在多元预测和受外生输入影响的单变量预测方面都提供了更优的准确性和效率。

Conclusion: XLinear通过有效整合时间维度和相关外生变量的信息信号，提供了一种轻量级但高效的时间序列预测解决方案，特别适用于存在不对称因果关系和不同数据获取成本的实际应用场景。

Abstract: Despite the prevalent assumption of uniform variable importance in long-term time series forecasting models, real world applications often exhibit asymmetric causal relationships and varying data acquisition costs. Specifically, cost-effective exogenous data (e.g., local weather) can unilaterally influence dynamics of endogenous variables, such as lake surface temperature. Exploiting these links enables more effective forecasts when exogenous inputs are readily available. Transformer-based models capture long-range dependencies but incur high computation and suffer from permutation invariance. Patch-based variants improve efficiency yet can miss local temporal patterns. To efficiently exploit informative signals across both the temporal dimension and relevant exogenous variables, this study proposes XLinear, a lightweight time series forecasting model built upon MultiLayer Perceptrons (MLPs). XLinear uses a global token derived from an endogenous variable as a pivotal hub for interacting with exogenous variables, and employs MLPs with sigmoid activation to extract both temporal patterns and variate-wise dependencies. Its prediction head then integrates these signals to forecast the endogenous series. We evaluate XLinear on seven standard benchmarks and five real-world datasets with exogenous inputs. Compared with state-of-the-art models, XLinear delivers superior accuracy and efficiency for both multivariate forecasts and univariate forecasts influenced by exogenous inputs.

</details>


### [92] [HGATSolver: A Heterogeneous Graph Attention Solver for Fluid-Structure Interaction](https://arxiv.org/abs/2601.09251)
*Qin-Yi Zhang,Hong Wang,Siyao Liu,Haichuan Lin,Linying Cao,Xiao-Hu Zhou,Chen Chen,Shuangyi Wang,Zeng-Guang Hou*

Main category: cs.LG

TL;DR: 提出HGATSolver，一种基于异构图注意力机制的流体-结构相互作用求解器，通过域特定的消息传递、物理条件门控机制和跨域梯度平衡损失，解决多物理场耦合系统的异质动力学建模难题。


<details>
  <summary>Details</summary>
Motivation: 流体-结构相互作用系统涉及不同物理域（流体和固体），受不同偏微分方程控制，在动态界面上耦合。现有基于学习的方法难以在统一框架中捕捉FSI的异质动力学，且由于界面耦合导致的响应不一致以及流体和固体区域学习难度差异，导致预测不稳定。

Method: HGATSolver将系统编码为异构图，通过为流体、固体和界面区域定义不同的节点和边类型，将物理结构直接嵌入模型。采用针对每个物理域定制的专门消息传递机制。引入物理条件门控机制作为可学习的自适应松弛因子来稳定显式时间步进。提出跨域梯度平衡损失，基于预测不确定性动态平衡各域的优化目标。

Result: 在两个构建的FSI基准测试和一个公共数据集上的大量实验表明，HGATSolver实现了最先进的性能，为耦合多物理场系统的代理建模建立了有效框架。

Conclusion: HGATSolver通过异构图表示、域特定消息传递、稳定机制和平衡优化策略，有效解决了FSI系统中异质动力学的建模挑战，为多物理场耦合系统的学习型求解器提供了新框架。

Abstract: Fluid-structure interaction (FSI) systems involve distinct physical domains, fluid and solid, governed by different partial differential equations and coupled at a dynamic interface. While learning-based solvers offer a promising alternative to costly numerical simulations, existing methods struggle to capture the heterogeneous dynamics of FSI within a unified framework. This challenge is further exacerbated by inconsistencies in response across domains due to interface coupling and by disparities in learning difficulty across fluid and solid regions, leading to instability during prediction. To address these challenges, we propose the Heterogeneous Graph Attention Solver (HGATSolver). HGATSolver encodes the system as a heterogeneous graph, embedding physical structure directly into the model via distinct node and edge types for fluid, solid, and interface regions. This enables specialized message-passing mechanisms tailored to each physical domain. To stabilize explicit time stepping, we introduce a novel physics-conditioned gating mechanism that serves as a learnable, adaptive relaxation factor. Furthermore, an Inter-domain Gradient-Balancing Loss dynamically balances the optimization objectives across domains based on predictive uncertainty. Extensive experiments on two constructed FSI benchmarks and a public dataset demonstrate that HGATSolver achieves state-of-the-art performance, establishing an effective framework for surrogate modeling of coupled multi-physics systems.

</details>


### [93] [RIFT: Repurposing Negative Samples via Reward-Informed Fine-Tuning](https://arxiv.org/abs/2601.09253)
*Zehua Liu,Shuqi Liu,Tao Zhong,Mingxuan Yuan*

Main category: cs.LG

TL;DR: RIFT（Reward Informed Fine-Tuning）是一种利用所有自生成样本进行LLM对齐的框架，通过奖励加权学习正负轨迹，比RFT更高效。


<details>
  <summary>Details</summary>
Motivation: 现有SFT依赖昂贵的专家数据，而RFT丢弃了有价值的负样本，导致数据效率低下。需要一种能充分利用自生成正负样本的方法。

Method: 提出RIFT框架，重新利用负轨迹，通过标量奖励对损失进行加权，从模型输出的正负轨迹中学习。为避免朴素奖励集成导致的训练崩溃，引入了稳定化损失公式确保数值鲁棒性和优化效率。

Result: 在多个基础模型上的数学基准测试中，RIFT始终优于RFT，证明了其在混合质量自生成数据对齐中的鲁棒性和数据效率。

Conclusion: RIFT是利用混合质量自生成数据进行LLM对齐的鲁棒且数据高效的替代方案。

Abstract: While Supervised Fine-Tuning (SFT) and Rejection Sampling Fine-Tuning (RFT) are standard for LLM alignment, they either rely on costly expert data or discard valuable negative samples, leading to data inefficiency. To address this, we propose Reward Informed Fine-Tuning (RIFT), a simple yet effective framework that utilizes all self-generated samples. Unlike the hard thresholding of RFT, RIFT repurposes negative trajectories, reweighting the loss with scalar rewards to learn from both the positive and negative trajectories from the model outputs. To overcome the training collapse caused by naive reward integration, where direct multiplication yields an unbounded loss, we introduce a stabilized loss formulation that ensures numerical robustness and optimization efficiency. Extensive experiments on mathematical benchmarks across various base models show that RIFT consistently outperforms RFT. Our results demonstrate that RIFT is a robust and data-efficient alternative for alignment using mixed-quality, self-generated data.

</details>


### [94] [Learning to Trust Experience: A Monitor-Trust-Regulator Framework for Learning under Unobservable Feedback Reliability](https://arxiv.org/abs/2601.09261)
*Zhipeng Zhang,Zhenjie Yao,Kai Li,Lei Yang*

Main category: cs.LG

TL;DR: 论文提出元认知调节框架（MTR）和自我诊断方法，用于在不可观测反馈可靠性下进行学习，通过内省监控来推断经验可信度，改善认知可识别性。


<details>
  <summary>Details</summary>
Motivation: 在不可观测反馈可靠性（EIUR）场景下，传统鲁棒学习方法可能稳定收敛但形成高置信度的系统性错误信念，因为系统无法区分可靠和不可靠的反馈，且数据由学习者自身信念和行动闭环生成。

Method: 提出元认知调节框架，采用Monitor-Trust-Regulator（MTR）分解，实例化为自我诊断方法：维护缓慢变化的经验信任变量，软调制学习更新，无需外部可靠性标签或显式腐败模型。

Result: 在EIUR场景中，自我诊断与改善的认知可识别性相关：在强化学习中实现校准的怀疑和系统性腐败奖励下的恢复；在监督学习中揭示性能恢复与认知恢复的分离，准确性可能反弹而内部信念动态仍被早期误导数据锁定。

Conclusion: MTR框架和自我诊断方法为自主学习中的内在可靠性评估提供了组织抽象和具体设计模板，在不可观测可靠性下实现内省诊断和可靠性推断。

Abstract: Learning under unobservable feedback reliability poses a distinct challenge beyond optimization robustness: a system must decide whether to learn from an experience, not only how to learn stably. We study this setting as Epistemic Identifiability under Unobservable Reliability (EIUR), where each experience has a latent credibility, reliable and unreliable feedback can be locally indistinguishable, and data are generated in a closed loop by the learner's own evolving beliefs and actions. In EIUR, standard robust learning can converge stably yet form high-confidence, systematically wrong beliefs.
  We propose metacognitive regulation as a practical response: a second, introspective control loop that infers experience credibility from endogenous evidence in the learner's internal dynamics. We formalize this as a modular Monitor-Trust-Regulator (MTR) decomposition and instantiate it with self-diagnosis, which maintains a slowly varying experience-trust variable that softly modulates learning updates, without exogenous reliability labels or an explicit corruption model.
  Empirically, in the EIUR regimes studied here, self-diagnosis is associated with improved epistemic identifiability. In reinforcement learning, it enables calibrated skepticism and recovery under systematically corrupted rewards. In supervised learning, it exposes a critical dissociation: performance recovery does not imply epistemic recovery. Accuracy can rebound while internal belief dynamics remain locked-in by early misleading data, a failure detectable only through introspective diagnostics. Together, MTR and self-diagnosis provide an organizing abstraction and a concrete design template for intrinsic reliability assessment in autonomous learning under unobservable reliability.

</details>


### [95] [Enhancing Spatial Reasoning in Large Language Models for Metal-Organic Frameworks Structure Prediction](https://arxiv.org/abs/2601.09285)
*Mianzhi Pan,JianFei Li,Peishuo Liu,Botian Wang,Yawen Ouyang,Yiming Rong,Hao Zhou,Jianbing Zhang*

Main category: cs.LG

TL;DR: MOF-LLM：首个基于大语言模型的块级MOF结构预测框架，通过空间感知预训练、监督微调和强化学习优化，显著提升MOF三维结构预测精度


<details>
  <summary>Details</summary>
Motivation: 金属有机框架（MOFs）在碳捕获和药物递送等领域有广泛应用，但准确预测其3D结构仍具挑战。现有大语言模型（LLMs）在晶体生成方面有潜力，但MOFs的高原子复杂性限制了其应用。受深度生成模型中块级范式的启发，需要开发专门针对MOF结构预测的LLM框架

Method: 提出MOF-LLM框架，采用块级预测范式。训练过程包含：1）空间感知持续预训练（CPT），2）结构监督微调（SFT），3）匹配驱动的强化学习（RL）。通过引入显式空间先验和使用Soft Adaptive Policy Optimization（SAPO）优化结构稳定性，增强Qwen-3 8B模型的空间推理能力

Result: MOF-LLM在综合实验中优于最先进的去噪基和LLM基方法，展现出卓越的采样效率，显著提升了MOF结构预测的准确性

Conclusion: 该研究首次将大语言模型成功应用于MOF结构预测领域，通过创新的块级训练范式有效解决了MOF高原子复杂性的挑战，为MOF设计提供了新的高效工具

Abstract: Metal-organic frameworks (MOFs) are porous crystalline materials with broad applications such as carbon capture and drug delivery, yet accurately predicting their 3D structures remains a significant challenge. While Large Language Models (LLMs) have shown promise in generating crystals, their application to MOFs is hindered by MOFs' high atomic complexity. Inspired by the success of block-wise paradigms in deep generative models, we pioneer the use of LLMs in this domain by introducing MOF-LLM, the first LLM framework specifically adapted for block-level MOF structure prediction. To effectively harness LLMs for this modular assembly task, our training paradigm integrates spatial-aware continual pre-training (CPT), structural supervised fine-tuning (SFT), and matching-driven reinforcement learning (RL). By incorporating explicit spatial priors and optimizing structural stability via Soft Adaptive Policy Optimization (SAPO), our approach substantially enhances the spatial reasoning capability of a Qwen-3 8B model for accurate MOF structure prediction. Comprehensive experiments demonstrate that MOF-LLM outperforms state-of-the-art denoising-based and LLM-based methods while exhibiting superior sampling efficiency.

</details>


### [96] [Single-Round Clustered Federated Learning via Data Collaboration Analysis for Non-IID Data](https://arxiv.org/abs/2601.09304)
*Sota Sugawara,Yuji Kawamata,Akihiro Toyoda,Tomoru Nakayama,Yukihiko Okada*

Main category: cs.LG

TL;DR: DC-CFL：单轮通信的聚类联邦学习框架，通过数据协作分析实现客户端聚类和聚类内学习，在非IID数据下达到与多轮方法相当的精度。


<details>
  <summary>Details</summary>
Motivation: 传统聚类联邦学习需要多轮通信进行聚类估计和模型更新，在通信轮次受限的实际场景中实用性受限。需要开发单轮通信的解决方案。

Method: 基于数据协作分析的单轮框架：1) 通过标签分布的总变差距离量化客户端相似性；2) 使用层次聚类进行客户端聚类；3) 通过数据协作分析进行聚类内学习。

Result: 在多个公开数据集和典型非IID条件下，DC-CFL仅需一轮通信就能达到与多轮基线方法相当的准确率。

Conclusion: DC-CFL为通信轮次受限的场景提供了实用的聚类联邦学习替代方案，适用于多轮通信不可行的协作AI模型开发。

Abstract: Federated Learning (FL) enables distributed learning across multiple clients without sharing raw data. When statistical heterogeneity across clients is severe, Clustered Federated Learning (CFL) can improve performance by grouping similar clients and training cluster-wise models. However, most CFL approaches rely on multiple communication rounds for cluster estimation and model updates, which limits their practicality under tight constraints on communication rounds. We propose Data Collaboration-based Clustered Federated Learning (DC-CFL), a single-round framework that completes both client clustering and cluster-wise learning, using only the information shared in DC analysis. DC-CFL quantifies inter-client similarity via total variation distance between label distributions, estimates clusters using hierarchical clustering, and performs cluster-wise learning via DC analysis. Experiments on multiple open datasets under representative non-IID conditions show that DC-CFL achieves accuracy comparable to multi-round baselines while requiring only one communication round. These results indicate that DC-CFL is a practical alternative for collaborative AI model development when multiple communication rounds are impractical.

</details>


### [97] [GeoRA: Geometry-Aware Low-Rank Adaptation for RLVR](https://arxiv.org/abs/2601.09361)
*Jiaying Zhang,Lei Shi,Jiguo Li,Jun Xu,Jiuchong Gao,Jinghua Hao,Renqing He*

Main category: cs.LG

TL;DR: GeoRA是一种针对强化学习可验证奖励（RLVR）的几何感知低秩适配方法，通过SVD提取主方向并冻结残差分量，解决了现有参数高效方法在RLVR中的谱崩溃和优化不稳定问题，在数学基准测试中取得SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 现有参数高效方法（如PiSSA和MiLoRA）是为监督微调设计的，不适用于RLVR的优化动态和几何结构，直接应用会导致谱崩溃和优化不稳定。同时，利用更新稀疏性的方法在现代硬件上存在效率瓶颈。

Method: GeoRA利用RL更新子空间的各向异性和可压缩性，通过奇异值分解在几何约束子空间内提取主方向来初始化适配器，并冻结残差分量。该方法保持了预训练几何结构，并通过密集算子实现高效的GPU计算。

Result: 在Qwen和Llama模型上的实验表明，GeoRA缓解了几何错配导致的优化瓶颈，在关键数学基准测试中持续优于现有低秩基线，取得了SOTA结果。此外，在领域外任务中表现出更好的泛化能力和对灾难性遗忘的抵抗力。

Conclusion: GeoRA通过几何感知的低秩适配有效解决了RLVR中的优化挑战，在保持计算效率的同时实现了卓越性能，为大规模推理模型的强化学习微调提供了有效解决方案。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is crucial for advancing large-scale reasoning models. However, existing parameter-efficient methods, such as PiSSA and MiLoRA, are designed for Supervised Fine-Tuning (SFT) and do not account for the distinct optimization dynamics and geometric structures of RLVR. Applying these methods directly leads to spectral collapse and optimization instability, which severely limit model performance. Meanwhile, alternative approaches that leverage update sparsity encounter significant efficiency bottlenecks on modern hardware due to unstructured computations. To address these challenges, we propose GeoRA (Geometry-Aware Low-Rank Adaptation), which exploits the anisotropic and compressible nature of RL update subspaces. GeoRA initializes adapters by extracting principal directions via Singular Value Decomposition (SVD) within a geometrically constrained subspace while freezing the residual components. This method preserves the pre-trained geometric structure and enables efficient GPU computation through dense operators. Experiments on Qwen and Llama demonstrate that GeoRA mitigates optimization bottlenecks caused by geometric misalignment. It consistently outperforms established low-rank baselines on key mathematical benchmarks, achieving state-of-the-art (SOTA) results. Moreover, GeoRA shows superior generalization and resilience to catastrophic forgetting in out-of-domain tasks.

</details>


### [98] [Preliminary Tests of the Anticipatory Classifier System with Hindsight Experience Replay](https://arxiv.org/abs/2601.09400)
*Olgierd Unold,Stanisław Franczyk*

Main category: cs.LG

TL;DR: ACS2HER将Anticipatory Classifier System与Hindsight Experience Replay结合，通过目标重标记解决稀疏奖励问题，在迷宫和冰湖环境中加速学习，但计算开销和分类器数量增加。


<details>
  <summary>Details</summary>
Motivation: ACS2在稀疏奖励环境中性能停滞，需要增强其学习信号密度以改善学习效率。

Method: 提出ACS2HER架构，当智能体未能达到主要目标时触发后见学习，将访问状态重新标记为虚拟目标，从而丰富学习信号。

Result: 在确定性的Maze 6和随机的FrozenLake基准测试中，ACS2HER相比标准ACS2显著加速知识获取和环境掌握，但计算开销和分类器数量大幅增加。

Conclusion: 这是首次将预期机制与回顾性目标重标记结合在学习分类器系统中的分析，展示了效率提升与计算成本之间的权衡。

Abstract: This paper introduces ACS2HER, a novel integration of the Anticipatory Classifier System (ACS2) with the Hindsight Experience Replay (HER) mechanism. While ACS2 is highly effective at building cognitive maps through latent learning, its performance often stagnates in environments characterized by sparse rewards. We propose a specific architectural variant that triggers hindsight learning when the agent fails to reach its primary goal, re-labeling visited states as virtual goals to densify the learning signal. The proposed model was evaluated on two benchmarks: the deterministic \texttt{Maze 6} and the stochastic \texttt{FrozenLake}. The results demonstrate that ACS2HER significantly accelerates knowledge acquisition and environmental mastery compared to the standard ACS2. However, this efficiency gain is accompanied by increased computational overhead and a substantial expansion in classifier numerosity. This work provides the first analysis of combining anticipatory mechanisms with retrospective goal-relabeling in Learning Classifier Systems.

</details>


### [99] [Draw it like Euclid: Teaching transformer models to generate CAD profiles using ruler and compass construction steps](https://arxiv.org/abs/2601.09428)
*Siyi Li,Joseph G. Lambourne,Longfei Zhang,Pradeep Kumar Jayaraman,Karl. D. D. Willis*

Main category: cs.LG

TL;DR: 提出一种通过几何构造序列生成CAD轮廓的新方法，类似语言模型中的思维链，通过添加构造步骤提高生成质量，并支持参数化编辑。


<details>
  <summary>Details</summary>
Motivation: 传统CAD建模通常需要复杂的参数化约束，作者希望开发一种更直观、更灵活的CAD轮廓生成方法，通过简单的几何构造序列来构建复杂形状，同时保持参数化编辑能力。

Method: 使用曲线偏移、旋转和交点等简单几何构造操作构建序列，从设计师提供的初始几何开始，逐步构建最终轮廓。引入强化学习优化构造序列，提高生成质量。

Result: 构造序列方法显著提高了CAD轮廓生成质量，类似思维链在语言模型中的作用。强化学习的应用进一步改善了多种指标，包括未明确优化的指标。该方法支持高精度参数化编辑。

Conclusion: 几何构造序列为CAD轮廓生成提供了一种新颖有效的方法，结合了直观的构造过程和参数化编辑能力，强化学习的应用进一步提升了性能，为CAD设计自动化开辟了新途径。

Abstract: We introduce a new method of generating Computer Aided Design (CAD) profiles via a sequence of simple geometric constructions including curve offsetting, rotations and intersections. These sequences start with geometry provided by a designer and build up the points and curves of the final profile step by step. We demonstrate that adding construction steps between the designer's input geometry and the final profile improves generation quality in a similar way to the introduction of a chain of thought in language models. Similar to the constraints in a parametric CAD model, the construction sequences reduce the degrees of freedom in the modeled shape to a small set of parameter values which can be adjusted by the designer, allowing parametric editing with the constructed geometry evaluated to floating point precision. In addition we show that applying reinforcement learning to the construction sequences gives further improvements over a wide range of metrics, including some which were not explicitly optimized.

</details>


### [100] [DeepLight: A Sobolev-trained Image-to-Image Surrogate Model for Light Transport in Tissue](https://arxiv.org/abs/2601.09439)
*Philipp Haim,Vasilis Ntziachristos,Torsten Enßlin,Dominik Jüstel*

Main category: cs.LG

TL;DR: 提出使用Sobolev训练改进光传输代理模型的导数准确性，以提升光声成像中吸收系数反演的性能。


<details>
  <summary>Details</summary>
Motivation: 光声成像中通过反演光传输来恢复组织吸收系数是一个挑战性问题。现有变分反演方法需要准确且可微的光传输模型，而神经代理模型虽然能快速模拟复杂物理过程，但其导数准确性无法保证，这会严重影响反演重建的质量。

Method: 提出使用Sobolev训练方法来改进组织光传输代理模型的导数准确性。这种Sobolev训练形式适用于高维模型，能够提高模型导数的匹配精度。

Result: Sobolev训练不仅提高了光传输代理模型的导数准确性，还降低了模型在分布内和分布外样本上的泛化误差。这些改进有望显著增强代理模型在下游任务（特别是反问题求解）中的实用性。

Conclusion: Sobolev训练为光传输代理模型提供了更准确的导数，这对于解决光声成像中的逆问题具有重要意义，有望提升光声成像的临床应用价值。

Abstract: In optoacoustic imaging, recovering the absorption coefficients of tissue by inverting the light transport remains a challenging problem. Improvements in solving this problem can greatly benefit the clinical value of optoacoustic imaging. Existing variational inversion methods require an accurate and differentiable model of this light transport. As neural surrogate models allow fast and differentiable simulations of complex physical processes, they are considered promising candidates to be used in solving such inverse problems. However, there are in general no guarantees that the derivatives of these surrogate models accurately match those of the underlying physical operator. As accurate derivatives are central to solving inverse problems, errors in the model derivative can considerably hinder high fidelity reconstructions. To overcome this limitation, we present a surrogate model for light transport in tissue that uses Sobolev training to improve the accuracy of the model derivatives. Additionally, the form of Sobolev training we used is suitable for high-dimensional models in general. Our results demonstrate that Sobolev training for a light transport surrogate model not only improves derivative accuracy but also reduces generalization error for in-distribution and out-of-distribution samples. These improvements promise to considerably enhance the utility of the surrogate model in downstream tasks, especially in solving inverse problems.

</details>


### [101] [Late Breaking Results: Quamba-SE: Soft-edge Quantizer for Activations in State Space Models](https://arxiv.org/abs/2601.09451)
*Yizhi Chen,Ahmed Hemani*

Main category: cs.LG

TL;DR: Quamba-SE是一种用于状态空间模型激活量化的软边缘量化器，采用三种自适应尺度来保留异常值信息，相比现有方法在多个基准测试中表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有的状态空间模型激活量化方法通常使用标准的INT8操作，会通过硬截断处理异常值，导致信息丢失。需要一种能更好保留异常值信息同时保持其他值精度的量化方法。

Method: 提出Quamba-SE软边缘量化器，采用三种自适应尺度：对较小值使用高精度尺度，对正常值使用标准尺度，对异常值使用低精度尺度。这种方法避免了硬截断，能更好地保留异常值信息。

Result: 在Mamba-130M模型上对6个零样本基准测试进行评估。Quamba-SE在单个基准测试上最高提升2.68%，在6个数据集的平均准确率上提升0.83%，始终优于原始Quamba方法。

Conclusion: Quamba-SE通过软边缘量化和多尺度自适应策略，有效解决了状态空间模型激活量化中的异常值处理问题，在保持精度的同时显著提升了量化性能。

Abstract: We propose Quamba-SE, a soft-edge quantizer for State Space Model (SSM) activation quantization. Unlike existing methods, using standard INT8 operation, Quamba-SE employs three adaptive scales: high-precision for small values, standard scale for normal values, and low-precision for outliers. This preserves outlier information instead of hard clipping, while maintaining precision for other values. We evaluate on Mamba- 130M across 6 zero-shot benchmarks. Results show that Quamba- SE consistently outperforms Quamba, achieving up to +2.68% on individual benchmarks and up to +0.83% improvement in the average accuracy of 6 datasets.

</details>


### [102] [On the Hardness of Computing Counterfactual and Semifactual Explanations in XAI](https://arxiv.org/abs/2601.09455)
*André Artelt,Martin Olsen,Kevin Tierney*

Main category: cs.LG

TL;DR: 本文综述了机器学习模型反事实和半事实解释的计算复杂性，发现生成这些解释通常是计算困难的，并进一步贡献了不可逼近性结果，讨论了这些复杂性结果对XAI社区和政策制定的影响。


<details>
  <summary>Details</summary>
Motivation: 在关键应用中部署机器学习模型时，提供清晰的解释至关重要。反事实和半事实解释已成为为用户提供模型输出洞察的两种机制，但需要了解这些解释生成的计算复杂性。

Method: 本文采用文献综述方法，系统梳理了反事实和半事实解释生成的计算复杂性结果，并进一步贡献了作者自己的不可逼近性结果，证明在某些假设下这些解释不仅难以生成，也难以逼近。

Result: 研究发现生成反事实和半事实解释在许多情况下是计算困难的，作者进一步证明了在某些假设下这些解释也是难以逼近的，这显著强化了现有文献中的论证。

Conclusion: 这些计算复杂性结果对XAI社区和政策制定者具有重要启示：在寻求监管AI解释时，需要考虑解释生成的计算可行性限制，并可能需要在解释的简洁性、准确性和计算成本之间做出权衡。

Abstract: Providing clear explanations to the choices of machine learning models is essential for these models to be deployed in crucial applications. Counterfactual and semi-factual explanations have emerged as two mechanisms for providing users with insights into the outputs of their models. We provide an overview of the computational complexity results in the literature for generating these explanations, finding that in many cases, generating explanations is computationally hard. We strengthen the argument for this considerably by further contributing our own inapproximability results showing that not only are explanations often hard to generate, but under certain assumptions, they are also hard to approximate. We discuss the implications of these complexity results for the XAI community and for policymakers seeking to regulate explanations in AI.

</details>


### [103] [Searth Transformer: A Transformer Architecture Incorporating Earth's Geospheric Physical Priors for Global Mid-Range Weather Forecasting](https://arxiv.org/abs/2601.09467)
*Tianye Li,Qi Liu,Hao Li,Lei Chen,Wencong Cheng,Fei Zheng,Xiangao Xia,Ya Wang,Gang Huang,Weiwei Wang,Xuan Tong,Ziqing Zu,Yi Fang,Shenming Fu,Jiang Jiang,Haochen Li,Mingxing Li,Jiangjiang Xia*

Main category: cs.LG

TL;DR: 提出Searth Transformer架构和RAR微调策略，开发YanTian全球中期天气预报模型，在精度和计算效率上优于传统方法


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的天气预报模型忽视地球球面几何和纬向周期性，且传统自回归训练计算成本高、误差累积限制预报时效

Method: 1) Searth Transformer：融入纬向周期性和经向边界约束的窗口自注意力架构；2) RAR微调策略：在有限计算资源下学习长程大气演化；3) 基于此开发YanTian模型

Result: YanTian精度优于ECMWF高分辨率预报，与SOTA AI模型相当，计算成本比标准自回归微调低200倍，Z500有效预报时效达10.3天（HRES为9天）

Conclusion: 该工作为复杂全球尺度地球物理环流系统的预测建模建立了稳健算法基础，为地球系统科学提供了新途径

Abstract: Accurate global medium-range weather forecasting is fundamental to Earth system science. Most existing Transformer-based forecasting models adopt vision-centric architectures that neglect the Earth's spherical geometry and zonal periodicity. In addition, conventional autoregressive training is computationally expensive and limits forecast horizons due to error accumulation. To address these challenges, we propose the Shifted Earth Transformer (Searth Transformer), a physics-informed architecture that incorporates zonal periodicity and meridional boundaries into window-based self-attention for physically consistent global information exchange. We further introduce a Relay Autoregressive (RAR) fine-tuning strategy that enables learning long-range atmospheric evolution under constrained memory and computational budgets. Based on these methods, we develop YanTian, a global medium-range weather forecasting model. YanTian achieves higher accuracy than the high-resolution forecast of the European Centre for Medium-Range Weather Forecasts and performs competitively with state-of-the-art AI models at one-degree resolution, while requiring roughly 200 times lower computational cost than standard autoregressive fine-tuning. Furthermore, YanTian attains a longer skillful forecast lead time for Z500 (10.3 days) than HRES (9 days). Beyond weather forecasting, this work establishes a robust algorithmic foundation for predictive modeling of complex global-scale geophysical circulation systems, offering new pathways for Earth system science.

</details>


### [104] [FairGU: Fairness-aware Graph Unlearning in Social Network](https://arxiv.org/abs/2601.09469)
*Renqiang Luo,Yongshuai Yang,Huafei Huang,Qing Qing,Mingliang Hou,Ziqi Xu,Yi Yu,Jingjing Zhou,Feng Xia*

Main category: cs.LG

TL;DR: FairGU是一个公平感知的图遗忘框架，旨在在遗忘过程中同时保持模型效用和公平性，解决了现有图遗忘技术对敏感属性保护不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有图遗忘技术在保护敏感属性方面不足，往往导致算法公平性比传统图学习方法更差。当前遗忘实践中存在被忽视的风险，需要开发既能保护隐私又能保持公平的解决方案。

Method: FairGU整合了专门的公平感知模块和有效的数据保护策略，确保在节点删除时敏感属性既不会被无意放大，也不会在结构上暴露。

Result: 在多个真实世界数据集上的实验表明，FairGU在准确性和公平性指标上都持续优于最先进的图遗忘方法和公平增强的图学习基线方法。

Conclusion: 研究揭示了当前遗忘实践中被忽视的风险，并确立了FairGU作为下一代社会可持续网络系统的稳健且公平的解决方案。

Abstract: Graph unlearning has emerged as a critical mechanism for supporting sustainable and privacy-preserving social networks, enabling models to remove the influence of deleted nodes and thereby better safeguard user information. However, we observe that existing graph unlearning techniques insufficiently protect sensitive attributes, often leading to degraded algorithmic fairness compared with traditional graph learning methods. To address this gap, we introduce FairGU, a fairness-aware graph unlearning framework designed to preserve both utility and fairness during the unlearning process. FairGU integrates a dedicated fairness-aware module with effective data protection strategies, ensuring that sensitive attributes are neither inadvertently amplified nor structurally exposed when nodes are removed. Through extensive experiments on multiple real-world datasets, we demonstrate that FairGU consistently outperforms state-of-the-art graph unlearning methods and fairness-enhanced graph learning baselines in terms of both accuracy and fairness metrics. Our findings highlight a previously overlooked risk in current unlearning practices and establish FairGU as a robust and equitable solution for the next generation of socially sustainable networked systems. The codes are available at https://github.com/LuoRenqiang/FairGU.

</details>


### [105] [SimMerge: Learning to Select Merge Operators from Similarity Signals](https://arxiv.org/abs/2601.09473)
*Oliver Bolton,Aakanksha,Arash Ahmadian,Sara Hooker,Marzieh Fadaee,Beyza Ermis*

Main category: cs.LG

TL;DR: SimMerge：一种基于模型相似性预测合并性能的方法，避免昂贵的合并-评估循环，实现高效模型合并选择


<details>
  <summary>Details</summary>
Motivation: 模型合并是LLM开发的重要工具，但大规模合并面临挑战：需要选择合适的合并算子、模型和合并顺序，通常需要进行昂贵的合并-评估搜索。需要一种更高效的方法来预测合并性能。

Method: 提出SimMerge方法，使用少量无标签探针计算模型的功能和结构特征，基于这些相似性信号预测2-way合并的性能。该方法可以自动选择最佳合并算子、模型子集和合并顺序，无需昂贵的合并-评估循环。

Result: 在7B参数LLM的2-way合并中超越了标准合并算子性能；能够泛化到多路合并和111B参数LLM合并而无需重新训练；还提出了支持动态添加新任务、模型和算子的bandit变体。

Conclusion: 学习如何合并是当检查点目录庞大且评估预算有限时，实现可扩展模型组合的实用途径。SimMerge提供了一种预测性合并选择方法，显著提高了模型合并的效率。

Abstract: Model merging enables multiple large language models (LLMs) to be combined into a single model while preserving performance. This makes it a valuable tool in LLM development, offering a competitive alternative to multi-task training. However, merging can be difficult at scale, as successful merging requires choosing the right merge operator, selecting the right models, and merging them in the right order. This often leads researchers to run expensive merge-and-evaluate searches to select the best merge. In this work, we provide an alternative by introducing \simmerge{}, \emph{a predictive merge-selection method} that selects the best merge using inexpensive, task-agnostic similarity signals between models. From a small set of unlabeled probes, we compute functional and structural features and use them to predict the performance of a given 2-way merge. Using these predictions, \simmerge{} selects the best merge operator, the subset of models to merge, and the merge order, eliminating the expensive merge-and-evaluate loop. We demonstrate that we surpass standard merge-operator performance on 2-way merges of 7B-parameter LLMs, and that \simmerge{} generalizes to multi-way merges and 111B-parameter LLM merges without retraining. Additionally, we present a bandit variant that supports adding new tasks, models, and operators on the fly. Our results suggest that learning how to merge is a practical route to scalable model composition when checkpoint catalogs are large and evaluation budgets are tight.

</details>


### [106] [Terminally constrained flow-based generative models from an optimal control perspective](https://arxiv.org/abs/2601.09474)
*Weiguo Gao,Ming Li,Qianxiao Li*

Main category: cs.LG

TL;DR: 提出TOCFlow方法，通过最优控制框架解决预训练流模型在终端约束分布采样问题，无需矩阵求逆即可实现几何一致的采样指导


<details>
  <summary>Details</summary>
Motivation: 现有流模型在生成满足特定终端约束的样本时存在困难，需要一种既能保持生成质量又能满足约束的采样指导方法

Method: 基于最优控制理论，将约束采样问题形式化为Hamilton-Jacobi-Bellman方程，提出TOCFlow方法：在跟踪参考轨迹的终端共动框架中求解控制问题，得到闭式标量阻尼因子，沿黎曼梯度工作

Result: TOCFlow在三个高维科学任务（Darcy流、约束轨迹规划、湍流快照生成）中，相比欧几里得指导和投影基线，显著提高了约束满足度，同时保持了参考模型的生成质量

Conclusion: TOCFlow提供了一种计算高效、几何一致的采样指导方法，能以标准梯度指导的计算成本实现高斯-牛顿更新的几何一致性，适用于多种约束类型的高维科学问题

Abstract: We address the problem of sampling from terminally constrained distributions with pre-trained flow-based generative models through an optimal control formulation. Theoretically, we characterize the value function by a Hamilton-Jacobi-Bellman equation and derive the optimal feedback control as the minimizer of the associated Hamiltonian. We show that as the control penalty increases, the controlled process recovers the reference distribution, while as the penalty vanishes, the terminal law converges to a generalized Wasserstein projection onto the constraint manifold. Algorithmically, we introduce Terminal Optimal Control with Flow-based models (TOCFlow), a geometry-aware sampling-time guidance method for pre-trained flows. Solving the control problem in a terminal co-moving frame that tracks reference trajectories yields a closed-form scalar damping factor along the Riemannian gradient, capturing second-order curvature effects without matrix inversions. TOCFlow therefore matches the geometric consistency of Gauss-Newton updates at the computational cost of standard gradient guidance. We evaluate TOCFlow on three high-dimensional scientific tasks spanning equality, inequality, and global statistical constraints, namely Darcy flow, constrained trajectory planning, and turbulence snapshot generation with Kolmogorov spectral scaling. Across all settings, TOCFlow improves constraint satisfaction over Euclidean guidance and projection baselines while preserving the reference model's generative quality.

</details>


### [107] [Deep Operator Networks for Surrogate Modeling of Cyclic Adsorption Processes with Varying Initial Conditions](https://arxiv.org/abs/2601.09491)
*Beatrice Ceccanti,Mattia Galanti,Ivo Roghair,Martin van Sint Annaland*

Main category: cs.LG

TL;DR: DeepONets作为PDE求解的算子学习方法，应用于吸附过程建模，成功构建了循环吸附过程的替代模型，能够加速TVSA等循环过程的模拟和优化。


<details>
  <summary>Details</summary>
Motivation: 循环吸附过程（如TVSA）需要重复求解瞬态PDE，计算成本高昂。需要开发高效的替代模型来加速收敛，同时要求模型能够泛化到广泛的初始条件范围。

Method: 使用DeepONets学习从初始条件到解场的算子映射。构建混合训练数据集，包含异构初始条件，训练模型近似对应的解算子。在训练参数范围外和未见函数形式上测试泛化能力。

Result: 训练后的模型在训练分布内外部都能做出准确预测，包括完全未见过的函数形式。DeepONets展现出作为循环吸附模拟和优化工作流高效替代模型的潜力。

Conclusion: DeepONets能够有效学习具有陡峭传播前沿的PDE解算子，在循环吸附过程建模中表现出良好的泛化能力，有望加速相关模拟和优化工作流。

Abstract: Deep Operator Networks are emerging as fundamental tools among various neural network types to learn mappings between function spaces, and have recently gained attention due to their ability to approximate nonlinear operators. In particular, DeepONets offer a natural formulation for PDE solving, since the solution of a partial differential equation can be interpreted as an operator mapping an initial condition to its corresponding solution field. In this work, we applied DeepONets in the context of process modeling for adsorption technologies, to assess their feasibility as surrogates for cyclic adsorption process simulation and optimization. The goal is to accelerate convergence of cyclic processes such as Temperature-Vacuum Swing Adsorption (TVSA), which require repeated solution of transient PDEs, which are computationally expensive. Since each step of a cyclic adsorption process starts from the final state of the preceding step, effective surrogate modeling requires generalization across a wide range of initial conditions. The governing equations exhibit steep traveling fronts, providing a demanding benchmark for operator learning. To evaluate functional generalization under these conditions, we construct a mixed training dataset composed of heterogeneous initial conditions and train DeepONets to approximate the corresponding solution operators. The trained models are then tested on initial conditions outside the parameter ranges used during training, as well as on completely unseen functional forms. The results demonstrate accurate predictions both within and beyond the training distribution, highlighting DeepONets as potential efficient surrogates for accelerating cyclic adsorption simulations and optimization workflows.

</details>


### [108] [Parallelizable memory recurrent units](https://arxiv.org/abs/2601.09495)
*Florent De Geeter,Gaspard Lambrechts,Damien Ernst,Guillaume Drion*

Main category: cs.LG

TL;DR: 提出记忆循环单元(MRU)，结合非线性RNN的持久记忆能力和状态空间模型(SSM)的可并行计算优势，通过多稳态实现持久记忆，同时消除瞬态动态以实现高效计算。


<details>
  <summary>Details</summary>
Motivation: Transformer在序列生成时效率低下，需要重新处理所有过去时间步；状态空间模型(SSM)虽然可并行训练，但缺乏持久记忆能力，因为其单稳态特性无法无限期保留信息。需要一种既能并行计算又具有持久记忆能力的模型。

Method: 提出记忆循环单元(MRU)家族，利用多稳态作为持久记忆的来源，同时消除瞬态动态以实现高效计算。具体实现为双稳态记忆循环单元(BMRU)，该RNN兼容并行扫描算法，可与状态空间模型结合形成混合网络。

Result: BMRU在具有长期依赖关系的任务中表现良好，能够与状态空间模型结合创建既可并行化又具有瞬态动态和持久记忆的混合网络。

Conclusion: 记忆循环单元(MRU)成功地将非线性RNN的持久记忆能力与状态空间模型的可并行计算优势相结合，为解决序列模型的效率和记忆能力之间的权衡提供了新思路。

Abstract: With the emergence of massively parallel processing units, parallelization has become a desirable property for new sequence models. The ability to parallelize the processing of sequences with respect to the sequence length during training is one of the main factors behind the uprising of the Transformer architecture. However, Transformers lack efficiency at sequence generation, as they need to reprocess all past timesteps at every generation step. Recently, state-space models (SSMs) emerged as a more efficient alternative. These new kinds of recurrent neural networks (RNNs) keep the efficient update of the RNNs while gaining parallelization by getting rid of nonlinear dynamics (or recurrence). SSMs can reach state-of-the art performance through the efficient training of potentially very large networks, but still suffer from limited representation capabilities. In particular, SSMs cannot exhibit persistent memory, or the capacity of retaining information for an infinite duration, because of their monostability. In this paper, we introduce a new family of RNNs, the memory recurrent units (MRUs), that combine the persistent memory capabilities of nonlinear RNNs with the parallelizable computations of SSMs. These units leverage multistability as a source of persistent memory, while getting rid of transient dynamics for efficient computations. We then derive a specific implementation as proof-of-concept: the bistable memory recurrent unit (BMRU). This new RNN is compatible with the parallel scan algorithm. We show that BMRU achieves good results in tasks with long-term dependencies, and can be combined with state-space models to create hybrid networks that are parallelizable and have transient dynamics as well as persistent memory.

</details>


### [109] [Class Adaptive Conformal Training](https://arxiv.org/abs/2601.09522)
*Badr-Eddine Marani,Julio Silva-Rodriguez,Ismail Ben Ayed,Maria Vakalopoulou,Stergios Christodoulidis,Jose Dolz*

Main category: cs.LG

TL;DR: CaCT提出了一种自适应类别条件置信训练方法，通过增广拉格朗日优化学习形状预测集，无需数据分布假设，在保持覆盖保证的同时产生更小更信息化的预测集。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络虽然在各种任务中表现出色，但常常存在概率估计不可靠的问题，容易过度自信。现有置信训练方法主要优化整体集合大小，但难以实现类别条件形状调整，通常需要数据分布的先验知识。

Method: 提出Class Adaptive Conformal Training (CaCT)，将置信训练表述为增广拉格朗日优化问题，自适应地学习类别条件预测集形状，无需任何分布假设。

Result: 在多个基准数据集（包括标准/长尾图像识别和文本分类）上的实验表明，CaCT始终优于先前的置信训练方法，产生显著更小且更具信息量的预测集，同时保持所需的覆盖保证。

Conclusion: CaCT提供了一种无需分布假设的自适应类别条件置信训练框架，能够有效改善深度神经网络的概率校准和不确定性量化，产生更优的预测集。

Abstract: Deep neural networks have achieved remarkable success across a variety of tasks, yet they often suffer from unreliable probability estimates. As a result, they can be overconfident in their predictions. Conformal Prediction (CP) offers a principled framework for uncertainty quantification, yielding prediction sets with rigorous coverage guarantees. Existing conformal training methods optimize for overall set size, but shaping the prediction sets in a class-conditional manner is not straightforward and typically requires prior knowledge of the data distribution. In this work, we introduce Class Adaptive Conformal Training (CaCT), which formulates conformal training as an augmented Lagrangian optimization problem that adaptively learns to shape prediction sets class-conditionally without making any distributional assumptions. Experiments on multiple benchmark datasets, including standard and long-tailed image recognition as well as text classification, demonstrate that CaCT consistently outperforms prior conformal training methods, producing significantly smaller and more informative prediction sets while maintaining the desired coverage guarantees.

</details>


### [110] [Private LLM Inference on Consumer Blackwell GPUs: A Practical Guide for Cost-Effective Local Deployment in SMEs](https://arxiv.org/abs/2601.09527)
*Jonathan Knoop,Hendrik Holtmann*

Main category: cs.LG

TL;DR: 评估NVIDIA消费级Blackwell GPU（RTX 5060 Ti/5070 Ti/5090）在生产环境LLM推理中的表现，发现自托管推理成本比云API便宜40-200倍，消费级GPU可替代大多数SME工作负载的云推理。


<details>
  <summary>Details</summary>
Motivation: 中小企业面临云LLM API的数据隐私问题，专用云GPU实例隐私保障有限且持续成本高，专业级硬件（A100/H100）价格昂贵，需要评估消费级GPU作为替代方案的可行性。

Method: 系统评估NVIDIA Blackwell消费级GPU，在79种配置下测试4个开源模型（Qwen3-8B, Gemma3-12B, Gemma3-27B, GPT-OSS-20B），涵盖量化格式（BF16, W4A16, NVFP4, MXFP4）、上下文长度（8k-64k）和三种工作负载：RAG、多LoRA代理服务和API高并发。

Result: RTX 5090比5060 Ti吞吐量高3.5-4.6倍，RAG延迟降低21倍；预算GPU在API工作负载中实现最高吞吐量/美元比；NVFP4量化比BF16吞吐量提高1.6倍，能耗降低41%，质量损失仅2-4%；自托管推理成本$0.001-0.04/百万token，比云API便宜40-200倍。

Conclusion: 消费级GPU可可靠替代大多数中小企业工作负载的云推理，除延迟敏感的长上下文RAG仍需高端GPU；硬件在中等使用量（3000万token/天）下4个月内回本；提供部署指南和可复现的基准数据。

Abstract: SMEs increasingly seek alternatives to cloud LLM APIs, which raise data privacy concerns. Dedicated cloud GPU instances offer improved privacy but with limited guarantees and ongoing costs, while professional on-premise hardware (A100, H100) remains prohibitively expensive. We present a systematic evaluation of NVIDIA's Blackwell consumer GPUs (RTX 5060 Ti, 5070 Ti, 5090) for production LLM inference, benchmarking four open-weight models (Qwen3-8B, Gemma3-12B, Gemma3-27B, GPT-OSS-20B) across 79 configurations spanning quantization formats (BF16, W4A16, NVFP4, MXFP4), context lengths (8k-64k), and three workloads: RAG, multi-LoRA agentic serving, and high-concurrency APIs. The RTX 5090 delivers 3.5-4.6x higher throughput than the 5060 Ti with 21x lower latency for RAG, but budget GPUs achieve the highest throughput-per-dollar for API workloads with sub-second latency. NVFP4 quantization provides 1.6x throughput over BF16 with 41% energy reduction and only 2-4% quality loss. Self-hosted inference costs $0.001-0.04 per million tokens (electricity only), which is 40-200x cheaper than budget-tier cloud APIs, with hardware breaking even in under four months at moderate volume (30M tokens/day). Our results show that consumer GPUs can reliably replace cloud inference for most SME workloads, except latency-critical long-context RAG, where high-end GPUs remain essential. We provide deployment guidance and release all benchmark data for reproducible SME-scale deployments.

</details>


### [111] [Constraint- and Score-Based Nonlinear Granger Causality Discovery with Kernels](https://arxiv.org/abs/2601.09579)
*Fiona Murphy,Alessio Benavoli*

Main category: cs.LG

TL;DR: 该论文将两种核基格兰杰因果方法统一于核主成分回归框架，提出基于此的改进方法，并引入带平滑信息准则惩罚的高斯过程评分模型，提升了非线性因果发现性能，还提出了完全基于格兰杰因果的同期因果识别算法。


<details>
  <summary>Details</summary>
Motivation: 现有核基格兰杰因果方法虽然能识别非线性因果关系，但缺乏理论统一框架，且现有时间序列非线性因果发现方法性能有待提升，同时需要更好的同期因果识别算法。

Method: 1) 将两种先进核基格兰杰因果方法统一于核主成分回归框架；2) 提出基于该统一框架的改进方法；3) 引入带平滑信息准则惩罚的高斯过程评分模型；4) 提出完全基于格兰杰因果的同期因果识别算法。

Result: 提出的方法在非线性因果识别上优于现有最先进方法，且提出的同期因果识别算法在性能上可与现有最先进同期时间序列因果发现算法相媲美。

Conclusion: 通过理论统一核基格兰杰因果方法并引入新的高斯过程评分模型，显著提升了非线性因果发现性能，同时提出的同期因果识别算法为时间序列因果分析提供了有效工具。

Abstract: Kernel-based methods are used in the context of Granger Causality to enable the identification of nonlinear causal relationships between time series variables. In this paper, we show that two state of the art kernel-based Granger Causality (GC) approaches can be theoretically unified under the framework of Kernel Principal Component Regression (KPCR), and introduce a method based on this unification, demonstrating that this approach can improve causal identification. Additionally, we introduce a Gaussian Process score-based model with Smooth Information Criterion penalisation on the marginal likelihood, and demonstrate improved performance over existing state of the art time-series nonlinear causal discovery methods. Furthermore, we propose a contemporaneous causal identification algorithm, fully based on GC, using the proposed score-based $GP_{SIC}$ method, and compare its performance to a state of the art contemporaneous time series causal discovery algorithm.

</details>


### [112] [Energy-Entropy Regularization: The True Power of Minimal Looped Transformers](https://arxiv.org/abs/2601.09588)
*Wai-Lun Lam*

Main category: cs.LG

TL;DR: 提出基于Tsallis熵和哈密顿动力学的新训练框架，成功训练单头循环Transformer解决归纳头任务，揭示了其内部机制


<details>
  <summary>Details</summary>
Motivation: 当前单头循环Transformer在基准任务上训练经常失败或表现不佳，因为损失函数景观高度非凸且不规则，优化容易陷入局部极小值和鞍点。这些模型的内部机制仍不清楚，从头训练具有挑战性。

Method: 提出新颖的训练框架，利用Tsallis熵和哈密顿动力学来改变损失函数景观的几何形状。将参数更新视为物理流动，成功训练了模型维度d=8的单头循环Transformer，处理1000个token的输入序列。

Result: 成功训练单头循环Transformer解决归纳头任务，揭示了其优越推理能力背后的内部机制。

Conclusion: 通过Tsallis熵和哈密顿动力学改变损失函数景观几何形状的方法，能够有效训练单头循环Transformer，为理解其内部机制提供了新途径。

Abstract: Recent research suggests that looped Transformers have superior reasoning capabilities compared to standard deep architectures. Current approaches to training single-head looped architectures on benchmark tasks frequently fail or yield suboptimal performance due to a highly non-convex and irregular loss landscape. In these settings, optimization often stagnates in poor local minima and saddle points of the loss landscape, preventing the model from discovering the global minimum point. The internal mechanisms of these single-head looped transformer models remain poorly understood, and training them from scratch remains a significant challenge. In this paper, we propose a novel training framework that leverages Tsallis entropy and Hamiltonian dynamics to transform the geometry of the loss landscape. By treating the parameter updates as a physical flow, we successfully trained a single-head looped Transformer with model dimension $d = 8$ to solve induction head task with input sequence length of 1000 tokens. This success reveals the internal mechanism behind the superior reasoning capability.

</details>


### [113] [Toward Understanding Unlearning Difficulty: A Mechanistic Perspective and Circuit-Guided Difficulty Metric](https://arxiv.org/abs/2601.09624)
*Jiali Cheng,Ziheng Chen,Chirag Agarwal,Hadi Amiri*

Main category: cs.LG

TL;DR: 提出CUD（电路引导的遗忘难度）指标，通过模型电路信号预测样本遗忘难度，发现易遗忘样本与短浅电路相关，难遗忘样本与深层电路相关。


<details>
  <summary>Details</summary>
Motivation: 机器遗忘在构建可信赖和合规的语言模型中变得至关重要，但现有遗忘方法在不同样本上的效果差异很大。作者认为这种差异不仅源于数据侧，还反映了模型内部编码和保护记忆信息的机制。

Method: 从机制角度研究遗忘问题，基于模型电路（结构化交互路径）提出CUD指标。该指标使用电路级信号为每个样本分配连续难度分数，能够可靠区分内在易遗忘和难遗忘样本。

Result: CUD指标在不同遗忘方法中保持稳定。研究发现易遗忘样本与较短、较浅的电路相关，集中在模型的早期到中间部分；而难遗忘样本依赖于更长、更深的电路路径，更接近后期计算阶段。

Conclusion: CUD为遗忘难度分析提供了原则性、细粒度和可解释的方法，相比现有定性研究迈出了重要一步，并激励开发基于模型机制的遗忘方法。

Abstract: Machine unlearning is becoming essential for building trustworthy and compliant language models. Yet unlearning success varies considerably across individual samples: some are reliably erased, while others persist despite the same procedure. We argue that this disparity is not only a data-side phenomenon, but also reflects model-internal mechanisms that encode and protect memorized information. We study this problem from a mechanistic perspective based on model circuits--structured interaction pathways that govern how predictions are formed. We propose Circuit-guided Unlearning Difficulty (CUD), a {\em pre-unlearning} metric that assigns each sample a continuous difficulty score using circuit-level signals. Extensive experiments demonstrate that CUD reliably separates intrinsically easy and hard samples, and remains stable across unlearning methods. We identify key circuit-level patterns that reveal a mechanistic signature of difficulty: easy-to-unlearn samples are associated with shorter, shallower interactions concentrated in earlier-to-intermediate parts of the original model, whereas hard samples rely on longer and deeper pathways closer to late-stage computation. Compared to existing qualitative studies, CUD takes a first step toward a principled, fine-grained, and interpretable analysis of unlearning difficulty; and motivates the development of unlearning methods grounded in model mechanisms.

</details>


### [114] [From Prompt to Protocol: Fast Charging Batteries with Large Language Models](https://arxiv.org/abs/2601.09626)
*Ge Lei,Ferran Brosa Planella,Sterling G. Baird,Samuel J. Cooper*

Main category: cs.LG

TL;DR: LLM驱动的P2O和P2P方法优化电池充电协议，相比传统方法提升4.2%的健康状态，无需约束搜索空间


<details>
  <summary>Details</summary>
Motivation: 电池充电协议优化面临评估慢、成本高、不可微分的挑战，现有方法过度约束搜索空间限制了协议多样性，阻碍发现更高性能解决方案

Method: 提出两种无梯度LLM驱动闭环方法：P2O使用LLM生成小型神经网络协议代码并通过内循环训练；P2P直接编写电流函数及其标量参数

Result: LLM引导的P2O优于贝叶斯优化、进化算法和随机搜索设计的神经网络；在快速充电场景中，P2O和P2P相比最先进的多步恒流基线提升约4.2%的健康状态

Conclusion: LLM能够扩展协议函数形式空间，整合基于语言的约束，在实验成本高的环境中实现高效优化

Abstract: Efficiently optimizing battery charging protocols is challenging because each evaluation is slow, costly, and non-differentiable. Many existing approaches address this difficulty by heavily constraining the protocol search space, which limits the diversity of protocols that can be explored, preventing the discovery of higher-performing solutions. We introduce two gradient-free, LLM-driven closed-loop methods: Prompt-to-Optimizer (P2O), which uses an LLM to propose the code for small neural-network-based protocols, which are then trained by an inner loop, and Prompt-to-Protocol (P2P), which simply writes an explicit function for the current and its scalar parameters. Across our case studies, LLM-guided P2O outperforms neural networks designed by Bayesian optimization, evolutionary algorithms, and random search. In a realistic fast charging scenario, both P2O and P2P yield around a 4.2 percent improvement in state of health (capacity retention based health metric under fast charging cycling) over a state-of-the-art multi-step constant current (CC) baseline, with P2P achieving this under matched evaluation budgets (same number of protocol evaluations). These results demonstrate that LLMs can expand the space of protocol functional forms, incorporate language-based constraints, and enable efficient optimization in high cost experimental settings.

</details>


### [115] [Exploring Fine-Tuning for Tabular Foundation Models](https://arxiv.org/abs/2601.09654)
*Aditya Tanna,Pratinav Seth,Mohamed Bouadi,Vinay Kumar Sankarapu*

Main category: cs.LG

TL;DR: 对表格基础模型微调策略的首次全面研究，发现零样本性能已很强，微调效果因模型和数据而异，提供了何时微调的实用指南


<details>
  <summary>Details</summary>
Motivation: 虽然表格基础模型已展现出强大的上下文学习能力，但关于不同微调策略（零样本、元学习、全监督微调、参数高效微调）在表格数据上的效果缺乏系统性研究，需要了解微调何时真正有益

Method: 在TALENT、OpenML-CC18和TabZilla等基准测试上，全面比较了零样本、元学习、全监督微调（SFT）和参数高效微调（PEFT）四种策略，分析了数据不平衡、数据集大小和维度等因素对结果的影响

Result: 零样本TFMs已表现出很强性能，微调效果高度依赖模型和数据特性；元学习和PEFT在特定条件下提供适度提升，而全监督微调常降低准确率或校准质量；研究涵盖了性能、校准和公平性多个维度

Conclusion: 提供了关于表格基础模型微调的实用指南，明确了微调的局限性，指出微调并非总是有益，需要根据具体模型特性和数据特征谨慎选择微调策略

Abstract: Tabular Foundation Models (TFMs) have recently shown strong in-context learning capabilities on structured data, achieving zero-shot performance comparable to traditional machine learning methods. We find that zero-shot TFMs already achieve strong performance, while the benefits of fine-tuning are highly model and data-dependent. Meta-learning and PEFT provide moderate gains under specific conditions, whereas full supervised fine-tuning (SFT) often reduces accuracy or calibration quality. This work presents the first comprehensive study of fine-tuning in TFMs across benchmarks including TALENT, OpenML-CC18, and TabZilla. We compare Zero-Shot, Meta-Learning, Supervised (SFT), and parameter-efficient (PEFT) approaches, analyzing how dataset factors such as imbalance, size, and dimensionality affect outcomes. Our findings cover performance, calibration, and fairness, offering practical guidelines on when fine-tuning is most beneficial and its limitations.

</details>


### [116] [Disentangling Task Conflicts in Multi-Task LoRA via Orthogonal Gradient Projection](https://arxiv.org/abs/2601.09684)
*Ziyu Yang,Guibin Chen,Yuxin Yang,Aoxiong Zeng,Xiangquan Yang*

Main category: cs.LG

TL;DR: Ortho-LoRA：一种针对LoRA双分结构的梯度投影方法，通过将冲突任务梯度投影到正交补空间，有效缓解多任务学习中的负迁移问题。


<details>
  <summary>Details</summary>
Motivation: 多任务学习结合LoRA虽然能减少存储开销，但存在负迁移问题——不同任务的梯度更新相互冲突，导致性能下降。LoRA的低秩约束进一步限制了优化空间容纳多样化任务需求的能力。

Method: 提出Ortho-LoRA，专门针对LoRA的双分结构设计的梯度投影方法。该方法动态地将冲突任务梯度投影到彼此的正交补空间中，在LoRA固有子空间内实现梯度解耦。

Result: 在GLUE基准测试上的广泛实验表明，Ortho-LoRA有效缓解了任务干扰，优于标准联合训练，恢复了多任务与单任务基线之间95%的性能差距，且计算开销可忽略不计。

Conclusion: Ortho-LoRA为参数高效的多任务学习提供了一种有效的解决方案，通过梯度正交化机制解决了LoRA在多任务场景下的负迁移问题，实现了存储效率与性能的良好平衡。

Abstract: Multi-Task Learning (MTL) combined with Low-Rank Adaptation (LoRA) has emerged as a promising direction for parameter-efficient deployment of Large Language Models (LLMs). By sharing a single adapter across multiple tasks, one can significantly reduce storage overhead. However, this approach suffers from negative transfer, where conflicting gradient updates from distinct tasks degrade the performance of individual tasks compared to single-task fine-tuning. This problem is exacerbated in LoRA due to the low-rank constraint, which limits the optimization landscape's capacity to accommodate diverse task requirements. In this paper, we propose Ortho-LoRA, a gradient projection method specifically tailored for the bipartite structure of LoRA. Ortho-LoRA dynamically projects conflicting task gradients onto the orthogonal complement of each other within the intrinsic LoRA subspace. Extensive experiments on the GLUE benchmark demonstrate that Ortho-LoRA effectively mitigates task interference, outperforming standard joint training and recovering 95\% of the performance gap between multi-task and single-task baselines with negligible computational overhead.

</details>


### [117] [Contrastive Geometric Learning Unlocks Unified Structure- and Ligand-Based Drug Design](https://arxiv.org/abs/2601.09693)
*Lisa Schneckenreiter,Sohvi Luukkonen,Lukas Friedrich,Daniel Kuhn,Günter Klambauer*

Main category: cs.LG

TL;DR: ConGLUDe是一个统一的对比几何模型，通过结合结构基础和配体基础的训练方法，在无需预定义结合位点的情况下，实现虚拟筛选、靶点预测和配体条件口袋选择。


<details>
  <summary>Details</summary>
Motivation: 传统的结构基础和配体基础计算药物设计方法使用不同的数据源和建模假设，限制了它们的大规模联合使用。需要一种统一的方法来整合这两种方法。

Method: ConGLUDe结合了几何蛋白质编码器（生成全蛋白表示和预测结合位点的隐式嵌入）与快速配体编码器。通过对比学习将配体与全局蛋白质表示和多个候选结合位点对齐，支持联合训练蛋白质-配体复合物和大规模生物活性数据。

Result: 在多种基准测试中，ConGLUDe在无需结合口袋输入的情况下实现了最先进的零样本虚拟筛选性能，在具有挑战性的靶点预测任务上显著优于现有方法，并在配体条件口袋选择方面表现出竞争力。

Conclusion: 统一的结构-配体训练具有优势，ConGLUDe是朝着药物发现通用基础模型迈出的一步。

Abstract: Structure-based and ligand-based computational drug design have traditionally relied on disjoint data sources and modeling assumptions, limiting their joint use at scale. In this work, we introduce Contrastive Geometric Learning for Unified Computational Drug Design (ConGLUDe), a single contrastive geometric model that unifies structure- and ligand-based training. ConGLUDe couples a geometric protein encoder that produces whole-protein representations and implicit embeddings of predicted binding sites with a fast ligand encoder, removing the need for pre-defined pockets. By aligning ligands with both global protein representations and multiple candidate binding sites through contrastive learning, ConGLUDe supports ligand-conditioned pocket prediction in addition to virtual screening and target fishing, while being trained jointly on protein-ligand complexes and large-scale bioactivity data. Across diverse benchmarks, ConGLUDe achieves state-of-the-art zero-shot virtual screening performance in settings where no binding pocket information is provided as input, substantially outperforms existing methods on a challenging target fishing task, and demonstrates competitive ligand-conditioned pocket selection. These results highlight the advantages of unified structure-ligand training and position ConGLUDe as a step toward general-purpose foundation models for drug discovery.

</details>
