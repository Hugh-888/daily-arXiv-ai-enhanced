<div id=toc></div>

# Table of Contents

- [quant-ph](#quant-ph) [Total: 55]
- [gr-qc](#gr-qc) [Total: 20]
- [physics.comp-ph](#physics.comp-ph) [Total: 2]
- [cs.LG](#cs.LG) [Total: 93]


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [1] [Relational Emergent Time for Quantum System: A Multi-Observer, Gravitational, and Cosmological Framework](https://arxiv.org/abs/2512.15789)
*Amir Hossein Ghasemi*

Main category: quant-ph

TL;DR: 该论文提出了一种关系性框架，其中时间结构并非基本存在，而是从全局稳态量子态的内部关联中涌现出来。每个子系统包含一个内部时钟，条件态相对于这些内部读数有效演化。该框架自然扩展到相对论运动、引力红移和宇宙膨胀，产生了一个适用于不同物理体系的统一涌现时间函数。


<details>
  <summary>Details</summary>
Motivation: 传统物理学将时间视为基本维度，但该研究试图从更基础的量子关联角度理解时间的本质。作者希望建立一个框架，其中时间不是基本实体，而是从量子系统的内部关联中涌现出来的现象，从而统一处理经典时间膨胀、引力效应和宇宙膨胀等问题。

Method: 采用关系性框架，假设存在全局稳态量子态，其中每个子系统包含内部时钟。通过分析子系统之间的量子关联，推导出条件态相对于内部时钟读数的演化。该方法扩展到相对论运动、引力红移和宇宙膨胀情况，构建统一的涌现时间函数。

Result: 该理论成功再现了经典时间膨胀效应，并预测了关联依赖的偏离标准演化的现象。特别指出非相互作用或质量为零的粒子表现出可忽略的内部时间。框架预测高度纠缠系统会出现可测量的偏离标准量子演化，且质量为零粒子的内部时间可以忽略。

Conclusion: 时间可以从量子关联中涌现，而非基本存在。这一关系性框架为时间物理学基础提供了新的研究方向，包括多时钟量子系统、精密计量学和宇宙学设置。预测的现象为实验验证提供了可能，特别是在高度纠缠系统和质量为零粒子方面。

Abstract: We present a relational framework in which temporal structure is not fundamental but emerges from correlations within a globally stationary quantum state. Each subsystem includes an internal clock, and conditional states evolve effectively with respect to these internal readings. The construction naturally extends to relativistic motion, gravitational redshift, and cosmological expansion, leading to a unified emergent-time functional valid across diverse physical regimes. The theory reproduces classical time dilation, predicts correlation-dependent deviations from standard evolution, and suggests that non-interacting or massless particles exhibit negligible internal time. These consequences open directions for conceptual and experimental investigations in the foundations of temporal physics, from multi-clock quantum systems to precision metrology and cosmological settings. In particular, the framework suggests measurable deviation from standard quantum evolution for highly entangled systems and predicts negligible internal time for massless particles.

</details>


### [2] [Geometric Latent Space Tomography with Metric-Preserving Autoencoders](https://arxiv.org/abs/2512.15801)
*S. M. Yousuf Iqbal Tomal,Abdullah Al Shafin*

Main category: quant-ph

TL;DR: 提出几何潜在空间量子层析成像，结合经典神经网络编码器和参数化量子电路解码器，通过保持度规的损失函数在潜在欧氏距离与量子Bures测地线之间建立比例关系，实现高保真度量子态重建并保留量子度量结构。


<details>
  <summary>Details</summary>
Motivation: 传统量子态层析面临系统尺寸指数级扩展问题，而现有神经网络方法虽然实现多项式扩展，但失去了量子态空间的几何结构。需要一种既能高效重建又能保持量子几何结构的方法。

Method: 结合经典神经网络编码器和参数化量子电路解码器，通过度规保持损失函数训练，强制潜在欧氏距离与量子Bures测地线成比例。在纯度0.85-0.95的两量子比特混合态上进行验证。

Result: 实现高保真度重建（平均保真度F=0.942±0.03），潜在测地线与Bures距离强线性相关（Pearson r=0.88，R²=0.78），保留78%量子度量结构。发现内在流形维度为6.35（环境维度20），具有可测量局部曲率（κ=0.011±0.006）。

Conclusion: 几何感知潜在空间量子层析相比传统方法具有O(d²)计算优势，支持直接态判别、基于欧氏距离的保真度估计和可解释误差流形，为NISQ设备提供关键能力，无需重复完整层析。

Abstract: Quantum state tomography faces exponential scaling with system size, while recent neural network approaches achieve polynomial scaling at the cost of losing the geometric structure of quantum state space. We introduce geometric latent space tomography, combining classical neural encoders with parameterized quantum circuit decoders trained via a metric-preservation loss that enforces proportionality between latent Euclidean distances and quantum Bures geodesics. On two-qubit mixed states with purity 0.85--0.95 representing NISQ-era decoherence, we achieve high-fidelity reconstruction (mean fidelity $F = 0.942 \pm 0.03$) with an interpretable 20-dimensional latent structure. Critically, latent geodesics exhibit strong linear correlation with Bures distances (Pearson $r = 0.88$, $R^2 = 0.78$), preserving 78\% of quantum metric structure. Geometric analysis reveals intrinsic manifold dimension 6.35 versus 20 ambient dimensions and measurable local curvature ($κ= 0.011 \pm 0.006$), confirming non-trivial Riemannian geometry with $O(d^2)$ computational advantage over $O(4^n)$ density matrix operations. Unlike prior neural tomography, our geometry-aware latent space enables direct state discrimination, fidelity estimation from Euclidean distances, and interpretable error manifolds for quantum error mitigation without repeated full tomography, providing critical capabilities for NISQ devices with limited coherence times.

</details>


### [3] [Optimization Techniques in Quantum Information](https://arxiv.org/abs/2512.15831)
*Benjamin Desef*

Main category: quant-ph

TL;DR: 开发了PolynomialOptimization.jl软件包，用于多项式优化问题，特别针对量子信息领域，通过混合传统非凸和凸方法解决复杂问题，展示了在纠缠分布问题中的应用。


<details>
  <summary>Details</summary>
Motivation: 多项式优化问题在量子信息等领域自然出现，但现有软件框架已成为瓶颈，无法充分利用硬件和算法进展，需要更高效的中间层和算法来减少问题规模。

Method: 开发了PolynomialOptimization.jl开源软件包，提供资源高效的中间层，支持复数和非负定约束，包含多种算法减少问题规模，采用混合传统非凸和凸方法，并开发了计算非负定矩阵内点障碍的新方法。

Result: 软件包成功应用于纠缠分布问题，即使涉及三到四位数大小的半正定矩阵松弛也能方便求解，新开发的内点障碍计算方法有潜力进一步减少资源消耗。

Conclusion: 该论文通过开发PolynomialOptimization.jl软件包填补了多项式优化软件框架的空白，为量子信息等领域的复杂优化问题提供了高效解决方案，混合方法和新算法显著提升了问题求解能力。

Abstract: This thesis focuses on the intersection of mathematical and computational optimization and quantum information. Main contributions are open-source software code: A hybrid approach mixing "traditional" nonconvex and convex methods can make difficult problems more accessible. A demonstration of how to efficiently implement such an algorithm, avoiding interfacial bottlenecks, is provided, finding optimal protocols to establish entanglement through a lossy channel. The central software package developed addresses polynomial optimization problems. Many problems naturally involve only a polynomial objective and constraint polynomials. Such problems can automatically be cast into semidefinite programs that provide a hierarchy of outer approximations. The resulting problems are often so large and scale so unfavorably with respect to the variable number and degree involved that the boundary of the doable is reached quickly. However, technical progress both in hardware and algorithms has pushed this boundary - but software frameworks for polynomial optimization have not followed in the same manner, often now making them the bottleneck that before was the solver. The package PolynomialOptimization.jl developed during this thesis aims to fill the gap and provide a very resource-efficient intermediate layer together with a wide number of algorithms to reduce the problem size, and naturally supporting complex numbers and semidefinite constraints ubiquitous in quantum information problems. Its application on an entanglement distribution problem is demonstrated, showing that even relaxations with semidefinite matrices of three- and four-digit size can be solved conveniently. Finally, a new way to calculate interior-point barriers for the cone of sums-of-squares matrices in a nearly time-optimal way is developed, whose efficient implementation has the potential of further reducing resource consumption.

</details>


### [4] [Low-Latency FPGA Control System for Real-Time Neural Network Processing in CCD-Based Trapped-Ion Qubit Measurement](https://arxiv.org/abs/2512.15838)
*Binglei Lou,Gautham Duddi Krishnaswaroop,Filip Wojcicki,Ruilin Wu,Richard Rademacher,Zhiqiang Que,Wayne Luk,Philip H. W. Leong*

Main category: quant-ph

TL;DR: 该研究比较了基于FPGA和GPU的DNN量子比特检测系统在延迟性能上的差异，发现FPGA方案能实现纳秒级推理延迟，相比GPU有100倍以上的加速。


<details>
  <summary>Details</summary>
Motivation: 虽然深度神经网络已被用于提高量子比特检测的保真度，但它们在特定硬件平台上的延迟性能尚未得到充分探索。准确且低延迟的量子比特状态测量对于离子阱量子计算至关重要。

Method: 在FPGA和GPU上部署多层感知机（MLP）和视觉变换器（ViT）模型进行量子比特检测性能评估。FPGA方案直接连接EMCCD与数据处理逻辑，而GPU系统使用高速PCIe图像采集卡作为基线。

Result: 相比传统阈值方法，DNN将平均测量保真度误差降低了1.8-2.5倍（单量子比特）和4.2-7.6倍（三量子比特）。FPGA上的MLP和ViT分别实现纳秒级和微秒级推理延迟，完整单次测量过程比GPU实现快100倍以上。

Conclusion: FPGA方案在量子比特检测中展现出显著的低延迟优势，时钟周期级信号分析揭示了Cameralink接口的传输效率问题，优化该接口可进一步发挥超低延迟DNN推理的优势，指导下一代量子比特检测系统开发。

Abstract: Accurate and low-latency qubit state measurement is critical for trapped-ion quantum computing. While deep neural networks (DNNs) have been integrated to enhance detection fidelity, their latency performance on specific hardware platforms remains underexplored. This work benchmarks the latency of DNN-based qubit detection on field-programmable gate arrays (FPGAs) and graphics processing units (GPUs). The FPGA solution directly interfaces an electron-multiplying charge-coupled device (EMCCD) with the subsequent data processing logic, eliminating buffering and interface overheads. As a baseline, the GPU-based system employs a high-speed PCIe image grabber for image input and I/O card for state output. We deploy Multilayer Perceptron (MLP) and Vision Transformer (ViT) models on hardware to evaluate measurement performance. Compared to conventional thresholding, DNNs reduce the mean measurement fidelity (MMF) error by factors of 1.8-2.5x (one-qubit case) and 4.2-7.6x (three-qubit case). FPGA-based MLP and ViT achieve nanosecond- and microsecond-scale inference latencies, while the complete single-shot measurement process achieves over 100x speedup compared to the GPU implementation. Additionally, clock-cycle-level signal analysis reveals inefficiencies in EMCCD data transmission via Cameralink, suggesting that optimizing this interface could further leverage the advantages of ultra-low-latency DNN inference, guiding the development of next-generation qubit detection systems.

</details>


### [5] [Efficient Simulation of Sparse, Non-Local Fermion Models](https://arxiv.org/abs/2512.15843)
*Reinis Irmejs,J. Ignacio Cirac*

Main category: quant-ph

TL;DR: 提出一种通过引入辅助费米子来消除Jordan-Wigner弦的编码方案，使得稀疏费米子模型的量子模拟电路深度达到渐近最优，将之前的乘法对数开销降低为加法开销。


<details>
  <summary>Details</summary>
Motivation: 费米子系统模拟是近期量子计算机的关键应用，但将费米子算符编码到量子比特硬件时存在开销问题，特别是Jordan-Wigner弦带来的电路深度开销限制了模拟效率。

Method: 为每个物理费米子模式引入少量辅助费米子，构建一种新的编码方案，能够消除Jordan-Wigner弦。虽然辅助费米子状态的制备需要初始开销，但该状态在时间演化中保持不变。

Result: 实现了渐近最优的电路深度，将之前的O(log N)乘法开销降低为加法开销。稀疏费米子模型在量子比特硬件上的模拟性能与理想费米子硬件相当，仅需常数因子和O(dN)辅助量子比特。

Conclusion: 通过引入辅助费米子的编码方案，显著提升了稀疏费米子模型在量子比特硬件上的模拟效率，为近期量子计算机上的费米子系统模拟提供了实用解决方案。

Abstract: Efficient simulation of interacting fermionic systems is a key application of near-term quantum computers, but is hindered by the overhead required to encode fermionic operators on qubit hardware. Here, we consider models with $N$ fermionic modes in which each participates in at most a constant number $d$ of interactions and study the circuit depth required to implement the Trotterized time evolution on qubit hardware with all-to-all connectivity. We introduce an encoding that augments each physical fermionic mode with a small number of auxiliary fermions, enabling the removal of Jordan--Wigner strings. Although the preparation of the auxiliary fermion state incurs an initial overhead, this state remains invariant under time evolution. As a result, long-time evolution can be implemented with asymptotically optimal circuit depth, reducing a previously multiplicative $O(\log N)$ overhead to an additive overhead. Our results thus establish that the simulation of sparse fermionic models on qubit hardware matches the performance achievable on ideal fermionic hardware up to constant factors and $O(dN)$ ancillary qubits.

</details>


### [6] [Solvable Quantum Circuits from Spacetime Lattices](https://arxiv.org/abs/2512.15871)
*Michael A. Rampp,Suhail A. Rather,Pieter W. Claeys*

Main category: quant-ph

TL;DR: 论文提出"完全可约电路"框架，扩展了双幺正电路，在更一般晶格几何中实现精确可解的非可积量子多体动力学，通过信息流模式解析刻画纠缠膜和算符增长。


<details>
  <summary>Details</summary>
Motivation: 双幺正电路及其多幺正推广虽然提供了精确可解但混沌的量子多体动力学模型，但缺乏对多幺正动力学可解性的系统理解。需要建立一个更广泛的框架来统一这些模型。

Method: 提出"完全可约电路"框架，这些电路在全局上打破双幺正性但在局部保持，允许更丰富的现象学。通过信息流模式分析纠缠线张力，将可解性与信息流无结特性联系起来，并与Kauffman括号作为结不变量建立联系。

Result: 构建了支持四和五个信息流方向的电路实例，推导了纠缠线张力与时空信息流模式的一般表达式。证明了可解性与信息流无结特性相关，并将纠缠线张力的曲率解释为信息传输密度。

Conclusion: 完全可约电路为精确可解的多体量子混沌模型提供了新的统一框架，包含并扩展了已知构造，将纠缠动力学与信息流拓扑特性联系起来。

Abstract: In recent years dual-unitary circuits and their multi-unitary generalizations have emerged as exactly solvable yet chaotic models of quantum many-body dynamics. However, a systematic picture for the solvability of multi-unitary dynamics remains missing. We present a framework encompassing a large class of such non-integrable models with exactly solvable dynamics, which we term \emph{completely reducible} circuits. In these circuits, the entanglement membrane determining operator growth and entanglement dynamics can be characterized analytically. Completely reducible circuits extend the notion of space-time symmetry to more general lattice geometries, breaking dual-unitarity globally but not locally, and allow for a rich phenomenology going beyond dual-unitarity. As example, we introduce circuits that support four and five directions of information flow. We derive a general expression for the entanglement line tension in terms of the pattern of information flow in spacetime. The solvability is shown to be related to the absence of knots of this information flow, connecting entanglement dynamics to the Kauffman bracket as knot invariant. Building on these results, we propose that in general non-integrable dynamics the curvature of the entanglement line tension can be interpreted as a density of information transport. Our results provide a new and unified framework for exactly solvable models of many-body quantum chaos, encompassing and extending known constructions.

</details>


### [7] [On the power of moving quantum sensors: fully flexible and noise-resilient sensing](https://arxiv.org/abs/2512.15876)
*Paul Aigner,Wolfgang Dür*

Main category: quant-ph

TL;DR: 移动量子传感器通过轨迹或内部状态控制，可选择性测量空间相关标量场的任意线性泛函（如梯度或傅里叶系数），同时完全消除正交空间相关的噪声，性能超越静态传感器网络。


<details>
  <summary>Details</summary>
Motivation: 传统量子传感器网络虽然能测量空间相关场，但噪声抑制能力受限于传感器数量，且静态传感器存在T^2的基本极限。需要探索移动传感器是否能突破这些限制。

Method: 使用单个移动量子传感器，通过控制其运动轨迹或内部量子状态，实现对空间相关标量场的选择性测量。该方法可测量任意线性泛函，同时利用正交性原理消除所有空间相关噪声。

Result: 移动传感器能够完全消除所有正交空间相关的噪声信号，这一能力超越了由多个纠缠但位置固定的传感器组成的网络。量子费希尔信息可实现超越静态传感器T^2基本极限的改进标度。

Conclusion: 单个移动量子传感器在测量空间相关标量场方面具有显著优势，不仅能选择性测量任意线性泛函并完全消除正交噪声，还能突破静态传感器的量子测量极限，为量子传感技术开辟了新方向。

Abstract: We show that a single moving quantum sensor provides complete access to spatially correlated scalar fields. We demonstrate that with either trajectory or internal state control, one can selectively measure any linear functional, e.g. a gradient or a spatial Fourier series coefficient, while successfully eliminating {\it all} noise signals with orthogonal spatial correlation. This even exceeds the capabilities of a sensor network consisting of multiple entangled, yet spatially fixed, quantum sensors, where the number of suppressed noise signals is limited by the number of sensor positions. We show that one can achieve an improved scaling of the quantum Fisher information for moving sensors beyond the static fundamental limit of $T^2$.

</details>


### [8] [Anticoncentration and State Design of Doped Real Clifford Circuits and Tensor Networks](https://arxiv.org/abs/2512.15880)
*Beatrice Magni,Markus Heinrich,Lorenzo Leone,Xhek Turkeshi*

Main category: quant-ph

TL;DR: 论文研究了掺杂魔法态和虚数资源的正交/实Clifford电路的统计特性，发现了新的普适类别——正交Clifford Porter-Thomas分布，并揭示了资源需求的层次结构。


<details>
  <summary>Details</summary>
Motivation: 研究正交Clifford电路在掺杂魔法态和虚数资源后的统计特性，探索不同资源对量子电路统计行为的影响，特别是理解从Clifford统计到Haar统计的过渡。

Method: 开发了实Clifford群的Weingarten微积分，推导了实稳定子态的确切重叠分布，分析了局部实架构在对数深度下的全局统计恢复，并比较了不同资源需求。

Result: 发现了新的普适类别——正交Clifford Porter-Thomas分布；证明了局部实架构在对数深度内恢复全局统计；揭示了资源需求的尖锐层次：恢复Haar统计需要多对数数量的魔法态，而恢复完整酉Clifford统计仅需单个相位门。

Conclusion: 正交Clifford电路掺杂资源后展现出独特的统计特性，形成了新的普适类别，资源需求存在明确的层次结构，为理解量子电路从Clifford到Haar统计的过渡提供了新见解。

Abstract: We investigate the statistical properties of orthogonal, or real, Clifford circuits doped with magic and imaginary resources. By developing the Weingarten calculus for the real Clifford group, we derive the exact overlap distribution of real stabilizer states, identifying a new universality class: the orthogonal Clifford Porter-Thomas distribution. We prove that local real architectures recover this global statistic in logarithmic depth. Furthermore, we uncover a sharp hierarchy in resource requirements: while retrieving Haar statistics necessitates a polylogarithmic amount of magic states, recovering the full unitary Clifford statistics requires only a single phase gate.

</details>


### [9] [Noncooperative Quantum Networks](https://arxiv.org/abs/2512.15884)
*Yanxuan Shao,Jannik L. Wyss,Don Towsley,Adilson E. Motter*

Main category: quant-ph

TL;DR: 量子通信网络中，增加纠缠资源反而可能降低最终纠缠保真度，这是非合作LOCC协议中的反直觉现象


<details>
  <summary>Details</summary>
Motivation: 现有量子通信协议通常假设初始分配纠缠资源，并通过LOCC操作建立远距离高保真纠缠。传统观点认为保真度会随纠缠资源增加而单调提高，但本文挑战这一假设

Method: 研究非合作LOCC协议在非纯态网络中的行为，分析增加纠缠资源对最终保真度的影响机制

Result: 发现在非合作LOCC协议中，当网络处于非纯态时，增加纠缠资源反而可能导致最终保真度下降，这是量子版本的"自私路由"效应

Conclusion: 量子网络中资源增加不一定带来性能提升，非合作行为可能导致反直觉的保真度下降，这对大规模量子网络资源优化使用构成潜在障碍

Abstract: Existing protocols for quantum communication networks usually assume an initial allocation of quantum entanglement resources, which are then manipulated through local operations and classical communication (LOCC) to establish high-fidelity entanglement between distant parties. It is generally held that the resulting fidelity would increase monotonically with the entanglement budget. Here, we show that for noncooperative LOCC protocols, the resulting fidelity may decrease as more entanglement is added to a network with non-pure states. This effect results from a quantum analog of selfish routing and constitutes a potential obstacle to the optimal use of resources in large quantum networks.

</details>


### [10] [Deflating quantum error-correcting codes](https://arxiv.org/abs/2512.15887)
*Jaron Skovsted Gundersen,Rene Bødker Christensen,Petar Popovski,Rafał Wisniewski*

Main category: quant-ph

TL;DR: 提出了一种称为"放气"的量子稳定子码长度缩减技术，这是对经典穿刺和缩短技术的推广，可控制参数并获得比连续应用穿刺和缩短更好的结果。


<details>
  <summary>Details</summary>
Motivation: 现有量子码长度缩减技术（穿刺和缩短）在移除多个量子比特时存在局限性，需要更通用的方法来控制量子码参数并获得更好的性能。

Method: 提出"放气"技术，作为穿刺和缩短技术的推广，适用于移除多个量子比特的情况。该方法提供了额外的自由度，允许更精细地控制量子码参数。

Result: 放气技术能够控制量子码参数，相比连续应用穿刺和缩短能获得更好的参数。该方法对经典线性码的效果不如量子码显著。

Conclusion: 放气技术是量子码长度缩减的有效方法，提供了比传统穿刺和缩短技术更大的灵活性和更好的参数控制能力。

Abstract: In this work, we introduce a technique for reducing the length of a quantum stabilizer code, and we call this deflation of the code. Deflation can be seen as a generalization of the well-known puncturing and shortening techniques in cases where more than a single qudit is removed. We show that the parameters of the deflated quantum code can be controlled, and argue that a similar approach is not as beneficial when applied to classical linear codes. Furthermore, it is shown that deflation introduces additional freedom compared to applying just puncturing and shortening consecutively. We exemplify that it is possible to obtain better parameters by deflating a code rather than consecutively using puncturing and shortening.

</details>


### [11] [Quantum Algorithms for Photoreactivity in Cancer-Targeted Photosensitizers](https://arxiv.org/abs/2512.15889)
*Yanbing Zhou,Pablo A. M. Casares,Diksha Dhawan,Ignacio Loaiza,Soran Jahangiri,Robert A. Lang,Juan Miguel Arrazola,Stepan Fomichev*

Main category: quant-ph

TL;DR: 量子算法用于光动力疗法光敏剂设计：通过量子计算模拟BODIPY衍生物的光吸收和系间窜越性能，为高效光敏剂筛选提供新方法。


<details>
  <summary>Details</summary>
Motivation: 光动力疗法（PDT）需要具有强光敏性和高活性氧生成效率的光敏剂，但传统计算方法在准确性和可扩展性方面存在局限，难以精确模拟复杂的光敏剂系统。

Method: 开发容错量子算法：1）使用阈值投影算法计算治疗窗口内的累积吸收以量化光敏感性；2）采用演化代理方法估计系间窜越（ISC）速率，辅以振动动力学处理，评估活性氧生成效率。

Result: 将算法应用于临床相关的BODIPY衍生物（包括重原子和过渡金属取代系统），资源估算显示需要180-350个逻辑量子比特和10^7-10^9的Toffoli门深度，表明算法在现实容错量子设备上可行。

Conclusion: 量子算法为光敏剂设计提供了高效的工作流程，有望加速新型PDT药物的发现，将量子计算应用于药物设计领域。

Abstract: Photodynamic therapy (PDT) is a targeted cancer treatment that uses light-activated photosensitizers to generate reactive oxygen species that selectively destroy tumor cells, generally causing less collateral damage than conventional treatments. However, its clinical success hinges on the availability of photosensitizers with strong optical sensitivity and high efficiency in generating reactive oxygen species. While classical computational methods have provided useful insights into photosensitizer design, they struggle to scale and often lack the accuracy needed for these simulations. In this work, we show how fault-tolerant quantum algorithms can be used to identify promising photosensitizer candidates for PDT. To predict photosensitizer performance, we assess two computational properties. First, we quantify light sensitivity by calculating the cumulative absorption in the therapeutic window with a threshold projection algorithm. Second, we determine the efficiency of reactive oxygen generation by estimating intersystem crossing (ISC) rates using the evolution-proxy approach, complemented by a vibronic dynamic treatment where appropriate. We apply these algorithms to a clinically relevant and actively pursued class of photosensitizers, BODIPY derivatives, including heavy-atom and transition-metal-substituted systems that are challenging for classical methods. Our resource estimates, obtained with PennyLane, suggest that systems with active spaces ranging from 11 to 45 spatial orbitals can be simulated using $180$-$350$ logical qubits and Toffoli gate depths between $10^7$ and $10^9$, placing our algorithms within reach of realistic fault-tolerant quantum devices. This paves the way to an efficient quantum-based workflow for designing photosensitizers that can accelerate the discovery of new PDT agents.

</details>


### [12] [Universal and Maximal Entanglement Swapping in General Fermionic Gaussian States](https://arxiv.org/abs/2512.15890)
*Jiyuan Fang,Qicheng Tang,Xueda Wen*

Main category: quant-ph

TL;DR: 在费米子高斯态中，通过投影贝尔测量实现最大纠缠交换的普适机制


<details>
  <summary>Details</summary>
Motivation: 探索多体系统中的普适纠缠结构，特别是在系统经历非幺正操作时，这是一个基础且具有挑战性的问题。研究费米子系统中的测量诱导纠缠现象。

Method: 考虑两个初始解耦的半填充自由费米子系统（任意维度），对两个副本中对应位置的一半位点进行后选择贝尔测量。推导后测量态的确切形式，并通过数值模拟进行一致性检验。

Result: 后测量态可分解为贝尔对的乘积，建立了与初始高斯态完全无关的最大层间纠缠。这种现象源于费米子统计与高斯性之间的稳健相互作用。

Conclusion: 揭示了费米子系统中实现测量诱导最大纠缠的普适机制，展示了费米子统计与高斯性相互作用产生的独特纠缠路径。

Abstract: Exploring universal entanglement structure in many-body systems is both fundamental and challenging, particularly when the system undergoes non-unitary operations. In this work, we uncover a universal mechanism for realizing maximal entanglement swapping in fermionic Gaussian states subjected to projective Bell measurements. We consider two initially decoupled, half-filled copies of a free-fermion system in arbitrary dimensions and perform post-selective Bell measurements on half of the corresponding sites across the two copies. Remarkably, the post-measurement state factorizes into a product of Bell pairs, establishing maximal interlayer entanglement entirely independent of the initial Gaussian state. We derive this post-measurement state exactly for general particle-number-conserving fermionic Gaussian states, establishing both the validity and universality of the mechanism, with numerical simulations serving as consistency checks. This phenomenon arises from a robust interplay between fermionic statistics and Gaussianity, revealing a distinct fermionic route to measurement-induced maximal entanglement.

</details>


### [13] [Closed-Form Optimal Quantum Circuits for Single-Query Identification of Boolean Functions](https://arxiv.org/abs/2512.15901)
*Leonardo Bohac*

Main category: quant-ph

TL;DR: 提出了一种针对单比特布尔函数的最小误差识别方案，通过显式构造的量子电路实现最优成功概率3/4，并探讨了最优查询识别在电路层面的可构造性问题。


<details>
  <summary>Details</summary>
Motivation: 研究在仅允许一次查询的情况下，如何对未知单比特布尔函数进行最小误差识别。超越抽象的最优测量，寻求完全可构造的解决方案，为理论到硬件的转换提供基础。

Method: 给出显式的状态准备和测量酉操作，构建低深度、固定门集的量子电路。在最小设置下，输入状态无需纠缠。通过计算基读取实现Helstrom最优成功概率3/4。

Result: 成功构建了显式量子电路，实现了区分四种可能函数的最优成功概率3/4。该电路具有低深度、固定门集的特点，在最小设置中无需纠缠输入状态。

Conclusion: 展示了在特定参数下，最优预言机判别不仅理论定义清晰，而且可实现为显式电路级原语。这为更大规模的最优查询识别问题提供了构造性思路，对理论到硬件的转换和物理意义明确的"预言机访问"形式有重要价值。

Abstract: We study minimum-error identification of an unknown single-bit Boolean function given black-box (oracle) access with one allowed query. Rather than stopping at an abstract optimal measurement, we give a fully constructive solution: an explicit state preparation and an explicit measurement unitary whose computational-basis readout achieves the Helstrom-optimal success probability 3/4 for distinguishing the four possible functions. The resulting circuit is low depth, uses a fixed gate set, and (in this smallest setting) requires no entanglement in the input state. Beyond the specific example, the main message is operational. It highlights a regime in which optimal oracle discrimination is not only well-defined but implementably explicit: the optimal POVM collapses to a compact gate-level primitive that can be compiled, verified, and composed inside larger routines. Motivated by this, we discuss a "what if" question that is open in spirit: for fixed (n,m,k), could optimal k-query identification (possibly for large hypothesis classes) admit deterministic, closed-form descriptions of the inter-query unitaries and the final measurement unitary acting on the natural n+m-qubit input--output registers (and, if needed, small work registers)? Even when such descriptions are not compact and do not evade known circuit-complexity barriers for generic Boolean functions, making the optimum constructive at the circuit level would be valuable for theory-to-hardware translation and for clarifying which forms of "oracle access" are physically meaningful.

</details>


### [14] [Resource-resolved quantum fluctuation theorems in end-point measurement scheme](https://arxiv.org/abs/2512.15928)
*Sukrut Mondkar,Sayan Mondal,Ujjwal Sen*

Main category: quant-ph

TL;DR: 该论文提出了一个统一框架，将量子资源（非热性、相干性和纠缠）纳入涨落定理，推导了广义Jarzynski等式和Crooks型涨落关系，并引入了相干性和纠缠涨落距离来量化量子资源的热力学相关性。


<details>
  <summary>Details</summary>
Motivation: 涨落定理为非平衡能量和熵涨落提供了普适约束，使其成为评估量子资源如何以及在何种程度上变得热力学相关的自然框架。然而，现有框架未能系统地将各种量子资源纳入涨落定理分析。

Method: 采用端点测量方案，避免初始能量测量，允许初始态中的量子资源影响非平衡能量统计。推导了量子涨落定理家族，包括广义Jarzynski等式和Crooks型涨落关系，其中修正项分解为资源分辨的贡献。对于单系统，引入非热性权重和相干性权重概念；对于二分系统，使用附加相关算子和最佳可分离近似分别获得纠缠分辨的涨落定理。

Result: 建立了统一的量子资源涨落定理框架，能够分离不同量子资源（非热性、相干性、纠缠）的热力学效应。引入了相干性和纠缠涨落距离作为Kullback-Leibler散度，以过程依赖和操作性的方式量化量子资源的热力学相关性。

Conclusion: 该工作为将量子资源系统纳入涨落定理提供了统一框架，能够量化量子资源在非平衡热力学过程中的作用，为量子热力学和量子资源理论建立了重要联系。

Abstract: Fluctuation theorems provide universal constraints on nonequilibrium energy and entropy fluctuations, making them a natural framework to assess how and to what extent quantum resources become thermodynamically relevant. We develop a unified framework for incorporating a generic quantum resource, including athermality, quantum coherence, and entanglement, into fluctuation theorems. We work within the end point measurement scheme, which avoids an initial energy measurement and allows quantum resources in the initial state to affect nonequilibrium energy statistics. We derive a family of quantum fluctuation theorems, including generalized Jarzynski equalities and Crooks type fluctuation relations, in which corrections decompose into resource resolved contributions. For single systems, we introduce the concept of weight of athermality, and combine it with the weight of coherence to isolate distinct thermodynamic effects of these quantum resources. For bipartite systems, we furthermore obtain two families of entanglement-resolved fluctuation theorems using an appended correlation operator and the best separable approximation, respectively. Finally, we introduce the concepts of coherence and entanglement fluctuation distances, as Kullback Leibler divergences, which quantify the thermodynamic relevance of quantum resources in a process-dependent and operational manner.

</details>


### [15] [A Dough-Like Model for Understanding Double-Slit Phenomena](https://arxiv.org/abs/2512.15932)
*Ping-Rui Tsai,Tzay-Ming Hong*

Main category: quant-ph

TL;DR: 论文提出基于深度学习的双缝衍射替代模型，用可拉伸面团类比解释量子叠加和测量坍缩，试图统一干涉、纠缠和隧穿现象。


<details>
  <summary>Details</summary>
Motivation: 双缝实验中的概率干涉条纹展示了量子叠加原理，但也暴露了测量前后系统关系的概念挑战。量子力学基于系综统计而非单个实体，单粒子行为尤其神秘，需要更直观的物理解释。

Method: 引入基于深度学习的双缝衍射替代模型，捕捉波函数与概率分布之间的映射关系。模型探索多个潜在传播路径，使用梯度下降自适应选择最优传输通道，形成网络信息主干。

Result: 提出面团类比：粒子像可拉伸面团，同时穿过两个狭缝，传输后重新连接，在屏障前可分离。蒙特卡洛模拟证实该框架能自然重现特征干涉和衍射概率模式。

Conclusion: 该方法为量子叠加和测量诱导坍缩提供了新颖、物理可解释的视角。面团类比有望扩展到其他量子现象，并试图统一干涉、纠缠和隧穿为同一基础现象的表现。

Abstract: The probabilistic interference fringes observed in the double slit experiment vividly demonstrate the quantum superposition principle, yet they also highlight a fundamental conceptual challenge: the relationship between a system before and after the measurement. According to Copenhagen interpretation, an unobserved quantum system evolves continuously based on the Schrodinger equation, whereas observation induces an instantaneous collapse of the wave function to an eigenstate. This contrast between continuous evolution and sudden collapse renders the single particle behavior particularly enigmatic, especially given that quantum mechanics itself is constructed upon the statistical behavior of ensembles rather than individual entities. In this study, we introduce a Double Slit Diffraction Surrogate Model DSM based on deep learning, designed to capture the mapping between wave functions and probability distributions. The DSM explores multiple potential propagation paths and adaptively selects optimal transmission channels using gradient descent, forming a backbone for the information through the network. By comparing the interpretability of paths and interference, we propose an intuitive physical analogy: the particle behaves like a stretchable dough, extending across both slits, reconnecting after transmission, allowing detachment before the barrier. Monte Carlo simulations confirm that this framework can naturally reproduce the characteristic interference and diffraction probability patterns. Our approach offers a novel, physically interpretable perspective on quantum superposition and measurement induced collapse. The dough analogy is expected to extend to other quantum phenomena. Finally, we provide a dough based picture, attempting to unify interference, entanglement, and tunneling as manifestations of the same underlying phenomenon.

</details>


### [16] [AC Stark effect or time-dependent Aharonov-Bohm effect for particle on a ring](https://arxiv.org/abs/2512.15935)
*Patrick Hinrichs,Douglas Singleton,Nader Inan*

Main category: quant-ph

TL;DR: 研究环形约束量子粒子在时变螺线管矢势下的效应，类似于时变Aharonov-Bohm效应但非严格AB效应，与交流斯塔克效应相似但机制不同


<details>
  <summary>Details</summary>
Motivation: 探索时变矢势对环形约束量子粒子的影响，研究这种类似时变Aharonov-Bohm效应但非严格AB效应的物理现象，并与标准交流斯塔克效应进行比较

Method: 研究量子粒子在环形约束下受时变螺线管矢势作用的系统，分析其动力学行为，特别关注矢势产生的时变电场效应

Result: 发现该效应产生可观测的准能边带，可通过光谱学检测，效应机制与交流斯塔克效应相似但来源于矢势而非标势

Conclusion: 该时变矢势效应提供了一种新的量子调控机制，与标准交流斯塔克效应在物理起源上不同但产生相似的可观测现象，为量子系统操控提供了新途径

Abstract: We study the effect of a time-varying solenoidal vector potential for a quantum particle confined to a ring. The setup appears to be a time-varying version of the Aharonov-Bohm effect, but since the particle moves in the presence of fields, it is not strictly an Aharonov-Bohm effect. The results are similar to the ac Stark effect, but with a time-varying electric field coming from the vector potential, rather than the scalar potential. We compare and contrast the present effect with the standard ac Stark effect. The signature of this setup is the generation of quasi-energy sidebands which are observable via spectroscopy.

</details>


### [17] [Random coding for long-range continuous-variable QKD](https://arxiv.org/abs/2512.15990)
*Arpan Akash Ray,Boris Skoric*

Main category: quant-ph

TL;DR: 提出了一种适用于长距离高斯调制连续变量量子密钥分发的随机码本纠错方法，使用似然比评分和基于阈值的块拒绝机制，具有高度并行化特性，在保守计算资源假设下可实现至少8%的Devetak-Winter值的实时密钥率。


<details>
  <summary>Details</summary>
Motivation: 连续变量量子密钥分发(CVQKD)虽然与标准电信设备兼容，但在长距离传输时面临极低的信噪比，需要大量人工纠错工作，且实时实现纠错解码具有挑战性。

Method: 引入随机码本纠错方法，采用似然比评分和基于阈值的块拒绝机制。为证明技术原因，接受/拒绝决策以加密形式通信，避免在泄漏分析中处理非高斯态。该方法具有高度并行化特性。

Result: 在保守计算资源假设下，预测可实现至少8%的Devetak-Winter值的实时密钥率，优于现有的协调方案。

Conclusion: 提出的随机码本纠错方法适用于长距离高斯调制CVQKD，具有高度并行化优势，能够实现比现有方案更好的实时密钥率性能。

Abstract: Quantum Key Distribution (QKD) schemes are key exchange protocols based on the physical properties of quantum channels. They avoid the computational-hardness assumptions that underlie the security of classical key exchange. Continuous-Variable QKD (CVQKD), in contrast to qubit-based discrete-variable (DV) schemes, makes use of quadrature measurements of the electromagnetic field. CVQKD has the advantage of being compatible with standard telecom equipment, but at long distances has to deal with very low signal to noise ratios, which necessitates labour-intensive error correction. It is challenging to implement the error correction decoding in realtime.
  In this paper we introduce a random-codebook error correction method that is suitable for long range Gaussian-modulated CVQKD. We use likelihood ratio scoring with block rejection based on thresholding. For proof-technical reasons, the accept/reject decisions are communicated in encrypted form; in this way we avoid having to deal with non-Gaussian states in the analysis of the leakage. The error correction method is highly parallelisable, which is advantageous for realtime implementation. Under conservative assumptions on the computational resources, we predict a realtime key ratio of at least 8% of the Devetak-Winter value, which outperforms existing reconciliation schemes.

</details>


### [18] [Stationary two-qubit entanglement mediated by one-dimensional plasmonic nanoarrays](https://arxiv.org/abs/2512.16016)
*Luke C. Ugwuoke,Tjaart P. J. Krüger,Mark S. Tame*

Main category: quant-ph

TL;DR: 研究金属纳米颗粒阵列对量子点量子比特间纠缠的远程等离子体介导作用，发现奇数个纳米颗粒阵列能更有效地维持纠缠


<details>
  <summary>Details</summary>
Motivation: 探索如何通过金属纳米颗粒阵列实现量子点量子比特之间的远程纠缠，以支持独立空间光学探测的可能性

Method: 采用满足弱耦合近似的共线周期性金属纳米颗粒阵列，在腔量子电动力学框架内建立有效模型，研究单粒子共振频率下的弱驱动条件

Result: 奇数个纳米颗粒阵列对纠缠衰减更具鲁棒性，能维持超过1微米间距的非零稳态纠缠，这归因于杂化偶极等离子体与驱动频率共振产生的强量子比特间耗散耦合

Conclusion: 奇数个金属纳米颗粒阵列能有效介导远程量子纠缠，为实现量子点的独立空间光学探测开辟了可能性

Abstract: Entanglement is one of the key measures of quantum correlations present in nanophotonic systems, with promising applications in quantum optics and beyond. Previous studies have shown that the degree of entanglement between two quantum dot qubits is preserved when a metal nanoparticle is used to mediate the interactions between the qubits. In this work, we investigate long-range plasmonic mediation of qubit--qubit entanglement by studying the impact of the number of mediating metal nanoparticles on stationary concurrence. Collinear and periodically spaced metal nanoparticles that satisfy the weak-coupling approximation are considered. An effective model that enables the derivation of the mediated interactions within the framework of cavity quantum electrodynamics is employed. Under weak driving at the single particle resonance frequency, the model shows that odd-number arrays are more robust to entanglement decay. We attribute this to strong inter-qubit dissipative coupling as a result of a hybridized dipole plasmon resonating with the driving frequency in odd-number arrays. These arrays can sustain non-vanishing stationary entanglement beyond an inter-qubit spacing of one micron, opening up the possibility of independent spatial optical probing of each quantum dot.

</details>


### [19] [Silicon T centre hyperfine structure and memory protection schemes](https://arxiv.org/abs/2512.16047)
*Nicholas Brunelle,Joshua Kanaganayagam,Mehdi Keshavarz,Chloe Clear,Oney Soykal,Myles Ruether,Adam DeAbreu,Amirhossein AlizadehKhaledi,Yihuang Xiong,Nikolay V. Abrosimov,Geoffroy Hautier,Michael Thewalt,Stephanie Simmons,Daniel Higginbottom*

Main category: quant-ph

TL;DR: 本文研究了硅中T中心自旋-光子界面的氢超精细耦合张量，并提出了在光学激发期间保护氢记忆量子比特免受退相干和弛豫的方案。


<details>
  <summary>Details</summary>
Motivation: 自旋-光子界面是实现网络化量子计算和长距离量子通信的关键平台。T中心作为硅平台上的自旋-光子界面，具有电信O波段发射特性，可直接与硅纳米光子学集成。其电子和核自旋量子比特分别作为通信和记忆量子比特，但需要保护记忆量子比特在通信量子比特纠缠操作期间免受退相干影响。

Method: 确定了T中心的氢超精细耦合张量，并引入了两种方案：1) 保护氢记忆量子比特免受退相干的方案；2) 消除光学激发期间氢记忆量子比特弛豫的方案。

Result: 获得了T中心氢超精细耦合张量的具体参数，并提出了有效的保护方案来维持氢记忆量子比特的相干性，解决了T中心量子网络实际应用中的关键挑战。

Conclusion: 这项工作为硅基T中心量子网络的实用化提供了重要进展，通过确定超精细耦合张量和设计保护方案，解决了记忆量子比特在纠缠操作期间的退相干问题，推动了基于硅平台的自旋-光子界面在量子网络中的应用。

Abstract: Combining the long-coherence of spin qubits and the capability to transmit information and entanglement through photons, spin-photon interfaces (SPIs) are a promising platform for networked quantum computation and long-distance quantum communication. SPIs that possess local `memory' qubits in addition to the optically coupled `communication' qubit can improve remote entanglement fidelities through brokered entanglement schemes and entanglement purification. In these schemes, it is critical to protect the memory qubit from decoherence during entanglement operations on the communications qubit. Silicon, a platform with mature microelectronic and nanophotonic fabrication, is host to the T centre, an SPI with emission in the telecommunications O-band that directly integrates with silicon nanophotonics. Cavity-coupled T centres are a platform for brokered entanglement distribution in silicon photonic circuits and over long-distance optical fibre links. The T centre's electron and nuclear spin qubits are an intrinsic register of communication and memory qubits respectively, with anisotropic hyperfine coupling. In this work we determine the T centre's hydrogen hyperfine coupling tensor. We also introduce schemes to protect against dephasing or eliminate relaxation of the T centre's hydrogen memory qubit during optical excitation. These results address a key challenge for practical T centre quantum networks.

</details>


### [20] [Discrete time crystals enhanced by Stark potentials in Rydberg atom arrays](https://arxiv.org/abs/2512.16097)
*Jian-Jia Wang,Ling-Zhi Tang,Yan-Xiong Du,Dan-Wei Zhang*

Main category: quant-ph

TL;DR: 提出在周期性驱动的里德堡原子阵列中实现无无序离散时间晶体的实验方案，利用线性势增强时间晶体序，无需无序诱导的多体局域化。


<details>
  <summary>Details</summary>
Motivation: 大多数离散时间晶体相通过无序诱导的多体局域化来稳定，但这种方法需要无序平均和特殊状态制备。本文旨在探索无需无序的离散时间晶体实现方案。

Method: 提出在周期性驱动的里德堡原子阵列中使用线性势（斯塔克势）来增强离散时间晶体序，通过数值模拟验证该方案的有效性。

Result: 数值模拟显示斯塔克势增强了离散时间晶体对翻转缺陷的鲁棒性，延长了其寿命，且这些特性与初始状态无关。

Conclusion: 该方案为在里德堡原子阵列中探索离散时间晶体提供了一种有前景的方法，无需无序平均和特殊状态制备。

Abstract: Discrete time crystals (DTCs) are non-equilibrium phases in periodically driven systems that exhibit spontaneous breaking of discrete time-translation symmetry. The stabilization of most DTC phases is achieved via the disorder-induced many-body localization. In this work, we propose an experimental scheme to realize disorder-free DTCs in a periodically driven Rydberg atom array. Our scheme utilizes a linear potential in the atomic detuning to enhance the DTC order, without being tired to (Stark) many-body localization. We numerically demonstrate that the Stark potential enhances the robustness of the DTC against the flip imperfections and extends its lifetime, which are independent of initial states. Thus, our scheme provides a promising way to explore DTCs in Rydberg atom arrays without disorder averaging and special state preparation.

</details>


### [21] [Analyzing the performance of CV-MDI QKD under continuous-mode scenarios](https://arxiv.org/abs/2512.16114)
*Yanhao Sun,Ziyang Chen,Xiangyu Wang,Song Yu,Hong Guo*

Main category: quant-ph

TL;DR: CV-MDI QKD中连续模式场景下，Bob端模式失配比Alice端对传输距离影响更严重，需要严格预校准时间模式特性


<details>
  <summary>Details</summary>
Motivation: 连续变量测量设备无关量子密钥分发（CV-MDI QKD）可以解决QKD系统检测侧的漏洞，但在高速系统中，频谱展宽导致贝尔测量偏离理想单模场景，造成模式失配、性能下降和安全受损

Method: 引入时间模式（TMs）来分析连续模式场景下CV-MDI QKD的性能，研究Bob传输模式与贝尔测量模式之间的失配效应

Result: Bob端的模式失配比Alice端对系统性能影响更显著：当贝尔接收器靠近Bob且失配仅为5%时，传输距离从87.96km急剧下降到18.50km；而Alice端相同失配仅降至86.83km。在15km传输距离下，时间模式特性失配导致密钥率降低83%

Conclusion: 在涉及连续模式干扰的场景中（如大规模MDI网络设置），必须仔细考虑每个用户的时间模式特性，严格预校准这些模式对于确保系统可靠性和效率至关重要

Abstract: Continuous-variable measurement-device-independent quantum key distribution (CV-MDI QKD) can address vulnerabilities on the detection side of a QKD system. The core of this protocol involves continuous-variable Bell measurements performed by an untrusted third party. However, in high-speed systems, spectrum broadening causes Bell measurements to deviate from the ideal single-mode scenario, resulting in mode mismatches, reduced performance, and compromised security. Here, we introduce temporal modes (TMs) to analyze the performance of CV-MDI QKD under continuous-mode scenarios. The mismatch between Bob's transmitting mode and Bell measurement mode has a more significant effect on system performance compared to that on Alice's side. When the Bell receiver is close to Bob and the mismatch is set to just 5%, the transmission distance drastically decreases from 87.96 km to 18.50 km. In comparison, the same mismatch for Alice reduces the distance to 86.83 km. This greater degradation on Bob's side can be attributed to the asymmetry in the data modification step. Furthermore, the mismatch in TM characteristics leads to a significant reduction in the secret key rate by 83% when the transmission distance is set to 15 km, which severely limits the practical usability of the protocol over specific distances. These results indicate that in scenarios involving continuous-mode interference, such as large-scale MDI network setups, careful consideration of each user's TM characteristics is crucial. Rigorous pre-calibration of these modes is essential to ensure the system's reliability and efficiency.

</details>


### [22] [Antisymmetrization of composite fermionic states for quantum simulations of nuclear reactions in first-quantization mapping](https://arxiv.org/abs/2512.16138)
*Ionel Stetcu*

Main category: quant-ph

TL;DR: 提出一种一阶量子化确定性算法，用于反对称化空间分离的目标-弹子系统，系统包含N_T和N_p个全同费米子。算法使用Dicke态辅助寄存器编码子系统间的单粒子交换通道，仅需单粒子交换操作即可生成完全反对称波函数。


<details>
  <summary>Details</summary>
Motivation: 在反应和散射模拟中，需要处理空间分离的费米子系统（如目标-弹子系统）的反对称化问题。传统方法在处理这类系统时存在可扩展性限制，需要开发更高效的量子算法来扩展可处理系统的范围。

Method: 算法从两个独立反对称化的多体态（可以是Slater行列式的叠加）的乘积出发，构建完全反对称波函数。使用Dicke态辅助寄存器相干编码两个子系统间的所有单粒子交换通道，关键是通过单粒子交换操作生成完全反对称结构。需要O(N_T N_p)次单粒子交换操作，其中最多N_p个可以并行执行（使用额外N_p个辅助比特）。通过应用Z门在N_T个辅助比特上引入正确的费米子相位，然后使用紧凑的受控操作序列高效解除辅助寄存器的计算。

Result: 该算法为反应和散射模拟中的完全反对称态制备提供了非平凡且可扩展的协议，显著扩展了一阶量子化量子算法能够处理的系统范围。算法复杂度为O(N_T N_p)，具有并行化潜力。

Conclusion: 提出的确定性算法能够高效反对称化空间分离的费米子系统，仅需单粒子交换操作，为量子计算中的反应和散射模拟提供了重要的工具，扩展了一阶量子化方法的应用范围。

Abstract: I present a first-quantization deterministic algorithm for antisymmetrizing a spatially separated target-projectile system containing $N_T$ and $N_p$ identical fermions, respectively. The method constructs a fully antisymmetric wavefunction from the product of two independently antisymmetrized many-body states, each of which may be a superposition of Slater determinants. The algorithm uses a Dicke-state ancilla register that coherently encodes all one-particle exchange channels between the two subsystems, and, crucially, requires only single-particle swaps to generate the full antisymmetric structure. A total of $O(N_T N_p)$ single-particle exchanges are needed, with up to $N_p$ of them implemented in parallel, if an additional $N_p$ ancillae are used. The correct fermionic phase is incorporated through application of $Z$ gates on $N_T$ ancillae, after which the ancilla register is efficiently uncomputed using a compact sequence of controlled operations. This construction provides a nontrivial and scalable protocol for preparing fully antisymmetric states in reaction and scattering simulations, significantly expanding the range of systems that can be addressed with first-quantized quantum algorithms.

</details>


### [23] [Tunneling in double-well potentials within stochastic quantization: Application to ammonia inversion](https://arxiv.org/abs/2512.16168)
*Danilo F. Schafaschek,Giovani L. Vasconcelos,Antônio M. S. Macêdo*

Main category: quant-ph

TL;DR: 使用随机量子化方法研究双势阱中束缚态的隧穿时间统计，推导出平均隧穿时间与量子力学隧穿时间的直接关系，并应用于氨分子反转动力学


<details>
  <summary>Details</summary>
Motivation: 随机量子化为量子现象提供了基于扩散过程的替代框架，能够研究标准量子力学中不易定义的动力学量，特别是隧穿时间统计问题

Method: 采用随机量子化框架，结合首达时间理论计算隧穿时间统计量，通过数值模拟验证理论预测，对平方双势阱推导解析表达式，并进行WKB分析

Result: 建立了随机力学隧穿时间与量子力学隧穿时间的直接关系：τ_QM = (π/2)τ̄，在氨分子应用中预测的反转频率约24GHz与实验观测一致

Conclusion: 随机量子化是分析量子系统隧穿现象的强大且物理直观的框架，能够提供传统量子力学难以获得的动力学洞察

Abstract: Stochastic quantization - introduced by Nelson in 1966 - describes quantum behavior as a conservative diffusion process in which a particle undergoes Brownian-like motion with a fluctuation amplitude set by Planck's constant. While it fully reproduces conventional quantum mechanics, this approach provides an alternative framework that enables the study of dynamical quantities not easily defined within the standard formulation. In the present work, stochastic quantization is employed to investigate tunneling-time statistics for bound states in double-well potentials. Using first-passage time theory within the stochastic quantization framework, both the mean tunneling time, $\barτ$, and the full probability distribution, $p(τ)$, are computed, and the theoretical predictions are validated through extensive numerical simulations of stochastic trajectories for the two potentials considered as representative cases. For the square double-well potential, analytical expressions for $\barτ$ are derived and show excellent agreement with simulations. In the high-barrier limit, the results reveal a direct relation between the stochastic-mechanical and quantum-mechanical tunneling times, expressed as $τ_{\mathrm{QM}} = (π/2)\barτ$, where $τ_{\mathrm{QM}}$ corresponds to half the oscillation period of the probability of finding the particle in either well. This relation is further confirmed for generic double-well systems through a WKB analysis. As a concrete application, the inversion dynamics of the ammonia molecule is analyzed, yielding an inversion frequency of approximately $24$ GHz, in close agreement with experimental observations. These results highlight the potential of stochastic quantization as a powerful and physically insightful framework for analyzing tunneling phenomena in quantum systems.

</details>


### [24] [Optimizing Quantum Data Embeddings for Ligand-Based Virtual Screening](https://arxiv.org/abs/2512.16177)
*Junggu Choi,Tak Hur,Seokhoon Jeong,Kyle L. Jung,Jun Bae Park,Junho Lee,Jae U. Jung,Daniel K. Park*

Main category: quant-ph

TL;DR: 量子数据嵌入方法在配体虚拟筛选中优于经典基线，特别是在数据有限的情况下


<details>
  <summary>Details</summary>
Motivation: 探索量子数据嵌入策略如何改进配体虚拟筛选任务，开发量子-经典混合嵌入方法以生成更具表达力的分子表示

Method: 开发了一系列量子-经典混合嵌入方法，将经典神经网络与参数化量子电路以不同方式结合，在两个不同规模的基准数据集（LIT-PCBA和COVID-19）上进行评估

Result: 在多个生物靶点和类别不平衡设置下，多种量子和混合嵌入变体始终优于经典基线，特别是在数据有限的情况下表现突出

Conclusion: 优化的量子数据嵌入有望成为配体虚拟筛选的数据高效工具

Abstract: Effective molecular representations are essential for ligand-based virtual screening. We investigate how quantum data embedding strategies can improve this task by developing and evaluating a family of quantum-classical hybrid embedding approaches. These approaches combine classical neural networks with parameterized quantum circuits in different ways to generate expressive molecular representations and are assessed across two benchmark datasets of different sizes: the LIT-PCBA and COVID-19 collections. Across multiple biological targets and class-imbalance settings, several quantum and hybrid embedding variants consistently outperform classical baselines, especially in limited-data regimes. These results highlight the potential of optimized quantum data embeddings as data-efficient tools for ligand-based virtual screening.

</details>


### [25] [Entropy Stability and Spectral Concentration under Convex Block Constraints](https://arxiv.org/abs/2512.16192)
*Hassan Nasreddine*

Main category: quant-ph

TL;DR: 论文研究了量子态在凸块对角约束下的熵最小化问题，证明了定量稳定性定理：若某态在固定块约束下的熵与最小值相差ε，则其在迹范数下距离熵最小化流形为O(ε^{1/2})，且该速率最优。


<details>
  <summary>Details</summary>
Motivation: 研究量子态在凸块对角约束下的熵最小化问题，旨在理解熵最小化态的稳定性特性，为量子信息理论提供基础分析工具。

Method: 采用纯有限维分析方法，基于熵的经典与内部分量精确分解，结合尖锐的相对熵不等式，推导出定量稳定性结果。

Result: 证明了最优的定量稳定性定理：熵与最小值的偏差ε对应迹范数距离为O(ε^{1/2})，并将该框架应用于有限加性算子的谱约束，得到诱导谱测度的定量非集中界。

Conclusion: 该研究建立了线性谱约束下熵最小化态的一般稳定性原理，提供了一个独立于算术输入的抽象框架，具有广泛的理论应用价值。

Abstract: We investigate entropy minimization problems for quantum states subject to convex block-diagonal constraints. Our principal result is a quantitative stability theorem: if a state has entropy within epsilon of the minimum possible value under a fixed block constraint, then it must lie within O(epsilon^{1/2}) in trace norm of the manifold of entropy minimizers. We show that this rate is optimal. The analysis is entirely finite-dimensional and relies on a precise decomposition of entropy into classical and internal components, together with sharp relative entropy inequalities. As an application, we study finite additive operators whose spectral decomposition induces natural block constraints. In this setting, the stability theorem yields quantitative non-concentration bounds for induced spectral measures. The framework is abstract and independent of arithmetic input. It provides a general stability principle for entropy minimizers under linear spectral constraints.

</details>


### [26] [Near-Infrared Quantum Emission from Oxygen-Related Defects in hBN](https://arxiv.org/abs/2512.16197)
*Sean Doan,Sahil D. Patel,Yilin Chen,Jordan A. Gusdorff. Mark E. Turiansky,Luis Villagomez,Luka Jevremovic,Nicholas Lewis,Kenji Watanabe,Takashi Taniguchi,Lee C. Bassett,Chris Van de Walle,Galan Moody*

Main category: quant-ph

TL;DR: 氧等离子体处理在hBN中产生近红外单光子发射器，具有高亮度、室温工作、窄线宽等优异特性，为量子网络提供理想平台。


<details>
  <summary>Details</summary>
Motivation: hBN中的色心是量子通信和量子网络的理想平台，但现有色心存在声子边带宽、发射不稳定或波长不合适等问题，需要开发性能更优的量子发射器。

Method: 采用简单可扩展的氧等离子体处理工艺，在hBN中可重复地制造氧相关单量子发射器；通过非共振激发测量发射特性，结合第一性原理计算识别可能的氧相关缺陷构型。

Result: 成功制备出覆盖700-960nm近红外光谱的无闪烁零声子线发射器，具有室温工作、高亮度、低温下几GHz的超窄线宽等优异特性，声子边带分析显示弱电子-声子耦合和主导的零声子线发射。

Conclusion: 氧等离子体处理的hBN量子发射器为不可区分的近红外单光子提供了有前景的平台，适用于自由空间量子网络应用。

Abstract: Color centers hosted in hexagonal boron nitride (hBN) have emerged as a promising platform for single-photon emission and coherent spin-photon interfaces that underpin quantum communication and quantum networking technologies. As a wide-bandgap van der Waals material, hBN can host individual optically active quantum defects emitting across the ultraviolet to visible spectrum, but existing color centers often show broad phonon sidebands (PSBs), unstable emission, or inconvenient wavelengths. Here, we show a simple, scalable oxygen-plasma process that reproducibly creates oxygen-related single quantum emitters in hBN with blinking-free zero-phonon lines spanning the near-infrared (NIR) spectrum from 700-960 nanometers. These emitters demonstrate room-temperature operation, high brightness, and ultra-sharp cryogenic linewidths in the few-gigahertz range under non-resonant excitation. Analysis of the PSBs shows weak electron-phonon coupling and predominant zero-phonon-line emission, while first-principles calculations identify plausible oxygen-related defect configurations. These emitters provide a promising platform for indistinguishable NIR single photons towards free-space quantum networking.

</details>


### [27] [Amplifying Decoherence-Free Many-Body Interactions with Giant Atoms Coupled to Parametric Waveguide](https://arxiv.org/abs/2512.16232)
*Xin Wang,Zhao-Min Gao*

Main category: quant-ph

TL;DR: 该论文提出了一种结合巨原子与行波参量波导的新量子平台，通过利用不同耦合点间的相消干涉，不仅显著增强了巨原子间的相互作用，还使其对压缩噪声免疫，为量子模拟提供了可扩展的稳健平台。


<details>
  <summary>Details</summary>
Motivation: 传统参量放大虽然能通过场压缩增强量子相互作用，但通常引入额外噪声加速量子退相干，限制了可扩展量子信息处理。压缩场通常在腔中实现而非连续波导，限制了量子模拟的可扩展性。

Method: 将压缩放大相互作用扩展到结合巨原子与基于χ(2)非线性的行波参量波导的新量子平台。通过利用不同耦合点间的相消干涉，使巨原子间的相互作用对压缩噪声免疫。

Result: 巨原子不仅表现出交换相互作用，还表现出配对相互作用，这些相互作用的强度可以通过调整压缩和耦合参数平滑调节。该平台特别适合模拟多体量子物理。

Conclusion: 该架构为强关联物理的量子模拟提供了多功能且可扩展的平台，为多体体系中的稳健量子控制铺平了道路。

Abstract: Parametric amplification offers a powerful means to enhance quantum interactions through field squeezing, yet it typically introduces additional noise which accelerates quantum decoherence, a major obstacle for scalable quantum information processing. The squeezing field is implemented in cavities rather than continuous waveguides, thereby limiting its scalability for applications in quantum simulation. Giant atoms, which couple to waveguides at multiple points, provide a promising route to mitigate dissipation via engineered interference, enabling decoherence-free interactions. We extend the squeezing-amplified interaction to a novel quantum platform combining giant atoms with traveling-wave parametric waveguides based on $χ^{(2)}$ nonlinearity. By exploiting destructive interference between different coupling points, the interaction between giant atoms is not only significantly enhanced but also becomes immune to squeezed noise. Unlike conventional waveguide quantum electrodynamics without a squeezing pump, the giant emitters exhibit both exchange and pairing interactions, making this platform particularly suitable for simulating many-body quantum physics. More intriguingly, the strengths of these interactions can be smoothly tuned by adjusting the squeezing and coupling parameters. Our architecture thus provides a versatile and scalable platform for quantum simulation of strongly correlated physics and paves the way toward robust quantum control in many-body regimes.

</details>


### [28] [Self-testing GHZ state via a Hardy-type paradox](https://arxiv.org/abs/2512.16242)
*Smritikana Patra,Soumyajit Pal,Ranendu Adhikary*

Main category: quant-ph

TL;DR: 提出基于Hardy非定域性论证推广的GHZ态自测试协议，证明达到最大Hardy成功概率的关联是量子关联集的暴露点，并建立与Mermin不等式最大违反的统一视角。


<details>
  <summary>Details</summary>
Motivation: 自测试框架能够在不假设设备内部结构的情况下认证量子态和测量。本研究旨在为GHZ态开发基于Hardy非定域性论证推广的自测试协议，探索多体量子关联的暴露性特征。

Method: 1. 提出基于Hardy非定域性论证自然推广的GHZ态自测试协议；2. 证明达到最大Hardy成功概率的关联是量子关联集的暴露点；3. 针对实验不完美性开发鲁棒的自测试分析；4. 建立Hardy型悖论与Mermin不等式最大违反之间的对应关系。

Result: 1. 证明了达到最大Hardy成功概率的关联构成量子关联集的暴露点；2. 开发了针对Hardy构造的鲁棒自测试分析；3. 发现Hardy型悖论最大违反与Mermin不等式最大违反对应同一多体关联；4. 建立了逻辑悖论解释与Bell不等式表征的统一视角。

Conclusion: 该工作为GHZ态提供了基于Hardy论证的自测试协议，揭示了量子关联的暴露性特征，建立了不同非定域性表征的统一框架，为研究N体Hardy悖论最大违反关联的暴露性奠定了基础。

Abstract: Self-testing is a correlation-based framework that enables the certification of both the underlying quantum state and the implemented measurements without imposing any assumptions on the internal structure of the devices. In this work, we introduce a self-testing protocol for the Greenberger-Horne-Zeilinger (GHZ) state based on a natural generalization of Hardy's nonlocality argument. Within this framework, we prove that the correlation achieving the maximal Hardy success probability constitutes an extremal point of the quantum correlation set and, moreover, that this point is \emph{exposed}. To address experimentally relevant imperfections, we further develop a robust self-testing analysis tailored to the Hardy construction. Additionally, we show that, in this scenario, the quantum correlation that attains the maximal violation of the Hardy-type paradox coincides with the correlation that yields the maximal violation of the Mermin inequality. This establishes a unified perspective in which the same multipartite correlation admits both a logical-paradox interpretation and a Bell-inequality-based characterization. Collectively, our results pave the way for investigating whether the correlations that maximally violate the generalized $N$-party Hardy paradox remain exposed in higher-party regimes.

</details>


### [29] [Prefix Sums via Kronecker Products](https://arxiv.org/abs/2512.16309)
*Aleksandros Sobczyk,Anastasios Zouzias*

Main category: quant-ph

TL;DR: 该论文通过线性代数视角重新审视前缀和问题，提出了一种新的电路设计方法，实现了零缺陷、常数扇出和小于2log(n)深度的三重优化，并应用于量子加法器设计。


<details>
  <summary>Details</summary>
Motivation: 重新审视前缀和问题，通过线性代数方法寻找更优的电路设计，特别是要同时实现零缺陷、常数扇出和更小的深度这三个传统上难以兼顾的特性。

Method: 利用线性代数工具，提出将三角全1矩阵分解为两个Kronecker积之和的恒等式，基于此设计递归的前缀和算法和电路结构。

Result: 提出的电路家族首次同时实现了：(1)零缺陷，(2)每层常数扇出，(3)深度严格小于2log(n)。应用于量子加法器设计，实现了1.893log(n)+O(1)的Toffoli深度、O(n)个Toffoli门和O(n)个额外量子比特。

Conclusion: 通过线性代数方法重新审视前缀和问题，获得了同时满足多重优化目标的电路设计，显著改进了现有量子加法器的性能，为相关计算问题提供了新的设计思路。

Abstract: In this work, we revisit prefix sums through the lens of linear algebra. We describe an identity that decomposes triangular all-ones matrices as a sum of two Kronecker products, and apply it to design recursive prefix sum algorithms and circuits. Notably, the proposed family of circuits is the first one that achieves the following three properties simultaneously: (i) zero-deficiency, (ii) constant fan-out per-level, and (iii) depth that is asymptotically strictly smaller than $2\log(n)$ for input length n. As an application, we show how to use these circuits to design quantum adders with $1.893\log(n) + O(1)$ Toffoli depth, $O(n)$ Toffoli gates, and $O(n)$ additional qubits, improving the Toffoli depth and/or Toffoli size of existing constructions.

</details>


### [30] [Feedback Cooling and Thermometry of a Single Trapped Ion Using a Knife Edge](https://arxiv.org/abs/2512.16368)
*Hans Dang,Sebastian Luff,Martin Fischer,Markus Sondermann,Gerd Leuchs*

Main category: quant-ph

TL;DR: 首次实现单囚禁离子的反馈冷却至低于多普勒极限，通过实时运动监测和电子反馈将离子冷却至多普勒冷却温度的1/9以下


<details>
  <summary>Details</summary>
Motivation: 突破传统多普勒冷却极限，实现更低的离子温度，为量子精密测量和量子计算提供更好的基础条件

Method: 使用刀边成像实时监测离子荧光，通过荧光强度调制生成反馈信号，利用抛物面镜收集荧光以提高光子探测率

Result: 成功将单囚禁离子冷却至低于多普勒极限，达到多普勒冷却温度的1/9以下

Conclusion: 首次实现了单囚禁离子的反馈冷却至低于多普勒极限，该方法为超冷离子实验开辟了新途径

Abstract: We report on the first feedback cooling of a single trapped ion below the Doppler limit of $\hbarΓ/2 k_\mathrm{B}$. The motion of a single ion is monitored in real-time and cooled up to 9-times below the Doppler cooling temperature by applying electronic feedback. Real-time motion detection is implemented by imaging the fluorescence photons emitted by the ion onto a knife edge and detecting the transmitted light, a method used so far to cool trapped nanoparticles. The intensity modulation of the fluorescence resulting from the ion motion is used to generate and apply the feedback signal and also to determine the ion temperature. The method benefits from a high rate of detected scattered photons, which can be a challenge, and which we address by using a parabolic mirror for collecting the fluorescence.

</details>


### [31] [Instantaneous velocity during quantum tunnelling](https://arxiv.org/abs/2512.16385)
*Xiao-Wen Shang,Jian-Peng Dou,Feng Lu,Sen Lin,Hao Tang,Xian-Min Jin*

Main category: quant-ph

TL;DR: 量子隧穿过程中粒子速度在势垒内从大初值连续弛豫到小值，概率密度逐渐建立而非瞬间形成，解决了稳态速度为零与有限概率密度共存的理论悖论。


<details>
  <summary>Details</summary>
Motivation: 量子隧穿是量子力学核心现象，但粒子在隧穿过程中的动力学行为仍存在争议，特别是稳态速度为零与有限概率密度共存的理论悖论需要解决。

Method: 通过分析隧穿过程的时间演化，研究粒子速度在势垒内的弛豫行为；从稳态方程推导粒子速度与势垒宽度的显式关系；对比基于概率密度与概率电流定义的有效速度。

Result: 发现粒子速度在势垒内从大初值连续弛豫到小值（在渐逝态中可接近零）；概率密度逐渐建立而非瞬间形成；推导出速度与势垒宽度的关系，证明宽势垒中渐逝态速度趋近于零。

Conclusion: 解决了稳态速度为零与有限概率密度共存的理论悖论，澄清了基于概率密度定义有效速度会导致虚假"稳态速度"的问题，为时间分辨隧穿现象测试提供了理论基础。

Abstract: Quantum tunnelling, a hallmark phenomenon of quantum mechanics, allows particles to pass through the classically forbidden region. It underpins fundamental processes ranging from nuclear fusion and photosynthesis to the operation of superconducting qubits. Yet the underlying dynamics of particle motion during tunnelling remain subtle and are still the subject of active debate. Here, by analyzing the temporal evolution of the tunnelling process, we show that the particle velocity inside the barrier continuously relaxes from a large initial value toward a smaller one, and may even approach zero in the evanescent regime. Meanwhile, the probability density within the barrier gradually builds up before reaching its stationary profile, in contrast to existing inherently. In addition, starting from the steady-state equations, we derive an explicit relation between the particle velocity and the barrier width, and show that the velocity in evanescent states approaches zero when the barrier is sufficiently wide. These findings resolve the apparent paradox of a vanishing steady-state velocity coexisting with a finite particle density. We point out that defining an effective speed from the probability density, rather than from the probability current, can lead to spuriously nonzero "stationary speed," as appears to be the case in Ref. [Nature 643, 67 (2025)]. Our work establishes a clear dynamical picture for the formation of tunnelling flow and provides a theoretical foundation for testing time-resolved tunnelling phenomena.

</details>


### [32] [Coined Quantum Walks on Complex Networks for Quantum Computers](https://arxiv.org/abs/2512.16400)
*Rei Sato*

Main category: quant-ph

TL;DR: 提出一种用于复杂网络上硬币量子行走的量子电路设计，采用双寄存器编码简化移位算子，在多种网络模型上验证性能，电路深度约N^1.9，并在真实量子处理器上测试。


<details>
  <summary>Details</summary>
Motivation: 复杂网络上的量子行走中，硬币和移位算子依赖于节点的不同度数，这使得电路构造比规则图更复杂，需要更高效的实现方法。

Method: 采用双寄存器编码方法，简化移位算子并减少资源开销。使用Qmod高级量子编程语言实现电路，在Erdős-Rényi、Watts-Strogatz和Barabási-Albert模型上进行数值模拟，并在ibm_torino超导量子处理器上实际执行。

Result: 电路深度缩放约为N^1.9，与网络拓扑无关。在真实量子硬件上测试显示，硬件感知优化对较大图略有改善，而连接约束对较小图带来开销。当前NISQ设备仅适用于小规模验证。

Conclusion: 该框架的多项式缩放特性使其适合在早期容错量子计算时代进行更大规模实现，虽然当前NISQ设备能力有限，但为未来应用奠定了基础。

Abstract: We propose a quantum circuit design for implementing coined quantum walks on complex networks. In complex networks, the coin and shift operators depend on the varying degrees of the nodes, which makes circuit construction more challenging than for regular graphs. To address this issue, we use a dual-register encoding. This approach enables a simplified shift operator and reduces the resource overhead compared to previous methods. We implement the circuit using Qmod, a high-level quantum programming language, and evaluated the performance through numerical simulations on Erdős-Rényi, Watts-Strogatz, and Barabási-Albert models. The results show that the circuit depth scales as approximately $N^{1.9}$ regardless of the network topology. Furthermore, we execute the proposed circuits on the ibm\_torino superconducting quantum processor for Watts-Strogatz models with $N=4$ and $N=8$. The experiments show that hardware-aware optimization slightly improved the $L_1$ distance for the larger graph, whereas connectivity constraints imposed overhead for the smaller one. These results indicate that while current NISQ devices are limited to small-scale validations, the polynomial scaling of our framework makes it suitable for larger-scale implementations in the early fault-tolerant quantum computing era.

</details>


### [33] [Quantum-Inspired Ising Machines for Quantum Chemistry Calculations](https://arxiv.org/abs/2512.16435)
*Mahmood Hasani,Hadis Salasi,Negar Ashari Astani*

Main category: quant-ph

TL;DR: 量子启发算法（相干伊辛机和模拟分岔算法）能够准确模拟H₂和H₂O分子的电子能量分布，计算速度比基于门的量子计算快5倍以上，为化学和材料科学提供了有前景的替代方案。


<details>
  <summary>Details</summary>
Motivation: 量子模拟是量子计算最有前景的应用之一，但当前量子硬件存在噪声问题，严重限制了量子算法的实际应用。量子启发算法提供了一种有吸引力的替代方案，能够避免对易出错的量子设备的依赖。

Method: 使用量子启发算法——相干伊辛机和模拟分岔算法，来模拟H₂和H₂O分子的电子能量分布，并与基于门的量子计算方法进行对比。

Result: 算法能够准确捕捉H₂和H₂O分子的基本能量特征，计算时间分别为1.2秒和2.4秒，相比基于门的量子计算方法（通常需要至少6秒计算单个分子构型）实现了显著加速。

Conclusion: 量子启发方法在扩展到更大分子系统方面具有巨大潜力，为未来化学和材料科学应用提供了有前景的替代方案，特别是在当前量子硬件存在噪声限制的情况下。

Abstract: Four decades after Richard Feynman's famous remark, we have reached a stage at which nature can be simulated quantum mechanically. Quantum simulation is among the most promising applications of quantum computing. However, like many quantum algorithms, it is severely constrained by noise in near-term hardware. Quantum-inspired algorithms provide an attractive alternative by avoiding the need for error-prone quantum devices. In this study, we demonstrate that the coherent Ising machine and simulated bifurcation algorithms can accurately reproduce the electronic energy profiles of H_2 and H_2O, capturing their essential energetic features. Notably, we obtain computational times of 1.2 s and 2.4 s for the H_2 and H_2O profiles, respectively, representing a substantial speed-up compared to gate-based quantum computing approaches, which typically require at least 6 s to compute a single molecular geometry with comparable accuracy. These results highlight the potential of quantum-inspired approaches for scaling to larger molecular systems and for future applications in chemistry and materials science.

</details>


### [34] [Classical and quantum electromagnetic momentum in anisotropic optical waveguides](https://arxiv.org/abs/2512.16495)
*Denis Kopylov,Manfred Hammer*

Main category: quant-ph

TL;DR: 该论文证明了介质波导中的导模满足与动量相关的正交条件，为宽带导波电磁场的量子化提供了严格的理论基础。


<details>
  <summary>Details</summary>
Motivation: 目前存在经典麦克斯韦方程组的导波场解与波导中光子的直观理解之间的理论鸿沟，需要建立严格自洽的量子化方法。

Method: 证明介质波导导模满足与动量相关的正交条件，建立与功率（能量）正交性的联系，提出适用于一般形状波导的量子化程序。

Result: 建立了导模动量正交条件，为宽带导波电磁场的量子化提供了严格理论基础，填补了经典解与光子直观理解之间的理论空白。

Conclusion: 该工作为集成光子电路中导波电磁场的量子化提供了自洽的理论框架，适用于一般形状的直波导，包括材料色散和各向异性情况。

Abstract: The guided modes supported by dielectric channel waveguides act as individual carriers of momentum. We show this by proving that the modes satisfy an orthogonality condition which relates to the momentum of the optical electromagnetic field, with a link to the more familiar power (energy) orthogonality. This result forms the basis for a rigorous, self-consistent procedure for the quantization of broadband guided electromagnetic fields in the typical channels used in integrated photonic circuits. Our work removes the existing theoretical gap between the classical solution of the Maxwell equations for guided fields and the intuitive understanding of photons in waveguides. The presented approach is valid for straight, lossless, and potentially anisotropic, dielectric waveguides of general shape, in the linear regime, and including material dispersion. Examples for the hybrid modes of a thin film lithium niobate strip waveguide are briefly discussed.

</details>


### [35] [Replica Keldysh field theory of quantum-jump processes: General formalism and application to imbalanced and inefficient fermion counting](https://arxiv.org/abs/2512.16520)
*Felix Kloiber-Tollinger,Lukas M. Sieberer*

Main category: quant-ph

TL;DR: 该论文开发了用于一般量子跳跃过程的综合副本Keldysh场论，统一描述了高效检测下的纯态量子轨迹和低效监测下的混合态动力学，建立了驱动开放量子物质非平衡稳态与测量诱导动力学中相变之间的直接联系。


<details>
  <summary>Details</summary>
Motivation: 测量诱导相变主要针对厄米算符的投影或连续测量进行研究，假设完美检测无信息损失。然而这类相变也出现在更一般的场景中，包括非厄米跳跃算符的量子跳跃过程以及低效检测情况。目前缺乏处理这些更广泛场景的理论框架。

Method: 开发了用于一般量子跳跃过程的综合副本Keldysh场论，适用于玻色子和费米子系统。该形式主义统一描述了高效检测下的纯态量子轨迹和低效监测下的混合态动力学，其中确定性Lindbladian演化作为极限情况出现。

Result: 应用该理论研究了不平衡和低效费米子计数：对于不平衡但高效计数，恢复了平衡情况的定性图像——任何非零跳跃率下纠缠都服从面积律，在两个参数分离的长度尺度之间出现扩展的量子临界区域。低效检测引入了有限关联长度，超过该长度时费米子对数负性度量的纠缠服从面积律，而子系统熵显示体积律标度。数值模拟支持了分析结果。

Conclusion: 该研究为研究广泛类别的监测和开放量子系统中的测量诱导现象提供了通用且多功能的理沦基础，建立了驱动开放量子物质非平衡稳态与测量诱导动力学中相变之间的直接联系。

Abstract: Measurement-induced phase transitions have largely been explored for projective or continuous measurements of Hermitian observables, assuming perfect detection without information loss. Yet such transitions also arise in more general settings, including quantum-jump processes with non-Hermitian jump operators, and under inefficient detection. A theoretical framework for treating these broader scenarios has been missing. Here we develop a comprehensive replica Keldysh field theory for general quantum-jump processes in both bosonic and fermionic systems. Our formalism provides a unified description of pure-state quantum trajectories under efficient detection and mixed-state dynamics emerging from inefficient monitoring, with deterministic Lindbladian evolution appearing as a limiting case. It thus establishes a direct connection between phase transitions in nonequilibrium steady states of driven open quantum matter and in measurement-induced dynamics. As an application, we study imbalanced and inefficient fermion counting in a one-dimensional lattice system: monitored gain and loss of fermions occurring at different rates, with a fraction of gain and loss jumps undetected. For imbalanced but efficient counting, we recover the qualitative picture of the balanced case: entanglement obeys an area law for any nonzero jump rate, with an extended quantum-critical regime emerging between two parametrically separated length scales. Inefficient detection introduces a finite correlation length beyond which entanglement, as quantified by the fermionic logarithmic negativity, obeys an area law, while the subsystem entropy shows volume-law scaling. Numerical simulations support our analytical findings. Our results offer a general and versatile theoretical foundation for studying measurement-induced phenomena across a wide class of monitored and open quantum systems.

</details>


### [36] [Wichmann-Kroll vacuum polarization density in a finite Gaussian basis set](https://arxiv.org/abs/2512.16569)
*Ryan Benazzouk,Maen Salman,Trond Saue*

Main category: quant-ph

TL;DR: 该研究改进了有限高斯基下QED效应的计算，特别是真空极化密度的非线性贡献，旨在达到与格林函数方法相当的精度。


<details>
  <summary>Details</summary>
Motivation: 提高有限高斯基方法计算真空极化效应的数值精度，使其能够与文献中报道的格林函数方法精度相媲美。

Method: 使用Riesz投影子推导真空极化密度线性贡献的解析表达式；采用偶调谐基组进行基组外推；进行误差分析评估数值噪声的鲁棒性；开发部分波展开外推策略。

Result: 建立了有限高斯基方案的计算框架，分析了收敛性和数值困难，提出了达到足够精度的计算策略，为氢类离子1s_{1/2}态能量位移的精确计算奠定了基础。

Conclusion: 有限高斯基方法可以用于精确计算QED效应，通过适当的数值策略和外推技术，能够达到与格林函数方法相当的精度水平。

Abstract: This work further develops the calculation of QED effects in a finite Gaussian basis. We focus on the non-linear $α(Zα)^{n\ge 3}$ contribution to the vacuum polarization density, computing the energy shift of 1s$_{1/2}$ states of hydrogen-like ions. Our goal is to improve the numerical computations to achieve a precision comparable to that of Green's function methods reported in the literature. To do so, an analytic expression for the linear contribution to the vacuum polarization density is derived using Riesz projectors. Alternative formulations of the vacuum polarization density and their relation is discussed. The convergence of the finite Gaussian basis scheme is investigated, and the numerical difficulties that arise are characterized. In particular, an error analysis is performed to assess the method's robustness to numerical noise. We then report a strategy for computing the energy shift with sufficient precision to enable a sensible extrapolation of the partial-wave expansion. A key feature of the procedure is the use of even-tempered basis sets, allowing for an extrapolation towards the complete basis set limit.

</details>


### [37] [The measured speed in the evanescent regime reflects the spatial decay of the wavefunction, not particle motion](https://arxiv.org/abs/2512.16580)
*Weixiang Ye*

Main category: quant-ph

TL;DR: 该论文回应了Sharoglazova等人对玻姆力学的挑战，指出他们误解了实验参数ν的物理意义，ν测量的是波函数振幅的空间梯度而非粒子速度，因此实验实际上支持而非反驳玻姆力学。


<details>
  <summary>Details</summary>
Motivation: 回应Sharoglazova等人对玻姆力学的挑战，澄清他们对实验参数ν的误解，维护玻姆力学框架的完整性。

Method: 通过分析玻姆力学本体论框架，重新解释实验参数ν的物理意义，区分波函数振幅梯度与粒子运动速度的概念差异。

Result: 证明ν测量的是波函数振幅的空间梯度这一几何性质，而非点状粒子的运动速度，因此实验不构成对玻姆力学的挑战。

Conclusion: 实验实际上展示了玻姆力学中波与粒子方面的本体论分离，支持而非反驳玻姆力学框架。

Abstract: The recent paper by Sharoglazova et al. reports an energy-dependent parameter $ν$ extracted from the spatial distribution of photons in a coupled-waveguide experiment. The authors interpret $ν$ as the speed of quantum particles, even in the classically forbidden regime, and claim that its finite value contradicts the Bohmian mechanics prediction of zero particle velocity. This challenge arises from a fundamental misunderstanding of the operational meaning of v within the Bohmian ontological framework. We demonstrate that v quantifies the spatial gradient of the wavefunctions amplitude, a geometric property of the guiding field, not the kinematical velocity of point-like particles. The experiment therefore does not challenge but rather illustrates the clean ontological separation between the wave and particle aspects inherent to Bohmian mechanics.

</details>


### [38] [Giant-atom quantum acoustodynamics in hybrid superconducting-phononic integrated circuits](https://arxiv.org/abs/2512.16582)
*Lintao Xiao,Bo Zhang,Yu Zeng,Xiaoxuan Pan,Jia-Qi Wang,Ziyue Hua,Hongwei Huang,Yifang Xu,Guangming Xue,Haifeng Yu,Xin-Biao Xu,Weiting Wang,Chang-Ling Zou,Luyan Sun*

Main category: quant-ph

TL;DR: 研究人员通过将超导transmon量子比特耦合到铌酸锂声波导的两个相距约600个声波波长的点上，实现了一个"巨型原子"系统，展示了非马尔可夫弛豫动力学和频率相关的有效衰减率。


<details>
  <summary>Details</summary>
Motivation: 探索声子集成电路作为实现巨型原子物理学的多功能平台，为高级量子信息处理提供高度可调的量子器件。

Method: 将超导transmon量子比特耦合到铌酸锂声波导的两个点上，两点相距约600个声波波长（传播延迟125纳秒），形成巨型原子结构。

Result: 观察到非马尔可夫弛豫动力学，包括声子回流现象；有效衰减率在4MHz范围内变化四倍，Purcell因子超过40；利用频率相关耗散制备了高纯度的量子叠加态。

Conclusion: 该工作确立了声子集成电路作为巨型原子物理学的多功能平台，为高级量子信息处理提供了高度可调的量子器件。

Abstract: We demonstrate a giant atom by coupling a superconducting transmon qubit to a lithium niobate phononic waveguide at two points separated by about 600 acoustic wavelengths, with a propagation delay of 125 ns. The giant atom yields non-Markovian relaxation dynamics characterized by phonon backflow and a frequency-dependent effective decay rate varying four-fold over merely 4 MHz, corresponding to a Purcell factor exceeding 40. Exploiting this frequency-dependent dissipation, we prepare quantum superposition states with high purity. Our results establish phononic integrated circuits as a versatile platform for giant-atom physics, providing highly tunable quantum devices for advanced quantum information processing.

</details>


### [39] [Indistinguishable photons from a two-photon cascade](https://arxiv.org/abs/2512.16617)
*Timon L. Baltisberger,Francesco Salusti,Mark R. Hogg,Malwina A. Marczak,Nils Heinisch,Sascha R. Valentin,Stefan Schumacher,Arne Ludwig,Klaus D. Jöns,Richard J. Warburton*

Main category: quant-ph

TL;DR: 通过Purcell增强量子点中双激子跃迁，实现了高相干性的纠缠光子对，双光子干涉可见度分别达到94%和82%。


<details>
  <summary>Details</summary>
Motivation: 量子点中的双激子级联是产生纠缠光子对的潜在源，但现有方案中光子存在时间相关性，导致光子相干性较差。

Method: 在低噪声器件中通过Purcell增强双激子跃迁，调节双激子与单激子寿命比超过两个数量级。

Result: 实现了高双光子干涉可见度：双激子光子94±2%，单激子光子82±6%，光子相干性符合量子光学理论预测。

Conclusion: Purcell增强双激子跃迁是提高量子点纠缠光子对相干性的有效方法，为量子信息应用提供了高质量光子源。

Abstract: Decay of a four-level diamond scheme via a cascade is a potential source of entangled photon pairs. A solid-state implementation is the biexciton cascade in a semiconductor quantum dot. While high entanglement fidelities have been demonstrated, the two photons, XX and X, are temporally correlated, typically resulting in poor photon coherence. Here, we demonstrate a high two-photon interference visibility (a measure of the photon coherence) for both XX (V=94$\pm$2%) and X (V=82$\pm$6%) photons. This is achieved by Purcell-enhancing the biexciton transition in a low-noise device. We find that the photon coherence follows the well-known quantum optics result upon tuning the XX:X lifetime ratio over two orders of magnitude.

</details>


### [40] [Fast Native Three-Qubit Gates and Fault-Tolerant Quantum Error Correction with Trapped Rydberg Ions](https://arxiv.org/abs/2512.16641)
*Katrin Bolsmann,Thiago L. M. Guedes,Weibin Li,Joseph W. P. Wilkinson,Igor Lesanovsky,Markus Müller*

Main category: quant-ph

TL;DR: 本文提出首个利用微波修饰里德伯离子实现原生三量子比特CCZ门的方案，并展示了其在九量子比特Bacon-Shor码中实现容错量子纠错的潜力。


<details>
  <summary>Details</summary>
Motivation: 传统离子阱量子计算平台中，基于集体运动的纠缠门速度慢且难以扩展。利用里德伯离子的强偶极-偶极相互作用可以克服这些限制，实现更快的多量子比特操作。

Method: 通过优化单脉冲协议，考虑里德伯态有限寿命，实现微波修饰里德伯离子的原生受控-受控-Z门。将该门应用于九量子比特Bacon-Shor码，开发并分析容错、免测量的量子纠错方案。

Result: 在现实条件下实现保真度超过97%的CCZ门，执行时间约2微秒（低温环境）。模拟证实在线性里德伯离子链上可以完全容错地执行量子纠错，尽管其量子比特连接性有限。

Conclusion: 原生多量子比特里德伯离子门是实现快速、高保真度量子计算的重要资源，在容错量子纠错方面具有显著潜力，为可扩展量子信息处理提供了新途径。

Abstract: Trapped ions as one of the most promising quantum-information-processing platforms, yet conventional entangling gates mediated by collective motion remain slow and difficult to scale. Exciting trapped ions to high-lying electronic Rydberg states provides a promising route to overcome these limitations by enabling strong, long-range dipole-dipole interactions that support much faster multi-qubit operations. Here, we introduce the first scheme for implementing a native controlled-controlled-Z gate with microwave-dressed Rydberg ions by optimizing a single-pulse protocol that accounts for the finite Rydberg-state lifetime. The resulting gate outperforms standard decompositions into one- and two-qubit gates by achieving fidelities above 97% under realistic conditions, with execution times of about 2 microseconds at cryogenic temperatures. To explore the potential of trapped Rydberg ions for fault-tolerant quantum error correction, and to illustrate the utility of three-qubit Rydberg-ion gates in this context, we develop and analyze a proposal for fault-tolerant, measurement-free quantum error correction using the nine-qubit Bacon-Shor code. Our simulations confirm that quantum error correction can be performed in a fully fault-tolerant manner on a linear Rydberg-ion chain despite its limited qubit connectivity. These results establish native multiqubit Rydberg-ion gates as a valuable resource for fast, high-fidelity quantum computing and highlight their potential for fault-tolerant quantum error correction.

</details>


### [41] [Scalable tests of quantum contextuality from stabilizer-testing nonlocal games](https://arxiv.org/abs/2512.16654)
*Wanbing Zhao,H. W. Shawn Liew,Wen Wei Ho,Chunxiao Liu,Vir B. Bulchandani*

Main category: quant-ph

TL;DR: 该论文研究了稳定子测试非局域游戏的经典值上界，证明稳定子态可以通过上下文性提供量子优越性证明，并针对GHZ、环面码和循环簇态等具体例子给出了紧致上界。


<details>
  <summary>Details</summary>
Motivation: DiVincenzo和Peres观察到稳定子码字可以通过上下文性提供简单的量子优越性证明，这可以重构为非局域游戏语言。然而，除了n-qubit GHZ态之外，可扩展例子的稳定子测试游戏的经典值大多未知，需要新的方法来界定这些经典值。

Method: 1. 证明了所有稳定子测试游戏的一般编码理论界：如果经典值p_cl* < 1，则p_cl* ≤ 7/8；2. 针对GHZ、环面码和循环簇态等常见可扩展例子，通过转移矩阵方法收紧了这个界；3. 对循环簇态建立了渐近紧致上界。

Result: 1. 建立了稳定子测试游戏的通用经典值上界(7/8)；2. 针对具体稳定子态获得了更紧致的上界；3. 特别地，对循环簇态证明了测量指数小的保真度就足以见证其上下文性。

Conclusion: 该研究提供了界定稳定子测试非局域游戏经典值的新方法，证明了稳定子态的上下文性可以通过相对简单的测量来检测，特别是循环簇态只需要指数小的保真度测量就能见证其量子优越性。

Abstract: Soon after the dawn of quantum error correction, DiVincenzo and Peres observed that stabilizer codewords could give rise to simple proofs of quantumness via contextuality. This discovery can be recast in the language of nonlocal games: every $n$-qubit stabilizer state defines a specific "stabilizer-testing" $n$-player nonlocal game, which quantum players can win with probability one. If quantum players can moreover outperform all possible classical players, then the state is contextual. However, the classical values of stabilizer-testing games are largely unknown for scalable examples beyond the $n$-qubit GHZ state. We introduce several new methods for upper-bounding the classical values of these games. We first prove a general coding-theory bound for all stabilizer-testing games: if the classical value $p_{\mathrm{cl}}^* < 1$, then $p_{\mathrm{cl}}^* \leq 7/8$, i.e., there is no classical strategy that can perform as well as the optimal quantum strategy even in an asymptotic sense. We then show how to tighten this bound for the most common scalable examples, namely GHZ, toric-code and cyclic cluster states. In particular, we establish an asymptotically tight upper bound for cyclic cluster states using transfer-matrix methods. This leads to the striking conclusion that measuring an exponentially small fidelity to the cyclic cluster state will suffice to witness its contextuality.

</details>


### [42] [Shaping Dynamics Through Memory: A Study of Reservoir Profiles in Open Quantum Systems](https://arxiv.org/abs/2512.16657)
*J. R. Silva,C. Antunis B. S. Santos*

Main category: quant-ph

TL;DR: 研究不同储层记忆核（洛伦兹、高斯、均匀）对波导系统动力学的影响，分析其对传输谱和非马尔可夫效应的调控作用。


<details>
  <summary>Details</summary>
Motivation: 探究不同储层记忆核如何影响波导系统的动力学演化，特别是不同空间关联特性对系统行为的影响，以及如何量化与马尔可夫极限的偏差。

Method: 比较三种代表性记忆核（洛伦兹、高斯、均匀），计算传输振幅、透明特性及长时间行为，使用基于信息回流的非马尔可夫性度量进行量化分析。

Result: 结果揭示了无记忆诱导的传输谱修改的清晰特征，并展示了特定储层分布如何增强或抑制非马尔可夫效应。

Conclusion: 不同储层记忆核对波导系统动力学有显著影响，特定记忆分布可调控非马尔可夫效应，为量子信息处理中的储层工程提供理论指导。

Abstract: In this work, we investigate how different reservoir memory profiles influence the dynamical evolution of a single waveguide coupled to an external environment. We compare three representative memory kernels: Lorentzian, Gaussian and Uniform, highlighting their distinct spatial correlations and their impact on system behavior. We compute the transmission amplitude, transparency properties, as well as long-time behavior of the system under each memory model. To quantify deviations from Markovian dynamics, we employ a non-Markovianity measure based on information backflow, allowing a direct comparison between the structured reservoirs and the Markovian limit. Our results reveal clear signatures of memoryless-induced modifications in the transmission spectrum and demonstrate how specific reservoir profiles enhance or suppress non-Markovian effects.

</details>


### [43] [Topological magic response in quantum spin chains](https://arxiv.org/abs/2512.16673)
*Ritu Nehra,Poetri Sonya Tarabunga,Martina Frau,Mario Collura,Emanuele Tirrito,Marcello Dalmonte*

Main category: quant-ph

TL;DR: 论文提出"拓扑魔法响应"概念，用于探测拓扑相在非Clifford扰动下的响应，揭示非局域量子关联。在Ising型自旋链中，对称破缺相和顺磁相缺乏这种响应，而对称保护拓扑相则表现出该响应。


<details>
  <summary>Details</summary>
Motivation: 虽然纠缠与拓扑的关系已确立，但非稳定化（魔法）在拓扑相中的作用尚不清楚。非稳定化是容错量子计算的关键概念，研究其在拓扑相中的角色对于理解拓扑物质在量子信息处理中的应用具有重要意义。

Method: 引入拓扑魔法响应概念，定义为状态在有限深度非Clifford电路扰动下在稳定子空间中的扩散能力。使用稳定子Rényi熵的组合来隔离非局域存储的信息，类似于拓扑纠缠熵。通过精确解析计算和基于新算法技术的矩阵乘积态模拟进行研究。

Result: 在Ising型自旋链中，对称破缺相和顺磁相缺乏拓扑魔法响应，而对称保护拓扑相总是表现出该响应。掺杂T门的SPT相支持鲁棒的拓扑魔法响应，而平凡相则保持无特征。

Conclusion: 拓扑魔法响应作为探测拓扑相对非Clifford扰动响应的新工具，揭示了非局域量子关联的存在。该研究建立了非稳定化与拓扑相之间的联系，为理解拓扑物质在容错量子计算中的作用提供了新视角。

Abstract: Topological matter provides natural platforms for robust, non-local information storage, central to quantum error correction. Yet, while the relation between entanglement and topology is well established, little is known about the role of nonstabilizerness (or magic), a pivotal concept in fault-tolerant quantum computation, in topological phases. We introduce the concept of topological magic response, the ability of a state to spread over stabilizer space when perturbed by finite-depth non-Clifford circuits. Unlike a topological invariant or order parameter, this response function probes how a phase reacts to non-Clifford perturbations, revealing the presence of non-local quantum correlations. In Ising-type spin chains, we show that symmetry-broken and paramagnetic phases lack such a response, whereas symmetry-protected topological (SPT) phases always display it. To capture this, we utilize a combination of stabilizer Rényi entropies that, in analogy with topological entanglement entropy, isolates non-locally stored information. Using exact analytic computations and matrix product states simulations based on an algorithmic technique we introduce, we show that SPT phases doped with $T$ gates support robust topological magic response, while trivial phases remain featureless.

</details>


### [44] [Symbolic Pauli Propagation for Gradient-Enabled Pre-Training of Quantum Circuits](https://arxiv.org/abs/2512.16674)
*Saverio Monaco,Jamal Slim,Florian Rehm,Dirk Krücker,Kerstin Borras*

Main category: quant-ph

TL;DR: 提出一种基于Pauli传播的量子机器学习方法，通过符号表示和截断技术实现可扩展的梯度估计，支持经典预训练和高效量子系统训练。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习模型通常需要昂贵的片上训练过程，且缺乏高效的梯度估计方法。现有方法难以扩展到经典模拟无法处理的大规模量子系统。

Method: 采用Pauli传播技术推导可观测量作为电路参数的解析函数符号表示。通过合适的ansatz设计和Pauli权重、频率分量的受控截断，获得准确且可处理的估计器。支持经典预训练和梯度优化。

Result: 在变分量子本征求解器上验证该方法，成功获得自旋模型的基态。证明该方法能够实现准确结果，同时保持可扩展性和计算效率。

Conclusion: 该方法为量子机器学习提供了一种可扩展的训练框架，能够处理超出经典模拟能力的系统规模，实现高效的梯度估计和经典预训练，为大规模量子系统优化开辟了新途径。

Abstract: Quantum Machine Learning models typically require expensive on-chip training procedures and often lack efficient gradient estimation methods. By employing Pauli propagation, it is possible to derive a symbolic representation of observables as analytic functions of a circuit's parameters. Although the number of terms in such functional representations grows rapidly with circuit depth, suitable choices of ansatz and controlled truncations on Pauli weights and frequency components yield accurate yet tractable estimators of the target observables. With the right ansatz design, this approach can be extended to system sizes beyond the reach of classical simulation, enabling scalable training for larger quantum systems. This also enables a form of classical pre-training through gradient-based optimization prior to deployment on quantum hardware. The proposed approach is demonstrated on the Variational Quantum Eigensolver for obtaining the ground state of a spin model, showing that accurate results can be achieved with a scalable and computationally efficient procedure.

</details>


### [45] [On the Dynamics of Local Hidden-Variable Models](https://arxiv.org/abs/2512.16682)
*Nick von Selzam,Florian Marquardt*

Main category: quant-ph

TL;DR: 论文探讨了贝尔非定域性的动态扩展，提出了动态局部隐变量模型的概念，并通过反例和严格的不可能性定理证明这种动态模型并不总是存在，揭示了量子系统中存在一种新的非定域性类型。


<details>
  <summary>Details</summary>
Motivation: 传统贝尔非定域性只关注静态关联，没有考虑关联随时间演化的动态情况。作者想要探索：如果关联在所有时间都保持局部性，那么能否通过演化隐变量来捕捉关联的时间演化？这引出了对动态局部隐变量模型的研究。

Method: 首先定义动态局部隐变量模型，讨论可能的物理和数学假设。然后通过一个简单的反例来挑战这种模型的存在性，最后通过严格的不可能性定理来证明动态局部隐变量模型并不总是存在。

Result: 通过反例和严格的不可能性定理证明，动态局部隐变量模型并不总是存在。这意味着即使每个时刻的关联都可以用局部隐变量模型描述，这些模型的时间演化可能无法通过演化隐变量本身来实现。

Conclusion: 研究结果表明存在一种新的非定域性类型，这种非定域性可以从观测到的测量统计的时间演化中推断出来，并且在相互作用的量子系统中普遍存在。这扩展了我们对量子非定域性的理解，从静态关联延伸到动态演化。

Abstract: Bell nonlocality is an intriguing property of quantum mechanics with far reaching consequences for information processing, philosophy and our fundamental understanding of nature. However, nonlocality is a statement about static correlations only. It does not take into account dynamics, i.e. time evolution of those correlations. Consider a dynamic situation where the correlations remain local for all times. Then at each moment in time there exists a local hidden-variable (LHV) model reproducing the momentary correlations. Can the time evolution of the correlations then be captured by evolving the hidden variables? In this light, we define dynamical LHV models and motivate and discuss potential additional physical and mathematical assumptions. Based on a simple counter example we conjecture that such LHV dynamics does not always exist. This is further substantiated by a rigorous no-go theorem. Our results suggest a new type of nonlocality that can be deduced from the observed time evolution of measurement statistics and which generically occurs in interacting quantum systems.

</details>


### [46] [Propagators of singular anharmonic oscillators with quasi-equidistant spectra](https://arxiv.org/abs/2512.16695)
*Andrey M. Pupasov-Maksimov,Marcelo Silva Oliveira*

Main category: quant-ph

TL;DR: 研究奇异谐振子的达布变换，通过镜像方法获得形式奇异传播子的解析表达式，展示双势阱和三势阱族势能及相应传播子，并识别对应的轴对称磁场构型。


<details>
  <summary>Details</summary>
Motivation: 研究奇异谐振子的达布变换，旨在获得奇异传播子的解析表达式，探索多势阱系统的量子传播特性，并建立与轴对称磁场构型的物理联系。

Method: 采用达布变换方法处理奇异谐振子，应用镜像方法处理形式奇异传播子，获得解析传播子表达式，构建双势阱和三势阱族势能系统。

Result: 获得了奇异传播子的解析表达式，展示了双势阱和三势阱族势能及相应传播子，识别了与这些势能对应的轴对称磁场构型。

Conclusion: 成功将达布变换应用于奇异谐振子，通过镜像方法获得解析传播子，建立了多势阱系统与轴对称磁场构型的对应关系，为相关量子系统研究提供了新工具。

Abstract: Darboux transformations of the singular harmonic oscillator are considered. Analytical expressions for the propagators are obtained, using the image method applied to formal singular propagators. Two-well and three-well families of potentials and the corresponding propagators are presented. Axially symmetric magnetic field configurations corresponding to these potentials have been identified.

</details>


### [47] [QuantumSavory: Write Symbolically, Run on Any Backend -- A Unified Simulation Toolkit for Quantum Computing and Networking](https://arxiv.org/abs/2512.16752)
*Hana KimLee,Leonardo Bacciottini,Abhishek Bhatt,Andrew Kille,Stefan Krastanov*

Main category: quant-ph

TL;DR: QuantumSavory是一个开源量子计算与网络工具包，通过分离符号前端与可互换数值后端，支持跨抽象层的端到端研究，特别关注LOCC协议中的经典-量子交互。


<details>
  <summary>Details</summary>
Motivation: 量子计算和网络的发展需要跨设备级噪声、异构硬件、算法结构和分布式经典控制等多个抽象层的协同设计。现有工具难以支持这种端到端研究，特别是在处理LOCC协议中的经典-量子交互方面存在不足。

Method: 1. 构建后端无关的符号语言表达状态、操作、测量和协议逻辑；2. 通过可互换的数值后端（稳定子、波函数、相空间等）执行同一模型；3. 引入标签/查询系统处理LOCC协议中的经典-量子交互；4. 提供可重用标准库和协议构建块。

Result: 开发了QuantumSavory工具包，能够：1. 在不重写模型的情况下跨多个后端快速探索精度-性能权衡；2. 通过数据驱动控制平面提高协议组件的可组合性和重用性；3. 支持任意量子系统的任意多体纠缠网络动力学；4. 通过一致接口减少粘合代码需求。

Conclusion: QuantumSavory通过分离符号前端与可互换后端、引入标签/查询系统处理经典-量子交互，为量子计算与网络的端到端协同设计提供了实用工具，显著提高了模型的可重用性和协议的可组合性。

Abstract: Progress in quantum computing and networking depends on codesign across abstraction layers: device-level noise and heterogeneous hardware, algorithmic structure, and distributed classical control. We present QuantumSavory, an open-source toolkit built to make such end-to-end studies practical by cleanly separating a symbolic computer-algebra frontend from interchangeable numerical simulation backends. States, operations, measurements, and protocol logic are expressed in a backend-agnostic symbolic language; the same model can be executed across multiple backends (e.g., stabilizer, wavefunction, phase-space), enabling rapid exploration of accuracy-performance tradeoffs without rewriting the model. Furthermore, new custom backends can be added via a small, well-defined interface that immediately reuses existing models and protocols.
  QuantumSavory also addresses the classical-quantum interaction inherent to LOCC protocols via discrete-event execution and a tag/query system for coordination. Tags attach structured classical metadata to quantum registers and message buffers, and queries retrieve, filter, or wait on matching metadata by wildcards or arbitrary predicates. This yields a data-driven control plane where protocol components coordinate by publishing and consuming semantic facts (e.g., resource availability, pairing relationships, protocol outcomes) rather than by maintaining rigid object graphs or bespoke message plumbing, improving composability and reuse as models grow. Our toolkit is also not limited to qubits and Bell pairs; rather, any networking dynamics of any quantum system under any type of multipartite entanglement can be tackled. Lastly, QuantumSavory ships reusable libraries of standard states, circuits, and protocol building blocks with consistent interfaces, enabling full-stack examples to be assembled, modified, and compared with minimal glue code.

</details>


### [48] [Reconstruction of Quantum Fields](https://arxiv.org/abs/2512.16775)
*Nicolás Medina Sánchez,Borivoje Dakić*

Main category: quant-ph

TL;DR: 论文提出了一种通过可区分粒子态空间的商来从第一量子化过渡到第二量子化的新方法，推导出满足特定操作原则的创生-湮灭代数，再现了超越玻色子和费米子的统计最大推广的分拆函数。


<details>
  <summary>Details</summary>
Motivation: 传统上通过创生湮灭代数引入玻色子和费米子，与量子层面的发射吸收过程相关。本文旨在通过可区分粒子态空间的商来形式化第一量子化到第二量子化的过渡，推广通常的对称化程序，并推导满足特定操作原则的新创生湮灭代数。

Method: 采用可区分粒子态空间的商构造，使得等价类识别出不含区分粒子信息的态。假设得到的不可区分粒子空间：(i) 具有与观测者标记可访问模式兼容的有序基，(ii) 在这些模式的幺正变换下不变，(iii) 支持粒子计数作为模式局部操作。基于这些操作原则推导新的创生湮灭代数。

Result: 推导出新的创生湮灭代数类，这些代数再现了与这些操作原则一致的超越玻色子和费米子的统计最大推广的分拆函数。

Conclusion: 通过可区分粒子态空间的商构造，本文提供了一种从第一量子化过渡到第二量子化的新方法，推广了传统的对称化程序，并推导出满足特定操作原则的创生湮灭代数，为超越传统玻色子和费米子的统计提供了新的理论框架。

Abstract: One of the traditional ways of introducing bosons and fermions is through creation and annihilation algebras. Historically, these have been associated with emission and absorption processes at the quantum level and are characteristic of the language of second quantization. In this work, we formulate the transition from first to second quantization by taking quotients of the state spaces of distinguishable particles, so that the resulting equivalence classes identify states that contain no information capable of distinguishing between particles, thereby generalising the usual symmetrisation procedure. Assuming that the resulting indistinguishable-particle space (i) admits an ordered basis compatible with how an observer may label the accessible modes, (ii) is invariant under unitary transformations of those modes, and (iii) supports particle counting as a mode-wise local operation, we derive a new class of creation-annihilation algebras. These algebras reproduce the partition functions of transtatistics-maximal generalisations of bosons and fermions consistent with these operational principles.

</details>


### [49] [A magic criterion (almost) as nice as PPT, with applications in distillation and detection](https://arxiv.org/abs/2512.16777)
*Zhenhuan Liu,Tobias Haug,Qi Ye,Zi-Wen Liu,Ingo Roth*

Main category: quant-ph

TL;DR: 该论文提出了混合态魔幻判据——三角判据，它在魔幻态中扮演类似纠缠中PPT判据的角色，具有强检测能力、几何解释和与魔幻蒸馏的操作联系。


<details>
  <summary>Details</summary>
Motivation: 研究多量子比特魔幻态的检测和蒸馏问题，特别是探索单量子比特方案与多量子比特方案的差异，揭示混合态魔幻检测的基本限制。

Method: 提出三角判据作为混合态魔幻检测工具，证明该判据在张量积下不稳定，分析多量子比特魔幻蒸馏协议，推导魔幻态的最小纯度上界。

Result: 发现多量子比特魔幻蒸馏协议严格强于所有单量子比特方案；证明低秩多量子比特魔幻态几乎不可能被单量子比特协议蒸馏；预测存在无法被保真度基魔幻见证检测的"不忠实魔幻态"。

Conclusion: 三角判据为魔幻态研究提供了类似PPT判据的强大工具，揭示了多量子比特魔幻蒸馏的优势和单拷贝方案检测魔幻态的基本局限性。

Abstract: We introduce a mixed-state magic criterion, the Triangle Criterion, which plays a role for magic analogous to the Positive Partial Transposition (PPT) criterion for entanglement: it combines strong detection capability, a clear geometric interpretation, and an operational link to magic distillation. Using this criterion, we uncover several new features of multi-qubit magic distillation and detection. We prove that genuinely multi-qubit magic distillation protocols are strictly more powerful than all single-qubit schemes by showing that the Triangle Criterion is not stable under tensor products, in sharp contrast to the PPT criterion. Moreover, we show that, with overwhelming probability, multi-qubit magic states with relatively low rank cannot be distilled by any single-qubit distillation protocol. We derive an upper bound on the minimal purity of magic states, which is conjectured to be tight with both numerical and constructive evidences. Using this minimal-purity result, we predict the existence of unfaithful magic states, namely states that cannot be detected by any fidelity-based magic witness, and reveal fundamental limitations of mixed-state magic detection in any single-copy scheme.

</details>


### [50] [Non-Linear Strong Data-Processing for Quantum Hockey-Stick Divergences](https://arxiv.org/abs/2512.16778)
*Theshani Nuradha,Ian George,Christoph Hirche*

Main category: quant-ph

TL;DR: 该论文建立了量子曲棍球散度的非线性强数据处理不等式，改进了现有线性SDPI，并应用于量子隐私通道的隐私保证和有限混合时间分析。


<details>
  <summary>Details</summary>
Motivation: 现有的线性强数据处理不等式（SDPI）在量子信息理论中并不总是紧致的，需要改进以提供更精确的量子态可区分性度量，特别是在量子通道传输过程中。

Method: 建立了满足特定噪声准则的量子通道的非线性SDPI；定义了推广Dobrushin曲线的F_γ曲线来表征异质通道序列组合的SDPI；推导了带有曲棍球散度约束的f-散度的反向Pinsker型不等式。

Result: 非线性SDPI改进了量子曲棍球散度的现有线性SDPI和经典曲棍球散度的非线性SDPI；能够建立线性SDPI无法实现的更紧致的有限混合时间；为序列私有量子通道的组合提供了更强的隐私保证。

Conclusion: 非线性强数据处理不等式为量子信息处理提供了更精确的分析工具，在量子隐私、混合时间分析等方面具有重要应用价值，改进了现有线性方法的局限性。

Abstract: Data-processing is a desired property of classical and quantum divergences and information measures. In information theory, the contraction coefficient measures how much the distinguishability of quantum states decreases when they are transmitted through a quantum channel, establishing linear strong data-processing inequalities (SDPI). However, these linear SDPI are not always tight and can be improved in most of the cases. In this work, we establish non-linear SDPI for quantum hockey-stick divergence for noisy channels that satisfy a certain noise criterion. We also note that our results improve upon existing linear SDPI for quantum hockey-stick divergences and also non-linear SDPI for classical hockey-stick divergence. We define $F_γ$ curves generalizing Dobrushin curves for the quantum setting while characterizing SDPI for the sequential composition of heterogeneous channels. In addition, we derive reverse-Pinsker type inequalities for $f$-divergences with additional constraints on hockey-stick divergences. We show that these non-linear SDPI can establish tighter finite mixing times that cannot be achieved through linear SDPI. Furthermore, we find applications of these in establishing stronger privacy guarantees for the composition of sequential private quantum channels when privacy is quantified by quantum local differential privacy.

</details>


### [51] [Numerically exact open quantum system work statistics with process tensors](https://arxiv.org/abs/2512.16823)
*Mike Shubrook,Moritz Cygorek,Erik Gauger,Jake Iles-Smith,Ahsan Nazir*

Main category: quant-ph

TL;DR: 提出一个过程张量框架，用于精确计算驱动开放量子系统的完整量子功统计，应用于超越弱耦合、马尔可夫和慢驱动极限的Landauer擦除协议。


<details>
  <summary>Details</summary>
Motivation: 准确量化量子操作的热力学功成本对于量子技术的发展至关重要，特别是在快速控制和复杂非平衡环境下，传统近似方法失效，需要新的精确计算方法。

Method: 引入过程张量框架，能够计算驱动开放量子系统的完整数值精确量子功统计分布，该方法具有非微扰精度，适用于超越弱耦合、马尔可夫和慢驱动极限的情况。

Result: 应用于Landauer擦除协议时，揭示出被低阶矩忽略的明显量子特征，这些特征显著影响协议的擦除保真度，展示了该框架在表征能量交换涨落方面的精确性和细节。

Conclusion: 该框架为探索近期和未来量子设备运行状态下的热力学和控制提供了强大而通用的工具，能够在复杂非平衡环境中精确表征能量交换涨落。

Abstract: Accurately quantifying the thermodynamic work costs of quantum operations is essential for the continued development and optimisation of emerging quantum technologies. This present a significant challenge in regimes of rapid control within complex, non-equilibrium environments - conditions under which many contemporary quantum devices operate and conventional approximations break down. Here, we introduce a process tensor framework that enables the computation of the full numerically exact quantum work statistics of driven open quantum systems. We demonstrate the utility of our approach by applying it to a Landauer erasure protocol operating beyond the weak-coupling, Markovian, and slow-driving limits. The resulting work probability distributions reveal distinct quantum signatures that are missed by low-order moments yet significantly impact the erasure fidelity of the protocol. Our framework delivers non-perturbative accuracy and detail in characterising energy-exchange fluctuations in driven open quantum systems, establishing a powerful and versatile tool for exploring thermodynamics and control in the operating regimes of both near-term and future quantum devices.

</details>


### [52] [Nonstabilizerness in Stark many-body localization](https://arxiv.org/abs/2512.16859)
*Han-Ze Li,Yi-Rui Zhang,Yu-Jun Zhao,Xuyang Huang,Jian-Xin Zhong*

Main category: quant-ph

TL;DR: 量子多体无无序局域化能抑制输运，同时允许计算代价高昂的非Clifford资源的积累。在实现无无序Stark多体局域化的横向场伊辛链中，稳定子Rényi熵保持非零并在强Stark场区域缓慢增长到有限平台值，具有强烈的初态选择性。


<details>
  <summary>Details</summary>
Motivation: 研究无无序多体局域化中的非稳定子性（"魔法"）行为，填补对无无序多体局域化中非稳定子性理解上的空白，为近期量子模拟器的基准测试和设计提供实用工具。

Method: 使用横向场伊辛链实现无无序Stark多体局域化，通过分析稳定子Rényi熵来探测非稳定子性（魔法），研究不同Stark场强度下的长时间魔法和纠缠行为。

Result: 在强Stark场区域，稳定子Rényi熵保持非零并缓慢增长到有限平台值，表现出强烈的初态选择性。随着Stark场强度增加，长时间魔法和纠缠一致显示从遍历到受限局域动力学的交叉。

Conclusion: 非稳定子性（魔法）可作为无无序遍历性破坏和受限局域化的实用复杂性探针，对近期量子模拟器的基准测试和设计具有直接相关性，填补了无无序多体局域化中非稳定子性理解上的空白。

Abstract: Quantum many-body disorder-free localization can suppress transport while still allowing the buildup of computationally costly non-Clifford resources. In a transverse-field Ising chain realizing disorder-free Stark many-body localization, we show that the stabilizer Rényi entropy remains nonzero and grows slowly to a finite plateau deep in the strong Stark-field regime, with strong initial-state selectivity. As the Stark field strength increases, long-time magic and entanglement consistently signal a crossover from ergodic to constrained localized dynamics. These results establish nonstabilizerness (``magic'') as a practical complexity probe for disorder-free ergodicity breaking and constrained localization, with direct relevance to benchmarking and designing near-term quantum simulators, and fill a gap in the understanding of nonstabilizerness in disorder-free many-body localization.

</details>


### [53] [Random purification channel for passive Gaussian bosons](https://arxiv.org/abs/2512.16878)
*Francesco Anna Mele,Filippo Girardi,Senrui Chen,Marco Fanizza,Ludovico Lami*

Main category: quant-ph

TL;DR: 构建了一个高斯版本的随机纯化通道，给定n个未知玻色被动高斯态的副本，可以生成n个随机选择的高斯纯化副本，且每个纯化的平均光子数恰好是初始态的两倍。


<details>
  <summary>Details</summary>
Motivation: 随机纯化通道在量子信息理论中已被证明是极其有价值的工具，但需要构建其高斯版本以处理玻色被动高斯态。

Method: 利用对偶约化酉群对的表示理论，通过表征被动高斯酉算子的交换子来构造高斯随机纯化通道。

Result: 成功构造了高斯随机纯化通道，该通道能够生成随机高斯纯化，且每个纯化的平均光子数恰好是初始态的两倍。

Conclusion: 该工作扩展了随机纯化通道到高斯领域，为处理玻色被动高斯态提供了重要工具，并具有精确控制光子数的优势。

Abstract: The random purification channel, which, given $n$ copies of an unknown mixed state $ρ$, prepares $n$ copies of an associated random purification, has proved to be an extremely valuable tool in quantum information theory. In this work, we construct a Gaussian version of this channel that, given $n$ copies of a bosonic passive Gaussian state, prepares $n$ copies of one of its randomly chosen Gaussian purifications. The construction has the additional advantage that each purification has a mean photon number which is exactly twice that of the initial state. Our construction relies on the characterisation of the commutant of passive Gaussian unitaries via the representation theory of dual reductive pairs of unitary groups.

</details>


### [54] [Advantage of Warm Starts for Electron-Phonon Systems on Quantum Computers](https://arxiv.org/abs/2512.16879)
*Arnab Adhikary,S. E. Skelton,Alberto Nocera,Mona Berciu*

Main category: quant-ph

TL;DR: 提出一种针对强耦合Holstein模型的初始态ansatz，显著提高基态重叠度，减少量子相位估计迭代次数，实现电路成本的指数级降低。


<details>
  <summary>Details</summary>
Motivation: 量子计算机上模拟电子-声子相互作用仍然具有挑战性，现有研究主要集中在哈密顿量模拟和电路优化上，需要改进初始态制备方法来提高效率。

Method: 研究单电子Holstein模型，提出一种初始态ansatz，特别针对强耦合区域设计，能够高效实现并显著提高基态重叠度。

Result: 该ansatz在强耦合区域显著提高基态重叠度，减少标准量子相位估计所需的迭代次数，相对于传统初始猜测实现电路成本的指数级降低。

Conclusion: 将物理直觉融入电子-声子耦合系统的初始态制备具有实际价值，能够显著提高量子模拟效率。

Abstract: Simulating electron-phonon interactions on quantum computers remains challenging, with most algorithmic effort focused on Hamiltonian simulation and circuit optimization. In this work, we study the single-electron Holstein model and propose an initial-state ansatz that substantially enhances ground state overlap in the strong coupling regime, thereby reducing the number of iterations required in standard quantum phase estimation. We further show that this ansatz can be implemented efficiently and yields an exponential reduction in overall circuit costs relative to conventional initial guesses. Our results highlight the practical value of incorporating physical intuition into initial state preparation for electron-phonon coupled systems.

</details>


### [55] [Many-body contextuality and self-testing quantum matter via nonlocal games](https://arxiv.org/abs/2512.16886)
*Oliver Hart,David T. Stephen,Evan Wickenden,Rahul Nandkishore*

Main category: quant-ph

TL;DR: 该论文提出了一种基于CSS量子纠错码的多体量子游戏框架，用于量化和探测量子上下文性，建立了量子码、布尔函数非线性度与上下文性之间的数学联系，并展示了该框架在自测试和多体上下文性研究中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究量子上下文性作为量子力学区别于经典物理的基本特性，探索其在量子计算加速和多体系统中的表现，建立量子纠错码与上下文性之间的系统联系。

Method: 提出基于CSS量子纠错码的多体量子游戏框架，通过单点泡利测量验证码字状态；引入辅助超图状态对称性分析方法计算经典成功概率；建立布尔函数非线性度与上下文性的数学联系；开发CSS子测量游戏用于自测试。

Result: 建立了CSS码字状态上下文性与布尔函数非线性度的定量关系；为多个典型CSS码计算了经典成功概率；将结果与经典统计力学模型和对称保护拓扑态的奇异关联子联系起来；展示了2D环面码的自测试能力；提出了多体状态中扩展上下文性的概念。

Conclusion: 该工作为量子上下文性研究提供了基于CSS量子纠错码的统一框架，建立了量子信息、布尔函数理论和多体物理之间的深刻联系，为量子计算优势分析和多体量子态表征提供了新工具。

Abstract: Contextuality is arguably the fundamental property that makes quantum mechanics different from classical physics. It is responsible for quantum computational speedups in both magic-state-injection-based and measurement-based models of computation, and can be directly probed in a many-body setting by multiplayer nonlocal quantum games. Here, we discuss a family of games that can be won with certainty when performing single-site Pauli measurements on a state that is a codeword of a Calderbank-Shor-Steane (CSS) error-correcting quantum code. We show that these games require deterministic computation of a code-dependent Boolean function, and that the classical probability of success is upper bounded by a generalized notion of nonlinearity/nonquadraticity. This success probability quantifies the state's contextuality, and is computed via the function's (generalized) Walsh-Hadamard spectrum. To calculate this, we introduce an efficient, many-body-physics-inspired method that involves identifying the symmetries of an auxiliary hypergraph state. We compute the classical probability of success for several paradigmatic CSS codes and relate it to both classical statistical mechanics models and to strange correlators of symmetry-protected topological states. We also consider CSS submeasurement games, which can only be won with certainty by sharing the appropriate codeword up to local isometries. These games therefore enable self-testing, which we illustrate explicitly for the 2D toric code. We also discuss how submeasurement games enable an extensive notion of contextuality in many-body states.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [56] [GRHayL: a modern, infrastructure-agnostic, extensible library for GRMHD simulations](https://arxiv.org/abs/2512.15846)
*Samuel Cupp,Leonardo R. Werneck,Terrence Pierre Jacques,Samuel Tootle,Zachariah B. Etienne*

Main category: gr-qc

TL;DR: GRHayL是一个模块化、基础设施无关的广义相对论磁流体动力学库，将成熟的IllinoisGRMHD代码重构为可重用的点式和模板式内核，支持跨平台验证和快速开发。


<details>
  <summary>Details</summary>
Motivation: 解释中子星和黑洞的多信使信号需要可靠的GRMHD模拟，但关键算法通常在特定基础设施的数值相对论代码中重复实现，阻碍了验证和重用。

Method: 将IllinoisGRMHD代码重构为模块化的、基础设施无关的库，提供守恒量到原始量的恢复、重构、通量/源项和感应算子、状态方程、中微子泄漏等功能。

Result: 在Einstein Toolkit和BlackHoles@Home中实现了相同内核，展示了可移植性。验证包括连续集成单元测试和跨基础设施比较，显示与原有代码相当或改进的性能。

Conclusion: GRHayL提供了一个可移植、可验证的GRMHD库，促进了跨代码验证、新微物理的采用和未来加速器的适应，解决了现有代码重复实现和验证困难的问题。

Abstract: Interpreting multi-messenger signals from neutron stars and black holes requires reliable general-relativistic magnetohydrodynamics (GRMHD) simulations across rapidly evolving high-performance-computing platforms, yet key algorithms are routinely rewritten within infrastructure-specific numerical-relativity codes, hindering verification and reuse. We present the General Relativistic Hydrodynamics Library (GRHayL), a modular, infrastructure-agnostic GR(M)HD library providing conservative-to-primitive recovery, reconstruction, flux/source and induction operators, equations of state, and neutrino leakage through an intuitive interface. GRHayL refactors and extends the mature IllinoisGRMHD code into reusable pointwise and stencil-wise kernels, enabling rapid development and cross-code validation in diverse frameworks, while easing adoption of new microphysics and future accelerators. We implement the same kernels in the Einstein Toolkit (Carpet and CarpetX) and BlackHoles@Home, demonstrating portability with minimal duplication. Validation combines continuous-integration unit tests with cross-infrastructure comparisons of analytic GRMHD Riemann problems, dynamical Tolman-Oppenheimer-Volkoff evolutions, and binary neutron-star mergers, showing comparable or improved behavior over legacy IllinoisGRMHD and established Einstein Toolkit codes.

</details>


### [57] [Particle Production by Time-Varying Dark Energy and the End of Cosmic Expansion](https://arxiv.org/abs/2512.15860)
*Nicolas Patino,Paul J. Steinhardt*

Main category: gr-qc

TL;DR: 研究时间变化的暗能量，考虑五元标量场能量部分转化为粒子时产生的热摩擦效应，分析其对宇宙膨胀和收缩的影响。


<details>
  <summary>Details</summary>
Motivation: 研究五元标量场暗能量模型中，场演化时能量转化为粒子产生的热摩擦效应如何影响暗能量的观测特征，特别是如何区分不同暗能量模型（陡峭势场、平坦势场、宇宙常数），以及热摩擦如何影响宇宙从膨胀到收缩的转变。

Method: 通过理论建模分析五元标量场暗能量，考虑场演化时能量转化为粒子产生的热摩擦效应，研究其对场加速度、宇宙膨胀加速、状态方程的影响，特别关注势场从正变负导致宇宙从膨胀转为收缩的情况。

Result: 热摩擦会减少标量场的加速度，增加宇宙加速膨胀的量，并在五元状态方程中产生显著凸起。即使势场从正变负导致宇宙收缩，热摩擦也会延长加速膨胀期，推迟宇宙收缩的开始，使传统宇宙学测试难以检测这种转变。但粒子产生可能通过产生热暗辐射背景（包含中微子等粒子）提供替代检测途径。

Conclusion: 热摩擦效应使得区分不同暗能量模型变得困难，同时延迟了宇宙从膨胀到收缩的转变，但粒子产生过程本身可能通过暗辐射背景提供新的探测机会。

Abstract: We consider various possible consequences of time-varying dark energy due to a quintessence scalar field whose energy density is partially converted to particles as the field evolves down its potential. This particle production acts as a source of thermal friction on the field that can make it difficult to distinguish whether dark energy is due to a radiating field rolling down a steep potential, a purely self-interacting field moving down a flatter potential, or a cosmological constant. By reducing the acceleration of the scalar field, thermal friction increases the amount of accelerated expansion and can cause a sizable bump in the quintessence equation of state. We take special interest in the case where a steep potential rapidly changes from positive to negative as the field evolves, resulting in the end of cosmic expansion and the beginning of contraction. Even in this case, we find that thermal friction lengthens the period of accelerated expansion and consequently delays the end of cosmic expansion, making it challenging to detect the impending transition to contraction using conventional cosmological tests. However, particle production can also provide alternative avenues for detection by generating a background of thermal dark radiation, partly comprised of neutrinos or other particles, whose energy density exceeds the remnant photon energy density.

</details>


### [58] [Modeling the frequency-domain ringdown amplitude of comparable-mass mergers with greybody factors](https://arxiv.org/abs/2512.15877)
*Romeo Felice Rosato,Sophia Yi,Emanuele Berti,Paolo Pani*

Main category: gr-qc

TL;DR: 提出基于灰体因子的四参数模型，能精确再现数值相对论波形振幅，将不匹配度降低约两个数量级，为黑洞光谱学提供新的一致性检验方法


<details>
  <summary>Details</summary>
Motivation: 最近研究发现，在双星并合过程中，残余黑洞的灰体因子会调制合并后的衰荡信号。传统黑洞光谱学方法存在局限性，需要开发更精确的模型来描述衰荡相位

Method: 基于灰体因子构建简单的四参数模型，使用SXS目录中的大量数值相对论波形数据进行验证，确定频域应用的最佳初始频率，并提供模型参数与原始质量和自旋的解析拟合

Result: 模型能精确再现可比较质量、对齐自旋的数值相对论波形振幅，不匹配度达到约10^-5量级，比现有模型提高约两个数量级。确定了频域应用的最佳初始频率，并提供了参数解析拟合

Conclusion: 该研究为衰荡相位提供了新的、与传统黑洞光谱学互补的一致性检验方法，基于灰体因子的简单模型能显著提高波形振幅的建模精度

Abstract: It was recently shown that, in a binary coalescence, the greybody factor of the remnant black hole modulates the post-merger ringdown signal. In this work, we demonstrate that a simple four-parameter model based on the greybody factor accurately reproduces the frequency-domain amplitude of a large set of comparable-mass, aligned-spin numerical relativity waveforms from the SXS catalog, achieving mismatches of order ${\cal O}(10^{-5})$ and improving existing models by roughly two orders of magnitude. We also identify the optimal initial frequency for applying the model in the frequency domain and provide analytical fits of the model parameters in terms of the progenitor masses and aligned spins. Our results pave the way for new consistency tests of the ringdown phase, complementary to traditional black hole spectroscopy.

</details>


### [59] [Excitation of scalar quasi-normal modes from boson clouds](https://arxiv.org/abs/2512.15878)
*Enrico Cannizzaro,Marco Palleschi,Laura Sberna,Richard Brito,Stephen Green*

Main category: gr-qc

TL;DR: 该论文证明了大质量标量场在黑洞背景下，准束缚态(QBS)和准正规模(QNM)两个模式族之间的正交性，并展示了它们可以通过频率变量重定义统一到格林函数的同一黎曼叶上，最后研究了玻色子云中QNM的发射机制。


<details>
  <summary>Details</summary>
Motivation: 研究大质量标量场在黑洞背景下两个重要模式族——准束缚态(QBS)和准正规模(QNM)之间的关系，以及它们在引力波物理中的相互作用和激发机制。

Method: 使用相对论性内积证明QBS和QNM的正交性；通过频率变量重定义将两个模式族统一到格林函数的同一黎曼叶上；采用鞍点近似法近似格林函数；研究第二致密天体潮汐扰动驱动的玻色子云中QNM发射。

Result: 证明了QBS和QNM相对于相对论性内积的正交性；发现通过适当的频率变量重定义，两个模式族可以统一到格林函数的同一黎曼叶上；QNM共振发射通常被抑制，但在非共振相互作用（如非束缚天体的动态捕获）以及扰动体接近光环时，QNM跃迁可能更显著。

Conclusion: QBS和QNM虽然是不同的模式族，但可以通过适当的数学处理统一描述，这对于理解黑洞背景下标量场的动力学行为具有重要意义，特别是在玻色子云与致密天体相互作用产生引力波信号的背景下。

Abstract: Massive scalar fields on black hole backgrounds generally admit two families of modes: quasi-bound states (QBS) and quasinormal modes (QNM). We demonstrate the orthogonality between the two mode families with respect to a relativistic product. We also find that, although the two families appear on different Riemann sheets of the Green's function of massive scalar perturbations, they can be brought to a single sheet with an appropriate redefinition of the frequency variable. In this variable, it is more natural to see how both mode families can be excited by initial data, and to approximate the Green's function with saddle points. Finally, we investigate the QNM emission from boson clouds - the latter effectively consisting of a single QBS - driven by the tidal perturbation of a second compact object. We show that while the resonant emission of QNMs is generally suppressed, QNM transitions may be more prominent when the interaction with the perturber is non-resonant, such as in the dynamical capture of unbound objects, and when the perturber transits close to the light ring.

</details>


### [60] [Effective metric for binaries in framework of EOB theory to fifth PM order](https://arxiv.org/abs/2512.16098)
*Jiliang Jing,Weike Deng,Sheng Long*

Main category: gr-qc

TL;DR: 构建了第五阶后闵可夫斯基精度的有效单体理论有效度量，为建立自洽的5PM阶EOB理论提供基础


<details>
  <summary>Details</summary>
Motivation: 为了建立基于后闵可夫斯基近似的自洽有效单体理论来描述双星系统的动力学演化，需要从有效度量推导哈密顿量、辐射反作用力和波形。第三代引力波探测器至少需要第五阶PM精度，因此需要构建第五阶PM精度的有效度量。

Method: 在有效单体理论中构建了第五阶后闵可夫斯基精度的有效度量。该有效度量属于D型，使得引力扰动Weyl张量的零标架分量方程能够解耦和变量分离。

Result: 成功构建了第五阶PM精度的有效度量，该度量具有D型特性，为建立自洽的5PM阶有效单体理论奠定了基础。

Conclusion: 构建的第五阶PM精度有效度量为建立完整的自洽有效单体理论提供了关键基础，能够支持第三代引力波探测器所需的精度要求。

Abstract: To establish a self-consistent effective one-body (EOB) theory that describes the dynamical evolution of binary systems based on the post-Minkowskian (PM) approximation, where the Hamiltonian, radiation reaction force, and waveforms are derived from an effective metric, the primary objective is to obtain the effective metric. Given that third generation gravitational wave detectors require at least fifth-order PM accuracy, in this paper we constructed an effective metric in the EOB theory of binaries up to fifth PM order. The effective metric is of type D, allowing for the derivation of decoupled and variable-separable equations for the null tetrad component of the gravitational perturbed Weyl tensor. This presents a basis for us to establish a self-consistent EOB theory up to 5PM order.

</details>


### [61] [Adiabatic Anisotropic Gravitational Collapse in Painlevé-Gullstrand Coordinates: A Geometric Analysis](https://arxiv.org/abs/2512.16104)
*G. Abellán,N. Bolívar,A. Alexandrova,I. Vasilev*

Main category: gr-qc

TL;DR: 本文在统一的Painlevé-Gullstrand坐标系中分析了各向异性引力坍缩的几何结构，得到了闭合形式的表面演化方程，发现了物质内部的双视界相，并确定了控制动力学的临界参数关系。


<details>
  <summary>Details</summary>
Motivation: 传统引力坍缩分析通常需要在内部和外部使用不同的坐标系，并通过匹配条件连接，这会产生跨图匹配伪影。本文旨在建立一个统一的坐标系来消除这些伪影，从而更清晰地分析坍缩过程的几何结构和视界动力学。

Method: 基于Oppenheimer-Snyder框架，采用唯象启发的能量密度分布，在统一的Painlevé-Gullstrand坐标系中建立模型。通过强制Israel连接条件获得闭合形式的表面演化方程，并推导出完整坍缩过程的精确解。

Result: 得到了坍缩过程的精确解析解，表征了因果结构，追踪了视界的形成和演化。特别发现了物质内部存在双视界相，事件视界最终稳定在Schwarzschild半径。确定了控制动力学的临界参数关系，包括连接初始致密度和立即视界形成的阈值。

Conclusion: 该模型在爱因斯坦方程内是几何自洽的，但违反了标准的逐点能量条件，这突显了理想化各向异性物质模型的已知局限性，并划定了经典描述变得不充分的边界。这些结果为坍缩和视界动力学提供了几何洞察、紧凑的解析基准和教学性的坐标统一视角。

Abstract: We present a detailed geometric analysis of adiabatic, anisotropic gravitational collapse formulated in a single Painlevé-Gullstrand coordinate system that covers both the interior and exterior, thereby eliminating cross-chart matching artifacts. Building on the Oppenheimer-Snyder framework with a phenomenologically motivated energy-density profile, we enforce the Israel junction conditions and obtain closed-form surface evolution. Within this unified chart we derive exact solutions for the complete collapse process, characterize the causal structure, and track horizon formation and evolution. In particular, we identify and analyse a double apparent-horizon phase inside the matter and show that the event horizon stabilizes at the Schwarzschild radius. We further obtain critical parameter relations that govern the dynamics, including a threshold linking initial compactness to immediate horizon formation. The model is geometrically self-consistent within Einstein's equations but exhibits violations of the standard point-wise energy conditions, highlighting known limitations of idealized anisotropic matter models and delineating the boundary where classical descriptions become inadequate. Together, these results provide geometric insights, compact analytic benchmarks and a didactic, coordinate-uniform perspective on collapse and horizon dynamics.

</details>


### [62] [Gravitational Effects of Sources Inspired by ideal Electromagnetic Fields in Spherical Painlevé-Gullstrand Coordinates](https://arxiv.org/abs/2512.16109)
*G. Abellán,N. Bolívar,I. Vasilev*

Main category: gr-qc

TL;DR: 构建并分析广义相对论中仅由经典静电构型驱动的静态球对称时空，使用Painlevé-Gullstrand类度规，开发分段解：内部平坦几何，外部由多种电磁分布源支持。


<details>
  <summary>Details</summary>
Motivation: 提供一个解析可处理的框架，探索物理简单、易于理解的源（无需奇异物质）的引力效应，研究经典静电构型如何影响时空几何。

Method: 使用具有单位时间膨胀和径向位移函数的球对称Painlevé-Gullstrand类度规，构建分段定义解：内部平坦几何，外部由点电荷类场、汤川屏蔽电场、介电层和Hulthén型场等多种电磁源支持。通过爱因斯坦方程建立能量密度与径向压力关系，从度规推导切向压力。

Result: 系统评估每个模型的经典能量条件，使用Israel连接条件研究奇异行为的出现，为理解简单电磁源如何产生引力效应提供了分析框架。

Conclusion: 该框架为探索物理简单、易于理解的源（无需奇异物质）的引力效应提供了分析可处理的设置，有助于理解经典电磁构型如何影响时空几何并可能产生奇异性。

Abstract: We construct and analyze a class of static spherically symmetric spacetimes in general relativity sourced exclusively by classical electrostatic configurations. Using a spherically symmetric Painlevé-Gullstrand-like metric with unit lapse and a radial shift function, we develop piecewise-defined solutions where the interior geometry is flat and the exterior is supported by several sources inspired by electromagnetic distributions. These include point-charge-like fields, Yukawa-screened electric fields, dielectric layers, and Hulthén-type field. The Einstein equations naturally impose a relation between the energy density and radial pressure, while the tangential pressure is derived from the metric. We systematically evaluate the classical energy conditions in each model and study the appearance of singular behavior using Israel junction conditions. This framework offers an analytically tractable setting to explore the gravitational effects of physically simple, well-understood sources without resorting to exotic matter.

</details>


### [63] [Unified dynamical system formulations for $f(R,φ,X)$ gravity with applications to nonminimal derivative coupling and $R^2$-Higgs inflation](https://arxiv.org/abs/2512.16176)
*Saikat Chakraborty,Sergio E. Jorás,Alberto Saa*

Main category: gr-qc

TL;DR: 论文提出了两种不同的动力学系统公式来分析f(R,φ,X)引力理论，并分别应用于无势NMDC玩具模型和混合R²-Higgs暴胀模型，发现第二种公式在分析固定点结构方面表现更好。


<details>
  <summary>Details</summary>
Motivation: 研究f(R,φ,X)引力理论家族的动力学子空间结构，特别是分析非最小导数耦合(NMDC)和混合R²-Higgs暴胀模型的相空间行为。

Method: 提出了两种不同的动力学系统公式：第一种应用于无势NMDC玩具模型，第二种应用于混合R²-Higgs暴胀模型。通过相空间分析、识别不变子流形和固定点来研究这些引力理论。

Result: 第一种公式在NMDC模型中只能识别不变子流形，但所有固定点都是非双曲的，无法完全分析固定点结构；然而发现动力学性质与Ricci标量和标量场导数之间的耦合强度无关。第二种公式在混合R²-Higgs模型中表现更好，能正确还原R²和Higgs暴胀的单独相空间，识别不变子流形和固定点，并提供了相图说明。

Conclusion: 第二种动力学系统公式比第一种更有效，特别是在分析混合R²-Higgs暴胀模型的相空间结构方面。研究为理解f(R,φ,X)引力理论的动力学行为提供了系统方法。

Abstract: Two different dynamical system formulations are presented for the generic $f(R,φ,X)$ family of gravity theories. As illustrative examples, the first and the second formulation is applied to study the phase space of a toy model of the Non-Minimal Derivative Coupling (NMDC) without a potential, and the mixed $R^2$-Higgs inflation model, respectively. The first dynamical system formulation applied to the toy NMDC model, although able to identify several invariant submanifolds, fails to fully investigate the fixed point structure, as all the fixed points turn out to be non-hyperbolic. We, however, discover an interesting feature that the qualitative dynamics are independent of the coupling strength between the Ricci scalar and the scalar field derivative. The second dynamical system formulation applied to the mixed $R^2$-Higgs inflation model performs much better, being able to correctly reduce to the individual phase spaces of the $R^2$ and Higgs inflation separately in special cases, as well as correctly delivering the expected invariant submanifolds and fixed points. For the mixed $R^2$-Higgs case, illustrative phase portraits are provided for a somewhat better understanding of the dynamics.

</details>


### [64] [Back-action from inertial and non-inertial Unruh-DeWitt detectors revisited in covariant perturbation theory](https://arxiv.org/abs/2512.16217)
*Adam S. Wilkinson,Leo J. A. Parry,Jorma Louko,William G. Unruh*

Main category: gr-qc

TL;DR: 研究点状粒子探测器对量子标量场的反作用，通过应力-能量张量期望值表征，不依赖探测器测量结果。在Minkowski时空中计算了惯性及匀加速探测器的反作用能量通量。


<details>
  <summary>Details</summary>
Motivation: 传统Unruh-DeWitt探测器研究多关注探测器响应，而忽略探测器对量子场的反作用。本文旨在系统研究探测器对场的反作用效应，特别是在非平衡态下的能量交换过程。

Method: 采用协变弯曲时空量子场论技术，在二阶微扰理论下计算场的两点函数。使用因果显式两点函数，对质量less标量场在(3+1)维Minkowski时空中计算重整化应力-能量张量。分析惯性及匀加速探测器轨迹。

Result: 1. 探测器两点函数分为确定性和涨落部分，反作用保持此分裂；2. 匀加速探测器的能量流入流出精确对应Unruh效应引起的跃迁能量；3. 惯性探测器只有向外通量，无向内通量；4. 匀加速探测器在基态时出现两个负能量密度区域。

Conclusion: 探测器对量子场的反作用可通过应力-能量张量系统表征，能量通量精确反映探测器跃迁能量交换。匀加速探测器展现出新颖的负能量密度区域，为量子场论中的能量守恒提供了新视角。

Abstract: We investigate the back-action from a spatially pointlike particle detector on a quantum scalar field, as characterised by the expectation value of the field's stress-energy tensor, without conditioning on a measurement of the detector. First, assuming the field to be initially in a zero-mean Gaussian Hadamard state in a globally hyperbolic spacetime, we evaluate the field's two-point function in second-order perturbation theory by techniques of covariant curved spacetime quantum field theory, which allow a full control of the time and space localisation of the interaction, and do not rely on field mode decompositions or non-local particle countings. The detector's two-point function splits into a deterministic and a fluctuating part, and we show that this split is maintained in the back-action.
  We then specialise to a two-level Unruh-DeWitt detector, prepared in an energy eigenstate, for which the back-action is fully fluctuating. We compute the renormalised stress-energy tensor for a massless scalar field in $(3+1)$-dimensional Minkowski spacetime for a general detector trajectory, using the manifestly causal two-point function. We present explicit analytic and numerical results for an inertial detector and a uniformly linearly accelerated detector, switched on in the asymptotic past. The energy flux into and out of the accelerated detector accounts exactly for the energy gained and lost by the detector in its transitions due to the Unruh effect. The same holds for the outward flux associated with de-excitations of the inertial detector, which has a vanishing excitation rate and no inward flux. A novelty with the accelerated detector is two regions of negative energy density when the detector is initially prepared in its ground state, one near the Rindler horizon that bounds the causal future of the trajectory, the other in the far future of the trajectory.

</details>


### [65] [Gravitational wave interactions with a viscous fluid: Core collapse supernova, binary neutron star merger, and accretion around a black hole merger](https://arxiv.org/abs/2512.16253)
*Nigel T. Bishop,Vishnu Kakkat,Monos Naidoo*

Main category: gr-qc

TL;DR: 该研究将引力波与粘性流体相互作用的理论从闵可夫斯基背景扩展到一般静态球对称时空，发现阻尼和加热效应显著增强，在某些天体物理场景中可能导致引力波信号完全阻尼并引发伽马射线暴。


<details>
  <summary>Details</summary>
Motivation: 传统上认为引力波与物质的相互作用可以忽略不计，但近期研究表明当物质与引力波源的距离小于引力波波长时，与粘性流体的相互作用可能具有天体物理重要性。先前研究主要基于闵可夫斯基背景，需要扩展到更一般的时空背景。

Method: 将引力波与粘性流体相互作用的理论框架从闵可夫斯基背景扩展到一般的非真空、静态、球对称时空背景，推导出引力波阻尼和流体加热的表达式，并实现为计算机代码。

Result: 与闵可夫斯基情况相比，阻尼和加热效应显著增强，在某些情况下增加数个数量级。引力波信号可能完全被阻尼，加热效应可能强烈到足以引发伽马射线暴。

Conclusion: 在一般静态球对称时空背景下，引力波与粘性流体的相互作用比先前认为的更为重要，可能在天体物理现象（如超新星核心坍缩、中子星并合后信号、黑洞并合吸积物质）中产生显著影响，甚至完全阻尼引力波信号并引发伽马射线暴。

Abstract: The interaction of gravitational waves (GWs) with matter is normally treated as being insignificant. However, recent work has shown that the interaction with a viscous fluid may be astrophysically important when the distance between the matter and GW source is somewhat smaller than the GW wavelength. Previous work has mainly considered perturbations on a Minkowski background, and here these results are extended to the case that the background is a general, non-vacuum, static, spherically symmetric spacetime. Expressions are obtained for GW damping and the consequent heating of the fluid, and implemented in computer code. The results are applied to astrophysical scenarios: Core collapse supernovae, the post-merger signal from a binary neutron star merger, and matter accreting at a binary black hole merger. It is found that, compared to the Minkowski case, the damping and heating effects increase, in some cases by several orders of magnitude. It is possible for a GW signal to be completely damped, and for the heating to be such that a gamma-ray burst occurs.

</details>


### [66] [Phantom Menace in general Palatini $f(R,φ)$ theories](https://arxiv.org/abs/2512.16256)
*Rahul Thakur*

Main category: gr-qc

TL;DR: 研究Palatini形式下的f(R,φ)理论，寻找能统一描述暴胀和晚期宇宙膨胀的模型，通过观测数据约束理论行为，发现存在一个由幻影标量场驱动的稳定固定点，但可能是瞬态的。


<details>
  <summary>Details</summary>
Motivation: 寻找能在Palatini形式下统一描述早期暴胀和晚期宇宙加速膨胀的f(R,φ)理论，并确保理论在弱引力场和不同宇宙时期的一致性。

Method: 假设曲率部分具有Starobinsky引力行为，在爱因斯坦框架下评估暴胀后动力学稳定性，分离出两个提供稳定晚期加速宇宙的固定点，并用DESI、宇宙钟和超新星数据集进行约束。

Result: 发现两个固定点，其中一个由幻影标量场驱动的固定点与观测数据一致，但时间尺度分析表明该点可能是瞬态的，最终可能演化为由势能主导的稳定膨胀阶段。

Conclusion: Palatini形式的f(R,φ)理论可以统一描述暴胀和晚期宇宙加速，但观测约束下的幻影标量场驱动阶段可能是瞬态的，宇宙最终可能演化为势能主导的稳定膨胀。

Abstract: We study general $f(R,φ)$ theories in Palatini formalism and attempt to constrain the behavior of ones that could support both inflationary and late-time expansion era in a unified model. In particular, we find conditions for which the theories remain consistent in weak gravity regimes as well as cosmic expansion eras in both early and late universe. Assuming that the curvature part of the $f(R,φ)$ behaves as Starobinsky gravity, we assess post-inflation dynamical stability of the theory in Einstein frame and proceed to isolate two distinct fixed points that provide a stable late-time accelerating universe. Comparison with DESI, Cosmic Chronometers, and SNeIa datasets adds more stringent constraints to the behavior of the theory near the present epoch, giving us one stable fixed point where expansion is driven by a phantom scalar field. However, time scales of the two fixed points suggest that this fixed point may be transient and may eventually evolve toward a stable expansion stage driven potential domination in the distant future of the universe.

</details>


### [67] [First-time assessment of glitch-induced bias and uncertainty in inference of extreme mass ratio inspirals](https://arxiv.org/abs/2512.16322)
*Amin Boumerdassi,Matthew C. Edwards,Avi Vajpeyi,Ollie Burke*

Main category: gr-qc

TL;DR: 研究LISA中瞬态非高斯噪声"毛刺"对极端质量比旋进(EMRI)参数估计的影响，发现适度缓解的毛刺流对EMRI参数估计影响很小，但高信噪比毛刺仍会导致显著偏差。


<details>
  <summary>Details</summary>
Motivation: 毛刺噪声对短时信号(如大质量黑洞双星)的参数估计会造成偏差和精度降低，但对长寿命源如EMRI的影响尚未量化，需要评估LISA时代EMRI分析的稳健性。

Method: 使用模拟LISA观测数据，注入EMRI信号和基于shapelet的毛刺流(来自LISA Pathfinder目录)，通过Fisher矩阵分析估计毛刺引起的参数偏差和不确定性，并用MCMC验证准确性。

Result: 适度缓解的毛刺流(信噪比ρ≲90)对EMRI参数推断产生可忽略到较小的偏差[∼0.04σ,∼0.6σ]；而弱缓解毛刺流(ρ≲400)可产生接近1σ的偏差。EMRI推断相比其他源(如大质量黑洞双星)对毛刺更具鲁棒性。

Conclusion: EMRI参数估计对毛刺噪声相对稳健，但至少需要一定程度的毛刺建模和缓解才能确保LISA时代无偏的EMRI分析。

Abstract: This work investigates the impact of streams of transient, non-Gaussian noise artifacts or "glitches" on the parameter estimation of extreme mass ratio inspirals (EMRI) in the Laser Interferometer Space Antenna (LISA). Glitches cause biased and less precise inference for short-duration signals such as massive black hole binaries, but their effect on long-lived sources such as EMRIs has not been quantified. Using simulated LISA observations containing injected EMRIs and streams of shapelet-based glitches drawn from the LISA Pathfinder catalog, we estimate the glitch-induced parameter biases and uncertainties through a Fisher-matrix-based analysis whose accuracy we verify with Markov-Chain Monte Carlo. We find that moderately mitigated glitch streams i.e. ones containing only glitches of up to moderate SNRs ($ρ\lesssim 90$) induce negligible to minor biases $[\sim0.04σ,\sim0.6σ]$ in the inferred EMRI parameters. In contrast, weakly mitigated glitch streams containing higher-SNR events ($ρ\lesssim 400$) can produce biases nearing $1σ$. These results demonstrate that, when compared to inference of other sources such as massive black hole binaries, EMRI inference is notably more robust to glitches. We stress that at least some amount of glitch modeling and mitigation remains essential for unbiased EMRI analyses in the LISA era.

</details>


### [68] [Modified light-cylinder and centrifugal acceleration in Schwarzschild geometry](https://arxiv.org/abs/2512.16337)
*Nikoloz Kurtskhalia,Nikoloz Maltsev,Zaza N. Osmanov*

Main category: gr-qc

TL;DR: 研究电子在原始亚恒星质量黑洞附近沿磁力线运动的动力学，考虑引力效应后得到修正的光柱面几何，并计算电子在各种辐射机制下的最大能量


<details>
  <summary>Details</summary>
Motivation: 先前研究在平坦时空处理电子沿黑洞磁力线运动问题，引入了光柱面概念，但未考虑引力效应。本文旨在研究引力如何改变电子动力学和光柱面几何，并确定电子在各种辐射机制下的最大能量

Method: 使用史瓦西度规分析电子在引力场中的动力学，推导修正的光柱面几何，然后考虑逆康普顿散射、曲率辐射和同步辐射等限制机制，计算电子的最大能量

Result: 引力显著改变了光柱面的几何形状，不再呈圆柱形。得到了修正的光柱面几何，并确定了电子在逆康普顿散射、曲率辐射和同步辐射等机制限制下的最大能量

Conclusion: 引力对电子沿黑洞磁力线运动的动力学有重要影响，改变了光柱面的几何形状。考虑各种辐射机制后，可以确定电子能达到的最大能量，这对理解原始黑洞附近的粒子加速和辐射过程具有重要意义

Abstract: We examine the motion of an electron constrained to follow a magnetic field line near a primordial sub-stellar mass black hole. Earlier studies treated the problem in flat (Minkowski) spacetime, yielding qualitatively correct results and introducing a light cylinder (LC), a hypothetical surface where the linear velocity of rotation equals the speed of light. However, this picture changes significantly when gravity is included. By analyzing the electron's dynamics in the Schwarzschild metric, we obtain a modified light cylinder (MLC) whose geometry no longer resembles a cylinder. We then determine the maximum energies attainable by the electrons under the limiting effects of inverse Compton scattering, curvature radiation, and synchrotron radiation.

</details>


### [69] [GWTC-4.0: Searches for Gravitational-Wave Lensing Signatures](https://arxiv.org/abs/2512.16347)
*The LIGO Scientific Collaboration,The Virgo Collaboration,The KAGRA Collaboration*

Main category: gr-qc

TL;DR: 在LIGO-Virgo-KAGRA第四次观测运行(O4a)数据中搜索引力波透镜效应，未发现强透镜证据，但找到一个异常事件GW231123_135430需要进一步研究


<details>
  <summary>Details</summary>
Motivation: 引力波在传播过程中可能被大质量天体引力透镜化，这会导致信号畸变或重复出现。通过搜索这些效应可以研究高红移黑洞并合率，并探测宇宙中的透镜天体分布

Method: 采用三种方法搜索强透镜效应：1) 寻找透镜势鞍点形成的相位偏移图像；2) 寻找频率演化一致的事件对；3) 识别检测信号的亚阈值对应候选。同时使用孤立点质量模型搜索所有检测信号中的透镜畸变

Result: 未发现强透镜引力波信号的证据，据此限制了可探测强透镜事件率和黑洞并合率密度。在单信号畸变搜索中发现一个异常事件GW231123_135430，需要进一步研究

Conclusion: 当前数据未提供引力波强透镜的确切证据，但异常事件GW231123_135430值得关注。未来更多黑洞并合观测和透镜天体研究将有助于确定该事件是否为透镜信号

Abstract: Gravitational waves can be gravitationally lensed by massive objects along their path. Depending on the lens mass and the lens-source geometry, this can lead to the observation of a single distorted signal or multiple repeated events with the same frequency evolution. We present the results for gravitational-wave lensing searches on the data from the first part of the fourth LIGO-Virgo-KAGRA observing run (O4a). We search for strongly lensed events in the newly acquired data by (1) searching for an overall phase shift present in an image formed at a saddle point of the lens potential, (2) looking for pairs of detected candidates with consistent frequency evolution, and (3) identifying sub-threshold counterpart candidates to the detected signals. Beyond strong lensing, we also look for lensing-induced distortions in all detected signals using an isolated point-mass model. We do not find evidence for strongly lensed gravitational-wave signals and use this result to constrain the rate of detectable strongly lensed events and the merger rate density of binary black holes at high redshift. In the search for single distorted lensed signals, we find one outlier: GW231123_135430, for which we report more detailed investigations. While this event is interesting, the associated waveform uncertainties make its interpretation complicated, and future observations of the populations of binary black holes and of gravitational lenses will help determine the probability that this event could be lensed.

</details>


### [70] [Pseudospectrum and black hole total transmission mode (in)stability](https://arxiv.org/abs/2512.16372)
*Yu-Sen Zhou,Ming-Fei Ji,Liang-Bi Wu,Li-Ming Cao*

Main category: gr-qc

TL;DR: 论文研究了黑洞时空中总传输模式（TTMs）的谱稳定性，发现TTMs通常具有谱不稳定性，但存在一个特殊的纯虚数TTM具有增强的稳定性。


<details>
  <summary>Details</summary>
Motivation: 受到虚拟吸收现象的启发，该研究旨在分析总传输模式（TTMs）的谱稳定性，这些模式是具有复频率且能在黑洞时空中无反射传播的模式。

Method: 使用伪谱和条件数方法，将d维Tangherlini黑洞的TTM问题重新表述为广义特征值问题，并利用Eddington-Finkelstein坐标进行分析。

Result: TTMs通常具有谱不稳定性，且敏感性随高阶泛音增加而增强，这与准正规模式类似。但发现一个纯虚数TTM具有显著增强的稳定性，其伪谱轮廓几乎同心，条件数比泛音小几个数量级。此外，纯虚数TTM仅出现在自旋s=2时，而真正的复杂TTM族仅在d≥8维时出现。

Conclusion: 总传输模式通常具有谱不稳定性，但存在一个特殊的纯虚数模式表现出增强的稳定性，这为理解黑洞散射过程中的模式稳定性提供了新见解。

Abstract: Total transmission modes (TTMs) are modes with complex frequencies that propagate across a black hole spacetime without reflection. Recently, it is found that suitably tailored time-dependent scattering can excite these complex modes and suppress the reflected signal for the entire duration of the process, a phenomenon referred to as virtual absorption. Motivated by this, we present the study of the spectrum stability of TTMs using pseudospectrum and condition numbers. We focus on perturbations of $d$-dimensional Tangherlini black holes and recast the TTM problem as a generalized eigenvalue problem by utilizing the Eddington-Finkelstein coordinates. The results show that TTMs are generically spectrally unstable, with sensitivity increasing for higher overtones, in close analogy with quasinormal modes. A notable exception is a purely imaginary TTM whose pseudospectrum's contours are nearly concentric and whose condition number is orders of magnitude smaller than that of the overtones, indicating enhanced spectral stability. Additionally, we confirm that purely imaginary TTMs occur only for spin $s=2$, whereas genuinely complex TTM families appear only in sufficiently high dimensions, $d \geqslant 8$, extending earlier claims that placed the onset at $d \geqslant 10$.

</details>


### [71] [Implementing F (T ) Gravity in Boltzmann Codes: A Framework for Power Spectrum Computation](https://arxiv.org/abs/2512.16404)
*Robert Rugg,Shambel Akalu,Amare Abebe*

Main category: gr-qc

TL;DR: 研究F(T)引力幂律模型的非线性问题，发现CLASS Boltzmann求解器无法处理非线性模型，采用二阶泰勒展开作为解决方案，在n≤0.05范围内有效。


<details>
  <summary>Details</summary>
Motivation: CLASS Boltzmann求解器无法处理F(T)引力幂律模型的非线性特性，需要找到一种方法来计算这类模型的功率谱。

Method: 对非线性场方程应用二阶泰勒展开，假设偏离ΛCDM模型的额外自由度参数n足够小，以保持ΛCDM模型的关键特性。

Result: 超新星数据显示n≤0.05时，泰勒展开有效，CLASS可以准确计算功率谱，截断误差可忽略不计。

Conclusion: 通过二阶泰勒展开方法，成功解决了CLASS无法处理F(T)引力非线性模型的问题，在n≤0.05范围内提供了可靠的计算框架。

Abstract: This work investigates the nonlinearity of the power-law model of F(T) gravity, highlighting the inability of the Boltzmann solver CLASS to handle nonlinear models. As a workaround, a second-order Taylor expansion is applied to the nonlinear field equations, under the assumption that the extra degree of freedom n, which quantifies deviations from the currently favored cosmological model (ΛCDM), remains sufficiently small to preserve the key properties of the ΛCDM model. The validity of the Taylor expansion is supported by supernova data indicating n \leq 0.05, for which the power spectrum can be accurately computed within CLASS with a negligible truncation error.

</details>


### [72] [Cosmology with non-linear barotropic Israel-Stewart fluid with causal relaxation time](https://arxiv.org/abs/2512.16502)
*Vishnu A Pai,Titus K Mathew*

Main category: gr-qc

TL;DR: 本文提出了一种扩展的以色列-斯图尔特流体弛豫时间表达式，建立了体粘性压力与能量密度之间的非线性关系，在平坦弗里德曼宇宙中获得了新的解析解，并展示了该模型能支持从哈勃慢滚膨胀相到辐射主导宇宙的平滑过渡。


<details>
  <summary>Details</summary>
Motivation: 现有因果粘性耗散模型在描述宇宙演化时存在局限性，特别是在实现从膨胀相到辐射主导宇宙的平滑过渡方面存在困难。本文旨在通过扩展以色列-斯图尔特理论，建立更一般的因果粘性耗散模型，以更好地描述宇宙动力学行为。

Method: 使用非线性因果性约束推导了barotropic以色列-斯图尔特流体的扩展弛豫时间表达式，建立了体粘性压力与能量密度之间的非线性关系。在平坦弗里德曼宇宙中应用这一扩展关系，对耦合的爱因斯坦-以色列-斯图尔特系统进行了详细的动力学系统分析和数值求解。

Result: 在线性区域中，有效状态方程自然地再现了广义多方形式；该模型能够支持瞬态的哈勃慢滚膨胀相，并平滑过渡到辐射主导的宇宙；确定了确保流体可接受演化行为所需的约束条件。

Conclusion: 扩展的以色列-斯图尔特理论为因果粘性耗散提供了新的建模框架，在线性和非线性区域都能获得解析解，并能实现从膨胀相到辐射主导宇宙的平滑过渡，这在标准暴胀模型中难以实现。

Abstract: We derive an extended expression for the relaxation time of a barotropic Israel-Stewart (IS) fluid using the non-linear causality constraint, and propose a new formulation for modeling causal viscous dissipation in barotropic fluids. With this generalized relaxation time, the non-linear IS equation simplifies to a first-order non-linear expression connecting bulk viscous pressure and energy density, which remains valid in any homogeneous and isotropic spacetime. In the case of spatially flat Friedmann universe, adopting this extended relation in the generalized non-linear IS theory, provides new class of analytical solutions in both, the linear, and the non-linear regimes. We also find that, the resulting effective equation of state in the linear regime naturally reproduces the generalized polytropic form which is often introduced phenomenologically in literature. Resulting dynamical implications are investigated and the constraints necessary for ensuring an acceptable evolutionary behavior for the fluid are determined. A detailed dynamical system analysis of the coupled Einstein-Israel-Stewart (EIS) system is also performed. Finally, we solve the coupled EIS equations numerically, and show that the model can support a transient Hubble slow-roll expansion phase with a smooth exit to a radiation-dominated universe, which is challenging to obtain in standard inflationary models.

</details>


### [73] [A Universal Geometric Framework for Black Hole Phase Transitions: From Multivaluedness to Classification](https://arxiv.org/abs/2512.16629)
*Shi-Hao Zhang,Zi-Yuan Li,Jing-Fei Zhang,Xin Zhang*

Main category: gr-qc

TL;DR: 该论文揭示了黑洞一阶相变中热力学、动力学和几何量同步多值行为的普遍数学机制，提出基于温度函数极点的相变判据和分类方案。


<details>
  <summary>Details</summary>
Motivation: 黑洞一阶相变中热力学、动力学和几何量出现同步多值行为，但其根本起源尚未被充分理解。需要建立统一的理论框架来解释这一现象。

Method: 构建统一几何框架，结合实分析和覆盖空间理论，分析温度函数T(r+)的临界点，证明多值性源于两个非退化临界点将参数空间折叠成三层覆盖结构。

Result: 提出黑洞经历一阶相变的充要条件是T(r+)曲线有两个极值点，据此建立A1、A2、B三类黑洞分类方案，为基于多值性诊断相变提供理论基础。

Conclusion: 该工作为通过多值性诊断相变提供了理论基础，建立了黑洞热力学、混沌动力学和时空结构在一阶相变中的统一几何视角。

Abstract: Recent studies have revealed synchronized multivalued behavior in thermodynamic, dynamical, and geometric quantities during the black hole first-order phase transition, which enables a diagnosis from different perspectives, yet its fundamental origin has remained poorly understood. By constructing a unified geometric framework integrating real analysis and covering space theory, we reveal the universal mathematical mechanism behind this phenomenon. We prove that this multivaluedness originates from two non-degenerate critical points in the temperature function $T(r_+)$, where $r_+$ is the horizon radius, which fold the parameter space into a three-sheeted covering structure. As a direct application, we propose that a black hole undergoes a first-order phase transition if and only if its $T(r_+)$ curve has two extrema. Accordingly, we establish a classification scheme, denoted $A1$, $A2$, and $B$ for black holes. This scheme offers a complementary perspective to classifications based on global topological invariants. Our work provides a theoretical foundation for diagnosing phase transitions via multivaluedness and establishes a unified geometric perspective on black hole thermodynamics, chaotic dynamics, and spacetime structure during first-order phase transitions.

</details>


### [74] [Field Quantisations in Schwarzschild Spacetime: Theory versus Low-Energy Experiments](https://arxiv.org/abs/2512.16667)
*Viacheslav A. Emelyanov*

Main category: gr-qc

TL;DR: 论文研究了量子场论在弯曲时空中霍金粒子的传播行为，发现其与路径积分形式的结果存在差异


<details>
  <summary>Details</summary>
Motivation: 量子力学作为量子场论的低能近似，在描述地球引力场中的量子粒子时表现良好，但量子场论在弯曲时空中的粒子概念存在模糊性，需要研究霍金粒子在黑洞视界远处的运动行为

Method: 在量子场论弯曲时空框架下，计算了Schwarzschild时空远视界区域中霍金粒子的传播子

Result: 发现该传播子与路径积分形式得到的结果不同，而路径积分形式能够很好地描述引力引起的自由落体和量子干涉现象

Conclusion: 量子场论在弯曲时空中的粒子传播行为与传统的量子力学描述存在差异，这揭示了量子引力理论中更深层次的问题

Abstract: Non-relativistic quantum particles in the Earth's gravitational field are successfully described by the Schrödinger equation with Newton's gravitational potential. Particularly, quantum mechanics is in agreement with such experiments as free fall and quantum interference induced by gravity. However, quantum mechanics is a low-energy approximation to quantum field theory. The latter is successful by the description of high-energy experiments. Gravity is embedded in quantum field theory through the general-covariance principle. This framework is known in the literature as quantum field theory in curved spacetime, where the concept of a quantum particle is, though, ambiguous. In this article, we study in this framework how a Hawking particle moves in the far-horizon region of Schwarzschild spacetime by computing its propagator. We find this propagator differs from that which follows from the path-integral formalism -- the formalism which adequately describes both free fall and quantum interference induced by gravity.

</details>


### [75] [Exponential plateaus and inflation in metric-affine gravity](https://arxiv.org/abs/2512.16815)
*Antonio Racioppi*

Main category: gr-qc

TL;DR: 提出了一种在度规-仿射引力框架下构建暴胀模型的新机制，涉及暴胀子与Holst不变量的非最小耦合，可在特定条件下产生指数平台势能，预测与Starobinsky暴胀相同。


<details>
  <summary>Details</summary>
Motivation: 在度规-仿射引力框架下探索新的暴胀模型构建机制，通过非最小耦合产生特定的暴胀势能特征，实现与观测一致的暴胀预测。

Method: 使用度规-仿射引力理论，引入暴胀子与Holst不变量的非最小耦合。当非最小耦合函数在零点处非常陡峭时，正则化后的暴胀子势能总是呈现指数平台特征。

Result: 无论原始暴胀子势能形状如何，在特定条件下正则化势能都会形成指数平台，其暴胀预测与Starobinsky暴胀模型完全一致。

Conclusion: 该机制为在度规-仿射引力框架下构建暴胀模型提供了新途径，能够自然地产生与观测相符的指数平台势能，预测结果与Starobinsky暴胀模型等价。

Abstract: We propose a new mechanism for inflationary model building in the framework of metric-affine gravity. Such a mechanism involves an inflaton non-minimally coupled with the Holst invariant. If the non-minimal coupling function has a zero point and it is very steep at that same point, then the canonically normalized inflaton potential always features an exponential plateau, regardless of the shape of the original inflaton potential. The inflationary predictions in such a region are equivalent to the ones of Starobinsky inflation.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [76] [Sparse Operator-Adapted Wavelet Decomposition Using Polygonal Elements for Multiscale FEM Problems](https://arxiv.org/abs/2512.16004)
*Furkan Şık,F. L. Teixeira,B. Shanker*

Main category: physics.comp-ph

TL;DR: 提出基于稀疏多尺度算子自适应小波分解的有限元方法，在非结构化多边形网格层次上实现高效求解。


<details>
  <summary>Details</summary>
Motivation: 传统有限元方法在处理多尺度问题时计算效率低，需要改进内存使用和计算复杂度，特别是在处理高梯度区域时。

Method: 采用非结构化多边形网格层次结构，通过几何粗化过程生成凸多边形元素，利用稀疏多尺度算子自适应小波分解，实现不同分辨率级别的解耦求解。

Result: 方法实现了近线性计算复杂度，通过自适应策略在平滑区域使用较少的大多边形元素，在高梯度区域使用小元素，提高了内存效率。

Conclusion: 该方法提供了一种高效的多尺度有限元求解框架，能够独立处理不同分辨率级别，显著降低计算成本并提高内存使用效率。

Abstract: We develop a sparse multiscale operator-adapted wavelet decomposition-based finite element method (FEM) on unstructured polygonal mesh hierarchies obtained via a coarsening procedure. Our approach decouples different resolution levels, allowing each scale to be solved independently and added to the entire solution without the need to recompute coarser levels. At the finest level, the meshes consist of triangular elements which are geometrically coarsened at each step to form convex polygonal elements. Smooth field regions of the domain are solved with fewer, larger, polygonal elements, whereas high-gradient regions are represented by smaller elements, thereby improving memory efficiency through adaptivity. The proposed algorithm computes solutions via sequences of hierarchical sparse linear-algebra operations with nearly linear computational complexity.

</details>


### [77] [ClusTEK: A grid clustering algorithm augmented with diffusion imputation and origin-constrained connected-component analysis: Application to polymer crystallization](https://arxiv.org/abs/2512.16110)
*Elyar Tourani,Brian J. Edwards,Bamin Khomami*

Main category: physics.comp-ph

TL;DR: 提出一种结合拉普拉斯核扩散插补和原点约束连通分量分析的网格聚类框架，通过自动预处理和数据驱动参数估计，在保持计算效率的同时提高聚类拓扑重建的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统网格聚类算法存在参数敏感、粗分辨率下结构细节丢失、细分辨率下边缘或桥接单元误分类等问题。现有方法如自适应网格、参数调优或混合方法在鲁棒性方面仍有局限。

Method: 提出统一网格上的聚类框架，包含：1) 自动预处理阶段提供数据驱动的单元大小和密度阈值估计；2) 拉普拉斯核扩散插补缓解稀疏性并重建缺失边缘单元；3) 原点约束连通分量分析(OC-CCA)约束分量增长到物理一致的原点，减少窄间隙处的错误合并。采用固定分辨率网格和空间索引确保O(nlog n)的扩展性。

Result: 在合成基准测试和聚合物模拟数据集上的实验表明，该方法能正确处理边缘、保持聚类拓扑并避免虚假连接。在聚合物系统(9k、180k和989k原子)的基准测试中，最优预处理结合基于扩散的聚类能重现原子级精度，捕捉物理有意义的形态，同时提供加速计算。

Conclusion: 该网格聚类框架通过集成扩散插补和原点约束连通分量分析，在保持计算效率的同时显著提高了聚类拓扑重建的准确性和鲁棒性，特别适用于大规模数据分析场景。

Abstract: Grid clustering algorithms are valued for their efficiency in large-scale data analysis but face persistent limitations: parameter sensitivity, loss of structural detail at coarse resolutions, and misclassifications of edge or bridge cells at fine resolutions. Previous studies have addressed these challenges through adaptive grids, parameter tuning, or hybrid integration with other clustering methods, each of which offers limited robustness. This paper introduces a grid clustering framework that integrates Laplacian-kernel diffusion imputation and origin-constrained connected-component analysis (OC-CCA) on a uniform grid to reconstruct the cluster topology with high accuracy and computational efficiency. During grid construction, an automated preprocessing stage provides data-driven estimates of cell size and density thresholds. The diffusion step then mitigates sparsity and reconstructs missing edge cells without over-smoothing physical gradients, while OC-CCA constrains component growth to physically consistent origins, reducing false merges across narrow gaps. Operating on a fixed-resolution grid with spatial indexing ensures the scaling of O(nlog n). Experiments on synthetic benchmarks and polymer simulation datasets demonstrate that the method correctly manages edges, preserves cluster topology, and avoids spurious connections. Benchmarking on polymer systems across scales (9k, 180k, and 989k atoms) shows that optimal preprocessing, combined with diffusion-based clustering, reproduces atomic-level accuracy and captures physically meaningful morphologies while delivering accelerated computation.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [78] [DiscoverDCP: A Data-Driven Approach for Construction of Disciplined Convex Programs via Symbolic Regression](https://arxiv.org/abs/2512.15721)
*Sveinung Myhre*

Main category: cs.LG

TL;DR: DiscoverDCP：结合符号回归与DCP规则的数据驱动框架，自动发现全局凸的模型表达式，避免后验凸性验证的计算负担


<details>
  <summary>Details</summary>
Motivation: 传统固定参数凸函数（如二次函数）形式受限且不够精确，而系统辨识中需要既能保持凸性又具有灵活函数形式的模型，同时避免后验凸性验证的计算复杂性

Method: 将符号回归与Disciplined Convex Programming（DCP）规则集结合，强制所有发现的候选模型表达式遵循DCP组合规则，确保输出表达式在构造时就是全局凸的

Result: 能够发现比传统固定参数凸表达式更宽松、更精确的凸替代模型，产生可解释、可验证且灵活的凸模型，适用于安全关键的控制和优化任务

Conclusion: DiscoverDCP框架通过将DCP规则嵌入符号回归过程，实现了自动发现全局凸模型，为安全关键应用提供了既精确又保证凸性的系统辨识方法

Abstract: We propose DiscoverDCP, a data-driven framework that integrates symbolic regression with the rule sets of Disciplined Convex Programming (DCP) to perform system identification. By enforcing that all discovered candidate model expressions adhere to DCP composition rules, we ensure that the output expressions are globally convex by construction, circumventing the computationally intractable process of post-hoc convexity verification. This approach allows for the discovery of convex surrogates that exhibit more relaxed and accurate functional forms than traditional fixed-parameter convex expressions (e.g., quadratic functions). The proposed method produces interpretable, verifiable, and flexible convex models suitable for safety-critical control and optimization tasks.

</details>


### [79] [Hybrid Quantum-Classical Ensemble Learning for S\&P 500 Directional Prediction](https://arxiv.org/abs/2512.15738)
*Abraham Itzhak Weinberg*

Main category: cs.LG

TL;DR: 提出混合集成框架，结合量子情感分析、决策变换器架构和战略模型选择，在标普500预测中实现60.14%方向准确率，比单个模型提升3.10%


<details>
  <summary>Details</summary>
Motivation: 金融市场预测是机器学习的重要应用，但大多数模型因高噪声、非平稳性和市场效率难以超过55-57%准确率。现有方法存在三个主要局限：架构多样性不足、情感分析效果有限、弱预测器影响集成性能

Method: 1. 混合集成框架结合多种学习算法（LSTM、决策变换器、XGBoost、随机森林、逻辑回归）；2. 使用4量子比特变分量子电路增强情感分析；3. 智能过滤排除准确率低于52%的弱预测器；4. 采用战略模型选择策略

Result: 在2020-2023年市场数据上实现60.14%方向准确率，比单个模型提升3.10%；McNemar检验证实统计显著性（p<0.05）；初步回测显示夏普比率1.2，优于买入持有策略的0.8

Conclusion: 架构多样性比数据集多样性更重要；量子增强情感分析提供显著增益；智能过滤弱预测器提升集成性能；该框架在复杂市场环境下具有实际交易潜力

Abstract: Financial market prediction is a challenging application of machine learning, where even small improvements in directional accuracy can yield substantial value. Most models struggle to exceed 55--57\% accuracy due to high noise, non-stationarity, and market efficiency. We introduce a hybrid ensemble framework combining quantum sentiment analysis, Decision Transformer architecture, and strategic model selection, achieving 60.14\% directional accuracy on S\&P 500 prediction, a 3.10\% improvement over individual models.
  Our framework addresses three limitations of prior approaches. First, architecture diversity dominates dataset diversity: combining different learning algorithms (LSTM, Decision Transformer, XGBoost, Random Forest, Logistic Regression) on the same data outperforms training identical architectures on multiple datasets (60.14\% vs.\ 52.80\%), confirmed by correlation analysis ($r>0.6$ among same-architecture models). Second, a 4-qubit variational quantum circuit enhances sentiment analysis, providing +0.8\% to +1.5\% gains per model. Third, smart filtering excludes weak predictors (accuracy $<52\%$), improving ensemble performance (Top-7 models: 60.14\% vs.\ all 35 models: 51.2\%).
  We evaluate on 2020--2023 market data across seven instruments, covering diverse regimes including the COVID-19 crash and inflation-driven correction. McNemar's test confirms statistical significance ($p<0.05$). Preliminary backtesting with confidence-based filtering (6+ model consensus) yields a Sharpe ratio of 1.2 versus buy-and-hold's 0.8, demonstrating practical trading potential.

</details>


### [80] [Introduction to Symbolic Regression in the Physical Sciences](https://arxiv.org/abs/2512.15920)
*Deaglan J. Bartlett,Harry Desmond,Pedro G. Ferreira,Gabriel Kronberger*

Main category: cs.LG

TL;DR: 该特刊介绍了物理科学中的符号回归方法，涵盖从自动方程发现到构建计算高效仿真代理模型的应用，并讨论了方法学挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 符号回归已成为从数据中发现可解释数学关系的强大方法，为科学发现和高效经验建模提供了新途径。该特刊的动机源于2025年4月皇家学会讨论会议，旨在展示符号回归在物理科学中的最新进展和应用。

Method: 特刊包含综述性介绍，涵盖符号回归的概念基础、与传统回归方法的对比、在物理科学中的主要应用案例（包括有效理论推导、经验函数形式和代理模型构建），以及方法学考虑如搜索空间设计、算子选择、复杂度控制、特征选择等。

Result: 特刊收集的论文展示了符号回归在物理科学中的广泛应用，包括自动方程发现、涌现现象建模和计算昂贵仿真的紧凑代理模型构建。这些贡献说明了符号回归的加速进展及其在物理科学中日益增长的相关性。

Conclusion: 符号回归在物理科学中显示出巨大潜力，但仍面临可扩展性、噪声鲁棒性、过拟合和计算复杂度等挑战。未来方向包括整合对称性约束、渐近行为和其他理论信息，这些新兴方向将推动符号回归的进一步发展。

Abstract: Symbolic regression (SR) has emerged as a powerful method for uncovering interpretable mathematical relationships from data, offering a novel route to both scientific discovery and efficient empirical modelling. This article introduces the Special Issue on Symbolic Regression for the Physical Sciences, motivated by the Royal Society discussion meeting held in April 2025. The contributions collected here span applications from automated equation discovery and emergent-phenomena modelling to the construction of compact emulators for computationally expensive simulations.
  The introductory review outlines the conceptual foundations of SR, contrasts it with conventional regression approaches, and surveys its main use cases in the physical sciences, including the derivation of effective theories, empirical functional forms and surrogate models. We summarise methodological considerations such as search-space design, operator selection, complexity control, feature selection, and integration with modern AI approaches. We also highlight ongoing challenges, including scalability, robustness to noise, overfitting and computational complexity. Finally we emphasise emerging directions, particularly the incorporation of symmetry constraints, asymptotic behaviour and other theoretical information. Taken together, the papers in this Special Issue illustrate the accelerating progress of SR and its growing relevance across the physical sciences.

</details>


### [81] [SHARe-KAN: Holographic Vector Quantization for Memory-Bound Inference](https://arxiv.org/abs/2512.15742)
*Jeff Smith*

Main category: cs.LG

TL;DR: SHARe-KAN框架通过Gain-Shape-Bias向量量化解决Vision KANs的内存瓶颈问题，结合硬件感知编译器实现88倍内存减少，同时保持原始精度。


<details>
  <summary>Details</summary>
Motivation: Kolmogorov-Arnold Networks (KANs)面临基本的内存墙问题：学习的基础函数导致参数数量激增，带来极高的带宽需求，阻碍了在内存受限环境中的部署。传统剪枝方法在Vision KANs上失败（10%稀疏度导致mAP从85.23%降至45%）。

Method: 提出SHARe-KAN框架，采用Gain-Shape-Bias向量量化来利用函数冗余同时保持密集拓扑结构。结合LUTHAM硬件感知编译器进行静态内存规划。

Result: 实现88倍运行时内存减少（从1.13GB降至12.91MB），在PASCAL VOC上匹配未压缩基线精度。在NVIDIA Ampere架构上分析显示>90% L2缓存驻留，工作负载与DRAM带宽约束解耦。

Conclusion: SHARe-KAN成功解决了Vision KANs的内存墙问题，通过向量量化和硬件感知编译技术实现了高效的内存压缩，同时保持了模型精度，为基于样条的架构在内存受限环境中的部署提供了可行方案。

Abstract: Kolmogorov-Arnold Networks (KANs) face a fundamental memory wall: their learned basis functions create parameter counts that impose extreme bandwidth demands, hindering deployment in memory-constrained environments. We show that Vision KANs exhibit a holographic topology, where information is distributed across the interference of splines rather than localized to specific edges. Consequently, traditional pruning fails (10% sparsity degrades mAP from 85.23% to 45%, a $\sim$40-point drop). To address this, we present SHARe-KAN, a framework utilizing Gain-Shape-Bias Vector Quantization to exploit functional redundancy while preserving the dense topology. Coupled with LUTHAM, a hardware-aware compiler with static memory planning, we achieve $88\times$ runtime memory reduction (1.13 GB $\to$ 12.91 MB) and match uncompressed baseline accuracy on PASCAL VOC. Profiling on NVIDIA Ampere architecture confirms $>90\%$ L2 cache residency, demonstrating that the workload is decoupled from DRAM bandwidth constraints inherent to spline-based architectures.

</details>


### [82] [How Do Graph Signals Affect Recommendation: Unveiling the Mystery of Low and High-Frequency Graph Signals](https://arxiv.org/abs/2512.15744)
*Feng Liu,Hao Cang,Huanhuan Yuan,Jiaqing Fan,Yongjing Hao,Fuzhen Zhuang,Guanfeng Liu,Pengpeng Zhao*

Main category: cs.LG

TL;DR: 该论文研究图信号在推荐系统中的角色，证明低频和高频图信号在推荐任务中具有等效效果，提出频率信号缩放器和空间翻转方法增强GNN推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究对低频和高频图信号在推荐系统中的作用认识不清，虽然谱图神经网络在推荐中很有效，但高频信号的重要性被忽视，需要澄清不同频率图信号对推荐性能的影响。

Method: 1. 理论证明低频和高频图信号在推荐任务中的等效性；2. 提出频率信号缩放器（可插拔模块）调整图信号滤波器函数，微调用户-物品对的平滑度；3. 提出空间翻转方法恢复图嵌入的表达能力。

Result: 实验证明仅使用低频或高频图信号就足以实现有效推荐，提出的方法在四个公开数据集上验证了有效性，代码已开源。

Conclusion: 低频和高频图信号在推荐任务中具有等效作用，都通过平滑用户-物品对相似性来贡献推荐性能，提出的频率信号缩放器和空间翻转方法能有效提升GNN推荐模型性能。

Abstract: Spectral graph neural networks (GNNs) are highly effective in modeling graph signals, with their success in recommendation often attributed to low-pass filtering. However, recent studies highlight the importance of high-frequency signals. The role of low-frequency and high-frequency graph signals in recommendation remains unclear. This paper aims to bridge this gap by investigating the influence of graph signals on recommendation performance. We theoretically prove that the effects of low-frequency and high-frequency graph signals are equivalent in recommendation tasks, as both contribute by smoothing the similarities between user-item pairs. To leverage this insight, we propose a frequency signal scaler, a plug-and-play module that adjusts the graph signal filter function to fine-tune the smoothness between user-item pairs, making it compatible with any GNN model. Additionally, we identify and prove that graph embedding-based methods cannot fully capture the characteristics of graph signals. To address this limitation, a space flip method is introduced to restore the expressive power of graph embeddings. Remarkably, we demonstrate that either low-frequency or high-frequency graph signals alone are sufficient for effective recommendations. Extensive experiments on four public datasets validate the effectiveness of our proposed methods. Code is avaliable at https://github.com/mojosey/SimGCF.

</details>


### [83] [LLaDA2.0: Scaling Up Diffusion Language Models to 100B](https://arxiv.org/abs/2512.15745)
*Tiwei Bie,Maosong Cao,Kun Chen,Lun Du,Mingliang Gong,Zhuochen Gong,Yanmei Gu,Jiaqi Hu,Zenan Huang,Zhenzhong Lan,Chengxi Li,Chongxuan Li,Jianguo Li,Zehuan Li,Huabin Liu,Ling Liu,Guoshan Lu,Xiaocheng Lu,Yuxin Ma,Jianfeng Tan,Lanning Wei,Ji-Rong Wen,Yipeng Xing,Xiaolu Zhang,Junbo Zhao,Da Zheng,Jun Zhou,Junlin Zhou,Zhanchao Zhou,Liwang Zhu,Yihong Zhuang*

Main category: cs.LG

TL;DR: LLaDA2.0 是一个通过系统转换自回归模型构建的离散扩散大语言模型，参数规模达100B，采用渐进式块扩散训练方案，包含16B和100B两个MoE变体，支持并行解码，已开源。


<details>
  <summary>Details</summary>
Motivation: 避免从头训练的高成本，通过知识继承、渐进适应和效率感知的设计原则，将预训练的自回归模型高效转换为离散扩散模型，实现前沿规模的部署。

Method: 提出3阶段块级WSD训练方案：1) 渐进增加块大小的块扩散（预热）；2) 大规模全序列扩散（稳定）；3) 回退到紧凑块大小扩散（衰减）。结合SFT和DPO进行后训练对齐，得到优化的MoE变体。

Result: 开发了LLaDA2.0-mini (16B) 和 LLaDA2.0-flash (100B) 两个指令调优的MoE变体，保持并行解码优势，在前沿规模上提供卓越的性能和效率，两个模型均已开源。

Conclusion: LLaDA2.0建立了一个新的前沿规模部署范式，通过系统转换而非从头训练，实现了知识继承和高效部署，为大规模离散扩散语言模型的实际应用提供了可行方案。

Abstract: This paper presents LLaDA2.0 -- a tuple of discrete diffusion large language models (dLLM) scaling up to 100B total parameters through systematic conversion from auto-regressive (AR) models -- establishing a new paradigm for frontier-scale deployment. Instead of costly training from scratch, LLaDA2.0 upholds knowledge inheritance, progressive adaption and efficiency-aware design principle, and seamless converts a pre-trained AR model into dLLM with a novel 3-phase block-level WSD based training scheme: progressive increasing block-size in block diffusion (warm-up), large-scale full-sequence diffusion (stable) and reverting back to compact-size block diffusion (decay). Along with post-training alignment with SFT and DPO, we obtain LLaDA2.0-mini (16B) and LLaDA2.0-flash (100B), two instruction-tuned Mixture-of-Experts (MoE) variants optimized for practical deployment. By preserving the advantages of parallel decoding, these models deliver superior performance and efficiency at the frontier scale. Both models were open-sourced.

</details>


### [84] [A Unified Generative-Predictive Framework for Deterministic Inverse Design](https://arxiv.org/abs/2512.15746)
*Reza T. Batley,Sourav Saha*

Main category: cs.LG

TL;DR: Janus框架统一生成与预测，通过解耦潜在空间实现异构材料微结构的实时物理感知逆向设计


<details>
  <summary>Details</summary>
Motivation: 异构材料微结构的逆向设计是一个病态且计算昂贵的问题，现有生成模型难以支持快速、稳定的确定性物理感知逆向

Method: 提出Janus框架，耦合深度编码器-解码器与可分离的KHRONOS预测头，学习同时支持生成逆向和物理预测的等距潜在流形

Result: 在MNIST上实现高保真重建和准确分类；在热导率微结构设计中达到R²=0.98的预测精度，逆向解满足1%相对误差

Conclusion: Janus通过统一预测和生成，实现了实时、物理感知的逆向微结构生成，计算成本低于传统优化方法

Abstract: Inverse design of heterogeneous material microstructures is a fundamentally ill-posed and famously computationally expensive problem. This is exacerbated by the high-dimensional design spaces associated with finely resolved images, multimodal input property streams, and a highly nonlinear forward physics. Whilst modern generative models excel at accurately modeling such complex forward behavior, most of them are not intrinsically structured to support fast, stable \emph{deterministic} inversion with a physics-informed bias. This work introduces Janus, a unified generative-predictive framework to address this problem. Janus couples a deep encoder-decoder architecture with a predictive KHRONOS head, a separable neural architecture. Topologically speaking, Janus learns a latent manifold simultaneously isometric for generative inversion and pruned for physical prediction; the joint objective inducing \emph{disentanglement} of the latent space. Janus is first validated on the MNIST dataset, demonstrating high-fidelity reconstruction, accurate classification and diverse generative inversion of all ten target classes. It is then applied to the inverse design of heterogeneous microstructures labeled with thermal conductivity. It achieves a forward prediction accuracy $R^2=0.98$ (2\% relative error) and sub-5\% pixelwise reconstruction error. Inverse solutions satisfy target properties to within $1\%$ relative error. Inverting a sweep through properties reveal smooth traversal of the latent manifold, and UMAP visualization confirms the emergence of a low-dimensional, disentangled manifold. By unifying prediction and generation within a single latent space, Janus enables real-time, physics-informed inverse microstructure generation at a lower computational cost typically associated with classical optimization-based approaches.

</details>


### [85] [D3G: Diverse Demographic Data Generation Increases Zero-Shot Image Classification Accuracy within Multimodal Models](https://arxiv.org/abs/2512.15747)
*Javon Hickmon*

Main category: cs.LG

TL;DR: 提出D3G方法，在零样本图像分类中通过生成多样化人口统计数据来提升准确率并减少偏见


<details>
  <summary>Details</summary>
Motivation: 当前多模态模型在细粒度图像分类中面临欠拟合问题，且数据集人口统计不平衡会导致偏见，影响零样本分类的公平性

Method: 提出D3G方法，使用CLIP作为基础多模态模型，Stable Diffusion XL作为生成模型，在推理时生成多样化人口统计数据来增强分类

Result: 在推理时提供多样化人口统计数据能提升模型性能，并探索了不同人口统计特征对准确率的影响

Conclusion: D3G方法能有效提升零样本图像分类准确率并减少人口统计偏见，无需额外训练

Abstract: Image classification is a task essential for machine perception to achieve human-level image understanding. Multimodal models such as CLIP have been able to perform well on this task by learning semantic similarities across vision and language; however, despite these advances, image classification is still a challenging task. Models with low capacity often suffer from underfitting and thus underperform on fine-grained image classification. Along with this, it is important to ensure high-quality data with rich cross-modal representations of each class, which is often difficult to generate. When datasets do not enforce balanced demographics, the predictions will be biased toward the more represented class, while others will be neglected. We focus on how these issues can lead to harmful bias for zero-shot image classification, and explore how to combat these issues in demographic bias. We propose Diverse Demographic Data Generation (D3G), a training-free, zero-shot method of boosting classification accuracy while reducing demographic bias in pre-trained multimodal models. With this method, we utilize CLIP as our base multimodal model and Stable Diffusion XL as our generative model. We demonstrate that providing diverse demographic data at inference time improves performance for these models, and explore the impact of individual demographics on the resulting accuracy metric.

</details>


### [86] [Surely Large Multimodal Models (Don't) Excel in Visual Species Recognition?](https://arxiv.org/abs/2512.15748)
*Tian Liu,Anwesha Basu,James Caverlee,Shu Kong*

Main category: cs.LG

TL;DR: 提出POC方法，利用大语言多模态模型对少样本学习专家模型的预测进行后验校正，显著提升视觉物种识别性能


<details>
  <summary>Details</summary>
Motivation: 视觉物种识别需要大量标注数据，但物种级标注需要领域专家，通常只能获得少量标注样本。虽然大语言多模态模型在通用识别任务上表现优异，但在高度专业化的视觉物种识别任务中表现不佳，甚至不如简单的少样本学习专家模型

Method: 提出后验校正方法：使用少样本学习专家模型对测试图像生成top预测，然后用大语言多模态模型重新排序这些预测。提示词包含softmax置信度分数和少量视觉示例，无需额外训练、验证或人工干预

Result: 在五个具有挑战性的视觉物种识别基准测试中，POC方法比现有少样本学习方法准确率提升+6.4%，且能泛化到不同的预训练骨干网络和大语言多模态模型

Conclusion: POC是一个即插即用的模块，能显著增强现有少样本学习方法，通过大语言多模态模型的后验校正能力提升视觉物种识别性能，为生物多样性评估和保护提供了有效工具

Abstract: Visual Species Recognition (VSR) is pivotal to biodiversity assessment and conservation, evolution research, and ecology and ecosystem management. Training a machine-learned model for VSR typically requires vast amounts of annotated images. Yet, species-level annotation demands domain expertise, making it realistic for domain experts to annotate only a few examples. These limited labeled data motivate training an ''expert'' model via few-shot learning (FSL). Meanwhile, advanced Large Multimodal Models (LMMs) have demonstrated prominent performance on general recognition tasks. It is straightforward to ask whether LMMs excel in the highly specialized VSR task and whether they outshine FSL expert models. Somewhat surprisingly, we find that LMMs struggle in this task, despite using various established prompting techniques. LMMs even significantly underperform FSL expert models, which are as simple as finetuning a pretrained visual encoder on the few-shot images. However, our in-depth analysis reveals that LMMs can effectively post-hoc correct the expert models' incorrect predictions. Briefly, given a test image, when prompted with the top predictions from an FSL expert model, LMMs can recover the ground-truth label. Building on this insight, we derive a simple method called Post-hoc Correction (POC), which prompts an LMM to re-rank the expert model's top predictions using enriched prompts that include softmax confidence scores and few-shot visual examples. Across five challenging VSR benchmarks, POC outperforms prior art of FSL by +6.4% in accuracy without extra training, validation, or manual intervention. Importantly, POC generalizes to different pretrained backbones and LMMs, serving as a plug-and-play module to significantly enhance existing FSL methods.

</details>


### [87] [A Special Case of Quadratic Extrapolation Under the Neural Tangent Kernel](https://arxiv.org/abs/2512.15749)
*Abiel Kim*

Main category: cs.LG

TL;DR: ReLU MLP在NTK机制下，在原点附近的分布外评估点表现出二次外推特性，这与远离原点的线性外推形成对比。


<details>
  <summary>Details</summary>
Motivation: 虽然ReLU MLP在分布外评估点通常呈现线性外推已有充分研究，但在NTK机制下，原点附近的外推分析仍相对缺乏。由于NTK诱导的无限维特征映射不具有平移不变性，原点附近和远离原点的情况代表了ReLU NTK外推的两个极端边界。

Method: 在神经正切核(NTK)机制下分析ReLU多层感知机的外推行为，特别关注原点附近和远离原点这两种特殊情况的对比研究。

Result: 研究发现，在NTK机制下，ReLU MLP在原点附近的分布外评估点表现出二次外推特性，这与远离原点时的线性外推形成鲜明对比。

Conclusion: ReLU NTK的外推行为存在两种极端情况：远离原点时呈现线性外推，而原点附近则表现出二次外推特性，这源于NTK特征映射的平移不变性缺失和旋转不变性。

Abstract: It has been demonstrated both theoretically and empirically that the ReLU MLP tends to extrapolate linearly for an out-of-distribution evaluation point. The machine learning literature provides ample analysis with respect to the mechanisms to which linearity is induced. However, the analysis of extrapolation at the origin under the NTK regime remains a more unexplored special case. In particular, the infinite-dimensional feature map induced by the neural tangent kernel is not translationally invariant. This means that the study of an out-of-distribution evaluation point very far from the origin is not equivalent to the evaluation of a point very near the origin. And since the feature map is rotation invariant, these two special cases may represent the most canonically extreme bounds of ReLU NTK extrapolation. Ultimately, it is this loose recognition of the two special cases of extrapolation that motivate the discovery of quadratic extrapolation for an evaluation close to the origin.

</details>


### [88] [GLOW: Graph-Language Co-Reasoning for Agentic Workflow Performance Prediction](https://arxiv.org/abs/2512.15751)
*Wei Guan,Jian Cao,Jinyu Cai,Qiqi Cai,Jianqi Gao,See-Kiong Ng*

Main category: cs.LG

TL;DR: GLOW：结合GNN和LLM的图导向大语言模型，用于预测Agentic Workflows性能，解决现有方法无法同时捕捉拓扑依赖和语义逻辑的问题


<details>
  <summary>Details</summary>
Motivation: Agentic Workflows自动化生成的可扩展性受限于执行评估的高成本和延迟，现有性能预测方法无法同时捕捉复杂的拓扑依赖和深层语义逻辑

Method: 提出GLOW统一框架，结合GNN的图结构建模能力和LLM的推理能力；使用图导向LLM提取拓扑感知语义特征，与GNN编码的结构表示融合；采用对比对齐策略优化潜在空间以区分高质量AWs

Result: 在FLORA-Bench上的大量实验表明，GLOW在预测准确性和排序效用方面优于最先进的基线方法

Conclusion: GLOW通过融合图结构建模和语义推理，有效解决了Agentic Workflows性能预测的挑战，为AW自动化生成提供了高效评估方案

Abstract: Agentic Workflows (AWs) have emerged as a promising paradigm for solving complex tasks. However, the scalability of automating their generation is severely constrained by the high cost and latency of execution-based evaluation. Existing AW performance prediction methods act as surrogates but fail to simultaneously capture the intricate topological dependencies and the deep semantic logic embedded in AWs. To address this limitation, we propose GLOW, a unified framework for AW performance prediction that combines the graph-structure modeling capabilities of GNNs with the reasoning power of LLMs. Specifically, we introduce a graph-oriented LLM, instruction-tuned on graph tasks, to extract topologically aware semantic features, which are fused with GNN-encoded structural representations. A contrastive alignment strategy further refines the latent space to distinguish high-quality AWs. Extensive experiments on FLORA-Bench show that GLOW outperforms state-of-the-art baselines in prediction accuracy and ranking utility.

</details>


### [89] [TAO-Net: Two-stage Adaptive OOD Classification Network for Fine-grained Encrypted Traffic Classification](https://arxiv.org/abs/2512.15753)
*Zihao Wang,Wei Peng,Junming Zhang,Jian Li,Wenxin Fang*

Main category: cs.LG

TL;DR: TAO-Net：一种两阶段自适应OOD加密流量分类网络，通过混合OOD检测机制和基于大语言模型的语义增强提示策略，实现对已知和未知加密流量的精确细粒度分类。


<details>
  <summary>Details</summary>
Motivation: 加密流量分类面临新应用不断涌现的挑战，这些新应用产生超出已知分布（OOD）的流量模式。现有方法依赖预定义类别，无法有效处理未知流量类型，或将未知流量简单归为"其他"类别，缺乏细粒度分类能力。

Method: 提出两阶段自适应OOD分类网络（TAO-Net）：第一阶段采用混合OOD检测机制，结合基于Transformer的层间变换平滑度和特征分析来区分ID和OOD流量；第二阶段利用大语言模型和语义增强提示策略，将OOD流量分类转化为生成任务，实现无需预定义标签的灵活细粒度分类。

Result: 在三个数据集上的实验表明，TAO-Net达到96.81-97.70%的宏精确率和96.77-97.68%的宏F1分数，显著优于先前方法（仅44.73-86.30%宏精确率），特别是在识别新兴网络应用方面表现优异。

Conclusion: TAO-Net通过创新的两阶段设计有效解决了加密流量分类中的OOD问题，实现了对已知和未知流量的精确细粒度分类，为处理不断涌现的新网络应用提供了有效解决方案。

Abstract: Encrypted traffic classification aims to identify applications or services by analyzing network traffic data. One of the critical challenges is the continuous emergence of new applications, which generates Out-of-Distribution (OOD) traffic patterns that deviate from known categories and are not well represented by predefined models. Current approaches rely on predefined categories, which limits their effectiveness in handling unknown traffic types. Although some methods mitigate this limitation by simply classifying unknown traffic into a single "Other" category, they fail to make a fine-grained classification. In this paper, we propose a Two-stage Adaptive OOD classification Network (TAO-Net) that achieves accurate classification for both In-Distribution (ID) and OOD encrypted traffic. The method incorporates an innovative two-stage design: the first stage employs a hybrid OOD detection mechanism that integrates transformer-based inter-layer transformation smoothness and feature analysis to effectively distinguish between ID and OOD traffic, while the second stage leverages large language models with a novel semantic-enhanced prompt strategy to transform OOD traffic classification into a generation task, enabling flexible fine-grained classification without relying on predefined labels. Experiments on three datasets demonstrate that TAO-Net achieves 96.81-97.70% macro-precision and 96.77-97.68% macro-F1, outperforming previous methods that only reach 44.73-86.30% macro-precision, particularly in identifying emerging network applications.

</details>


### [90] [KAN-Matrix: Visualizing Nonlinear Pairwise and Multivariate Contributions for Physical Insight](https://arxiv.org/abs/2512.15755)
*Luis A. De la Fuente,Hernan A. Moreno,Laura V. Alvarez,Hoshin V. Gupta*

Main category: cs.LG

TL;DR: 论文提出两种基于Kolmogorov-Arnold Networks的可视化工具PKAN和MKAN，用于增强高维数据的可解释性，相比传统相关性分析能更好地捕捉非线性关系。


<details>
  <summary>Details</summary>
Motivation: 解决复杂数据集解释的挑战，特别是高维度和变量间共线性问题。传统相关性分析在捕捉非线性关系和提供可解释性方面存在局限。

Method: 应用Kolmogorov-Arnold Networks（KANs）开发两种可视化工具：PKAN（成对KAN矩阵）用于表征变量间的非线性关联；MKAN（多元KAN贡献矩阵）作为非线性特征排序工具，量化输入变量对目标变量的相对贡献。

Result: 实验比较显示，PKAN和MKAN比Pearson相关性和互信息方法产生更稳健和信息丰富的结果。这些工具能够捕捉关系的强度和函数形式，促进隐藏物理模式的发现。

Conclusion: PKAN和MKAN为模型开发工作流提供了有效的预处理（特征选择、冗余分析）和后处理（模型解释、物理洞察）工具，支持基于领域知识的模型开发。

Abstract: Interpreting complex datasets remains a major challenge for scientists, particularly due to high dimensionality and collinearity among variables. We introduce a novel application of Kolmogorov-Arnold Networks (KANs) to enhance interpretability and parsimony beyond what traditional correlation analyses offer. We present two interpretable, color-coded visualization tools: the Pairwise KAN Matrix (PKAN) and the Multivariate KAN Contribution Matrix (MKAN). PKAN characterizes nonlinear associations between pairs of variables, while MKAN serves as a nonlinear feature-ranking tool that quantifies the relative contributions of inputs in predicting a target variable. These tools support pre-processing (e.g., feature selection, redundancy analysis) and post-processing (e.g., model explanation, physical insights) in model development workflows. Through experimental comparisons, we demonstrate that PKAN and MKAN yield more robust and informative results than Pearson Correlation and Mutual Information. By capturing the strength and functional forms of relationships, these matrices facilitate the discovery of hidden physical patterns and promote domain-informed model development.

</details>


### [91] [ReactorFold: Generative discovery of nuclear reactor cores via emergent physical reasoning](https://arxiv.org/abs/2512.15756)
*Yoonpyo Lee*

Main category: cs.LG

TL;DR: ReactorFold：将核反应堆燃料组件设计重新定义为语言模型的序列建模问题，通过DPO对齐实现设计空间扩展，能够自主调整Gd棒数量并发现高性能非对称配置。


<details>
  <summary>Details</summary>
Motivation: 传统核反应堆设计方法（确定性、元启发式、机器学习辅助）在固定的人工定义配置空间中搜索，限制了发现全新设计拓扑的能力。需要一种能够超越人类设计约束、发现根本性新设计的方法。

Method: 提出ReactorFold生成框架：1) 将燃料组件设计重新定义为语言模型的序列建模问题；2) 使用蒙特卡洛数据进行参数高效微调；3) 采用直接偏好优化(DPO)对齐模型；4) 模型通过单次前向传播生成候选布局。

Result: 1) DPO对齐模型展现出设计空间扩展的涌现能力：尽管仅在固定Gd棒数量的配置上训练，却能自主调整Gd库存以满足严格的功率峰值约束；2) 发现了挑战传统对称装载启发式的高性能非对称配置；3) 能够访问传统搜索方法无法达到的设计区域。

Conclusion: 语言模型能够内化因果物理关系并超越人类施加的设计约束，为核反应堆设计提供了新的生成方法，能够发现传统方法无法访问的高性能设计配置。

Abstract: Designing nuclear reactor cores requires navigating large discrete design spaces governed by complex neutronic interactions. Traditional deterministic, metaheuristic, and machine-learning-assisted methods search within fixed, human-defined configuration spaces, limiting their ability to discover fundamentally new design topologies. Here we introduce ReactorFold, a generative framework that reformulates fuel-assembly design as a sequence modeling problem for language models. Using Monte Carlo data, parameter-efficient fine-tuning, and Direct Preference Optimization (DPO), the model learns the latent structure of a pressurized-water-reactor assembly and generates candidate layouts in a single forward pass. Notably, the DPO-aligned model exhibits emergent design-space expansion: despite being trained exclusively on configurations with a fixed number of gadolinium burnable absorber (Gd) rods, it autonomously adjusts Gd inventory to satisfy strict power-peaking constraints. The model also discovers high-performing asymmetric configurations that challenge conventional symmetric loading heuristics, accessing design regimes inaccessible to conventional search methods and demonstrating that language models can internalize causal physical relationships and transcend human-imposed design constraints.

</details>


### [92] [Twin Restricted Kernel Machines for Multiview Classification](https://arxiv.org/abs/2512.15757)
*A. Quadir,M. Sajid,Mushir Akhtar,M. Tanveer*

Main category: cs.LG

TL;DR: 提出了一种新的多视图孪生限制核机(TMvRKM)模型，通过正则化最小二乘方法高效确定最优分离超平面，解决了传统核方法在计算效率和泛化性能方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统多视图支持向量机(MvSVM)方法在高维空间中使用核技巧时难以有效捕捉决策边界，容易产生错误且难以处理视图不一致性问题，这些在多视图数据集中很常见。

Method: 提出TMvRKM模型，将核机优势与多视图框架结合，通过正则化最小二乘方法而非传统的大规模二次规划问题来高效确定最优分离超平面。模型包含耦合项以平衡多视图误差，并整合早期和晚期融合策略。

Result: 在UCI、KEEL和AwA基准数据集上进行严格测试，实验和统计分析一致显示TMvRKM具有优异的泛化性能，在所有场景中都优于基线模型。

Conclusion: TMvRKM成功解决了传统核方法在计算效率和泛化性能方面的挑战，通过创新的融合策略和高效优化方法，在多视图学习中展现出卓越性能。

Abstract: Multi-view learning (MVL) is an emerging field in machine learning that focuses on improving generalization performance by leveraging complementary information from multiple perspectives or views. Various multi-view support vector machine (MvSVM) approaches have been developed, demonstrating significant success. Moreover, these models face challenges in effectively capturing decision boundaries in high-dimensional spaces using the kernel trick. They are also prone to errors and struggle with view inconsistencies, which are common in multi-view datasets. In this work, we introduce the multiview twin restricted kernel machine (TMvRKM), a novel model that integrates the strengths of kernel machines with the multiview framework, addressing key computational and generalization challenges associated with traditional kernel-based approaches. Unlike traditional methods that rely on solving large quadratic programming problems (QPPs), the proposed TMvRKM efficiently determines an optimal separating hyperplane through a regularized least squares approach, enhancing both computational efficiency and classification performance. The primal objective of TMvRKM includes a coupling term designed to balance errors across multiple views effectively. By integrating early and late fusion strategies, TMvRKM leverages the collective information from all views during training while remaining flexible to variations specific to individual views. The proposed TMvRKM model is rigorously tested on UCI, KEEL, and AwA benchmark datasets. Both experimental results and statistical analyses consistently highlight its exceptional generalization performance, outperforming baseline models in every scenario.

</details>


### [93] [Yantra AI -- An intelligence platform which interacts with manufacturing operations](https://arxiv.org/abs/2512.15758)
*Varshini Krishnamurthy*

Main category: cs.LG

TL;DR: 该论文开发了一个用于XRIT的智能生产系统，集成了机器学习模型（随机森林分类器和孤立森林）进行预测性维护和异常检测，结合Streamlit实时可视化仪表板和GPT-4虚拟助手，显著提升了运营效率、能源管理和维修规划能力。


<details>
  <summary>Details</summary>
Motivation: 工业4.0快速发展改变了智能生产，需要解决能源管理、预测性维护和AI决策支持等关键问题。XRIT生产环境需要实时监控、机器学习集成和AI驱动系统来优化运营。

Method: 开发智能生产系统，集成随机森林分类器进行主动维护预测，孤立森林进行异常检测。使用Streamlit构建实时数据可视化仪表板，集成GPT-4构建AI虚拟助手提供实时决策支持。系统使用模拟数据进行测试，设计为可扩展架构。

Result: 系统测试显示显著提升了运营效率、能源管理和维修规划能力。AI虚拟助手使工人能够获得实时有用信息，简化复杂问题解答，改善操作决策。系统设计为可扩展，适合XRIT生产环境实时部署。

Conclusion: 开发的智能生产系统成功解决了工业4.0环境下的关键生产问题。未来工作将专注于系统向实时数据集成迁移，并探索其他优化改进方向。

Abstract: Industry 4.0 is growing quickly, which has changed smart production by encouraging the use of real-time tracking, machine learning, and AI-driven systems to make operations run more smoothly. The main focus of this dissertation is on creating and testing an intelligent production system for XRIT that solves important problems like energy management, predictive maintenance, and AI-powered decision support. Machine learning models are built into the system, such as the Random Forest Classifier for proactive maintenance and the Isolation Forest for finding outliers. These models help with decision-making and reducing downtime. Streamlit makes real-time data visualisation possible, giving workers access to dashboards that they can interact with and see real-time observations.The system was tested with fake data and is made to be scalable, so it can be used in real time in XRIT's production setting. Adding an AI-powered virtual assistant made with GPT-4 lets workers get real-time, useful information that makes complicated questions easier to answer and improves operational decisions. The testing shows that the system makes working efficiency, energy management, and the ability to plan repairs much better. Moving the system to real-time data merging and looking for other ways to make it better will be the main focus of future work.

</details>


### [94] [Semantic-Constrained Federated Aggregation: Convergence Theory and Privacy-Utility Bounds for Knowledge-Enhanced Distributed Learning](https://arxiv.org/abs/2512.15759)
*Jahidul Arafat*

Main category: cs.LG

TL;DR: 提出语义约束联邦聚合(SCFA)框架，将领域知识约束融入联邦学习优化，理论上证明收敛性，实践中在非IID数据下提升收敛速度22%，减少模型发散41.3%


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习方法在非独立同分布数据下收敛缓慢，且对所有客户端更新采用相同处理方式，忽略了语义有效性。需要将领域知识约束融入分布式优化以改善性能

Method: 提出语义约束联邦聚合(SCFA)框架，将领域知识约束作为正则化项加入联邦学习优化目标。使用知识图谱编码约束（从ISA-95和MASON本体中提取3000个约束），在理论分析中建立收敛理论，证明约束能减少数据异质性

Result: 理论证明收敛率O(1/sqrt(T)+ρ)，约束减少41%数据异质性，隐私-效用权衡改善2.7倍。在博世生产数据实验中：收敛速度提升22%，模型发散减少41.3%，约束违反率ρ<0.05时保持90%最优性能

Conclusion: SCFA框架成功将领域知识约束融入联邦学习，在理论和实践中都证明了其有效性，显著改善非IID数据下的收敛性能、隐私-效用权衡和模型质量

Abstract: Federated learning enables collaborative model training across distributed data sources but suffers from slow convergence under non-IID data conditions. Existing solutions employ algorithmic modifications treating all client updates identically, ignoring semantic validity. We introduce Semantic-Constrained Federated Aggregation (SCFA), a theoretically-grounded framework incorporating domain knowledge constraints into distributed optimization. We prove SCFA achieves convergence rate O(1/sqrt(T) + rho) where rho represents constraint violation rate, establishing the first convergence theory for constraint-based federated learning. Our analysis shows constraints reduce effective data heterogeneity by 41% and improve privacy-utility tradeoffs through hypothesis space reduction by factor theta=0.37. Under (epsilon,delta)-differential privacy with epsilon=10, constraint regularization maintains utility within 3.7% of non-private baseline versus 12.1% degradation for standard federated learning, representing 2.7x improvement. We validate our framework on manufacturing predictive maintenance using Bosch production data with 1.18 million samples and 968 sensor features, constructing knowledge graphs encoding 3,000 constraints from ISA-95 and MASON ontologies. Experiments demonstrate 22% faster convergence, 41.3% model divergence reduction, and constraint violation thresholds where rho<0.05 maintains 90% optimal performance while rho>0.18 causes catastrophic failure. Our theoretical predictions match empirical observations with R^2>0.90 across convergence, privacy, and violation-performance relationships.

</details>


### [95] [A Tutorial on Dimensionless Learning: Geometric Interpretation and the Effect of Noise](https://arxiv.org/abs/2512.15760)
*Zhengtao Jake Gan,Xiaoyu Xie*

Main category: cs.LG

TL;DR: 本文介绍了一种结合经典量纲分析与现代机器学习的方法——无量纲学习，用于从实验数据中发现无量纲数和标度律，并通过正则化技术使学习到的系数具有可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统实验数据分析往往难以发现隐藏的物理规律和标度关系，需要一种系统性的方法从实验测量中自动发现无量纲数和物理定律，同时保持物理可解释性。

Method: 将实验数据中的物理量组合成无量纲群，使用神经网络发现最佳预测实验输出的组合，并采用正则化技术鼓励学习到的系数取简单可解释值（如整数或半整数）。

Result: 方法能够有效处理单变量或多变量情况，揭示不同但等效的物理表示，正则化方法对测量噪声和离散采样具有鲁棒性，成功发现了准确且物理意义明确的定律。

Conclusion: 无量纲学习为实验数据分析提供了强大的数据驱动框架，但仍面临计算成本、数据特性影响、变量自动选择和工具易用性等挑战，需要进一步研究解决。

Abstract: Dimensionless learning is a data-driven framework for discovering dimensionless numbers and scaling laws from experimental measurements. This tutorial introduces the method, explaining how it transforms experimental data into compact physical laws that reveal compact dimensional invariance between variables. The approach combines classical dimensional analysis with modern machine learning techniques. Starting from measurements of physical quantities, the method identifies the fundamental ways to combine variables into dimensionless groups, then uses neural networks to discover which combinations best predict the experimental output. A key innovation is a regularization technique that encourages the learned coefficients to take simple, interpretable values like integers or half-integers, making the discovered laws both accurate and physically meaningful. We systematically investigate how measurement noise and discrete sampling affect the discovery process, demonstrating that the regularization approach provides robustness to experimental uncertainties. The method successfully handles cases with single or multiple dimensionless numbers, revealing how different but equivalent representations can capture the same underlying physics. Despite recent progress, key challenges remain, including managing the computational cost of identifying multiple dimensionless groups, understanding the influence of data characteristics, automating the selection of relevant input variables, and developing user-friendly tools for experimentalists. This tutorial serves as both an educational resource and a practical guide for researchers seeking to apply dimensionless learning to their experimental data.

</details>


### [96] [Machine Learning Framework for Thrombosis Risk Prediction in Rotary Blood Pumps](https://arxiv.org/abs/2512.15761)
*Christopher Blum,Michael Neidlin*

Main category: cs.LG

TL;DR: 提出可解释机器学习框架，基于CFD流场特征进行空间血栓风险评估，实现高效、透明的血栓形成预测


<details>
  <summary>Details</summary>
Motivation: 现有计算模型难以将复杂流动条件转化为可靠且可解释的血栓风险预测，反映了对特定流动特征如何影响血栓形成的不完全理解

Method: 使用逻辑回归模型结合结构化特征选择流程，从CFD流场特征中提取紧凑且物理可解释的特征集，包括非线性特征组合，基于已验证的宏观血栓模型的空间风险模式进行训练

Result: 模型能重现标记的风险分布，识别与血栓风险增加相关的流动特征集；应用于离心泵时，即使仅使用单轴泵工况训练，也能预测合理的血栓易发区域

Conclusion: 可解释机器学习能够将局部流动特征与血栓风险联系起来，同时保持计算效率和机理透明性，为将可解释机器学习整合到CFD驱动的血栓分析和设备设计工作流程提供方法基础

Abstract: Thrombosis in rotary blood pumps arises from complex flow conditions that remain difficult to translate into reliable and interpretable risk predictions using existing computational models. This limitation reflects an incomplete understanding of how specific flow features contribute to thrombus initiation and growth. This study introduces an interpretable machine learning framework for spatial thrombosis assessment based directly on computational fluid dynamics-derived flow features. A logistic regression (LR) model combined with a structured feature-selection pipeline is used to derive a compact and physically interpretable feature set, including nonlinear feature combinations. The framework is trained using spatial risk patterns from a validated, macro-scale thrombosis model for two representative scenarios. The model reproduces the labeled risk distributions and identifies distinct sets of flow features associated with increased thrombosis risk. When applied to a centrifugal pump, despite training on a single axial pump operating point, the model predicts plausible thrombosis-prone regions. These results show that interpretable machine learning can link local flow features to thrombosis risk while remaining computationally efficient and mechanistically transparent. The low computational cost enables rapid thrombogenicity screening without repeated or costly simulations. The proposed framework complements physics-based thrombosis modeling and provides a methodological basis for integrating interpretable machine learning into CFD-driven thrombosis analysis and device design workflows.

</details>


### [97] [Cross-Sample Augmented Test-Time Adaptation for Personalized Intraoperative Hypotension Prediction](https://arxiv.org/abs/2512.15762)
*Kanxue Li,Yibing Zhan,Hua Jin,Chongchong Qi,Xu Lin,Baosheng Yu*

Main category: cs.LG

TL;DR: CSA-TTA：一种跨样本增强的测试时适应框架，通过整合其他患者的低血压事件来提升术中低血压预测的个性化准确性。


<details>
  <summary>Details</summary>
Motivation: 术中低血压（IOH）具有显著的个体差异性，准确预测面临挑战。传统测试时适应（TTA）方法因IOH事件罕见而导致测试时训练不可靠。

Method: 提出CSA-TTA框架：1）构建跨样本库，将历史数据分为低血压和非低血压样本；2）采用粗到细检索策略：先用K-Shape聚类识别代表性簇中心，再基于当前患者信号检索语义相似的top-K样本；3）训练中整合自监督掩码重建和回顾性序列预测信号。

Result: 在VitalDB数据集和真实医院数据集上评估，CSA-TTA与TimesFM和UniTS等先进时间序列预测模型集成，性能持续提升。在VitalDB上，微调场景下Recall和F1分别提升+1.33%和+1.13%，零样本场景下提升+7.46%和+5.07%。

Conclusion: CSA-TTA通过跨样本增强有效解决了IOH事件罕见导致的测试时训练不可靠问题，显著提升了术中低血压预测的准确性和泛化能力。

Abstract: Intraoperative hypotension (IOH) poses significant surgical risks, but accurate prediction remains challenging due to patient-specific variability. While test-time adaptation (TTA) offers a promising approach for personalized prediction, the rarity of IOH events often leads to unreliable test-time training. To address this, we propose CSA-TTA, a novel Cross-Sample Augmented Test-Time Adaptation framework that enhances training by incorporating hypotension events from other individuals. Specifically, we first construct a cross-sample bank by segmenting historical data into hypotensive and non-hypotensive samples. Then, we introduce a coarse-to-fine retrieval strategy for building test-time training data: we initially apply K-Shape clustering to identify representative cluster centers and subsequently retrieve the top-K semantically similar samples based on the current patient signal. Additionally, we integrate both self-supervised masked reconstruction and retrospective sequence forecasting signals during training to enhance model adaptability to rapid and subtle intraoperative dynamics. We evaluate the proposed CSA-TTA on both the VitalDB dataset and a real-world in-hospital dataset by integrating it with state-of-the-art time series forecasting models, including TimesFM and UniTS. CSA-TTA consistently enhances performance across settings-for instance, on VitalDB, it improves Recall and F1 scores by +1.33% and +1.13%, respectively, under fine-tuning, and by +7.46% and +5.07% in zero-shot scenarios-demonstrating strong robustness and generalization.

</details>


### [98] [AdaGradSelect: An adaptive gradient-guided layer selection method for efficient fine-tuning of SLMs](https://arxiv.org/abs/2512.15764)
*Anshul Kumar,Gagan Raj Gupta,Manisha Chawla*

Main category: cs.LG

TL;DR: AdaGradSelect是一种针对小型语言模型的自适应参数高效微调方法，通过基于梯度选择要更新的transformer块，在保持接近全微调性能的同时显著减少计算和内存开销。


<details>
  <summary>Details</summary>
Motivation: 全微调大型语言模型成本高昂且内存需求大，而现有的参数高效微调方法（如LoRA）将训练限制在有限子空间中，有时会降低性能。对于小型语言模型，效率提升更为重要，需要一种既能保持性能又更高效的微调方法。

Method: AdaGradSelect基于梯度选择要更新的transformer块：1）根据梯度范数识别最重要的块；2）使用基于Dirichlet的采样策略，考虑块的历史更新频率；3）结合epsilon-greedy探索策略，早期探索不同块，后期聚焦重要块。

Result: 实验显示AdaGradSelect比全微调训练速度快约12%，GPU内存使用减少35%，性能接近全微调。在GSM8K数据集上，相比LoRA（秩256）平均提升约3%（在Qwen2.5-0.5B、LLaMA3.2-1B、Phi4-mini-3.8B等模型上）。在MATH数据集上达到相似准确率。

Conclusion: AdaGradSelect为传统微调方法提供了更有效和资源高效的替代方案，特别适合小型语言模型，在保持性能的同时显著提升训练效率和减少内存消耗。

Abstract: Large Language Models (LLMs) can perform many NLP tasks well, but fully fine-tuning them is expensive and requires a lot of memory. Parameter-Efficient Fine-Tuning (PEFT) methods such as LoRA reduce this cost by adding small low-rank updates to frozen model weights. However, these methods restrict the training to a limited subspace, which can sometimes reduce performance.
  For Small Language Models (SLMs), where efficiency gains matter even more, we introduce AdaGradSelect, an adaptive method that selects which transformer blocks to update based on gradients.
  Early observations showed that updating only the transformer blocks with the highest gradient norms can achieve performance close to full fine-tuning. Building on this insight, AdaGradSelect adaptively chooses which blocks to train. It uses a combination of Dirichlet-based sampling, which depends on how frequently blocks were updated in the past, and an epsilon-greedy exploration strategy. This lets the method explore different blocks in early training and gradually focus on the most important ones in later epochs.
  Experiments show that AdaGradSelect trains about 12 percent faster and uses 35 percent less GPU memory while delivering performance very close to full fine-tuning. On the GSM8K dataset, it outperforms LoRA (rank 256) by about 3 percent on average across models such as Qwen2.5-0.5B, LLaMA3.2-1B, and Phi4-mini-3.8B. It also achieves similar accuracy on the MATH dataset. Overall, AdaGradSelect provides a more effective and resource-efficient alternative to traditional fine-tuning methods.

</details>


### [99] [Data Valuation for LLM Fine-Tuning: Efficient Shapley Value Approximation via Language Model Arithmetic](https://arxiv.org/abs/2512.15765)
*Mélissa Tamine,Otmane Sakhi,Benjamin Heymann*

Main category: cs.LG

TL;DR: 本文提出了一种针对使用DPO训练的LLM的高效数据估值方法，通过利用DPO的数学结构简化了Shapley值的计算，解决了传统数据估值方法计算成本过高的问题。


<details>
  <summary>Details</summary>
Motivation: 数据是训练大语言模型的关键资产，但数据估值面临两大挑战：数据所有者如何做出明智的数据投资决策，以及多个数据所有者如何公平合作训练更好的模型。传统的Shapley值计算方法需要大量模型重训练，计算成本极高，尤其对于大型模型。

Method: 利用Direct Preference Optimization (DPO)训练LLM的特定数学结构，开发可扩展的Shapley值计算方法。DPO的特殊结构使得数据贡献的评估可以更高效地进行，避免了传统方法中需要大量模型重训练的问题。

Result: 证明了对于使用DPO训练的LLM，数据估值的计算挑战得到了显著简化。该方法能够实现可扩展的Shapley值计算，为数据估值与大型语言模型的交叉应用开辟了新的可能性。

Conclusion: DPO的数学结构为LLM数据估值提供了高效的计算框架，这一发现有望推动数据估值与大型语言模型交叉领域的多种应用发展。

Abstract: Data is a critical asset for training large language models (LLMs), alongside compute resources and skilled workers. While some training data is publicly available, substantial investment is required to generate proprietary datasets, such as human preference annotations or to curate new ones from existing sources. As larger datasets generally yield better model performance, two natural questions arise. First, how can data owners make informed decisions about curation strategies and data sources investment? Second, how can multiple data owners collaboratively pool their resources to train superior models while fairly distributing the benefits? This problem, data valuation, which is not specific to large language models, has been addressed by the machine learning community through the lens of cooperative game theory, with the Shapley value being the prevalent solution concept. However, computing Shapley values is notoriously expensive for data valuation, typically requiring numerous model retrainings, which can become prohibitive for large machine learning models. In this work, we demonstrate that this computational challenge is dramatically simplified for LLMs trained with Direct Preference Optimization (DPO). We show how the specific mathematical structure of DPO enables scalable Shapley value computation. We believe this observation unlocks many applications at the intersection of data valuation and large language models.

</details>


### [100] [Bridging Data and Physics: A Graph Neural Network-Based Hybrid Twin Framework](https://arxiv.org/abs/2512.15767)
*M. Gorpinich,B. Moya,S. Rodriguez,F. Meraghni,Y. Jaafra,A. Briot,M. Henner,R. Leon,F. Chinesta*

Main category: cs.LG

TL;DR: 提出基于图神经网络的混合孪生方法，用少量数据学习物理模型与真实现象间的差距（无知模型），提升模拟精度


<details>
  <summary>Details</summary>
Motivation: 传统有限元等物理模型存在简化假设导致与真实现象存在差距，而纯数据驱动方法需要大量高质量数据，现实中难以获取

Method: 采用混合孪生方法，用图神经网络学习物理模型与真实间的差距（无知模型），利用GNN处理稀疏空间测量的优势

Result: 在非线性热传导问题中，GNN成功捕捉无知模型，在不同网格、几何和载荷位置下都能泛化修正，提高模拟精度

Conclusion: GNN混合孪生方法能用少量数据有效学习物理模型的不足，提升模拟精度和可解释性，减少数据需求

Abstract: Simulating complex unsteady physical phenomena relies on detailed mathematical models, simulated for instance by using the Finite Element Method (FEM). However, these models often exhibit discrepancies from the reality due to unmodeled effects or simplifying assumptions. We refer to this gap as the ignorance model. While purely data-driven approaches attempt to learn full system behavior, they require large amounts of high-quality data across the entire spatial and temporal domain. In real-world scenarios, such information is unavailable, making full data-driven modeling unreliable. To overcome this limitation, we model of the ignorance component using a hybrid twin approach, instead of simulating phenomena from scratch. Since physics-based models approximate the overall behavior of the phenomena, the remaining ignorance is typically lower in complexity than the full physical response, therefore, it can be learned with significantly fewer data. A key difficulty, however, is that spatial measurements are sparse, also obtaining data measuring the same phenomenon for different spatial configurations is challenging in practice. Our contribution is to overcome this limitation by using Graph Neural Networks (GNNs) to represent the ignorance model. GNNs learn the spatial pattern of the missing physics even when the number of measurement locations is limited. This allows us to enrich the physics-based model with data-driven corrections without requiring dense spatial, temporal and parametric data. To showcase the performance of the proposed method, we evaluate this GNN-based hybrid twin on nonlinear heat transfer problems across different meshes, geometries, and load positions. Results show that the GNN successfully captures the ignorance and generalizes corrections across spatial configurations, improving simulation accuracy and interpretability, while minimizing data requirements.

</details>


### [101] [TENG++: Time-Evolving Natural Gradient for Solving PDEs With Deep Neural Nets under General Boundary Conditions](https://arxiv.org/abs/2512.15771)
*Xinjie He,Chenggong Zhang*

Main category: cs.LG

TL;DR: 将时间演化自然梯度（TENG）框架扩展到处理狄利克雷边界条件，结合自然梯度优化与数值时间步进方法（欧拉和Heun方法），通过边界惩罚项精确实施约束，在热方程上验证了方法的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统数值方法处理高维或复杂PDE问题存在困难，物理信息神经网络（PINNs）虽然将物理约束嵌入深度学习框架，但在实现高精度和处理复杂边界条件方面仍有挑战。

Method: 扩展时间演化自然梯度（TENG）框架来处理狄利克雷边界条件，将自然梯度优化与数值时间步进方案（欧拉和Heun方法）结合，在损失函数中加入边界条件惩罚项来精确实施约束。

Result: 在热方程上的实验表明，Heun方法由于其二阶校正具有更高的准确性，而欧拉方法在简单场景中计算效率更高。该方法为扩展到诺伊曼和混合边界条件以及更广泛的PDE类别奠定了基础。

Conclusion: 该工作为扩展TENG框架到更广泛的边界条件和PDE类型建立了基础，推进了基于神经网络的求解器在实际问题中的应用。

Abstract: Partial Differential Equations (PDEs) are central to modeling complex systems across physical, biological, and engineering domains, yet traditional numerical methods often struggle with high-dimensional or complex problems. Physics-Informed Neural Networks (PINNs) have emerged as an efficient alternative by embedding physics-based constraints into deep learning frameworks, but they face challenges in achieving high accuracy and handling complex boundary conditions. In this work, we extend the Time-Evolving Natural Gradient (TENG) framework to address Dirichlet boundary conditions, integrating natural gradient optimization with numerical time-stepping schemes, including Euler and Heun methods, to ensure both stability and accuracy. By incorporating boundary condition penalty terms into the loss function, the proposed approach enables precise enforcement of Dirichlet constraints. Experiments on the heat equation demonstrate the superior accuracy of the Heun method due to its second-order corrections and the computational efficiency of the Euler method for simpler scenarios. This work establishes a foundation for extending the framework to Neumann and mixed boundary conditions, as well as broader classes of PDEs, advancing the applicability of neural network-based solvers for real-world problems.

</details>


### [102] [TS-DP: Reinforcement Speculative Decoding For Temporal Adaptive Diffusion Policy Acceleration](https://arxiv.org/abs/2512.15773)
*Ye Li,Jiahe Feng,Yuan Meng,Kangye Ji,Chen Tang,Xinwan Wen,Shutao Xia,Zhi Wang,Wenwu Zhu*

Main category: cs.LG

TL;DR: TS-DP：首个为扩散策略引入时序感知强化学习推测解码的框架，通过Transformer草稿器和RL调度器动态适应任务难度，实现4.17倍加速且保持94%以上草稿接受率，达到25Hz实时控制。


<details>
  <summary>Details</summary>
Motivation: 扩散策略在具身控制中表现出色，但存在高推理延迟和计算成本问题。静态加速方法（如量化）无法处理动态具身任务，而推测解码虽无损且自适应但在扩散策略中尚未充分探索。需要解决如何在任务难度随时间变化的具身环境中以更低成本匹配基础模型的去噪质量，以及如何动态调整计算资源。

Method: 提出时序感知强化学习推测扩散策略（TS-DP）：1）使用Transformer草稿器模仿基础模型，替代昂贵的去噪调用以处理动态环境；2）基于RL的调度器通过调整推测参数来适应时变任务难度，在保持准确性的同时提高效率。

Result: 在多样具身环境中的实验表明，TS-DP实现高达4.17倍的推理加速，草稿接受率超过94%，推理频率达到25Hz，实现了无性能下降的实时扩散控制。

Conclusion: TS-DP成功将推测解码应用于扩散策略，通过时序自适应机制解决了动态具身任务中的计算效率问题，为实时扩散控制提供了有效解决方案。

Abstract: Diffusion Policy (DP) excels in embodied control but suffers from high inference latency and computational cost due to multiple iterative denoising steps. The temporal complexity of embodied tasks demands a dynamic and adaptable computation mode. Static and lossy acceleration methods, such as quantization, fail to handle such dynamic embodied tasks, while speculative decoding offers a lossless and adaptive yet underexplored alternative for DP. However, it is non-trivial to address the following challenges: how to match the base model's denoising quality at lower cost under time-varying task difficulty in embodied settings, and how to dynamically and interactively adjust computation based on task difficulty in such environments. In this paper, we propose Temporal-aware Reinforcement-based Speculative Diffusion Policy (TS-DP), the first framework that enables speculative decoding for DP with temporal adaptivity. First, to handle dynamic environments where task difficulty varies over time, we distill a Transformer-based drafter to imitate the base model and replace its costly denoising calls. Second, an RL-based scheduler further adapts to time-varying task difficulty by adjusting speculative parameters to maintain accuracy while improving efficiency. Extensive experiments across diverse embodied environments demonstrate that TS-DP achieves up to 4.17 times faster inference with over 94% accepted drafts, reaching an inference frequency of 25 Hz and enabling real-time diffusion-based control without performance degradation.

</details>


### [103] [Adversarial Robustness in Financial Machine Learning: Defenses, Economic Impact, and Governance Evidence](https://arxiv.org/abs/2512.15780)
*Samruddhi Baviskar*

Main category: cs.LG

TL;DR: 评估金融决策中表格机器学习模型的对抗鲁棒性，发现小扰动会导致显著性能下降，对抗训练能部分恢复性能


<details>
  <summary>Details</summary>
Motivation: 金融决策中的表格机器学习模型（如信用评分和欺诈检测）对对抗攻击的鲁棒性尚未充分研究，需要评估其对歧视性、校准性和金融风险指标的影响

Method: 使用信用评分和欺诈检测数据，应用基于梯度的对抗攻击方法，测量模型在歧视性、校准性和金融风险指标上的变化

Result: 结果显示在小扰动下模型性能显著下降，通过对抗训练可以部分恢复性能，但无法完全恢复到原始水平

Conclusion: 金融决策中的表格机器学习模型对对抗攻击脆弱，需要加强对抗鲁棒性研究，对抗训练是有效的防御策略但仍有改进空间

Abstract: We evaluate adversarial robustness in tabular machine learning models used in financial decision making. Using credit scoring and fraud detection data, we apply gradient based attacks and measure impacts on discrimination, calibration, and financial risk metrics. Results show notable performance degradation under small perturbations and partial recovery through adversarial training.

</details>


### [104] [Boosting t-SNE Efficiency for Sequencing Data: Insights from Kernel Selection](https://arxiv.org/abs/2512.15900)
*Avais Jan,Prakash Chourasia,Sarwan Ali,Murray Patterson*

Main category: cs.LG

TL;DR: 该研究评估了九种不同核函数在t-SNE降维中的表现，发现余弦相似度核在生物序列数据分析中优于传统高斯核和隔离核，具有更好的运行效率和距离保持能力。


<details>
  <summary>Details</summary>
Motivation: 传统t-SNE使用的高斯核缺乏数据依赖性且计算开销大，限制了其在分类生物序列数据中的可扩展性和效果。虽然已有研究提出隔离核作为替代，但仍可能无法最优地捕获序列相似性。

Method: 使用三种嵌入方法（One-Hot Encoding、Spike2Vec和minimizers）评估九种不同核函数在t-SNE中的应用。通过主观可视化和客观指标（包括邻域保持分数）进行评估，并在六个不同生物数据集上进行分类和聚类实验验证。

Result: 余弦相似度核总体上优于其他核函数（包括高斯核和隔离核），实现了更好的运行效率和低维空间中成对距离的保持。核选择不仅影响可视化质量，还显著影响下游分析任务。

Conclusion: 余弦相似度核在不同数据类型和嵌入策略中提供最稳健的性能，特别适合大规模生物序列分析。核函数选择对t-SNE在生物序列数据分析中的效果具有重要影响。

Abstract: Dimensionality reduction techniques are essential for visualizing and analyzing high-dimensional biological sequencing data. t-distributed Stochastic Neighbor Embedding (t-SNE) is widely used for this purpose, traditionally employing the Gaussian kernel to compute pairwise similarities. However, the Gaussian kernel's lack of data-dependence and computational overhead limit its scalability and effectiveness for categorical biological sequences. Recent work proposed the isolation kernel as an alternative, yet it may not optimally capture sequence similarities. In this study, we comprehensively evaluate nine different kernel functions for t-SNE applied to molecular sequences, using three embedding methods: One-Hot Encoding, Spike2Vec, and minimizers. Through both subjective visualization and objective metrics (including neighborhood preservation scores), we demonstrate that the cosine similarity kernel in general outperforms other kernels, including Gaussian and isolation kernels, achieving superior runtime efficiency and better preservation of pairwise distances in low-dimensional space. We further validate our findings through extensive classification and clustering experiments across six diverse biological datasets (Spike7k, Host, ShortRead, Rabies, Genome, and Breast Cancer), employing multiple machine learning algorithms and evaluation metrics. Our results show that kernel selection significantly impacts not only visualization quality but also downstream analytical tasks, with the cosine similarity kernel providing the most robust performance across different data types and embedding strategies, making it particularly suitable for large-scale biological sequence analysis.

</details>


### [105] [A Unification of Discrete, Gaussian, and Simplicial Diffusion](https://arxiv.org/abs/2512.15923)
*Nuria Alina Chandra,Yucen Lily Li,Alan N. Amin,Alex Ali,Joshua Rollins,Sebastian W. Ober,Aniruddh Raghu,Andrew Gordon Wilson*

Main category: cs.LG

TL;DR: 本文提出了一个统一框架，将离散扩散、高斯扩散和单纯形扩散三种方法统一为Wright-Fisher种群遗传模型的不同参数化形式，解决了现有方法的算法差异和数值不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 当前离散序列建模（如DNA、蛋白质、语言）存在三种主要扩散方法：离散空间扩散、欧几里得空间的高斯扩散、单纯形扩散。这些方法各有优缺点：离散扩散领域最自然，高斯扩散算法更成熟，单纯形扩散理论上结合了两者优势但实践中数值不稳定。需要统一框架来理解这些方法的内在联系，并让实践者能在不同模型间切换。

Method: 构建理论框架，将三种离散扩散方法统一为Wright-Fisher种群遗传模型的不同参数化形式。发现单纯形扩散和高斯扩散是该模型的两个大种群极限。利用数十年数学遗传学文献开发稳定的单纯形扩散算法，并训练单一模型使其能在测试时在任意这三种领域中进行扩散。

Result: Wright-Fisher单纯形扩散比之前的单纯形扩散模型更稳定，在条件DNA生成任务上表现更好。同时，训练的多领域模型与任何单一领域训练的模型相比都具竞争力。

Conclusion: 通过Wright-Fisher种群遗传模型统一了三种离散扩散方法，解决了单纯形扩散的数值不稳定问题，使实践者无需在模型权衡中做选择，单一模型即可在多个领域进行扩散。

Abstract: To model discrete sequences such as DNA, proteins, and language using diffusion, practitioners must choose between three major methods: diffusion in discrete space, Gaussian diffusion in Euclidean space, or diffusion on the simplex. Despite their shared goal, these models have disparate algorithms, theoretical structures, and tradeoffs: discrete diffusion has the most natural domain, Gaussian diffusion has more mature algorithms, and diffusion on the simplex in principle combines the strengths of the other two but in practice suffers from a numerically unstable stochastic processes. Ideally we could see each of these models as instances of the same underlying framework, and enable practitioners to switch between models for downstream applications. However previous theories have only considered connections in special cases. Here we build a theory unifying all three methods of discrete diffusion as different parameterizations of the same underlying process: the Wright-Fisher population genetics model. In particular, we find simplicial and Gaussian diffusion as two large-population limits. Our theory formally connects the likelihoods and hyperparameters of these models and leverages decades of mathematical genetics literature to unlock stable simplicial diffusion. Finally, we relieve the practitioner of balancing model trade-offs by demonstrating it is possible to train a single model that can perform diffusion in any of these three domains at test time. Our experiments show that Wright-Fisher simplicial diffusion is more stable and outperforms previous simplicial diffusion models on conditional DNA generation. We also show that we can train models on multiple domains at once that are competitive with models trained on any individual domain.

</details>


### [106] [DSO: Direct Steering Optimization for Bias Mitigation](https://arxiv.org/abs/2512.15926)
*Lucas Monteiro Paes,Nivedha Sivakumar,Yinong Oliver Wang,Masha Fedzechkina Donaldson,Luca Zappella,Nicholas Apostoloff*

Main category: cs.LG

TL;DR: 提出DSO方法，通过强化学习优化激活转向，在推理时可控地减少VLMs和LLMs的偏见，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 生成模型决策受人口属性偏见影响（如VLMs难以识别女性医生），现有转向方法难以纠正偏见，且用户需要在偏见减少和性能之间进行权衡控制。

Method: 提出直接转向优化（DSO），使用强化学习寻找线性变换来转向激活，专门针对偏见缓解，同时保持对模型性能的控制。

Result: DSO在VLMs和LLMs上实现了公平性和能力之间的最优权衡，为从业者提供推理时的权衡控制。

Conclusion: 直接优化转向策略比依赖预定义启发式方法更有效，为模型偏见干预提供了更有效的解决方案。

Abstract: Generative models are often deployed to make decisions on behalf of users, such as vision-language models (VLMs) identifying which person in a room is a doctor to help visually impaired individuals. Yet, VLM decisions are influenced by the perceived demographic attributes of people in the input, which can lead to biased outcomes like failing to identify women as doctors. Moreover, when reducing bias leads to performance loss, users may have varying needs for balancing bias mitigation with overall model capabilities, highlighting the demand for methods that enable controllable bias reduction during inference. Activation steering is a popular approach for inference-time controllability that has shown potential in inducing safer behavior in large language models (LLMs). However, we observe that current steering methods struggle to correct biases, where equiprobable outcomes across demographic groups are required. To address this, we propose Direct Steering Optimization (DSO) which uses reinforcement learning to find linear transformations for steering activations, tailored to mitigate bias while maintaining control over model performance. We demonstrate that DSO achieves state-of-the-art trade-off between fairness and capabilities on both VLMs and LLMs, while offering practitioners inference-time control over the trade-off. Overall, our work highlights the benefit of designing steering strategies that are directly optimized to control model behavior, providing more effective bias intervention than methods that rely on pre-defined heuristics for controllability.

</details>


### [107] [BarcodeMamba+: Advancing State-Space Models for Fungal Biodiversity Research](https://arxiv.org/abs/2512.15931)
*Tiancheng Gao,Scott C. Lowe,Brendan Furneaux,Angel X Chang,Graham W. Taylor*

Main category: cs.LG

TL;DR: BarcodeMamba+：基于状态空间模型架构的真菌DNA条形码分类基础模型，通过预训练-微调范式在数据稀疏环境中显著优于传统监督方法


<details>
  <summary>Details</summary>
Motivation: 真菌DNA条形码分类面临极端挑战：标签稀疏、长尾分布、传统监督方法难以泛化到未见物种且无法捕捉数据的层次结构特征

Method: 基于状态空间模型架构构建基础模型，采用预训练-微调范式利用部分标记数据；微调阶段整合层次标签平滑、加权损失函数和MycoAI的多头输出层等增强技术

Result: 在具有明显分类分布偏移的真菌分类基准测试中，最终模型在所有分类级别上均优于现有方法；每个增强组件都带来显著性能提升

Conclusion: 该工作为基于基因组学的生物多样性研究提供了强大新工具，并为这一挑战性领域建立了有效且可扩展的训练范式

Abstract: Accurate taxonomic classification from DNA barcodes is a cornerstone of global biodiversity monitoring, yet fungi present extreme challenges due to sparse labelling and long-tailed taxa distributions. Conventional supervised learning methods often falter in this domain, struggling to generalize to unseen species and to capture the hierarchical nature of the data. To address these limitations, we introduce BarcodeMamba+, a foundation model for fungal barcode classification built on a powerful and efficient state-space model architecture. We employ a pretrain and fine-tune paradigm, which utilizes partially labelled data and we demonstrate this is substantially more effective than traditional fully-supervised methods in this data-sparse environment. During fine-tuning, we systematically integrate and evaluate a suite of enhancements--including hierarchical label smoothing, a weighted loss function, and a multi-head output layer from MycoAI--to specifically tackle the challenges of fungal taxonomy. Our experiments show that each of these components yields significant performance gains. On a challenging fungal classification benchmark with distinct taxonomic distribution shifts from the broad training set, our final model outperforms a range of existing methods across all taxonomic levels. Our work provides a powerful new tool for genomics-based biodiversity research and establishes an effective and scalable training paradigm for this challenging domain. Our code is publicly available at https://github.com/bioscan-ml/BarcodeMamba.

</details>


### [108] [In-Context Semi-Supervised Learning](https://arxiv.org/abs/2512.15934)
*Jiashuo Fan,Paul Rosu,Aaron T. Wang,Michael Li,Lawrence Carin,Xiang Cheng*

Main category: cs.LG

TL;DR: 该论文研究了Transformer在上下文半监督学习中的能力，证明其能利用未标记数据提升少标签场景下的性能


<details>
  <summary>Details</summary>
Motivation: 现有Transformer上下文学习理论主要关注有监督的显式标记数据，但实践中Transformer在标签稀疏或缺失时仍表现良好，这表明未标记上下文演示中存在关键结构需要研究

Method: 引入并研究上下文半监督学习，其中少量标记示例伴随大量未标记点，展示Transformer能利用未标记上下文学习鲁棒的、上下文相关的表示

Result: Transformer学习的上下文相关表示能够实现准确预测，在低标签场景下显著提升性能

Conclusion: 该研究为Transformer如何在上下文学习框架中利用未标记上下文进行表示学习提供了基础性见解

Abstract: There has been significant recent interest in understanding the capacity of Transformers for in-context learning (ICL), yet most theory focuses on supervised settings with explicitly labeled pairs. In practice, Transformers often perform well even when labels are sparse or absent, suggesting crucial structure within unlabeled contextual demonstrations. We introduce and study in-context semi-supervised learning (IC-SSL), where a small set of labeled examples is accompanied by many unlabeled points, and show that Transformers can leverage the unlabeled context to learn a robust, context-dependent representation. This representation enables accurate predictions and markedly improves performance in low-label regimes, offering foundational insights into how Transformers exploit unlabeled context for representation learning within the ICL framework.

</details>


### [109] [SALVE: Sparse Autoencoder-Latent Vector Editing for Mechanistic Control of Neural Networks](https://arxiv.org/abs/2512.15938)
*Vegard Flovik*

Main category: cs.LG

TL;DR: SALVE框架：通过稀疏自编码器发现、验证和控制深度神经网络特征，实现可解释的模型编辑


<details>
  <summary>Details</summary>
Motivation: 深度神经网络性能优异但难以解释和控制，需要将机制可解释性与模型编辑相结合的方法

Method: 使用ℓ1正则化自编码器学习稀疏特征基，通过Grad-FAM验证特征，利用自编码器结构进行权重空间干预，推导关键抑制阈值α_crit

Result: 在ResNet-18和ViT-B/16模型上验证了框架有效性，实现了对类别定义特征和跨类别特征的连续调制

Conclusion: SALVE为特征发现到可操作模型编辑提供了原则性方法，推动了透明可控AI系统的发展

Abstract: Deep neural networks achieve impressive performance but remain difficult to interpret and control. We present SALVE (Sparse Autoencoder-Latent Vector Editing), a unified "discover, validate, and control" framework that bridges mechanistic interpretability and model editing. Using an $\ell_1$-regularized autoencoder, we learn a sparse, model-native feature basis without supervision. We validate these features with Grad-FAM, a feature-level saliency mapping method that visually grounds latent features in input data. Leveraging the autoencoder's structure, we perform precise and permanent weight-space interventions, enabling continuous modulation of both class-defining and cross-class features. We further derive a critical suppression threshold, $α_{crit}$, quantifying each class's reliance on its dominant feature, supporting fine-grained robustness diagnostics. Our approach is validated on both convolutional (ResNet-18) and transformer-based (ViT-B/16) models, demonstrating consistent, interpretable control over their behavior. This work contributes a principled methodology for turning feature discovery into actionable model edits, advancing the development of transparent and controllable AI systems.

</details>


### [110] [AIE4ML: An End-to-End Framework for Compiling Neural Networks for the Next Generation of AMD AI Engines](https://arxiv.org/abs/2512.15946)
*Dimitrios Danopoulos,Enrico Lupi,Chang Sun,Sebastian Dittmeier,Michael Kagan,Vladimir Loncar,Maurizio Pierini*

Main category: cs.LG

TL;DR: AIE4ML：首个针对AMD Versal AIE-ML架构的自动AI模型转换框架，实现接近架构峰值的性能，支持全片上执行，在粒子物理触发系统等超低延迟环境中达到GPU级吞吐量。


<details>
  <summary>Details</summary>
Motivation: 在AMD Versal AI Engine上进行高效AI推理面临挑战，包括紧密耦合的VLIW执行、显式数据路径和本地内存管理。先前工作仅关注第一代AIE内核优化，未解决跨2D阵列的完整神经网络执行问题。

Method: 1) 单内核级：实现接近架构峰值的性能；2) 图和系统级：提供结构化并行化方法，可跨2D AIE-ML架构扩展，利用专用内存瓦片实现全片上执行；3) 开发通用高效的线性层实现，支持融合偏置加法和ReLU激活；4) 通过新颖的图放置和搜索算法，系统化推导确定性、紧凑且拓扑优化的布局；5) 无缝接受来自hls4ml或PyTorch等高级工具的量化模型。

Result: 在层扩展基准测试中，相对于单内核基线达到98.6%的效率，使用304个AIE瓦片中的296个（97.4%），实现全片上数据移动。在实际模型拓扑评估中，在微秒级延迟约束下提供GPU级吞吐量。

Conclusion: AIE4ML是首个针对AIE-ML代设备的全面框架，能够自动将AI模型转换为优化固件，在超低延迟环境（如粒子物理实验中的触发系统）中具有实际应用价值，同时保持前向兼容性以支持更新的AIE-MLv2架构。

Abstract: Efficient AI inference on AMD's Versal AI Engine (AIE) is challenging due to tightly coupled VLIW execution, explicit datapaths, and local memory management. Prior work focused on first-generation AIE kernel optimizations, without tackling full neural network execution across the 2D array. In this work, we present AIE4ML, the first comprehensive framework for converting AI models automatically into optimized firmware targeting the AIE-ML generation devices, also with forward compatibility for the newer AIE-MLv2 architecture. At the single-kernel level, we attain performance close to the architectural peak. At the graph and system levels, we provide a structured parallelization method that can scale across the 2D AIE-ML fabric and exploit its dedicated memory tiles to stay entirely on-chip throughout the model execution. As a demonstration, we designed a generalized and highly efficient linear-layer implementation with intrinsic support for fused bias addition and ReLU activation. Also, as our framework necessitates the generation of multi-layer implementations, our approach systematically derives deterministic, compact, and topology-optimized placements tailored to the physical 2D grid of the device through a novel graph placement and search algorithm. Finally, the framework seamlessly accepts quantized models imported from high-level tools such as hls4ml or PyTorch while preserving bit-exactness. In layer scaling benchmarks, we achieve up to 98.6% efficiency relative to the single-kernel baseline, utilizing 296 of 304 AIE tiles (97.4%) of the device with entirely on-chip data movement. With evaluations across real-world model topologies, we demonstrate that AIE4ML delivers GPU-class throughput under microsecond latency constraints, making it a practical companion for ultra-low-latency environments such as trigger systems in particle physics experiments.

</details>


### [111] [Governance by Evidence: Regulated Predictors in Decision-Tree Models](https://arxiv.org/abs/2512.15955)
*Alexios Veskoukis,Dimitris Kalles*

Main category: cs.LG

TL;DR: 该研究分析了已发表的决策树论文中使用的预测变量，发现许多属于受隐私法规监管的数据类别，支持隐私保护方法和治理检查。


<details>
  <summary>Details</summary>
Motivation: 决策树方法在结构化表格数据中广泛应用，因其可解释性而受到重视。然而，已发表的研究通常列出使用的预测变量（如年龄、诊断代码、位置等），而这些数据类型越来越多地受到隐私法规的监管。研究旨在通过分析已发表的决策树论文来了解现实世界中对受法律管辖数据的使用情况。

Method: 研究编译了一个决策树研究语料库，将每个报告的预测变量分配到受监管的数据类别（如健康数据、生物识别标识符、儿童数据、财务属性、位置轨迹和政府ID）。然后将每个类别与欧盟和美国隐私法律中的具体条款进行关联。

Result: 研究发现许多报告的预测变量属于受监管类别，其中医疗保健领域占比最大，不同行业间存在明显差异。研究分析了流行程度、行业构成和时间模式，并使用每个监管框架的参考年份总结了法规对齐的时间趋势。

Conclusion: 研究证据支持隐私保护方法和治理检查，这些发现可以为超越决策树的机器学习实践提供信息，促进更负责任的AI开发。

Abstract: Decision-tree methods are widely used on structured tabular data and are valued for interpretability across many sectors. However, published studies often list the predictors they use (for example age, diagnosis codes, location). Privacy laws increasingly regulate such data types. We use published decision-tree papers as a proxy for real-world use of legally governed data. We compile a corpus of decision-tree studies and assign each reported predictor to a regulated data category (for example health data, biometric identifiers, children's data, financial attributes, location traces, and government IDs). We then link each category to specific excerpts in European Union and United States privacy laws. We find that many reported predictors fall into regulated categories, with the largest shares in healthcare and clear differences across industries. We analyze prevalence, industry composition, and temporal patterns, and summarize regulation-aligned timing using each framework's reference year. Our evidence supports privacy-preserving methods and governance checks, and can inform ML practice beyond decision trees.

</details>


### [112] [Tracking Wildfire Assets with Commodity RFID and Gaussian Process Modeling](https://arxiv.org/abs/2512.15956)
*John Hateley,Sriram Narasimhan,Omid Abari*

Main category: cs.LG

TL;DR: 提出一种基于商品RFID的森林资产追踪方法，无需预先标记已知位置即可实现GPS级别的定位精度，适用于野火响应等应用场景。


<details>
  <summary>Details</summary>
Motivation: 商品RFID系统在森林环境中因信号衰减、多径效应和环境变化导致定位性能差。现有指纹识别方法需要预先在已知位置部署标签，但在实际应用中往往无法满足这一条件。

Method: 使用高斯过程建模不同环境的RF信号响应特征，无需GPS或摄像头等额外传感器。提出加权对数似然方法将未知环境与预先建模的环境字典进行匹配。

Result: 能够实现GPS级别的定位精度（米级），使用被动式商品RFID可同时追踪数十个野火响应资产，成本远低于GPS解决方案。

Conclusion: 该方法提供了一种成本效益高、可扩展的森林资产追踪方案，无需预先标记已知位置，在野火响应等应用中具有重要实用价值。

Abstract: This paper presents a novel, cost-effective, and scalable approach to track numerous assets distributed in forested environments using commodity Radio Frequency Identification (RFID) targeting wildfire response applications. Commodity RFID systems suffer from poor tag localization when dispersed in forested environments due to signal attenuation, multi-path effects and environmental variability. Current methods to address this issue via fingerprinting rely on dispersing tags at known locations {\em a priori}. In this paper, we address the case when it is not possible to tag known locations and show that it is possible to localize tags to accuracies comparable to global positioning systems (GPS) without such a constraint. For this, we propose Gaussian Process to model various environments solely based on RF signal response signatures and without the aid of additional sensors such as global positioning GPS or cameras, and match an unknown RF to the closest match in a model dictionary. We utilize a new weighted log-likelihood method to associate an unknown environment with the closest environment in a dictionary of previously modeled environments, which is a crucial step in being able to use our approach. Our results show that it is possible to achieve localization accuracies of the order of GPS, but with passive commodity RFID, which will allow the tracking of dozens of wildfire assets within the vicinity of mobile readers at-a-time simultaneously, does not require known positions to be tagged {\em a priori}, and can achieve localization at a fraction of the cost compared to GPS.

</details>


### [113] [Dynamic Rank Reinforcement Learning for Adaptive Low-Rank Multi-Head Self Attention in Large Language Models](https://arxiv.org/abs/2512.15973)
*Caner Erden*

Main category: cs.LG

TL;DR: DR-RL：通过强化学习和在线矩阵扰动理论动态优化LLM中多头自注意力的低秩分解，实现自适应计算效率提升


<details>
  <summary>Details</summary>
Motivation: 传统低秩近似方法依赖静态秩假设，无法适应不同输入上下文和硬件约束，限制了灵活性和效率

Method: 提出DR-RL框架：1）RL代理将秩选择建模为序列策略优化问题；2）奖励函数平衡注意力保真度和计算延迟；3）使用在线矩阵扰动理论实现增量秩更新；4）集成轻量级Transformer策略网络和批量SVD操作

Result: 在保持与全秩注意力统计等效的下游准确性的同时，显著减少FLOPs，尤其在长序列（L>4096）场景下效果明显

Conclusion: DR-RL在MHSA中桥接了自适应效率和理论严谨性，为资源受限深度学习提供了有原则的、数学基础扎实的低秩优化替代方案

Abstract: We propose Dynamic Rank Reinforcement Learning (DR-RL), a novel framework that adaptively optimizes the low-rank factorization of Multi-Head Self-Attention (MHSA) in Large Language Models (LLMs) through the integration of reinforcement learning and online matrix perturbation theory. While traditional low-rank approximations often rely on static rank assumptions--limiting their flexibility across diverse input contexts--our method dynamically selects ranks based on real-time sequence dynamics, layer-specific sensitivities, and hardware constraints. The core innovation lies in an RL agent that formulates rank selection as a sequential policy optimization problem, where the reward function strictly balances attention fidelity against computational latency. Crucially, we employ online matrix perturbation bounds to enable incremental rank updates, thereby avoiding the prohibitive cost of full decomposition during inference. Furthermore, the integration of a lightweight Transformer-based policy network and batched Singular Value Decomposition (SVD) operations ensures scalable deployment on modern GPU architectures. Experiments demonstrate that DR-RL maintains downstream accuracy statistically equivalent to full-rank attention while significantly reducing Floating Point Operations (FLOPs), particularly in long-sequence regimes (L > 4096). This work bridges the gap between adaptive efficiency and theoretical rigor in MHSA, offering a principled, mathematically grounded alternative to heuristic rank reduction techniques in resource-constrained deep learning. Source code and experiment logs are available at: https://github.com/canererden/DR_RL_Project

</details>


### [114] [Provably Extracting the Features from a General Superposition](https://arxiv.org/abs/2512.15987)
*Allen Liu*

Main category: cs.LG

TL;DR: 提出一种高效查询算法，能从叠加表示的黑盒函数中恢复特征方向和响应函数，适用于过完备（n>d）的广义叠加设置。


<details>
  <summary>Details</summary>
Motivation: 复杂机器学习模型通常通过线性表示编码特征，但这些特征以叠加形式存在，难以恢复。特别是在过完备（n>d）的叠加机制下，现有算法面临挑战。需要一种能处理广义叠加设置的方法，包括任意响应函数和非接近相同的特征方向。

Method: 设计了一种高效查询算法，通过噪声oracle访问函数f，在傅里叶空间中迭代细化搜索空间来定位隐藏方向vi。算法能识别所有非退化响应的特征方向并重构函数f。

Result: 算法能在更一般的设置下工作：允许任意叠加，只要求vi和vj不接近相同，支持一般响应函数σi。相比之前相关工作，适用范围显著更广。

Conclusion: 提出了一种从叠加表示中学习特征的新方法，能有效处理过完备机制下的特征恢复问题，为理解复杂模型中的特征表示提供了新工具。

Abstract: It is widely believed that complex machine learning models generally encode features through linear representations, but these features exist in superposition, making them challenging to recover. We study the following fundamental setting for learning features in superposition from black-box query access: we are given query access to a function \[ f(x)=\sum_{i=1}^n a_i\,σ_i(v_i^\top x), \] where each unit vector $v_i$ encodes a feature direction and $σ_i:\mathbb{R} \rightarrow \mathbb{R}$ is an arbitrary response function and our goal is to recover the $v_i$ and the function $f$.
  In learning-theoretic terms, superposition refers to the overcomplete regime, when the number of features is larger than the underlying dimension (i.e. $n > d$), which has proven especially challenging for typical algorithmic approaches. Our main result is an efficient query algorithm that, from noisy oracle access to $f$, identifies all feature directions whose responses are non-degenerate and reconstructs the function $f$. Crucially, our algorithm works in a significantly more general setting than all related prior results -- we allow for essentially arbitrary superpositions, only requiring that $v_i, v_j$ are not nearly identical for $i \neq j$, and general response functions $σ_i$. At a high level, our algorithm introduces an approach for searching in Fourier space by iteratively refining the search space to locate the hidden directions $v_i$.

</details>


### [115] [Higher-Order LaSDI: Reduced Order Modeling with Multiple Time Derivatives](https://arxiv.org/abs/2512.15997)
*Robert Stephany,William Michael Anderson,Youngsoo Choi*

Main category: cs.LG

TL;DR: 提出了一种结合灵活高阶有限差分格式和Rollout损失函数的方法，用于提升降阶模型在长时间预测中的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统降阶模型虽然能解决参数化偏微分方程，但在长时间预测中精度会显著下降，需要改进其长期预测能力。

Method: 1) 引入灵活、高阶且计算成本低的有限差分格式；2) 提出Rollout损失函数，训练降阶模型在任意时间范围内做出准确预测。

Result: 在2D Burgers方程上验证了该方法，展示了其在长时间预测中的有效性。

Conclusion: 通过结合改进的数值方法和专门的训练损失函数，显著提升了降阶模型在长时间预测中的精度和稳定性。

Abstract: Solving complex partial differential equations is vital in the physical sciences, but often requires computationally expensive numerical methods. Reduced-order models (ROMs) address this by exploiting dimensionality reduction to create fast approximations. While modern ROMs can solve parameterized families of PDEs, their predictive power degrades over long time horizons. We address this by (1) introducing a flexible, high-order, yet inexpensive finite-difference scheme and (2) proposing a Rollout loss that trains ROMs to make accurate predictions over arbitrary time horizons. We demonstrate our approach on the 2D Burgers equation.

</details>


### [116] [Surrogate Neural Architecture Codesign Package (SNAC-Pack)](https://arxiv.org/abs/2512.15998)
*Jason Weitz,Dmitri Demler,Benjamin Hawks,Nhan Tran,Javier Duarte*

Main category: cs.LG

TL;DR: SNAC-Pack是一个自动化神经网络设计与FPGA部署的集成框架，通过硬件感知的神经架构搜索实现多目标优化，避免传统代理指标（如BOPs）的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有神经架构搜索方法难以准确优化真实硬件性能，通常依赖位操作等代理指标，无法直接针对FPGA部署进行优化，需要更精确的硬件感知设计框架。

Method: 结合神经架构协同设计的多阶段搜索能力与资源利用率和延迟估计器，实现精度、FPGA资源利用率和延迟的多目标优化，无需为每个候选模型进行耗时的综合过程。

Result: 在高能物理喷注分类任务中达到63.84%精度，在Xilinx Virtex UltraScale+ VU13P FPGA上综合后，模型保持基准精度，资源利用率与传统BOPs优化模型相当。

Conclusion: 该工作展示了硬件感知神经架构搜索在资源受限部署中的潜力，提供了自动化设计高效FPGA加速模型的开源框架，为实际硬件部署提供了更准确的优化方法。

Abstract: Neural Architecture Search is a powerful approach for automating model design, but existing methods struggle to accurately optimize for real hardware performance, often relying on proxy metrics such as bit operations. We present Surrogate Neural Architecture Codesign Package (SNAC-Pack), an integrated framework that automates the discovery and optimization of neural networks focusing on FPGA deployment. SNAC-Pack combines Neural Architecture Codesign's multi-stage search capabilities with the Resource Utilization and Latency Estimator, enabling multi-objective optimization across accuracy, FPGA resource utilization, and latency without requiring time-intensive synthesis for each candidate model. We demonstrate SNAC-Pack on a high energy physics jet classification task, achieving 63.84% accuracy with resource estimation. When synthesized on a Xilinx Virtex UltraScale+ VU13P FPGA, the SNAC-Pack model matches baseline accuracy while maintaining comparable resource utilization to models optimized using traditional BOPs metrics. This work demonstrates the potential of hardware-aware neural architecture search for resource-constrained deployments and provides an open-source framework for automating the design of efficient FPGA-accelerated models.

</details>


### [117] [Towards Fine-Tuning-Based Site Calibration for Knowledge-Guided Machine Learning: A Summary of Results](https://arxiv.org/abs/2512.16013)
*Ruolei Zeng,Arun Sharma,Shuai An,Mingzhou Yang,Shengya Zhang,Licheng Liu,David Mulla,Shashi Shekhar*

Main category: cs.LG

TL;DR: FTBSC-KGML是一个基于预训练-微调、考虑空间变异性和知识引导的机器学习框架，用于准确量化农业生态系统碳循环，通过利用迁移学习和空间异质性提高区域适用性。


<details>
  <summary>Details</summary>
Motivation: 在决策相关尺度上准确且经济地量化农业生态系统碳循环对气候缓解和可持续农业至关重要。现有方法在处理异构数据和复杂跨尺度依赖时面临挑战，通常采用位置无关的参数化和独立训练，未能充分利用迁移学习和输入数据的空间异质性，限制了在高度变异区域的适用性。

Method: 提出FTBSC-KGML框架，结合预训练-微调过程、站点特定参数和知识引导机器学习。使用遥感GPP、气候和土壤协变量数据，通过全局预训练模型，然后在各州或站点进行微调，学习位置感知表示。框架增强了KGML-ag，包含空间异质性感知的迁移学习方案。

Result: FTBSC-KGML在验证误差上低于纯全局模型，解释能力更一致，能更好地捕捉跨州的空间变异性。在有限数据条件下提高了局部准确性，同时不牺牲可解释性。

Conclusion: 该工作扩展了先前的SDSA-KGML框架，证明了预训练-微调方法结合空间异质性感知迁移学习在农业生态系统碳循环量化中的有效性，为气候缓解和可持续农业提供了更适用的工具。

Abstract: Accurate and cost-effective quantification of the agroecosystem carbon cycle at decision-relevant scales is essential for climate mitigation and sustainable agriculture. However, both transfer learning and the exploitation of spatial variability in this field are challenging, as they involve heterogeneous data and complex cross-scale dependencies. Conventional approaches often rely on location-independent parameterizations and independent training, underutilizing transfer learning and spatial heterogeneity in the inputs, and limiting their applicability in regions with substantial variability. We propose FTBSC-KGML (Fine-Tuning-Based Site Calibration-Knowledge-Guided Machine Learning), a pretraining- and fine-tuning-based, spatial-variability-aware, and knowledge-guided machine learning framework that augments KGML-ag with a pretraining-fine-tuning process and site-specific parameters. Using a pretraining-fine-tuning process with remote-sensing GPP, climate, and soil covariates collected across multiple midwestern sites, FTBSC-KGML estimates land emissions while leveraging transfer learning and spatial heterogeneity. A key component is a spatial-heterogeneity-aware transfer-learning scheme, which is a globally pretrained model that is fine-tuned at each state or site to learn place-aware representations, thereby improving local accuracy under limited data without sacrificing interpretability. Empirically, FTBSC-KGML achieves lower validation error and greater consistency in explanatory power than a purely global model, thereby better capturing spatial variability across states. This work extends the prior SDSA-KGML framework.

</details>


### [118] [Techno-economic optimization of a heat-pipe microreactor, part I: theory and cost optimization](https://arxiv.org/abs/2512.16032)
*Paul Seurin,Dean Price,Luis Nunez*

Main category: cs.LG

TL;DR: 本文提出了一种结合强化学习的几何设计优化方法，用于降低热管微反应器的平准化电力成本，通过代理模型和约束优化实现了超过57%的成本降低。


<details>
  <summary>Details</summary>
Motivation: 热管微反应器虽然适合偏远地区供电，但存在规模不经济问题，财务可行性不足。需要早期设计阶段就考虑经济和物理分析来改善经济性。

Method: 提出新颖的统一几何设计优化方法：1) 生成随机样本训练高斯过程和多层感知机代理模型；2) 在强化学习框架中使用这些代理模型优化平准化电力成本，同时约束燃料寿命、停堆裕度、峰值热通量和棒积分峰值因子。

Result: 研究了轴向反射体成本高和低两种情况。发现运维成本和资本成本是平准化电力成本的主要贡献者，特别是轴向反射体成本（第一种情况）和控制鼓材料成本。优化器巧妙调整设计参数，在满足约束的同时最小化成本，两种情况下平准化电力成本均降低超过57%。

Conclusion: 该方法有效降低了热管微反应器的电力成本。未来将进行燃料和热管性能与多目标优化的全面集成，以深入理解约束与成本性能之间的相互作用。

Abstract: Microreactors, particularly heat-pipe microreactors (HPMRs), are compact, transportable, self-regulated power systems well-suited for access-challenged remote areas where costly fossil fuels dominate. However, they suffer from diseconomies of scale, and their financial viability remains unconvincing. One step in addressing this shortcoming is to design these reactors with comprehensive economic and physics analyses informing early-stage design iteration. In this work, we present a novel unifying geometric design optimization approach that accounts for techno-economic considerations. We start by generating random samples to train surrogate models, including Gaussian processes (GPs) and multi-layer perceptrons (MLPs). We then deploy these surrogates within a reinforcement learning (RL)-based optimization framework to optimize the levelized cost of electricity (LCOE), all the while imposing constraints on the fuel lifetime, shutdown margin (SDM), peak heat flux, and rod-integrated peaking factor. We study two cases: one in which the axial reflector cost is very high, and one in which it is inexpensive. We found that the operation and maintenance and capital costs are the primary contributors to the overall LCOE particularly the cost of the axial reflectors (for the first case) and the control drum materials. The optimizer cleverly changes the design parameters so as to minimize one of them while still satisfying the constraints, ultimately reducing the LCOE by more than 57% in both instances. A comprehensive integration of fuel and HP performance with multi-objective optimization is currently being pursued to fully understand the interaction between constraints and cost performance.

</details>


### [119] [Explainable AI in Big Data Fraud Detection](https://arxiv.org/abs/2512.16037)
*Ayush Jain,Rahul Kulkarni,Siyi Lin*

Main category: cs.LG

TL;DR: 该论文探讨了如何将可解释人工智能（XAI）集成到大数据分析流程中，用于欺诈检测和风险管理，提出了一个结合可扩展大数据基础设施与上下文感知解释机制的概念框架。


<details>
  <summary>Details</summary>
Motivation: 随着大数据在金融、保险和网络安全领域的广泛应用，机器学习系统被用于大规模风险评估和欺诈检测，但自动化分析带来的透明度、监管合规性和信任问题日益凸显，需要将可解释性融入大数据分析流程。

Method: 论文回顾了大数据的关键特征和主要分析工具（包括分布式存储系统、流处理平台和高级欺诈检测模型），系统综述了广泛使用的XAI方法（如LIME、SHAP、反事实解释和注意力机制），分析了这些方法在大规模部署时的优势和局限性，并提出了一个集成可扩展大数据基础设施与上下文感知解释机制的概念框架。

Result: 识别了与可扩展性、实时处理以及图和时序模型可解释性相关的研究空白，提出了解决这些挑战的概念框架，该框架将可扩展大数据基础设施与上下文感知解释机制和人类反馈相结合。

Conclusion: 论文总结了可扩展XAI、隐私感知解释和可解释欺诈检测系统标准化评估方法等开放研究方向，强调了将可解释性融入大数据分析流程对于提高透明度、合规性和信任的重要性。

Abstract: Big Data has become central to modern applications in finance, insurance, and cybersecurity, enabling machine learning systems to perform large-scale risk assessments and fraud detection. However, the increasing dependence on automated analytics introduces important concerns about transparency, regulatory compliance, and trust. This paper examines how explainable artificial intelligence (XAI) can be integrated into Big Data analytics pipelines for fraud detection and risk management. We review key Big Data characteristics and survey major analytical tools, including distributed storage systems, streaming platforms, and advanced fraud detection models such as anomaly detectors, graph-based approaches, and ensemble classifiers. We also present a structured review of widely used XAI methods, including LIME, SHAP, counterfactual explanations, and attention mechanisms, and analyze their strengths and limitations when deployed at scale. Based on these findings, we identify key research gaps related to scalability, real-time processing, and explainability for graph and temporal models. To address these challenges, we outline a conceptual framework that integrates scalable Big Data infrastructure with context-aware explanation mechanisms and human feedback. The paper concludes with open research directions in scalable XAI, privacy-aware explanations, and standardized evaluation methods for explainable fraud detection systems.

</details>


### [120] [CauSTream: Causal Spatio-Temporal Representation Learning for Streamflow Forecasting](https://arxiv.org/abs/2512.16046)
*Shu Wan,Reepal Shah,John Sabo,Huan Liu,K. Selçuk Candan*

Main category: cs.LG

TL;DR: CauStream是一个用于因果时空径流预测的统一框架，通过联合学习径流因果图和路由图，在保持物理可解释性的同时提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在径流预测中忽视物理过程，限制了可解释性和泛化能力；而现有因果学习方法通常依赖固定的因果图，无法适应数据变化。

Method: 提出CauStream框架，联合学习：(1)气象强迫与径流之间的因果图；(2)捕捉站点间动态依赖关系的路由图。在非参数设置下建立了这些因果结构的可识别性条件。

Result: 在三个美国主要河流流域和三个预测时间尺度上评估，CauStream始终优于现有最先进方法，在较长预测窗口下性能优势更明显。学习到的因果图与领域知识高度一致。

Conclusion: CauStream为因果时空建模提供了原则性基础，具有扩展到广泛科学和环境应用的潜力，在保持物理可解释性的同时提升了预测性能。

Abstract: Streamflow forecasting is crucial for water resource management and risk mitigation. While deep learning models have achieved strong predictive performance, they often overlook underlying physical processes, limiting interpretability and generalization. Recent causal learning approaches address these issues by integrating domain knowledge, yet they typically rely on fixed causal graphs that fail to adapt to data. We propose CauStream, a unified framework for causal spatiotemporal streamflow forecasting. CauSTream jointly learns (i) a runoff causal graph among meteorological forcings and (ii) a routing graph capturing dynamic dependencies across stations. We further establish identifiability conditions for these causal structures under a nonparametric setting. We evaluate CauSTream on three major U.S. river basins across three forecasting horizons. The model consistently outperforms prior state-of-the-art methods, with performance gaps widening at longer forecast windows, indicating stronger generalization to unseen conditions. Beyond forecasting, CauSTream also learns causal graphs that capture relationships among hydrological factors and stations. The inferred structures align closely with established domain knowledge, offering interpretable insights into watershed dynamics. CauSTream offers a principled foundation for causal spatiotemporal modeling, with the potential to extend to a wide range of scientific and environmental applications.

</details>


### [121] [In-Context Multi-Operator Learning with DeepOSets](https://arxiv.org/abs/2512.16074)
*Shao-Ting Chiu,Aditya Nambiar,Ali Syed,Jonathan W. Siegel,Ulisses Braga-Neto*

Main category: cs.LG

TL;DR: DeepOSets架构通过结合DeepSets和DeepONets，无需权重更新即可从上下文示例中学习新PDE的解算子，成为首个在科学机器学习中证明的通用均匀逼近器。


<details>
  <summary>Details</summary>
Motivation: 研究非自回归、非注意力机制的神经网络架构是否也能实现上下文学习能力，特别是在科学机器学习领域解决未见过的PDE问题。

Method: 提出改进的DeepOSets架构，结合DeepSets的集合学习和DeepONets的算子学习，通过用户提示中的参数-解示例对，无需权重更新即可学习新PDE的解算子。

Result: DeepOSets能够从上下文示例中准确预测训练期间未见过的PDE的解，在泊松方程和反应扩散方程的正反边界值问题上表现良好，并且被证明是连续算子类的通用均匀逼近器。

Conclusion: DeepOSets架构展示了强大的上下文学习能力，能够在科学机器学习中实现多算子上下文学习，为PDE求解提供了新的非注意力机制解决方案。

Abstract: In-context Learning (ICL) is the remarkable capability displayed by some machine learning models to learn from examples in a prompt, without any further weight updates. ICL had originally been thought to emerge from the self-attention mechanism in autoregressive transformer architectures. DeepOSets is a non-autoregressive, non-attention based neural architecture that combines set learning via the DeepSets architecture with operator learning via Deep Operator Networks (DeepONets). In a previous study, DeepOSets was shown to display ICL capabilities in supervised learning problems. In this paper, we show that the DeepOSets architecture, with the appropriate modifications, is a multi-operator in-context learner that can recover the solution operator of a new PDE, not seen during training, from example pairs of parameter and solution placed in a user prompt, without any weight updates. Furthermore, we show that DeepOSets is a universal uniform approximator over a class of continuous operators, which we believe is the first result of its kind in the literature of scientific machine learning. This means that a single DeepOSets architecture exists that approximates in-context any continuous operator in the class to any fixed desired degree accuracy, given an appropriate number of examples in the prompt. Experiments with Poisson and reaction-diffusion forward and inverse boundary-value problems demonstrate the ability of the proposed model to use in-context examples to predict accurately the solutions corresponding to parameter queries for PDEs not seen during training.

</details>


### [122] [Privacy Blur: Quantifying Privacy and Utility for Image Data Release](https://arxiv.org/abs/2512.16086)
*Saeed Mahloujifar,Narine Kokhlikyan,Chuan Guo,Kamalika Chaudhuri*

Main category: cs.LG

TL;DR: 研究发现高斯模糊在实际低精度实现中可被逆向攻击，隐私性最差；像素化和像素化加噪声在适当粒度下能更好平衡隐私与实用性，作者开发了Privacy Blur软件包。


<details>
  <summary>Details</summary>
Motivation: 野外收集的图像数据常包含人脸、车牌等隐私信息，负责任的数据发布需要隐藏这些信息，同时保持数据对模型训练的有效性。当前行业标准的高斯模糊方法存在隐私风险。

Method: 比较了四种隐私模糊算法：高斯模糊、像素化、像素化加噪声（DP-Pix）和裁剪。通过逆向攻击和识别攻击评估隐私性，通过在模糊人脸数据上训练模型的质量评估实用性。

Result: 高斯模糊在实际低精度实现中最不隐私，易受逆向攻击。像素化和像素化加噪声在适当粒度下能提供更好的隐私保护，同时保持计算机视觉任务的实用性。

Conclusion: 行业标准的高斯模糊方法隐私性不足，像素化和像素化加噪声是更好的隐私保护方案。作者开发了Privacy Blur软件包提供建议参数和方法。

Abstract: Image data collected in the wild often contains private information such as faces and license plates, and responsible data release must ensure that this information stays hidden. At the same time, released data should retain its usefulness for model-training. The standard method for private information obfuscation in images is Gaussian blurring. In this work, we show that practical implementations of Gaussian blurring are reversible enough to break privacy. We then take a closer look at the privacy-utility tradeoffs offered by three other obfuscation algorithms -- pixelization, pixelization and noise addition (DP-Pix), and cropping. Privacy is evaluated by reversal and discrimination attacks, while utility by the quality of the learnt representations when the model is trained on data with obfuscated faces. We show that the most popular industry-standard method, Gaussian blur is the least private of the four -- being susceptible to reversal attacks in its practical low-precision implementations. In contrast, pixelization and pixelization plus noise addition, when used at the right level of granularity, offer both privacy and utility for a number of computer vision tasks. We make our proposed methods together with suggested parameters available in a software package called Privacy Blur.

</details>


### [123] [AIMM: An AI-Driven Multimodal Framework for Detecting Social-Media-Influenced Stock Market Manipulation](https://arxiv.org/abs/2512.16103)
*Sandeep Neela*

Main category: cs.LG

TL;DR: AIMM框架通过融合Reddit活动、机器人指标和市场数据，为每只股票生成每日操纵风险评分，用于检测社交媒体驱动的市场操纵。


<details>
  <summary>Details</summary>
Motivation: 市场操纵越来越多地来自协调的社交媒体活动而非孤立交易，零售投资者、监管机构和经纪商需要能够连接在线叙事、协调模式与市场行为的工具。

Method: 构建AIMM框架，融合Reddit活动、机器人与协调指标、OHLCV市场特征，使用parquet-native流水线和Streamlit仪表板，采用校准的合成社交特征匹配事件特征，市场数据来自真实历史数据。

Result: 创建AIMM-GT数据集（33个标记的股票-日，涵盖8只股票），实现前向评估和预测日志记录，AIMM在GME事件中提前22天发出预警，初步显示出判别能力。

Conclusion: 尽管当前标记数据集较小，但AIMM显示出初步的社交媒体驱动市场监控能力，发布代码、数据集架构和仪表板设计以支持相关研究。

Abstract: Market manipulation now routinely originates from coordinated social media campaigns, not isolated trades. Retail investors, regulators, and brokerages need tools that connect online narratives and coordination patterns to market behavior. We present AIMM, an AI-driven framework that fuses Reddit activity, bot and coordination indicators, and OHLCV market features into a daily AIMM Manipulation Risk Score for each ticker.
  The system uses a parquet-native pipeline with a Streamlit dashboard that allows analysts to explore suspicious windows, inspect underlying posts and price action, and log model outputs over time. Due to Reddit API restrictions, we employ calibrated synthetic social features matching documented event characteristics; market data (OHLCV) uses real historical data from Yahoo Finance. This release makes three contributions. First, we build the AIMM Ground Truth dataset (AIMM-GT): 33 labeled ticker-days spanning eight equities, drawing from SEC enforcement actions, community-verified manipulation cases, and matched normal controls. Second, we implement forward-walk evaluation and prospective prediction logging for both retrospective and deployment-style assessment. Third, we analyze lead times and show that AIMM flagged GME 22 days before the January 2021 squeeze peak.
  The current labeled set is small (33 ticker-days, 3 positive events), but results show preliminary discriminative capability and early warnings for the GME incident. We release the code, dataset schema, and dashboard design to support research on social media-driven market surveillance.

</details>


### [124] [BUILD with Precision: Bottom-Up Inference of Linear DAGs](https://arxiv.org/abs/2512.16111)
*Hamed Ajorlou,Samuel Rey,Gonzalo Mateos,Geert Leus,Antonio G. Marques*

Main category: cs.LG

TL;DR: BUILD算法利用观测数据的精度矩阵结构，通过自底向上逐步识别叶节点并剪枝，实现线性高斯SEM下DAG的确定性重构


<details>
  <summary>Details</summary>
Motivation: 从观测数据学习有向无环图结构是因果发现、统计信号处理和机器学习中的核心问题。在线性高斯结构方程模型且噪声方差相等的条件下，该问题是可识别的，需要开发有效的DAG恢复算法

Method: 提出BUILD算法：利用观测数据精度矩阵的独特结构，自底向上逐步识别叶节点及其父节点，然后通过移除入射边剪除叶节点，重复此过程直到完整重构DAG。为处理有限数据估计精度矩阵时的误差累积，采用周期性重新估计精度矩阵的策略

Result: 在具有挑战性的合成基准测试中，BUILD算法相比最先进的DAG学习算法表现优异，同时提供了明确的复杂度控制

Conclusion: BUILD算法在线性高斯SEM下提供了一种确定性的DAG重构方法，通过利用精度矩阵的结构特性实现高效准确的图结构学习，并在实际应用中通过重新估计策略增强鲁棒性

Abstract: Learning the structure of directed acyclic graphs (DAGs) from observational data is a central problem in causal discovery, statistical signal processing, and machine learning. Under a linear Gaussian structural equation model (SEM) with equal noise variances, the problem is identifiable and we show that the ensemble precision matrix of the observations exhibits a distinctive structure that facilitates DAG recovery. Exploiting this property, we propose BUILD (Bottom-Up Inference of Linear DAGs), a deterministic stepwise algorithm that identifies leaf nodes and their parents, then prunes the leaves by removing incident edges to proceed to the next step, exactly reconstructing the DAG from the true precision matrix. In practice, precision matrices must be estimated from finite data, and ill-conditioning may lead to error accumulation across BUILD steps. As a mitigation strategy, we periodically re-estimate the precision matrix (with less variables as leaves are pruned), trading off runtime for enhanced robustness. Reproducible results on challenging synthetic benchmarks demonstrate that BUILD compares favorably to state-of-the-art DAG learning algorithms, while offering an explicit handle on complexity.

</details>


### [125] [Dual-View Inference Attack: Machine Unlearning Amplifies Privacy Exposure](https://arxiv.org/abs/2512.16126)
*Lulu Xue,Shengshan Hu,Linqiang Qian,Peijin Guo,Yechao Zhang,Minghui Li,Yanjun Zhang,Dayong Ye,Leo Yu Zhang*

Main category: cs.LG

TL;DR: 该论文首次揭示了机器遗忘在双视图设置下的隐私风险，提出了DVIA攻击方法，证明攻击者通过查询原始模型和遗忘模型可以获得比单独查询任一模型更多的隐私信息。


<details>
  <summary>Details</summary>
Motivation: 机器遗忘技术虽然能响应用户数据删除请求，但现有研究主要关注已遗忘数据的隐私风险，而保留数据的隐私风险尚未充分探索。本文旨在填补这一空白，研究机器遗忘在双视图设置下对保留数据带来的隐私威胁。

Method: 从信息论角度引入"隐私知识增益"概念，证明双视图设置能让攻击者获得更多信息。提出DVIA（双视图推理攻击）方法，该方法无需训练攻击模型，通过黑盒查询原始模型和遗忘模型，使用轻量级似然比推理模块高效提取保留数据的成员信息。

Result: 在不同数据集和模型架构上的实验验证了DVIA的有效性，证实双视图设置确实会放大隐私泄露风险，攻击者通过查询两个模型能比单独查询任一模型获得更多隐私信息。

Conclusion: 机器遗忘在双视图设置下会引入新的隐私风险，攻击者通过同时查询原始模型和遗忘模型可以获取更多关于保留数据的隐私信息。这揭示了机器遗忘技术在实际部署中需要考虑的新安全问题。

Abstract: Machine unlearning is a newly popularized technique for removing specific training data from a trained model, enabling it to comply with data deletion requests. While it protects the rights of users requesting unlearning, it also introduces new privacy risks. Prior works have primarily focused on the privacy of data that has been unlearned, while the risks to retained data remain largely unexplored. To address this gap, we focus on the privacy risks of retained data and, for the first time, reveal the vulnerabilities introduced by machine unlearning under the dual-view setting, where an adversary can query both the original and the unlearned models. From an information-theoretic perspective, we introduce the concept of {privacy knowledge gain} and demonstrate that the dual-view setting allows adversaries to obtain more information than querying either model alone, thereby amplifying privacy leakage. To effectively demonstrate this threat, we propose DVIA, a Dual-View Inference Attack, which extracts membership information on retained data using black-box queries to both models. DVIA eliminates the need to train an attack model and employs a lightweight likelihood ratio inference module for efficient inference. Experiments across different datasets and model architectures validate the effectiveness of DVIA and highlight the privacy risks inherent in the dual-view setting.

</details>


### [126] [INTELLECT-3: Technical Report](https://arxiv.org/abs/2512.16144)
*Prime Intellect Team,Mika Senghaas,Fares Obeid,Sami Jaghouar,William Brown,Jack Min Ong,Daniel Auras,Matej Sirovatka,Jannik Straube,Andrew Baker,Sebastian Müller,Justus Mattern,Manveer Basra,Aiman Ismail,Dominik Scherm,Cooper Miller,Ameen Patel,Simon Kirsten,Mario Sieg,Christian Reetz,Kemal Erdem,Vincent Weisser,Johannes Hagemann*

Main category: cs.LG

TL;DR: INTELLECT-3是一个106B参数的MoE模型（12B激活），通过大规模强化学习训练，在数学、代码、科学和推理基准测试中达到同尺寸模型的最先进性能，并开源了完整的RL基础设施栈。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够在数学、代码、科学和推理等多个领域达到最先进性能的高效大型语言模型，同时构建一个可扩展的强化学习基础设施栈，支持大规模训练并促进开源社区发展。

Method: 使用混合专家架构（106B参数，12B激活），基于GLM-4.5-Air-Base模型进行监督微调和强化学习训练。开发了prime-rl框架支持大规模异步RL训练，可扩展到数千个GPU，并支持多轮交互和工具使用。训练使用了512个H200 GPU，并利用了Environments Hub社区平台的环境库。

Result: INTELLECT-3在数学、代码、科学和推理基准测试中达到了同尺寸模型的最先进性能，超越了多个更大的前沿模型。模型和完整的RL基础设施栈（包括RL框架、训练配方、环境库）均已开源。

Conclusion: 通过构建可扩展的强化学习基础设施栈和大规模训练，成功开发了在多个领域具有最先进性能的高效MoE模型，同时为社区提供了完整的开源工具链，促进了强化学习在大型语言模型训练中的应用和发展。

Abstract: We present INTELLECT-3, a 106B-parameter Mixture-of-Experts model (12B active) trained with large-scale reinforcement learning on our end-to-end RL infrastructure stack. INTELLECT-3 achieves state of the art performance for its size across math, code, science and reasoning benchmarks, outperforming many larger frontier models. We open-source the model together with the full infrastructure stack used to create it, including RL frameworks, complete recipe, and a wide collection of environments, built with the verifiers library, for training and evaluation from our Environments Hub community platform. Built for this effort, we introduce prime-rl, an open framework for large-scale asynchronous reinforcement learning, which scales seamlessly from a single node to thousands of GPUs, and is tailored for agentic RL with first-class support for multi-turn interactions and tool use. Using this stack, we run both SFT and RL training on top of the GLM-4.5-Air-Base model, scaling RL training up to 512 H200s with high training efficiency.

</details>


### [127] [A Multimodal Approach to Alzheimer's Diagnosis: Geometric Insights from Cube Copying and Cognitive Assessments](https://arxiv.org/abs/2512.16184)
*Jaeho Yang,Kijung Yoon*

Main category: cs.LG

TL;DR: 该研究提出了一种多模态框架，将手绘立方体草图转换为图结构表示，结合人口统计信息和神经心理学测试分数进行阿尔茨海默病分类。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病的早期和可及性检测仍是临床挑战，立方体复制任务提供了一种简单但信息丰富的视觉空间功能评估方法。需要开发更准确、可解释的筛查工具。

Method: 将手绘立方体建模为图结构，节点特征编码空间坐标、局部图元拓扑和角度几何特征，使用图神经网络处理，并与年龄、教育程度和神经心理学测试特征进行后期融合。

Result: 图基表示提供了强大的单模态基线，显著优于基于像素的卷积模型，多模态集成进一步提高了性能和对类别不平衡的鲁棒性。SHAP可解释性分析识别出特定图元基序和几何畸变是关键预测因子。

Conclusion: 基于图的立方体复制分析为阿尔茨海默病筛查提供了一种可解释、非侵入性和可扩展的方法，与临床观察到的AD患者立方体绘图紊乱现象一致。

Abstract: Early and accessible detection of Alzheimer's disease (AD) remains a critical clinical challenge, and cube-copying tasks offer a simple yet informative assessment of visuospatial function. This work proposes a multimodal framework that converts hand-drawn cube sketches into graph-structured representations capturing geometric and topological properties, and integrates these features with demographic information and neuropsychological test (NPT) scores for AD classification. Cube drawings are modeled as graphs with node features encoding spatial coordinates, local graphlet-based topology, and angular geometry, which are processed using graph neural networks and fused with age, education, and NPT features in a late-fusion model. Experimental results show that graph-based representations provide a strong unimodal baseline and substantially outperform pixel-based convolutional models, while multimodal integration further improves performance and robustness to class imbalance. SHAP-based interpretability analysis identifies specific graphlet motifs and geometric distortions as key predictors, closely aligning with clinical observations of disorganized cube drawings in AD. Together, these results establish graph-based analysis of cube copying as an interpretable, non-invasive, and scalable approach for Alzheimer's disease screening.

</details>


### [128] [A Multi-scale Fused Graph Neural Network with Inter-view Contrastive Learning for Spatial Transcriptomics Data Clustering](https://arxiv.org/abs/2512.16188)
*Jianping Mei,Siqi Ai,Ye Yuan*

Main category: cs.LG

TL;DR: stMFG提出了一种多尺度交互融合图网络，通过层间跨视图注意力动态整合空间和基因特征，结合跨视图对比学习和空间约束，在空间转录组学中显著提升了空间域识别性能。


<details>
  <summary>Details</summary>
Motivation: 空间转录组学能在原生组织环境中进行全基因组表达分析，但识别空间域仍面临挑战，因为基因与空间存在复杂相互作用。现有方法通常分别处理空间和特征视图，仅在输出层融合，这种"分别编码、后期融合"范式限制了多尺度语义捕获和跨视图交互。

Method: stMFG是一种多尺度交互融合图网络，引入层间跨视图注意力机制，在每次卷积后动态整合空间和基因特征。模型结合跨视图对比学习和空间约束，增强区分能力的同时保持空间连续性。

Result: 在DLPFC和乳腺癌数据集上，stMFG优于现有最先进方法，在某些切片上实现了高达14%的ARI（调整兰德指数）提升。

Conclusion: stMFG通过多尺度交互融合有效解决了空间转录组学中空间域识别的挑战，为复杂基因-空间相互作用的建模提供了新范式。

Abstract: Spatial transcriptomics enables genome-wide expression analysis within native tissue context, yet identifying spatial domains remains challenging due to complex gene-spatial interactions. Existing methods typically process spatial and feature views separately, fusing only at output level - an "encode-separately, fuse-late" paradigm that limits multi-scale semantic capture and cross-view interaction. Accordingly, stMFG is proposed, a multi-scale interactive fusion graph network that introduces layer-wise cross-view attention to dynamically integrate spatial and gene features after each convolution. The model combines cross-view contrastive learning with spatial constraints to enhance discriminability while maintaining spatial continuity. On DLPFC and breast cancer datasets, stMFG outperforms state-of-the-art methods, achieving up to 14% ARI improvement on certain slices.

</details>


### [129] [Explicit and Non-asymptotic Query Complexities of Rank-Based Zeroth-order Algorithms on Smooth Functions](https://arxiv.org/abs/2512.16200)
*Haishan Ye*

Main category: cs.LG

TL;DR: 本文首次为基于排序的零阶优化算法建立了显式的非渐进收敛率，填补了该领域理论分析的空白。


<details>
  <summary>Details</summary>
Motivation: 基于排序的零阶优化方法（如CMA-ES、自然进化策略等）在实践中广泛成功，但现有理论分析仅限于渐近结果，缺乏显式收敛率分析，特别是对于选择top-k方向的算法。

Method: 分析一个简单的基于排序的零阶算法，采用新颖的分析方法避免传统的漂移和信息几何技术，为d维问题建立显式查询复杂度。

Result: 对于L-光滑、μ-强凸函数，达到Õ(dL/μ·log(dL/μδ)·log(1/ε))查询复杂度；对于光滑非凸目标，达到O(dL/ε·log(1/ε))查询复杂度，均以至少1-δ的概率成立。

Conclusion: 首次为基于排序的零阶优化提供了显式非渐进收敛率，揭示了基于排序的启发式方法在零阶优化中高效性的理论依据。

Abstract: Rank-based zeroth-order (ZO) optimization -- which relies only on the ordering of function evaluations -- offers strong robustness to noise and monotone transformations, and underlies many successful algorithms such as CMA-ES, natural evolution strategies, and rank-based genetic algorithms. Despite its widespread use, the theoretical understanding of rank-based ZO methods remains limited: existing analyses provide only asymptotic insights and do not yield explicit convergence rates for algorithms selecting the top-$k$ directions.
  This work closes this gap by analyzing a simple rank-based ZO algorithm and establishing the first \emph{explicit}, and \emph{non-asymptotic} query complexities. For a $d$-dimension problem, if the function is $L$-smooth and $μ$-strongly convex, the algorithm achieves $\widetilde{\mathcal O}\!\left(\frac{dL}μ\log\!\frac{dL}{μδ}\log\!\frac{1}{\varepsilon}\right)$ to find an $\varepsilon$-suboptimal solution, and for smooth nonconvex objectives it reaches $\mathcal O\!\left(\frac{dL}{\varepsilon}\log\!\frac{1}{\varepsilon}\right)$. Notation $\cO(\cdot)$ hides constant terms and $\widetilde{\mathcal O}(\cdot)$ hides extra $\log\log\frac{1}{\varepsilon}$ term. These query complexities hold with a probability at least $1-δ$ with $0<δ<1$. The analysis in this paper is novel and avoids classical drift and information-geometric techniques. Our analysis offers new insight into why rank-based heuristics lead to efficient ZO optimization.

</details>


### [130] [Neural emulation of gravity-driven geohazard runout](https://arxiv.org/abs/2512.16221)
*Lorenzo Nava,Ye Chen,Maximillian Van Wyk de Vries*

Main category: cs.LG

TL;DR: 使用机器学习模型预测地质灾害（滑坡、雪崩等）的运移范围，相比传统数值模拟快100-10000倍，能准确预测流动范围和沉积厚度。


<details>
  <summary>Details</summary>
Motivation: 地质灾害（滑坡、雪崩等）造成大量人员伤亡，其运移范围难以预测，特别是对下游社区。现有模型面临速度与真实性的权衡，需要既物理真实又计算高效的模型。

Method: 训练机器学习模型来预测地质灾害运移范围。模型基于超过100,000个数值模拟数据，覆盖10,000多个真实世界数字高程模型区域，能够预测流动范围和沉积厚度。

Result: 模型预测准确度高，计算速度比数值求解器快100-10,000倍，能够重现关键物理行为（如分流和沉积模式），并能泛化到不同流动类型、规模和地形。

Conclusion: 神经仿真技术能够实现快速、空间分辨的运移预测，为灾害风险减少和基于影响的预报开辟新机会，是扩展物理真实地质灾害建模到大规模预警系统相关时空尺度的有前景途径。

Abstract: Predicting geohazard runout is critical for protecting lives, infrastructure and ecosystems. Rapid mass flows, including landslides and avalanches, cause several thousand deaths across a wide range of environments, often travelling many kilometres from their source. The wide range of source conditions and material properties governing these flows makes their runout difficult to anticipate, particularly for downstream communities that may be suddenly exposed to severe impacts. Accurately predicting runout at scale requires models that are both physically realistic and computationally efficient, yet existing approaches face a fundamental speed-realism trade-off. Here we train a machine learning model to predict geohazard runout across representative real world terrains. The model predicts both flow extent and deposit thickness with high accuracy and 100 to 10,000 times faster computation than numerical solvers. It is trained on over 100,000 numerical simulations across over 10,000 real world digital elevation model chips and reproduces key physical behaviours, including avulsion and deposition patterns, while generalizing across different flow types, sizes and landscapes. Our results demonstrate that neural emulation enables rapid, spatially resolved runout prediction across diverse real world terrains, opening new opportunities for disaster risk reduction and impact-based forecasting. These results highlight neural emulation as a promising pathway for extending physically realistic geohazard modelling to spatial and temporal scales relevant for large scale early warning systems.

</details>


### [131] [Coarse-to-Fine Open-Set Graph Node Classification with Large Language Models](https://arxiv.org/abs/2512.16244)
*Xueqi Ma,Xingjun Ma,Sarah Monazam Erfani,Danilo Mandic,James Bailey*

Main category: cs.LG

TL;DR: 提出CFC框架，利用大语言模型实现图数据上的粗到细开放集分类，将OOD检测扩展到OOD分类，无需真实标签信息


<details>
  <summary>Details</summary>
Motivation: 现有方法将OOD样本视为单一类别，但实际应用（如欺诈检测、医疗诊断）需要更深入了解OOD样本的可能标签。关键问题：能否在没有真实标签信息的情况下将OOD检测扩展到OOD分类？

Method: CFC框架包含三个组件：1) 粗分类器使用LLM提示进行OOD检测和异常标签生成；2) GNN细分类器利用粗分类器识别的OOD样本训练，增强OOD检测和ID分类；3) 通过LLM提示和后处理的OOD标签实现精细化OOD分类。使用语义OOD实例而非合成样本。

Result: CFC在图和文本领域的OOD检测性能比最先进方法提升10%，在图数据集上的OOD分类准确率达到70%

Conclusion: CFC框架成功将OOD检测扩展到OOD分类，利用LLM生成语义OOD标签，提高了开放集分类的实用性和可解释性，特别适用于高风险应用场景

Abstract: Developing open-set classification methods capable of classifying in-distribution (ID) data while detecting out-of-distribution (OOD) samples is essential for deploying graph neural networks (GNNs) in open-world scenarios. Existing methods typically treat all OOD samples as a single class, despite real-world applications, especially high-stake settings such as fraud detection and medical diagnosis, demanding deeper insights into OOD samples, including their probable labels. This raises a critical question: can OOD detection be extended to OOD classification without true label information? To address this question, we propose a Coarse-to-Fine open-set Classification (CFC) framework that leverages large language models (LLMs) for graph datasets. CFC consists of three key components: a coarse classifier that uses LLM prompts for OOD detection and outlier label generation, a GNN-based fine classifier trained with OOD samples identified by the coarse classifier for enhanced OOD detection and ID classification, and refined OOD classification achieved through LLM prompts and post-processed OOD labels. Unlike methods that rely on synthetic or auxiliary OOD samples, CFC employs semantic OOD instances that are genuinely out-of-distribution based on their inherent meaning, improving interpretability and practical utility. Experimental results show that CFC improves OOD detection by ten percent over state-of-the-art methods on graph and text domains and achieves up to seventy percent accuracy in OOD classification on graph datasets.

</details>


### [132] [Sharpness-aware Federated Graph Learning](https://arxiv.org/abs/2512.16247)
*Ruiyu Li,Peige Zhao,Guangxia Li,Pengcheng Wu,Xingyu Gao,Zhiqiang Xu*

Main category: cs.LG

TL;DR: SEAL提出了一种基于锐度感知的联邦图学习算法，通过同时最小化损失函数及其锐度，并引入基于相关矩阵的正则化器，解决联邦图学习中的数据异构性和维度坍塌问题。


<details>
  <summary>Details</summary>
Motivation: 联邦图学习面临两个核心挑战：1）基于经验风险最小化的优化器导致局部模型陷入尖锐谷，削弱了对分布外图数据的泛化能力；2）局部图数据学习表示中的维度坍塌对GNN模型的分类能力产生负面影响。

Method: 提出SEAL算法：1）制定锐度感知的优化目标，同时最小化损失函数及其锐度，寻找平坦区域中的模型参数；2）引入基于局部表示相关矩阵的正则化器，放松单个局部图样本生成表示之间的相关性，缓解维度坍塌。

Result: 在多个图分类基准测试中，SEAL始终优于最先进的联邦图学习基线方法，并为更多参与者提供了性能增益，增强了局部GNN模型的分类准确性和泛化能力。

Conclusion: SEAL算法通过锐度感知优化和相关矩阵正则化，有效解决了联邦图学习中的数据异构性和维度坍塌问题，提高了模型在异构数据上的泛化性能。

Abstract: One of many impediments to applying graph neural networks (GNNs) to large-scale real-world graph data is the challenge of centralized training, which requires aggregating data from different organizations, raising privacy concerns. Federated graph learning (FGL) addresses this by enabling collaborative GNN model training without sharing private data. However, a core challenge in FGL systems is the variation in local training data distributions among clients, known as the data heterogeneity problem. Most existing solutions suffer from two problems: (1) The typical optimizer based on empirical risk minimization tends to cause local models to fall into sharp valleys and weakens their generalization to out-of-distribution graph data. (2) The prevalent dimensional collapse in the learned representations of local graph data has an adverse impact on the classification capacity of the GNN model. To this end, we formulate a novel optimization objective that is aware of the sharpness (i.e., the curvature of the loss surface) of local GNN models. By minimizing the loss function and its sharpness simultaneously, we seek out model parameters in a flat region with uniformly low loss values, thus improving the generalization over heterogeneous data. By introducing a regularizer based on the correlation matrix of local representations, we relax the correlations of representations generated by individual local graph samples, so as to alleviate the dimensional collapse of the learned model. The proposed \textbf{S}harpness-aware f\textbf{E}derated gr\textbf{A}ph \textbf{L}earning (SEAL) algorithm can enhance the classification accuracy and generalization ability of local GNN models in federated graph learning. Experimental studies on several graph classification benchmarks show that SEAL consistently outperforms SOTA FGL baselines and provides gains for more participants.

</details>


### [133] [Sharpness-aware Second-order Latent Factor Model for High-dimensional and Incomplete Data](https://arxiv.org/abs/2512.16277)
*Jialiang Wang,Xueyan Bao,Hao Wu*

Main category: cs.LG

TL;DR: 提出Sharpness-aware SLF (SSLF)模型，通过Hessian-vector products获取二阶信息，并在曲率中注入锐度项，以解决SLF模型优化困难问题


<details>
  <summary>Details</summary>
Motivation: 二阶潜在因子(SLF)模型在处理高维不完整数据时有效，但由于其双线性和非凸性质，优化非常困难。Sharpness-aware Minimization (SAM)方法能够找到平坦的局部最小值，从而改善表示学习模型的泛化能力

Method: 提出Sharpness-aware SLF (SSLF)模型，包含两个关键思想：(1)通过Hessian-vector products获取二阶信息；(2)通过设计的Hessian-vector products在曲率(Hessian)中注入锐度项

Result: 在多个工业数据集上的实验表明，所提出的模型始终优于最先进的基线方法

Conclusion: SSLF模型通过结合二阶信息和锐度感知优化，有效解决了SLF模型的优化困难问题，提高了模型的性能

Abstract: Second-order Latent Factor (SLF) model, a class of low-rank representation learning methods, has proven effective at extracting node-to-node interaction patterns from High-dimensional and Incomplete (HDI) data. However, its optimization is notoriously difficult due to its bilinear and non-convex nature. Sharpness-aware Minimization (SAM) has recently proposed to find flat local minima when minimizing non-convex objectives, thereby improving the generalization of representation-learning models. To address this challenge, we propose a Sharpness-aware SLF (SSLF) model. SSLF embodies two key ideas: (1) acquiring second-order information via Hessian-vector products; and (2) injecting a sharpness term into the curvature (Hessian) through the designed Hessian-vector products. Experiments on multiple industrial datasets demonstrate that the proposed model consistently outperforms state-of-the-art baselines.

</details>


### [134] [CKA-Guided Modular Quantization: Beyond Bit-Width to Algorithmic Diversity](https://arxiv.org/abs/2512.16282)
*Jinhao Zhang,Yunquan Zhang,Daning Chen*

Main category: cs.LG

TL;DR: 提出CKA引导的模块化量化方法，通过逐层评估多种PTQ算法并自动选择最优策略，构建混合量化模型，在LLaMA和Qwen等主流大语言模型上优于均匀量化和混合精度方法。


<details>
  <summary>Details</summary>
Motivation: 当前主流的大语言模型后训练量化方法通常对所有网络层采用统一的量化策略，忽略了不同层在算法适用性上的显著差异。为了解决这一局限性，需要开发能够考虑层间差异的量化方法。

Method: 提出CKA引导的模块化量化框架：1）独立评估多种PTQ算法在每个层上的表现；2）使用线性中心核对齐（CKA）作为度量标准，自动为每层选择最优量化策略；3）将个体优化策略集成构建混合量化模型。该方法无需微调，即插即用。

Result: 实验表明，该方法在主流LLM（包括LLaMA和Qwen）上，在困惑度（PPL）和下游任务性能方面，始终优于均匀量化基线和最先进的混合精度方法。

Conclusion: CKA引导的模块化量化方法通过考虑不同层的算法适用性差异，实现了更优的量化效果，为大型语言模型的高效部署提供了有效的解决方案。

Abstract: Current mainstream post-training quantization methods for large language models typically apply a uniform quantization strategy across all network layers, overlooking the substantial differences in algorithmic suitability among layers. To address this limitation, we propose CKA Guided Modular Quantization, a fine-tuning-free, plug-and-play framework for algorithmic heterogeneous quantization. Our method independently evaluates multiple PTQ algorithms on each layer and employs Linear Centered Kernel Alignment (CKA) as a metric to automatically select the optimal quantization strategy per layer. The individually optimized strategies are then integrated to construct a hybrid quantized model. Experiments demonstrate that our approach consistently outperforms both uniform quantization baselines and state-of-the-art mixed-precision methods across mainstream LLMs including LLaMA and Qwen ,in terms of perplexity (PPL) and downstream task performance.

</details>


### [135] [Feature-Selective Representation Misdirection for Machine Unlearning](https://arxiv.org/abs/2512.16297)
*Taozhao Chen,Linghan Huang,Kim-Kwang Raymond Choo,Huaming Chen*

Main category: cs.LG

TL;DR: SRMU提出了一种新的激活编辑框架，通过特征感知和方向可控的扰动来实现大语言模型的选择性遗忘，在高度纠缠的数据分布下仍能保持模型效用。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在安全关键和受监管领域的应用增加，模型中保留的敏感或禁止知识带来了隐私泄露、监管不合规和潜在滥用等风险。现有的遗忘技术假设遗忘和保留数据集之间有清晰的分离，这在现实操作环境中难以实现，因为数据分布通常是高度纠缠的。基于扰动的方法在这种情况下往往会降低模型效用或无法确保安全性。

Method: SRMU（选择性表示误导遗忘）是一个原则性的激活编辑框架，它实施特征感知和方向可控的扰动。与不加区分的模型权重扰动不同，SRMU使用结构化误导向量和激活重要性图，选择性抑制有害表示，同时保留对良性数据的效用。

Result: 在WMDP基准测试上的实验表明，SRMU在低纠缠和高纠缠配置下都实现了最先进的遗忘性能，且效用损失最小。在20-30%数据重叠的情况下，现有基线方法失效，而SRMU仍能保持有效性。

Conclusion: SRMU为安全驱动的模型治理、隐私合规和受控知识移除提供了稳健的基础，适用于新兴的基于LLM的应用场景。该方法在高度纠缠的数据分布下仍能有效工作，解决了现有遗忘技术的局限性。

Abstract: As large language models (LLMs) are increasingly adopted in safety-critical and regulated sectors, the retention of sensitive or prohibited knowledge introduces escalating risks, ranging from privacy leakage to regulatory non-compliance to to potential misuse, and so on. Recent studies suggest that machine unlearning can help ensure deployed models comply with evolving legal, safety, and governance requirements. However, current unlearning techniques assume clean separation between forget and retain datasets, which is challenging in operational settings characterized by highly entangled distributions. In such scenarios, perturbation-based methods often degrade general model utility or fail to ensure safety. To address this, we propose Selective Representation Misdirection for Unlearning (SRMU), a novel principled activation-editing framework that enforces feature-aware and directionally controlled perturbations. Unlike indiscriminate model weights perturbations, SRMU employs a structured misdirection vector with an activation importance map. The goal is to allow SRMU selectively suppresses harmful representations while preserving the utility on benign ones. Experiments are conducted on the widely used WMDP benchmark across low- and high-entanglement configurations. Empirical results reveal that SRMU delivers state-of-the-art unlearning performance with minimal utility losses, and remains effective under 20-30\% overlap where existing baselines collapse. SRMU provides a robust foundation for safety-driven model governance, privacy compliance, and controlled knowledge removal in the emerging LLM-based applications. We release the replication package at https://figshare.com/s/d5931192a8824de26aff.

</details>


### [136] [Pretrained Battery Transformer (PBT): A battery life prediction foundation model](https://arxiv.org/abs/2512.16334)
*Ruifeng Tan,Weixiang Hong,Jia Li,Jiaqiang Huang,Tong-Yi Zhang*

Main category: cs.LG

TL;DR: 开发了首个电池寿命预测基础模型PBT，通过领域知识编码的专家混合层，在13个锂离子电池数据集上学习可迁移表征，平均性能提升19.8%，在15个不同数据集上实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 电池循环寿命早期预测对加速电池研究、制造和部署至关重要。现有机器学习方法受限于数据稀缺性和异质性（来自不同的老化条件）。其他领域的基础模型通过迁移学习实现了广泛泛化，但电池寿命预测领域尚无基础模型。

Method: 提出了预训练电池变换器(PBT)，这是首个电池寿命预测基础模型，通过领域知识编码的专家混合层开发。在最大的公共电池寿命数据库上验证，从13个锂离子电池数据集中学习可迁移表征。

Result: PBT平均性能比现有模型提升19.8%。通过迁移学习，在包含各种操作条件、化成协议和化学组成的15个不同数据集上实现了最先进的性能。

Conclusion: 这项工作为电池寿命预测建立了基础模型路径，为通用电池寿命预测系统铺平了道路。

Abstract: Early prediction of battery cycle life is essential for accelerating battery research, manufacturing, and deployment. Although machine learning methods have shown encouraging results, progress is hindered by data scarcity and heterogeneity arising from diverse aging conditions. In other fields, foundation models (FMs) trained on diverse datasets have achieved broad generalization through transfer learning, but no FMs have been reported for battery cycle life prediction yet. Here we present the Pretrained Battery Transformer (PBT), the first FM for battery life prediction, developed through domain-knowledge-encoded mixture-of-expert layers. Validated on the largest public battery life database, PBT learns transferable representations from 13 lithium-ion battery (LIB) datasets, outperforming existing models by an average of 19.8%. With transfer learning, PBT achieves state-of-the-art performance across 15 diverse datasets encompassing various operating conditions, formation protocols, and chemistries of LIBs. This work establishes a foundation model pathway for battery lifetime prediction, paving the way toward universal battery lifetime prediction systems.

</details>


### [137] [Multivariate Uncertainty Quantification with Tomographic Quantile Forests](https://arxiv.org/abs/2512.16383)
*Takuya Kanazawa*

Main category: cs.LG

TL;DR: Tomographic Quantile Forests (TQF) 是一种用于多元目标变量的非参数树回归模型，通过方向投影学习条件分位数，并通过切片Wasserstein距离重建多元条件分布。


<details>
  <summary>Details</summary>
Motivation: 量化预测不确定性对于AI在真实世界中的安全可信部署至关重要，但目前对多元目标变量的完全非参数条件分布估计仍然具有挑战性。

Method: TQF学习方向投影n⊤y的条件分位数作为输入x和单位方向n的函数。在推理时，它聚合多个方向的分位数，并通过高效的交替方案（具有凸子问题）最小化切片Wasserstein距离来重建多元条件分布。

Result: TQF在合成和真实世界数据集上进行了评估，相比经典方向分位数方法，TQF能够用单一模型覆盖所有方向而不施加凸性限制。

Conclusion: TQF提供了一种有效的非参数方法来估计多元条件分布，解决了传统方法需要为不同方向训练单独模型且只能产生凸分位数区域的问题。

Abstract: Quantifying predictive uncertainty is essential for safe and trustworthy real-world AI deployment. Yet, fully nonparametric estimation of conditional distributions remains challenging for multivariate targets. We propose Tomographic Quantile Forests (TQF), a nonparametric, uncertainty-aware, tree-based regression model for multivariate targets. TQF learns conditional quantiles of directional projections $\mathbf{n}^{\top}\mathbf{y}$ as functions of the input $\mathbf{x}$ and the unit direction $\mathbf{n}$. At inference, it aggregates quantiles across many directions and reconstructs the multivariate conditional distribution by minimizing the sliced Wasserstein distance via an efficient alternating scheme with convex subproblems. Unlike classical directional-quantile approaches that typically produce only convex quantile regions and require training separate models for different directions, TQF covers all directions with a single model without imposing convexity restrictions. We evaluate TQF on synthetic and real-world datasets, and release the source code on GitHub.

</details>


### [138] [Quantitative Verification of Fairness in Tree Ensembles](https://arxiv.org/abs/2512.16386)
*Zhenjiang Zhao,Takahisa Toda,Takashi Kitamura*

Main category: cs.LG

TL;DR: 该研究提出了一种针对树集成模型的公平性定量验证方法，能够提供反例比例的上界和下界，相比传统方法仅返回单个反例，该方法能更全面地诊断和缓解偏差。


<details>
  <summary>Details</summary>
Motivation: 传统公平性验证方法仅返回单个反例，而定量验证能估计所有反例的比例并定位其发生区域，这对诊断和缓解偏差至关重要。现有定量验证方法主要针对深度神经网络，对树集成模型存在局限性。

Method: 利用树集成模型的离散结构，提出高效的量化技术，提供任意时间的上界和下界估计。该方法扩展了反例引导抽象精化框架，但克服了其仅能提供下界且性能扩展性差的限制。

Result: 在五个广泛使用的数据集上的实验证明了该方法的有效性和效率。应用于公平性测试时，该量化方法显著优于最先进的测试技术。

Conclusion: 该研究提出的树集成模型公平性定量验证方法能够高效提供反例比例的上界和下界，为偏差诊断和缓解提供了更全面的信息，在公平性测试中表现出优越性能。

Abstract: This work focuses on quantitative verification of fairness in tree ensembles. Unlike traditional verification approaches that merely return a single counterexample when the fairness is violated, quantitative verification estimates the ratio of all counterexamples and characterizes the regions where they occur, which is important information for diagnosing and mitigating bias. To date, quantitative verification has been explored almost exclusively for deep neural networks (DNNs). Representative methods, such as DeepGemini and FairQuant, all build on the core idea of Counterexample-Guided Abstraction Refinement, a generic framework that could be adapted to other model classes. We extended the framework into a model-agnostic form, but discovered two limitations: (i) it can provide only lower bounds, and (ii) its performance scales poorly. Exploiting the discrete structure of tree ensembles, our work proposes an efficient quantification technique that delivers any-time upper and lower bounds. Experiments on five widely used datasets demonstrate its effectiveness and efficiency. When applied to fairness testing, our quantification method significantly outperforms state-of-the-art testing techniques.

</details>


### [139] [Kascade: A Practical Sparse Attention Method for Long-Context LLM Inference](https://arxiv.org/abs/2512.16391)
*Dhruv Deshmukh,Saurabh Goyal,Nipun Kwatra,Ramachandran Ramjee*

Main category: cs.LG

TL;DR: Kascade是一种无需训练的稀疏注意力方法，通过选择性地在锚定层计算Top-k索引并在中间层重用这些索引，显著加速长上下文LLM推理，同时保持与密集注意力相近的准确性。


<details>
  <summary>Details</summary>
Motivation: 注意力机制是长上下文LLM推理的主要延迟来源，特别是在推理模型和RAG等日益流行的工作负载中。现有的注意力计算在长上下文场景下效率低下，需要更高效的解决方案。

Method: Kascade利用两个关键观察：1) softmax后的注意力本质上是稀疏的；2) 高权重键的身份在相邻层之间是稳定的。方法包括：在锚定层计算精确的Top-k索引，在中间重用层复用这些索引；通过动态规划算法选择锚定层以最大化跨层相似性；实现头感知的Top-k选择和重用；支持预填充和解码注意力的高效实现。

Result: 在H100 GPU上，Kascade相比FlashAttention-3基线，解码注意力速度提升最高达4.1倍，预填充注意力速度提升最高达2.2倍。在LongBench和AIME-24等长上下文基准测试中，准确性与密集注意力非常接近。

Conclusion: Kascade是一种有效的训练无关稀疏注意力方法，通过利用注意力稀疏性和跨层稳定性，在保持准确性的同时显著加速长上下文LLM推理，为实际部署提供了实用的解决方案。

Abstract: Attention is the dominant source of latency during long-context LLM inference, an increasingly popular workload with reasoning models and RAG. We propose Kascade, a training-free sparse attention method that leverages known observations such as 1) post-softmax attention is intrinsically sparse, and 2) the identity of high-weight keys is stable across nearby layers. Kascade computes exact Top-k indices in a small set of anchor layers, then reuses those indices in intermediate reuse layers. The anchor layers are selected algorithmically, via a dynamic-programming objective that maximizes cross-layer similarity over a development set, allowing easy deployment across models. The method incorporates efficient implementation constraints (e.g. tile-level operations), across both prefill and decode attention. The Top-k selection and reuse in Kascade is head-aware and we show in our experiments that this is critical for high accuracy. Kascade achieves up to 4.1x speedup in decode attention and 2.2x speedup in prefill attention over FlashAttention-3 baseline on H100 GPUs while closely matching dense attention accuracy on long-context benchmarks such as LongBench and AIME-24.

</details>


### [140] [NDRL: Cotton Irrigation and Nitrogen Application with Nested Dual-Agent Reinforcement Learning](https://arxiv.org/abs/2512.16408)
*Ruifeng Xu,Liang He*

Main category: cs.LG

TL;DR: 提出嵌套双智能体强化学习(NDRL)方法优化棉花灌溉和氮肥管理，通过父智能体宏观规划和子智能体动态调节，提高产量和资源利用效率。


<details>
  <summary>Details</summary>
Motivation: 现有研究面临两个主要问题：1) 作物生长过程中水氮组合优化复杂度高，产量优化效果差；2) 轻度胁迫信号难以量化且反馈延迟，导致水氮动态调节不精确，资源利用效率低。

Method: 提出嵌套双智能体强化学习(NDRL)方法：父智能体基于预期累积产量效益识别有前景的宏观灌溉和施肥动作，减少无效探索；子智能体的奖励函数包含量化的水分胁迫因子(WSF)和氮胁迫因子(NSF)，使用混合概率分布动态优化每日策略。使用2023和2024年田间试验数据校准和验证DSSAT系统来模拟真实条件并与NDRL交互。

Result: 与最佳基线相比，模拟产量在2023和2024年均增加4.7%，灌溉水生产率分别提高5.6%和5.1%，氮偏生产力分别提高6.3%和1.0%。

Conclusion: NDRL方法推进了棉花灌溉和氮肥管理的发展，为解决农业资源管理的复杂性和精确性问题以及可持续农业发展提供了新思路。

Abstract: Effective irrigation and nitrogen fertilization have a significant impact on crop yield. However, existing research faces two limitations: (1) the high complexity of optimizing water-nitrogen combinations during crop growth and poor yield optimization results; and (2) the difficulty in quantifying mild stress signals and the delayed feedback, which results in less precise dynamic regulation of water and nitrogen and lower resource utilization efficiency. To address these issues, we propose a Nested Dual-Agent Reinforcement Learning (NDRL) method. The parent agent in NDRL identifies promising macroscopic irrigation and fertilization actions based on projected cumulative yield benefits, reducing ineffective explorationwhile maintaining alignment between objectives and yield. The child agent's reward function incorporates quantified Water Stress Factor (WSF) and Nitrogen Stress Factor (NSF), and uses a mixed probability distribution to dynamically optimize daily strategies, thereby enhancing both yield and resource efficiency. We used field experiment data from 2023 and 2024 to calibrate and validate the Decision Support System for Agrotechnology Transfer (DSSAT) to simulate real-world conditions and interact with NDRL. Experimental results demonstrate that, compared to the best baseline, the simulated yield increased by 4.7% in both 2023 and 2024, the irrigation water productivity increased by 5.6% and 5.1% respectively, and the nitrogen partial factor productivity increased by 6.3% and 1.0% respectively. Our method advances the development of cotton irrigation and nitrogen fertilization, providing new ideas for addressing the complexity and precision issues in agricultural resource management and for sustainable agricultural development.

</details>


### [141] [Geometric Laplace Neural Operator](https://arxiv.org/abs/2512.16409)
*Hao Tang,Jiongyu Zhu,Zimeng Feng,Hao Li,Chao Li*

Main category: cs.LG

TL;DR: 提出基于极点-残差分解和指数基函数的广义算子学习框架GLNO，将拉普拉斯谱表示嵌入到拉普拉斯-贝尔特拉米算子的特征基中，扩展算子学习到任意黎曼流形，无需周期性或均匀网格。


<details>
  <summary>Details</summary>
Motivation: 现有神经算子方法在处理非周期性激励、瞬态响应以及不规则或非欧几里得几何上的信号时存在困难，需要一种能够处理这些挑战的广义算子学习框架。

Method: 基于极点-残差分解和指数基函数构建广义算子学习框架，提出几何拉普拉斯神经算子(GLNO)，将拉普拉斯谱表示嵌入到拉普拉斯-贝尔特拉米算子的特征基中，并设计网格不变网络架构GLNONet实现GLNO。

Result: 在PDEs/ODEs和真实世界数据集上的大量实验表明，该方法相比其他最先进模型具有鲁棒的性能优势。

Conclusion: 提出的GLNO框架成功扩展了算子学习到任意黎曼流形，有效解决了非周期性、衰减动态以及不规则几何上的学习问题，为复杂几何和动态系统建模提供了有力工具。

Abstract: Neural operators have emerged as powerful tools for learning mappings between function spaces, enabling efficient solutions to partial differential equations across varying inputs and domains. Despite the success, existing methods often struggle with non-periodic excitations, transient responses, and signals defined on irregular or non-Euclidean geometries. To address this, we propose a generalized operator learning framework based on a pole-residue decomposition enriched with exponential basis functions, enabling expressive modeling of aperiodic and decaying dynamics. Building on this formulation, we introduce the Geometric Laplace Neural Operator (GLNO), which embeds the Laplace spectral representation into the eigen-basis of the Laplace-Beltrami operator, extending operator learning to arbitrary Riemannian manifolds without requiring periodicity or uniform grids. We further design a grid-invariant network architecture (GLNONet) that realizes GLNO in practice. Extensive experiments on PDEs/ODEs and real-world datasets demonstrate our robust performance over other state-of-the-art models.

</details>


### [142] [Multi-Fidelity Delayed Acceptance: hierarchical MCMC sampling for Bayesian inverse problems combining multiple solvers through deep neural networks](https://arxiv.org/abs/2512.16430)
*Filippo Zacchei,Paolo Conti,Attilio Alberto Frangi,Andrea Manzoni*

Main category: cs.LG

TL;DR: 提出一种多保真度延迟接受方案用于贝叶斯反问题，通过多保真度神经网络结合不同保真度求解器，避免在线阶段的高保真模拟，提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统基于物理模型的逆不确定性量化计算成本高，特别是涉及偏微分方程时，全阶模型使得马尔可夫链蒙特卡洛采样计算不可行。数据驱动代理模型受限于高保真数据生成成本，而低保真数据虽然生成效率高但会降低反问题求解精度。

Method: 扩展多级延迟接受框架，引入多保真度神经网络，将不同保真度求解器的预测相结合。高保真评估仅限于离线训练阶段，在线阶段通过评估粗求解器并将其输出传递给训练好的神经网络来获得似然评估，避免额外的高保真模拟。

Result: 该方法提高了低保真求解器的近似精度，导致更长的子链长度、更好的混合性和加速的后验推断。在两个基准反问题上展示了显著的计算节省：(1)稳态各向同性地下水流，(2)非稳态反应-扩散系统。

Conclusion: 提出的多保真度延迟接受方案能够将异构粗求解器一致地纳入层次结构中，比标准多级延迟接受提供更大的灵活性，有效解决了贝叶斯反问题中的计算效率问题。

Abstract: Inverse uncertainty quantification (UQ) tasks such as parameter estimation are computationally demanding whenever dealing with physics-based models, and typically require repeated evaluations of complex numerical solvers. When partial differential equations are involved, full-order models such as those based on the Finite Element Method can make traditional sampling approaches like Markov Chain Monte Carlo (MCMC) computationally infeasible. Although data-driven surrogate models may help reduce evaluation costs, their utility is often limited by the expense of generating high-fidelity data. In contrast, low-fidelity data can be produced more efficiently, although relying on them alone may degrade the accuracy of the inverse UQ solution.
  To address these challenges, we propose a Multi-Fidelity Delayed Acceptance scheme for Bayesian inverse problems. Extending the Multi-Level Delayed Acceptance framework, the method introduces multi-fidelity neural networks that combine the predictions of solvers of varying fidelity, with high fidelity evaluations restricted to an offline training stage. During the online phase, likelihood evaluations are obtained by evaluating the coarse solvers and passing their outputs to the trained neural networks, thereby avoiding additional high-fidelity simulations.
  This construction allows heterogeneous coarse solvers to be incorporated consistently within the hierarchy, providing greater flexibility than standard Multi-Level Delayed Acceptance. The proposed approach improves the approximation accuracy of the low fidelity solvers, leading to longer sub-chain lengths, better mixing, and accelerated posterior inference. The effectiveness of the strategy is demonstrated on two benchmark inverse problems involving (i) steady isotropic groundwater flow, (ii) an unsteady reaction-diffusion system, for which substantial computational savings are obtained.

</details>


### [143] [Emergent Bias and Fairness in Multi-Agent Decision Systems](https://arxiv.org/abs/2512.16433)
*Maeve Madigan,Parameswaran Kamalaruban,Glenn Moynihan,Tom Kempton,David Sutton,Stuart Burrell*

Main category: cs.LG

TL;DR: 该论文提出多智能体预测系统在金融领域存在公平性风险，需要开发专门的公平性评估方法，研究发现多智能体系统可能表现出无法追溯到单个组件的集体偏见行为。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统虽然能通过协作决策提升预测性能，但缺乏有效的公平性评估方法，这在高风险的金融领域（如消费金融）尤其危险，因为偏见决策可能导致监管违规和财务损失。

Method: 通过大规模模拟实验，在不同多智能体配置（包括不同的通信和协作机制）下，使用公平性指标进行系统性评估，特别关注金融表格数据领域。

Result: 研究发现多智能体系统在金融决策中出现了无法追溯到单个智能体组件的涌现性偏见模式，表明这些系统可能表现出真正的集体行为。

Conclusion: 金融多智能体系统的公平性风险是模型风险的重要组成部分，对信用评分和收入估计等任务有实际影响。多智能体决策系统应作为整体实体进行评估，而非对其组成组件进行还原论分析。

Abstract: Multi-agent systems have demonstrated the ability to improve performance on a variety of predictive tasks by leveraging collaborative decision making. However, the lack of effective evaluation methodologies has made it difficult to estimate the risk of bias, making deployment of such systems unsafe in high stakes domains such as consumer finance, where biased decisions can translate directly into regulatory breaches and financial loss. To address this challenge, we need to develop fairness evaluation methodologies for multi-agent predictive systems and measure the fairness characteristics of these systems in the financial tabular domain. Examining fairness metrics using large-scale simulations across diverse multi-agent configurations, with varying communication and collaboration mechanisms, we reveal patterns of emergent bias in financial decision-making that cannot be traced to individual agent components, indicating that multi-agent systems may exhibit genuinely collective behaviors. Our findings highlight that fairness risks in financial multi-agent systems represent a significant component of model risk, with tangible impacts on tasks such as credit scoring and income estimation. We advocate that multi-agent decision systems must be evaluated as holistic entities rather than through reductionist analyses of their constituent components.

</details>


### [144] [A Novel Proposal in Wind Turbine Blade Failure Detection: An Integrated Approach to Energy Efficiency and Sustainability](https://arxiv.org/abs/2512.16437)
*Jordan Abarca-Albores,Danna Cristina Gutiérrez Cabrera,Luis Antonio Salazar-Licea,Dante Ruiz-Robles,Jesus Alejandro Franco,Alberto-Jesus Perea-Moreno,David Muñoz-Rodríguez,Quetzalcoatl Hernandez-Escobedo*

Main category: cs.LG

TL;DR: 本文提出了一种基于计算学习技术的风力涡轮机叶片故障检测新方法，评估了逻辑回归和聚类两种模型，发现聚类方法在精度和数据分割方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 风力涡轮机叶片故障检测对系统可靠性至关重要，需要开发有效的早期故障检测方法来提高风电系统的运行效率和安全性。

Method: 采用两种计算学习模型：1) 逻辑回归模型，与神经网络、决策树和朴素贝叶斯方法进行比较；2) 聚类模型，用于数据分割和模式识别。使用Orange Data Mining等工具实现。

Result: 逻辑回归模型在故障模式识别方面优于其他监督学习方法，而聚类模型在精度和数据分割方面表现更佳，表明聚类方法能更好地捕捉数据底层特征。

Conclusion: 提出的方法为风力涡轮机叶片早期故障检测提供了新途径，展示了不同计算学习技术集成的潜力。未来工作将结合这些方法提高检测精度，并扩展到能源基础设施的其他关键部件。

Abstract: This paper presents a novel methodology for detecting faults in wind turbine blades using com-putational learning techniques. The study evaluates two models: the first employs logistic regression, which outperformed neural networks, decision trees, and the naive Bayes method, demonstrating its effectiveness in identifying fault-related patterns. The second model leverages clustering and achieves superior performance in terms of precision and data segmentation. The results indicate that clustering may better capture the underlying data characteristics compared to supervised methods. The proposed methodology offers a new approach to early fault detection in wind turbine blades, highlighting the potential of integrating different computational learning techniques to enhance system reliability. The use of accessible tools like Orange Data Mining underscores the practical application of these advanced solutions within the wind energy sector. Future work will focus on combining these methods to improve detection accuracy further and extend the application of these techniques to other critical components in energy infrastructure.

</details>


### [145] [Topic Modelling Black Box Optimization](https://arxiv.org/abs/2512.16445)
*Roman Akramov,Artem Khamatullin,Svetlana Glazyrina,Maksim Kryzhanovskiy,Roman Ischenko*

Main category: cs.LG

TL;DR: 该研究将LDA主题模型中的主题数量T选择问题形式化为离散黑盒优化问题，比较了四种优化器在固定评估预算下的表现，发现摊销优化器在样本和时间效率上显著优于传统进化方法。


<details>
  <summary>Details</summary>
Motivation: LDA主题模型中主题数量T的选择是一个关键设计决策，它强烈影响模型的统计拟合度和可解释性。传统方法通常需要大量试错，因此需要更高效的优化方法。

Method: 将主题数量T选择问题形式化为离散黑盒优化问题，每个函数评估对应训练一个LDA模型并测量其验证困惑度。在固定评估预算下，比较四种优化器：两种手工设计的进化方法（遗传算法GA和进化策略ES），以及两种学习的摊销方法（偏好摊销黑盒优化PABBO和锐度感知黑盒优化SABBO）。

Result: 虽然GA、ES、PABBO和SABBO最终都能达到相似的困惑度范围，但摊销优化器在样本和时间效率上显著更优。SABBO通常在一次评估后就能识别出接近最优的主题数量，PABBO在几次评估内就能找到有竞争力的配置，而GA和ES需要几乎全部预算才能接近相同区域。

Conclusion: 摊销黑盒优化方法在LDA主题数量选择问题上比传统进化方法更高效，能够以更少的评估次数找到接近最优的配置，这为模型超参数优化提供了更实用的解决方案。

Abstract: Choosing the number of topics $T$ in Latent Dirichlet Allocation (LDA) is a key design decision that strongly affects both the statistical fit and interpretability of topic models. In this work, we formulate the selection of $T$ as a discrete black-box optimization problem, where each function evaluation corresponds to training an LDA model and measuring its validation perplexity. Under a fixed evaluation budget, we compare four families of optimizers: two hand-designed evolutionary methods - Genetic Algorithm (GA) and Evolution Strategy (ES) - and two learned, amortized approaches, Preferential Amortized Black-Box Optimization (PABBO) and Sharpness-Aware Black-Box Optimization (SABBO). Our experiments show that, while GA, ES, PABBO, and SABBO eventually reach a similar band of final perplexity, the amortized optimizers are substantially more sample- and time-efficient. SABBO typically identifies a near-optimal topic number after essentially a single evaluation, and PABBO finds competitive configurations within a few evaluations, whereas GA and ES require almost the full budget to approach the same region.

</details>


### [146] [IoMT-based Automated Leukemia Classification using CNN and Higher Order Singular Value](https://arxiv.org/abs/2512.16448)
*Shabnam Bagheri Marzijarani,Mohammad Zolfaghari,Hedieh Sajedi*

Main category: cs.LG

TL;DR: 本文提出了一种结合卷积神经网络(CNN)和高阶奇异值分解(HOSVD)分类器的白血病细胞识别方法，应用于医疗物联网(IoMT)结构，在ALL-IDB2数据集上达到98.88%的测试准确率。


<details>
  <summary>Details</summary>
Motivation: 急性淋巴细胞白血病(ALL)是一种致命疾病，早期诊断至关重要。传统人工检测存在人为错误风险且耗时，需要基于人工智能的自动化诊断方法来提高准确性和效率。

Method: 采用卷积神经网络(CNN)提取特征，结合新型分类器高阶奇异值分解(HOSVD)对ALL和正常细胞进行分类，并将模型部署在医疗物联网(IoMT)结构中实现实时通信。

Result: 在急性淋巴细胞白血病图像数据库(ALL-IDB2)上测试，模型平均准确率达到98.88%，能够快速准确地识别白血病细胞。

Conclusion: 提出的CNN-HOSVD框架在白血病细胞分类中表现出色，结合IoMT结构可实现实时诊断，为医疗物联网环境下的白血病早期检测提供了有效解决方案。

Abstract: The Internet of Things (IoT) is a concept by which objects find identity and can communicate with each other in a network. One of the applications of the IoT is in the field of medicine, which is called the Internet of Medical Things (IoMT). Acute Lymphocytic Leukemia (ALL) is a type of cancer categorized as a hematic disease. It usually begins in the bone marrow due to the overproduction of immature White Blood Cells (WBCs or leukocytes). Since it has a high rate of spread to other body organs, it is a fatal disease if not diagnosed and treated early. Therefore, for identifying cancerous (ALL) cells in medical diagnostic laboratories, blood, as well as bone marrow smears, are taken by pathologists. However, manual examinations face limitations due to human error risk and time-consuming procedures. So, to tackle the mentioned issues, methods based on Artificial Intelligence (AI), capable of identifying cancer from non-cancer tissue, seem vital. Deep Neural Networks (DNNs) are the most efficient machine learning (ML) methods. These techniques employ multiple layers to extract higher-level features from the raw input. In this paper, a Convolutional Neural Network (CNN) is applied along with a new type of classifier, Higher Order Singular Value Decomposition (HOSVD), to categorize ALL and normal (healthy) cells from microscopic blood images. We employed the model on IoMT structure to identify leukemia quickly and safely. With the help of this new leukemia classification framework, patients and clinicians can have real-time communication. The model was implemented on the Acute Lymphoblastic Leukemia Image Database (ALL-IDB2) and achieved an average accuracy of %98.88 in the test step.

</details>


### [147] [Batch Normalization-Free Fully Integer Quantized Neural Networks via Progressive Tandem Learning](https://arxiv.org/abs/2512.16476)
*Pengfei Sun,Wenyu Jiang,Piew Yoong Chee,Paul Devos,Dick Botteldooren*

Main category: cs.LG

TL;DR: 提出一种无需批归一化(BN)的全整数量化神经网络训练方法，通过渐进式逐层蒸馏实现整数运算推理，适用于资源受限的边缘设备。


<details>
  <summary>Details</summary>
Motivation: 现有的量化神经网络(QNNs)虽然通过低比特算术缩小模型并减少推理能耗，但大多数仍依赖批归一化(BN)层，这阻碍了真正的纯整数部署。先前尝试去除BN的方法要么通过参数折叠，要么通过定制初始化，但很少能恢复BN的稳定性和准确性，且通常需要特殊约束。

Method: 提出一种BN-free、全整数的QNN训练方法，采用渐进式逐层蒸馏方案。从预训练的带BN的教师模型开始，使用逐层目标和渐进补偿来训练学生模型，该模型完全使用整数算术进行推理，且不包含任何BN操作。

Result: 在ImageNet数据集上使用AlexNet架构，BN-free模型在激进量化下获得了有竞争力的Top-1准确率。该方法可直接集成到标准量化工作流程中。

Conclusion: 该方法实现了端到端的纯整数推理，适用于边缘和嵌入式设备等资源受限场景，解决了量化神经网络中BN依赖的问题。

Abstract: Quantised neural networks (QNNs) shrink models and reduce inference energy through low-bit arithmetic, yet most still depend on a running statistics batch normalisation (BN) layer, preventing true integer-only deployment. Prior attempts remove BN by parameter folding or tailored initialisation; while helpful, they rarely recover BN's stability and accuracy and often impose bespoke constraints. We present a BN-free, fully integer QNN trained via a progressive, layer-wise distillation scheme that slots into existing low-bit pipelines. Starting from a pretrained BN-enabled teacher, we use layer-wise targets and progressive compensation to train a student that performs inference exclusively with integer arithmetic and contains no BN operations. On ImageNet with AlexNet, the BN-free model attains competitive Top-1 accuracy under aggressive quantisation. The procedure integrates directly with standard quantisation workflows, enabling end-to-end integer-only inference for resource-constrained settings such as edge and embedded devices.

</details>


### [148] [Persistent Multiscale Density-based Clustering](https://arxiv.org/abs/2512.16558)
*Daniël Bot,Leland McInnes,Jan Aerts*

Main category: cs.LG

TL;DR: PLSCAN是一种新的基于密度的聚类算法，通过识别HDBSCAN*在所有最小聚类大小下产生的稳定（叶）聚类，无需预设密度阈值或最小聚类大小参数。


<details>
  <summary>Details</summary>
Motivation: 密度聚类算法在探索性数据分析中很有用，但实际应用需要选择超参数（如DBSCAN的密度阈值、HDBSCAN*的最小聚类大小），这在没有先验数据分布知识时很困难。

Method: PLSCAN基于尺度空间聚类原理，等价于在新度量空间上的持久同调，能高效识别HDBSCAN*在所有最小聚类大小下产生的稳定叶聚类。

Result: 在多个真实数据集上，PLSCAN比HDBSCAN*获得更高的平均ARI（调整兰德指数），对互达邻域数量的变化更不敏感；在低维数据集上计算成本与k-Means竞争，高维时与HDBSCAN*类似。

Conclusion: PLSCAN提供了一种无需预设超参数的密度聚类方法，在保持计算效率的同时提高了聚类稳定性和性能。

Abstract: Clustering is a cornerstone of modern data analysis. Detecting clusters in exploratory data analyses (EDA) requires algorithms that make few assumptions about the data. Density-based clustering algorithms are particularly well-suited for EDA because they describe high-density regions, assuming only that a density exists. Applying density-based clustering algorithms in practice, however, requires selecting appropriate hyperparameters, which is difficult without prior knowledge of the data distribution. For example, DBSCAN requires selecting a density threshold, and HDBSCAN* relies on a minimum cluster size parameter. In this work, we propose Persistent Leaves Spatial Clustering for Applications with Noise (PLSCAN). This novel density-based clustering algorithm efficiently identifies all minimum cluster sizes for which HDBSCAN* produces stable (leaf) clusters. PLSCAN applies scale-space clustering principles and is equivalent to persistent homology on a novel metric space. We compare its performance to HDBSCAN* on several real-world datasets, demonstrating that it achieves a higher average ARI and is less sensitive to changes in the number of mutual reachability neighbours. Additionally, we compare PLSCAN's computational costs to k-Means, demonstrating competitive run-times on low-dimensional datasets. At higher dimensions, run times scale more similarly to HDBSCAN*.

</details>


### [149] [Abacus: Self-Supervised Event Counting-Aligned Distributional Pretraining for Sequential User Modeling](https://arxiv.org/abs/2512.16581)
*Sullivan Castro,Artem Betlei,Thomas Di Martino,Nadir El Manouzi*

Main category: cs.LG

TL;DR: 提出Abacus方法，通过自监督预训练预测用户事件的经验频率分布，结合序列学习目标，提升展示广告中用户购买行为建模效果


<details>
  <summary>Details</summary>
Motivation: 展示广告系统中用户购买行为建模面临正样本稀疏、用户行为随机性导致的类别不平衡和事件时间不规则问题。现有方法依赖手工"计数"特征，忽略了用户意图的细粒度时间演化，而序列模型又缺少有用的事件计数统计信息。

Method: 提出Abacus方法，通过自监督预训练预测用户事件的经验频率分布。进一步提出混合目标函数，将Abacus与序列学习目标统一，结合聚合统计的稳定性和序列建模的敏感性。

Result: 在两个真实数据集上的实验表明，Abacus预训练优于现有方法，加速了下游任务收敛，混合方法相比基线AUC提升最高达+6.1%。

Conclusion: Abacus方法通过结合事件频率分布预测和序列建模，有效解决了展示广告中用户行为建模的挑战，显著提升了预测性能。

Abstract: Modeling user purchase behavior is a critical challenge in display advertising systems, necessary for real-time bidding. The difficulty arises from the sparsity of positive user events and the stochasticity of user actions, leading to severe class imbalance and irregular event timing. Predictive systems usually rely on hand-crafted "counter" features, overlooking the fine-grained temporal evolution of user intent. Meanwhile, current sequential models extract direct sequential signal, missing useful event-counting statistics. We enhance deep sequential models with self-supervised pretraining strategies for display advertising. Especially, we introduce Abacus, a novel approach of predicting the empirical frequency distribution of user events. We further propose a hybrid objective unifying Abacus with sequential learning objectives, combining stability of aggregated statistics with the sequence modeling sensitivity. Experiments on two real-world datasets show that Abacus pretraining outperforms existing methods accelerating downstream task convergence, while hybrid approach yields up to +6.1% AUC compared to the baselines.

</details>


### [150] [Stackelberg Learning from Human Feedback: Preference Optimization as a Sequential Game](https://arxiv.org/abs/2512.16626)
*Barna Pásztor,Thomas Kleine Buening,Andreas Krause*

Main category: cs.LG

TL;DR: SLHF是一种新的偏好优化框架，将对齐问题建模为领导者-跟随者之间的序贯博弈，相比RLHF和NLHF具有更好的偏好结构捕捉能力和推理时优化能力。


<details>
  <summary>Details</summary>
Motivation: 现有偏好优化方法如RLHF（基于标量奖励）和NLHF（基于同时博弈均衡）在捕捉丰富偏好结构方面存在局限，需要一种能更好处理序贯决策和推理时优化的新框架。

Method: 将对齐问题建模为领导者-跟随者序贯博弈：领导者承诺一个动作，跟随者根据领导者动作条件响应。将偏好优化分解为跟随者的精炼问题和领导者对抗对手的优化问题。

Result: 实验表明SLHF在各种偏好数据集上实现强对齐，模型规模从0.5B到8B参数可扩展，推理时精炼能力可在不同模型族间迁移而无需微调。

Conclusion: SLHF通过序贯博弈设计提供了比RLHF和NLHF更一致的偏好优化框架，在一致性、数据敏感性和处理非传递性偏好方面具有优势，支持推理时优化。

Abstract: We introduce Stackelberg Learning from Human Feedback (SLHF), a new framework for preference optimization. SLHF frames the alignment problem as a sequential-move game between two policies: a Leader, which commits to an action, and a Follower, which responds conditionally on the Leader's action. This approach decomposes preference optimization into a refinement problem for the Follower and an optimization problem against an adversary for the Leader. Unlike Reinforcement Learning from Human Feedback (RLHF), which assigns scalar rewards to actions, or Nash Learning from Human Feedback (NLHF), which seeks a simultaneous-move equilibrium, SLHF leverages the asymmetry of sequential play to capture richer preference structures. The sequential design of SLHF naturally enables inference-time refinement, as the Follower learns to improve the Leader's actions, and these refinements can be leveraged through iterative sampling. We compare the solution concepts of SLHF, RLHF, and NLHF, and lay out key advantages in consistency, data sensitivity, and robustness to intransitive preferences. Experiments on large language models demonstrate that SLHF achieves strong alignment across diverse preference datasets, scales from 0.5B to 8B parameters, and yields inference-time refinements that transfer across model families without further fine-tuning.

</details>


### [151] [Exploiting Radio Frequency Fingerprints for Device Identification: Tackling Cross-receiver Challenges in the Source-data-free Scenario](https://arxiv.org/abs/2512.16648)
*Liu Yang,Qiang Li,Luxiong Wen,Jian Yang*

Main category: cs.LG

TL;DR: 本文提出MS-SHOT方法，解决无源数据跨接收器射频指纹识别问题，通过动量中心引导的软伪标签和全局结构约束，提升目标域性能。


<details>
  <summary>Details</summary>
Motivation: 边缘计算中基于深度学习的RFFI模型在实际部署时面临关键挑战：当应用于具有不同硬件特性的接收器时，由于接收器变化引入的分布偏移，模型性能会显著下降。现有方法在目标域存在标签偏移或非均匀类别分布时表现不佳。

Method: 提出MS-SHOT方法：1) 建立约束伪标签的SCRFFI适应框架；2) 理论分析揭示目标域性能对伪标签质量敏感；3) 采用动量中心引导的软伪标签生成；4) 实施全局结构约束以鼓励自信且多样化的预测。

Result: 在真实世界数据集上的广泛实验表明，MS-SHOT在准确性和鲁棒性方面始终优于现有方法，特别是在处理目标域标签偏移或非均匀类别分布的场景中表现优异。

Conclusion: MS-SHOT为RFFI中的无源数据跨接收器适应提供了一个实用且可扩展的解决方案，有效解决了先前方法在处理标签偏移和非均匀分布时的局限性。

Abstract: With the rapid proliferation of edge computing, Radio Frequency Fingerprint Identification (RFFI) has become increasingly important for secure device authentication. However, practical deployment of deep learning-based RFFI models is hindered by a critical challenge: their performance often degrades significantly when applied across receivers with different hardware characteristics due to distribution shifts introduced by receiver variation. To address this, we investigate the source-data-free cross-receiver RFFI (SCRFFI) problem, where a model pretrained on labeled signals from a source receiver must adapt to unlabeled signals from a target receiver, without access to any source-domain data during adaptation. We first formulate a novel constrained pseudo-labeling-based SCRFFI adaptation framework, and provide a theoretical analysis of its generalization performance. Our analysis highlights a key insight: the target-domain performance is highly sensitive to the quality of the pseudo-labels generated during adaptation. Motivated by this, we propose Momentum Soft pseudo-label Source Hypothesis Transfer (MS-SHOT), a new method for SCRFFI that incorporates momentum-center-guided soft pseudo-labeling and enforces global structural constraints to encourage confident and diverse predictions. Notably, MS-SHOT effectively addresses scenarios involving label shift or unknown, non-uniform class distributions in the target domain -- a significant limitation of prior methods. Extensive experiments on real-world datasets demonstrate that MS-SHOT consistently outperforms existing approaches in both accuracy and robustness, offering a practical and scalable solution for source-data-free cross-receiver adaptation in RFFI.

</details>


### [152] [DataFlow: An LLM-Driven Framework for Unified Data Preparation and Workflow Automation in the Era of Data-Centric AI](https://arxiv.org/abs/2512.16676)
*Hao Liang,Xiaochen Ma,Zhou Liu,Zhen Hao Wong,Zhengyang Zhao,Zimo Meng,Runming He,Chengyu Shen,Qifeng Cai,Zhaoyang Han,Meiyi Qiang,Yalin Feng,Tianyi Bai,Zewei Pan,Ziyi Guo,Yizhen Jiang,Jingwen Deng,Qijie You,Peichao Lai,Tianyu Guo,Chi Hsu Tsai,Hengyi Feng,Rui Hu,Wenkai Yu,Junbo Niu,Bohan Zeng,Ruichuan An,Lu Ma,Jihao Huang,Yaowei Zheng,Conghui He,Linpeng Tang,Bin Cui,Weinan E,Wentao Zhang*

Main category: cs.LG

TL;DR: DataFlow是一个统一的LLM驱动数据准备框架，提供模块化、可组合的数据转换抽象和PyTorch风格API，包含近200个可复用操作符和6个领域通用管道，通过DataFlow-Agent实现自然语言到可执行管道的自动转换，在多个基准测试中显著提升LLM性能。


<details>
  <summary>Details</summary>
Motivation: 当前LLM高质量数据需求快速增长，但现有数据准备实践主要依赖临时脚本和松散的工作流程，缺乏原则性抽象、可复现性差，且对模型在环数据生成支持有限。

Method: 提出DataFlow框架，包含系统级抽象实现模块化、可复用、可组合的数据转换；提供PyTorch风格管道构建API；包含近200个可复用操作符和6个领域通用管道；引入DataFlow-Agent通过操作符合成、管道规划和迭代验证自动将自然语言规范转换为可执行管道。

Result: 在六个代表性用例中，DataFlow持续提升下游LLM性能：数学、代码和文本管道优于人工策划数据集和专用合成基线，在Text-to-SQL上比SynSQL提升+3%执行准确率，代码基准平均提升+7%，MATH、GSM8K和AIME提升1-3个百分点；统一10K样本数据集使基础模型超越使用1M Infinity-Instruct数据训练的对应模型。

Conclusion: DataFlow为可靠、可复现、可扩展的LLM数据准备提供了实用高性能基础，并为未来以数据为中心的AI发展建立了系统级基础。

Abstract: The rapidly growing demand for high-quality data in Large Language Models (LLMs) has intensified the need for scalable, reliable, and semantically rich data preparation pipelines. However, current practices remain dominated by ad-hoc scripts and loosely specified workflows, which lack principled abstractions, hinder reproducibility, and offer limited support for model-in-the-loop data generation. To address these challenges, we present DataFlow, a unified and extensible LLM-driven data preparation framework. DataFlow is designed with system-level abstractions that enable modular, reusable, and composable data transformations, and provides a PyTorch-style pipeline construction API for building debuggable and optimizable dataflows. The framework consists of nearly 200 reusable operators and six domain-general pipelines spanning text, mathematical reasoning, code, Text-to-SQL, agentic RAG, and large-scale knowledge extraction. To further improve usability, we introduce DataFlow-Agent, which automatically translates natural-language specifications into executable pipelines via operator synthesis, pipeline planning, and iterative verification. Across six representative use cases, DataFlow consistently improves downstream LLM performance. Our math, code, and text pipelines outperform curated human datasets and specialized synthetic baselines, achieving up to +3\% execution accuracy in Text-to-SQL over SynSQL, +7\% average improvements on code benchmarks, and 1--3 point gains on MATH, GSM8K, and AIME. Moreover, a unified 10K-sample dataset produced by DataFlow enables base models to surpass counterparts trained on 1M Infinity-Instruct data. These results demonstrate that DataFlow provides a practical and high-performance substrate for reliable, reproducible, and scalable LLM data preparation, and establishes a system-level foundation for future data-centric AI development.

</details>


### [153] [Blog Data Showdown: Machine Learning vs Neuro-Symbolic Models for Gender Classification](https://arxiv.org/abs/2512.16687)
*Natnael Tilahun Sinshaw,Mengmei He,Tadesse K. Bahiru,Sudhir Kumar Mohapatra*

Main category: cs.LG

TL;DR: 该研究比较了多种机器学习算法（SVM、NB、LR、AdaBoost、XGBoost）和神经符号AI在文本分类任务上的性能，并探索了不同文本表示和特征提取技术的影响。


<details>
  <summary>Details</summary>
Motivation: 文本分类（如博客性别分类）是成熟的研究领域，在市场营销、客户推荐等领域有广泛应用。本研究旨在比较传统机器学习算法与新兴的神经符号AI方法在文本分类任务上的性能差异。

Method: 采用比较分析方法，评估了SVM、朴素贝叶斯、逻辑回归、AdaBoost、XGBoost等机器学习算法以及SVM变体与神经符号AI的结合。探索了TF-IDF、通用句子编码器、RoBERTa等文本表示方法，以及卡方检验、互信息、主成分分析等特征提取技术。

Result: 实验结果表明，神经符号AI方法在有限数据集上能够匹配多层感知机的性能表现，显示出其在文本分类任务中的潜力。

Conclusion: 神经符号AI在文本分类任务中表现出竞争力，未来研究将扩展知识库、嵌入类型范围和超参数配置，以进一步研究该方法的有效性。

Abstract: Text classification problems, such as gender classification from a blog, have been a well-matured research area that has been well studied using machine learning algorithms. It has several application domains in market analysis, customer recommendation, and recommendation systems. This study presents a comparative analysis of the widely used machine learning algorithms, namely Support Vector Machines (SVM), Naive Bayes (NB), Logistic Regression (LR), AdaBoost, XGBoost, and an SVM variant (SVM_R) with neuro-symbolic AI (NeSy). The paper also explores the effect of text representations such as TF-IDF, the Universal Sentence Encoder (USE), and RoBERTa. Additionally, various feature extraction techniques, including Chi-Square, Mutual Information, and Principal Component Analysis, are explored. Building on these, we introduce a comparative analysis of the machine learning and deep learning approaches in comparison to the NeSy. The experimental results show that the use of the NeSy approach matched strong MLP results despite a limited dataset. Future work on this research will expand the knowledge base, the scope of embedding types, and the hyperparameter configuration to further study the effectiveness of the NeSy approach.

</details>


### [154] [CLARiTy: A Vision Transformer for Multi-Label Classification and Weakly-Supervised Localization of Chest X-ray Pathologies](https://arxiv.org/abs/2512.16700)
*John M. Statheros,Hairong Wang,Richard Klein*

Main category: cs.LG

TL;DR: CLARiTy是一个基于视觉Transformer的模型，用于胸部X光片的多标签病理分类和弱监督定位，通过类特定token和SegmentCAM模块实现，在NIH ChestX-ray14数据集上取得了竞争性的分类性能和最先进的弱监督定位性能。


<details>
  <summary>Details</summary>
Motivation: 胸部X光片解释面临多标签病理分类和空间定位的挑战，通常受限于区域级（密集）标注的稀缺性。需要一种能够同时处理不同标注粒度任务的模型。

Method: CLARiTy采用视觉Transformer架构，使用多个类特定token生成判别性注意力图，结合SegmentCAM模块进行前景分割和背景抑制（利用解剖先验知识）。模型使用图像级标签在NIH ChestX-ray14数据集上训练，并通过ConvNeXtV2教师模型进行蒸馏以提高效率。

Result: 在NIH官方划分上，CLARiTy-S-16-512在14种病理分类上取得竞争性性能，在8种病理的弱监督定位上达到最先进水平，比先前方法提升50.7%。特别是对于结节和肿块等小病理有显著提升。低分辨率变体CLARiTy-S-16-224在保持高效率的同时明显超越基线。

Conclusion: CLARiTy超越了CNN-ViT混合模型，通过利用ViT自注意力获取全局上下文和类特定定位，并通过卷积背景抑制进行精炼，生成精确、降噪的热力图。该模型在低资源环境下具有应用潜力。

Abstract: The interpretation of chest X-rays (CXRs) poses significant challenges, particularly in achieving accurate multi-label pathology classification and spatial localization. These tasks demand different levels of annotation granularity but are frequently constrained by the scarcity of region-level (dense) annotations. We introduce CLARiTy (Class Localizing and Attention Refining Image Transformer), a vision transformer-based model for joint multi-label classification and weakly-supervised localization of thoracic pathologies. CLARiTy employs multiple class-specific tokens to generate discriminative attention maps, and a SegmentCAM module for foreground segmentation and background suppression using explicit anatomical priors. Trained on image-level labels from the NIH ChestX-ray14 dataset, it leverages distillation from a ConvNeXtV2 teacher for efficiency. Evaluated on the official NIH split, the CLARiTy-S-16-512 (a configuration of CLARiTy), achieves competitive classification performance across 14 pathologies, and state-of-the-art weakly-supervised localization performance on 8 pathologies, outperforming prior methods by 50.7%. In particular, pronounced gains occur for small pathologies like nodules and masses. The lower-resolution variant of CLARiTy, CLARiTy-S-16-224, offers high efficiency while decisively surpassing baselines, thereby having the potential for use in low-resource settings. An ablation study confirms contributions of SegmentCAM, DINO pretraining, orthogonal class token loss, and attention pooling. CLARiTy advances beyond CNN-ViT hybrids by harnessing ViT self-attention for global context and class-specific localization, refined through convolutional background suppression for precise, noise-reduced heatmaps.

</details>


### [155] [Towards Reproducibility in Predictive Process Mining: SPICE - A Deep Learning Library](https://arxiv.org/abs/2512.16715)
*Oliver Stritzel,Nick Hühnerbein,Simon Rauch,Itzel Zarate,Lukas Fleischmann,Moike Buck,Attila Lischka,Christian Frey*

Main category: cs.LG

TL;DR: SPICE是一个Python框架，重新实现了三种流行的预测过程挖掘深度学习方法，提供可配置的基础框架，支持可重复和稳健的模型比较。


<details>
  <summary>Details</summary>
Motivation: 现有的预测过程挖掘方法缺乏可重复性、决策透明度、对新数据集的适应性以及基准测试能力，使得不同实现之间的比较非常困难。

Method: 在PyTorch中重新实现三种流行的基线深度学习方法，设计具有严格可配置性的通用基础框架，支持可重复和稳健的比较。

Result: 在11个数据集上比较SPICE与原始报告指标，并使用公平指标进行评估。

Conclusion: SPICE框架解决了预测过程挖掘领域的可重复性和比较性问题，为过去和未来的建模方法提供了标准化的评估平台。

Abstract: In recent years, Predictive Process Mining (PPM) techniques based on artificial neural networks have evolved as a method for monitoring the future behavior of unfolding business processes and predicting Key Performance Indicators (KPIs). However, many PPM approaches often lack reproducibility, transparency in decision making, usability for incorporating novel datasets and benchmarking, making comparisons among different implementations very difficult. In this paper, we propose SPICE, a Python framework that reimplements three popular, existing baseline deep-learning-based methods for PPM in PyTorch, while designing a common base framework with rigorous configurability to enable reproducible and robust comparison of past and future modelling approaches. We compare SPICE to original reported metrics and with fair metrics on 11 datasets.

</details>


### [156] [Phishing Detection System: An Ensemble Approach Using Character-Level CNN and Feature Engineering](https://arxiv.org/abs/2512.16717)
*Rudra Dubey,Arpit Mani Tripathi,Archit Srivastava,Sarvpal Singh*

Main category: cs.LG

TL;DR: 本文提出了一种结合字符级CNN和LightGBM的集成AI模型，用于钓鱼网站URL检测，在测试集上达到99.819%的准确率，并通过FastAPI提供实时检测服务。


<details>
  <summary>Details</summary>
Motivation: 钓鱼攻击是当前最普遍的网络安全威胁之一，恶意行为者不断改变策略欺骗用户，需要更有效的检测方法。

Method: 采用集成方法结合字符级卷积神经网络（CNN）和LightGBM：1）从URL中提取36个词汇、结构和基于域名的特征；2）使用字符级CNN提取序列特征；3）将两种模型集成（LightGBM贡献40%，字符CNN贡献60%）。

Result: 在19,873个URL的测试集上，集成模型达到：准确率99.819%、精确率100%、召回率99.635%、ROC-AUC 99.947%，保持极低的误报率，能有效识别现代钓鱼技术。

Conclusion: 提出的集成方法优于单一模型，通过FastAPI服务提供实时检测，在保持低误报率的同时有效应对不断演变的钓鱼攻击。

Abstract: In actuality, phishing attacks remain one of the most prevalent cybersecurity risks in existence today, with malevolent actors constantly changing their strategies to successfully trick users. This paper presents an AI model for a phishing detection system that uses an ensemble approach to combine character-level Convolutional Neural Networks (CNN) and LightGBM with engineered features. Our system uses a character-level CNN to extract sequential features after extracting 36 lexical, structural, and domain-based features from the URLs. On a test dataset of 19,873 URLs, the ensemble model achieves an accuracy of 99.819 percent, precision of 100 percent, recall of 99.635 percent, and ROC-AUC of 99.947 percent. Through a FastAPI-based service with an intuitive user interface, the suggested system has been utilised to offer real-time detection. In contrast, the results demonstrate that the suggested solution performs better than individual models; LightGBM contributes 40 percent and character-CNN contributes 60 percent to the final prediction. The suggested method maintains extremely low false positive rates while doing a good job of identifying contemporary phishing techniques. Index Terms - Phishing detection, machine learning, deep learning, CNN, ensemble methods, cybersecurity, URL analysis

</details>


### [157] [Polyharmonic Spline Packages: Composition, Efficient Procedures for Computation and Differentiation](https://arxiv.org/abs/2512.16718)
*Yuriy N. Bakhvalov*

Main category: cs.LG

TL;DR: 提出级联架构解决高维空间中多调和样条回归的计算复杂度和理论假设失效问题


<details>
  <summary>Details</summary>
Motivation: 先前研究表明机器学习回归问题可在随机函数理论框架下解决，最优核函数为多调和样条，但直接应用面临O(N^3)计算复杂度和高维输入空间下理论假设失效的限制

Method: 提出由多调和样条包构建的级联架构，同时解决可扩展性问题，并为具有未知内在低维性的问题提供理论依据；提出前向计算和端到端级联微分的高效矩阵程序

Result: 级联架构理论上适用于具有未知内在低维性的问题，并提供了可扩展的解决方案

Conclusion: 提出的级联多调和样条架构有效解决了先前方法的计算复杂度和高维理论限制问题，为实际应用提供了可行的解决方案

Abstract: In a previous paper it was shown that a machine learning regression problem can be solved within the framework of random function theory, with the optimal kernel analytically derived from symmetry and indifference principles and coinciding with a polyharmonic spline. However, a direct application of that solution is limited by O(N^3) computational cost and by a breakdown of the original theoretical assumptions when the input space has excessive dimensionality. This paper proposes a cascade architecture built from packages of polyharmonic splines that simultaneously addresses scalability and is theoretically justified for problems with unknown intrinsic low dimensionality. Efficient matrix procedures are presented for forward computation and end-to-end differentiation through the cascade.

</details>


### [158] [KOSS: Kalman-Optimal Selective State Spaces for Long-Term Sequence Modeling](https://arxiv.org/abs/2512.16723)
*Lei Wang,Xin Tan,Mingwei Wang,Ying Zhang*

Main category: cs.LG

TL;DR: KOSS提出了一种基于卡尔曼最优选择的状态空间模型，通过不确定性最小化实现上下文感知的选择机制，在多个任务上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有选择性状态空间模型（如Mamba、Mamba-2）的选择机制缺乏理论依据，且无法支持基于潜在状态动态的上下文感知选择。

Method: KOSS将选择机制建模为潜在状态不确定性最小化问题，采用卡尔曼增益动态调节信息传播，使用全局谱微分进行频域导数估计，并采用分段扫描实现硬件高效处理。

Result: 在选择性复制任务中，KOSS达到79%以上准确率，而基线方法低于20%；在9个长期预测基准测试中，MSE降低2.92-36.23%；在二次监视雷达跟踪案例中表现出鲁棒性。

Conclusion: KOSS通过理论驱动的闭环上下文感知选择机制，在序列建模任务中实现了显著性能提升，为选择性状态空间模型提供了理论支撑。

Abstract: Recent selective state space models (SSMs), such as Mamba and Mamba-2, have demonstrated strong performance in sequence modeling owing to input-dependent selection mechanisms. However, these mechanisms lack theoretical grounding and cannot support context-aware selection from latent state dynamics. To address these limitations, we propose KOSS, a Kalman-optimal Selective State Space model that formulates selection as latent state uncertainty minimization. Derived from estimation theory, KOSS adopts a continuous-time latent update driven by a Kalman gain that dynamically modulates information propagation based on content and context, enabling a closed-loop, context-aware selectivity mechanism. To ensure stable computation and near-linear scalability, KOSS employs global spectral differentiation for frequency-domain derivative estimation, along with a segment-wise scan for hardware-efficient processing. On a selective copying task with distractors, KOSS achieves over 79\% accuracy while baselines drop below 20\%, demonstrating robust context-aware selection. Furthermore, across nine long-term forecasting benchmarks, KOSS reduces MSE by 2.92--36.23\% and consistently outperforms state-of-the-art models in both accuracy and stability. To assess real-world applicability, a case study on secondary surveillance radar (SSR) tracking confirms KOSS's robustness under irregular intervals and noisy conditions and demonstrates its effectiveness in real-world applications. Finally, supplementary experiments verify Kalman gain convergence and the frequency response of spectral differentiation, providing theoretical support for the proposed closed-loop design.

</details>


### [159] [Machine Learning Algorithms: Detection Official Hajj and Umrah Travel Agency Based on Text and Metadata Analysis](https://arxiv.org/abs/2512.16742)
*Wisnu Uriawan,Muhamad Veva Ramadhan,Firman Adi Nugraha,Hasbi Nur Wahid,M Dantha Arianvasya,Muhammad Zaki Alghifari*

Main category: cs.LG

TL;DR: 该研究针对印尼朝觐服务数字化中的虚假应用欺诈问题，通过机器学习算法自动验证应用真实性，SVM算法表现最佳，准确率达92.3%。


<details>
  <summary>Details</summary>
Motivation: 印尼朝觐和副朝服务的快速数字化虽然便利了朝觐者，但也为通过假冒移动应用进行的数字欺诈开辟了途径。这些欺诈应用不仅造成经济损失，还通过收集敏感个人数据带来严重的隐私风险。

Method: 使用包含官方注册应用和非官方应用的综合数据集，比较三种分类器（SVM、随机森林、朴素贝叶斯）的性能。采用混合特征提取方法，结合应用描述的文本分析（TF-IDF）和敏感访问权限的元数据分析。

Result: SVM算法表现最佳，准确率92.3%，精确率91.5%，F1分数92.0%。特征分析显示，与合法性相关的特定关键词和高风险权限（如读取手机状态）是最重要的区分特征。

Conclusion: 该系统被提议作为一种主动、可扩展的解决方案，以增强宗教旅游领域的数字信任，可能作为国家验证系统的原型。

Abstract: The rapid digitalization of Hajj and Umrah services in Indonesia has significantly facilitated pilgrims but has concurrently opened avenues for digital fraud through counterfeit mobile applications. These fraudulent applications not only inflict financial losses but also pose severe privacy risks by harvesting sensitive personal data. This research aims to address this critical issue by implementing and evaluating machine learning algorithms to verify application authenticity automatically. Using a comprehensive dataset comprising both official applications registered with the Ministry of Religious Affairs and unofficial applications circulating on app stores, we compare the performance of three robust classifiers: Support Vector Machine (SVM), Random Forest (RF), and Na"ive Bayes (NB). The study utilizes a hybrid feature extraction methodology that combines Textual Analysis (TF-IDF) of application descriptions with Metadata Analysis of sensitive access permissions. The experimental results indicate that the SVM algorithm achieves the highest performance with an accuracy of 92.3%, a precision of 91.5%, and an F1-score of 92.0%. Detailed feature analysis reveals that specific keywords related to legality and high-risk permissions (e.g., READ PHONE STATE) are the most significant discriminators. This system is proposed as a proactive, scalable solution to enhance digital trust in the religious tourism sector, potentially serving as a prototype for a national verification system.

</details>


### [160] [NRGPT: An Energy-based Alternative for GPT](https://arxiv.org/abs/2512.16762)
*Nima Dehmamy,Benjamin Hoover,Bishwajit Saha,Leo Kozachkov,Jean-Jacques Slotine,Dmitry Krotov*

Main category: cs.LG

TL;DR: 该论文提出了一种将GPT架构与能量基模型框架统一的最小修改方法，称为eNeRgy-GPT（NRGPT），将推理过程概念化为在能量景观上的探索。


<details>
  <summary>Details</summary>
Motivation: GPT架构是目前最流行的语言建模设计，而能量基模型（EBM）将推理视为在能量景观上的动态过程。作者希望将这两种范式统一起来，结合两者的优势。

Method: 对GPT设置进行最小修改，提出eNeRgy-GPT（NRGPT）模型，将推理步骤概念化为在能量景观上对token的探索。在某些情况下，这种探索会变成梯度下降。

Result: 模型在简单语言（莎士比亚数据集）、代数ListOPS任务和更丰富的OpenWebText语言建模中表现良好。模型对过拟合更具抵抗力，仅在非常长的训练后才会出现过拟合。

Conclusion: 成功将GPT与EBM框架统一，提出的NRGPT模型在不同复杂度任务中表现良好，且具有更好的抗过拟合特性，为语言建模提供了新的视角。

Abstract: Generative Pre-trained Transformer (GPT) architectures are the most popular design for language modeling. Energy-based modeling is a different paradigm that views inference as a dynamical process operating on an energy landscape. We propose a minimal modification of the GPT setting to unify it with the EBM framework. The inference step of our model, which we call eNeRgy-GPT (NRGPT), is conceptualized as an exploration of the tokens on the energy landscape. We prove, and verify empirically, that under certain circumstances this exploration becomes gradient descent, although they don't necessarily lead to the best performing models. We demonstrate that our model performs well for simple language (Shakespeare dataset), algebraic ListOPS tasks, and richer settings such as OpenWebText language modeling. We also observe that our models may be more resistant to overfitting, doing so only during very long training.

</details>


### [161] [Pattern recognition in complex systems via vector-field representations of spatio-temporal data](https://arxiv.org/abs/2512.16763)
*Ingrid Amaranta Membrillo Solis,Maria van Rossem,Tristan Madeleine,Tetiana Orlova,Nina Podoliak,Giampaolo D'Alessandro,Jacek Brodzki,Malgosia Kaczmarek*

Main category: cs.LG

TL;DR: 本文提出了一种基于离散测度空间上向量场理论的几何框架，用于分析复杂系统的时空数据，引入了一个适用于数据分析和机器学习的两参数度量族，能有效解决维度约简、模态分解、相空间重构等关键分析挑战。


<details>
  <summary>Details</summary>
Motivation: 复杂系统（如人脑、生态系统、经济等）具有高维非线性动力学特性，传统建模方法面临挑战。虽然信息技术进步使得数据驱动方法成为可能，但时空数据的巨大规模和复杂性阻碍了传统维度约简、相空间重构和吸引子表征等方法的有效性。

Method: 提出基于离散测度空间上向量场理论的几何框架，引入两参数度量族，适用于时间相关图像、图像梯度以及图和单纯复形上定义的实值或向量值函数。使用多维尺度分析结合提出的度量进行验证。

Result: 在平面和弯曲域上的生物和物理系统数值模拟数据验证表明，所提出的度量结合多维尺度分析能有效解决维度约简、模态分解、相空间重构和吸引子表征等关键分析挑战。

Conclusion: 该框架为理解复杂动力系统提供了稳健途径，特别适用于传统建模不切实际但实验数据丰富的场景，为复杂系统分析提供了新的几何工具。

Abstract: A complex system comprises multiple interacting entities whose interdependencies form a unified whole, exhibiting emergent behaviours not present in individual components. Examples include the human brain, living cells, soft matter, Earth's climate, ecosystems, and the economy. These systems exhibit high-dimensional, non-linear dynamics, making their modelling, classification, and prediction particularly challenging. Advances in information technology have enabled data-driven approaches to studying such systems. However, the sheer volume and complexity of spatio-temporal data often hinder traditional methods like dimensionality reduction, phase-space reconstruction, and attractor characterisation. This paper introduces a geometric framework for analysing spatio-temporal data from complex systems, grounded in the theory of vector fields over discrete measure spaces. We propose a two-parameter family of metrics suitable for data analysis and machine learning applications. The framework supports time-dependent images, image gradients, and real- or vector-valued functions defined on graphs and simplicial complexes. We validate our approach using data from numerical simulations of biological and physical systems on flat and curved domains. Our results show that the proposed metrics, combined with multidimensional scaling, effectively address key analytical challenges. They enable dimensionality reduction, mode decomposition, phase-space reconstruction, and attractor characterisation. Our findings offer a robust pathway for understanding complex dynamical systems, especially in contexts where traditional modelling is impractical but abundant experimental data are available.

</details>


### [162] [MEPIC: Memory Efficient Position Independent Caching for LLM Serving](https://arxiv.org/abs/2512.16822)
*Qian Wang,Zahra Yousefijamarani,Morgan Lindsay Heisler,Rongzhi Gu,Bai Xiaolong,Shan Yizhou,Wei Zhang,Wang Lan,Ying Xiong,Yong Zhang,Zhenan Fan*

Main category: cs.LG

TL;DR: MEPIC是一种内存高效的KV缓存系统，通过分块对齐、块级重计算和RoPE融合技术，实现跨位置、跨请求的KV缓存重用，显著减少HBM内存使用。


<details>
  <summary>Details</summary>
Motivation: 现代LLM应用（如深度研究助手、代码代理和RAG系统）需要反复处理包含共享文档或代码块的长提示历史，这给KV缓存带来巨大压力。现有前缀缓存和位置无关缓存（PIC）方法存在限制：前缀缓存需要严格前缀匹配，PIC虽然支持任意位置重用但需要选择性重计算和位置编码调整，导致相同块的KV在不同请求中发散，内存布局不统一，HBM节省有限。

Method: MEPIC采用四种关键技术：1）将块KV对齐到分页存储；2）将重计算从token级转移到block级，使只有第一个block是请求特定的；3）通过注意力内核中的RoPE融合移除位置编码；4）使剩余block完全可共享。这些技术消除了HBM中的大部分重复块KV。

Result: MEPIC在保持可比延迟和准确性的情况下，相比最先进的PIC方法，将HBM使用减少高达2倍；对于长提示，减少高达5倍，且无需修改模型。

Conclusion: MEPIC通过创新的内存对齐、块级重计算和RoPE融合技术，实现了跨位置、跨请求和跨批次的块KV重用，显著提升了KV缓存的内存效率，为处理长提示的LLM应用提供了有效的解决方案。

Abstract: Modern LLM applications such as deep-research assistants, coding agents, and Retrieval-Augmented Generation (RAG) systems, repeatedly process long prompt histories containing shared document or code chunks, creating significant pressure on the Key Value (KV) cache, which must operate within limited memory while sustaining high throughput and low latency. Prefix caching partially alleviates some of these costs by reusing KV cache for previously processed tokens, but limited by strict prefix matching. Position-independent caching (PIC) enables chunk-level reuse at arbitrary positions, but requires selective recomputation and positional-encoding (PE) adjustments. However, because these operations vary across queries, KV for the same chunk diverges across requests. Moreover, without page alignment, chunk KV layouts diverge in memory, preventing page sharing. These issues result in only modest HBM savings even when many requests reuse the same content.
  We present MEPIC, a memory-efficient PIC system that enables chunk KV reuse across positions, requests, and batches. MEPIC aligns chunk KV to paged storage, shifts recomputation from token- to block-level so only the first block is request-specific, removes positional encodings via Rotary Position Embedding (RoPE) fusion in the attention kernel, and makes remaining blocks fully shareable. These techniques eliminate most duplicate chunk KV in HBM, reducing usage by up to 2x over state-of-the-art PIC at comparable latency and accuracy, and up to 5x for long prompts, without any model changes.

</details>


### [163] [Tiny Recursive Control: Iterative Reasoning for Efficient Optimal Control](https://arxiv.org/abs/2512.16824)
*Amit Jain,Richard Linares*

Main category: cs.LG

TL;DR: TRC是一种基于递归迭代的神经控制架构，通过深度迭代而非参数数量来提升容量，在嵌入式航空航天系统中实现高效控制。


<details>
  <summary>Details</summary>
Motivation: 神经网络控制器参数数量激增（百万到数十亿），而嵌入式航空航天系统有严格的功耗和延迟限制，传统缩放方式不可行。

Method: TRC采用紧凑网络（约150万参数）通过两级分层潜在结构进行递归迭代，通过模拟轨迹和基于跟踪误差修正来细化控制序列，相同权重处理每个细化步骤。

Result: 在非线性控制问题（振荡器稳定和燃料约束的动力下降）上，TRC实现接近最优的控制成本，GPU上毫秒级推理，内存小于10MB，比语言模型基线小两个数量级。

Conclusion: 递归推理方法从离散任务成功转移到连续控制合成，证明通过迭代深度而非参数数量可以构建高效的嵌入式控制架构。

Abstract: Neural network controllers increasingly demand millions of parameters, and language model approaches push into the billions. For embedded aerospace systems with strict power and latency constraints, this scaling is prohibitive. We present Tiny Recursive Control (TRC), a neural architecture based on a counterintuitive principle: capacity can emerge from iteration depth rather than parameter count. TRC applies compact networks (approximately 1.5M parameters) repeatedly through a two-level hierarchical latent structure, refining control sequences by simulating trajectories and correcting based on tracking error. Because the same weights process every refinement step, adding iterations increases computation without increasing memory. We evaluate TRC on nonlinear control problems including oscillator stabilization and powered descent with fuel constraints. Across these domains, TRC achieves near-optimal control costs while requiring only millisecond-scale inference on GPU and under 10~MB memory, two orders of magnitude smaller than language model baselines. These results demonstrate that recursive reasoning, previously confined to discrete tasks, transfers effectively to continuous control synthesis.

</details>


### [164] [Meta-RL Induces Exploration in Language Agents](https://arxiv.org/abs/2512.16848)
*Yulun Jiang,Liangze Jiang,Damien Teney,Michael Moor,Maria Brbic*

Main category: cs.LG

TL;DR: LaMer是一个元强化学习框架，让LLM智能体在测试时主动探索环境并从反馈中学习，显著提升多步长时程任务的性能。


<details>
  <summary>Details</summary>
Motivation: 传统RL训练的LLM智能体在需要主动探索的任务中表现不佳，难以从试错经验中高效适应。需要一种方法让智能体在测试时主动探索并学习环境反馈。

Method: LaMer包含两个关键组件：1)跨回合训练框架，鼓励探索和长期奖励优化；2)通过反思进行上下文策略适应，让智能体无需梯度更新就能从任务反馈信号中调整策略。

Result: 在多样化环境中，LaMer显著优于RL基线方法，在Sokoban、MineSweeper和Webshop上分别获得11%、14%和19%的性能提升。在更具挑战性或未见任务上也表现出更好的泛化能力。

Conclusion: 元强化学习为语言智能体提供了诱导探索的原则性方法，通过学习探索策略实现对新颖环境更鲁棒的适应。

Abstract: Reinforcement learning (RL) has enabled the training of large language model (LLM) agents to interact with the environment and to solve multi-turn long-horizon tasks. However, the RL-trained agents often struggle in tasks that require active exploration and fail to efficiently adapt from trial-and-error experiences. In this paper, we present LaMer, a general Meta-RL framework that enables LLM agents to actively explore and learn from the environment feedback at test time. LaMer consists of two key components: (i) a cross-episode training framework to encourage exploration and long-term rewards optimization; and (ii) in-context policy adaptation via reflection, allowing the agent to adapt their policy from task feedback signal without gradient update. Experiments across diverse environments show that LaMer significantly improves performance over RL baselines, with 11%, 14%, and 19% performance gains on Sokoban, MineSweeper and Webshop, respectively. Moreover, LaMer also demonstrates better generalization to more challenging or previously unseen tasks compared to the RL-trained agents. Overall, our results demonstrate that Meta-RL provides a principled approach to induce exploration in language agents, enabling more robust adaptation to novel environments through learned exploration strategies.

</details>


### [165] [Semi-Supervised Online Learning on the Edge by Transforming Knowledge from Teacher Models](https://arxiv.org/abs/2512.16866)
*Jiabin Xue*

Main category: cs.LG

TL;DR: 论文提出知识转换(KT)方法，结合知识蒸馏、主动学习和因果推理，为在线边缘机器学习中未见数据生成伪标签，解决标签获取难题。


<details>
  <summary>Details</summary>
Motivation: 在线边缘机器学习需要持续更新模型以适应新数据，但面临为未来未见数据确定标签的挑战。传统静态模型无法处理未见数据，而在线学习需要有效的标签获取机制。

Method: 提出知识转换(KT)方法，将知识蒸馏、主动学习和因果推理相结合。KT作为主动学习中的"预言机"，从教师模型转换知识，为学生模型生成伪标签进行训练。

Result: 仿真实验表明，当提供稳定的教师模型时，学生模型最终能达到预期最大性能。KT在教师任务通用且学生任务标签难以获取的场景中具有潜在优势。

Conclusion: KT方法为解决在线边缘机器学习中未见数据的标签问题提供了有效方案，特别适用于教师模型任务通用且学生任务标签获取困难的场景。

Abstract: Edge machine learning (Edge ML) enables training ML models using the vast data distributed across network edges. However, many existing approaches assume static models trained centrally and then deployed, making them ineffective against unseen data. To address this, Online Edge ML allows models to be trained directly on edge devices and updated continuously with new data. This paper explores a key challenge of Online Edge ML: "How to determine labels for truly future, unseen data points". We propose Knowledge Transformation (KT), a hybrid method combining Knowledge Distillation, Active Learning, and causal reasoning. In short, KT acts as the oracle in active learning by transforming knowledge from a teacher model to generate pseudo-labels for training a student model. To verify the validity of the method, we conducted simulation experiments with two setups: (1) using a less stable teacher model and (2) a relatively more stable teacher model. Results indicate that when a stable teacher model is given, the student model can eventually reach its expected maximum performance. KT is potentially beneficial for scenarios that meet the following circumstances: (1) when the teacher's task is generic, which means existing pre-trained models might be adequate for its task, so there will be no need to train the teacher model from scratch; and/or (2) when the label for the student's task is difficult or expensive to acquire.

</details>


### [166] [Sequencing to Mitigate Catastrophic Forgetting in Continual Learning](https://arxiv.org/abs/2512.16871)
*Hesham G. Moussa,Aroosa Hameed,Arashmid Akhavain*

Main category: cs.LG

TL;DR: 本文提出通过智能任务排序来缓解持续学习中的灾难性遗忘问题，利用零样本评分算法确定最优任务顺序，并与传统方法结合提升性能。


<details>
  <summary>Details</summary>
Motivation: 持续学习系统需要在整个生命周期中增量获取、更新和利用知识，但灾难性遗忘（学习新任务导致旧任务性能急剧下降）是主要挑战。现有方法主要分为五类，本文从不同角度考虑任务呈现顺序对缓解遗忘的影响。

Method: 提出基于任务排序的方法来缓解灾难性遗忘，利用受神经架构搜索启发的零样本评分算法确定最优任务顺序。该方法可与传统持续学习策略结合使用。

Result: 实验结果表明，智能任务排序能显著减少灾难性遗忘。当与传统持续学习策略结合时，能提供更好的性能和更强的抗遗忘鲁棒性。

Conclusion: 任务排序是缓解持续学习中灾难性遗忘的有效方法，该方法还可应用于课程学习等其他领域。智能任务排序与传统方法结合能提供更优的持续学习解决方案。

Abstract: To cope with real-world dynamics, an intelligent system needs to incrementally acquire, update, and exploit knowledge throughout its lifetime. This ability, known as Continual learning, provides a foundation for AI systems to develop themselves adaptively. Catastrophic forgetting is a major challenge to the progress of Continual Learning approaches, where learning a new task usually results in a dramatic performance drop on previously learned ones. Many approaches have emerged to counteract the impact of CF. Most of the proposed approaches can be categorized into five classes: replay-based, regularization-based, optimization-based, representation-based, and architecture-based. In this work, we approach the problem from a different angle, specifically by considering the optimal sequencing of tasks as they are presented to the model. We investigate the role of task sequencing in mitigating CF and propose a method for determining the optimal task order. The proposed method leverages zero-shot scoring algorithms inspired by neural architecture search (NAS). Results demonstrate that intelligent task sequencing can substantially reduce CF. Moreover, when combined with traditional continual learning strategies, sequencing offers enhanced performance and robustness against forgetting. Additionally, the presented approaches can find applications in other fields, such as curriculum learning.

</details>


### [167] [Training Together, Diagnosing Better: Federated Learning for Collagen VI-Related Dystrophies](https://arxiv.org/abs/2512.16876)
*Astrid Brull,Sara Aguti,Véronique Bolduc,Ying Hu,Daniel M. Jimenez-Gutierrez,Enrique Zuazua,Joaquin Del-Rio,Oleksii Sliusarenko,Haiyan Zhou,Francesco Muntoni,Carsten G. Bönnemann,Xabi Uribe-Etxebarria*

Main category: cs.LG

TL;DR: 利用联邦学习平台对胶原VI相关肌营养不良症进行诊断，通过分布式数据集训练模型，在保护患者隐私的同时显著提升诊断性能。


<details>
  <summary>Details</summary>
Motivation: 罕见病如胶原VI相关肌营养不良症（COL6-RD）的诊断面临数据稀缺和分散的挑战，跨机构数据共享存在隐私、监管和物流障碍，需要一种能在保护隐私前提下实现协作学习的方法。

Method: 采用联邦学习（FL）方法，使用Sherpa.ai FL平台，在两个国际组织的分布式数据集上进行协作训练。利用患者来源成纤维细胞培养物的胶原VI免疫荧光显微镜图像，训练分类模型识别三种主要致病机制：外显子跳跃、甘氨酸替换和假外显子插入。

Result: 联邦学习模型在COL6-RD诊断中取得了0.82的F1分数，显著优于单一机构模型（0.57-0.75），证明FL能大幅提升诊断效用和泛化能力。

Conclusion: 联邦学习为罕见病诊断提供了有效的隐私保护协作方案，不仅能提高诊断准确性，还有助于解释意义未明变异和指导测序策略，识别新的致病变异。

Abstract: The application of Machine Learning (ML) to the diagnosis of rare diseases, such as collagen VI-related dystrophies (COL6-RD), is fundamentally limited by the scarcity and fragmentation of available data. Attempts to expand sampling across hospitals, institutions, or countries with differing regulations face severe privacy, regulatory, and logistical obstacles that are often difficult to overcome. The Federated Learning (FL) provides a promising solution by enabling collaborative model training across decentralized datasets while keeping patient data local and private. Here, we report a novel global FL initiative using the Sherpa.ai FL platform, which leverages FL across distributed datasets in two international organizations for the diagnosis of COL6-RD, using collagen VI immunofluorescence microscopy images from patient-derived fibroblast cultures. Our solution resulted in an ML model capable of classifying collagen VI patient images into the three primary pathogenic mechanism groups associated with COL6-RD: exon skipping, glycine substitution, and pseudoexon insertion. This new approach achieved an F1-score of 0.82, outperforming single-organization models (0.57-0.75). These results demonstrate that FL substantially improves diagnostic utility and generalizability compared to isolated institutional models. Beyond enabling more accurate diagnosis, we anticipate that this approach will support the interpretation of variants of uncertain significance and guide the prioritization of sequencing strategies to identify novel pathogenic variants.

</details>


### [168] [Impacts of Racial Bias in Historical Training Data for News AI](https://arxiv.org/abs/2512.16901)
*Rahul Bhargava,Malene Hornstrup Jespersen,Emily Boardman Ndulue,Vivica Dsouza*

Main category: cs.LG

TL;DR: 研究分析了基于《纽约时报》语料库训练的AI分类器中"blacks"标签的偏见问题，发现该标签部分充当"种族主义检测器"，但对现代种族议题表现不佳，揭示了新闻业采用AI工具时面临的历史偏见再现风险。


<details>
  <summary>Details</summary>
Motivation: AI模型在新闻研究和新闻编辑室应用中越来越普遍，但这些基于历史数据训练的模型可能编码了过时的态度和刻板印象。本研究旨在调查基于《纽约时报》语料库训练的分类器中"blacks"标签的偏见问题，揭示AI工具在新闻业应用中可能带来的风险。

Method: 通过定量和定性方法分析训练语料库中"blacks"标签的使用情况，应用可解释AI方法探究该标签在训练分类器中编码的概念，并测试其在现代种族议题（如COVID-19期间反亚裔仇恨报道和"黑人的命也是命"运动报道）上的表现。

Result: 研究发现"blacks"标签在一定程度上充当了针对某些少数群体的"种族主义检测器"，但在现代种族议题上表现不佳，未能有效识别反亚裔仇恨报道和"黑人的命也是命"运动报道。这表明基于历史数据训练的模型可能无法适应现代语境。

Conclusion: 这项案例研究揭示了AI模型中嵌入的历史偏见问题，表明新闻业在采用AI工作流工具时面临根本性矛盾：如何在利用AI技术优势的同时，降低在新闻报道中复制历史偏见的风险。这对故事发现、受众定位、摘要生成等多种AI应用都有重要影响。

Abstract: AI technologies have rapidly moved into business and research applications that involve large text corpora, including computational journalism research and newsroom settings. These models, trained on extant data from various sources, can be conceptualized as historical artifacts that encode decades-old attitudes and stereotypes. This paper investigates one such example trained on the broadly-used New York Times Annotated Corpus to create a multi-label classifier. Our use in research settings surfaced the concerning "blacks" thematic topic label. Through quantitative and qualitative means we investigate this label's use in the training corpus, what concepts it might be encoding in the trained classifier, and how those concepts impact our model use. Via the application of explainable AI methods, we find that the "blacks" label operates partially as a general "racism detector" across some minoritized groups. However, it performs poorly against expectations on modern examples such as COVID-19 era anti-Asian hate stories, and reporting on the Black Lives Matter movement. This case study of interrogating embedded biases in a model reveals how similar applications in newsroom settings can lead to unexpected outputs that could impact a wide variety of potential uses of any large language model-story discovery, audience targeting, summarization, etc. The fundamental tension this exposes for newsrooms is how to adopt AI-enabled workflow tools while reducing the risk of reproducing historical biases in news coverage.

</details>


### [169] [Posterior Behavioral Cloning: Pretraining BC Policies for Efficient RL Finetuning](https://arxiv.org/abs/2512.16911)
*Andrew Wagenmaker,Perry Dong,Raymond Tsao,Chelsea Finn,Sergey Levine*

Main category: cs.LG

TL;DR: 提出后验行为克隆(PostBC)方法，通过建模演示数据的后验分布而非直接模仿动作，为RL微调提供更好的初始化策略，提升机器人控制性能。


<details>
  <summary>Details</summary>
Motivation: 当前实践中，通常先在大规模演示数据上预训练策略，然后通过RL微调提升性能。然而，现有研究主要关注微调算法本身，而忽略了预训练策略作为RL初始化的重要性。标准行为克隆(BC)可能无法覆盖演示者的所有动作，影响后续RL微调效果。

Method: 提出后验行为克隆(PostBC)方法：不同于标准BC直接匹配演示者的动作，PostBC训练策略来建模给定演示数据集条件下演示者行为的后验分布。这种方法确保了对演示者动作的覆盖，同时保持了与BC相当的预训练性能。PostBC仅需标准监督学习即可实现，适用于现代生成模型。

Result: 理论分析表明标准BC可能无法确保对演示者动作的覆盖，而PostBC能够满足这一RL微调的必要条件。在机器人控制基准测试和真实世界机器人操作任务中，PostBC相比标准BC显著提升了RL微调性能。

Conclusion: PostBC方法通过建模演示数据的后验分布，为RL微调提供了更有效的初始化策略，在保持预训练性能的同时显著提升了后续微调效果，为从演示学习到强化学习的过渡提供了更好的解决方案。

Abstract: Standard practice across domains from robotics to language is to first pretrain a policy on a large-scale demonstration dataset, and then finetune this policy, typically with reinforcement learning (RL), in order to improve performance on deployment domains. This finetuning step has proved critical in achieving human or super-human performance, yet while much attention has been given to developing more effective finetuning algorithms, little attention has been given to ensuring the pretrained policy is an effective initialization for RL finetuning. In this work we seek to understand how the pretrained policy affects finetuning performance, and how to pretrain policies in order to ensure they are effective initializations for finetuning. We first show theoretically that standard behavioral cloning (BC) -- which trains a policy to directly match the actions played by the demonstrator -- can fail to ensure coverage over the demonstrator's actions, a minimal condition necessary for effective RL finetuning. We then show that if, instead of exactly fitting the observed demonstrations, we train a policy to model the posterior distribution of the demonstrator's behavior given the demonstration dataset, we do obtain a policy that ensures coverage over the demonstrator's actions, enabling more effective finetuning. Furthermore, this policy -- which we refer to as the posterior behavioral cloning (PostBC) policy -- achieves this while ensuring pretrained performance is no worse than that of the BC policy. We then show that PostBC is practically implementable with modern generative models in robotic control domains -- relying only on standard supervised learning -- and leads to significantly improved RL finetuning performance on both realistic robotic control benchmarks and real-world robotic manipulation tasks, as compared to standard behavioral cloning.

</details>


### [170] [Exploration v.s. Exploitation: Rethinking RLVR through Clipping, Entropy, and Spurious Reward](https://arxiv.org/abs/2512.16912)
*Peter Chen,Xiaopeng Li,Ziniu Li,Wotao Yin,Xi Chen,Tianyi Lin*

Main category: cs.LG

TL;DR: 本文研究强化学习可验证奖励（RLVR）框架中的探索-利用权衡问题，发现虚假奖励和熵最小化这两种看似矛盾的机制都能提升大语言模型的数学推理能力，并通过剪裁偏差和奖励错配模型解释了其内在机制。


<details>
  <summary>Details</summary>
Motivation: 近期研究表明RLVR能通过两种看似矛盾的机制（虚假奖励抑制利用，熵最小化抑制探索）提升LLMs的数学推理能力，但这些效应背后的原理尚不清楚。本文旨在探究政策熵与性能的关系，以及虚假奖励是否通过剪裁偏差和模型污染相互作用产生收益。

Method: 研究RLVR框架中的探索-利用权衡，分析虚假奖励和熵最小化对模型性能的影响。通过实验验证剪裁偏差在虚假奖励下如何降低政策熵，并提出了奖励错配模型来解释虚假奖励在非污染设置下的性能提升机制。

Result: 研究发现：1）虚假奖励下的剪裁偏差能降低政策熵，使输出更自信和确定；2）单独的熵最小化不足以提升性能；3）提出的奖励错配模型解释了虚假奖励如何在非污染设置下提升性能。

Conclusion: 本文阐明了虚假奖励提升性能的机制，为更有效的RLVR训练提供了原则指导。研究揭示了探索-利用权衡中看似矛盾的现象背后的统一原理，有助于优化LLMs的推理能力训练方法。

Abstract: This paper examines the exploration-exploitation trade-off in reinforcement learning with verifiable rewards (RLVR), a framework for improving the reasoning of Large Language Models (LLMs). Recent studies suggest that RLVR can elicit strong mathematical reasoning in LLMs through two seemingly paradoxical mechanisms: spurious rewards, which suppress exploitation by rewarding outcomes unrelated to the ground truth, and entropy minimization, which suppresses exploration by pushing the model toward more confident and deterministic outputs, highlighting a puzzling dynamic: both discouraging exploitation and discouraging exploration improve reasoning performance, yet the underlying principles that reconcile these effects remain poorly understood. We focus on two fundamental questions: (i) how policy entropy relates to performance, and (ii) whether spurious rewards yield gains, potentially through the interplay of clipping bias and model contamination. Our results show that clipping bias under spurious rewards reduces policy entropy, leading to more confident and deterministic outputs, while entropy minimization alone is insufficient for improvement. We further propose a reward-misalignment model explaining why spurious rewards can enhance performance beyond contaminated settings. Our findings clarify the mechanisms behind spurious-reward benefits and provide principles for more effective RLVR training.

</details>
