<div id=toc></div>

# Table of Contents

- [gr-qc](#gr-qc) [Total: 30]
- [cs.LG](#cs.LG) [Total: 167]
- [physics.comp-ph](#physics.comp-ph) [Total: 4]
- [quant-ph](#quant-ph) [Total: 70]


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [1] [Radial Integral Reformulation of the Gauss-Bonnet Weak Deflection Angle at Finite Distance](https://arxiv.org/abs/2601.17059)
*Ali Övgün,Reggie C. Pantig*

Main category: gr-qc

TL;DR: 提出一种径向积分重构方法，用于计算静态球对称时空中有有限距离引力透镜的偏转角，基于高斯-博内定理和Li型曲率原函数恒等式。


<details>
  <summary>Details</summary>
Motivation: 现有有限距离引力透镜计算方法通常复杂且依赖隐式轨道参数，需要更透明、模块化的计算框架来简化不同时空配置下的偏转角计算。

Method: 采用高斯-博内定理描述有限距离偏转角，结合Li型曲率原函数恒等式将曲率-面积贡献简化为沿物理光线的单维积分。通过零阶首次积分进行变量替换，将Li线积分从φ积分转换为r积分，并在转折点（最近点）分割轨迹。

Result: 得到偏转角表示为两个径向积分（[r₀,r_S]和[r₀,r_R]）加上有限距离角度簿记项之和的公式，具有透明的归一化/抵消结构。在史瓦西规范下提供弱场评估工具包，将计算简化为可重用的标准径向积分族。

Conclusion: 该方法为有限距离引力透镜计算提供了模块化、透明的径向高斯-博内计算流程，成功应用于史瓦西、Kottler时空以及浸没在完美流体暗物质有限晕中的黑洞等实例，展示了该框架的通用性和实用性。

Abstract: We develop a radial integral reformulation of finite distance gravitational lensing in optical geometry for static, spherically symmetric spacetimes. Starting from the Gauss-Bonnet characterization of the finite distance deflection angle, we adopt the Li-type curvature primitive identity [https://doi.org/10.1103/PhysRevD.101.124058] [2006.13047], which reduces the curvature-area contribution to a one-dimensional integral evaluated along the physical light ray. We then remove the remaining implicit orbit dependence by an explicit change of variables using the null first integrals, converting the Li line integral from $φ$-integration to $r$-integration and splitting the trajectory at the turning point (closest approach). The resulting formula expresses the deflection angle as a sum of two radial integrals over $[r_0,r_S]$ and $[r_0,r_R]$ plus the finite distance angular bookkeeping term, with a transparent normalization/cancellation structure for the curvature primitive. In Schwarzschild gauge, we provide a weak-field evaluation toolkit that reduces the computation to reusable families of standard radial integrals and gives compact expressions for the endpoint incidence angles in the optical metric. Worked examples include Schwarzschild and Kottler (Schwarzschild-de Sitter) spacetimes and a black hole immersed in perfect-fluid dark matter with a finite halo. For the finite-halo model we derive closed-form leading weak-deflection expressions for mixed endpoint configurations (source/receiver inside or outside the halo), illustrating the modularity of the radial Gauss-Bonnet pipeline.

</details>


### [2] [Quasi-homogeneous geometrothermodynamics of a noncommutative Reissner-Nordstrom black hole](https://arxiv.org/abs/2601.17081)
*Alberto Maya,Hernando Quevedo*

Main category: gr-qc

TL;DR: 研究非对易Reissner-Nordström黑洞的热力学性质，使用几何热力学方法分析相变，探讨非对易参数作为热力学变量的作用


<details>
  <summary>Details</summary>
Motivation: 研究非对易Reissner-Nordström黑洞的热力学行为，特别是相变特性，探索非对易参数在热力学中的作用

Method: 使用Legendre不变的几何热力学(GTD)形式，应用于由NCRN黑洞生成的准齐次系统，通过Ricci标量奇点定位相变点

Result: 确定了相变点与热力学变量的关系，发现非对易参数可以作为热力学变量，在准齐次热力学定律中影响相变

Conclusion: 几何热力学方法有效分析非对易黑洞相变，非对易参数在热力学中起重要作用，揭示了超越热容量发散的传统相变机制

Abstract: We present the thermodynamic properties of a noncommutative Reissner Nordstrom (NCRN) black hole (BH) modeled with Lorentzian distributions. The analysis is carried out using a Legendre invariant formalism called Geometrothermodynamics (GTD) which is applied to a quasihomogeneous system generated by the NCRN BH. This formalism enables the study of phase transitions by locating Ricci scalar singularities, from which the phase transition points are determined in terms of the thermodynamic variables. We also examine how the noncommutative (NC) parameter can be interpreted as a thermodynamic variable within quasi-homogeneous thermodynamic laws, highlighting its potential role on phase transitions beyond those well-known characterized by divergences in the heat capacity.

</details>


### [3] [Effective geometrodynamics for renormalization-group improved black-hole spacetimes in spherical symmetry](https://arxiv.org/abs/2601.17115)
*Johanna Borissova,Raúl Carballo-Rubio*

Main category: gr-qc

TL;DR: 本文提出了一种系统化的重整化群改进方法，用于处理球对称引力场，通过二维Horndeski理论保留高阶曲率截断的部分贡献，同时保持场方程的二阶性质。


<details>
  <summary>Details</summary>
Motivation: 传统重整化群改进方法在作用量、场方程或解的不同层面实施时会产生不一致的结果，需要建立系统化的操作框架来统一这些方法。

Method: 利用二维Horndeski理论构造的球对称引力场主场方程，引入重整化群尺度相关的牛顿引力耦合，推导静态RG改进的黑洞时空解。

Result: 得到了有效引力耦合依赖于面积半径和Misner-Sharp质量的静态RG改进黑洞时空解，这些解被识别为一般协变二维Horndeski理论的真空解。

Conclusion: 新发展的形式主义为RG改进提供了统一框架，能够明确展示在不同层面实施RG改进时结果的差异，并具有广泛的适用性。

Abstract: We consider the spherically reduced Einstein-Hilbert action, Einstein field equations and Schwarzschild spacetime modified by a renormalization-group (RG) scale-dependent gravitational Newton coupling, and present a systematic and operational approach to such an RG-improvement. The master field equations for spherically symmetric gravitational fields, recently constructed from two-dimensional Horndeski theory, allow us to retain partial contributions from higher-curvature truncations of the effective action, while preserving the second-order nature of the resulting field equations. Static RG-improved black-hole spacetimes with an effective gravitational coupling depending on the areal radius and the Misner-Sharp mass are derived as vacuum solutions to these master field equations, and are thereby identified as solutions to generally covariant two-dimensional Horndeski theories. We discuss explicitly the embedding of previous key works on RG-improvement into the newly developed formalism to illustrate its broad range of applicability. This formalism moreover allows us to establish explicitly the discrepancies in the outcomes of RG-improvement when implemented at the level of the action, in the field equations, or in the Schwarzschild solution.

</details>


### [4] [Averaging Theory and Dynamical Systems in Cosmology: A Qualitative Study of Oscillatory Scalar-Field Models](https://arxiv.org/abs/2601.17157)
*Genly Leon,Claudio Michea*

Main category: gr-qc

TL;DR: 该论文使用动力系统和平均方法研究宇宙学模型，涵盖FLRW几何和Bianchi类型，建立了振荡流与平均慢流之间的共轭关系，并得到几何依赖的晚期吸引子分类。


<details>
  <summary>Details</summary>
Motivation: 研究宇宙学模型的动力学行为，特别是振荡系统在宇宙演化中的平均效应，理解不同几何结构下的晚期吸引子特性。

Method: 采用动力系统理论和平均方法，研究平坦和开放FLRW几何以及LRS Bianchi类型I、III、V的宇宙学模型，在正则性和频率缩放假设下建立振荡流与平均慢流之间的近恒等共轭关系。

Result: 获得了振荡流与平均慢流之间的共轭关系，误差为$\mathcal{O}(H(t))$，有效系统保持了原始渐近行为，并得到几何依赖的晚期吸引子分类。当主导平均向量场为零时，系统在$H^0$阶没有自主漂移。

Conclusion: 平均方法为研究振荡宇宙学模型提供了有效工具，能够揭示不同几何结构下的晚期演化特性，特别是吸引子分类对几何的依赖性，为理解宇宙演化提供了新的理论框架。

Abstract: We study cosmological models using dynamical systems and averaging methods, encompassing flat and open FLRW geometries as well as the LRS Bianchi types I, III, and V. Under mild regularity and frequency-scaling assumptions, we obtain a near-identity conjugacy between the oscillatory flow and an averaged slow flow, with $\| \mathbf{x}(t)-\bar {\mathbf{x}}(t)\| =\mathcal{O}(H(t))$. The effective systems preserve the original asymptotics and yield geometry-dependent late-time attractor classifications. A corollary addresses the case in which the leading averaged vector field vanishes, so the system exhibits no autonomous drift at order $H^0$.

</details>


### [5] [Varying Newton constant, entropy and the black hole evaporation law](https://arxiv.org/abs/2601.17162)
*Julia Haba,Zbigniew Haba*

Main category: gr-qc

TL;DR: 该论文研究了爱因斯坦方程中随时间变化的牛顿常数G和宇宙学常数Λ，以及能量-动量张量不守恒的情况。通过比安基恒等式建立了能量-动量不守恒与G、Λ变化之间的关系，并应用热力学将理想流体的能量-动量不守恒与熵联系起来。最后推导了修正的史瓦西黑洞蒸发公式，发现蒸发寿命比常数G情况下延长了9/5倍。


<details>
  <summary>Details</summary>
Motivation: 研究爱因斯坦方程中牛顿常数G和宇宙学常数Λ随时间变化的可能性，以及能量-动量张量不守恒的情况。探索这些变化如何通过比安基恒等式相互关联，并理解它们与热力学熵变化的关系。

Method: 将能量-动量张量表示为理想流体加上宇宙学项，考虑随时间变化的牛顿常数G和宇宙学常数Λ。利用比安基恒等式建立能量-动量（不）守恒与G、Λ变化之间的关系。应用热力学将理想流体的能量-动量不守恒与熵变化联系起来。通过变化的牛顿常数G与黑洞熵的关系，推导修正的史瓦西黑洞蒸发公式。

Result: 如果能量-动量张量守恒，则牛顿常数G和宇宙学常数Λ要么都不变化，要么都随时间变化。如果能量-动量张量不守恒，则比安基恒等式给出了能量-动量与G或Λ（或两者）时间变化之间的关系。推导出的修正黑洞蒸发公式显示，黑洞蒸发寿命比常数G情况下延长了9/5倍。当黑洞半径收缩到零时，平均密度保持恒定。

Conclusion: 该研究建立了随时间变化的牛顿常数G和宇宙学常数Λ与能量-动量不守恒之间的理论联系，并将这些变化与熵变化相关联。修正的黑洞蒸发模型表明，变化的G会显著影响黑洞的蒸发过程，延长其寿命。这为理解引力常数变化对天体物理过程的影响提供了新的理论框架。

Abstract: In Einstein equations we represent the energy-momentum tensor as the one ($T^{μν}$ ) of an ideal fluid plus the cosmological term. We consider time-dependent Newton ``constant" $G$, the cosmological term $Λ$ and non-conserved $T^{μν}$. The Bianchi identity imposes a relation between the energy-momentum (non)conservation and the variation of $G$ and $Λ$. If the energy-momentum $T^{μν}$ is conserved then both the Newton ``constant" $G$ and the cosmological term $Λ$ either do not change or both must depend on time. If the energy-momentum $T^{μν}$ is not conserved then the Bianchi identity implies a relation between the energy-momentum and a variation in time of either $G$ or $Λ$ (or both). We apply thermodynamics in order to express the non-conservation of the energy-momentum of an ideal fluid by entropy and relate the time variations of $G$ and $Λ$ to a change of entropy. Using the relation between a varying Newton constant G and the black hole entropy we derive a modified formula for the Schwarzschild black hole evaporation (a slower evaporation). Its life time is $\frac{9}{5}$ times larger than the one for a constant $G$. The average black hole's density remains constant when the black hole's radius shrinks to zero .

</details>


### [6] [Dissipative Unimodular Gravity: Linking Energy Diffusion to Bulk Viscosity as an Alternative to $Λ$CDM under DESI DR2 Data](https://arxiv.org/abs/2601.17281)
*Norman Cruz,Esteban González*

Main category: gr-qc

TL;DR: 在单模引力框架中首次引入粘性耗散，研究晚期平坦FLRW宇宙中的能量扩散，通过观测数据测试发现某些模型与ΛCDM竞争，为宇宙常数问题提供新解。


<details>
  <summary>Details</summary>
Motivation: 在单模引力框架中首次探索粘性耗散效应，旨在为宇宙常数问题提供新解决方案，并检验能量非守恒在晚期宇宙观测数据中的兼容性。

Method: 在平坦FLRW宇宙晚期，采用Eckart理论描述物质耗散过程，引入粘性系数与能量扩散函数的幂律关系，假设Q=νH²，推导宇宙演化的解析解，并用超新星、BAO、宇宙时钟、引力透镜和黑洞阴影等最新观测数据测试模型。

Result: 测试的两个模型在χ²最小化方面显著优于其他模型，根据贝叶斯信息准则与ΛCDM模型竞争力相当，表明微小的能量非守恒与晚期观测数据兼容。

Conclusion: 耗散单模引力是标准模型的强有力替代方案，结合其缓解宇宙常数问题的固有能力，表明微小的能量非守恒与观测数据兼容，为宇宙学提供新视角。

Abstract: In this paper, we explore a theoretical and observational study of the presence of viscosity in the Unimodular Gravity formalism, a pioneering approach that, to the best of our knowledge, has not been previously explored in this context. Specifically, we study a flat FLRW universe at late times, where matter experiences dissipative processes in the form of a bulk viscosity, in the framework of Eckart's theory, which is linked to the energy diffusion function $Q$ through the power law $ξ=ξ_{0}\left|Q\right|^{1/2}$, being $ξ_{0}$ a positive dimensionless parameter. By assuming the ansatz $Q=νH^{2}$, where $H$ is the Hubble parameter and $ν$ is a dimensionless arbitrary constant, we find analytical solutions for the cosmological evolution. We test these models against the most recent cosmological observations, including type Ia supernovae, baryon acoustic oscillations, cosmic chronometers, gravitational lensing, and black hole shadow data. Our results show that two of the tested models provide a significantly better fit to the data ($χ_{\text{min}}^{2}$) and remain as competitive as $Λ$CDM model according to the Bayesian Information Criterion. These findings, combined with the inherent ability of Unimodular Gravity to alleviate the cosmological constant problem, position dissipative UG as a robust and compelling alternative to the standard model, potentially suggesting that a very small but nontrivial energy nonconservation is compatible with the late-time observational data.

</details>


### [7] [Revisiting induced gravity in scalar-tensor thermodynamics](https://arxiv.org/abs/2601.17398)
*Andrea Giusti*

Main category: gr-qc

TL;DR: 研究诱导引力理论的热力学性质，推导引力温度及其演化方程，分析广义相对论平衡态和向爱因斯坦理论收敛的吸引子机制


<details>
  <summary>Details</summary>
Motivation: 在修正引力理论的热力学框架下研究诱导引力理论，探索引力温度概念及其演化，分析广义相对论作为平衡态的可能性以及是否存在向爱因斯坦理论收敛的吸引子机制

Method: 将诱导引力作为全局尺度不变的"第一代"标量-张量理论，在修正引力热力学框架下推导引力温度及其演化方程，分析广义相对论平衡态

Result: 成功推导了诱导引力模型的引力温度及其演化方程，可用于分析广义相对论平衡态，并研究向爱因斯坦理论收敛的吸引子机制

Conclusion: 诱导引力理论在热力学框架下具有引力温度概念，可用于研究广义相对论作为平衡态的性质，并探索向爱因斯坦理论收敛的吸引子机制

Abstract: Induced gravity, defined as a globally scale-invariant ``first-generation'' scalar-tensor theory, is investigated within the framework of the thermodynamics of modified gravity theories. The ``temperature of gravity'' and its evolution equation are derived for this model, and the resulting expressions are used to analyse General-Relativity equilibrium states and to investigate the possible existence of an attractor mechanism toward Einstein's theory with a cosmological constant.

</details>


### [8] [Nonsingular Rotating Black Holes in the Dark-Energy Dominated Universe](https://arxiv.org/abs/2601.17509)
*Ramon Torres*

Main category: gr-qc

TL;DR: 构建了一类嵌入改进的de Sitter背景中的非奇异旋转黑洞时空，允许常数或跑动的宇宙学常数Λ，通过广义Kerr-Schild构造实现从静态球对称正则模型到旋转对应物的直接映射。


<details>
  <summary>Details</summary>
Motivation: 受量子引力场景（用正则核心取代经典黑洞奇点）和暗能量可能具有尺度依赖性的启发，研究在暗能量背景下具有正则核心的旋转黑洞，为引力波和视界尺度成像观测提供理论框架。

Method: 提出广义Kerr-Schild构造方法，在（可能尺度依赖Λ的）de Sitter种子度规上构建Carter型度规，由质量函数和Λ函数表征。该方法避免了Newman-Janis算法与宇宙学常数流体的不兼容问题。

Result: 推导了环处的正则性条件，识别了最小阶子类；证明了对于非负质量函数和Λ在一定负极限以上，时空是稳定因果的；对于具有非负质量的最小阶几何，弱能量条件必须被违反。

Conclusion: 该框架为在暗能量背景下研究正则旋转黑洞提供了可控的观测导向平台，可用于与引力波和视界尺度成像数据的对比分析，并展示了渐近安全启发的模型示例。

Abstract: Motivated by quantum-gravity scenarios that replace the classical black hole singularity with a regular core, and by the possibility that the dark-energy sector may be scale dependent, we construct a broad class of nonsingular rotating black-hole spacetimes embedded in an improved de Sitter--like background with either constant or running $Λ$. Because the Newman--Janis algorithm is generically incompatible with a cosmological-constant fluid, we instead propose a generalized Kerr--Schild construction on a (possibly scale-dependent $Λ$) de Sitter seed, yielding a Carter-type metric characterized by a mass function and a $Λ$ function. Our construction provides a direct map from static, spherically symmetric regular models to their rotating counterparts. We derive sharp regularity conditions at the ring and we identify a minimal-order subclass. We analyze chronology and show that, for non-negative mass function and $Λ$ above a certain negative limit, the spacetimes are stably causal. For minimal-order geometries with non-negative mass, we prove that the weak energy condition must be violated. Finally, we illustrate the framework with an asymptotic-safety--inspired model and discuss horizon structure, surface gravities, and conformal diagrams. These results provide a controlled, observationally oriented arena to confront regular rotating black holes in dark-energy backgrounds with the rapidly improving gravitational-wave and horizon-scale imaging data.

</details>


### [9] [From Thermodynamic Criticality to Geometric Criticality: A Linear Kernel Map from Matter Susceptibilities to Black-Hole Shadows](https://arxiv.org/abs/2601.17613)
*Jingxu Wu,Jie Shi,Chenjia Li,Yuwei Yin*

Main category: gr-qc

TL;DR: 该论文构建了从热力学扰动到黑洞几何观测量的显式映射，揭示了热力学临界指数与几何响应之间的对应关系。


<details>
  <summary>Details</summary>
Motivation: 研究黑洞热力学扰动如何影响其几何观测量（如阴影半径和光子球频率），建立热力学临界现象与黑洞几何响应之间的理论联系。

Method: 构造了从守恒热力学扰动到静态球对称时空度规响应的显式线性映射，使用L¹有界核函数以"局部+尾部"形式表达，并提供了可重复的数值计算流程。

Result: 在温和假设下，热力学临界指数直接传递到几何响应中（γ_sh = γ_th），并给出了AdS远区边界的显式约束，建立了热力学与几何观测之间的定量对应关系。

Conclusion: 成功建立了黑洞热力学扰动与几何观测量之间的理论桥梁，为通过视界尺度成像观测热力学临界现象提供了理论基础。

Abstract: We construct an explicit linear map from compact, conserved thermodynamic/effective-medium perturbations of the stress-energy tensor to the metric response in static, spherically symmetric spacetimes, and from there to geometric observables of direct relevance to horizon-scale imaging: the shadow radius and photon-sphere frequency. The response is expressed through $L^{1}$-bounded kernels written in a piecewise "local $+$ tail" form, which makes transparent the separation between near-photon-sphere sensitivity and far-zone contributions (including AdS tails). Under mild assumptions on the matter susceptibilities near a critical point, dominated convergence transfers the thermodynamic exponent to the geometric susceptibility, $γ_{\rm sh}=γ_{\rm th}$, with controlled analytic corrections. We further provide AdS far-zone bounds with explicit outside-support constants depending only on background geometric data at the photon sphere and shell geometry. A reproducible numerical pipeline with convergence diagnostics is presented and benchmarked.

</details>


### [10] [The neutrino behavior in the Einstein$\text{-}$Hilbert$\text{-}$Bumblebee gravity around global monopole field](https://arxiv.org/abs/2601.17696)
*B. Q. Wang,S. R. Wu,Z. W. Long*

Main category: gr-qc

TL;DR: 研究爱因斯坦-希尔伯特-大黄蜂引力场中全局单极子场附近沿径向和非径向路径传播的中微子振荡相位，获得修正的振荡概率表达式，发现与史瓦西黑洞不同，洛伦兹破坏参数a主要影响振荡概率峰值，全局单极子参数和最小中微子质量影响振荡频率。


<details>
  <summary>Details</summary>
Motivation: 探索弯曲时空中的中微子振荡现象，特别是在爱因斯坦-希尔伯特-大黄蜂引力场和全局单极子场这种特殊引力环境中，研究引力效应对中微子振荡的影响，为探测致密天体性质和理解中微子物理提供新途径。

Method: 使用量子力学处理方法，研究中微子在爱因斯坦-希尔伯特-大黄蜂引力场中沿径向和非径向路径传播时的振荡相位，推导修正的中微子振荡概率表达式。

Result: 发现该引力环境中的中微子振荡与史瓦西黑洞不同；洛伦兹破坏参数a主要影响振荡概率峰值；全局单极子参数和最小中微子质量影响振荡频率。

Conclusion: 研究弯曲时空中的中微子振荡现象不仅可能成为探测致密天体性质的新技术，也有助于深化对中微子物理的理解。

Abstract: In this work, we study the phase of neutrino oscillation propagating along radial and non-radial paths in the Einstein$\text{-}$Hilbert$\text{-}$Bumblebee (EHB) gravity around global monopole field, by using the quantummechanical treatment, the expression of the corrected neutrino of probability of oscillation is obtained. Our results show that neutrino oscillation in the EHB gravity around global monopole field is different from that in Schwarzschild black hole, the Lorentz-violating parameter $a$ mainly affects the peak of the oscillation probability, and the global monopole $\overline { μ}$ and the lightest neutrino mass both affect the frequency of the oscillations of probabilities, which means that studying the neutrino oscillation phenomenon in curved spacetime may not only become a new technology for probing the properties of compact celestial bodies, but also help deepen our understanding of neutrinos.

</details>


### [11] [Three dimensional black bounces in $f(R)$ gravity](https://arxiv.org/abs/2601.17848)
*Marcos V. de S. Silva,Manuel E. Rodrigues,C. F. S. Pereira*

Main category: gr-qc

TL;DR: 本文研究了在2+1维f(R)引力理论中黑洞反弹解的存在性，分析了广义相对论中的黑洞反弹几何能否推广到f(R)理论，并识别支持此类解的物质源。


<details>
  <summary>Details</summary>
Motivation: 研究黑洞反弹解在f(R)引力理论中的存在性和性质，探索f(R)理论如何修改能量条件，并评估支持这些解所需的物质奇异程度。

Method: 1) 分析广义相对论中的黑洞反弹几何能否推广到f(R)理论；2) 通过施加曲率标量为零构造新解类；3) 在物质部分考虑标量场与非线性电动力学的耦合模型；4) 在引力部分分析Starobinsky模型和更一般的f(R)形式；5) 检验f(R)模型的可行性条件，包括标量子质量行为；6) 研究相关的能量条件。

Result: 确定了在f(R)理论中黑洞反弹解的存在性，识别了支持这些解的物质源，构造了新的零曲率标量解类，并分析了f(R)理论如何修改能量条件。

Conclusion: 黑洞反弹解可以在2+1维f(R)引力理论中存在，f(R)理论显著影响支持这些解所需的物质能量条件，为理解黑洞反弹现象在修正引力理论中的性质提供了新见解。

Abstract: We investigate the existence of black bounce solutions in $2+1$ dimensions within the framework of $f(R)$ gravity. We analyze whether black bounce geometries originally obtained in general relativity can be consistently generalized to $f(R)$ theories and identify the matter sources capable of supporting such solutions. We also construct a new class of solutions by imposing a vanishing curvature scalar. In the matter sector, we consider models involving a coupling between a scalar field and nonlinear electrodynamics, while in the gravitational sector we analyze both the Starobinsky model and more general forms of $f(R)$. We further examine the viability conditions of the $f(R)$ models that give rise to these spacetimes, including the behavior of the scalaron mass. Finally, we study the associated energy conditions, in order to assess the degree of exoticity of the matter content required to sustain these black bounce solutions and how the $f(R)$ theory modifies the energy conditions.

</details>


### [12] [Generation of gravitating solutions with Baryonic charge from Einstein-Scalar-Maxwell seeds](https://arxiv.org/abs/2601.17864)
*Fabrizio Canfora,Anibal Neira,Seung Hun Oh*

Main category: gr-qc

TL;DR: 首次建立爱因斯坦-标量-麦克斯韦理论与规范Skyrme-麦克斯韦-爱因斯坦模型之间的精确对应关系，将电真空解生成技术应用于更复杂的规范Skyrme理论中。


<details>
  <summary>Details</summary>
Motivation: 规范Skyrme-麦克斯韦-爱因斯坦理论在宇宙学和天体物理学中有重要应用，但求解复杂。建立与更简单的爱因斯坦-标量-麦克斯韦理论的对应关系，可以利用成熟的电真空解生成技术来系统探索Skyrme理论的精确解。

Method: 在规范Skyrme-麦克斯韦框架内构造最简单的相容ansatz，揭示在具有非零高度磁化重子电荷的扇区中与爱因斯坦-标量-麦克斯韦理论的等价性。建立两种理论之间的"字典"对应关系。

Result: 成功建立了两种理论之间的精确对应关系，使得电真空系统的解生成技术可以应用于规范Skyrme-麦克斯韦-爱因斯坦理论。应用该对应关系到带有标量场的旋转Kerr-Newman类时空，发现重子电荷的量子化强制Kerr旋转参数的量子化，并推导了重子电荷的上界。

Conclusion: 这一对应关系为系统探索Skyrme-麦克斯韦-爱因斯坦理论的精确解及其在宇宙学和天体物理学中的应用打开了大门，特别是在小重子电荷区域，旋转参数与重子电荷呈线性关系。

Abstract: We establish, for the first time, an exact correspondence between Einstein-scalar-Maxwell theory and gauged Skyrme-Maxwell-Einstein models in (3+1) dimensions. By constructing the simplest consistent ansatz within the gauged Skyrme-Maxwell framework, we reveal a remarkable equivalence in a sector that admits nonvanishing, highly magnetized baryonic charge. This correspondence has a particularly appealing consequence: it transfers the full power of solution-generating techniques developed for electrovacuum systems-many of which naturally accommodate scalar fields to the considerably more intricate setting of gauged Skyrme-Maxwell theory minimally coupled to General Relativity. As a result, it opens the door to a systematic and much broader exploration of exact solutions in Skyrme-Maxwell-Einstein theory and of their potential applications in cosmology and astrophysics. Notably, the resulting configurations carry nonzero baryonic charge whenever the derivative of the hadronic profile along the magnetic field lines does not vanish. As an illustrative example, we apply this new dictionary to a rotating Kerr-Newman-like spacetime dressed with a scalar field. In the corresponding Skyrme-Maxwell-Einstein solution, the quantization of the baryonic charge enforces a quantization of the Kerr rotation parameter. We derive an upper bound on the baryonic charge in terms of the integration constants of the solution and show that, in the regime of small baryonic charge, the rotation parameter depends linearly on the baryonic charge.

</details>


### [13] [Stability-Protected Phantom Bound in Scalar-Field Cosmology](https://arxiv.org/abs/2601.17873)
*Prasanta Sahoo*

Main category: gr-qc

TL;DR: 该论文证明，对于一类广泛的单场有效标量宇宙学模型，要求无鬼（动能响应函数为正）会强制将幻影分界线（w=-1）作为宇宙相空间中的稳定性保护边界，从而禁止连续无鬼演化进入幻影区域。


<details>
  <summary>Details</summary>
Motivation: DESI DR2等近期宇宙学观测暗示暗能量状态方程可能存在红移演化，这重新引发了关于幻影区域（w<-1）物理可行性的基本问题。作者旨在从理论稳定性角度探讨幻影区域是否可物理实现。

Method: 研究一类广泛的单场有效标量宇宙学模型，其中动能响应由哈勃膨胀率调制（红外修正和非局部引力理论的典型特征）。通过分析动能响应函数M≡∂ρ/∂X>0的无鬼条件，证明该条件强制w=-1成为稳定性保护边界。

Result: 证明无鬼条件强制幻影分界线（w=-1）作为宇宙相空间中的稳定性保护边界。状态方程可以无限接近该界限，但连续无鬼演化进入幻影区域被严格禁止。动力学收敛于de Sitter类吸引子，其中w→-1是动力学选择和稳定性的结果，而非标量势的精细调节。

Conclusion: DESI DR2观测到的演化"暗示"可能反映了有效场论的基本稳定性要求，该理论机制阻止了物理上向幻影相的转变。幻影分界线作为稳定性保护边界出现，而非可穿越的相变点。

Abstract: Recent cosmological observations, most notably from the DESI Data Release 2 (DR2) \cite{DESIDR2}, suggest a potential redshift evolution of the dark energy equation of state, reviving fundamental questions regarding the physical viability of the phantom regime ($w < -1$). In this Letter, a no-go result is established for a broad class of single-field effective scalar cosmologies where the kinetic response is modulated by the Hubble expansion rate, a structural feature characteristic of infrared-modified and nonlocal gravity theories \cite{DeserWoodard2007, Maggiore2014}. It is proved that imposing ghost freedom, defined by the positivity of the kinetic response function $\mathcal{M} \equiv \partialρ/\partial X > 0$, enforces the phantom divide ($w = -1$) as a \textit{stability-protected boundary} in the cosmological phase space. While the equation of state can approach this limit arbitrarily closely, continuous ghost-free evolution into the phantom regime is shown to be strictly forbidden. The dynamics are found to converge toward a de~Sitter-like attractor where $w \to -1$ emerges as a consequence of dynamical selection and stability rather than the fine-tuning of the scalar potential. These results suggest that the "hints" of evolution observed in DESI DR2 may reflect the underlying stability requirements of the effective field theory, providing a theoretical mechanism that prevents a physical transition into the phantom phase.

</details>


### [14] [The Hamiltonian for an atom interacting with gravitational waves](https://arxiv.org/abs/2601.17891)
*Linda M. van Manen,André Grossardt*

Main category: gr-qc

TL;DR: 该研究基于相对论哈密顿量，推导了原子系统在弱引力波背景下的曲率相关修正，发现内部能量变化不总是简化为质量重整化，可能产生真实的力，未来实验或可探测这些引力波相互作用产生的力。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于量子光学中出现的异常摩擦样力，这些力实际上是质量-能量等效原理带来的相对论修正。作者希望进一步探索原子系统在动态引力背景下的行为，特别是引力波相互作用可能产生的额外力。

Method: 基于Sonnleitner和Barnett的相对论哈密顿量及其后牛顿扩展，使用局部惯性系和微扰的闵可夫斯基度规，推导了原子系统在弱引力波背景下的曲率相关修正。分别考虑了质心哈密顿量和内部哈密顿量的修正。

Result: 得到的哈密顿量包含不同的曲率耦合项，这些项修改了内部势能并影响质心动力学。内部能量变化不总是简化为质量重整化，而是可以由于动量变化产生真实的力。这些力源于引力波与原子系统的相互作用。

Conclusion: 随着探测器灵敏度的提高，引力波相互作用产生的额外力可能在未来实验中变得可观测。该研究澄清了量子光学中异常力的本质，并为探测引力波与物质系统的微弱相互作用提供了理论基础。

Abstract: Building on the relativistic Hamiltonian of Sonnleitner and Barnett arXiv:1806.00234 and its post-Newtonian extensions by Schwartz and Giuilini arXiv:1908.06929, we investigate composite atomic systems in dynamical gravitational backgrounds. Using a local inertial frame and a perturbed Minkowski metric, we derive curvature-dependent corrections to both center-of-mass and internal Hamiltonians for atoms interacting with weak gravitational waves. The resulting Hamiltonian contains distinct curvature couplings modifying the internal potential and affecting the center-of-mass dynamics. These contributions imply that internal-energy variations do not always reduce to mass renormalization and can induce genuine forces due to changes in momentum. The initial research was motivated by anomalous friction-like forces emerging in quantum optics, and clarified that the anomalous forces are mere relativistic corrections from mass-energy equivalence. Our results suggest that, with increasingly sensitive detectors, additional forces from gravitational wave interactions may become visible in future experiments.

</details>


### [15] [Telling tails and quasi-resonances in the vicinity of Dymnikova regular black hole](https://arxiv.org/abs/2601.17906)
*Bekir Can Lütfüoğlu,Javlon Rayimbaev,Bekzod Rahmatov,Fayzullo Shayimov,Ikram Davletov*

Main category: gr-qc

TL;DR: 研究Dymnikova正则黑洞背景下大质量标量扰动的准正规模、晚期拖尾和灰体因子，发现大质量场与无质量场存在定性差异，大质量场可能作为探测黑洞近视界量子修正的探针。


<details>
  <summary>Details</summary>
Motivation: 研究大质量标量场在Dymnikova正则黑洞背景下的动力学行为，探索大质量场如何作为探测正则黑洞特征和近视界量子修正的工具。

Method: 使用时域积分法和带有Padé改进的WKB方法，分析大质量标量扰动在Dymnikova正则黑洞背景下的准正规模、晚期拖尾和灰体因子。

Result: 大质量场与无质量场谱存在定性差异：主导模的振荡频率随场质量μ增加而增长，阻尼率减小，表明在足够大μ时存在准共振；时域晚期信号显示具有幂律包络的振荡拖尾；灰体因子计算显示质量增加会强烈抑制辐射。

Conclusion: 大质量场为Dymnikova正则黑洞提供了独特的特征信号，可能作为探测近视界量子修正的探针，有助于区分正则黑洞与奇异黑洞。

Abstract: We investigate quasinormal modes, late-time tails, and grey-body factors for massive scalar perturbations in the background of the Dymnikova regular black hole. By applying both the time-domain integration and the WKB method with Padé improvements, we show that the spectrum of massive fields differs qualitatively from the massless case. The oscillation frequency of the dominant mode grows with the field mass $μ$, while the damping rate decreases, suggesting the existence of quasi-resonances at sufficiently large $μ$. In the time domain, the late-time signal exhibits oscillatory tails with a power-law envelope, whose decay rate matches analytic expectations. Grey-body factors are also computed, showing strong suppression of radiation when mass is increased. Taken together, these results indicate that massive fields provide distinctive signatures of regular black holes and may serve as probes of near-horizon quantum corrections in the Dymnikova geometry.

</details>


### [16] [QPO-Based Bayesian Constraints on Charged Particle Dynamics Around Magnetized Schwarzschild Black Holes](https://arxiv.org/abs/2601.17953)
*Z. Ahal,H. El Moumni,K. Masmar*

Main category: gr-qc

TL;DR: 研究带电粒子在施瓦西黑洞外部抛物型磁场中的运动，分析磁偶极矩耦合对轨道稳定性和准周期振荡频率的影响，并用观测数据约束黑洞参数。


<details>
  <summary>Details</summary>
Motivation: 研究带电粒子在黑洞磁层中的动力学行为，特别是磁偶极矩耦合如何影响轨道稳定性，并探索这种相互作用对黑洞吸积盘准周期振荡观测特征的影响。

Method: 使用哈密顿-雅可比形式推导运动方程，分析赤道圆轨道、最内稳定圆轨道和环向振荡，建立相对论进动框架下的高频准周期振荡模型，并基于贝叶斯参数估计和马尔可夫链蒙特卡洛方法处理观测数据。

Result: 磁场强度和耦合参数对轨道稳定性产生竞争效应，通过QPO观测数据成功约束了黑洞质量、磁场强度、场几何结构、耦合参数和QPO轨道半径等参数。

Conclusion: 磁层相互作用在塑造粒子动力学和吸积黑洞的时序特性中发挥关键作用，为理解黑洞磁层中的粒子运动提供了重要见解。

Abstract: We study the motion of charged particles with a magnetic dipole moment orbiting a Schwarzschild black hole immersed in an external paraboloidal magnetic field. The interaction between the particle's intrinsic magnetic moment and the black hole magnetosphere is modeled through a dipole coupling, and the equations of motion are derived using the Hamilton-Jacobi formalism. We analyze equatorial circular orbits, the innermost stable circular orbit, and epicyclic oscillations, showing that the magnetic field strength and coupling parameter produce competing effects on orbital stability and fundamental frequencies. These frequencies are applied to model high-frequency quasi-periodic oscillations within the relativistic precession framework. Using observational QPO data from stellar-mass, intermediate-mass, and supermassive black holes, we perform a Bayesian parameter estimation based on Markov Chain Monte Carlo techniques. The analysis constrains the black hole mass, magnetic field strength, field geometry, coupling parameter, and QPO orbital radius, highlighting the role of magnetospheric interactions in shaping both particle dynamics and timing properties of accreting black holes.

</details>


### [17] [Vanishing Compactness Gap and Fermionic Compact Dark Matter in Hořava-Lifshitz Gravity](https://arxiv.org/abs/2601.18079)
*Edwin J. Son,Kyungmin Kim,John J. Oh*

Main category: gr-qc

TL;DR: 在Hořava-Lifshitz引力中，黑洞与中子星之间的致密性差距可能消失，使得LIGO-Virgo-KAGRA观测到的低质量间隙天体难以分类为黑洞或中子星。


<details>
  <summary>Details</summary>
Motivation: 研究Hořava-Lifshitz引力中黑洞与中子星致密性差距的变化，探讨引力波观测中低质量间隙天体的分类问题。

Method: 在Hořava-Lifshitz引力框架下，采用费米子状态方程，求解Tolman-Oppenheimer-Volkoff方程。

Result: 存在最小费米子质量m_f^(min)(q,y)，超过该质量时黑洞与费米子致密天体的致密性差距消失；发现质量约40 GeV的费米子可形成质量约10^-4太阳质量、半径约1米的高度致密天体，可能作为冷暗物质候选体。

Conclusion: Hořava-Lifshitz引力中黑洞与中子星的致密性差距可能消失，使得引力波观测中的低质量间隙天体分类变得困难，同时提出了新的暗物质候选体可能性。

Abstract: We show that the gap in the compactness between black holes and neutron stars witnessed in general relativity may be vanishing in Hořava-Lifshitz (HL) gravity. Assuming a fermion equation-of-state for simplicity, and solving the Tolman-Oppenheimer-Volkoff equation within the HL gravity framework, we see that there exists a minimum fermion mass $m_f^\text{(min)}(q,y)$, above which the gap of the compactness between black hole and fermionic compact object vanishes, for a given deformation parameter $q$ of HL and interaction strength $y$ between fermions. Thus, in HL gravity, the mass and radius of an object found in the lower mass gap by LIGO-Virgo-KAGRA observations might not be able to classify it as a black hole or a neutron star. It is interesting to note that a fermion of mass $\sim 40\ \text{GeV}$ can form a highly compact object of mass $\sim 10^{-4}\ \msun$ and radius $\sim 1\ \text{m}$ that may play the role of the cold dark matter. In addition, we find the possible existence of another class of compact objects whose compactness is comparable to that of a black hole.

</details>


### [18] [Static stable timelike circular orbits and Aschenbach effect in horizonless solutions of Einstein cubic gravity](https://arxiv.org/abs/2601.18122)
*Zhen-Hua Zhao,Yong-Qiang Wang*

Main category: gr-qc

TL;DR: 在爱因斯坦立方引力理论描述的视界致密天体时空中，存在静止的稳定类时圆轨道，这些轨道同时是最内稳定圆轨道，形成不受多普勒效应影响的环状结构，并呈现Aschenbach效应。


<details>
  <summary>Details</summary>
Motivation: 研究爱因斯坦立方引力理论中无视界致密天体时空的轨道特性，探索与传统黑洞不同的轨道行为，特别是静止稳定轨道的存在及其观测意义。

Method: 在爱因斯坦立方引力理论框架下分析无视界致密天体的时空几何，计算类时圆轨道的稳定性条件，研究轨道速度的径向依赖关系，并分析稳定轨道区域的连续性。

Result: 发现静态稳定类时圆轨道的存在，这些轨道同时是最内稳定圆轨道；轨道速度呈现非单调的Aschenbach效应；稳定轨道区域可能不连续；中心附近稳定轨道粒子能量可大于1。

Conclusion: 爱因斯坦立方引力理论中的无视界致密天体展现出独特的轨道特性，包括静止稳定轨道、Aschenbach效应和不连续的稳定区域，这些特征可能产生独特的观测信号。

Abstract: In the spacetime of horizonless compact objects described by Einsteinian cubic gravity (ECG), we demonstrate the existence of static stable timelike circular orbits on which massive particles remain at rest relative to distant observers. These static orbits are further identified as the innermost stable circular orbits (ISCOs) in this spacetime. If such static orbits form part of an accretion disk, they would give rise to a ring-like structure that is unaffected by Doppler shifts. Moreover, the Aschenbach effect is shown to be present: the orbital velocity of particles on timelike circular orbits, as measured by a zero angular momentum observer (ZAMO), displays a non-monotonic dependence on the radial coordinate. Additionally, the regions supporting stable circular orbits can be discontinuous, and particles on stable orbits near the center can possess specific energies greater than one ($E > 1$).

</details>


### [19] [Rotating black holes in the Hernquist galactic halo and its accretion disk luminosity](https://arxiv.org/abs/2601.18176)
*Malihe Heydari-Fard,Mohaddese Heydari-Fard*

Main category: gr-qc

TL;DR: 该论文通过Newman-Janis算法构建了在Hernquist型暗物质晕中的旋转黑洞（Cardoso黑洞）度规，并研究了其吸积盘的电磁特性，发现暗物质对吸积盘性质影响不显著。


<details>
  <summary>Details</summary>
Motivation: 研究暗物质晕中的旋转黑洞（Cardoso黑洞）的吸积盘特性，探索暗物质对黑洞吸积过程的影响，并与无暗物质的Kerr黑洞进行比较。

Method: 使用Newman-Janis算法从静态球对称Cardoso黑洞度规构造旋转黑洞度规；采用稳态Novikov-Thorne模型分析薄吸积盘的电磁特性；研究自旋参数和晕致密参数对吸积盘性质的影响。

Result: 暗物质对吸积盘性质影响不显著；对于大自旋参数的天体物理黑洞，旋转Cardoso黑洞与Kerr黑洞的区分变得更加困难。

Conclusion: 暗物质晕的存在对黑洞吸积盘性质影响有限，特别是对于高自旋黑洞，这使得通过吸积盘观测区分暗物质环境中的黑洞与标准Kerr黑洞更具挑战性。

Abstract: Static, spherically symmetric black holes immersed in a dark matter halo with a Hernquist-type density profile have been derived by Cardoso et. al. in Ref. \redcite{Cardoso:2021wlq}. Using the Newman-Janis algorithm, we construct the metric for a stationary and axially symmetric rotating black hole in this environment. Then, we obtain the electromagnetic properties of thin accretion disks around such rotating black holes by utilizing the steady-state Novikov-Thorne model, and study the effects of spin parameter and halo compactness parameter on the disk properties. Finally, by comparison the results of the rotating Cardoso black hole with that of Kerr black hole in the absence of dark matter, we find that the presence of dark matter can not significantly affect the disk properties and thus for astrophysical black holes with large spin parameter, the distinction of rotating Cardoso black holes becomes more difficult than the Kerr black hole.

</details>


### [20] [Critical collapse of a massive scalar field in semi-classical loop quantum gravity](https://arxiv.org/abs/2601.18191)
*Li-Jie Xin,Xiangdong Zhang*

Main category: gr-qc

TL;DR: 研究两种半经典圈量子引力框架下大质量标量场引力坍缩的临界现象，发现小质量参数产生II型临界现象（与广义相对论结果一致），大质量参数产生I型临界现象，表明圈量子引力修正对临界坍缩动力学影响可忽略


<details>
  <summary>Details</summary>
Motivation: 探索在两种不同的半经典圈量子引力方法下，球形对称大质量标量场引力坍缩过程中的临界现象，检验圈量子引力修正对临界坍缩动力学的影响

Method: 在球形对称条件下，采用两种不同的半经典圈量子引力方法，对大质量标量场的引力坍缩进行数值模拟，分析不同质量参数下的临界行为

Result: 数值模拟显示：1）小质量参数时出现II型临界现象，回波周期和临界指数与广义相对论结果精确匹配；2）大质量参数时出现I型临界现象，形成具有有限最小质量的黑洞；3）两种半经典圈量子引力框架下结果一致

Conclusion: 半经典圈量子引力修正对临界坍缩动力学的影响可以忽略，临界现象的类型和特征参数主要由标量场的质量参数决定，与经典广义相对论预测一致

Abstract: We investigate critical phenomena during the gravitational collapse of a massive scalar field under two distinct semi-classical loop quantum gravity (LQG) approaches within spherical symmetry. Numerical simulations reveal that the massive scalar field in both semi-classical frameworks exhibits two distinct types of critical behavior, consistent with the classical scenario. When the scalar field's mass parameter is small, type II critical phenomena emerge, with the resulting echoing periods and critical exponents precisely matching those obtained in general relativity. In contrast, a large mass parameter triggers type I critical phenomena, where the resulting black holes possess a finite minimum mass. These findings suggest that semi-classical corrections from LQG have a negligible impact on the dynamics of critical collapse.

</details>


### [21] [Gluing different gravitational models: $f(R)$ case](https://arxiv.org/abs/2601.18205)
*Amin Aalipour,Nima Khosravi*

Main category: gr-qc

TL;DR: 本文系统推导了不同f(R)引力理论在非零超曲面上连接的连接条件，证明了当连接两个不同的f(R)理论时，需要∂f(R)/∂R和外曲率K_{μν}连续，而允许Ricci标量R不连续。


<details>
  <summary>Details</summary>
Motivation: 研究不同f(R)引力理论在界面处的连接条件，为构建复合引力模型提供理论基础，并比较与爱因斯坦引力连接条件的差异。

Method: 使用变分方法系统推导一般f(R)理论和爱因斯坦引力特例的连接条件，通过共形变换处理约旦框架和爱因斯坦框架的等价性。

Result: 推导出连接两个不同f(R)理论时，需要∂f(R)/∂R和外曲率K_{μν}连续，Ricci标量R可以不连续，并建立了连接条件与理论函数形式之间的具体关系。

Conclusion: 不同f(R)理论可以在满足特定函数形式和几何量关系的条件下一致地连接，这为构建更复杂的引力模型提供了数学基础。

Abstract: This paper presents a comprehensive analysis of junction conditions for gluing different $f(R)$ gravitational theories across a non-null hypersurface. Using the variational approach, we systematically derive the junction conditions for both general $f(R)$ theories and the special case of Einstein gravity, for comparison. We demonstrate that when joining two distinct $f(R)$ theories, the junction conditions require continuity of $\partial f(R)/\partial R$, the extrinsic curvature $K_{μν}$, while allowing for discontinuities in the Ricci Scalar $R$. Furthermore, we establish the equivalence between Jordan and Einstein frame formulations through careful treatment of conformal transformations; Our results reveal that different $f(R)$ theories can be consistently matched provided specific relations between their functional forms and geometric quantities are satisfied at the interface.

</details>


### [22] [Complexity and structure scalars of Type II matter fields](https://arxiv.org/abs/2601.18283)
*Samarjit Chakraborty,Rituparno Goswami,Sunil D. Maharaj*

Main category: gr-qc

TL;DR: 本文采用半四元协变方法分析广义Vaidya时空中Type II流体的结构标量，建立了1+1+2协变量与结构标量的关系，计算了复杂度因子，并研究了结构标量的传播演化方程。


<details>
  <summary>Details</summary>
Motivation: 研究广义Vaidya时空中Type II流体结构标量的性质，探索复杂度因子与Misner-Sharp质量的关系，比较Type I和Type II物质场的复杂度差异，分析结构标量的动力学行为。

Method: 采用半四元协变方法，建立1+1+2协变量与结构标量的关系，通过Misner-Sharp质量和物质变量计算复杂度因子，推导结构标量的传播和演化方程，研究高斯曲率的因果波动方程。

Result: 获得了复杂度因子与Misner-Sharp质量的关系，发现了一类具有零复杂度的非平凡时空，纯Type II物质场的Vaidya时空具有负复杂度，揭示了Type I和Type II物质场复杂度的差异，建立了结构标量与运动学变量的相互依赖关系。

Conclusion: 本文系统分析了广义Vaidya时空中Type II流体的结构标量，建立了完整的理论框架，揭示了复杂度因子的物理意义，为理解不同类型物质场的时空结构提供了新见解。

Abstract: A general semi-tetrad covariant approach is adopted to analyse the structure scalars of a Type II fluid in generalized Vaidya spacetime. The relationship between the $1+1+2$ covariant quantities and the structure scalars are obtained. We calculate the complexity factor in terms of the Misner-Sharp mass and the matter variables to obtain a non-trivial class of spacetimes with vanishing complexity. Also the Vaidya spacetime with pure Type II matter field has negative complexity. The differences between the complexity of Type I and Type II matter fields are highlighted. We compute the propagation and evolution equations of the structure scalars, showcasing their interdependency through the kinematical variables. The causal wave equation of the Gaussian curvature of the 2-shell and its dependence on the structure scalars are also studied.

</details>


### [23] [Physical Features of Geometrically Deformed Anisotropic Charged Three-dimensional BTZ Black Holes](https://arxiv.org/abs/2601.18367)
*Z. Yousaf,Kazuharu Bamba,Mansoor Alshehri,S. Khan,M. Z. Bhatti*

Main category: gr-qc

TL;DR: 使用最小几何形变解耦方案，在三维带电BTZ度规作为种子度规的背景下推导恒星内部解，通过两种状态方程确定形变函数和新物质贡献，分析形变参数和总电荷对热力学量的影响。


<details>
  <summary>Details</summary>
Motivation: 研究三维引力中的带电致密分布，通过几何形变解耦方法探索新的恒星内部解，分析低维度下自由度较少时的量子效应。

Method: 采用最小几何形变解耦方案，以带电BTZ度规作为种子度规，施加两种不同的状态方程来确定形变函数和额外场源产生的新物质贡献。

Result: 推导出所有热力学量（包括有效热力学量）在形变参数和总电荷变化下保持有限的新恒星内部解，展示了通过任何已知三维时空作为各向同性基础构建物理可接受解的可能性。

Conclusion: 几何形变解耦方法在三维带电致密分布背景下有效，能够产生物理可接受的恒星内部解，为分析低维度量子效应提供了新途径。

Abstract: This work employs the minimal geometric deformation decoupling scheme to derive interior stellar solutions in the background of an electrically charged BTZ ansatz as a seed metric in three dimensions. In this respect, we impose two different equations of state to determine the deformation function and the new material contributions emerging from the additional field source. Furthermore, we describe the finiteness of all thermodynamic quantities of the presented stellar solutions, including the effective thermodynamical quantities, for varying values of the deformation parameter and total electric charge. We explore the new interior astrophysical solutions in three-dimensional gravity by analyzing the charged BTZ metric, admitting circular symmetry through the principles of geometric deformation. This study examines the impact of radial-metric deformation on the charged BTZ geometry and underscores the importance of stellar decoupling within the context of electrically charged dense distributions. It is shown that new physically acceptable solutions by incorporating any known three-dimensional spacetime as the isotropic basis are possible, which in turn enable one to analyze the quantum effects due to low degrees of freedom at lower dimensions.

</details>


### [24] [Assessing astrophysical foreground subtraction in DECIGO using compact binary populations inferred from the first part of the LIGO-Virgo-KAGRA's fourth observation run](https://arxiv.org/abs/2601.18378)
*Takahiro S. Yamamoto*

Main category: gr-qc

TL;DR: DECIGO需要检测宇宙膨胀时期的随机引力波背景，但0.1Hz频段被致密双星系统的引力波主导。本文评估了基于LVK最新观测数据构建的种群模型来扣除这些双星信号的可行性，发现需要采用Cutler & Harms (2005)提出的投影方案才能将双星信号降低到足以探测原初背景的水平。


<details>
  <summary>Details</summary>
Motivation: DECIGO的主要科学目标之一是探测宇宙膨胀时期的随机引力波背景，但在其敏感的0.1Hz频段，致密双星系统（如黑洞、中子星双星）的引力波信号占主导地位。为了探测原初随机引力波背景，必须首先扣除这些天体物理源的信号。

Method: 基于LIGO-Virgo-KAGRA合作组织最新引力波事件目录推断的种群模型，评估扣除双星信号的可行性。特别采用了Cutler & Harms (2005)提出的投影方案来减少双星信号的干扰。

Result: 研究发现，为了将双星信号降低到DECIGO能够探测原初随机引力波背景的水平，必须采用投影方案。这表明单纯依靠种群模型进行信号扣除是不够的，需要更先进的信号处理技术。

Conclusion: DECIGO探测原初随机引力波背景需要采用投影方案来有效扣除致密双星系统的引力波信号，基于LVK观测数据的种群模型分析证实了这一必要性。

Abstract: Detecting the stochastic gravitational wave background (SGWB) from our Universe under the inflationary era is one of the primary scientific objectives of DECIGO, a space-borne gravitational wave detector sensitive in the 0.1 Hz frequency band. This frequency band is dominated by the gravitational waves from inspiraling compact object binaries. Subtracting these signals is necessary to search for the primordial SGWB. In this paper, we assess the feasibility of the subtraction of such binary signals by employing the population model inferred from the latest gravitational wave event catalogue of the LIGO-Virgo-KAGRA Collaboration. We find that the projection scheme, which was originally proposed by Cutler & Harms (2005), is necessary to reduce the binary signals to the level where DECIGO can detect the primordial background.

</details>


### [25] [Time-reversed Shannon entropy as a chaos indicator for non-integrable systems](https://arxiv.org/abs/2601.18422)
*Wenfu Cao,Siyan Chen,Hongsheng Zhang*

Main category: gr-qc

TL;DR: 提出了一种新的混沌指标——时间反演香农熵（TRSE），通过量化粒子轨道正向和反向时间演化之间的统计差异，在弯曲时空中区分混沌和规则动力学。


<details>
  <summary>Details</summary>
Motivation: 在广义相对论系统中，特别是在非可积系统中，需要更有效的混沌检测方法来理解动力学行为。传统方法在弯曲时空中可能不够鲁棒，因此需要开发基于时间反演对称性破缺和信息熵的新指标。

Method: 提出时间反演香农熵（TRSE）作为混沌指标，量化正向和反向时间演化概率分布的统计差异。同时改进了先前提出的粒子对互信息（MIPP）方法。在Kerr和Schwarzschild-Melvin黑洞几何中进行高精度数值模拟，对轨迹进行正向和反向时间演化。

Result: TRSE能够鲁棒地区分混沌和规则动力学。在可积系统中，概率分布保持稳定对称（如Carter常数守恒）；在非可积系统中，TRSE检测到时间反演对称性破缺。MIPP和TRSE在参数空间扫描中显示出强定量一致性，两者互为补充。

Conclusion: TRSE和MIPP共同建立了一个统一的框架来诊断广义相对论系统中的混沌。TRSE捕捉轨道演化中的对称性破缺，MIPP测量统计相关性。这一方法为理解非可积系统中混沌的基本性质开辟了新途径。

Abstract: We propose a novel chaos indicator -- time-reversed Shannon entropy (TRSE) -- that leverages the interplay between time-reversal symmetry breaking and information entropy in curved spacetimes. By quantifying statistical discrepancies between forward and backward temporal evolution of particle orbits, TRSE robustly distinguishes chaotic from regular dynamics in non-integrable systems. In contrast, integrable systems exhibit stable, symmetric probability distributions preserved by conserved quantities such as the Carter constant. We validate the method through high-precision numerical simulations in both Kerr and Schwarzschild-Melvin black hole geometries, evolving trajectories forward and backward in time. Furthermore, we refine our previously introduced particle-pair mutual information (MIPP) and perform comprehensive parameter-space scans, revealing a strong quantitative agreement between MIPP and TRSE. The two indicators emerge as complementary probes of chaos: TRSE captures symmetry breaking in orbital evolution, while MIPP measures statistical correlations. Together, they establish a unified framework for diagnosing chaos in general relativistic systems, paving a new path to understand the fundamental nature of chaos in non-integrable systems.

</details>


### [26] [Study of dynamical systems and large-scale structure](https://arxiv.org/abs/2601.18466)
*Dumiso Mithi,Saikat Charkraborty,Shambel Sahlu,Amare Abebe*

Main category: gr-qc

TL;DR: 使用动力系统方法分析大尺度结构，研究暗物质与暗能量之间的线性和非线性相互作用模型，基于QCD Veneziano ghost理论启发的动态暗能量模型。


<details>
  <summary>Details</summary>
Motivation: 研究暗物质和暗能量之间的相互作用机制，探索基于量子色动力学Veneziano ghost理论的动态暗能量模型在大尺度结构形成中的理论可行性。

Method: 采用动力系统方法，建立线性和非线性相互作用模型，定义无量纲参数，推导自治方程，计算雅可比矩阵的迹和行列式，分析固定点稳定性。

Result: 发现存在不稳定、鞍点和稳定固定点，分别对应辐射主导、物质主导和暗能量主导时期，表明这些模型在理论上能够描述暗物质与暗能量之间的相互作用。

Conclusion: 基于QCD Veneziano ghost理论的动态暗能量模型在描述暗物质与暗能量相互作用方面具有理论可行性，能够再现宇宙演化不同阶段的主导机制。

Abstract: In this study, we employ dynamical systems methods to analyse the large-scale structure by considering two distinct interaction models (linear and non-linear) within the dark sector, associated with a specific dynamical dark energy model inspired by the Veneziano ghost theory in quantum chromodynamics (QCD). In these models, the dark energy density ($ρ_{DE}$) varies with the Hubble parameter ($H$), expressed as $ρ_{DE} = αH + βH^2$. After defining the dimensionless parameters, we present autonomous equations that allow us to find the trace $\text{Tr}(J)$ and the determinant $D(J)$. With these solutions, we demonstrate the presence of unstable, saddle, and stable fixed points, corresponding to the radiation-, matter-, and dark-energy-dominated eras, respectively. Our results suggest that these models are theoretically viable for representing the interaction between dark sector fluids.

</details>


### [27] [Gravitational Lorentz-violating $e^-+e^+\to\ell^-+\ell^+$ scattering](https://arxiv.org/abs/2601.18523)
*L. A. S. Evangelista,A. F. Santos*

Main category: gr-qc

TL;DR: 在引力电动力学框架下研究电子-正电子散射过程，考虑洛伦兹破坏和热效应的影响


<details>
  <summary>Details</summary>
Motivation: 研究引力相互作用中的洛伦兹破坏效应和热修正，特别是在高能或天体物理环境中，这些效应可能变得显著

Method: 采用引力电动力学（引力的弱场近似）框架，考虑标准模型扩展中的非最小引力扇区，使用热场动力学形式处理有限温度效应，计算散射截面的修正

Result: 计算了零温度和有限温度下引力散射过程的洛伦兹破坏修正，获得了散射截面的修正表达式

Conclusion: 洛伦兹破坏和热效应对引力相互作用有重要影响，这些结果对于理解高能或天体物理环境中的引力过程具有重要意义

Abstract: We investigate the gravitational $e^-+e^+\to\ell^-+\ell^+$ scattering process within the framework of gravitoelectromagnetism, a weak-field approximation of gravity analogous to Maxwell's theory of electromagnetism. This process involves the interaction between a fermion and an antifermion mediated by graviton exchange. We consider the nonminimal gravitational sector of the standard model extension and calculate the corrections to the scattering cross section arising from Lorentz violation. The analysis is carried out in two scenarios: (i) at zero temperature and (ii) at finite temperature. To incorporate thermal effects, we employ the thermo field dynamics formalism, which allows for a consistent treatment of quantum fields at finite temperature. The results provide insights into how Lorentz-violating and thermal corrections influence gravitational interactions, particularly relevant in high-energy or astrophysical environments.

</details>


### [28] [Correspondence between quasinormal modes and grey-body factors of Schwarzschild--Tangherlini black holes](https://arxiv.org/abs/2601.18613)
*Hyewon Han,Bogeun Gwak*

Main category: gr-qc

TL;DR: 研究高维Schwarzschild-Tangherlini黑洞的准正规模与灰体因子之间的对应关系，分析不同维度、不同扰动类型下的对应精度，发现D≥7维中l=2标量引力扰动对应关系失效的原因。


<details>
  <summary>Details</summary>
Motivation: 探索高维黑洞引力扰动的准正规模与灰体因子之间的对应关系，理解这种对应关系在不同维度和不同扰动类型下的适用性，特别是识别对应关系失效的情况及其物理原因。

Method: 将高维黑洞引力扰动分为标量、矢量和张量类型，考虑维度相关的有效势形式。采用连分式法和中点积分法计算精确准正规模，通过对应关系获得灰体因子，并与数值计算的灰体因子比较分析精度。

Result: 在D≥7维中，l=2标量引力扰动的准正规模与灰体因子对应关系失效，原因是势垒结构显著不同于四维情况。矢量和张量扰动在所有情况下都表现出良好的对应精度。对应关系的失效被严格证明源于多重势垒的存在。

Conclusion: 准正规模与灰体因子的对应关系在高维黑洞中具有模式依赖性，对于矢量和张量扰动普遍适用，但对于某些标量扰动在特定维度下会因势垒结构变化而失效，这为理解高维黑洞的扰动特性提供了重要见解。

Abstract: We investigate the correspondence between the quasinormal modes and grey-body factors of Schwarzschild--Tangherlini black holes. The gravitational perturbations in higher-dimensional black holes can be classified into scalar, vector, and tensor types. Considering the dimension-dependent forms of their effective potentials, the correspondence was examined for each dimension and perturbation mode. The accurate quasinormal modes were computed by suitably adopting the continued fraction and integration-through-midpoints methods, depending on the structure of the singularity. The grey-body factor can be obtained through its correspondence with the quasinormal mode, and its accuracy was analyzed by calculating its difference from the numerically computed grey-body factor. The correspondence failed for $l=2$ scalar gravitational perturbations in $D\ge7$ because the form of the potential is markedly different from that in four dimensions. The vector and tensor perturbation types exhibited good correspondence accuracies in all cases. The breakdown of the correspondence was rigorously demonstrated to stem from multiple potential barriers, and its applicability to each mode in higher dimensions was assessed.

</details>


### [29] [Quantum gravitational stellar evolution beyond shell-crossing singularities](https://arxiv.org/abs/2601.18618)
*Michał Bobula,Francesco Fazzini*

Main category: gr-qc

TL;DR: 本文提出了一种基于哈密顿形式的Darmois-Israel连接条件的方法，用于延伸受圈量子引力启发的恒星坍缩模型中出现的壳交叉奇点，将奇点视为非孤立薄尘埃壳，从而构建出星际虫洞。


<details>
  <summary>Details</summary>
Motivation: 受圈量子引力启发的有效恒星坍缩模型预测当恒星能量密度达到普朗克尺度时会发生反弹，但随后通常形成壳交叉奇点。这些奇点阻碍了时空的进一步延伸，需要找到一种方法来超越这些奇点。

Method: 采用哈密顿形式的Darmois-Israel连接条件，将壳交叉奇点视为非孤立薄尘埃壳进行处理。通过构造，无论初始恒星质量如何，壳的运动在整个演化过程中都保持类时性，且壳上的诱导度量保持连续。

Result: 该方法成功延伸了壳交叉奇点后的时空，产生的恒星演化形成了一个星际虫洞，类似于更简单的Oppenheimer-Snyder情景。壳在整个演化过程中保持类时运动，诱导度量连续。

Conclusion: 提出的方法为任何以壳交叉奇点为特征的有效（或经典）恒星坍缩理论提供了一个通用框架，能够处理奇点并构建出星际虫洞结构。

Abstract: Models of effective stellar collapse inspired by loop quantum gravity predict a bounce when the stellar energy density reaches the Planck scale, typically followed by the formation of shell-crossing singularities. This work aims to extend the spacetime beyond these singularities by employing a Hamiltonian formulation of the Darmois-Israel junction conditions, treating the singularity as a non-isolated thin dust shell. By construction, the shell's motion remains timelike throughout the entire evolution, regardless of the amount of initial stellar mass, and the induced metric on the shell remains continuous. The resulting stellar evolution produces an inter-universal wormhole, analogous to the simpler Oppenheimer-Snyder scenario. The proposed approach provides a general framework for any effective (or classical) theory of stellar collapse characterized by shell-crossing singularities.

</details>


### [30] [Novikov Coordinates and the Physical Description of Gravitational Collapse](https://arxiv.org/abs/2601.18660)
*Jaume de Haro*

Main category: gr-qc

TL;DR: Novikov坐标可以通过Schwarzschild时空中负能量大质量粒子的径向测地线直接获得，这些测地线形成覆盖整个时空的完整汇。使用固有时作为时间坐标，Novikov变量自然出现，为通常被识别为黑洞和白洞扇区的不同区域提供了清晰的动力学解释。


<details>
  <summary>Details</summary>
Motivation: 论文旨在提供一种更直接、物理上更透明的方法来理解Novikov坐标，澄清Schwarzschild-Droste坐标中观测到的无限时间坍缩现象实际上是坐标人工产物，而非物理效应。

Method: 通过研究Schwarzschild时空中负能量大质量粒子的径向测地线，这些测地线形成覆盖整个时空的完整汇。使用固有时作为时间坐标来"拉直"这族轨迹，从而自然导出Novikov变量。

Result: Novikov坐标中的观测者在固定空间位置跟随自由落体轨迹。从他们的视角看，尘埃星的引力坍缩在有限固有时内完成，与初始距离无关。而Schwarzschild-Droste坐标中的观测者感知到坍缩星边界需要无限坐标时间才能到达视界。

Conclusion: Schwarzschild-Droste观测者相对于星体质心是静态的，因此不能处于自由落体状态。使用这些坐标隐含需要存在一个力来补偿引力吸引。从这个角度看，表观的无限时间坍缩不是物理效应，而是与非惯性观测者相关的坐标人工产物。

Abstract: We show that the Novikov coordinates can be obtained in a direct and physically transparent way from the radial geodesics of massive particles with negative energy in the Schwarzschild spacetime. These geodesics form a complete congruence that covers the entire spacetime. By rectifying this family of trajectories using the proper time as the time coordinate, the Novikov variables naturally emerge, providing a clear dynamical interpretation of the different regions usually identified as black-hole and white-hole sectors.
  In Novikov coordinates, observers at fixed spatial position follow free-fall trajectories. From their perspective, the gravitational collapse of a dust star is completed in a finite proper time, independently of their initial distance from the star. In contrast, observers described by Schwarzschild-Droste coordinates perceive the boundary of the collapsing star as taking an infinite coordinate time to reach the horizon.
  We emphasize that Schwarzschild-Droste observers are static with respect to the center of mass of the star and therefore cannot be in free fall. The use of these coordinates implicitly requires the presence of a force that compensates the gravitational attraction. From this viewpoint, the apparent infinite-time collapse is not a physical effect but a coordinate artifact associated with non-inertial observers.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [31] [TelcoAI: Advancing 3GPP Technical Specification Search through Agentic Multi-Modal Retrieval-Augmented Generation](https://arxiv.org/abs/2601.16984)
*Rahul Ghosh,Chun-Hao Liu,Gaurav Rele,Vidya Sagar Ravipati,Hazar Aouad*

Main category: cs.LG

TL;DR: TelcoAI：针对3GPP技术规范的智能多模态RAG系统，通过智能分块、查询规划和多模态融合，显著提升技术文档理解能力


<details>
  <summary>Details</summary>
Motivation: 3GPP技术规范结构复杂、格式密集且包含多模态内容，现有方法难以处理复杂查询、视觉信息和文档间依赖关系，需要专门解决方案

Method: 提出TelcoAI系统，采用基于章节的分块策略、结构化查询规划、元数据引导检索以及文本与图表的跨模态融合技术

Result: 在多个基准测试中达到87%召回率、83%声明召回率和92%忠实度，相比现有最佳方法提升16%

Conclusion: TelcoAI证明了智能代理和多模态推理在技术文档理解中的有效性，为电信研究和工程提供了实用的解决方案

Abstract: The 3rd Generation Partnership Project (3GPP) produces complex technical specifications essential to global telecommunications, yet their hierarchical structure, dense formatting, and multi-modal content make them difficult to process. While Large Language Models (LLMs) show promise, existing approaches fall short in handling complex queries, visual information, and document interdependencies. We present TelcoAI, an agentic, multi-modal Retrieval-Augmented Generation (RAG) system tailored for 3GPP documentation. TelcoAI introduces section-aware chunking, structured query planning, metadata-guided retrieval, and multi-modal fusion of text and diagrams. Evaluated on multiple benchmarks-including expert-curated queries-our system achieves $87\%$ recall, $83\%$ claim recall, and $92\%$ faithfulness, representing a $16\%$ improvement over state-of-the-art baselines. These results demonstrate the effectiveness of agentic and multi-modal reasoning in technical document understanding, advancing practical solutions for real-world telecommunications research and engineering.

</details>


### [32] [Sparsity-Aware Low-Rank Representation for Efficient Fine-Tuning of Large Language Models](https://arxiv.org/abs/2601.16991)
*Longteng Zhang,Sen Wu,Shuai Hou,Zhengyu Qing,Zhuo Zheng,Danning Ke,Qihong Lin,Qiang Wang,Shaohuai Shi,Xiaowen Chu*

Main category: cs.LG

TL;DR: SALR是一种新的微调范式，通过将低秩适应与稀疏剪枝结合，在保持LoRA性能的同时实现50%稀疏度、2倍模型压缩和1.7倍推理加速。


<details>
  <summary>Details</summary>
Motivation: 大型预训练语言模型在下游任务微调时需要调整数百万参数或部署昂贵的密集权重更新，这在资源受限环境中难以应用。LoRA减少了可训练参数，但底层密集权重仍带来高存储和计算成本。基于幅度的剪枝可以获得稀疏模型，但直接应用于LoRA会降低性能。

Method: 提出SALR（稀疏感知低秩表示），在均方误差框架下统一低秩适应与稀疏剪枝。静态剪枝冻结的基础权重以最小化剪枝误差边界，通过截断SVD低秩适配器恢复丢弃的残差信息。采用多低秩适配器融合为单个GEMM，并使用基于位图的编码和两阶段流水线解码+GEMM设计。

Result: 在多种LLM上实现50%稀疏度，在GSM8K和MMLU任务上性能与LoRA相当，模型大小减少2倍，推理速度提升最高达1.7倍。

Conclusion: SALR提供了一种有效的微调范式，能够在保持性能的同时显著减少模型存储和计算需求，适用于资源受限环境。

Abstract: Adapting large pre-trained language models to downstream tasks often entails fine-tuning millions of parameters or deploying costly dense weight updates, which hinders their use in resource-constrained environments. Low-rank Adaptation (LoRA) reduces trainable parameters by factorizing weight updates, yet the underlying dense weights still impose high storage and computation costs. Magnitude-based pruning can yield sparse models but typically degrades LoRA's performance when applied naively. In this paper, we introduce SALR (Sparsity-Aware Low-Rank Representation), a novel fine-tuning paradigm that unifies low-rank adaptation with sparse pruning under a rigorous mean-squared-error framework. We prove that statically pruning only the frozen base weights minimizes the pruning error bound, and we recover the discarded residual information via a truncated-SVD low-rank adapter, which provably reduces per-entry MSE by a factor of $(1 - r/\min(d,k))$. To maximize hardware efficiency, we fuse multiple low-rank adapters into a single concatenated GEMM, and we adopt a bitmap-based encoding with a two-stage pipelined decoding + GEMM design to achieve true model compression and speedup. Empirically, SALR attains 50\% sparsity on various LLMs while matching the performance of LoRA on GSM8K and MMLU, reduces model size by $2\times$, and delivers up to a $1.7\times$ inference speedup.

</details>


### [33] [A Dataset of Dengue Hospitalizations in Brazil (1999 to 2021) with Weekly Disaggregation from Monthly Counts](https://arxiv.org/abs/2601.16994)
*Lucas M. Morello,Matheus Lima Castro,Pedro Cesar M. G. Camargo,Liliane Moreira Nery,Darllan Collins da Cunha e Silva,Leopoldo Lusquino Filho*

Main category: cs.LG

TL;DR: 该论文发布了一个巴西市级登革热住院时间序列数据集，将原始月度数据通过三次样条插值法分解为周度分辨率，并包含多种解释变量，用于流行病学预测的AI模型训练。


<details>
  <summary>Details</summary>
Motivation: 为了提升AI模型在流行病学预测中的训练效果，需要将原始月度数据的时间粒度增加到周度分辨率。现有数据的时间分辨率不足限制了预测模型的准确性。

Method: 采用三次样条插值法将市级登革热住院月度时间序列分解为流行病学周度数据，通过校正步骤保持月度总量不变。使用圣保罗州的高分辨率参考数据集验证了分解方法的有效性。

Result: 三次样条插值法在三种策略（线性插值、抖动、三次样条）中表现出最高的参考数据贴合度，因此被采用来生成1999-2021年期间的周度序列。数据集包含住院时间序列和多种解释变量。

Conclusion: 该研究成功创建了一个高质量的周度分辨率登革热住院数据集，为多变量时间序列分析、环境健康研究和机器学习模型开发提供了重要资源，特别适用于疫情爆发的预测建模。

Abstract: This data paper describes and publicly releases this dataset (v1.0.0), published on Zenodo under DOI 10.5281/zenodo.18189192. Motivated by the need to increase the temporal granularity of originally monthly data to enable more effective training of AI models for epidemiological forecasting, the dataset harmonizes municipal-level dengue hospitalization time series across Brazil and disaggregates them to weekly resolution (epidemiological weeks) through an interpolation protocol with a correction step that preserves monthly totals. The statistical and temporal validity of this disaggregation was assessed using a high-resolution reference dataset from the state of Sao Paulo (2024), which simultaneously provides monthly and epidemiological-week counts, enabling a direct comparison of three strategies: linear interpolation, jittering, and cubic spline. Results indicated that cubic spline interpolation achieved the highest adherence to the reference data, and this strategy was therefore adopted to generate weekly series for the 1999 to 2021 period. In addition to hospitalization time series, the dataset includes a comprehensive set of explanatory variables commonly used in epidemiological and environmental modeling, such as demographic density, CH4, CO2, and NO2 emissions, poverty and urbanization indices, maximum temperature, mean monthly precipitation, minimum relative humidity, and municipal latitude and longitude, following the same temporal disaggregation scheme to ensure multivariate compatibility. The paper documents the datasets provenance, structure, formats, licenses, limitations, and quality metrics (MAE, RMSE, R2, KL, JSD, DTW, and the KS test), and provides usage recommendations for multivariate time-series analysis, environmental health studies, and the development of machine learning and deep learning models for outbreak forecasting.

</details>


### [34] [Physics-Informed Uncertainty Enables Reliable AI-driven Design](https://arxiv.org/abs/2601.18638)
*Tingkai Xue,Chin Chun Ooi,Yang Jiang,Luu Trung Pham Duong,Pao-Hsiung Chiu,Weijiang Zhao,Nagarajan Raghavan,My Ha Dao*

Main category: cs.LG

TL;DR: 提出物理信息不确定性作为预测不确定性的替代度量，将其融入多保真度优化流程，显著提升频率选择表面设计的成功率和计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统基于深度学习的代理优化方法通常缺乏不确定性量化，导致在数据稀疏区域产生错误预测，从而影响优化性能。需要一种能有效量化预测不确定性的方法。

Method: 提出物理信息不确定性范式，利用模型预测违反基本物理定律的程度作为预测不确定性的计算廉价且有效的代理指标。将此方法集成到多保真度不确定性感知优化工作流中。

Result: 在20-30 GHz频率选择表面设计中，将找到高性能解决方案的成功率从不到10%提升到超过50%，同时相比仅使用高保真求解器将计算成本降低一个数量级。

Conclusion: 物理信息不确定性是物理系统代理模型中量化不确定性的可行替代方案，为能够高效稳健探索和评估候选设计的自主科学发现系统奠定了基础。

Abstract: Inverse design is a central goal in much of science and engineering, including frequency-selective surfaces (FSS) that are critical to microelectronics for telecommunications and optical metamaterials. Traditional surrogate-assisted optimization methods using deep learning can accelerate the design process but do not usually incorporate uncertainty quantification, leading to poorer optimization performance due to erroneous predictions in data-sparse regions. Here, we introduce and validate a fundamentally different paradigm of Physics-Informed Uncertainty, where the degree to which a model's prediction violates fundamental physical laws serves as a computationally-cheap and effective proxy for predictive uncertainty. By integrating physics-informed uncertainty into a multi-fidelity uncertainty-aware optimization workflow to design complex frequency-selective surfaces within the 20 - 30 GHz range, we increase the success rate of finding performant solutions from less than 10% to over 50%, while simultaneously reducing computational cost by an order of magnitude compared to the sole use of a high-fidelity solver. These results highlight the necessity of incorporating uncertainty quantification in machine-learning-driven inverse design for high-dimensional problems, and establish physics-informed uncertainty as a viable alternative to quantifying uncertainty in surrogate models for physical systems, thereby setting the stage for autonomous scientific discovery systems that can efficiently and robustly explore and evaluate candidate designs.

</details>


### [35] [MathMixup: Boosting LLM Mathematical Reasoning with Difficulty-Controllable Data Synthesis and Curriculum Learning](https://arxiv.org/abs/2601.17006)
*Xuchen Li,Jing Chen,Xuzhao Li,Hao Liang,Xiaohuan Zhou,Taifeng Wang,Wentao Zhang*

Main category: cs.LG

TL;DR: MathMixup：通过混合与分解策略生成难度可控的数学推理问题，构建分级数据集并设计课程学习策略，显著提升LLMs数学推理能力


<details>
  <summary>Details</summary>
Motivation: 现有数学推理数据合成方法存在多样性有限、难度控制不精确的问题，难以支持课程学习等高效训练范式，需要系统化生成高质量、难度可控的数学问题

Method: 提出MathMixup数据合成范式，采用混合和分解策略系统生成难度可控的数学推理问题，结合自动自检和人工筛选确保语义清晰和难度梯度，构建MathMixupQA数据集并设计课程学习策略

Result: Qwen2.5-7B在7个数学基准测试中平均得分52.6%，超越先前SOTA方法，验证了MathMixup在提升LLMs数学推理能力和推进数据为中心课程学习方面的有效性

Conclusion: MathMixup通过系统化生成难度可控的高质量数学问题，结合课程学习策略，能显著提升LLMs的数学推理能力，为数据为中心的课程学习提供了有效解决方案

Abstract: In mathematical reasoning tasks, the advancement of Large Language Models (LLMs) relies heavily on high-quality training data with clearly defined and well-graded difficulty levels. However, existing data synthesis methods often suffer from limited diversity and lack precise control over problem difficulty, making them insufficient for supporting efficient training paradigms such as curriculum learning. To address these challenges, we propose MathMixup, a novel data synthesis paradigm that systematically generates high-quality, difficulty-controllable mathematical reasoning problems through hybrid and decomposed strategies. Automated self-checking and manual screening are incorporated to ensure semantic clarity and a well-structured difficulty gradient in the synthesized data. Building on this, we construct the MathMixupQA dataset and design a curriculum learning strategy that leverages these graded problems, supporting flexible integration with other datasets. Experimental results show that MathMixup and its curriculum learning strategy significantly enhance the mathematical reasoning performance of LLMs. Fine-tuned Qwen2.5-7B achieves an average score of 52.6\% across seven mathematical benchmarks, surpassing previous state-of-the-art methods. These results fully validate the effectiveness and broad applicability of MathMixup in improving the mathematical reasoning abilities of LLMs and advancing data-centric curriculum learning.

</details>


### [36] [Analysis of voice recordings features for Classification of Parkinson's Disease](https://arxiv.org/abs/2601.17007)
*Beatriz Pérez-Sánchez,Noelia Sánchez-Maroño,Miguel A. Díaz-Freire*

Main category: cs.LG

TL;DR: 该论文提出结合特征选择方法的机器学习模型用于帕金森病早期诊断，通过语音记录分析，发现神经网络模型表现良好，且特征数量可大幅减少而不影响性能。


<details>
  <summary>Details</summary>
Motivation: 帕金森病早期诊断困难，早期运动症状轻微。虽然语音记录分析有助于早期诊断，但临床分析成本高，且语音特征众多，不清楚哪些特征对诊断真正相关。

Method: 使用不同类型的机器学习模型结合特征选择方法，通过特征选择技术减少分类器使用的特征数量，确定哪些特征对问题提供最多信息。

Result: 机器学习方法（特别是神经网络）适合帕金森病分类，特征数量可以显著减少而不影响模型性能。

Conclusion: 机器学习结合特征选择方法可以有效用于帕金森病早期诊断，既能提高诊断效率又能降低临床分析成本。

Abstract: Parkinson's disease (PD) is a chronic neurodegenerative disease. Early diagnosis is essential to mitigate the progressive deterioration of patients' quality of life. The most characteristic motor symptoms are very mild in the early stages, making diagnosis difficult. Recent studies have shown that the use of patient voice recordings can aid in early diagnosis. Although the analysis of such recordings is costly from a clinical point of view, advances in machine learning techniques are making the processing of this type of data increasingly accurate and efficient. Vocal recordings contain many features, but it is not known whether all of them are relevant for diagnosing the disease.
  This paper proposes the use of different types of machine learning models combined with feature selection methods to detect the disease. The selection techniques allow to reduce the number of features used by the classifiers by determining which ones provide the most information about the problem. The results show that machine learning methods, in particular neural networks, are suitable for PD classification and that the number of features can be significantly reduced without affecting the performance of the models.

</details>


### [37] [Bayesian Robust Financial Trading with Adversarial Synthetic Market Data](https://arxiv.org/abs/2601.17008)
*Haochong Xia,Simin Li,Ruixiao Xu,Zhixia Zhang,Hongxiang Wang,Zhiqian Liu,Teng Yao Long,Molei Qin,Chuqiao Zong,Bo An*

Main category: cs.LG

TL;DR: 提出贝叶斯鲁棒框架，通过宏观条件GAN生成多样化市场数据，结合贝叶斯马尔可夫博弈学习鲁棒交易策略，在9种金融工具上超越9个SOTA基线


<details>
  <summary>Details</summary>
Motivation: 传统机器学习交易模型在样本内表现良好，但在真实市场制度变化时性能下降。主要问题：1）现有策略对高级市场波动的鲁棒性不足；2）缺乏真实多样的模拟训练环境导致策略过拟合

Method: 提出贝叶斯鲁棒框架：1）数据侧：使用宏观条件GAN生成器，以宏观经济指标为主要控制变量，合成具有真实时间、跨工具和宏观相关性的数据；2）策略侧：将交易过程建模为两人零和贝叶斯马尔可夫博弈，对抗代理通过扰动宏观指标模拟制度变化，交易代理通过分位数信念网络维护和更新隐藏市场状态信念，使用贝叶斯神经虚拟自博弈寻求鲁棒完美贝叶斯均衡

Result: 在9种金融工具上的广泛实验表明，该框架优于9个最先进的基线方法。在COVID等极端事件中，该方法显示出改进的盈利能力和风险管理能力

Conclusion: 该框架为不确定和变化的市场动态下的交易提供了可靠解决方案，通过系统整合宏观条件生成模型和鲁棒策略学习，解决了现有方法在真实市场制度变化时的性能退化问题

Abstract: Algorithmic trading relies on machine learning models to make trading decisions. Despite strong in-sample performance, these models often degrade when confronted with evolving real-world market regimes, which can shift dramatically due to macroeconomic changes-e.g., monetary policy updates or unanticipated fluctuations in participant behavior. We identify two challenges that perpetuate this mismatch: (1) insufficient robustness in existing policy against uncertainties in high-level market fluctuations, and (2) the absence of a realistic and diverse simulation environment for training, leading to policy overfitting. To address these issues, we propose a Bayesian Robust Framework that systematically integrates a macro-conditioned generative model with robust policy learning. On the data side, to generate realistic and diverse data, we propose a macro-conditioned GAN-based generator that leverages macroeconomic indicators as primary control variables, synthesizing data with faithful temporal, cross-instrument, and macro correlations. On the policy side, to learn robust policy against market fluctuations, we cast the trading process as a two-player zero-sum Bayesian Markov game, wherein an adversarial agent simulates shifting regimes by perturbing macroeconomic indicators in the macro-conditioned generator, while the trading agent-guided by a quantile belief network-maintains and updates its belief over hidden market states. The trading agent seeks a Robust Perfect Bayesian Equilibrium via Bayesian neural fictitious self-play, stabilizing learning under adversarial market perturbations. Extensive experiments on 9 financial instruments demonstrate that our framework outperforms 9 state-of-the-art baselines. In extreme events like the COVID, our method shows improved profitability and risk management, offering a reliable solution for trading under uncertain and shifting market dynamics.

</details>


### [38] [Optimizing the Landscape of LLM Embeddings with Dynamic Exploratory Graph Analysis for Generative Psychometrics: A Monte Carlo Study](https://arxiv.org/abs/2601.17010)
*Hudson Golino*

Main category: cs.LG

TL;DR: 该研究将大语言模型嵌入重构为可搜索的语义景观，通过动态探索图分析识别最优嵌入维度深度，发现不同指标（TEFI和NMI）在嵌入空间中存在竞争性优化轨迹，需要加权复合标准来平衡结构准确性和组织性。


<details>
  <summary>Details</summary>
Motivation: 当前心理学研究中将LLM嵌入作为静态、横截面表示，假设所有嵌入坐标均匀贡献，忽略了最优结构信息可能集中在嵌入空间特定区域的可能性。需要系统探索嵌入空间以找到最优维度深度。

Method: 将嵌入重构为可搜索景观，采用动态探索图分析（DynEGA），将维度索引视为伪时间顺序。通过大规模蒙特卡洛模拟，使用OpenAI的text-embedding-3-small模型嵌入代表自恋五个维度的项目，系统变化项目池大小（每维度3-40项）和嵌入深度（3-1298维度）。

Result: TEFI在深度嵌入范围（900-1200维度）达到最小值，此时基于熵的组织性最大但结构准确性下降；NMI在浅层深度达到峰值，此时维度恢复最强但基于熵的拟合仍不理想。单一指标优化产生结构不一致解，加权复合标准能识别同时平衡准确性和组织性的嵌入维度深度区域。最优嵌入深度随项目池大小系统缩放。

Conclusion: 嵌入景观是非均匀语义空间，需要原则性优化而非默认使用全向量。研究建立了系统方法识别最优嵌入维度深度，为心理学项目开发中LLM嵌入的有效使用提供了指导。

Abstract: Large language model (LLM) embeddings are increasingly used to estimate dimensional structure in psychological item pools prior to data collection, yet current applications treat embeddings as static, cross-sectional representations. This approach implicitly assumes uniform contribution across all embedding coordinates and overlooks the possibility that optimal structural information may be concentrated in specific regions of the embedding space. This study reframes embeddings as searchable landscapes and adapts Dynamic Exploratory Graph Analysis (DynEGA) to systematically traverse embedding coordinates, treating the dimension index as a pseudo-temporal ordering analogous to intensive longitudinal trajectories. A large-scale Monte Carlo simulation embedded items representing five dimensions of grandiose narcissism using OpenAI's text-embedding-3-small model, generating network estimations across systematically varied item pool sizes (3-40 items per dimension) and embedding depths (3-1,298 dimensions). Results reveal that Total Entropy Fit Index (TEFI) and Normalized Mutual Information (NMI) leads to competing optimization trajectories across the embedding landscape. TEFI achieves minima at deep embedding ranges (900--1,200 dimensions) where entropy-based organization is maximal but structural accuracy degrades, whereas NMI peaks at shallow depths where dimensional recovery is strongest but entropy-based fit remains suboptimal. Single-metric optimization produces structurally incoherent solutions, whereas a weighted composite criterion identifies embedding dimensions depth regions that jointly balance accuracy and organization. Optimal embedding depth scales systematically with item pool size. These findings establish embedding landscapes as non-uniform semantic spaces requiring principled optimization rather than default full-vector usage.

</details>


### [39] [FlashMoE: Reducing SSD I/O Bottlenecks via ML-Based Cache Replacement for Mixture-of-Experts Inference on Edge Devices](https://arxiv.org/abs/2601.17063)
*Byeongju Kim,Jungwan Lee,Donghyeon Han,Hoi-Jun Yoo,Sangyeob Kim*

Main category: cs.LG

TL;DR: FlashMoE是一个将不活跃专家卸载到SSD的系统，支持在有限RAM下进行高效MoE推理，通过ML缓存策略提升缓存命中率，在真实硬件上相比现有系统获得2.6倍加速。


<details>
  <summary>Details</summary>
Motivation: 现有MoE推理系统（如Fiddler、DAOP）依赖DRAM卸载，不适合内存受限的移动设备环境。随着MoE模型增长到数百GB，RAM卸载方案变得不切实际，需要新的解决方案。

Method: 提出FlashMoE系统，将不活跃专家卸载到SSD，采用轻量级ML缓存策略，结合最近使用和频率信号自适应管理缓存，最大化专家重用，减少存储I/O。构建了用户级桌面平台验证实用性。

Result: 在真实硬件设置上，FlashMoE相比LRU和LFU等传统卸载策略提升缓存命中率高达51%，相比现有MoE推理系统实现最高2.6倍加速。

Conclusion: FlashMoE通过SSD卸载和智能缓存策略，成功解决了内存受限环境下大型MoE模型推理的挑战，为边缘设备上的MoE推理提供了实用解决方案。

Abstract: Recently, Mixture-of-Experts (MoE) models have gained attention for efficiently scaling large language models. Although these models are extremely large, their sparse activation enables inference to be performed by accessing only a fraction of the model at a time. This property opens the possibility of on-device inference of MoE, which was previously considered infeasible for such large models. Consequently, various systems have been proposed to leverage this sparsity and enable efficient MoE inference for edge devices. However, previous MoE inference systems like Fiddler[8] or DAOP[13] rely on DRAM-based offloading and are not suitable for memory constrained on-device environments. As recent MoE models grow to hundreds of gigabytes, RAM-offloading solutions become impractical. To address this, we propose FlashMoE, a system that offloads inactive experts to SSD, enabling efficient MoE inference under limited RAM. FlashMoE incorporates a lightweight ML-based caching strategy that adaptively combines recency and frequency signals to maximize expert reuse, significantly reducing storage I/O. In addition, we built a user-grade desktop platform to demonstrate the practicality of FlashMoE. On this real hardware setup, FlashMoE improves cache hit rate by up to 51% over well-known offloading policies such as LRU and LFU, and achieves up to 2.6x speedup compared to existing MoE inference systems.

</details>


### [40] [ThinkTank-ME: A Multi-Expert Framework for Middle East Event Forecasting](https://arxiv.org/abs/2601.17065)
*Haoxuan Li,He Chang,Yunshan Ma,Yi Bin,Yang Yang,See-Kiong Ng,Tat-Seng Chua*

Main category: cs.LG

TL;DR: 提出ThinkTank-ME框架，通过模拟专家协作分析来改进中东事件预测，构建POLECAT-FOR-ME基准测试，验证多专家协作在复杂地缘政治预测中的优势。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的事件预测方法采用单一模型架构，只能生成单一显式轨迹的预测，难以捕捉复杂区域背景下多样化的地缘政治细微差别。事件预测本质上受到多方面因素的影响，包括国际关系、区域历史动态和文化背景等。

Method: 引入ThinkTank-ME框架，模拟现实世界战略决策中的协作专家分析。构建POLECAT-FOR-ME中东事件预测基准，促进专家专业化和严格评估。采用多专家协作架构处理复杂时间地缘政治预测任务。

Result: 实验结果表明，多专家协作在处理复杂时间地缘政治预测任务方面具有优越性。代码已在GitHub上开源。

Conclusion: ThinkTank-ME框架通过模拟专家协作分析，有效解决了单一模型架构在复杂区域事件预测中的局限性，为中东地缘政治预测提供了更准确的方法。

Abstract: Event forecasting is inherently influenced by multifaceted considerations, including international relations, regional historical dynamics, and cultural contexts. However, existing LLM-based approaches employ single-model architectures that generate predictions along a singular explicit trajectory, constraining their ability to capture diverse geopolitical nuances across complex regional contexts. To address this limitation, we introduce ThinkTank-ME, a novel Think Tank framework for Middle East event forecasting that emulates collaborative expert analysis in real-world strategic decision-making. To facilitate expert specialization and rigorous evaluation, we construct POLECAT-FOR-ME, a Middle East-focused event forecasting benchmark. Experimental results demonstrate the superiority of multi-expert collaboration in handling complex temporal geopolitical forecasting tasks. The code is available at https://github.com/LuminosityX/ThinkTank-ME.

</details>


### [41] [Multi-Agent Deep Reinforcement Learning Under Constrained Communications](https://arxiv.org/abs/2601.17069)
*Shahil Shaik,Jonathon M. Smereka,Yue Wang*

Main category: cs.LG

TL;DR: 提出分布式多智能体强化学习框架DG-MAPPO，通过多跳通信完全消除对集中式训练和全局信息的依赖，在多个基准测试中优于集中式方法。


<details>
  <summary>Details</summary>
Motivation: 集中式训练分散式执行(CTDE)范式存在可扩展性、鲁棒性和泛化性瓶颈，依赖全局状态信息，在实际场景中（如队友增减、环境动态变化）脆弱且重训练成本高。分布式方法仅需本地信息和点对点通信，更具适应性。

Method: 1) 开发分布式图注意力网络(D-GAT)，通过多跳通信进行全局状态推断，智能体以完全分布式方式通过输入依赖的注意力权重整合邻居特征；2) 基于D-GAT构建分布式图注意力MAPPO(DG-MAPPO)框架，智能体使用本地观察、多跳通信和共享/平均奖励优化本地策略和价值函数。

Result: 在StarCraftII多智能体挑战、Google Research Football和Multi-Agent Mujoco上的实验表明，该方法在广泛合作任务中（包括同质和异质团队）始终优于强CTDE基线，实现更优的协调性能。

Conclusion: DG-MAPPO提供了原则性且可扩展的鲁棒协作解决方案，完全消除了对集中式训练或全局可观测性的需求，据作者所知是首个完全消除对特权集中信息依赖的方法，使智能体仅通过点对点通信即可学习和行动。

Abstract: Centralized training with decentralized execution (CTDE) has been the dominant paradigm in multi-agent reinforcement learning (MARL), but its reliance on global state information during training introduces scalability, robustness, and generalization bottlenecks. Moreover, in practical scenarios such as adding/dropping teammates or facing environment dynamics that differ from the training, CTDE methods can be brittle and costly to retrain, whereas distributed approaches allow agents to adapt using only local information and peer-to-peer communication. We present a distributed MARL framework that removes the need for centralized critics or global information. Firstly, we develop a novel Distributed Graph Attention Network (D-GAT) that performs global state inference through multi-hop communication, where agents integrate neighbor features via input-dependent attention weights in a fully distributed manner. Leveraging D-GAT, we develop the distributed graph-attention MAPPO (DG-MAPPO) -- a distributed MARL framework where agents optimize local policies and value functions using local observations, multi-hop communication, and shared/averaged rewards. Empirical evaluation on the StarCraftII Multi-Agent Challenge, Google Research Football, and Multi-Agent Mujoco demonstrates that our method consistently outperforms strong CTDE baselines, achieving superior coordination across a wide range of cooperative tasks with both homogeneous and heterogeneous teams. Our distributed MARL framework provides a principled and scalable solution for robust collaboration, eliminating the need for centralized training or global observability. To the best of our knowledge, DG-MAPPO appears to be the first to fully eliminate reliance on privileged centralized information, enabling agents to learn and act solely through peer-to-peer communication.

</details>


### [42] [Attention-Based Variational Framework for Joint and Individual Components Learning with Applications in Brain Network Analysis](https://arxiv.org/abs/2601.17073)
*Yifei Zhang,Meimei Liu,Zhengwu Zhang*

Main category: cs.LG

TL;DR: CM-JIVNet是一个概率框架，用于从配对的脑结构-功能连接数据中学习因子化的潜在表示，通过多头注意力融合模块捕获跨模态依赖关系并分离模态特异性信号，在HCP-YA数据上表现出优越的跨模态重建和行为预测性能。


<details>
  <summary>Details</summary>
Motivation: 脑组织通过多种成像模态（特别是结构连接SC和功能连接FC）进行表征，整合这些本质上不同但互补的数据源对于揭示驱动行为表型的跨模态模式至关重要。然而，有效整合受到连接组数据的高维度和非线性、复杂的非线性SC-FC耦合以及从模态特异性变化中分离共享信息的挑战所阻碍。

Method: 提出跨模态联合-个体变分网络（CM-JIVNet），这是一个统一的概率框架，设计用于从配对的SC-FC数据集中学习因子化的潜在表示。模型利用多头注意力融合模块捕获非线性跨模态依赖关系，同时分离独立的模态特异性信号。

Result: 在人类连接组项目年轻成人（HCP-YA）数据上验证，CM-JIVNet在跨模态重建和行为特征预测方面表现出优越性能。通过有效分离联合和个体特征空间，该模型为大规模多模态脑分析提供了稳健、可解释和可扩展的解决方案。

Conclusion: CM-JIVNet通过概率框架和多头注意力融合，成功解决了多模态脑连接数据整合的挑战，实现了跨模态依赖关系的捕获和模态特异性信号的分离，为大规模多模态脑分析提供了有效的工具。

Abstract: Brain organization is increasingly characterized through multiple imaging modalities, most notably structural connectivity (SC) and functional connectivity (FC). Integrating these inherently distinct yet complementary data sources is essential for uncovering the cross-modal patterns that drive behavioral phenotypes. However, effective integration is hindered by the high dimensionality and non-linearity of connectome data, complex non-linear SC-FC coupling, and the challenge of disentangling shared information from modality-specific variations. To address these issues, we propose the Cross-Modal Joint-Individual Variational Network (CM-JIVNet), a unified probabilistic framework designed to learn factorized latent representations from paired SC-FC datasets. Our model utilizes a multi-head attention fusion module to capture non-linear cross-modal dependencies while isolating independent, modality-specific signals. Validated on Human Connectome Project Young Adult (HCP-YA) data, CM-JIVNet demonstrates superior performance in cross-modal reconstruction and behavioral trait prediction. By effectively disentangling joint and individual feature spaces, CM-JIVNet provides a robust, interpretable, and scalable solution for large-scale multimodal brain analysis.

</details>


### [43] [PhysE-Inv: A Physics-Encoded Inverse Modeling approach for Arctic Snow Depth Prediction](https://arxiv.org/abs/2601.17074)
*Akila Sampath,Vandana Janeja,Jianwu Wang*

Main category: cs.LG

TL;DR: PhysE-Inv：一种结合物理约束与深度学习的新型框架，用于从稀疏噪声数据中反演北极雪深，相比现有方法误差降低20%，物理一致性更好


<details>
  <summary>Details</summary>
Motivation: 北极雪深估计是关键的时变反演问题，现有过程模型对稀疏数据敏感，数据驱动模型缺乏物理可解释性，无法满足气候关键应用需求

Method: 提出PhysE-Inv框架，集成LSTM编码器-解码器多头注意力架构与物理引导对比学习，采用满射物理约束反演方法：1) 利用静水平衡前向模型作为目标代理；2) 在潜空间应用重构物理正则化从噪声不完整时间序列中发现隐藏物理参数

Result: 相比最先进基线方法，PhysE-Inv显著提升预测性能，误差降低20%，在物理一致性和数据稀疏性鲁棒性方面优于经验方法

Conclusion: 该方法为噪声容忍、可解释的反演建模开辟了新路径，在遥感和冰冻圈领域具有广泛应用前景

Abstract: The accurate estimation of Arctic snow depth ($h_s$) remains a critical time-varying inverse problem due to the extreme scarcity and noise inherent in associated sea ice parameters. Existing process-based and data-driven models are either highly sensitive to sparse data or lack the physical interpretability required for climate-critical applications. To address this gap, we introduce PhysE-Inv, a novel framework that integrates a sophisticated sequential architecture, an LSTM Encoder-Decoder with Multi-head Attention and physics-guided contrastive learning, with physics-guided inference.Our core innovation lies in a surjective, physics-constrained inversion methodology. This methodology first leverages the hydrostatic balance forward model as a target-formulation proxy, enabling effective learning in the absence of direct $h_s$ ground truth; second, it uses reconstruction physics regularization over a latent space to dynamically discover hidden physical parameters from noisy, incomplete time-series input. Evaluated against state-of-the-art baselines, PhysE-Inv significantly improves prediction performance, reducing error by 20\% while demonstrating superior physical consistency and resilience to data sparsity compared to empirical methods. This approach pioneers a path for noise-tolerant, interpretable inverse modeling, with wide applicability in geospatial and cryospheric domains.

</details>


### [44] [E2PL: Effective and Efficient Prompt Learning for Incomplete Multi-view Multi-Label Class Incremental Learning](https://arxiv.org/abs/2601.17076)
*Jiajun Chen,Yue Wu,Kai Huang,Wen Xi,Yangyang Wu,Xiaoye Miao,Mengying Zhu,Meng Xi,Guanjie Cheng*

Main category: cs.LG

TL;DR: E2PL：一种用于不完全多视图多标签类增量学习的高效提示学习框架，通过任务定制提示和缺失感知提示解决视图缺失和类别动态扩展问题


<details>
  <summary>Details</summary>
Motivation: 现实世界Web应用中存在视图缺失和类别动态扩展的问题，现有方法无法同时处理这两个挑战，要么缺乏对新类别的适应性，要么在处理缺失视图模式时参数呈指数增长

Method: 提出E2PL框架，包含：1）任务定制提示用于类别增量适应；2）缺失感知提示用于灵活集成任意视图缺失场景；3）高效原型张量化模块通过原子张量分解将提示参数复杂度从指数级降至线性级；4）动态对比学习策略显式建模不同缺失视图模式间的复杂依赖关系

Result: 在三个基准测试上的广泛实验表明，E2PL在效果和效率方面均优于现有最先进方法

Conclusion: E2PL为不完全多视图多标签类增量学习提供了一种有效且高效的解决方案，通过统一的提示设计和参数优化策略，成功解决了现实Web应用中视图缺失和类别动态扩展的双重挑战

Abstract: Multi-view multi-label classification (MvMLC) is indispensable for modern web applications aggregating information from diverse sources. However, real-world web-scale settings are rife with missing views and continuously emerging classes, which pose significant obstacles to robust learning. Prevailing methods are ill-equipped for this reality, as they either lack adaptability to new classes or incur exponential parameter growth when handling all possible missing-view patterns, severely limiting their scalability in web environments. To systematically address this gap, we formally introduce a novel task, termed \emph{incomplete multi-view multi-label class incremental learning} (IMvMLCIL), which requires models to simultaneously address heterogeneous missing views and dynamic class expansion. To tackle this task, we propose \textsf{E2PL}, an Effective and Efficient Prompt Learning framework for IMvMLCIL. \textsf{E2PL} unifies two novel prompt designs: \emph{task-tailored prompts} for class-incremental adaptation and \emph{missing-aware prompts} for the flexible integration of arbitrary view-missing scenarios. To fundamentally address the exponential parameter explosion inherent in missing-aware prompts, we devise an \emph{efficient prototype tensorization} module, which leverages atomic tensor decomposition to elegantly reduce the prompt parameter complexity from exponential to linear w.r.t. the number of views. We further incorporate a \emph{dynamic contrastive learning} strategy explicitly model the complex dependencies among diverse missing-view patterns, thus enhancing the model's robustness. Extensive experiments on three benchmarks demonstrate that \textsf{E2PL} consistently outperforms state-of-the-art methods in both effectiveness and efficiency. The codes and datasets are available at https://anonymous.4open.science/r/code-for-E2PL.

</details>


### [45] [SFO: Learning PDE Operators via Spectral Filtering](https://arxiv.org/abs/2601.17090)
*Noam Koren,Rafael Moschopoulos,Kira Radinsky,Elad Hazan*

Main category: cs.LG

TL;DR: SFO是一种新型神经算子，使用通用谱基表示积分核，通过仅学习衰减快的特征值谱系数，高效捕捉PDE解映射中的长程非局部相互作用。


<details>
  <summary>Details</summary>
Motivation: 传统神经算子在捕捉偏微分方程解映射中的长程非局部相互作用时效率低下，而研究发现离散格林函数具有空间线性动力系统结构，这为高效表示提供了理论基础。

Method: 提出SFO神经算子，使用从希尔伯特矩阵特征模态导出的固定全局正交基（USB）参数化积分核，仅学习快速衰减特征值的谱系数，实现紧凑近似。

Result: 在六个基准测试（包括反应扩散、流体动力学和3D电磁学）中，SFO达到最先进精度，相比强基线误差降低达40%，同时使用更少参数。

Conclusion: SFO通过谱基表示提供了一种高效捕捉PDE长程相互作用的神经算子框架，在精度和参数效率方面均优于现有方法。

Abstract: Partial differential equations (PDEs) govern complex systems, yet neural operators often struggle to efficiently capture the long-range, nonlocal interactions inherent in their solution maps. We introduce Spectral Filtering Operator (SFO), a neural operator that parameterizes integral kernels using the Universal Spectral Basis (USB), a fixed, global orthonormal basis derived from the eigenmodes of the Hilbert matrix in spectral filtering theory. Motivated by our theoretical finding that the discrete Green's functions of shift-invariant PDE discretizations exhibit spatial Linear Dynamical System (LDS) structure, we prove that these kernels admit compact approximations in the USB. By learning only the spectral coefficients of rapidly decaying eigenvalues, SFO achieves a highly efficient representation. Across six benchmarks, including reaction-diffusion, fluid dynamics, and 3D electromagnetics, SFO achieves state-of-the-art accuracy, reducing error by up to 40% relative to strong baselines while using substantially fewer parameters.

</details>


### [46] [CUROCKET: Optimizing ROCKET for GPU](https://arxiv.org/abs/2601.17091)
*Ole Stüven,Keno Moenck,Thorsten Schüppstuhl*

Main category: cs.LG

TL;DR: CUROCKET是ROCKET算法的GPU加速版本，通过解决随机卷积核在GPU上的计算效率问题，实现了比CPU版本高11倍的每瓦计算效率。


<details>
  <summary>Details</summary>
Motivation: ROCKET算法在时间序列分类中表现出色，但现有实现主要在CPU上运行。卷积计算高度可并行化，适合GPU加速，但ROCKET使用的非均匀卷积核使得标准GPU卷积方法效率低下。

Method: 提出一种新算法，能够高效地在GPU上执行ROCKET的随机卷积操作，解决非均匀卷积核在GPU上的计算效率问题。

Result: CUROCKET实现了比CPU版本高11倍的每瓦计算效率，代码已在GitHub开源。

Conclusion: 通过GPU加速ROCKET算法，显著提升了计算效率，为时间序列分类提供了更高效的解决方案。

Abstract: ROCKET (RandOm Convolutional KErnel Transform) is a feature extraction algorithm created for Time Series Classification (TSC), published in 2019. It applies convolution with randomly generated kernels on a time series, producing features that can be used to train a linear classifier or regressor like Ridge. At the time of publication, ROCKET was on par with the best state-of-the-art algorithms for TSC in terms of accuracy while being significantly less computationally expensive, making ROCKET a compelling algorithm for TSC. This also led to several subsequent versions, further improving accuracy and computational efficiency. The currently available ROCKET implementations are mostly bound to execution on CPU. However, convolution is a task that can be highly parallelized and is therefore suited to be executed on GPU, which speeds up the computation significantly. A key difficulty arises from the inhomogeneous kernels ROCKET uses, making standard methods for applying convolution on GPU inefficient. In this work, we propose an algorithm that is able to efficiently perform ROCKET on GPU and achieves up to 11 times higher computational efficiency per watt than ROCKET on CPU. The code for CUROCKET is available in this repository https://github.com/oleeven/CUROCKET on github.

</details>


### [47] [The Triangle of Similarity: A Multi-Faceted Framework for Comparing Neural Network Representations](https://arxiv.org/abs/2601.17093)
*Olha Sirikova,Alvin Chan*

Main category: cs.LG

TL;DR: 提出"相似性三角形"框架，结合三种互补视角（静态表示相似性、功能相似性、稀疏性相似性）来全面比较神经网络表示，发现架构家族是表示相似性的主要决定因素，并揭示了剪枝过程中的有趣现象。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络表示比较方法往往提供有限视角，无法全面评估模型是否收敛到相似的内部机制。需要更全面的框架来支持科学应用中的模型理解和验证。

Method: 提出相似性三角形框架，结合三种视角：1) 静态表示相似性（CKA/Procrustes），2) 功能相似性（线性模式连接性或预测相似性），3) 稀疏性相似性（剪枝下的鲁棒性）。在CNN、Vision Transformer和视觉语言模型上，使用分布内（ImageNetV2）和分布外（CIFAR-10）测试集进行分析。

Result: 1) 架构家族是表示相似性的主要决定因素，形成明显聚类；2) CKA自相似性与任务准确率在剪枝过程中强相关，但准确率下降更剧烈；3) 某些模型对在剪枝后表现出正则化效果，暴露出共享的计算核心。

Conclusion: 相似性三角形框架提供了更全面的神经网络表示评估方法，有助于判断模型是否收敛到相似内部机制，为科学研究中的模型选择和分折提供了有用工具。

Abstract: Comparing neural network representations is essential for understanding and validating models in scientific applications. Existing methods, however, often provide a limited view. We propose the Triangle of Similarity, a framework that combines three complementary perspectives: static representational similarity (CKA/Procrustes), functional similarity (Linear Mode Connectivity or Predictive Similarity), and sparsity similarity (robustness under pruning). Analyzing a range of CNNs, Vision Transformers, and Vision-Language Models using both in-distribution (ImageNetV2) and out-of-distribution (CIFAR-10) testbeds, our initial findings suggest that: (1) architectural family is a primary determinant of representational similarity, forming distinct clusters; (2) CKA self-similarity and task accuracy are strongly correlated during pruning, though accuracy often degrades more sharply; and (3) for some model pairs, pruning appears to regularize representations, exposing a shared computational core. This framework offers a more holistic approach for assessing whether models have converged on similar internal mechanisms, providing a useful tool for model selection and analysis in scientific research.

</details>


### [48] [Boltzmann-GPT: Bridging Energy-Based World Models and Language Generation](https://arxiv.org/abs/2601.17094)
*Junichiro Niimi*

Main category: cs.LG

TL;DR: 该论文提出"嘴不是大脑"的架构原则，将世界模型与语言模型分离，使用深度玻尔兹曼机作为世界模型，结合冻结的GPT-2进行文本生成，在消费者评论领域验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型虽然能生成流畅文本，但人们对其是否真正理解世界还是仅仅产生看似合理的语言存在争议。作者希望明确分离世界理解和语言能力，探索更可控、一致的生成方法。

Method: 提出三组件架构：1) 深度玻尔兹曼机作为基于能量的世界模型捕捉领域结构；2) 适配器将潜在信念状态投影到嵌入空间；3) 冻结的GPT-2提供语言能力但不含领域知识。在亚马逊智能手机评论领域实例化该框架。

Result: 实验表明：1) 通过世界模型调节的生成在情感相关性、困惑度和语义相似度上显著优于仅基于提示的生成；2) DBM能量函数能区分连贯与不连贯的市场配置，对不合理品牌价格组合赋予更高能量；3) 特定属性的干预能因果传播到生成文本，干预输出与自然样本分布一致。

Conclusion: 即使小规模语言模型，当连接到适当的世界模型时，也能实现一致、可控的生成。这为分离语言能力和世界理解提供了实证支持，验证了"嘴不是大脑"的架构原则。

Abstract: Large Language Models (LLMs) generate fluent text, yet whether they truly understand the world or merely produce plausible language about it remains contested. We propose an architectural principle, the mouth is not the brain, that explicitly separates world models from language models. Our architecture comprises three components: a Deep Boltzmann Machine (DBM) that captures domain structure as an energy-based world model, an adapter that projects latent belief states into embedding space, and a frozen GPT-2 that provides linguistic competence without domain knowledge. We instantiate this framework in the consumer review domain using Amazon smartphone reviews. Experiments demonstrate that (1) conditioning through the world model yields significantly higher sentiment correlation, lower perplexity, and greater semantic similarity compared to prompt-based generation alone; (2) the DBM's energy function distinguishes coherent from incoherent market configurations, assigning higher energy to implausible brand-price combinations; and (3) interventions on specific attributes propagate causally to generated text with intervened outputs exhibiting distributions statistically consistent with naturally occurring samples sharing the target configuration. These findings suggest that even small-scale language models can achieve consistent, controllable generation when connected to an appropriate world model, providing empirical support for separating linguistic competence from world understanding.

</details>


### [49] [MambaNet: Mamba-assisted Channel Estimation Neural Network With Attention Mechanism](https://arxiv.org/abs/2601.17108)
*Dianxin Luan,Chengsi Liang,Jie Huang,Zheng Lin,Kaitao Meng,John Thompson,Cheng-Xiang Wang*

Main category: cs.LG

TL;DR: 提出一种结合Mamba架构和自注意力机制的神经网络框架，用于OFDM系统的大规模子载波信道估计，在降低复杂度的同时提升性能。


<details>
  <summary>Details</summary>
Motivation: 针对OFDM波形（特别是大规模子载波配置）的信道估计问题，传统方法在处理大规模子载波时复杂度高，而基于Transformer的神经网络虽然能捕获长距离依赖但空间复杂度较高。需要一种既能有效处理大规模子载波、捕获长距离依赖，又具有较低复杂度的解决方案。

Method: 提出Mamba辅助的神经网络框架，集成定制化的Mamba架构和自注意力机制。关键创新包括：1）采用双向选择性扫描（bidirectional selective scan）来处理非因果性的子载波信道增益；2）相比传统Mamba结构进行改进以适应信道估计特性；3）整体框架相比基于Transformer的神经网络具有更低的空间复杂度。

Result: 在3GPP TS 36.101信道模型上进行仿真测试，结果表明：相比其他基线神经网络解决方案，所提方法在减少可调参数数量的同时，实现了改进的信道估计性能。

Conclusion: 该Mamba辅助的神经网络框架为OFDM系统的大规模子载波信道估计提供了一种高效解决方案，能够在降低复杂度的同时提升估计性能，特别适用于大规模子载波配置的场景。

Abstract: This paper proposes a Mamba-assisted neural network framework incorporating self-attention mechanism to achieve improved channel estimation with low complexity for orthogonal frequency-division multiplexing (OFDM) waveforms, particularly for configurations with a large number of subcarriers. With the integration of customized Mamba architecture, the proposed framework handles large-scale subcarrier channel estimation efficiently while capturing long-distance dependencies among these subcarriers effectively. Unlike conventional Mamba structure, this paper implements a bidirectional selective scan to improve channel estimation performance, because channel gains at different subcarriers are non-causal. Moreover, the proposed framework exhibits relatively lower space complexity than transformer-based neural networks. Simulation results tested on the 3GPP TS 36.101 channel demonstrate that compared to other baseline neural network solutions, the proposed method achieves improved channel estimation performance with a reduced number of tunable parameters.

</details>


### [50] [Least-Loaded Expert Parallelism: Load Balancing An Imbalanced Mixture-of-Experts](https://arxiv.org/abs/2601.17111)
*Xuan-Phi Nguyen,Shrey Pandit,Austin Xu,Caiming Xiong,Shafiq Joty*

Main category: cs.LG

TL;DR: 提出LLEP算法解决MoE模型专家并行中的负载不平衡问题，通过动态重路由实现5倍加速和4倍内存降低


<details>
  <summary>Details</summary>
Motivation: MoE模型即使在预训练后仍存在显著的路由不平衡，而专家并行(EP)假设平衡路由，在极端不平衡时会导致过载设备计算和内存故障

Method: 提出最小负载专家并行(LLEP)算法，动态将过载设备的超额token和相关专家参数重路由到未充分利用的设备

Result: 在不同模型规模上，LLEP相比标准EP实现高达5倍加速和4倍峰值内存使用降低，gpt-oss-120b推理速度提升约1.9倍

Conclusion: LLEP解决了MoE模型专家并行中的负载不平衡问题，通过理论分析和实验验证了其有效性，为硬件特定超参数调优提供了框架

Abstract: Mixture-of-Experts (MoE) models are typically pre-trained with explicit load-balancing constraints to ensure statistically balanced expert routing. Despite this, we observe that even well-trained MoE models exhibit significantly imbalanced routing. This behavior is arguably natural-and even desirable - as imbalanced routing allows models to concentrate domain-specific knowledge within a subset of experts. Expert parallelism (EP) is designed to scale MoE models by distributing experts across multiple devices, but with a less-discussed assumption of balanced routing. Under extreme imbalance, EP can funnel a disproportionate number of tokens to a small number of experts, leading to compute- and memory-bound failures on overloaded devices during post-training or inference, where explicit load balancing is often inapplicable. We propose Least-Loaded Expert Parallelism (LLEP), a novel EP algorithm that dynamically reroutes excess tokens and associated expert parameters from overloaded devices to underutilized ones. This ensures that all devices complete their workloads within the minimum collective latency while respecting memory constraints. Across different model scales, LLEP achieves up to 5x speedup and 4x reduction in peak memory usage compared to standard EP. This enables faster and higher-throughput post-training and inference, with ~1.9x faster for gpt-oss-120b. We support our method with extensive theoretical analysis and comprehensive empirical evaluations, including ablation studies. These results illuminate key trade-offs and enable a principled framework for hardware-specific hyper-parameter tuning to achieve optimal performance.

</details>


### [51] [Low-Rank Tensor Approximation of Weights in Large Language Models via Cosine Lanczos Bidiagonalization](https://arxiv.org/abs/2601.17112)
*A. El Ichi,K. Jbilou*

Main category: cs.LG

TL;DR: 提出基于cproduct的张量压缩框架，用于降低LLMs的内存占用和计算成本


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然性能卓越，但存在内存占用大和计算成本高的问题，需要更高效的压缩方法

Method: 利用cproduct的代数结构，在变换域中表示权重张量，通过低秩张量因子联合近似正面切片

Result: 该方法能够实现计算高效的压缩，利用多维相关性，超越传统的SVD方法

Conclusion: cproduct张量压缩框架为LLMs提供了更有效的压缩方案，能够更好地利用多维相关性

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse natural language tasks but suffer from extremely large memory footprints and computational costs. In this paper, we introduce a tensor compression framework based on the cproduct for computing low rank approximation In the first part of our approach, we leverage the algebraic structure of the cproduct to represent weight tensors such as those in embedding layers, attention projections, and feed forward networks in a transform domain where frontal slices can be jointly approximated by low rank tensor factors. This enables computationally efficient compression that exploits multidimensional correlations beyond traditional SVD methods.

</details>


### [52] [How does Graph Structure Modulate Membership-Inference Risk for Graph Neural Networks?](https://arxiv.org/abs/2601.17130)
*Megha Khosla*

Main category: cs.LG

TL;DR: 该论文研究了图神经网络中的成员推理攻击风险，特别关注图结构对隐私泄露的影响，发现训练图构建方式和推理时边访问权限是关键因素，并指出传统泛化差距不能完全代表成员推理风险。


<details>
  <summary>Details</summary>
Motivation: 图神经网络在敏感应用中的使用引发了训练数据泄露的担忧。现有隐私泄露研究主要基于非图领域（如图像和表格数据），缺乏针对图结构的专门分析。作者强调需要进行图特定的隐私分析，研究图结构对节点级别成员推理攻击的影响。

Method: 形式化了节点-邻域元组上的成员推理攻击，研究两个关键维度：(1) 训练图构建方式（随机采样 vs 雪球采样），(2) 推理时的边访问权限。通过实验分析不同模型和数据集上的成员推理优势，并检验差分隐私图神经网络的审计性。

Result: 雪球采样的覆盖偏差通常损害泛化能力；推理时允许访问训练-测试边能提高测试准确率、缩小训练-测试差距，并在大多数模型和数据集上产生最低的成员推理优势。泛化差距不能完全代表成员推理风险：边访问权限起主导作用，成员推理风险可能独立于差距变化而上升或下降。对于节点级任务，归纳分割破坏了统计可交换性，限制了差分隐私模型成员推理优势标准界限的适用性。

Conclusion: 图结构对成员推理攻击有显著影响，需要专门的图特定隐私分析。训练图构建和推理时边访问权限是关键因素。传统的泛化差距指标不能完全捕捉成员推理风险。差分隐私图神经网络的审计性受到图结构分割方式的限制，需要重新考虑隐私保证的评估框架。

Abstract: Graph neural networks (GNNs) have become the standard tool for encoding data and their complex relationships into continuous representations, improving prediction accuracy in several machine learning tasks like node classification and link prediction. However, their use in sensitive applications has raised concerns about the potential leakage of training data. Research on privacy leakage in GNNs has largely been shaped by findings from non-graph domains, such as images and tabular data. We emphasize the need of graph specific analysis and investigate the impact of graph structure on node level membership inference. We formalize MI over node-neighbourhood tuples and investigate two important dimensions: (i) training graph construction and (ii) inference-time edge access. Empirically, snowball's coverage bias often harms generalisation relative to random sampling, while enabling inter-train-test edges at inference improves test accuracy, shrinks the train-test gap, and yields the lowest membership advantage across most of the models and datasets. We further show that the generalisation gap empirically measured as the performance difference between the train and test nodes is an incomplete proxy for MI risk: access to edges dominates-MI can rise or fall independent of gap changes. Finally, we examine the auditability of differentially private GNNs, adapting the definition of statistical exchangeability of train-test data points for graph based models. We show that for node level tasks the inductive splits (random or snowball sampled) break exchangeability, limiting the applicability of standard bounds for membership advantage of differential private models.

</details>


### [53] [Learning to Collaborate: An Orchestrated-Decentralized Framework for Peer-to-Peer LLM Federation](https://arxiv.org/abs/2601.17133)
*Inderjeet Singh,Eleonore Vissol-Gaudin,Andikan Otung,Motoyoshi Sekiya*

Main category: cs.LG

TL;DR: KNEXA-FL：一种新颖的编排去中心化联邦学习框架，通过上下文多臂老虎机算法优化异构LLM代理间的P2P知识交换，解决数据隐私与模型性能的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习在专业化LLM微调中存在矛盾：需要跨组织数据但受限于数据隐私；集中式FL存在单点故障和模型反转攻击风险；去中心化FL使用随机P2P配对效率低下且可能导致负迁移。

Method: 提出KNEXA-FL框架，采用非聚合的中央分析器/匹配器(CPM)，将P2P协作建模为上下文多臂老虎机问题，使用LinUCB算法在抽象代理配置文件上学习最优匹配策略，通过安全蒸馏实现异构PEFT-based LLM代理间的直接知识交换。

Result: 在代码生成任务上的实验显示，KNEXA-FL相比随机P2P协作将Pass@1提高了约50%，且表现出稳定的收敛性，而强大的集中式蒸馏基线则出现灾难性性能崩溃。

Conclusion: 自适应、基于学习的编排是构建稳健有效去中心化AI生态系统的基础原则，KNEXA-FL成功解决了数据隐私与模型性能的权衡问题。

Abstract: Fine-tuning Large Language Models (LLMs) for specialized domains is constrained by a fundamental challenge: the need for diverse, cross-organizational data conflicts with the principles of data privacy and sovereignty. While Federated Learning (FL) provides a framework for collaboration without raw data exchange, its classic centralized form introduces a single point of failure and remains vulnerable to model inversion attacks. Decentralized FL (DFL) mitigates this risk by removing the central aggregator but typically relies on inefficient, random peer-to-peer (P2P) pairings, forming a collaboration graph that is blind to agent heterogeneity and risks negative transfer. This paper introduces KNEXA-FL, a novel framework for orchestrated decentralization that resolves this trade-off. KNEXA-FL employs a non-aggregating Central Profiler/Matchmaker (CPM) that formulates P2P collaboration as a contextual bandit problem, using a LinUCB algorithm on abstract agent profiles to learn an optimal matchmaking policy. It orchestrates direct knowledge exchange between heterogeneous, PEFT-based LLM agents via secure distillation, without ever accessing the models themselves. Our comprehensive experiments on a challenging code generation task show that KNEXA-FL yields substantial gains, improving Pass@1 by approx. 50% relative to random P2P collaboration. Critically, our orchestrated approach demonstrates stable convergence, in stark contrast to a powerful centralized distillation baseline which suffers from catastrophic performance collapse. Our work establishes adaptive, learning-based orchestration as a foundational principle for building robust and effective decentralized AI ecosystems.

</details>


### [54] [ConceptACT: Episode-Level Concepts for Sample-Efficient Robotic Imitation Learning](https://arxiv.org/abs/2601.17135)
*Jakob Karalus,Friedhelm Schwenker*

Main category: cs.LG

TL;DR: ConceptACT：通过概念感知注意力机制，在模仿学习中利用语义概念注释提升学习效率的扩展方法


<details>
  <summary>Details</summary>
Motivation: 当前模仿学习方法仅依赖低层传感器数据，忽略了人类自然拥有的丰富语义知识。人类在演示任务时具有对象属性、空间关系、任务约束等概念理解，这些语义信息可以显著提升机器人学习效率。

Method: 扩展Action Chunking with Transformers (ACT)，在训练时利用演示级别的语义概念注释。采用修改的transformer架构，在最终编码器层实现概念感知交叉注意力机制，监督其与人类注释对齐。概念仅在演示收集时提供，部署时不需要语义输入。

Result: 在两个具有逻辑约束的机器人操作任务上，ConceptACT比标准ACT收敛更快，样本效率更高。注意力机制集成方法显著优于简单的辅助预测损失或语言条件模型。

Conclusion: 适当集成的语义监督为更高效的机器人学习提供了强大的归纳偏置。概念感知注意力机制是有效利用人类语义知识的关键。

Abstract: Imitation learning enables robots to acquire complex manipulation skills from human demonstrations, but current methods rely solely on low-level sensorimotor data while ignoring the rich semantic knowledge humans naturally possess about tasks. We present ConceptACT, an extension of Action Chunking with Transformers that leverages episode-level semantic concept annotations during training to improve learning efficiency. Unlike language-conditioned approaches that require semantic input at deployment, ConceptACT uses human-provided concepts (object properties, spatial relationships, task constraints) exclusively during demonstration collection, adding minimal annotation burden. We integrate concepts using a modified transformer architecture in which the final encoder layer implements concept-aware cross-attention, supervised to align with human annotations. Through experiments on two robotic manipulation tasks with logical constraints, we demonstrate that ConceptACT converges faster and achieves superior sample efficiency compared to standard ACT. Crucially, we show that architectural integration through attention mechanisms significantly outperforms naive auxiliary prediction losses or language-conditioned models. These results demonstrate that properly integrated semantic supervision provides powerful inductive biases for more efficient robot learning.

</details>


### [55] [Conservative & Aggressive NaNs Accelerate U-Nets for Neuroimaging](https://arxiv.org/abs/2601.17180)
*Inés Gonzalez-Pepe,Vinuyan Sivakolunthu,Jacob Fortin,Yohan Chatelain,Tristan Glatard*

Main category: cs.LG

TL;DR: 通过分析CNN数值不确定性，发现许多卷积操作对数值噪声主导的无效数据，提出Conservative & Aggressive NaNs两种方法，利用NaN标记不稳定体素以跳过计算，在神经影像任务中实现最高1.67倍推理加速。


<details>
  <summary>Details</summary>
Motivation: 尽管硬件进步，神经影像深度学习模型的大型架构仍面临效率问题。研究发现CNN中许多操作应用于数值噪声主导的数据，对输出影响可忽略，部分模型高达三分之二的卷积操作冗余。

Method: 提出Conservative & Aggressive NaNs两种max pooling/unpooling变体，识别数值不稳定体素并用NaN替换，使后续层可跳过无关数据计算。无需架构修改，在PyTorch中实现。

Result: 在包含至少50% NaN的输入中观察到持续运行时改进；当NaN超过三分之二时（神经影像常见），平均推理加速1.67倍。Conservative NaNs平均减少30%卷积操作，无性能下降，特定层可跳过64.64%卷积；Aggressive NaNs可跳过69.30%卷积但可能影响性能。

Conclusion: 数值不确定性可被利用来减少CNN冗余计算并提高推理效率，为神经影像和图像分类任务提供了有效的计算优化方法。

Abstract: Deep learning models for neuroimaging increasingly rely on large architectures, making efficiency a persistent concern despite advances in hardware. Through an analysis of numerical uncertainty of convolutional neural networks (CNNs), we observe that many operations are applied to values dominated by numerical noise and have negligible influence on model outputs. In some models, up to two-thirds of convolution operations appear redundant. We introduce Conservative & Aggressive NaNs, two novel variants of max pooling and unpooling that identify numerically unstable voxels and replace them with NaNs, allowing subsequent layers to skip computations on irrelevant data. Both methods are implemented within PyTorch and require no architectural changes. We evaluate these approaches on four CNN models spanning neuroimaging and image classification tasks. For inputs containing at least 50% NaNs, we observe consistent runtime improvements; for data with more than two-thirds NaNs )common in several neuroimaging settings) we achieve an average inference speedup of 1.67x. Conservative NaNs reduces convolution operations by an average of 30% across models and datasets, with no measurable performance degradation, and can skip up to 64.64% of convolutions in specific layers. Aggressive NaNs can skip up to 69.30% of convolutions but may occasionally affect performance. Overall, these methods demonstrate that numerical uncertainty can be exploited to reduce redundant computation and improve inference efficiency in CNNs.

</details>


### [56] [Federated Proximal Optimization for Privacy-Preserving Heart Disease Prediction: A Controlled Simulation Study on Non-IID Clinical Data](https://arxiv.org/abs/2601.17183)
*Farzam Asad,Junaid Saif Khan,Maria Tariq,Sundus Munir,Muhammad Adnan Khan*

Main category: cs.LG

TL;DR: 该研究通过模拟四家异构医院客户端，验证了FedProx算法在非IID医疗数据上的心脏疾病预测效果优于集中式学习和孤立本地模型，同时保护患者隐私。


<details>
  <summary>Details</summary>
Motivation: 医疗数据因隐私法规无法共享，但联邦学习可实现协作建模。然而临床数据天然具有非IID特性（人口差异、疾病流行度不同、机构实践差异），需要解决客户端漂移问题。

Method: 使用UCI心脏疾病数据集（克利夫兰诊所303名患者），通过人口统计分层模拟四家异构医院客户端，创建非IID数据分区。采用FedProx算法，进行50次独立运行的消融研究。

Result: FedProx（μ=0.05）达到85.00%准确率，优于集中式学习（83.33%）和孤立本地模型（平均78.45%）。近端正则化能有效抑制异构环境中的客户端漂移。

Conclusion: FedProx在非IID医疗数据上表现优异，为实际联邦医疗系统提供了算法见解和部署指南，结果可直接应用于医院IT管理员实施隐私保护的协作学习。

Abstract: Healthcare institutions have access to valuable patient data that could be of great help in the development of improved diagnostic models, but privacy regulations like HIPAA and GDPR prevent hospitals from directly sharing data with one another. Federated Learning offers a way out to this problem by facilitating collaborative model training without having the raw patient data centralized. However, clinical datasets intrinsically have non-IID (non-independent and identically distributed) features brought about by demographic disparity and diversity in disease prevalence and institutional practices. This paper presents a comprehensive simulation research of Federated Proximal Optimization (FedProx) for Heart Disease prediction based on UCI Heart Disease dataset. We generate realistic non-IID data partitions by simulating four heterogeneous hospital clients from the Cleveland Clinic dataset (303 patients), by inducing statistical heterogeneity by demographic-based stratification. Our experimental results show that FedProx with proximal parameter mu=0.05 achieves 85.00% accuracy, which is better than both centralized learning (83.33%) and isolated local models (78.45% average) without revealing patient privacy. Through generous sheer ablation studies with statistical validation on 50 independent runs we demonstrate that proximal regularization is effective in curbing client drift in heterogeneous environments. This proof-of-concept research offers algorithmic insights and practical deployment guidelines for real-world federated healthcare systems, and thus, our results are directly transferable to hospital IT-administrators, implementing privacy-preserving collaborative learning.

</details>


### [57] [Rethinking Benchmarks for Differentially Private Image Classification](https://arxiv.org/abs/2601.17189)
*Sabrina Mokhtari,Sara Kodeiri,Shubhankar Mohapatra,Florian Tramer,Gautam Kamath*

Main category: cs.LG

TL;DR: 该论文重新审视了差分隐私图像分类的基准测试，提出了一套全面的基准集，并创建了公开可用的排行榜来追踪社区进展。


<details>
  <summary>Details</summary>
Motivation: 当前差分隐私机器学习领域缺乏全面、标准化的基准测试，难以在不同设置下公平比较不同技术，阻碍了该领域的研究进展。

Method: 提出一套全面的基准测试集，涵盖不同设置（有无额外数据、凸优化设置、不同性质的数据集），并在这些基准上测试现有技术，创建公开的排行榜。

Result: 建立了全面的差分隐私图像分类基准测试框架，识别了在不同设置下仍然有效的技术，为社区提供了标准化的评估平台。

Conclusion: 该工作填补了差分隐私机器学习领域基准测试的空白，通过标准化评估和公开排行榜将促进该领域的研究进展和技术比较。

Abstract: We revisit benchmarks for differentially private image classification. We suggest a comprehensive set of benchmarks, allowing researchers to evaluate techniques for differentially private machine learning in a variety of settings, including with and without additional data, in convex settings, and on a variety of qualitatively different datasets. We further test established techniques on these benchmarks in order to see which ideas remain effective in different settings. Finally, we create a publicly available leader board for the community to track progress in differentially private machine learning.

</details>


### [58] [PUNCH: Physics-informed Uncertainty-aware Network for Coronary Hemodynamics](https://arxiv.org/abs/2601.17192)
*Sukirt Thakur,Marcus Roper,Yang Zhou,Reza Akbarian Bafghi,Brahmajee K. Nallamothu,C. Alberto Figueroa,Srinivas Paruchuri,Scott Burger,Maziar Raissi*

Main category: cs.LG

TL;DR: 提出一种基于标准血管造影的非侵入性、不确定性感知框架，用于直接估计冠状动脉血流储备，无需真实血流测量，通过物理信息神经网络和变分推断实现。


<details>
  <summary>Details</summary>
Motivation: 冠状动脉微血管功能障碍影响数百万人，但当前金标准生理测量方法具有侵入性且可重复性差，需要开发非侵入性、可扩展的诊断工具。

Method: 集成物理信息神经网络与变分推断，从造影剂传输的第一性原理模型推断冠状动脉血流，无需真实血流测量数据，整个流程在单个GPU上约3分钟完成。

Result: 在1000个合成数据上显示预测不确定性与误差强相关；在12名患者临床验证中，与侵入性热稀释法CFR测量结果高度一致；LAD动脉的置信区间小于重复侵入测量的变异性。

Conclusion: 该框架将常规血管造影转化为定量、不确定性感知的评估，可实现可扩展、更安全、更可重复的冠状动脉微血管功能评估，有望扩大CMD诊断的可及性。

Abstract: Coronary microvascular dysfunction (CMD) affects millions worldwide yet remains underdiagnosed because gold-standard physiological measurements are invasive and variably reproducible. We introduce a non-invasive, uncertainty-aware framework for estimating coronary flow reserve (CFR) directly from standard angiography. The system integrates physics-informed neural networks with variational inference to infer coronary blood flow from first-principles models of contrast transport, without requiring ground-truth flow measurements. The pipeline runs in approximately three minutes per patient on a single GPU, with no population-level training.
  Using 1{,}000 synthetic spatiotemporal intensity maps (kymographs) with controlled noise and artifacts, the framework reliably identifies degraded data and outputs appropriately inflated uncertainty estimates, showing strong correspondence between predictive uncertainty and error (Pearson $r = 0.997$, Spearman $ρ= 0.998$). Clinical validation in 12 patients shows strong agreement between PUNCH-derived CFR and invasive bolus thermodilution (Pearson $r = 0.90$, $p = 6.3 \times 10^{-5}$). We focus on the LAD, the artery most commonly assessed in routine CMD testing. Probabilistic CFR estimates have confidence intervals narrower than the variability of repeated invasive measurements.
  By transforming routine angiography into quantitative, uncertainty-aware assessment, this approach enables scalable, safer, and more reproducible evaluation of coronary microvascular function. Because standard angiography is widely available globally, the framework could expand access to CMD diagnosis and establish a new paradigm for physics-informed, patient-specific inference from clinical imaging.

</details>


### [59] [Accelerated Sinkhorn Algorithms for Partial Optimal Transport](https://arxiv.org/abs/2601.17196)
*Nghia Thu Truong,Qui Phu Pham,Quang Nguyen,Dung Luong,Mai Tran*

Main category: cs.LG

TL;DR: ASPOT：通过Nesterov加速和交替最小化改进部分最优传输的Sinkhorn算法，将复杂度降至O(n^{7/3}ε^{-5/3})


<details>
  <summary>Details</summary>
Motivation: 部分最优传输（POT）处理两个分布间部分质量传输问题，适用于边缘分布大小不等或包含异常值的情况。现有Sinkhorn方法在POT中的复杂度边界不理想，限制了可扩展性。

Method: 提出加速Sinkhorn部分最优传输（ASPOT）方法，将交替最小化与Nesterov风格加速相结合，应用于POT设置。同时展示了通过明智选择熵参数γ可以改进经典Sinkhorn方法的收敛速率。

Result: ASPOT实现了O(n^{7/3}ε^{-5/3})的复杂度，优于现有方法。实验验证了理论分析，并展示了所提方法在实际应用中的优越性能。

Conclusion: ASPOT通过加速技术显著提升了部分最优传输问题的计算效率，为处理不等边缘分布和异常值提供了更高效的解决方案。

Abstract: Partial Optimal Transport (POT) addresses the problem of transporting only a fraction of the total mass between two distributions, making it suitable when marginals have unequal size or contain outliers. While Sinkhorn-based methods are widely used, their complexity bounds for POT remain suboptimal and can limit scalability. We introduce Accelerated Sinkhorn for POT (ASPOT), which integrates alternating minimization with Nesterov-style acceleration in the POT setting, yielding a complexity of $\mathcal{O}(n^{7/3}\varepsilon^{-5/3})$. We also show that an informed choice of the entropic parameter $γ$ improves rates for the classical Sinkhorn method. Experiments on real-world applications validate our theories and demonstrate the favorable performance of our proposed methods.

</details>


### [60] [SpecBridge: Bridging Mass Spectrometry and Molecular Representations via Cross-Modal Alignment](https://arxiv.org/abs/2601.17204)
*Yinkai Wang,Yan Zhou Chen,Xiaohui Chen,Li-Ping Liu,Soha Hassoun*

Main category: cs.LG

TL;DR: SpecBridge提出了一种新颖的隐式对齐框架，通过将质谱数据直接映射到预训练分子模型的潜在空间，显著提高了小分子鉴定的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的小分子鉴定方法存在两个极端：要么是显式生成模型（原子级构建分子图），要么是从头开始学习的联合对比模型。这两种方法都有局限性，特别是在非靶向质谱分析中，谱库不完整的情况下鉴定小分子仍然是一个瓶颈。

Method: SpecBridge采用隐式对齐框架，将结构鉴定视为几何对齐问题。方法包括：1）微调自监督质谱编码器（DreaMS），使其直接投影到冻结的分子基础模型（ChemBERTa）的潜在空间；2）通过余弦相似度在预计算的分子嵌入库中进行检索。

Result: 在MassSpecGym、Spectraverse和MSnLib基准测试中，SpecBridge相对于强大的神经基线模型，将top-1检索准确率提高了约20-25%，同时保持了较少的可训练参数。

Conclusion: 与从头设计新架构相比，对齐到冻结的基础模型是一种实用且稳定的替代方案。该方法在保持参数效率的同时显著提高了小分子鉴定性能。

Abstract: Small-molecule identification from tandem mass spectrometry (MS/MS) remains a bottleneck in untargeted settings where spectral libraries are incomplete. While deep learning offers a solution, current approaches typically fall into two extremes: explicit generative models that construct molecular graphs atom-by-atom, or joint contrastive models that learn cross-modal subspaces from scratch. We introduce SpecBridge, a novel implicit alignment framework that treats structure identification as a geometric alignment problem. SpecBridge fine-tunes a self-supervised spectral encoder (DreaMS) to project directly into the latent space of a frozen molecular foundation model (ChemBERTa), and then performs retrieval by cosine similarity to a fixed bank of precomputed molecular embeddings. Across MassSpecGym, Spectraverse, and MSnLib benchmarks, SpecBridge improves top-1 retrieval accuracy by roughly 20-25% relative to strong neural baselines, while keeping the number of trainable parameters small. These results suggest that aligning to frozen foundation models is a practical, stable alternative to designing new architectures from scratch. The code for SpecBridge is released at https://github.com/HassounLab/SpecBridge.

</details>


### [61] [NewPINNs: Physics-Informing Neural Networks Using Conventional Solvers for Partial Differential Equations](https://arxiv.org/abs/2601.17207)
*Maedeh Makki,Satish Chandran,Maziar Raissi,Adrien Grenier,Behzad Mohebbi*

Main category: cs.LG

TL;DR: NewPINNs将神经网络与传统数值求解器耦合，通过求解器一致性而非残差损失来训练网络，避免了传统PINNs的优化难题和权重敏感问题。


<details>
  <summary>Details</summary>
Motivation: 传统物理信息神经网络(PINNs)存在优化困难、损失权重敏感、在刚性问题或非线性区域表现不佳等已知失败模式，需要一种更稳健的方法来将物理约束融入神经网络训练。

Method: 将数值求解器直接集成到训练循环中，神经网络生成候选解状态，数值求解器推进这些状态，训练目标是最小化网络预测与求解器演化状态之间的差异，形成"拉-推"交互机制。

Result: NewPINNs能够有效缓解传统PINNs的多个失败模式，在涉及有限体积、有限元和谱求解器的多个正向和逆向问题中表现出有效性。

Conclusion: 通过将物理约束、边界条件和数值稳定性的执行委托给成熟的数值求解器，NewPINNs提供了一种无需特定问题损失工程或显式计算微分方程残差的物理信息学习框架。

Abstract: We introduce NewPINNs, a physics-informing learning framework that couples neural networks with conventional numerical solvers for solving differential equations. Rather than enforcing governing equations and boundary conditions through residual-based loss terms, NewPINNs integrates the solver directly into the training loop and defines learning objectives through solver-consistency. The neural network produces candidate solution states that are advanced by the numerical solver, and training minimizes the discrepancy between the network prediction and the solver-evolved state. This pull-push interaction enables the network to learn physically admissible solutions through repeated exposure to the solver's action, without requiring problem-specific loss engineering or explicit evaluation of differential equation residuals. By delegating the enforcement of physics, boundary conditions, and numerical stability to established numerical solvers, NewPINNs mitigates several well-known failure modes of standard physics-informed neural networks, including optimization pathologies, sensitivity to loss weighting, and poor performance in stiff or nonlinear regimes. We demonstrate the effectiveness of the proposed approach across multiple forward and inverse problems involving finite volume, finite element, and spectral solvers.

</details>


### [62] [JetFormer: A Scalable and Efficient Transformer for Jet Tagging from Offline Analysis to FPGA Triggers](https://arxiv.org/abs/2601.17215)
*Ruoqing Zheng,Chang Sun,Qibin Liu,Lauri Laatu,Arianna Cox,Benedikt Maier,Alexander Tapper,Jose G. F. Coutinho,Wayne Luk,Zhiqiang Que*

Main category: cs.LG

TL;DR: JetFormer是一种用于LHC粒子喷注标记的Transformer架构，设计用于从离线分析到在线触发的全场景，在保持高性能的同时实现计算效率和硬件部署优化。


<details>
  <summary>Details</summary>
Motivation: 现有喷注标记方法通常针对特定部署场景设计，缺乏一个统一架构能在从高精度离线分析到超低延迟在线触发的全谱系场景中有效工作。需要一种既保持高性能又易于硬件部署的通用解决方案。

Method: 提出JetFormer编码器Transformer架构，处理可变长度粒子特征集，无需显式成对相互作用输入。引入硬件感知优化流程，包括多目标超参数搜索、结构化剪枝和量化，生成适用于FPGA触发系统的紧凑变体。

Result: 在JetClass数据集上，JetFormer与ParT模型精度相当（相差0.7%以内），但FLOPs减少37.4%。在HLS4ML 150P基准数据集上，比MLPs、Deep Sets和Interaction Networks准确率高3-4%。通过压缩可生成JetFormer-tiny等变体，满足亚微秒级延迟要求。

Conclusion: JetFormer通过统一高性能建模和可部署性，为LHC离线分析和在线触发环境提供了实用的Transformer喷注标记器部署路径，实现了性能与效率的平衡。

Abstract: We present JetFormer, a versatile and scalable encoder-only Transformer architecture for particle jet tagging at the Large Hadron Collider (LHC). Unlike prior approaches that are often tailored to specific deployment regimes, JetFormer is designed to operate effectively across the full spectrum of jet tagging scenarios, from high-accuracy offline analysis to ultra-low-latency online triggering. The model processes variable-length sets of particle features without relying on input of explicit pairwise interactions, yet achieves competitive or superior performance compared to state-of-the-art methods. On the large-scale JetClass dataset, a large-scale JetFormer matches the accuracy of the interaction-rich ParT model (within 0.7%) while using 37.4% fewer FLOPs, demonstrating its computational efficiency and strong generalization. On benchmark HLS4ML 150P datasets, JetFormer consistently outperforms existing models such as MLPs, Deep Sets, and Interaction Networks by 3-4% in accuracy. To bridge the gap to hardware deployment, we further introduce a hardware-aware optimization pipeline based on multi-objective hyperparameter search, yielding compact variants like JetFormer-tiny suitable for FPGA-based trigger systems with sub-microsecond latency requirements. Through structured pruning and quantization, we show that JetFormer can be aggressively compressed with minimal accuracy loss. By unifying high-performance modeling and deployability within a single architectural framework, JetFormer provides a practical pathway for deploying Transformer-based jet taggers in both offline and online environments at the LHC. Code is available at https://github.com/walkieq/JetFormer.

</details>


### [63] [Parameter Inference and Uncertainty Quantification with Diffusion Models: Extending CDI to 2D Spatial Conditioning](https://arxiv.org/abs/2601.17224)
*Dmitrii Torbunov,Yihui Ren,Lijun Wu,Yimei Zhu*

Main category: cs.LG

TL;DR: 将条件扩散模型从一维时间信号扩展到二维空间数据，用于科学逆问题中的不确定性量化，在CBED材料表征中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 科学逆问题中需要量化不确定性以区分可识别参数和模糊参数。虽然CDI在一维时间信号上有效，但尚未探索其在更高维空间数据上的适用性。

Method: 将CDI扩展到二维空间条件化，直接从空间观测中进行概率参数推断。在收敛束电子衍射(CBED)参数推断这一具有挑战性的多参数逆问题上进行验证。

Result: CDI产生了校准良好的后验分布：对确定性参数产生紧密分布，对模糊参数产生适当宽泛的分布。相比之下，标准回归方法虽然聚合指标看似准确，但通过预测训练集均值来掩盖不确定性。

Conclusion: CDI成功从时间域扩展到空间域，为稳健的科学推断提供了真实的不确定性信息。

Abstract: Uncertainty quantification is critical in scientific inverse problems to distinguish identifiable parameters from those that remain ambiguous given available measurements. The Conditional Diffusion Model-based Inverse Problem Solver (CDI) has previously demonstrated effective probabilistic inference for one-dimensional temporal signals, but its applicability to higher-dimensional spatial data remains unexplored. We extend CDI to two-dimensional spatial conditioning, enabling probabilistic parameter inference directly from spatial observations. We validate this extension on convergent beam electron diffraction (CBED) parameter inference - a challenging multi-parameter inverse problem in materials characterization where sample geometry, electronic structure, and thermal properties must be extracted from 2D diffraction patterns. Using simulated CBED data with ground-truth parameters, we demonstrate that CDI produces well-calibrated posterior distributions that accurately reflect measurement constraints: tight distributions for well-determined quantities and appropriately broad distributions for ambiguous parameters. In contrast, standard regression methods - while appearing accurate on aggregate metrics - mask this underlying uncertainty by predicting training set means for poorly constrained parameters. Our results confirm that CDI successfully extends from temporal to spatial domains, providing the genuine uncertainty information required for robust scientific inference.

</details>


### [64] [A Constrained Optimization Perspective of Unrolled Transformers](https://arxiv.org/abs/2601.17257)
*Javier Porras-Valenzuela,Samar Hadou,Alejandro Ribeiro*

Main category: cs.LG

TL;DR: 提出一种带约束的优化框架，用于训练Transformer使其行为像优化下降算法，通过层间下降约束和原始-对偶训练方案，使中间表示在期望上单调降低损失


<details>
  <summary>Details</summary>
Motivation: 传统Transformer训练使用经验风险最小化(ERM)，但缺乏理论保证中间表示能系统性地降低目标函数。希望让Transformer的行为更像优化下降算法，从而获得更好的鲁棒性和泛化能力

Method: 1. 在目标函数上施加层间下降约束；2. 用原始-对偶训练方案替代标准ERM；3. 确保中间表示在期望上单调降低损失；4. 应用于展开式Transformer架构和预训练Transformer

Result: 在视频去噪和文本分类任务上，约束Transformer展现出更强的扰动鲁棒性，保持更高的分布外泛化能力，同时不损害分布内性能

Conclusion: 通过约束优化框架训练Transformer使其行为像优化算法，能有效提升模型的鲁棒性和泛化能力，为Transformer设计提供了新的理论指导方向

Abstract: We introduce a constrained optimization framework for training transformers that behave like optimization descent algorithms. Specifically, we enforce layerwise descent constraints on the objective function and replace standard empirical risk minimization (ERM) with a primal-dual training scheme. This approach yields models whose intermediate representations decrease the loss monotonically in expectation across layers. We apply our method to both unrolled transformer architectures and conventional pretrained transformers on tasks of video denoising and text classification. Across these settings, we observe constrained transformers achieve stronger robustness to perturbations and maintain higher out-of-distribution generalization, while preserving in-distribution performance.

</details>


### [65] [The Viscosity of Logic: Phase Transitions and Hysteresis in DPO Alignment](https://arxiv.org/abs/2601.17260)
*Marco Pollanen*

Main category: cs.LG

TL;DR: DPO的β参数不是简单的"越大越好"，而是控制参数，不同架构对β变化有不同响应模式，偏好边际可能与推理能力负相关，且训练路径存在滞后效应。


<details>
  <summary>Details</summary>
Motivation: 挑战DPO中β参数越大越好的传统观念，研究β作为控制参数时对不同模型架构的影响，揭示偏好优化与推理能力之间的复杂关系。

Method: 对三个7B开源模型家族（Mistral、Llama、Qwen）在固定DPO配方下密集扫描β参数，分析逻辑探针边际、能力变化和训练路径效应。

Result: Mistral能力呈尖锐非单调性，仅在β≈10⁻²窄带内为正；不同架构有不同响应模式；DPO偏好边际与推理能力可呈负相关（Pearson r=-0.91）；高β暴露导致能力损失具有滞后性。

Conclusion: 需要在整个β参数空间进行能力分辨评估，而非依赖偏好边际或聚合基准，训练路径和架构差异对DPO效果有重要影响。

Abstract: Direct Preference Optimization (DPO) is often tuned as if increasing alignment pressure (controlled by $β$) yields progressively "better" behavior. We instead treat $β$ as a control parameter and densely sweep it for three 7B open-weight families under a fixed DPO recipe. In Mistral, capability is sharply non-monotonic: aggregated logic-probe margins become positive only in a narrow band near $β\approx 10^{-2}$ and revert outside it, with boundary points that are seed-sensitive. Across architectures under the same sweep, we observe qualitatively different response modes: sharp reorganization in Mistral, selective changes in Llama, and smooth trade-offs in Qwen. Critically, the DPO preference margin can anticorrelate with reasoning capability (Pearson $r=-0.91$ for Llama logic), so margin-based selection can prefer capability-impaired models. Training path also matters: exposure to high $β$ induces capability losses that persist even after $β$ is reduced (hysteresis). These findings motivate capability-resolved evaluation across the $β$ landscape rather than reliance on margins or aggregate benchmarks.

</details>


### [66] [AGZO: Activation-Guided Zeroth-Order Optimization for LLM Fine-Tuning](https://arxiv.org/abs/2601.17261)
*Wei Lin,Yining Jiang,Qingyu Song,Qiao Xiang,Hong Xu*

Main category: cs.LG

TL;DR: AGZO提出了一种激活引导的零阶优化方法，利用前向传播中的激活结构信息来指导参数扰动，相比各向同性扰动方法显著提升了优化效果，同时保持了相似的内存开销。


<details>
  <summary>Details</summary>
Motivation: 零阶优化在内存受限的LLM微调中很有前景，但现有方法使用各向同性扰动，忽略了前向传播中丰富的激活结构信息。研究发现线性层的梯度被限制在其输入激活张成的子空间中，这为改进零阶优化提供了关键洞见。

Method: 提出激活引导零阶优化（AGZO），在前向传播过程中动态提取紧凑的激活信息子空间，并将参数扰动限制在这个低秩子空间中，而不是使用各向同性扰动。

Result: 在Qwen3和Pangu模型上的实验表明，AGZO持续优于最先进的零阶基线方法，显著缩小了与一阶微调的性能差距，同时保持了与其他零阶方法几乎相同的峰值内存占用。

Conclusion: AGZO通过利用激活结构信息指导零阶优化，在保持内存效率的同时显著提升了优化效果，为零阶优化在LLM微调中的应用提供了更有效的解决方案。

Abstract: Zeroth-Order (ZO) optimization has emerged as a promising solution for fine-tuning LLMs under strict memory constraints, as it avoids the prohibitive memory cost of storing activations for backpropagation. However, existing ZO methods typically employ isotropic perturbations, neglecting the rich structural information available during the forward pass. In this paper, we identify a crucial link between gradient formation and activation structure: the gradient of a linear layer is confined to the subspace spanned by its input activations. Leveraging this insight, we propose Activation-Guided Zeroth-Order optimization (AGZO). Unlike prior methods, AGZO extracts a compact, activation-informed subspace on the fly during the forward pass and restricts perturbations to this low-rank subspace. We provide a theoretical framework showing that AGZO optimizes a subspace-smoothed objective and provably yields update directions with higher cosine similarity to the true gradient than isotropic baselines. Empirically, we evaluate AGZO on Qwen3 and Pangu models across various benchmarks. AGZO consistently outperforms state-of-the-art ZO baselines and significantly narrows the performance gap with first-order fine-tuning, while maintaining almost the same peak memory footprint as other ZO methods.

</details>


### [67] [Unrolled Neural Networks for Constrained Optimization](https://arxiv.org/abs/2601.17274)
*Samar Hadou,Alejandro Ribeiro*

Main category: cs.LG

TL;DR: 提出约束对偶展开（CDU）框架，通过两个耦合的神经网络模拟对偶上升算法，解决约束优化问题，在混合整数二次规划和无线网络功率分配中实现近最优解。


<details>
  <summary>Details</summary>
Motivation: 传统对偶上升算法在约束优化问题中收敛慢，需要手动调参。本文旨在开发可学习的加速版本，通过神经网络模拟优化过程，提高求解效率并增强泛化能力。

Method: 提出约束对偶展开（CDU）框架，包含两个耦合神经网络：原始网络模拟给定对偶乘子下的拉格朗日函数平稳点求解；对偶网络生成最优乘子轨迹。通过约束学习强制原始下降和对偶上升动态，采用交替训练策略更新两个网络。

Result: 在混合整数二次规划（MIQP）和无线网络功率分配问题上，CDU框架能够产生接近最优且接近可行的解，展现出强大的分布外泛化能力。

Conclusion: CDU框架成功将传统对偶上升算法转化为可学习的神经网络形式，在保持理论保证的同时实现了加速求解和良好泛化，为约束优化问题提供了新的深度学习解决方案。

Abstract: In this paper, we develop unrolled neural networks to solve constrained optimization problems, offering accelerated, learnable counterparts to dual ascent (DA) algorithms. Our framework, termed constrained dual unrolling (CDU), comprises two coupled neural networks that jointly approximate the saddle point of the Lagrangian. The primal network emulates an iterative optimizer that finds a stationary point of the Lagrangian for a given dual multiplier, sampled from an unknown distribution. The dual network generates trajectories towards the optimal multipliers across its layers while querying the primal network at each layer. Departing from standard unrolling, we induce DA dynamics by imposing primal-descent and dual-ascent constraints through constrained learning. We formulate training the two networks as a nested optimization problem and propose an alternating procedure that updates the primal and dual networks in turn, mitigating uncertainty in the multiplier distribution required for primal network training. We numerically evaluate the framework on mixed-integer quadratic programs (MIQPs) and power allocation in wireless networks. In both cases, our approach yields near-optimal near-feasible solutions and exhibits strong out-of-distribution (OOD) generalization.

</details>


### [68] [Latent-Space Contrastive Reinforcement Learning for Stable and Efficient LLM Reasoning](https://arxiv.org/abs/2601.17275)
*Lianlei Shan,Han Chen,Yixuan Wang,Zhenjie Liu,Wei Li*

Main category: cs.LG

TL;DR: DLR提出了一种潜在空间双向对比强化学习框架，将试错成本从昂贵的token级序列生成转移到连续潜在流形，通过冻结主模型参数避免灾难性遗忘，实现更稳定的训练收敛和更长的推理链。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理复杂多步推理任务时往往只是"统计拟合"而非系统逻辑推理。传统强化学习虽然引入了"先思考后说话"范式，但在高维离散token空间中面临样本效率低、梯度估计方差大和灾难性遗忘三大挑战。

Method: 提出DeepLatent Reasoning (DLR)框架：1) 使用轻量级辅助模型在潜在空间中采样K个推理链编码；2) 通过基于正确性和格式的双重奖励机制筛选高价值潜在轨迹；3) 仅将高价值轨迹输入冻结主模型进行单次解码；4) 设计对比学习目标实现潜在空间中的定向探索。

Result: 在可比较的GPU计算预算下，DLR实现了更稳定的训练收敛，支持更长的推理链，促进了推理能力的可持续积累，为LLMs提供了可靠且可扩展的强化学习路径。

Conclusion: DLR通过将强化学习从离散token空间转移到连续潜在空间，从根本上解决了传统方法的瓶颈，为LLMs的可靠和可扩展强化学习提供了可行路径，同时避免了灾难性遗忘问题。

Abstract: While Large Language Models (LLMs) demonstrate exceptional performance in surface-level text generation, their nature in handling complex multi-step reasoning tasks often remains one of ``statistical fitting'' rather than systematic logical deduction. Traditional Reinforcement Learning (RL) attempts to mitigate this by introducing a ``think-before-speak'' paradigm. However, applying RL directly in high-dimensional, discrete token spaces faces three inherent challenges: sample-inefficient rollouts, high gradient estimation variance, and the risk of catastrophic forgetting. To fundamentally address these structural bottlenecks, we propose \textbf{DeepLatent Reasoning (DLR)}, a latent-space bidirectional contrastive reinforcement learning framework. This framework shifts the trial-and-error cost from expensive token-level full sequence generation to the continuous latent manifold. Specifically, we introduce a lightweight assistant model to efficiently sample $K$ reasoning chain encodings within the latent space. These encodings are filtered via a dual reward mechanism based on correctness and formatting; only high-value latent trajectories are fed into a \textbf{frozen main model} for single-pass decoding. To maximize reasoning diversity while maintaining coherence, we design a contrastive learning objective to enable directed exploration within the latent space. Since the main model parameters remain frozen during optimization, this method mathematically eliminates catastrophic forgetting. Experiments demonstrate that under comparable GPU computational budgets, DLR achieves more stable training convergence, supports longer-horizon reasoning chains, and facilitates the sustainable accumulation of reasoning capabilities, providing a viable path toward reliable and scalable reinforcement learning for LLMs.

</details>


### [69] [Tabular Foundation Models are Strong Graph Anomaly Detectors](https://arxiv.org/abs/2601.17301)
*Yunhui Liu,Tieke He,Yongchao Liu,Can Yi,Hong Jin,Chuntao Hong*

Main category: cs.LG

TL;DR: TFM4GAD将表格基础模型(TFMs)应用于图异常检测，通过"扁平化"图结构构建增强特征表，实现无需重新训练的跨领域异常检测，性能超越专门训练的GAD模型。


<details>
  <summary>Details</summary>
Motivation: 现有图异常检测(GAD)方法遵循"一个模型对应一个数据集"的模式，导致计算成本高、数据需求大、泛化能力差。需要一种能够跨不同图检测异常而无需重新训练的基础模型解决方案。

Method: TFM4GAD通过"扁平化"图结构，构建增强特征表：将原始节点特征与拉普拉斯嵌入、局部和全局结构特征、异常敏感邻域聚合相结合。然后使用表格基础模型(TFMs)在完全上下文学习机制下处理这些特征。

Result: 在多个数据集和各种TFM骨干网络上的广泛实验表明，TFM4GAD显著超越了专门从头训练的GAD模型性能，提供了强大的通用图异常检测能力。

Conclusion: 该工作为利用TFMs作为强大、通用的图异常检测器提供了新视角和实践范式，解决了跨领域图异常检测中的特征异质性、泛化能力和标签稀缺等核心挑战。

Abstract: Graph anomaly detection (GAD), which aims to identify abnormal nodes that deviate from the majority, has become increasingly important in high-stakes Web domains. However, existing GAD methods follow a "one model per dataset" paradigm, leading to high computational costs, substantial data demands, and poor generalization when transferred to new datasets. This calls for a foundation model that enables a "one-for-all" GAD solution capable of detecting anomalies across diverse graphs without retraining. Yet, achieving this is challenging due to the large structural and feature heterogeneity across domains. In this paper, we propose TFM4GAD, a simple yet effective framework that adapts tabular foundation models (TFMs) for graph anomaly detection. Our key insight is that the core challenges of foundation GAD, handling heterogeneous features, generalizing across domains, and operating with scarce labels, are the exact problems that modern TFMs are designed to solve via synthetic pre-training and powerful in-context learning. The primary challenge thus becomes structural: TFMs are agnostic to graph topology. TFM4GAD bridges this gap by "flattening" the graph, constructing an augmented feature table that enriches raw node features with Laplacian embeddings, local and global structural characteristics, and anomaly-sensitive neighborhood aggregations. This augmented table is processed by a TFM in a fully in-context regime. Extensive experiments on multiple datasets with various TFM backbones reveal that TFM4GAD surprisingly achieves significant performance gains over specialized GAD models trained from scratch. Our work offers a new perspective and a practical paradigm for leveraging TFMs as powerful, generalist graph anomaly detectors.

</details>


### [70] [Decentralized Multi-Agent Swarms for Autonomous Grid Security in Industrial IoT: A Consensus-based Approach](https://arxiv.org/abs/2601.17303)
*Samaresh Kumar Singh,Joyjit Roy*

Main category: cs.LG

TL;DR: 提出了一种用于工业物联网的分布式多智能体群架构，通过边缘网关的自主AI代理实现分布式数字免疫系统，显著提升了安全响应速度和检测精度。


<details>
  <summary>Details</summary>
Motivation: 工业物联网环境扩展到数万台设备时，集中式安全监控架构存在严重延迟问题，攻击者可利用此漏洞破坏整个制造生态系统。

Method: 采用去中心化多智能体群架构，在每个边缘网关部署自主AI代理，通过轻量级P2P协议协作检测异常行为，无需将数据发送到云端。还包括基于共识的威胁验证流程，代理对识别威胁的威胁级别进行投票。

Result: 在模拟2000个IIoT设备的创新工厂测试环境中，DMAS表现出亚毫秒级响应时间（平均0.85ms），高负载下恶意活动检测准确率达97.3%，零日攻击检测准确率达87%。相比云解决方案减少89%网络带宽使用。

Conclusion: DMAS架构显著优于集中式和边缘计算基线，能够防止工业控制系统的实时级联故障，为大规模IIoT环境提供了高效、低延迟的安全解决方案。

Abstract: As Industrial Internet of Things (IIoT) environments expand to include tens of thousands of connected devices. The centralization of security monitoring architectures creates serious latency issues that savvy attackers can exploit to compromise an entire manufacturing ecosystem. This paper outlines a new, decentralized multi-agent swarm (DMAS) architecture that includes autonomous artificial intelligence (AI) agents at each edge gateway, functioning as a distributed digital "immune system" for IIoT networks. Instead of using a traditional static firewall approach, the DMAS agents communicate via a lightweight peer-to-peer protocol to cooperatively detect anomalous behavior across the IIoT network without sending data to a cloud infrastructure. The authors also outline a consensus-based threat validation (CVT) process in which agents vote on the threat level of an identified threat, enabling instant quarantine of a compromised node or nodes. The authors conducted experiments on a testbed that simulated an innovative factory environment with 2000 IIoT devices and found that the DMAS demonstrated sub-millisecond response times (average of 0.85ms), 97.3% accuracy in detecting malicious activity under high load, and 87% accuracy in detecting zero-day attacks. All significantly higher than baseline values for both centralized and edge computing. Additionally, the proposed architecture can prevent real-time cascading failures in industrial control systems and reduce network bandwidth use by 89% compared to cloud-based solutions.

</details>


### [71] [Weighted Graph Clustering via Scale Contraction and Graph Structure Learning](https://arxiv.org/abs/2601.17307)
*Haobing Liu,Yinuo Zhang,Tingting Wang,Ruobing Jiang,Yanwei Yu*

Main category: cs.LG

TL;DR: 提出收缩边权重感知图聚类网络，通过图收缩模块减少图规模，通过边权重感知注意力网络减弱噪声连接，提升加权图聚类效果。


<details>
  <summary>Details</summary>
Motivation: 现有图聚类方法未能充分利用边权重信息，而利用边权重面临两大挑战：1) 边权重增加存储和计算成本，需要减少图规模同时保留对聚类有益的节点；2) 边权重信息可能包含噪声，影响聚类结果。现有研究很少能同时优化聚类和边权重。

Method: 提出收缩边权重感知图聚类网络：1) 设计面向聚类的图收缩模块，减少图规模同时保留重要节点；2) 设计边权重感知注意力网络，识别并减弱噪声连接。

Result: 在三个真实世界加权图数据集上的实验表明，模型性能优于最佳基线方法。图收缩模块能显著减少训练时间和存储空间。

Conclusion: 该模型能有效处理加权图聚类中的噪声和计算效率问题，通过联合优化聚类和边权重，提升聚类效果同时降低计算成本。

Abstract: Graph clustering aims to partition nodes into distinct clusters based on their similarity, thereby revealing relationships among nodes. Nevertheless, most existing methods do not fully utilize these edge weights. Leveraging edge weights in graph clustering tasks faces two critical challenges. (1) The introduction of edge weights may significantly increase storage space and training time, making it essential to reduce the graph scale while preserving nodes that are beneficial for the clustering task. (2) Edge weight information may inherently contain noise that negatively impacts clustering results. However, few studies can jointly optimize clustering and edge weights, which is crucial for mitigating the negative impact of noisy edges on clustering task. To address these challenges, we propose a contractile edge-weight-aware graph clustering network. Specifically, a cluster-oriented graph contraction module is designed to reduce the graph scale while preserving important nodes. An edge-weight-aware attention network is designed to identify and weaken noisy connections. In this way, we can more easily identify and mitigate the impact of noisy edges during the clustering process, thus enhancing clustering effectiveness. We conducted extensive experiments on three real-world weighted graph datasets. In particular, our model outperforms the best baseline, demonstrating its superior performance. Furthermore, experiments also show that the proposed graph contraction module can significantly reduce training time and storage space.

</details>


### [72] [PAR: Plausibility-aware Amortized Recourse Generation](https://arxiv.org/abs/2601.17309)
*Anagha Sabu,Vidhya S,Narayanan C Krishnan*

Main category: cs.LG

TL;DR: PAR提出一种基于约束最大后验推断的算法补救方法，通过可处理概率模型直接估计补救可能性，生成高效、有效且高度可信的补救方案。


<details>
  <summary>Details</summary>
Motivation: 算法补救旨在为不利模型决策推荐可操作的改变，但现有方法在生成现实可行且高度可信的补救方案方面存在不足。需要一种能同时考虑补救约束和补救方案似然性的方法。

Method: 将补救问题形式化为约束最大后验推断问题，在可接受类别数据分布下寻找高似然性的反事实。提出PAR方法，使用可处理概率模型直接估计补救似然性，通过摊销近似推理高效生成补救方案。训练目标包括最大化可接受类别分布下的似然性、最小化拒绝类别分布下的似然性，以及编码其他补救约束的损失函数。还包含基于邻域的调节机制以定制化生成补救方案。

Result: 在广泛使用的算法补救数据集上验证PAR，证明其能高效生成有效、与事实相似、稀疏且高度可信的补救方案，性能优于现有最先进方法。

Conclusion: PAR通过将补救问题形式化为约束MAP推断，并使用可处理概率模型直接估计似然性，能够生成高质量、高效且高度可信的算法补救方案，为算法补救领域提供了有效的解决方案。

Abstract: Algorithmic recourse aims to recommend actionable changes to a factual's attributes that flip an unfavorable model decision while remaining realistic and feasible. We formulate recourse as a Constrained Maximum A-Posteriori (MAP) inference problem under the accepted-class data distribution seeking counterfactuals with high likelihood while respecting other recourse constraints. We present PAR, an amortized approximate inference procedure that generates highly likely recourses efficiently. Recourse likelihood is estimated directly using tractable probabilistic models that admit exact likelihood evaluation and efficient gradient propagation that is useful during training. The recourse generator is trained with the objective of maximizing the likelihood under the accepted-class distribution while minimizing the likelihood under the denied-class distribution and other losses that encode recourse constraints. Furthermore, PAR includes a neighborhood-based conditioning mechanism to promote recourse generation that is customized to a factual. We validate PAR on widely used algorithmic recourse datasets and demonstrate its efficiency in generating recourses that are valid, similar to the factual, sparse, and highly plausible, yielding superior performance over existing state-of-the-art approaches.

</details>


### [73] [Conformal Feedback Alignment: Quantifying Answer-Level Reliability for Robust LLM Alignment](https://arxiv.org/abs/2601.17329)
*Tiejin Chen,Xiaoou Liu,Vishnu Nandam,Kuan-Ru Liou,Hua Wei*

Main category: cs.LG

TL;DR: CFA使用共形预测量化答案可靠性，为偏好对齐提供统计保证的权重，提升鲁棒性和数据效率


<details>
  <summary>Details</summary>
Motivation: 现有基于偏好的对齐方法（如RLHF）面临偏好标签噪声和不一致问题，现有不确定性感知方法只关注偏好权重，忽略了答案本身的可靠性

Method: 提出Conformal Feedback Alignment (CFA)框架，利用共形预测构建具有可控覆盖率的预测集来量化答案级可靠性，并将这些可靠性聚合为DPO和PPO训练的权重

Result: 在不同数据集上的实验表明，CFA提高了对齐的鲁棒性和数据效率，证明建模答案侧不确定性能补充偏好级权重

Conclusion: CFA通过共形预测为偏好对齐提供统计保证的答案可靠性量化，实现了更鲁棒、数据高效的对齐，代码已开源

Abstract: Preference-based alignment like Reinforcement Learning from Human Feedback (RLHF) learns from pairwise preferences, yet the labels are often noisy and inconsistent. Existing uncertainty-aware approaches weight preferences, but ignore a more fundamental factor: the reliability of the \emph{answers} being compared. To address the problem, we propose Conformal Feedback Alignment (CFA), a framework that grounds preference weighting in the statistical guarantees of Conformal Prediction (CP). CFA quantifies answer-level reliability by constructing conformal prediction sets with controllable coverage and aggregates these reliabilities into principled weights for both DPO- and PPO-style training. Experiments across different datasets show that CFA improves alignment robustness and data efficiency, highlighting that modeling \emph{answer-side} uncertainty complements preference-level weighting and yields more robust, data-efficient alignment. Codes are provided here.

</details>


### [74] [Thermodynamically Optimal Regularization under Information-Geometric Constraints](https://arxiv.org/abs/2601.17330)
*Laurent Caraffa*

Main category: cs.LG

TL;DR: 该论文提出了一个统一的理论框架，将热力学最优性、信息几何和正则化联系起来，证明了在特定假设下Fisher-Rao度量是信念空间的唯一容许几何，热力学最优正则化对应于最小化到参考状态的Fisher-Rao距离平方。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习依赖于一系列经验上成功但理论上异构的正则化技术（如权重衰减、dropout、指数移动平均），同时训练大模型的能量成本急剧增加，这引发了学习算法是否接近任何基本效率界限的问题。

Method: 提出了一个统一的理论框架，基于三个明确假设：(A1)最优性需要内在的、参数化不变的信息度量；(A2)信念状态由已知约束下的最大熵分布建模；(A3)最优过程是准静态的。在此框架下证明了条件最优性定理，推导了高斯和圆形信念模型的诱导几何，并提出了学习的热力学效率概念。

Result: 证明了Fisher-Rao度量是信念空间的唯一容许几何，热力学最优正则化对应于最小化到参考状态的Fisher-Rao距离平方。推导出高斯信念模型对应双曲流形，圆形信念模型对应von Mises流形，并表明经典正则化方案在结构上无法保证热力学最优性。

Conclusion: 这项工作为机器学习中的正则化提供了原则性的几何和热力学基础，提出了可实验验证的预测，并为理解学习算法的基本效率界限提供了理论框架。

Abstract: Modern machine learning relies on a collection of empirically successful but theoretically heterogeneous regularization techniques, such as weight decay, dropout, and exponential moving averages. At the same time, the rapidly increasing energetic cost of training large models raises the question of whether learning algorithms approach any fundamental efficiency bound. In this work, we propose a unifying theoretical framework connecting thermodynamic optimality, information geometry, and regularization.
  Under three explicit assumptions -- (A1) that optimality requires an intrinsic, parametrization-invariant measure of information, (A2) that belief states are modeled by maximum-entropy distributions under known constraints, and (A3) that optimal processes are quasi-static -- we prove a conditional optimality theorem. Specifically, the Fisher--Rao metric is the unique admissible geometry on belief space, and thermodynamically optimal regularization corresponds to minimizing squared Fisher--Rao distance to a reference state.
  We derive the induced geometries for Gaussian and circular belief models, yielding hyperbolic and von Mises manifolds, respectively, and show that classical regularization schemes are structurally incapable of guaranteeing thermodynamic optimality. We introduce a notion of thermodynamic efficiency of learning and propose experimentally testable predictions. This work provides a principled geometric and thermodynamic foundation for regularization in machine learning.

</details>


### [75] [Power-based Partial Attention: Bridging Linear-Complexity and Full Attention](https://arxiv.org/abs/2601.17334)
*Yufeng Huang*

Main category: cs.LG

TL;DR: 论文提出了一种幂基部分注意力机制（PPA），其复杂度为O(L^{1+p})，其中0≤p≤1，通过调节p值可以探索从线性复杂度到二次复杂度注意力之间的性能变化，发现存在p<1使得次二次复杂度注意力能达到与全注意力相当的性能。


<details>
  <summary>Details</summary>
Motivation: 虽然Transformer研究中普遍认为"注意力就是一切"，但从未系统量化过到底需要多少注意力。需要探究二次复杂度O(L^2)的注意力是否必要，是否存在次二次复杂度的注意力机制能达到可比性能。

Method: 提出了幂基部分注意力机制（PPA），复杂度为O(L^{1+p})，其中p从0到1可调：p=0对应滑动窗口注意力（线性复杂度），p=1对应全注意力。通过调节p值系统研究Transformer架构性能随注意力缩放行为的变化。

Result: 实验显示性能呈现S曲线行为：在p值的狭窄窗口内，性能从滑动窗口（线性复杂度）注意力过渡到全注意力，当p接近1时性能趋于稳定。存在0<p<1使得O(L^{1+p})的次二次复杂度注意力足以达到与O(L^2)全注意力相似的结果。

Conclusion: 二次复杂度的注意力并非必要，存在次二次复杂度的注意力机制能够达到与全注意力相当的性能，这为设计更高效的Transformer架构提供了理论依据。

Abstract: It is widely accepted from transformer research that "attention is all we need", but the amount of attention required has never been systematically quantified. Is quadratic $O(L^2)$ attention necessary, or is there a sub-quadratic attention mechanism that can achieve comparable performance? To answer this question, we introduce power-based partial attention (PPA), an attention mechanism of order $O(L^{1+p})$, where $0 \leq p \leq 1$, such that $p=0$ corresponds to sliding window attention with linear complexity, and $p=1$ corresponds to full attention. With this attention construction, we can explore how transformer architecture performance varies as a function of the attention scaling behavior controlled by $p$. The overall trend from our experiments shows an S-curve-like behavior where the performance transitions from sliding-window (linear-complexity) attention to full attention over a narrow window of $p$ values, and plateaus as $p$ approaches $1$. In our experiments, we show that there exists $0<p<1$ such that $O(L^{1+p})$ attention is sufficient to achieve similar results as $O(L^2)$ full attention.

</details>


### [76] [Spectral Geometry for Deep Learning: Compression and Hallucination Detection via Random Matrix Theory](https://arxiv.org/abs/2601.17357)
*Davide Ettori*

Main category: cs.LG

TL;DR: 该论文提出基于谱几何和随机矩阵理论的统一框架，通过分析隐藏激活的特征值结构来解决大语言模型和深度神经网络的可靠性问题和计算成本问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型和深度神经网络虽然性能强大，但存在可靠性问题和计算成本高的挑战。需要开发既能检测模型不确定性（如幻觉）又能有效压缩模型的方法。

Method: 提出基于谱几何和随机矩阵理论的统一框架。包含两个主要贡献：1) EigenTrack：使用谱特征及其时间动态实时检测语言和视觉语言模型中的幻觉和分布外行为；2) RMT-KD：通过识别信息性谱分量并应用迭代知识蒸馏来压缩模型，保持准确性的同时减少计算成本。

Result: 谱统计量为大规模神经网络的监控不确定性和指导压缩提供了可解释且鲁棒的信号。EigenTrack能有效检测模型幻觉，RMT-KD能产生紧凑高效的模型同时保持准确性。

Conclusion: 谱几何和随机矩阵理论为解决大语言模型和深度神经网络的可靠性问题和计算成本问题提供了有效的统一框架，谱统计量是监控模型不确定性和指导模型压缩的有力工具。

Abstract: Large language models and deep neural networks achieve strong performance but suffer from reliability issues and high computational cost. This thesis proposes a unified framework based on spectral geometry and random matrix theory to address both problems by analyzing the eigenvalue structure of hidden activations. The first contribution, EigenTrack, is a real-time method for detecting hallucinations and out-of-distribution behavior in language and vision-language models using spectral features and their temporal dynamics. The second contribution, RMT-KD, is a principled compression method that identifies informative spectral components and applies iterative knowledge distillation to produce compact and efficient models while preserving accuracy. Together, these results show that spectral statistics provide interpretable and robust signals for monitoring uncertainty and guiding compression in large-scale neural networks.

</details>


### [77] [Robust Privacy: Inference-Time Privacy through Certified Robustness](https://arxiv.org/abs/2601.17360)
*Jiankai Jin,Xiangzheng Zhang,Zhao Liu,Deyue Zhang,Quanchen Zou*

Main category: cs.LG

TL;DR: 提出Robust Privacy (RP)作为推理时隐私保护概念，通过模型预测在输入邻域内的不变性来保护隐私，并开发Attribute Privacy Enhancement (APE)将输入级不变性转化为属性级隐私效果。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统在推理时可能泄露敏感输入属性，现有隐私保护方法在推理时保护不足，需要一种新的推理时隐私保护概念。

Method: 引入Robust Privacy (RP)概念，基于认证鲁棒性思想：如果模型预测在输入x的半径R邻域内保持不变，则x享有R-Robust Privacy。开发Attribute Privacy Enhancement (APE)将输入级不变性转化为属性级隐私保护。

Result: 在受控推荐任务中，RP扩展了与正推荐兼容的敏感属性值集合；在模型反演攻击实验中，即使小噪声水平(σ=0.1)也能将攻击成功率从73%降至4%，且可部分缓解攻击(降至44%)而不影响模型性能。

Conclusion: Robust Privacy提供了一种有效的推理时隐私保护框架，既能保护敏感属性不被推断，又能缓解模型反演攻击，在隐私保护与模型性能间取得平衡。

Abstract: Machine learning systems can produce personalized outputs that allow an adversary to infer sensitive input attributes at inference time. We introduce Robust Privacy (RP), an inference-time privacy notion inspired by certified robustness: if a model's prediction is provably invariant within a radius-$R$ neighborhood around an input $x$ (e.g., under the $\ell_2$ norm), then $x$ enjoys $R$-Robust Privacy, i.e., observing the prediction cannot distinguish $x$ from any input within distance $R$ of $x$. We further develop Attribute Privacy Enhancement (APE) to translate input-level invariance into an attribute-level privacy effect. In a controlled recommendation task where the decision depends primarily on a sensitive attribute, we show that RP expands the set of sensitive-attribute values compatible with a positive recommendation, expanding the inference interval accordingly. Finally, we empirically demonstrate that RP also mitigates model inversion attacks (MIAs) by masking fine-grained input-output dependence. Even at small noise levels ($σ=0.1$), RP reduces the attack success rate (ASR) from 73% to 4% with partial model performance degradation. RP can also partially mitigate MIAs (e.g., ASR drops to 44%) with no model performance degradation.

</details>


### [78] [Diversified Scaling Inference in Time Series Foundation Models](https://arxiv.org/abs/2601.17376)
*Ruijin Hua,Zichuan Liu,Kun Zhang,Yiyuan Yang*

Main category: cs.LG

TL;DR: 本文系统研究了时间序列基础模型在推理时的计算潜力，发现标准采样方法因探索不足而无法遵循缩放定律，提出通过多样化推理缩放（使用时间序列扰动）来扩展生成分布支持，显著提升性能且无需参数更新。


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型主要依赖大规模预训练，但推理时的计算潜力尚未充分挖掘。本文旨在探索两个关键问题：TSFMs在标准采样推理缩放下的行为表现，以及通过控制采样多样性是否能提升性能。

Method: 首先分析TSFMs在标准采样下的特性，发现其因解空间探索不足而无法遵循缩放定律。然后通过定制化的时间序列扰动实现多样化推理缩放，扩展生成分布的支持范围。理论分析了多样性-保真度权衡，推导出多样化采样优于标准采样的关键样本阈值。

Result: 在多种TSFMs和数据集上的广泛实验表明，适当的多样化推理缩放能带来显著的性能提升，且无需参数更新。作为应用，提出了RobustMSE指标来量化固定预算下TSFM的性能上限。

Conclusion: 推理设计是TSFM优化的关键计算高效维度。研究阐明了这些因素的相互作用，使得在不重新训练TSFMs的情况下，通过并行环境中的多样化大规模推理时间序列实现可靠性能成为可能。

Abstract: The advancement of Time Series Foundation Models (TSFMs) has been driven primarily by large-scale pre-training, but inference-time compute potential remains largely untapped. This work systematically investigates two questions: how do TSFMs behave under standard sampling-based inference scaling, and can controlled sampling diversity enhance performance? We first examine the properties of TSFMs under standard sampling often fail to adhere to scaling laws due to insufficient exploration of the solution space. Building on this, we then delve into diversified inference scaling via tailored time series perturbations to expand the generative distribution's support. We theoretically analyze the diversity-fidelity trade-off and derive a critical sample threshold for diversified sampling to outperform standard sampling. Extensive experiments across various TSFMs and datasets show proper diversified inference scaling yields substantial performance gains without parameter updates, establishing inference design as a critical, compute-efficient dimension of TSFM optimization. As an application, we propose RobustMSE, a rigorous metric to quantify the headroom performance of TSFM under a fixed budget. Overall, our findings clarify these factor interactions, enabling reliable performance via diverse large-scale inference time series in parallel environments without re-training TSFMs.

</details>


### [79] [GO-OSC and VASH: Geometry-Aware Representation Learning for Early Degradation Detection in Oscillatory Systems](https://arxiv.org/abs/2601.17396)
*Vashista Nobaub*

Main category: cs.LG

TL;DR: GO-OSC是一个几何感知的振荡时间序列表示学习框架，通过强制规范化和可识别的潜在参数化，实现对早期退化（如相位抖动、频率漂移）的稳定检测，相比传统能量基方法具有更高灵敏度。


<details>
  <summary>Details</summary>
Motivation: 振荡系统的早期退化通常表现为动力学的几何畸变（如相位抖动、频率漂移），这些变化在信号能量变化可检测之前就已出现。传统的能量基诊断方法和无约束学习表示对此结构不敏感，导致检测延迟或不稳定。

Method: 提出GO-OSC框架：1）强制规范化和可识别的潜在参数化，实现跨短、无标签窗口的稳定比较和聚合；2）定义一族不变线性几何探针，针对潜在空间中与退化相关的方向；3）提供理论分析，证明在早期仅相位退化情况下，能量基统计量的检测能力为零阶，而几何探针具有严格正灵敏度。

Result: 理论分析表明，在非可识别表示下线性探针会失效，而规范化能恢复统计可检测性。在合成基准和真实振动数据集上的实验验证了理论，展示了更早的检测、改进的数据效率和操作条件变化的鲁棒性。

Conclusion: GO-OSC框架通过几何感知的表示学习和规范化，解决了振荡系统早期退化检测的挑战，相比传统能量基方法具有理论保证的更高灵敏度，在实际应用中表现出优越性能。

Abstract: Early-stage degradation in oscillatory systems often manifests as geometric distortions of the dynamics, such as phase jitter, frequency drift, or loss of coherence, long before changes in signal energy are detectable. In this regime, classical energy-based diagnostics and unconstrained learned representations are structurally insensitive, leading to delayed or unstable detection. We introduce GO-OSC, a geometry-aware representation learning framework for oscillatory time series that enforces a canonical and identifiable latent parameterization, enabling stable comparison and aggregation across short, unlabeled windows. Building on this representation, we define a family of invariant linear geometric probes that target degradation-relevant directions in latent space. We provide theoretical results showing that under early phase-only degradation, energy-based statistics have zero first-order detection power, whereas geometric probes achieve strictly positive sensitivity. Our analysis characterizes when and why linear probing fails under non-identifiable representations and shows how canonicalization restores statistical detectability. Experiments on synthetic benchmarks and real vibration datasets validate the theory, demonstrating earlier detection, improved data efficiency, and robustness to operating condition changes.

</details>


### [80] [Efficient Dilated Squeeze and Excitation Neural Operator for Differential Equations](https://arxiv.org/abs/2601.17407)
*Prajwal Chauhan,Salah Eddine Choutri,Saif Eddin Jabari*

Main category: cs.LG

TL;DR: D-SENO：一种轻量级神经算子框架，结合扩张卷积和挤压-激励模块，在多种PDE问题上实现快速训练和准确推理，比传统Transformer模型快约20倍。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的模型和神经算子参数过多，导致训练成本高、部署缓慢，需要开发轻量级但准确的PDE求解器。

Method: 提出D-SENO框架，结合扩张卷积块（捕获宽感受野和长程物理依赖）和挤压-激励模块（通过通道注意力自适应重新校准特征通道）。精心选择的扩张率使感受野聚焦于关键区域。

Result: 在空气动力学势流、多孔介质达西流、管道泊肃叶流和不可压缩Navier-Stokes涡流场等多种PDE基准测试中，训练速度比标准Transformer模型和神经算子快约20倍，同时准确度达到或超过现有方法。

Conclusion: D-SENO通过结合扩张卷积和挤压-激励模块，实现了轻量级、高效且准确的PDE求解，为物理驱动偏微分方程的快速准确代理模型提供了有效解决方案。

Abstract: Fast and accurate surrogates for physics-driven partial differential equations (PDEs) are essential in fields such as aerodynamics, porous media design, and flow control. However, many transformer-based models and existing neural operators remain parameter-heavy, resulting in costly training and sluggish deployment. We propose D-SENO (Dilated Squeeze-Excitation Neural Operator), a lightweight operator learning framework for efficiently solving a wide range of PDEs, including airfoil potential flow, Darcy flow in porous media, pipe Poiseuille flow, and incompressible Navier Stokes vortical fields. D-SENO combines dilated convolution (DC) blocks with squeeze-and-excitation (SE) modules to jointly capture wide receptive fields and dynamics alongside channel-wise attention, enabling both accurate and efficient PDE inference. Carefully chosen dilation rates allow the receptive field to focus on critical regions, effectively modeling long-range physical dependencies. Meanwhile, the SE modules adaptively recalibrate feature channels to emphasize dynamically relevant scales. Our model achieves training speed of up to approximately $20\times$ faster than standard transformer-based models and neural operators, while also surpassing (or matching) them in accuracy across multiple PDE benchmarks. Ablation studies show that removing the SE modules leads to a slight drop in performance.

</details>


### [81] [Active Hypothesis Testing for Correlated Combinatorial Anomaly Detection](https://arxiv.org/abs/2601.17430)
*Zichuan Yang,Yiming Xing*

Main category: cs.LG

TL;DR: 提出ECC-AHT算法，用于相关噪声环境下异常流检测，通过主动噪声消除和差分感知实现最优样本复杂度


<details>
  <summary>Details</summary>
Motivation: 现有组合臂和假设检验方法通常假设观测独立，无法利用相关性进行高效测量设计，而网络物理系统中的监控和安全需要处理相关噪声下的异常流识别

Method: 提出ECC-AHT自适应算法，选择连续约束测量以最大化竞争假设间的Chernoff信息，通过差分感知实现主动噪声消除

Result: ECC-AHT达到最优样本复杂度保证，在合成和真实世界相关环境中显著优于现有基线方法

Conclusion: ECC-AHT算法有效解决了相关噪声下的异常流检测问题，通过利用相关性实现高效测量设计，在监控和安全应用中具有重要价值

Abstract: We study the problem of identifying an anomalous subset of streams under correlated noise, motivated by monitoring and security in cyber-physical systems. This problem can be viewed as a form of combinatorial pure exploration, where each stream plays the role of an arm and measurements must be allocated sequentially under uncertainty. Existing combinatorial bandit and hypothesis testing methods typically assume independent observations and fail to exploit correlation for efficient measurement design. We propose ECC-AHT, an adaptive algorithm that selects continuous, constrained measurements to maximize Chernoff information between competing hypotheses, enabling active noise cancellation through differential sensing. ECC-AHT achieves optimal sample complexity guarantees and significantly outperforms state-of-the-art baselines in both synthetic and real-world correlated environments. The code is available on https://github.com/VincentdeCristo/ECC-AHT

</details>


### [82] [Data-driven Clustering and Merging of Adapters for On-device Large Language Models](https://arxiv.org/abs/2601.17441)
*Ondrej Bohdal,Taha Ceritli,Mete Ozay,Jijoong Moon,Kyeng-Hun Lee,Hyeonmok Ko,Umberto Michieli*

Main category: cs.LG

TL;DR: 提出D2C方法，通过少量任务示例进行适配器聚类，将多个任务适配器合并为多任务适配器，以在存储受限的设备上提升性能。


<details>
  <summary>Details</summary>
Motivation: 移动设备上存储所有任务适配器不现实，但通常有足够容量存储有限数量的适配器参数。现有文献未探索如何选择具有跨任务泛化能力的代表性适配器。

Method: 提出D2C适配器聚类方法，利用少量任务特定示例（如每个任务10个），采用迭代优化过程精炼聚类分配，将每个簇内的适配器合并为多任务适配器。

Result: 实验结果表明，该方法在考虑存储预算的情况下有效提升了性能。

Conclusion: D2C方法解决了资源受限设备上适配器选择问题，通过聚类和合并适配器实现了更好的跨任务泛化能力。

Abstract: On-device large language models commonly employ task-specific adapters (e.g., LoRAs) to deliver strong performance on downstream tasks. While storing all available adapters is impractical due to memory constraints, mobile devices typically have sufficient capacity to store a limited number of these parameters. This raises a critical challenge: how to select representative adapters that generalize well across multiple tasks - a problem that remains unexplored in existing literature. We propose a novel method D2C for adapter clustering that leverages minimal task-specific examples (e.g., 10 per task) and employs an iterative optimization process to refine cluster assignments. The adapters within each cluster are merged, creating multi-task adapters deployable on resource-constrained devices. Experimental results demonstrate that our method effectively boosts performance for considered storage budgets.

</details>


### [83] [DREAM: Dual-Standard Semantic Homogeneity with Dynamic Optimization for Graph Learning with Label Noise](https://arxiv.org/abs/2601.17449)
*Yusheng Zhao,Jiaye Xie,Qixin Zhang,Weizhi Zhang,Xiao Luo,Zhiping Xiao,Philip S. Yu,Ming Zhang*

Main category: cs.LG

TL;DR: DREAM是一种针对标签噪声图学习的双重标准语义同质性动态优化方法，通过关系感知的动态优化框架和双重标准锚点选择策略，有效处理图数据中的不可靠标签问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界图数据中的标签可靠性无法保证，现有方法难以区分可靠与不可靠节点，且忽略了图拓扑中的关系信息，需要一种能够同时处理这两个问题的可靠图学习方法。

Method: 提出DREAM方法：1）关系感知动态优化框架，迭代评估图中每个标记节点的可靠性；2）双重标准选择策略，基于节点邻近性和图拓扑选择锚点集；3）计算目标节点与锚点之间的语义同质性，指导优化过程。

Result: 在六个不同领域的图数据集上，针对三种类型的图标签噪声进行广泛实验，与竞争基线相比，DREAM表现出显著的有效性和优越性能。

Conclusion: DREAM通过结合关系信息和动态优化机制，成功解决了图学习中标签噪声问题，提供了理论分析和实验验证，为不可靠标签下的图学习提供了有效解决方案。

Abstract: Graph neural networks (GNNs) have been widely used in various graph machine learning scenarios. Existing literature primarily assumes well-annotated training graphs, while the reliability of labels is not guaranteed in real-world scenarios. Recently, efforts have been made to address the problem of graph learning with label noise. However, existing methods often (i) struggle to distinguish between reliable and unreliable nodes, and (ii) overlook the relational information embedded in the graph topology. To tackle this problem, this paper proposes a novel method, Dual-Standard Semantic Homogeneity with Dynamic Optimization (DREAM), for reliable, relation-informed optimization on graphs with label noise. Specifically, we design a relation-informed dynamic optimization framework that iteratively reevaluates the reliability of each labeled node in the graph during the optimization process according to the relation of the target node and other nodes. To measure this relation comprehensively, we propose a dual-standard selection strategy that selects a set of anchor nodes based on both node proximity and graph topology. Subsequently, we compute the semantic homogeneity between the target node and the anchor nodes, which serves as guidance for optimization. We also provide a rigorous theoretical analysis to justify the design of DREAM. Extensive experiments are performed on six graph datasets across various domains under three types of graph label noise against competing baselines, and the results demonstrate the effectiveness of the proposed DREAM.

</details>


### [84] [Harnessing Reasoning Trajectories for Hallucination Detection via Answer-agreement Representation Shaping](https://arxiv.org/abs/2601.17467)
*Jianxiong Zhang,Bing Guo,Yuming Jiang,Haobo Wang,Bo An,Xuefeng Du*

Main category: cs.LG

TL;DR: ARS通过扰动推理轨迹的边界嵌入生成反事实答案，学习基于答案一致性的表示，以检测大型推理模型中的幻觉风险，无需人工标注即可提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）经常生成看似连贯但答案错误的推理轨迹，使得幻觉检测变得困难。现有方法直接使用轨迹文本或原始隐藏状态进行检测存在局限性：轨迹形式多变，检测器容易过拟合到表面模式而非答案有效性。

Method: 提出答案一致性表示塑形（ARS）方法：通过小规模潜在干预（扰动轨迹边界嵌入）生成反事实答案，根据扰动后答案是否与原答案一致进行标注，学习使答案一致状态聚集、不一致状态分离的表示，从而暴露指示幻觉风险的潜在不稳定性。

Result: 实验表明，ARS能持续改进幻觉检测性能，相比强基线方法取得显著提升。塑形后的嵌入表示可与现有基于嵌入的检测器即插即用，且训练过程无需人工标注。

Conclusion: ARS通过显式编码答案稳定性，学习检测友好的轨迹条件表示，有效解决了大型推理模型中幻觉检测的挑战，提供了一种无需人工标注的高效检测方法。

Abstract: Large reasoning models (LRMs) often generate long, seemingly coherent reasoning traces yet still produce incorrect answers, making hallucination detection challenging. Although trajectories contain useful signals, directly using trace text or vanilla hidden states for detection is brittle: traces vary in form and detectors can overfit to superficial patterns rather than answer validity. We introduce Answer-agreement Representation Shaping (ARS), which learns detection-friendly trace-conditioned representations by explicitly encoding answer stability. ARS generates counterfactual answers through small latent interventions, specifically, perturbing the trace-boundary embedding, and labels each perturbation by whether the resulting answer agrees with the original. It then learns representations that bring answer-agreeing states together and separate answer-disagreeing ones, exposing latent instability indicative of hallucination risk. The shaped embeddings are plug-and-play with existing embedding-based detectors and require no human annotations during training. Experiments demonstrate that ARS consistently improves detection and achieves substantial gains over strong baselines.

</details>


### [85] [Identifying and Correcting Label Noise for Robust GNNs via Influence Contradiction](https://arxiv.org/abs/2601.17469)
*Wei Ju,Wei Zhang,Siyu Yi,Zhengyang Mao,Yifan Wang,Jingyang Yuan,Zhiping Xiao,Ziyue Qiao,Ming Zhang*

Main category: cs.LG

TL;DR: ICGNN：一种利用图结构信息处理噪声标签的新方法，通过影响矛盾评分检测噪声节点，结合邻居预测修正标签，并利用伪标签增强监督信号


<details>
  <summary>Details</summary>
Motivation: 现实场景中图数据常存在标签噪声（标注错误或不一致），这会严重影响图神经网络的鲁棒性和性能，需要有效方法来处理图结构数据中的噪声标签问题

Method: 1) 基于图扩散矩阵设计影响矛盾评分(ICS)作为噪声指示器，量化节点标签可信度；2) 使用高斯混合模型精确检测噪声标签；3) 开发软策略结合邻居节点预测修正检测到的噪声标签；4) 对大量未标记节点进行伪标签生成，提供辅助监督信号

Result: 在基准数据集上的实验表明该方法具有优越性

Conclusion: ICGNN能有效利用图结构信息缓解噪声标签带来的挑战，通过综合的噪声检测、标签修正和伪标签策略提升图神经网络在噪声环境下的鲁棒性

Abstract: Graph Neural Networks (GNNs) have shown remarkable capabilities in learning from graph-structured data with various applications such as social analysis and bioinformatics. However, the presence of label noise in real scenarios poses a significant challenge in learning robust GNNs, and their effectiveness can be severely impacted when dealing with noisy labels on graphs, often stemming from annotation errors or inconsistencies. To address this, in this paper we propose a novel approach called ICGNN that harnesses the structure information of the graph to effectively alleviate the challenges posed by noisy labels. Specifically, we first design a novel noise indicator that measures the influence contradiction score (ICS) based on the graph diffusion matrix to quantify the credibility of nodes with clean labels, such that nodes with higher ICS values are more likely to be detected as having noisy labels. Then we leverage the Gaussian mixture model to precisely detect whether the label of a node is noisy or not. Additionally, we develop a soft strategy to combine the predictions from neighboring nodes on the graph to correct the detected noisy labels. At last, pseudo-labeling for abundant unlabeled nodes is incorporated to provide auxiliary supervision signals and guide the model optimization. Experiments on benchmark datasets show the superiority of our proposed approach.

</details>


### [86] [LeanTutor: Towards a Verified AI Mathematical Proof Tutor](https://arxiv.org/abs/2601.17473)
*Manooshree Patel,Rayna Bhattacharyya,Thomas Lu,Arnav Mehta,Niels Voss,Narges Norouzi,Gireeja Ranade*

Main category: cs.LG

TL;DR: 开发结合LLM与定理证明器的AI数学证明辅导系统LeanTutor，包含自动形式化/证明检查、下一步生成和自然语言反馈三个模块，并创建PeanoBench数据集进行评估


<details>
  <summary>Details</summary>
Motivation: LLM虽然支持自然语言交流但容易出错，定理证明器（如Lean）能保证正确性但学习门槛高，需要结合两者优势开发可靠的数学证明辅导工具

Method: 提出LeanTutor系统，包含三个核心模块：1)自动形式化/证明检查器，2)下一步生成器，3)自然语言反馈生成器。创建PeanoBench数据集（371个Peano算术证明）用于评估

Result: 提出了概念验证系统LeanTutor，通过结合LLM的自然语言交互能力和定理证明器的正确性保证，为数学证明辅导提供可靠解决方案

Conclusion: 结合LLM与定理证明器的混合方法能够克服各自局限，为数学证明辅导提供既易于使用又保证正确性的解决方案，PeanoBench为这类系统评估提供了基准

Abstract: This paper considers the development of an AI-based provably-correct mathematical proof tutor. While Large Language Models (LLMs) allow seamless communication in natural language, they are error prone. Theorem provers such as Lean allow for provable-correctness, but these are hard for students to learn. We present a proof-of-concept system (LeanTutor) by combining the complementary strengths of LLMs and theorem provers. LeanTutor is composed of three modules: (i) an autoformalizer/proof-checker, (ii) a next-step generator, and (iii) a natural language feedback generator. To evaluate the system, we introduce PeanoBench, a dataset of 371 Peano Arithmetic proofs in human-written natural language and formal language, derived from the Natural Numbers Game.

</details>


### [87] [Unintended Memorization of Sensitive Information in Fine-Tuned Language Models](https://arxiv.org/abs/2601.17480)
*Marton Szep,Jorge Marin Ruiz,Georgios Kaissis,Paulina Seidl,Rüdiger von Eisenhart-Rothe,Florian Hinterwimmer,Daniel Rueckert*

Main category: cs.LG

TL;DR: 该研究系统调查了LLM微调中PII泄露风险，发现即使PII仅出现在输入而非训练目标中也会被记忆，并评估了四种隐私保护方法的权衡


<details>
  <summary>Details</summary>
Motivation: 微调大型语言模型在敏感数据集上存在意外记忆和PII泄露的重大风险，这违反隐私法规并危害个人安全。当前对仅出现在模型输入而非训练目标中的PII暴露这一关键漏洞研究不足

Method: 使用合成和真实数据集设计受控提取探针来量化意外PII记忆，研究语言、PII频率、任务类型和模型大小等因素的影响，并基准测试四种隐私保护方法（差分隐私、机器遗忘、正则化和偏好对齐）

Result: 研究发现后训练方法通常提供更一致的隐私-效用权衡，而差分隐私在特定设置中能显著减少泄露，但可能引入训练不稳定性。PII记忆行为受多种因素影响

Conclusion: 微调LLM中的记忆问题仍然是一个持续挑战，需要强大、可扩展的隐私保护技术来平衡隐私保护和任务性能

Abstract: Fine-tuning Large Language Models (LLMs) on sensitive datasets carries a substantial risk of unintended memorization and leakage of Personally Identifiable Information (PII), which can violate privacy regulations and compromise individual safety. In this work, we systematically investigate a critical and underexplored vulnerability: the exposure of PII that appears only in model inputs, not in training targets. Using both synthetic and real-world datasets, we design controlled extraction probes to quantify unintended PII memorization and study how factors such as language, PII frequency, task type, and model size influence memorization behavior. We further benchmark four privacy-preserving approaches including differential privacy, machine unlearning, regularization, and preference alignment, evaluating their trade-offs between privacy and task performance. Our results show that post-training methods generally provide more consistent privacy-utility trade-offs, while differential privacy achieves strong reduction in leakage in specific settings, although it can introduce training instability. These findings highlight the persistent challenge of memorization in fine-tuned LLMs and emphasize the need for robust, scalable privacy-preserving techniques.

</details>


### [88] [Automatic Stability and Recovery for Neural Network Training](https://arxiv.org/abs/2601.17483)
*Barak Or*

Main category: cs.LG

TL;DR: 提出一个运行时稳定性监督框架，将优化视为受控随机过程，通过创新信号自动检测和恢复不稳定更新，无需修改底层优化器


<details>
  <summary>Details</summary>
Motivation: 现代神经网络训练日益脆弱，罕见但严重的破坏性更新常导致不可逆发散或性能静默退化。现有优化方法主要依赖优化器内部的预防机制，一旦发生不稳定，检测和恢复能力有限。

Method: 引入监督运行时稳定性框架，将优化视为受控随机过程。通过从验证探针等次要测量中提取创新信号，实现自动检测和恢复破坏性更新，无需修改底层优化器。

Result: 提供理论运行时安全保证，形式化有界退化和恢复。实现开销最小，兼容内存受限的训练设置。

Conclusion: 该框架为神经网络训练提供了有效的运行时稳定性监督机制，能够在保持优化器不变的情况下自动处理训练不稳定问题。

Abstract: Training modern neural networks is increasingly fragile, with rare but severe destabilizing updates often causing irreversible divergence or silent performance degradation. Existing optimization methods primarily rely on preventive mechanisms embedded within the optimizer, offering limited ability to detect and recover from instability once it occurs. We introduce a supervisory runtime stability framework that treats optimization as a controlled stochastic process. By isolating an innovation signal derived from secondary measurements, such as validation probes, the framework enables automatic detection and recovery from destabilizing updates without modifying the underlying optimizer. We provide theoretical runtime safety guarantees that formalize bounded degradation and recovery. Our implementation incurs minimal overhead and is compatible with memory-constrained training settings.

</details>


### [89] [SpatialMath: Spatial Comprehension-Infused Symbolic Reasoning for Mathematical Problem-Solving](https://arxiv.org/abs/2601.17489)
*Ashutosh Bajpai,Akshat Bhandari,Akshay Nambi,Tanmoy Chakraborty*

Main category: cs.LG

TL;DR: SpatialMath框架通过将空间感知融入符号推理链，显著提升多模态语言模型在几何问题上的视觉理解和数学推理能力，在视觉密集型数学问题上比基线模型提升10个百分点。


<details>
  <summary>Details</summary>
Motivation: 当前多模态中小型语言模型在视觉理解和数学推理方面存在局限，特别是在几何问题上难以准确分解复杂视觉输入并连接感知与结构化推理，导致性能不佳。

Method: 提出SpatialMath框架：1）专用感知模块提取视觉图表中的空间基础表示；2）将这些表示系统性地融入符号推理链；3）创建MATHVERSE-PLUS数据集，包含结构化视觉解释和逐步推理路径。

Result: SpatialMath显著优于强大多模态基线，在视觉密集型场景下比监督微调加数据增强提升高达10个百分点。鲁棒性分析显示增强的空间表示直接提高推理准确性。

Conclusion: 结构化感知到推理管道对多模态语言模型至关重要，空间感知与符号推理的集成能有效解决几何问题中的视觉理解挑战。

Abstract: Multimodal Small-to-Medium sized Language Models (MSLMs) have demonstrated strong capabilities in integrating visual and textual information but still face significant limitations in visual comprehension and mathematical reasoning, particularly in geometric problems with diverse levels of visual infusion. Current models struggle to accurately decompose intricate visual inputs and connect perception with structured reasoning, leading to suboptimal performance. To address these challenges, we propose SpatialMath, a novel Spatial Comprehension-Infused Symbolic Reasoning Framework designed to integrate spatial representations into structured symbolic reasoning chains. SpatialMath employs a specialized perception module to extract spatially-grounded representations from visual diagrams, capturing critical geometric structures and spatial relationships. These representations are then methodically infused into symbolic reasoning chains, facilitating visual comprehension-aware structured reasoning. To this end, we introduce MATHVERSE-PLUS, a novel dataset containing structured visual interpretations and step-by-step reasoning paths for vision-intensive mathematical problems. SpatialMath significantly outperforms strong multimodal baselines, achieving up to 10 percentage points improvement over supervised fine-tuning with data augmentation in vision-intensive settings. Robustness analysis reveals that enhanced spatial representations directly improve reasoning accuracy, reinforcing the need for structured perception-to-reasoning pipelines in MSLMs.

</details>


### [90] [PEARL: Prototype-Enhanced Alignment for Label-Efficient Representation Learning with Deployment-Driven Insights from Digital Governance Communication Systems](https://arxiv.org/abs/2601.17495)
*Ruiyu Zhang,Lin Nie,Wai-Fung Lam,Qihao Wang,Xin Zhao*

Main category: cs.LG

TL;DR: PEARL是一种标签高效的表示学习方法，通过原型增强对齐嵌入表示，改善局部邻域几何结构，在标签稀缺条件下显著提升检索性能。


<details>
  <summary>Details</summary>
Motivation: 现实部署中，基于预训练模型固定嵌入的检索系统经常失败，原因不是模型本身，而是嵌入空间的最近邻对应错误案例。标签稀缺、领域漂移和重新训练成本高，导致下游性能严重依赖嵌入几何结构，而原始嵌入往往与检索所需的局部邻域结构不匹配。

Method: PEARL（原型增强对齐表示学习）使用有限监督将嵌入软对齐到类别原型，重塑局部邻域几何结构，同时保持维度并避免激进投影或坍缩。该方法在标签稀缺到较丰富标签的不同控制条件下进行评估。

Result: 在标签稀缺条件下，PEARL显著改善局部邻域质量，相比原始嵌入提升25.7%，相比强无监督后处理方法提升超过21.1%，在基于相似性的系统最脆弱的场景中表现优异。

Conclusion: PEARL填补了纯无监督后处理（增益有限且不一致）与完全监督投影（需要大量标注数据）之间的空白，为标签稀缺场景下的检索系统提供了有效的嵌入对齐解决方案。

Abstract: In many deployed systems, new text inputs are handled by retrieving similar past cases, for example when routing and responding to citizen messages in digital governance platforms. When these systems fail, the problem is often not the language model itself, but that the nearest neighbors in the embedding space correspond to the wrong cases. Modern machine learning systems increasingly rely on fixed, high-dimensional embeddings produced by large pretrained models and sentence encoders. In real-world deployments, labels are scarce, domains shift over time, and retraining the base encoder is expensive or infeasible. As a result, downstream performance depends heavily on embedding geometry. Yet raw embeddings are often poorly aligned with the local neighborhood structure required by nearest-neighbor retrieval, similarity search, and lightweight classifiers that operate directly on embeddings. We propose PEARL (Prototype-Enhanced Aligned Representation Learning), a label-efficient approach that uses limited supervision to softly align embeddings toward class prototypes. The method reshapes local neighborhood geometry while preserving dimensionality and avoiding aggressive projection or collapse. Its aim is to bridge the gap between purely unsupervised post-processing, which offers limited and inconsistent gains, and fully supervised projections that require substantial labeled data. We evaluate PEARL under controlled label regimes ranging from extreme label scarcity to higher-label settings. In the label-scarce condition, PEARL substantially improves local neighborhood quality, yielding 25.7% gains over raw embeddings and more than 21.1% gains relative to strong unsupervised post-processing, precisely in the regime where similarity-based systems are most brittle.

</details>


### [91] [One-Shot Federated Clustering of Non-Independent Completely Distributed Data](https://arxiv.org/abs/2601.17512)
*Yiqun Zhang,Shenghong Cai,Zihua Yang,Sen Feng,Yuzhu Ji,Haijun Zhang*

Main category: cs.LG

TL;DR: 论文提出GOLD框架解决联邦聚类中Non-IID数据的挑战，特别是针对集群被不同客户端分割的Non-ICD问题，通过探索局部集群分布、全局融合和局部增强来提升聚类性能。


<details>
  <summary>Details</summary>
Motivation: 联邦聚类在无标签的分布式物联网数据中应用广泛，但现有方法在处理Non-IID数据时面临三大挑战：如何融合非独立同分布客户端的模式知识（集群分布）、客户端间集群分布的关系如何、以及这种关系如何与全局知识融合关联。论文发现了一个被忽视的瓶颈现象——不同客户端可能分割同一个集群（Non-ICD问题），这限制了现有联邦聚类方法的性能。

Method: 提出GOLD（Global Oriented Local Distribution Learning）框架：1）精细探索客户端的潜在不完整局部集群分布；2）将分布摘要上传到服务器进行全局融合；3）在全局分布指导下执行局部集群增强。该方法系统解决了Non-ICD带来的挑战。

Result: 通过大量实验（包括显著性检验、消融研究、可扩展性评估、定性结果等）证明了GOLD的优越性。实验结果显示该方法在联邦聚类任务中显著优于现有方法。

Conclusion: 论文揭示了联邦聚类中Non-IID数据的深层问题（Non-ICD），并提出了有效的GOLD框架来解决这些挑战。该方法通过全局导向的局部分布学习，成功提升了分布式无标签数据中的聚类性能，为联邦聚类研究提供了新思路。

Abstract: Federated Learning (FL) that extracts data knowledge while protecting the privacy of multiple clients has achieved remarkable results in distributed privacy-preserving IoT systems, including smart traffic flow monitoring, smart grid load balancing, and so on. Since most data collected from edge devices are unlabeled, unsupervised Federated Clustering (FC) is becoming increasingly popular for exploring pattern knowledge from complex distributed data. However, due to the lack of label guidance, the common Non-Independent and Identically Distributed (Non-IID) issue of clients have greatly challenged FC by posing the following problems: How to fuse pattern knowledge (i.e., cluster distribution) from Non-IID clients; How are the cluster distributions among clients related; and How does this relationship connect with the global knowledge fusion? In this paper, a more tricky but overlooked phenomenon in Non-IID is revealed, which bottlenecks the clustering performance of the existing FC approaches. That is, different clients could fragment a cluster, and accordingly, a more generalized Non-IID concept, i.e., Non-ICD (Non-Independent Completely Distributed), is derived. To tackle the above FC challenges, a new framework named GOLD (Global Oriented Local Distribution Learning) is proposed. GOLD first finely explores the potential incomplete local cluster distributions of clients, then uploads the distribution summarization to the server for global fusion, and finally performs local cluster enhancement under the guidance of the global distribution. Extensive experiments, including significance tests, ablation studies, scalability evaluations, qualitative results, etc., have been conducted to show the superiority of GOLD.

</details>


### [92] [Towards Generalisable Imitation Learning Through Conditioned Transition Estimation and Online Behaviour Alignment](https://arxiv.org/abs/2601.17563)
*Nathan Gavenski,Matteo Leonetti,Odinaldo Rodrigues*

Main category: cs.LG

TL;DR: 提出无监督观察模仿学习(UfO)，通过两阶段学习解决现有ILfO方法需要动作监督、假设状态有单一最优动作、不考虑环境状态完整信息等限制


<details>
  <summary>Details</summary>
Motivation: 现有观察模仿学习方法存在三个主要限制：需要基于动作的监督优化、假设状态有单一最优动作、应用教师动作时未充分考虑实际环境状态。虽然真实信息存在于观察轨迹中，但现有方法难以在无监督情况下提取这些信息。

Method: 提出UfO方法，采用两阶段学习过程：1) 从观察到的状态转移中近似教师的真实动作；2) 通过调整智能体轨迹使其与教师轨迹紧密对齐来进一步优化学习策略。

Result: 在五个广泛使用的环境中进行实验，UfO不仅超越了教师和所有其他ILfO方法，而且显示出最小的标准差。标准差的减少表明在未见场景中具有更好的泛化能力。

Conclusion: UfO成功解决了现有ILfO方法的三个主要限制，通过无监督方式从观察中学习，实现了更好的性能和泛化能力，为观察模仿学习提供了更有效的解决方案。

Abstract: State-of-the-art imitation learning from observation methods (ILfO) have recently made significant progress, but they still have some limitations: they need action-based supervised optimisation, assume that states have a single optimal action, and tend to apply teacher actions without full consideration of the actual environment state. While the truth may be out there in observed trajectories, existing methods struggle to extract it without supervision. In this work, we propose Unsupervised Imitation Learning from Observation (UfO) that addresses all of these limitations. UfO learns a policy through a two-stage process, in which the agent first obtains an approximation of the teacher's true actions in the observed state transitions, and then refines the learned policy further by adjusting agent trajectories to closely align them with the teacher's. Experiments we conducted in five widely used environments show that UfO not only outperforms the teacher and all other ILfO methods but also displays the smallest standard deviation. This reduction in standard deviation indicates better generalisation in unseen scenarios.

</details>


### [93] [Quantum-Inspired Episode Selection for Monte Carlo Reinforcement Learning via QUBO Optimization](https://arxiv.org/abs/2601.17570)
*Hadi Salloum,Ali Jnadi,Yaroslav Kholodov,Alexander Gasnikov*

Main category: cs.LG

TL;DR: MC强化学习存在样本效率低的问题，特别是在稀疏奖励、大状态空间和相关轨迹的环境中。本文提出MC+QUBO方法，将回合选择重新表述为QUBO问题，并使用量子启发采样器求解，通过组合过滤提升策略评估效率。


<details>
  <summary>Details</summary>
Motivation: 蒙特卡洛强化学习在稀疏奖励、大状态空间和相关轨迹环境中存在高样本复杂度问题，需要更高效的样本利用方法来加速收敛。

Method: 将回合选择重新表述为二次无约束二进制优化问题，从每批轨迹中选择最大化累积奖励同时促进状态空间覆盖的子集。线性项偏好高奖励回合，二次项惩罚冗余。使用模拟量子退火和模拟分岔作为黑盒求解器。

Result: 在有限时域GridWorld实验中，MC+QUBO在收敛速度和最终策略质量上都优于传统蒙特卡洛方法。

Conclusion: 量子启发优化作为强化学习中决策子程序具有潜力，能够有效提升蒙特卡洛强化学习的样本效率和性能。

Abstract: Monte Carlo (MC) reinforcement learning suffers from high sample complexity, especially in environments with sparse rewards, large state spaces, and correlated trajectories. We address these limitations by reformulating episode selection as a Quadratic Unconstrained Binary Optimization (QUBO) problem and solving it with quantum-inspired samplers. Our method, MC+QUBO, integrates a combinatorial filtering step into standard MC policy evaluation: from each batch of trajectories, we select a subset that maximizes cumulative reward while promoting state-space coverage. This selection is encoded as a QUBO, where linear terms favor high-reward episodes and quadratic terms penalize redundancy. We explore both Simulated Quantum Annealing (SQA) and Simulated Bifurcation (SB) as black-box solvers within this framework. Experiments in a finite-horizon GridWorld demonstrate that MC+QUBO outperforms vanilla MC in convergence speed and final policy quality, highlighting the potential of quantum-inspired optimization as a decision-making subroutine in reinforcement learning.

</details>


### [94] [Understanding Transformer Encoder-Decoder Representations through Bernoulli Dropout](https://arxiv.org/abs/2601.17602)
*Xuanzhou Chen*

Main category: cs.LG

TL;DR: 研究Transformer过参数化问题，通过高维编码器-解码器嵌入的角度相似性分析，使用伯努利dropout识别保持Top-1预测的稀疏性阈值


<details>
  <summary>Details</summary>
Motivation: 研究Transformer模型过参数化现象，探索编码器-解码器嵌入在高维空间中的角度相似性，理解模型对参数稀疏化的鲁棒性

Method: 应用伯努利dropout在编码器和解码器之间，改变保留概率p来识别稀疏性阈值；理论上证明当嵌入有效稀疏性足够大时，解码器性能在适度坐标dropout下保持稳定；实验上构建带有二进制擦除通道(BEC)的Transformer模型，在英法翻译任务上测试

Result: 实验结果显示验证准确率和BLEU分数在某个阈值处急剧下降，可视化展示了这一趋势

Conclusion: Transformer模型存在稀疏性依赖的阈值，当dropout超过该阈值时性能急剧下降，但适度稀疏化下模型性能保持稳定

Abstract: We study Transformer overparameterization through the lens of angular similarity in high-dimensional encoder-decoder embeddings. We apply Bernoulli dropout between the encoder and the decoder, varying the keep probability $p$ to identify a sparsity-dependent threshold above which the Top-1 prediction is preserved. Theoretically, we prove that, if the effective sparsity embeddings is sufficiently large, and thus decoder performance, remain stable under moderate coordinate dropout. Empirically, we implement the Bernoulli dropout by constructing a new Transformer model augmented with Binary Erasure Channel (BEC) and test its performance on an English-French translation task. Experimental results visualize the trends for validation accuracies and BLEU scores, both decline sharply at some threshold.

</details>


### [95] [A Thermodynamic Theory of Learning I: Irreversible Ensemble Transport and Epistemic Costs](https://arxiv.org/abs/2601.17607)
*Daisuke Okanohara*

Main category: cs.LG

TL;DR: 论文提出学习本质上是一个不可逆过程，需要熵产生来实现认知结构，并推导出认知速度极限(ESL)，为任何学习过程实现给定分布变换所需的最小熵产生设定下界。


<details>
  <summary>Details</summary>
Motivation: 经典信息论表明确定性变换不会增加信息，但学习系统却能获得结构化内部表示。这引发了一个基本问题：学习如何在不违反信息论限制的情况下产生抽象和洞察？

Method: 将学习建模为模型配置概率分布空间中的传输过程，引入认知自由能框架，定义自由能下降作为记录学习轨迹中认知自由能总减少的记账量，并将其分解为可逆和不可逆分量。

Result: 推导出认知速度极限(ESL)，这是一个有限时间不等式，为任何学习过程实现给定分布变换所需的最小熵产生设定下界。该界限仅取决于初始和最终集合分布之间的Wasserstein距离，与具体学习算法无关。

Conclusion: 学习本质上是一个不可逆过程，认知结构的实现必然伴随熵产生。认知速度极限为学习过程的基本限制提供了理论框架，将热力学概念应用于机器学习理论。

Abstract: Learning systems acquire structured internal representations from data, yet classical information-theoretic results state that deterministic transformations do not increase information. This raises a fundamental question: how can learning produce abstraction and insight without violating information-theoretic limits?
  We argue that learning is inherently an irreversible process when performed over finite time, and that the realization of epistemic structure necessarily incurs entropy production. To formalize this perspective, we model learning as a transport process in the space of probability distributions over model configurations and introduce an epistemic free-energy framework.
  Within this framework, we define the free-energy drop as a bookkeeping quantity that records the total reduction of epistemic free energy along a learning trajectory. This reduction decomposes into a reversible component associated with potential improvement and an irreversible component corresponding to entropy production.
  We then derive the Epistemic Speed Limit (ESL), a finite-time inequality that lower-bounds the minimal entropy production required by any learning process to realize a given distributional transformation. This bound depends only on the Wasserstein distance between initial and final ensemble distributions and is independent of the specific learning algorithm.

</details>


### [96] [Split-on-Share: Mixture of Sparse Experts for Task-Agnostic Continual Learning](https://arxiv.org/abs/2601.17616)
*Fatema Siddika,Md Anwar Hossen,Tanwi Mallick,Ali Jannesari*

Main category: cs.LG

TL;DR: SETA框架通过混合稀疏专家解决LLMs持续学习中的可塑性-稳定性困境，将知识分解为任务特定专家和共享专家，使用弹性权重锚定保护关键知识


<details>
  <summary>Details</summary>
Motivation: 大型语言模型持续学习面临可塑性-稳定性困境：学习新能力会导致灾难性遗忘先前知识。现有方法通常均匀处理参数，无法区分特定任务知识和共享能力

Method: 提出SETA框架，将模型分解为模块化子空间：任务特定专家（隔离任务特定模式）和共享专家（捕获共同特征）。通过弹性权重锚定保护关键共享知识，使用统一门控网络在推理时自动检索正确的专家组合

Result: 在多样领域特定和通用基准测试中，SETA始终优于最先进的参数高效微调持续学习方法

Conclusion: SETA通过混合稀疏专家框架有效解决了LLMs持续学习中的可塑性-稳定性困境，实现了更好的知识保留和新任务学习平衡

Abstract: Continual learning in Large Language Models (LLMs) is hindered by the plasticity-stability dilemma, where acquiring new capabilities often leads to catastrophic forgetting of previous knowledge. Existing methods typically treat parameters uniformly, failing to distinguish between specific task knowledge and shared capabilities. We introduce Mixture of Sparse Experts for Task-Agnostic Continual Learning, referred to as SETA, a framework that resolves the plasticity-stability conflict by decomposing the model into modular subspaces. Unlike standard updates, where tasks compete for the same parameters, SETA separates knowledge into unique experts, designed to isolate task-specific patterns, and shared experts, responsible for capturing common features. This structure is maintained through elastic weight anchoring, which protects critical shared knowledge and enables a unified gating network to automatically retrieve the correct expert combination for each task during inference. Extensive experiments across diverse domain-specific and general benchmarks demonstrate that SETA consistently outperforms state-of-the-art parameter-efficient fine-tuning-based continual learning methods.

</details>


### [97] [BrainDistill: Implantable Motor Decoding with Task-Specific Knowledge Distillation](https://arxiv.org/abs/2601.17625)
*Yuhan Xie,Jinhan Liu,Xiaoyong Ni,Fei Tan,Icare Sakr,Thibault Collin,Shiqi Sun,Alejandro Rodriguez Guajardo,Demon Fanny,Charles-francois Vincent Latchoumane,Henri Lorach,Jocelyne Bloch,Gregoire Courtine,Mahsa Shoaran*

Main category: cs.LG

TL;DR: BrainDistill：一种新型植入式运动解码框架，通过任务特定知识蒸馏和量化训练，在保持高性能的同时大幅降低计算需求，适用于功率受限的植入式脑机接口系统。


<details>
  <summary>Details</summary>
Motivation: Transformer架构的神经解码器在脑机接口任务中表现出色，但其庞大的参数量和计算需求阻碍了在功率受限的植入式系统中的部署。需要开发既能保持高性能又能在资源受限环境中运行的解决方案。

Method: 提出BrainDistill框架，包含：1）植入式神经解码器（IND）；2）任务特定知识蒸馏（TSKD）框架，通过监督投影优先保留解码关键特征；3）量化感知训练方案，实现仅整数推理并学习激活裁剪范围。

Result: IND在多个神经数据集上优于现有神经解码器，其TSKD蒸馏变体在少样本校准设置中超越其他蒸馏方法。量化后的IND在严格功率约束下部署时性能损失最小。

Conclusion: BrainDistill通过创新的知识蒸馏和量化技术，成功解决了Transformer解码器在植入式脑机接口中的部署难题，为高性能、低功耗的神经解码系统提供了可行方案。

Abstract: Transformer-based neural decoders with large parameter counts, pre-trained on large-scale datasets, have recently outperformed classical machine learning models and small neural networks on brain-computer interface (BCI) tasks. However, their large parameter counts and high computational demands hinder deployment in power-constrained implantable systems. To address this challenge, we introduce BrainDistill, a novel implantable motor decoding pipeline that integrates an implantable neural decoder (IND) with a task-specific knowledge distillation (TSKD) framework. Unlike standard feature distillation methods that attempt to preserve teacher representations in full, TSKD explicitly prioritizes features critical for decoding through supervised projection. Across multiple neural datasets, IND consistently outperforms prior neural decoders on motor decoding tasks, while its TSKD-distilled variant further surpasses alternative distillation methods in few-shot calibration settings. Finally, we present a quantization-aware training scheme that enables integer-only inference with activation clipping ranges learned during training. The quantized IND enables deployment under the strict power constraints of implantable BCIs with minimal performance loss.

</details>


### [98] [RPNT: Robust Pre-trained Neural Transformer -- A Pathway for Generalized Motor Decoding](https://arxiv.org/abs/2601.17641)
*Hao Fang,Ryan A. Canfield,Tomohiro Ouchi,Beatrice Macagno,Eli Shlizerman,Amy L. Orsborn*

Main category: cs.LG

TL;DR: RPNT是一个用于脑解码的预训练神经Transformer模型，通过多维旋转位置嵌入、基于上下文的注意力机制和鲁棒的自监督学习目标，实现了跨会话、跨类型、跨受试者和跨脑区的稳健泛化能力。


<details>
  <summary>Details</summary>
Motivation: 脑解码模型需要能够泛化到不同的脑区记录、不同会话、不同行为类型和不同受试者。现有模型只能部分解决这些挑战，因此需要开发能够适应和泛化的预训练神经Transformer模型。

Method: 1) 多维旋转位置嵌入(MRoPE)聚合实验元数据；2) 基于卷积核的上下文注意力机制处理神经群体活动的非平稳性；3) 具有均匀因果掩码策略和对比表示的鲁棒自监督学习目标。在两个不同数据集上预训练：多会话多任务多受试者微电极基准数据集和多站点Neuropixel 1.0探针记录数据集。

Result: RPNT在跨会话、跨类型、跨受试者和跨脑区的下游行为解码任务中，始终达到并超越了现有解码模型的性能。

Conclusion: RPNT通过创新的架构设计和预训练策略，实现了脑解码模型的稳健泛化能力，为神经活动到行为的翻译提供了更有效的解决方案。

Abstract: Brain decoding aims to interpret and translate neural activity into behaviors. As such, it is imperative that decoding models are able to generalize across variations, such as recordings from different brain sites, distinct sessions, different types of behavior, and a variety of subjects. Current models can only partially address these challenges and warrant the development of pretrained neural transformer models capable to adapt and generalize. In this work, we propose RPNT - Robust Pretrained Neural Transformer, designed to achieve robust generalization through pretraining, which in turn enables effective finetuning given a downstream task. In particular, RPNT unique components include 1) Multidimensional rotary positional embedding (MRoPE) to aggregate experimental metadata such as site coordinates, session name and behavior types; 2) Context-based attention mechanism via convolution kernels operating on global attention to learn local temporal structures for handling non-stationarity of neural population activity; 3) Robust self-supervised learning (SSL) objective with uniform causal masking strategies and contrastive representations. We pretrained two separate versions of RPNT on distinct datasets a) Multi-session, multi-task, and multi-subject microelectrode benchmark; b) Multi-site recordings using high-density Neuropixel 1.0 probes. The datasets include recordings from the dorsal premotor cortex (PMd) and from the primary motor cortex (M1) regions of nonhuman primates (NHPs) as they performed reaching tasks. After pretraining, we evaluated the generalization of RPNT in cross-session, cross-type, cross-subject, and cross-site downstream behavior decoding tasks. Our results show that RPNT consistently achieves and surpasses the decoding performance of existing decoding models in all tasks.

</details>


### [99] [A Mosco sufficient condition for intrinsic stability of non-unique convex Empirical Risk Minimization](https://arxiv.org/abs/2601.17646)
*Karim Bounja,Lahcen Laayouni,Abdeljalil Sakat*

Main category: cs.LG

TL;DR: 论文研究了经验风险最小化（ERM）的稳定性问题，特别关注凸非严格损失函数产生集值最小化器的情况，提出了Painlevé-Kuratowski上半连续性作为ERM解对应的内在稳定性概念。


<details>
  <summary>Details</summary>
Motivation: 传统ERM稳定性研究通常针对单值输出，但凸非严格损失函数会产生集值最小化器，需要建立适合集值映射的稳定性理论框架。

Method: 采用Painlevé-Kuratowski上半连续性作为ERM解对应的稳定性概念，在Mosco一致扰动和局部有界最小化器的条件下，证明了PK上半连续性、最小值连续性和消失间隙近最小化器的一致性。

Result: 在最小非退化定性机制下，Mosco一致扰动和局部有界最小化器可推导出PK上半连续性、最小值连续性和近最小化器的一致性；二次增长条件可得到显式的定量偏差界。

Conclusion: PK上半连续性是ERM解对应的内在稳定性概念，为理解选择稳定性提供了理论基础，在适当条件下可保证ERM的稳定性和一致性。

Abstract: Empirical risk minimization (ERM) stability is usually studied via single-valued outputs, while convex non-strict losses yield set-valued minimizers. We identify Painlevé-Kuratowski upper semicontinuity (PK-u.s.c.) as the intrinsic stability notion for the ERM solution correspondence (set-level Hadamard well-posedness) and a prerequisite to interpret stability of selections. We then characterize a minimal non-degenerate qualitative regime: Mosco-consistent perturbations and locally bounded minimizers imply PK-u.s.c., minimal-value continuity, and consistency of vanishing-gap near-minimizers. Quadratic growth yields explicit quantitative deviation bounds.

</details>


### [100] [Time-Varying Causal Treatment for Quantifying the Causal Effect of Short-Term Variations on Arctic Sea Ice Dynamics](https://arxiv.org/abs/2601.17647)
*Akila Sampath,Vandana Janeja,Jianwu Wang*

Main category: cs.LG

TL;DR: 提出KGCM-VAE模型，通过知识引导的因果建模量化海冰厚度与海面高度之间的因果关系，结合物理约束和分布平衡机制提升时空因果推断效果。


<details>
  <summary>Details</summary>
Motivation: 量化冰融化和淡水分布之间的因果关系对理解极地气候变化和海平面上升至关重要。传统深度学习模型在时空环境中处理未观测混杂因素和缺乏物理约束时，因果效应估计不可靠。

Method: 提出知识引导的因果模型变分自编码器(KGCM-VAE)：1) 速度调制方案，通过SSH转换控制的sigmoid函数动态放大平滑速度信号生成物理基础的因果处理；2) 在潜空间使用最大均值差异(MMD)平衡处理组和对照组协变量分布；3) 因果邻接约束解码器确保与已知物理结构对齐。

Result: 在合成和真实北极数据集上的实验表明，KGCM-VAE在PEHE指标上优于现有基准方法。消融研究证实方法的有效性，MMD和因果邻接约束的联合应用使估计误差降低1.88%。

Conclusion: KGCM-VAE通过整合物理知识和因果约束，有效解决了时空因果推断中的挑战，为理解海冰厚度与海面高度之间的因果关系提供了可靠工具。

Abstract: Quantifying the causal relationship between ice melt and freshwater distribution is critical, as these complex interactions manifest as regional fluctuations in sea surface height (SSH). Leveraging SSH as a proxy for sea ice dynamics enables improved understanding of the feedback mechanisms driving polar climate change and global sea-level rise. However, conventional deep learning models often struggle with reliable treatment effect estimation in spatiotemporal settings due to unobserved confounders and the absence of physical constraints. To address these challenges, we propose the Knowledge-Guided Causal Model Variational Autoencoder (KGCM-VAE) to quantify causal mechanisms between sea ice thickness and SSH. The proposed framework integrates a velocity modulation scheme in which smoothed velocity signals are dynamically amplified via a sigmoid function governed by SSH transitions to generate physically grounded causal treatments. In addition, the model incorporates Maximum Mean Discrepancy (MMD) to balance treated and control covariate distributions in the latent space, along with a causal adjacency-constrained decoder to ensure alignment with established physical structures. Experimental results on both synthetic and real-world Arctic datasets demonstrate that KGCM-VAE achieves superior PEHE compared to state-of-the-art benchmarks. Ablation studies further confirm the effectiveness of the approach, showing that the joint application of MMD and causal adjacency constraints yields a 1.88\% reduction in estimation error.

</details>


### [101] [Kareus: Joint Reduction of Dynamic and Static Energy in Large Model Training](https://arxiv.org/abs/2601.17654)
*Ruofan Wu,Jae-Won Chung,Mosharaf Chowdhury*

Main category: cs.LG

TL;DR: Kareus是一个AI训练系统，通过联合优化细粒度内核调度和频率缩放来同时降低动态和静态能耗，在时间-能耗权衡前沿上取得显著改进。


<details>
  <summary>Details</summary>
Motivation: AI计算需求快速增长，但能源供应跟不上，能源已成为昂贵且竞争激烈的资源。现有工作只关注动态或静态能耗的单一方面，而细粒度内核调度和频率缩放会共同影响两种能耗，需要联合优化。

Method: Kareus将难以处理的联合优化问题分解为局部的、基于分区的子问题，然后使用多通道多目标优化算法寻找能够推进时间-能耗权衡前沿的执行调度方案。

Result: 与现有技术相比，Kareus在相同训练时间下减少能耗达28.3%，或在相同能耗下减少训练时间达27.5%。

Conclusion: 通过联合优化内核调度和频率缩放来同时处理动态和静态能耗，Kareus成功推进了AI训练的时间-能耗权衡前沿，为解决AI计算能耗问题提供了有效方案。

Abstract: The computing demand of AI is growing at an unprecedented rate, but energy supply is not keeping pace. As a result, energy has become an expensive, contended resource that requires explicit management and optimization. Although recent works have made significant progress in large model training optimization, they focus only on a single aspect of energy consumption: dynamic or static energy.
  We find that fine-grained kernel scheduling and frequency scaling jointly and interdependently impact both dynamic and static energy consumption. Based on this finding, we design Kareus, a training system that pushes the time--energy tradeoff frontier by optimizing both aspects. Kareus decomposes the intractable joint optimization problem into local, partition-based subproblems. It then uses a multi-pass multi-objective optimization algorithm to find execution schedules that push the time--energy tradeoff frontier. Compared to the state of the art, Kareus reduces training energy by up to 28.3% at the same training time, or reduces training time by up to 27.5% at the same energy consumption.

</details>


### [102] [Entropic Risk-Aware Monte Carlo Tree Search](https://arxiv.org/abs/2601.17667)
*Pedro P. Santos,Jacopo Silvestrin,Alberto Sardinha,Francisco S. Melo*

Main category: cs.LG

TL;DR: 提出一种可证明正确的蒙特卡洛树搜索算法，用于解决具有熵风险度量目标的风险感知马尔可夫决策过程，并提供非渐近分析。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理具有熵风险度量目标的风险感知MDPs时缺乏可证明正确的树搜索算法，需要开发既能保证正确性又具有多项式遗憾集中性的算法。

Method: 基于置信上界的蒙特卡洛树搜索算法，利用先前工作中引入的用于解决具有熵风险度量目标的风险感知MDPs的动态规划公式。

Result: 算法具有正确性（根节点的经验熵风险度量收敛到最优熵风险度量）和多项式遗憾集中性，实验表明风险感知MCTS方法优于相关基线。

Conclusion: 成功开发了首个可证明正确的风险感知蒙特卡洛树搜索算法，为具有熵风险度量目标的风险感知MDPs提供了有效的解决方案。

Abstract: We propose a provably correct Monte Carlo tree search (MCTS) algorithm for solving \textit{risk-aware} Markov decision processes (MDPs) with \textit{entropic risk measure} (ERM) objectives. We provide a \textit{non-asymptotic} analysis of our proposed algorithm, showing that the algorithm: (i) is \textit{correct} in the sense that the empirical ERM obtained at the root node converges to the optimal ERM; and (ii) enjoys \textit{polynomial regret concentration}. Our algorithm successfully exploits the dynamic programming formulations for solving risk-aware MDPs with ERM objectives introduced by previous works in the context of an upper confidence bound-based tree search algorithm. Finally, we provide a set of illustrative experiments comparing our risk-aware MCTS method against relevant baselines.

</details>


### [103] [Fast KVzip: Efficient and Accurate LLM Inference with Gated KV Eviction](https://arxiv.org/abs/2601.17668)
*Jang-Hyun Kim,Dongyoon Han,Sangdoo Yun*

Main category: cs.LG

TL;DR: 提出基于门控的KV缓存驱逐方法，通过轻量级sink-attention门控模块识别关键KV对，实现70%缓存驱逐的同时保持接近无损的性能，计算开销极小。


<details>
  <summary>Details</summary>
Motivation: 现有KV缓存压缩技术通常在性能下降和计算开销之间需要权衡，对于冻结权重的大语言模型部署来说，需要一种既能高效压缩缓存又不会显著增加计算成本的方法。

Method: 引入轻量级sink-attention门控模块来识别和保留关键KV对，提出仅依赖前向传播的门训练算法，使用任务无关的重建目标实现强任务泛化能力，无缝集成到预填充和解码阶段。

Result: 在Qwen2.5-1M、Qwen3和Gemma3系列模型上的实验表明，该方法在驱逐高达70%的KV缓存时仍能保持接近无损的性能，在长上下文理解、代码理解和数学推理等多种任务上表现一致。

Conclusion: 提出的基于门控的KV缓存驱逐方法实现了高压缩比和低计算开销的良好平衡，为冻结权重大语言模型的实用部署提供了有效的缓存管理解决方案。

Abstract: Efficient key-value (KV) cache management is crucial for the practical deployment of large language models (LLMs), yet existing compression techniques often incur a trade-off between performance degradation and computational overhead. We propose a novel gating-based KV cache eviction method for frozen-weight LLMs that achieves high compression ratios with negligible computational cost. Our approach introduces lightweight sink-attention gating modules to identify and retain critical KV pairs, and integrates seamlessly into both the prefill and decoding stages. The proposed gate training algorithm relies on forward passes of an LLM, avoiding expensive backpropagation, while achieving strong task generalization through a task-agnostic reconstruction objective. Extensive experiments across the Qwen2.5-1M, Qwen3, and Gemma3 families show that our method maintains near-lossless performance while evicting up to 70% of the KV cache. The results are consistent across a wide range of tasks, including long-context understanding, code comprehension, and mathematical reasoning, demonstrating the generality of our approach.

</details>


### [104] [$\infty$-MoE: Generalizing Mixture of Experts to Infinite Experts](https://arxiv.org/abs/2601.17680)
*Shota Takashiro,Takeshi Kojima,Shohei Taniguchi,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.LG

TL;DR: ∞-MoE：通过连续空间选择大型前馈网络的部分参数，实现无限专家数量，在保持计算效率的同时提升性能


<details>
  <summary>Details</summary>
Motivation: 传统MoE将每个专家视为完全独立，在离散空间组合专家。当专家数量增加时，难以有效训练每个专家。需要稳定训练同时增加专家数量。

Method: 提出∞-MoE，基于每个token采样的连续值选择大型前馈网络的部分参数。通过在连续空间中考虑专家，实现无限专家数量同时保持计算效率。

Result: 基于GPT-2 Small的∞-MoE模型（1.29亿激活参数，1.86亿总参数）性能与3.5亿参数的密集GPT-2 Medium相当。推理时调整采样专家数量可在准确性和速度间灵活权衡，比传统MoE准确率提升高达2.5%。

Conclusion: ∞-MoE通过在连续空间中选择专家参数，解决了传统MoE专家数量增加时的训练难题，实现了无限专家数量的可能性，在计算效率和性能间取得了更好平衡。

Abstract: The Mixture of Experts (MoE) selects a few feed-forward networks (FFNs) per token, achieving an effective trade-off between computational cost and performance. In conventional MoE, each expert is treated as entirely independent, and experts are combined in a discrete space. As a result, when the number of experts increases, it becomes difficult to train each expert effectively. To stabilize training while increasing the number of experts, we propose $\infty$-MoE that selects a portion of the parameters of large FFNs based on continuous values sampled for each token. By considering experts in a continuous space, this approach allows for an infinite number of experts while maintaining computational efficiency. Experiments show that a GPT-2 Small-based $\infty$-MoE model, with 129M active and 186M total parameters, achieves comparable performance to a dense GPT-2 Medium with 350M parameters. Adjusting the number of sampled experts at inference time allows for a flexible trade-off between accuracy and speed, with an improvement of up to 2.5\% in accuracy over conventional MoE.

</details>


### [105] [Agentic reinforcement learning empowers next-generation chemical language models for molecular design and synthesis](https://arxiv.org/abs/2601.17687)
*Hao Li,He Cao,Shenyao Peng,Zijing Liu,Bin Feng,Yu Wang,Zhiyuan Yan,Yonghong Tian,Yu Li,Li Yuan*

Main category: cs.LG

TL;DR: ChemCRAFT框架通过代理强化学习将化学推理与知识存储解耦，让小语言模型通过沙箱交互实现高性能化学任务，解决了现有方法在幻觉、隐私和成本之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 当前生化领域语言模型存在两难：小模型易产生幻觉且知识有限，大云模型有隐私风险和推理成本高。需要一种既能保持高性能又能本地部署、成本低廉的解决方案。

Method: 1) 构建代理轨迹构建管道和化学代理沙箱；2) 创建ChemToolDataset大规模化学工具轨迹数据集；3) 提出SMILES-GRPO构建密集化学奖励函数；4) 通过代理强化学习让模型学习调用化学代理的能力。

Result: ChemCRAFT在药物设计的多个方面（分子结构分析、分子优化、合成路径预测）超越了当前基于云的LLMs，证明科学推理不是模型规模的涌现能力，而是可学习的工具编排策略。

Conclusion: 该工作建立了成本效益高且保护隐私的AI辅助化学范式，为通过本地可部署代理加速分子发现开辟了新途径，展示了小模型通过工具编排也能实现高性能科学推理。

Abstract: Language models are revolutionizing the biochemistry domain, assisting scientists in drug design and chemical synthesis with high efficiency. Yet current approaches struggle between small language models prone to hallucination and limited knowledge retention, and large cloud-based language models plagued by privacy risks and high inference costs. To bridge this gap, we introduce ChemCRAFT, a novel framework leveraging agentic reinforcement learning to decouple chemical reasoning from knowledge storage. Instead of forcing the model to memorize vast chemical data, our approach empowers the language model to interact with a sandbox for precise information retrieval. This externalization of knowledge allows a locally deployable small model to achieve superior performance with minimal inference costs. To enable small language models for agent-calling ability, we build an agentic trajectory construction pipeline and a comprehensive chemical-agent sandbox. Based on sandbox interactions, we constructed ChemToolDataset, the first large-scale chemical tool trajectory dataset. Simultaneously, we propose SMILES-GRPO to build a dense chemical reward function, promoting the model's ability to call chemical agents. Evaluations across diverse aspects of drug design show that ChemCRAFT outperforms current cloud-based LLMs in molecular structure analysis, molecular optimization, and synthesis pathway prediction, demonstrating that scientific reasoning is not solely an emergent ability of model scale, but a learnable policy of tool orchestration. This work establishes a cost-effective and privacy-preserving paradigm for AI-aided chemistry, opening new avenues for accelerating molecular discovery with locally deployable agents.

</details>


### [106] [REV-INR: Regularized Evidential Implicit Neural Representation for Uncertainty-Aware Volume Visualization](https://arxiv.org/abs/2601.17689)
*Shanu Saklani,Tushar M. Athawale,Nairita Pal,David Pugmire,Christopher R. Johnson,Soumya Dutta*

Main category: cs.LG

TL;DR: REV-INR是一种正则化证据隐式神经表示，通过单次前向传播同时预测数据值和不确定性，解决传统INR缺乏不确定性估计的问题，实现高效可靠的体积重建和可视化。


<details>
  <summary>Details</summary>
Motivation: 传统确定性隐式神经表示（INR）只能预测数据值，无法提供模型预测不确定性或数据固有噪声的影响，这可能导致不可靠的数据解释和可视化。由于原始数据可能因体积过大而无法获得，识别模型预测数据中的错误结果可能不可行。

Method: 提出REV-INR（正则化证据隐式神经表示），通过单次前向传播同时学习预测数据值、坐标级数据不确定性（偶然不确定性）和模型不确定性（认知不确定性）。该方法结合证据深度学习框架进行不确定性估计。

Result: REV-INR在体积重建质量方面表现最佳，提供鲁棒的数据和模型不确定性估计，且推理时间最快。与现有深度不确定性估计方法相比，在重建质量和不确定性估计方面均有优势。

Conclusion: REV-INR能够评估提取的等值面和体积可视化结果的可靠性和可信度，使分析能够完全基于模型预测的数据进行，解决了传统INR缺乏不确定性估计的局限性。

Abstract: Applications of Implicit Neural Representations (INRs) have emerged as a promising deep learning approach for compactly representing large volumetric datasets. These models can act as surrogates for volume data, enabling efficient storage and on-demand reconstruction via model predictions. However, conventional deterministic INRs only provide value predictions without insights into the model's prediction uncertainty or the impact of inherent noisiness in the data. This limitation can lead to unreliable data interpretation and visualization due to prediction inaccuracies in the reconstructed volume. Identifying erroneous results extracted from model-predicted data may be infeasible, as raw data may be unavailable due to its large size. To address this challenge, we introduce REV-INR, Regularized Evidential Implicit Neural Representation, which learns to predict data values accurately along with the associated coordinate-level data uncertainty and model uncertainty using only a single forward pass of the trained REV-INR during inference. By comprehensively comparing and contrasting REV-INR with existing well-established deep uncertainty estimation methods, we show that REV-INR achieves the best volume reconstruction quality with robust data (aleatoric) and model (epistemic) uncertainty estimates using the fastest inference time. Consequently, we demonstrate that REV-INR facilitates assessment of the reliability and trustworthiness of the extracted isosurfaces and volume visualization results, enabling analyses to be solely driven by model-predicted data.

</details>


### [107] [FedCCA: Client-Centric Adaptation against Data Heterogeneity in Federated Learning on IoT Devices](https://arxiv.org/abs/2601.17713)
*Kaile Wang,Jiannong Cao,Yu Yang,Xiaoyin Li,Yinfeng Cao*

Main category: cs.LG

TL;DR: FedCCA是一种针对物联网数据异构性的联邦学习算法，通过客户端中心化自适应机制，为每个客户端学习独特模型，提升性能和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 物联网设备上的AI模型训练需求增长，但数据异构性问题严重影响联邦学习的性能和收敛速度。现有方法在固定客户端选择和云端聚合方面存在局限，难以在保护隐私的同时提取客户端特定信息。

Method: 提出FedCCA算法：1）采用动态客户端选择；2）基于额外的客户端特定编码器进行自适应聚合；3）使用基于注意力的全局聚合策略增强多源知识转移。

Result: 在多个数据集上的广泛实验表明，FedCCA在处理数据异构性问题时，相比基线方法展现出显著的性能优势。

Conclusion: FedCCA通过客户端中心化自适应机制，有效缓解了联邦学习中的数据异构性问题，为每个客户端学习独特模型，提升了整体性能。

Abstract: With the rapid development of the Internet of Things (IoT), AI model training on private data such as human sensing data is highly desired. Federated learning (FL) has emerged as a privacy-preserving distributed training framework for this purpuse. However, the data heterogeneity issue among IoT devices can significantly degrade the model performance and convergence speed in FL. Existing approaches limit in fixed client selection and aggregation on cloud server, making the privacy-preserving extraction of client-specific information during local training challenging. To this end, we propose Client-Centric Adaptation federated learning (FedCCA), an algorithm that optimally utilizes client-specific knowledge to learn a unique model for each client through selective adaptation, aiming to alleviate the influence of data heterogeneity. Specifically, FedCCA employs dynamic client selection and adaptive aggregation based on the additional client-specific encoder. To enhance multi-source knowledge transfer, we adopt an attention-based global aggregation strategy. We conducted extensive experiments on diverse datasets to assess the efficacy of FedCCA. The experimental results demonstrate that our approach exhibits a substantial performance advantage over competing baselines in addressing this specific problem.

</details>


### [108] [Do Reasoning Models Ask Better Questions? A Formal Information-Theoretic Analysis on Multi-Turn LLM Games](https://arxiv.org/abs/2601.17716)
*Daniel M. Pedrozo,Telma W. de L. Soares,Bryan L. M. de Oliveira*

Main category: cs.LG

TL;DR: 该论文提出了一个多轮对话框架，用于定量评估LLMs通过是/否问题在分层知识图谱环境中收集信息的效果，采用信息增益作为主要指标，并在"猜城市"游戏中验证了具有显式推理能力的模型表现更好。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在许多任务上表现出色，但在处理LLM智能体的关键能力——为消除用户请求中的歧义而提出好问题——方面仍有不足。现有基准缺乏基于信息增益的全面评估框架，也很少系统比较使用链式思维推理和不使用该推理的模型。

Method: 提出了一个多轮对话框架，采用三个交互的LLM智能体：提问者、回答者和假设空间更新者。使用基于香农熵的信息增益作为主要指标，评估每个回合和累积的查询效果。在按五级分类组织的"猜城市"游戏环境中实例化该框架，评估了在完全和部分可观测条件下、有/无链式思维推理的多个LLM变体。

Result: 实验表明，在评估的模型中，具有显式推理能力的模型每回合获得更高的信息增益，并以更少的步骤达到解决方案，特别是在部分可观测设置中。推理轨迹分析显示，较小模型通过更积极地探索候选问题来弥补能力限制，而较大模型在选择最优查询时表现出更高的自信，生成具有更大潜在信息增益的候选问题。

Conclusion: 该研究提出了一个系统评估LLMs信息收集能力的框架，证明了显式推理对提高LLMs提问效率的重要性，为开发更有效的LLM智能体提供了理论基础和评估方法。

Abstract: Large Language Models (LLMs) excel at many tasks but still struggle with a critical ability for LLM-based agents: asking good questions for resolving ambiguity in user requests. While prior work has explored information-seeking behavior through word games, existing benchmarks lack comprehensive evaluation frameworks that provide both final and intermediate signals based on Information Gain (IG). Moreover, they rarely provide systematic comparisons between models that use chain-of-thought reasoning and those that do not. We propose a multi-turn dialogue framework that quantitatively measures how effectively LLMs gather information through yes/no questions in a hierarchical knowledge graph environment. Our framework employs a triad of interacting LLM agents that ask questions, answer them, and update the hypothesis space. We adopt IG as the main metric, grounded in Shannon entropy, to assess query effectiveness at each turn and cumulatively. We instantiate our framework in a geographical Guess My City game setting organized in a five-level taxonomy and evaluate multiple LLM variants under fully and partially observable conditions, with and without Chain-of-Thought reasoning. Our experiments demonstrate that, among the evaluated models, the ones with explicit reasoning capabilities achieve higher IG per turn and reach solutions in fewer steps, particularly in partially observable settings. Analysis of reasoning traces reveals that smaller models compensate for limited capacity through more aggressive exploration of candidate questions, while larger models exhibit higher assertiveness in selecting optimal queries, generating candidates with greater potential IG.

</details>


### [109] [AR-Omni: A Unified Autoregressive Model for Any-to-Any Generation](https://arxiv.org/abs/2601.17761)
*Dongjie Cheng,Ruifeng Yuan,Yongqi Li,Runyang You,Wenjie Wang,Liqiang Nie,Lei Zhang,Wenjie Li*

Main category: cs.LG

TL;DR: AR-Omni是一个统一的自回归多模态大语言模型，支持文本、图像和语音的任意到任意生成，无需专家解码器，通过单一Transformer解码器实现实时多模态生成。


<details>
  <summary>Details</summary>
Motivation: 现实世界的感知和交互本质上是多模态的，需要支持多模态输入和输出的"全能"MLLMs。现有系统大多依赖额外的专家组件来实现多模态生成，限制了统一训练和推理的简洁性。自回归建模在文本领域已被证明是优雅且可扩展的基础，因此希望将其扩展到多模态领域。

Method: 提出AR-Omni统一自回归模型：1）使用单一Transformer解码器支持文本、图像和流式语音生成；2）通过任务感知损失重加权解决模态不平衡问题；3）使用轻量级令牌级感知对齐损失提高视觉保真度；4）采用有限状态解码机制平衡稳定性和创造性。

Result: AR-Omni在三个模态上都实现了强大的生成质量，同时保持实时性，语音生成的实时因子达到0.88。

Conclusion: AR-Omni展示了自回归范式在多模态生成中的有效性，通过统一架构简化了训练和推理流程，为真正的任意到任意多模态交互提供了可行的解决方案。

Abstract: Real-world perception and interaction are inherently multimodal, encompassing not only language but also vision and speech, which motivates the development of "Omni" MLLMs that support both multimodal inputs and multimodal outputs. While a sequence of omni MLLMs has emerged, most existing systems still rely on additional expert components to achieve multimodal generation, limiting the simplicity of unified training and inference. Autoregressive (AR) modeling, with a single token stream, a single next-token objective, and a single decoder, is an elegant and scalable foundation in the text domain. Motivated by this, we present AR-Omni, a unified any-to-any model in the autoregressive paradigm without any expert decoders. AR-Omni supports autoregressive text and image generation, as well as streaming speech generation, all under a single Transformer decoder. We further address three practical issues in unified AR modeling: modality imbalance via task-aware loss reweighting, visual fidelity via a lightweight token-level perceptual alignment loss for image tokens, and stability-creativity trade-offs via a finite-state decoding mechanism. Empirically, AR-Omni achieves strong quality across three modalities while remaining real-time, achieving a 0.88 real-time factor for speech generation.

</details>


### [110] [LLM-42: Enabling Determinism in LLM Inference with Verified Speculation](https://arxiv.org/abs/2601.17768)
*Raja Gond,Aditya K Kamath,Arkaprava Basu,Ramachandran Ramjee,Ashish Panwar*

Main category: cs.LG

TL;DR: LLM-42通过调度方法实现LLM推理确定性，利用推测解码思想，在非确定性快速路径解码后通过轻量级验证-回滚循环确保一致性，避免动态批处理关闭导致的吞吐量下降。


<details>
  <summary>Details</summary>
Motivation: LLM推理中的非确定性源于浮点非结合性与动态批处理及GPU核的批大小相关归约顺序变化。现有方法要么关闭动态批处理严重降低吞吐量，要么需要重新设计核实现，将确定性与核设计紧密耦合且带来固定运行时开销。

Method: LLM-42采用基于调度的方法：1）使用非确定性快速路径解码令牌；2）通过轻量级验证-回滚循环强制确定性；3）验证器在固定形状归约调度下重放候选令牌；4）提交保证跨运行一致的令牌，回滚违反确定性的令牌。

Result: LLM-42能够：1）大部分重用现有核实现；2）仅按需要确定性的流量比例产生开销；3）保持动态批处理的吞吐优势；4）通过验证-回滚机制确保输出一致性。

Conclusion: LLM-42提供了一种实用的调度方法来解决LLM推理中的非确定性问题，既保持了动态批处理的吞吐优势，又避免了与核设计的紧密耦合，仅在实际需要确定性的工作负载上产生开销。

Abstract: In LLM inference, the same prompt may yield different outputs across different runs. At the system level, this non-determinism arises from floating-point non-associativity combined with dynamic batching and GPU kernels whose reduction orders vary with batch size. A straightforward way to eliminate non-determinism is to disable dynamic batching during inference, but doing so severely degrades throughput. Another approach is to make kernels batch-invariant; however, this tightly couples determinism to kernel design, requiring new implementations. This coupling also imposes fixed runtime overheads, regardless of how much of the workload actually requires determinism.
  Inspired by ideas from speculative decoding, we present LLM-42, a scheduling-based approach to enable determinism in LLM inference. Our key observation is that if a sequence is in a consistent state, the next emitted token is likely to be consistent even with dynamic batching. Moreover, most GPU kernels use shape-consistent reductions. Leveraging these insights, LLM-42 decodes tokens using a non-deterministic fast path and enforces determinism via a lightweight verify-rollback loop. The verifier replays candidate tokens under a fixed-shape reduction schedule, commits those that are guaranteed to be consistent across runs, and rolls back those violating determinism. LLM-42 mostly re-uses existing kernels unchanged and incurs overhead only in proportion to the traffic that requires determinism.

</details>


### [111] [Shortcut Learning in Binary Classifier Black Boxes: Applications to Voice Anti-Spoofing and Biometrics](https://arxiv.org/abs/2601.17782)
*Md Sahidullah,Hye-jin Shim,Rosa Gonzalez Hautamäki,Tomi H. Kinnunen*

Main category: cs.LG

TL;DR: 提出一个分析二分类器中数据集偏差和"捷径学习"效应的框架，通过干预和观察视角结合线性混合效应模型进行事后分析，在音频反欺骗和说话人验证任务上验证有效性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在数据驱动应用中的广泛使用引发了人们对数据集和模型偏见的关注。被忽视或隐藏的偏见可能导致意外结果，需要解决数据集偏见问题并探索二分类器中的"捷径学习"或"聪明汉斯效应"。

Method: 提出一个新颖的框架来分析黑盒分类器，并检查训练和测试数据对分类器分数的影响。该框架结合干预和观察视角，采用线性混合效应模型进行事后分析，超越错误率评估分类器性能。

Result: 在音频反欺骗和说话人验证任务上，使用统计模型和深度神经网络验证了方法的有效性。实验表明该框架能够提供对偏见数据集的洞察，并全面理解其对分类器行为的影响。

Conclusion: 该研究提出的框架为分析数据集偏见和分类器行为提供了新视角，对解决其他领域的偏见问题和推进可解释人工智能领域具有更广泛的意义。

Abstract: The widespread adoption of deep-learning models in data-driven applications has drawn attention to the potential risks associated with biased datasets and models. Neglected or hidden biases within datasets and models can lead to unexpected results. This study addresses the challenges of dataset bias and explores ``shortcut learning'' or ``Clever Hans effect'' in binary classifiers. We propose a novel framework for analyzing the black-box classifiers and for examining the impact of both training and test data on classifier scores. Our framework incorporates intervention and observational perspectives, employing a linear mixed-effects model for post-hoc analysis. By evaluating classifier performance beyond error rates, we aim to provide insights into biased datasets and offer a comprehensive understanding of their influence on classifier behavior. The effectiveness of our approach is demonstrated through experiments on audio anti-spoofing and speaker verification tasks using both statistical models and deep neural networks. The insights gained from this study have broader implications for tackling biases in other domains and advancing the field of explainable artificial intelligence.

</details>


### [112] [Robust Computational Extraction of Non-Enhancing Hypercellular Tumor Regions from Clinical Imaging Data](https://arxiv.org/abs/2601.17802)
*A. Brawanski,Th. Schaffer,F. Raab,K. -M. Schebesch,M. Schrey,Chr. Doenitz,A. M. Tomé,E. W. Lang*

Main category: cs.LG

TL;DR: 提出一个计算框架，从常规MRI数据生成非增强高细胞性肿瘤区域的概率图，通过多网络架构解决边界模糊问题，验证了方法学稳健性和生物学相关性。


<details>
  <summary>Details</summary>
Motivation: 神经肿瘤影像中准确识别非增强高细胞性肿瘤区域是一个未满足的需求，对患者管理和治疗规划有重要意义。目前缺乏可靠的成像方法来定位这些区域。

Method: 开发了一个稳健的计算框架，利用多种网络架构从常规MRI数据生成NEH区域的概率图，解决了固有的变异性和缺乏清晰成像边界的问题。

Result: 该方法通过独立临床标志物（相对脑血容量和增强肿瘤复发位置）进行了验证，证明了方法学稳健性和生物学相关性，能够可靠地无创映射NEH肿瘤区域。

Conclusion: 该框架支持将NEH区域作为影像生物标志物整合到临床工作流程中，推进脑肿瘤患者的精准肿瘤学发展。

Abstract: Accurate identification of non-enhancing hypercellular (NEH) tumor regions is an unmet need in neuro-oncological imaging, with significant implications for patient management and treatment planning. We present a robust computational framework that generates probability maps of NEH regions from routine MRI data, leveraging multiple network architectures to address the inherent variability and lack of clear imaging boundaries. Our approach was validated against independent clinical markers -- relative cerebral blood volume (rCBV) and enhancing tumor recurrence location (ETRL) -- demonstrating both methodological robustness and biological relevance. This framework enables reliable, non-invasive mapping of NEH tumor compartments, supporting their integration as imaging biomarkers in clinical workflows and advancing precision oncology for brain tumor patients.

</details>


### [113] [MergeMix: Optimizing Mid-Training Data Mixtures via Learnable Model Merging](https://arxiv.org/abs/2601.17858)
*Jiapeng Wang,Changxin Tian,Kunlong Chen,Ziqi Liu,Jiaxin Mao,Wayne Xin Zhao,Zhiqiang Zhang,Jun Zhou*

Main category: cs.LG

TL;DR: MergeMix通过将模型合并权重作为高性能代理，高效优化数据混合比例，大幅降低搜索成本，在8B和16B参数模型上验证有效。


<details>
  <summary>Details</summary>
Motivation: 优化数据混合对释放大语言模型潜力至关重要，但当前依赖启发式试验或昂贵代理训练的方法计算成本过高，需要更高效的优化方案。

Method: 提出MergeMix方法：在少量token上训练领域专家模型，然后优化这些专家的合并权重以匹配下游基准性能，将模型合并权重作为高性能、低成本的代理指标。

Result: 在8B和16B参数模型上的实验表明，MergeMix性能达到或超过穷举手动调优，同时大幅降低搜索成本，具有高秩一致性（Spearman ρ>0.9）和强跨尺度可迁移性。

Conclusion: MergeMix为数据混合优化提供了可扩展的自动化解决方案，通过模型合并权重作为高效代理，解决了传统方法计算成本过高的问题。

Abstract: Optimizing data mixtures is essential for unlocking the full potential of large language models (LLMs), yet identifying the optimal composition remains computationally prohibitive due to reliance on heuristic trials or expensive proxy training. To address this, we introduce \textbf{MergeMix}, a novel approach that efficiently determines optimal data mixing ratios by repurposing model merging weights as a high-fidelity, low-cost performance proxy. By training domain-specific experts on minimal tokens and optimizing their merging weights against downstream benchmarks, MergeMix effectively optimizes the performance of data mixtures without incurring the cost of full-scale training. Extensive experiments on models with 8B and 16B parameters validate that MergeMix achieves performance comparable to or surpassing exhaustive manual tuning while drastically reducing search costs. Furthermore, MergeMix exhibits high rank consistency (Spearman $ρ> 0.9$) and strong cross-scale transferability, offering a scalable, automated solution for data mixture optimization.

</details>


### [114] [EEG Foundation Models: Progresses, Benchmarking, and Open Problems](https://arxiv.org/abs/2601.17883)
*Dingkun Liu,Yuheng Chen,Zhu Chen,Zhenyao Cui,Yaozhi Wen,Jiayu An,Jingwei Luo,Dongrui Wu*

Main category: cs.LG

TL;DR: 该论文对现有EEG基础模型进行了系统性评估，比较了12个开源模型在13个数据集上的表现，发现线性探测通常不足、专业模型仍具竞争力、更大模型不一定带来更好泛化性能。


<details>
  <summary>Details</summary>
Motivation: EEG基础模型在脑机接口领域发展迅速，但由于预训练目标、预处理方法和评估协议不一致，缺乏公平全面的比较。本文旨在填补这一空白，为EEG基础模型研究提供系统评估框架。

Method: 首先回顾50个代表性模型并构建统一分类框架，然后评估12个开源基础模型和竞争性专业基线模型在13个EEG数据集上，涵盖9种BCI范式。采用跨被试泛化（留一被试）和少样本快速校准两种设置，比较全参数微调与线性探测，并分析模型规模与性能关系。

Result: 研究发现：1）线性探测通常不足以获得最佳性能；2）从头训练的专业模型在许多任务上仍具有竞争力；3）在当前数据规模和训练实践下，更大的基础模型不一定带来更好的泛化性能。

Conclusion: 该研究为EEG基础模型提供了首个系统性评估基准，揭示了当前方法的局限性，为未来EEG基础模型的设计和评估提供了重要指导。

Abstract: Electroencephalography (EEG) foundation models have recently emerged as a promising paradigm for brain-computer interfaces (BCIs), aiming to learn transferable neural representations from large-scale heterogeneous recordings. Despite rapid progresses, there lacks fair and comprehensive comparisons of existing EEG foundation models, due to inconsistent pre-training objectives, preprocessing choices, and downstream evaluation protocols. This paper fills this gap. We first review 50 representative models and organize their design choices into a unified taxonomic framework including data standardization, model architectures, and self-supervised pre-training strategies. We then evaluate 12 open-source foundation models and competitive specialist baselines across 13 EEG datasets spanning nine BCI paradigms. Emphasizing real-world deployments, we consider both cross-subject generalization under a leave-one-subject-out protocol and rapid calibration under a within-subject few-shot setting. We further compare full-parameter fine-tuning with linear probing to assess the transferability of pre-trained representations, and examine the relationship between model scale and downstream performance. Our results indicate that: 1) linear probing is frequently insufficient; 2) specialist models trained from scratch remain competitive across many tasks; and, 3) larger foundation models do not necessarily yield better generalization performance under current data regimes and training practices.

</details>


### [115] [Adaptive Weighting in Knowledge Distillation: An Axiomatic Framework for Multi-Scale Teacher Ensemble Optimization](https://arxiv.org/abs/2601.17910)
*Aaron R. Flouro,Shawn P. Chadwick*

Main category: cs.LG

TL;DR: 本文提出了一个算子无关的公理化框架，用于多教师知识蒸馏中的自适应权重分配，涵盖token、task和context三个互补尺度，为异构、分布偏移和安全约束下的蒸馏方法提供理论分析基础。


<details>
  <summary>Details</summary>
Motivation: 现有多教师知识蒸馏方法主要依赖启发式或实现特定的权重方案，缺乏统一的理论框架。本文旨在建立一个算子无关的公理化框架，为自适应权重分配提供理论基础，以应对异构性、分布偏移和安全约束等挑战。

Method: 开发了一个算子无关的公理化框架，形式化了自适应权重算子在token、task和context三个尺度上的结构条件，包括良好定义性、多重非等价实现可能性，以及通过乘积结构归一化的层次组合。在该框架内建立了符合算子的存在性和非唯一性，分析了梯度优化的收敛性、稳定性和扰动鲁棒性，并提供了安全约束蒸馏的抽象表述。

Result: 该框架将理论保证与具体权重公式解耦，使得在异构性、分布偏移和安全约束下能够对自适应蒸馏方法进行原则性分析。建立了算子的存在性、非唯一性、收敛性、稳定性和鲁棒性等理论性质。

Conclusion: 本文提出的公理化框架为多教师知识蒸馏的自适应权重分配提供了统一的理论基础，使得能够在不依赖具体实现细节的情况下分析和设计蒸馏方法，特别是在面对复杂现实场景中的异构性、分布偏移和安全要求时具有重要价值。

Abstract: Knowledge distillation with multiple teachers is increasingly used to improve robustness, efficiency, and safety, yet existing approaches rely largely on heuristic or implementation-specific weighting schemes. This paper develops an operator-agnostic axiomatic framework for adaptive weighting in multi-teacher knowledge distillation across three complementary scales: token, task, and context. We formalize structural conditions under which adaptive weighting operators are well-defined, admit multiple non-equivalent implementations, and can be hierarchically composed via product-structure normalization. Within this framework, we establish existence and non-uniqueness of conforming operators, characterize convergence of gradient-based optimization under standard assumptions, analyze stability and perturbation robustness, and provide an abstract formulation of safety-constrained distillation. The results decouple theoretical guarantees from specific weighting formulas, enabling principled analysis of adaptive distillation methods under heterogeneity, distribution shift, and safety constraints.

</details>


### [116] [Causal Pre-training Under the Fairness Lens: An Empirical Study of TabPFN](https://arxiv.org/abs/2601.17912)
*Qinyi Liu,Mohammad Khalil,Naman Goel*

Main category: cs.LG

TL;DR: TabPFN等表格数据基础模型通过因果预训练获得高预测精度，但其公平性表现有限，尤其在MNAR协变量偏移下公平性改善不一致，需要额外的公平性干预措施。


<details>
  <summary>Details</summary>
Motivation: 虽然TabPFN等表格基础模型通过因果预训练获得了高预测性能，但这些融入因果推理思想的模型在公平性方面的特性尚未得到充分探索，需要评估其在实际部署中的公平性表现。

Method: 对TabPFN及其微调变体进行全面的实证评估，包括预测性能、公平性和鲁棒性，在不同数据集大小和分布偏移条件下进行测试。

Result: TabPFN相比基线模型具有更强的预测精度，对虚假相关性表现出鲁棒性，但公平性改善有限且不一致，特别是在MNAR协变量偏移下公平性表现不佳。

Conclusion: TabPFN的因果预训练有助于预测性能，但不足以确保算法公平性，实际部署中需要额外的公平性干预措施，未来研究需要进一步关注基础模型的公平性问题。

Abstract: Foundation models for tabular data, such as the Tabular Prior-data Fitted Network (TabPFN), are pre-trained on a massive number of synthetic datasets generated by structural causal models (SCM). They leverage in-context learning to offer high predictive accuracy in real-world tasks. However, the fairness properties of these foundational models, which incorporate ideas from causal reasoning during pre-training, have not yet been explored in sufficient depth. In this work, we conduct a comprehensive empirical evaluation of TabPFN and its fine-tuned variants, assessing predictive performance, fairness, and robustness across varying dataset sizes and distributional shifts. Our results reveal that while TabPFN achieves stronger predictive accuracy compared to baselines and exhibits robustness to spurious correlations, improvements in fairness are moderate and inconsistent, particularly under missing-not-at-random (MNAR) covariate shifts. These findings suggest that the causal pre-training in TabPFN is helpful but insufficient for algorithmic fairness, highlighting implications for deploying such models in practice and the need for further fairness interventions.

</details>


### [117] [UniPACT: A Multimodal Framework for Prognostic Question Answering on Raw ECG and Structured EHR](https://arxiv.org/abs/2601.17916)
*Jialu Tang,Tong Xia,Yuan Lu,Aaqib Saeed*

Main category: cs.LG

TL;DR: UniPACT是一个统一的临床预后问答框架，通过结构化提示将数值型EHR数据转换为语义丰富的文本，并与原始ECG波形表示融合，使LLM能够对两种模态进行整体推理，在MDS-ED基准测试中达到89.37%的平均AUROC。


<details>
  <summary>Details</summary>
Motivation: 准确的临床预后需要综合结构化电子健康记录（EHR）和实时生理信号（如心电图ECG）。虽然大型语言模型（LLMs）为此任务提供了强大的推理引擎，但难以原生处理这些异构的非文本数据类型。

Method: 提出UniPACT框架，核心是结构化提示机制，将数值型EHR数据转换为语义丰富的文本。然后将这种文本化的患者上下文与从原始ECG波形直接学习的表示融合，使LLM能够对两种模态进行整体推理。

Result: 在综合的MDS-ED基准测试中，UniPACT在包括诊断、病情恶化、ICU入院和死亡率在内的多样化预后任务上实现了89.37%的平均AUROC，优于专门的基线方法。

Conclusion: 多模态、多任务方法对性能至关重要，并在数据缺失场景中提供了鲁棒性。UniPACT成功弥合了模态差距，使LLM能够有效处理异构临床数据。

Abstract: Accurate clinical prognosis requires synthesizing structured Electronic Health Records (EHRs) with real-time physiological signals like the Electrocardiogram (ECG). Large Language Models (LLMs) offer a powerful reasoning engine for this task but struggle to natively process these heterogeneous, non-textual data types. To address this, we propose UniPACT (Unified Prognostic Question Answering for Clinical Time-series), a unified framework for prognostic question answering that bridges this modality gap. UniPACT's core contribution is a structured prompting mechanism that converts numerical EHR data into semantically rich text. This textualized patient context is then fused with representations learned directly from raw ECG waveforms, enabling an LLM to reason over both modalities holistically. We evaluate UniPACT on the comprehensive MDS-ED benchmark, it achieves a state-of-the-art mean AUROC of 89.37% across a diverse set of prognostic tasks including diagnosis, deterioration, ICU admission, and mortality, outperforming specialized baselines. Further analysis demonstrates that our multimodal, multi-task approach is critical for performance and provides robustness in missing data scenarios.

</details>


### [118] [treaming-dLLM: Accelerating Diffusion LLMs via Suffix Pruning and Dynamic Decoding](https://arxiv.org/abs/2601.17917)
*Zhongyu Xiao,Zhiwei Hao,Jianyuan Guo,Yong Luo,Jia Liu,Jie Xu,Han Hu*

Main category: cs.LG

TL;DR: Streaming-dLLM是一个无需训练的高效推理框架，通过空间维度的衰减引导后缀建模和时间维度的动态置信感知策略，显著加速扩散大语言模型的推理速度，最高可达68.2倍加速。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散大语言模型推理加速方法（如KV缓存重用或启发式解码）忽略了块级扩散过程中的内在低效性：空间冗余（对信息稀疏的后缀区域进行统一建模）和时间低效（在整个解码过程中应用固定的去噪调度）。

Method: 提出Streaming-dLLM框架：1）空间上，采用衰减引导后缀建模，通过剪枝冗余的掩码标记来近似完整上下文；2）时间上，采用动态置信感知策略和提前退出机制，允许模型对已收敛的标记跳过不必要的迭代。

Result: 实验表明Streaming-dLLM在保持生成质量的同时，实现了高达68.2倍的推理加速，证明了其在扩散解码中的有效性。

Conclusion: Streaming-dLLM通过解决扩散大语言模型推理中的空间冗余和时间低效问题，显著提升了推理效率，为扩散模型的实用化部署提供了有效解决方案。

Abstract: Diffusion Large Language Models (dLLMs) offer a compelling paradigm for natural language generation, leveraging parallel decoding and bidirectional attention to achieve superior global coherence compared to autoregressive models. While recent works have accelerated inference via KV cache reuse or heuristic decoding, they overlook the intrinsic inefficiencies within the block-wise diffusion process. Specifically, they suffer from spatial redundancy by modeling informative-sparse suffix regions uniformly and temporal inefficiency by applying fixed denoising schedules across all the decoding process. To address this, we propose Streaming-dLLM, a training-free framework that streamlines inference across both spatial and temporal dimensions. Spatially, we introduce attenuation guided suffix modeling to approximate the full context by pruning redundant mask tokens. Temporally, we employ a dynamic confidence aware strategy with an early exit mechanism, allowing the model to skip unnecessary iterations for converged tokens. Extensive experiments show that Streaming-dLLM achieves up to 68.2X speedup while maintaining generation quality, highlighting its effectiveness in diffusion decoding. The code is available at https://github.com/xiaoshideta/Streaming-dLLM.

</details>


### [119] [Dissipative Learning: A Framework for Viable Adaptive Systems](https://arxiv.org/abs/2601.17933)
*Laurent Caraffa*

Main category: cs.LG

TL;DR: 该论文提出BEDS框架，将学习视为内在耗散过程，证明Fisher-Rao正则化是热力学最优策略，统一了多种现有方法，重新定义了过拟合和灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 传统学习理论将遗忘和正则化视为启发式附加组件，而非学习系统的结构要求。作者认为学习本质上是一个耗散过程，需要从信息理论、热力学和信息几何角度重新理解学习动力学。

Method: 提出BEDS（贝叶斯涌现耗散结构）框架，将学习建模为在耗散约束下压缩信念状态的演化。引入条件最优性定理，证明Fisher-Rao正则化是唯一热力学最优策略。该框架统一了岭回归、SIGReg、EMA、SAC等方法。

Result: 证明了Fisher-Rao正则化在热力学上最优，而欧几里得正则化结构上次优。将过拟合解释为过度结晶，灾难性遗忘解释为耗散控制不足。区分了BEDS可结晶问题和BEDS可维持问题。

Conclusion: 学习应被重新定义为在耗散约束下维持可行信念状态的过程。该框架为遗忘、正则化和稳定性提供了原则性视角，将可行性而非渐近最优性作为主要标准，适用于持续学习和多智能体系统。

Abstract: We propose a perspective in which learning is an intrinsically dissipative process. Forgetting and regularization are not heuristic add-ons but structural requirements for adaptive systems. Drawing on information theory, thermodynamics, and information geometry, we introduce the BEDS (Bayesian Emergent Dissipative Structures) framework, modeling learning as the evolution of compressed belief states under dissipation constraints.
  A central contribution is the Conditional Optimality Theorem, showing that Fisher-Rao regularization measuring change via information divergence rather than Euclidean distance is the unique thermodynamically optimal regularization strategy, achieving minimal dissipation. Euclidean regularization is shown to be structurally suboptimal. The framework unifies existing methods (Ridge, SIGReg, EMA, SAC) as special cases of a single governing equation.
  Within this view, overfitting corresponds to over-crystallization, while catastrophic forgetting reflects insufficient dissipation control. The framework distinguishes BEDS-crystallizable problems, where beliefs converge to stable equilibria, from BEDS-maintainable problems, which require continual adaptation. It extends naturally to continual and multi-agent systems, where viability, stability under adaptation and finite resources replaces asymptotic optimality as the primary criterion. Overall, this work reframes learning as maintaining viable belief states under dissipation constraints, providing a principled lens on forgetting, regularization, and stability.

</details>


### [120] [FedGraph-VASP: Privacy-Preserving Federated Graph Learning with Post-Quantum Security for Cross-Institutional Anti-Money Laundering](https://arxiv.org/abs/2601.17935)
*Daniel Commey,Matilda Nkoom,Yousef Alsenani,Sena G. Hounsinou,Garth V. Crosby*

Main category: cs.LG

TL;DR: FedGraph-VASP是一个保护隐私的联邦图学习框架，用于跨机构反洗钱检测，通过边界嵌入交换协议在不暴露原始数据的情况下实现协作分析，在连接性强的交易图中表现优异。


<details>
  <summary>Details</summary>
Motivation: 虚拟资产服务提供商在反洗钱检测中面临监管合规与用户隐私的冲突，现有方法要么需要共享敏感交易数据，要么孤立运行无法检测跨链洗钱模式。

Method: 提出FedGraph-VASP框架，核心是边界嵌入交换协议，只共享压缩的、不可逆的图神经网络边界账户表示，使用后量子密码学（Kyber-512和AES-256-GCM）保护通信安全。

Result: 在Elliptic比特币数据集上，FedGraph-VASP的F1分数达到0.508，优于FedSage+（0.453）12.1%；在连接性强的场景中接近集中式性能（0.620），但在稀疏连接场景中FedSage+表现更好。

Conclusion: 存在拓扑依赖的权衡：嵌入交换在连接性强的交易图中表现优异，而生成式插补在高度模块化的稀疏图中占优势；隐私审计显示嵌入仅部分可逆，限制了特征恢复。

Abstract: Virtual Asset Service Providers (VASPs) face a fundamental tension between regulatory compliance and user privacy when detecting cross-institutional money laundering. Current approaches require either sharing sensitive transaction data or operating in isolation, leaving critical cross-chain laundering patterns undetected. We present FedGraph-VASP, a privacy-preserving federated graph learning framework that enables collaborative anti-money laundering (AML) without exposing raw user data. Our key contribution is a Boundary Embedding Exchange protocol that shares only compressed, non-invertible graph neural network representations of boundary accounts. These exchanges are secured using post-quantum cryptography, specifically the NIST-standardized Kyber-512 key encapsulation mechanism combined with AES-256-GCM authenticated encryption. Experiments on the Elliptic Bitcoin dataset with realistic Louvain partitioning show that FedGraph-VASP achieves an F1-score of 0.508, outperforming the state-of-the-art generative baseline FedSage+ (F1 = 0.453) by 12.1 percent on binary fraud detection. We further show robustness under low-connectivity settings where generative imputation degrades performance, while approaching centralized performance (F1 = 0.620) in high-connectivity regimes. We additionally evaluate generalization on an Ethereum fraud detection dataset, where FedGraph-VASP (F1 = 0.635) is less effective under sparse cross-silo connectivity, while FedSage+ excels (F1 = 0.855), outperforming even local training (F1 = 0.785). These results highlight a topology-dependent trade-off: embedding exchange benefits connected transaction graphs, whereas generative imputation can dominate in highly modular sparse graphs. A privacy audit shows embeddings are only partially invertible (R^2 = 0.32), limiting exact feature recovery.

</details>


### [121] [Scaling Effects and Uncertainty Quantification in Neural Actor Critic Algorithms](https://arxiv.org/abs/2601.17954)
*Nikos Georgoudios,Konstantinos Spiliopoulos,Justin Sirignano*

Main category: cs.LG

TL;DR: 研究神经Actor-Critic算法中网络宽度缩放对收敛性和统计特性的影响，提出可调缩放参数并分析其统计行为


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注收敛速度，本文转向更全面的统计特性分析，旨在量化神经Actor-Critic方法的不确定性，为算法提供统计保证

Method: 研究Actor和Critic使用浅层神经网络，分析网络宽度的一般逆多项式缩放（指数在0.5到1之间），推导网络输出的渐近展开，将其解释为统计估计量

Result: 方差随网络宽度以幂次衰减，指数为0.5减去缩放参数，表明缩放参数接近1时统计鲁棒性更好；数值实验支持该行为并显示更快收敛

Conclusion: 分析结果为选择算法超参数（学习率、探索率）提供具体指导，确保可证明的有利统计行为，为神经Actor-Critic方法提供统计保证

Abstract: We investigate the neural Actor Critic algorithm using shallow neural networks for both the Actor and Critic models. The focus of this work is twofold: first, to compare the convergence properties of the network outputs under various scaling schemes as the network width and the number of training steps tend to infinity; and second, to provide precise control of the approximation error associated with each scaling regime. Previous work has shown convergence to ordinary differential equations with random initial conditions under inverse square root scaling in the network width. In this work, we shift the focus from convergence speed alone to a more comprehensive statistical characterization of the algorithm's output, with the goal of quantifying uncertainty in neural Actor Critic methods. Specifically, we study a general inverse polynomial scaling in the network width, with an exponent treated as a tunable hyperparameter taking values strictly between one half and one. We derive an asymptotic expansion of the network outputs, interpreted as statistical estimators, in order to clarify their structure. To leading order, we show that the variance decays as a power of the network width, with an exponent equal to one half minus the scaling parameter, implying improved statistical robustness as the scaling parameter approaches one. Numerical experiments support this behavior and further suggest faster convergence for this choice of scaling. Finally, our analysis yields concrete guidelines for selecting algorithmic hyperparameters, including learning rates and exploration rates, as functions of the network width and the scaling parameter, ensuring provably favorable statistical behavior.

</details>


### [122] [TensorLens: End-to-End Transformer Analysis via High-Order Attention Tensors](https://arxiv.org/abs/2601.17958)
*Ido Andrew Atad,Itamar Zimerman,Shahar Katz,Lior Wolf*

Main category: cs.LG

TL;DR: TensorLens：一种将整个Transformer表示为单一输入依赖线性算子的新方法，通过高阶注意力交互张量统一编码注意力、FFN、激活、归一化和残差连接。


<details>
  <summary>Details</summary>
Motivation: 现有注意力分析大多局限于单个注意力头或层，无法捕捉模型的全局行为。虽然已有研究尝试通过平均和矩阵乘法扩展注意力公式，或纳入归一化和FFN等组件，但仍缺乏一个统一完整的表示来封装所有Transformer块。

Method: 提出TensorLens方法，将整个Transformer表示为单一输入依赖线性算子，通过高阶注意力交互张量来联合编码注意力机制、前馈网络、激活函数、归一化层和残差连接。

Result: TensorLens在理论上具有一致性，经验验证表明它比之前的注意力聚合方法产生更丰富的表示。实验证明注意力张量可以作为开发可解释性和模型理解工具的强大基础。

Conclusion: TensorLens提供了一个理论上连贯且表达力强的线性表示，能够统一捕捉Transformer的全局计算行为，为可解释性和模型理解研究提供了新基础。

Abstract: Attention matrices are fundamental to transformer research, supporting a broad range of applications including interpretability, visualization, manipulation, and distillation. Yet, most existing analyses focus on individual attention heads or layers, failing to account for the model's global behavior. While prior efforts have extended attention formulations across multiple heads via averaging and matrix multiplications or incorporated components such as normalization and FFNs, a unified and complete representation that encapsulates all transformer blocks is still lacking. We address this gap by introducing TensorLens, a novel formulation that captures the entire transformer as a single, input-dependent linear operator expressed through a high-order attention-interaction tensor. This tensor jointly encodes attention, FFNs, activations, normalizations, and residual connections, offering a theoretically coherent and expressive linear representation of the model's computation. TensorLens is theoretically grounded and our empirical validation shows that it yields richer representations than previous attention-aggregation methods. Our experiments demonstrate that the attention tensor can serve as a powerful foundation for developing tools aimed at interpretability and model understanding. Our code is attached as a supplementary.

</details>


### [123] [Federated learning for unpaired multimodal data through a homogeneous transformer model](https://arxiv.org/abs/2601.17986)
*Anders Eklund*

Main category: cs.LG

TL;DR: 提出联邦多模态学习新框架，能在数据模态分离、无配对样本的分散节点上训练全局多模态Transformer，无需共享原始数据或特征嵌入


<details>
  <summary>Details</summary>
Motivation: 现实联邦环境中数据通常是未配对且分散的，不同节点拥有不同模态数据（如图像和文本），这些数据严格私有且无共同样本。现有联邦学习方法假设本地客户端拥有对齐配对数据或需要共享原始特征嵌入，这违反了数据主权

Method: 1) 引入小型公共锚点集对齐分离的私有流形；2) 使用Gram矩阵通过中心核对齐实现跨模态语义对齐，不传输私有样本；3) 提出子空间稳定微调方法处理大型Transformer；4) 提出精度加权平均，利用不确定性估计降低不确定节点权重

Result: 建立了联邦未配对基础模型的数学基础，使全局模型能从分散、分离和私有数据孤岛中学习统一的世界表示，无需集中存储或配对样本

Conclusion: 该框架为联邦多模态学习提供了数学基础，能够在保护数据隐私的前提下，从分散的未配对多模态数据中训练统一表示模型，解决了现实联邦环境中的数据分离和隐私保护挑战

Abstract: Training of multimodal foundation models is currently restricted to centralized data centers containing massive, aligned datasets (e.g., image-text pairs). However, in realistic federated environments, data is often unpaired and fragmented across disjoint nodes; one node may hold sensor data, while another holds textual logs. These datasets are strictly private and share no common samples. Current federated learning (FL) methods fail in this regime, as they assume local clients possess aligned pairs or require sharing raw feature embeddings, which violates data sovereignty. We propose a novel framework to train a global multimodal transformer across decentralized nodes with disjoint modalities. We introduce a small public anchor set to align disjoint private manifolds. Using Gram matrices calculated from these public anchors, we enforce semantic alignment across modalities through centered kernel alignment without ever transmitting private samples, offering a mathematically superior privacy guarantee compared to prototype sharing. Further, we introduce a subspace-stabilized fine-tuning method to handle FL with huge transformer models. We strictly decouple domain-specific magnitude shifts from semantic direction, ensuring that nodes with varying sensor characteristics align geometrically to the global consensus. Lastly, we propose precision weighted averaging, where efficiently obtained uncertainty estimates are used to downweight uncertain nodes. This paper establishes the mathematical backbone for federated unpaired foundation models, enabling a global model to learn a unified representation of the world from fragmented, disjoint, and private data silos without requiring centralized storage or paired samples.

</details>


### [124] [Systematic Characterization of Minimal Deep Learning Architectures: A Unified Analysis of Convergence, Pruning, and Quantization](https://arxiv.org/abs/2601.17987)
*Ziwei Zheng,Huizhi Liang,Vaclav Snasel,Vito Latora,Panos Pardalos,Giuseppe Nicosia,Varun Ojha*

Main category: cs.LG

TL;DR: 该研究提出了一种系统探索收敛性、剪枝和量化关系的计算方法，发现尽管架构多样，但性能基本不变，学习动态呈现三个阶段，并量化了剪枝冗余和量化影响。


<details>
  <summary>Details</summary>
Motivation: 深度学习网络擅长分类，但确定可靠完成任务的最小架构仍然具有挑战性。需要系统探索收敛性、剪枝和量化之间的关系，为在剪枝和低精度约束下选择紧凑稳定模型提供指导。

Method: 提出计算方法论：首先对大量架构进行结构化设计扫描，然后在代表性模型上评估收敛行为、剪枝敏感性和量化鲁棒性。研究涵盖DNN、CNN和Vision Transformers，针对复杂度递增的图像分类任务。

Result: 发现性能基本不变，学习动态呈现不稳定、学习和过拟合三个阶段；确定了稳定学习所需的最小可学习参数；揭示了不同的收敛和剪枝阶段；量化了降低数值精度对可训练参数的影响。更深架构对剪枝更具弹性（参数冗余高达60%），量化对参数较少的模型影响更大，对更难的数据集影响更显著。

Conclusion: 这些发现为在剪枝和低精度约束下选择紧凑稳定的图像分类模型提供了可操作的指导，证实了架构深度对剪枝弹性的重要性，并量化了量化对不同模型复杂度的不同影响。

Abstract: Deep learning networks excel at classification, yet identifying minimal architectures that reliably solve a task remains challenging. We present a computational methodology for systematically exploring and analyzing the relationships among convergence, pruning, and quantization. The workflow first performs a structured design sweep across a large set of architectures, then evaluates convergence behavior, pruning sensitivity, and quantization robustness on representative models. Focusing on well-known image classification of increasing complexity, and across Deep Neural Networks, Convolutional Neural Networks, and Vision Transformers, our initial results show that, despite architectural diversity, performance is largely invariant and learning dynamics consistently exhibit three regimes: unstable, learning, and overfitting. We further characterize the minimal learnable parameters required for stable learning, uncover distinct convergence and pruning phases, and quantify the effect of reduced numeric precision on trainable parameters. Aligning with intuition, the results confirm that deeper architectures are more resilient to pruning than shallower ones, with parameter redundancy as high as 60%, and quantization impacts models with fewer learnable parameters more severely and has a larger effect on harder image datasets. These findings provide actionable guidance for selecting compact, stable models under pruning and low-precision constraints in image classification.

</details>


### [125] [Coding-Enforced Resilient and Secure Aggregation for Hierarchical Federated Learning](https://arxiv.org/abs/2601.17995)
*Shudi Weng,Ming Xiao,Mikael Skoglund*

Main category: cs.LG

TL;DR: 提出H-SecCoGC方案，通过编码策略实现结构化聚合，在不可靠通信下提升分层联邦学习的鲁棒性、隐私保护和学习效率


<details>
  <summary>Details</summary>
Motivation: 分层联邦学习(HFL)虽然能改善客户端与服务器间的链路质量，但在不可靠通信环境下，如何在保证模型精度的同时保护隐私仍面临挑战，因为隐私噪声的协调可能被随机干扰

Method: 提出鲁棒的分层安全聚合方案H-SecCoGC，集成编码策略来强制执行结构化聚合，避免部分参与问题

Result: 该方案在不同隐私级别下都能确保准确的全局模型构建，显著提高了鲁棒性、隐私保护和学习效率，理论和实验结果均验证了其在不可靠通信和任意强隐私保证下的优越性

Conclusion: H-SecCoGC方案通过编码策略实现了结构化聚合，有效解决了分层联邦学习在不可靠通信环境下的隐私保护与模型精度平衡问题，为实际部署提供了可行方案

Abstract: Hierarchical federated learning (HFL) has emerged as an effective paradigm to enhance link quality between clients and the server. However, ensuring model accuracy while preserving privacy under unreliable communication remains a key challenge in HFL, as the coordination among privacy noise can be randomly disrupted. To address this limitation, we propose a robust hierarchical secure aggregation scheme, termed H-SecCoGC, which integrates coding strategies to enforce structured aggregation. The proposed scheme not only ensures accurate global model construction under varying levels of privacy, but also avoids the partial participation issue, thereby significantly improving robustness, privacy preservation, and learning efficiency. Both theoretical analyses and experimental results demonstrate the superiority of our scheme under unreliable communication across arbitrarily strong privacy guarantees

</details>


### [126] [Spelling Bee Embeddings for Language Modeling](https://arxiv.org/abs/2601.18030)
*Markus N. Rabe,Judith Clymo,Zheren Dong*

Main category: cs.LG

TL;DR: 通过修改嵌入层，将单词拼写信息融入词嵌入，提升模型在拼写和标准基准测试上的表现，相当于减少约8%的计算和数据需求


<details>
  <summary>Details</summary>
Motivation: 传统词嵌入方法可能未充分利用单词的拼写信息，而拼写信息对语言理解有重要作用。通过将拼写信息融入嵌入层，可以提升模型性能

Method: 对嵌入层进行简单修改，将词嵌入与单词拼写信息融合。具体方法是在嵌入层中注入关于单词拼写的特征信息

Result: 使用这种嵌入的模型不仅在拼写任务上表现更好，在标准基准测试上也有提升。对40M到800M参数模型的扩展研究表明，改进效果相当于需要减少约8%的计算和数据来达到相同的测试损失

Conclusion: 将拼写信息融入词嵌入是一种简单有效的改进方法，能显著提升模型性能并减少计算资源需求，为自然语言处理模型设计提供了新思路

Abstract: We introduce a simple modification to the embedding layer. The key change is to infuse token embeddings with information about their spelling. Models trained with these embeddings improve not only on spelling, but also across standard benchmarks. We conduct scaling studies for models with 40M to 800M parameters, which suggest that the improvements are equivalent to needing about 8% less compute and data to achieve the same test loss.

</details>


### [127] [Multimodal Machine Learning for Soft High-k Elastomers under Data Scarcity](https://arxiv.org/abs/2601.18032)
*Brijesh FNU,Viet Thanh Duy Nguyen,Ashima Sharma,Md Harun Rashid Molla,Chengyi Xu,Truong-Son Hy*

Main category: cs.LG

TL;DR: 开发了一个基于多模态学习的框架，利用预训练的聚合物表示来预测介电弹性体的性能，解决了数据稀缺问题


<details>
  <summary>Details</summary>
Motivation: 软电子学快速发展需要高性能介电弹性体，但现有研究缺乏系统数据集，且同时实现高介电常数和低杨氏模量是重大挑战

Method: 收集了10年文献中的丙烯酸酯基介电弹性体数据集，提出多模态学习框架，利用图基和序列基编码器的预训练聚合物表示进行少样本预测

Result: 建立了高质量数据集，开发了能准确预测介电和机械性能的模型，实现了从预训练多模态模型的知识迁移以克服数据稀缺

Conclusion: 该研究为聚合物发现提供了新范式，可推广到其他聚合物骨架，加速高性能介电弹性体的数据高效发现

Abstract: Dielectric materials are critical building blocks for modern electronics such as sensors, actuators, and transistors. With the rapid recent advance in soft and stretchable electronics for emerging human- and robot-interfacing applications, there is a surging need for high-performance dielectric elastomers. However, it remains a grand challenge to develop soft elastomers that simultaneously possess high dielectric constants (k, related to energy storage capacity) and low Young's moduli (E, related to mechanical flexibility). While some new elastomer designs have been reported in individual (mostly one-off) studies, almost no structured dataset is currently available for dielectric elastomers that systematically encompasses their molecular sequence, dielectric, and mechanical properties. Within this context, we curate a compact, high-quality dataset of acrylate-based dielectric elastomers, one of the most widely explored elastomer backbones due to its versatile chemistry and molecular design flexibility, by screening and aggregating experimental results from the literature over the past 10 years. Building on this dataset, we propose a multimodal learning framework that leverages large-scale pretrained polymer representations from graph- and sequence-based encoders. These pretrained embeddings transfer rich chemical and structural knowledge from vast polymer corpora, enabling accurate few-shot prediction of both dielectric and mechanical properties from molecular sequences. Our results represent a new paradigm for transferring knowledge from pretrained multimodal models to overcome severe data scarcity, which can be readily translated to other polymer backbones (e.g., silicones, urethanes) and thus accelerate data-efficient discovery of soft high-k dielectric elastomers. Our source code and dataset are publicly available at https://github.com/HySonLab/Polymers

</details>


### [128] [Resonant Sparse Geometry Networks](https://arxiv.org/abs/2601.18064)
*Hasi Hays*

Main category: cs.LG

TL;DR: RSGN是一种受大脑启发的稀疏几何网络，通过在双曲空间中嵌入计算节点实现输入依赖的动态稀疏连接，相比Transformer具有O(n*k)的计算复杂度，参数效率更高。


<details>
  <summary>Details</summary>
Motivation: Transformer架构使用密集注意力机制，计算复杂度为O(n²)，参数效率低。受大脑稀疏、几何组织计算原理的启发，研究者希望开发更高效、更符合生物学的神经网络架构。

Method: RSGN将计算节点嵌入学习的双曲空间，连接强度随测地距离衰减，实现输入依赖的动态稀疏性。架构采用两种时间尺度：快速可微激活传播（梯度下降优化）和慢速Hebbian启发结构学习（局部相关性规则）。

Result: 在长距离依赖任务上达到96.5%准确率，参数比标准Transformer少约15倍。在20类层次分类任务上达到23.8%准确率（随机基线5%），仅需41,672参数，比需要403,348参数达到30.1%准确率的Transformer少近10倍。

Conclusion: 受大脑启发的稀疏、几何组织计算原理为开发更高效、更符合生物学的神经架构提供了有前景的方向，RSGN在保持性能的同时显著提高了参数效率。

Abstract: We introduce Resonant Sparse Geometry Networks (RSGN), a brain-inspired architecture with self-organizing sparse
  hierarchical input-dependent connectivity. Unlike Transformer architectures that employ dense attention mechanisms with
  O(n^2) computational complexity, RSGN embeds computational nodes in learned hyperbolic space where connection strength
  decays with geodesic distance, achieving dynamic sparsity that adapts to each input. The architecture operates on two
  distinct timescales: fast differentiable activation propagation optimized through gradient descent, and slow
  Hebbian-inspired structural learning for connectivity adaptation through local correlation rules. We provide rigorous
  mathematical analysis demonstrating that RSGN achieves O(n*k) computational complexity, where k << n represents the average
  active neighborhood size. Experimental evaluation on hierarchical classification and long-range dependency tasks
  demonstrates that RSGN achieves 96.5% accuracy on long-range dependency tasks while using approximately 15x fewer
  parameters than standard Transformers. On challenging hierarchical classification with 20 classes, RSGN achieves 23.8%
  accuracy (compared to 5% random baseline) with only 41,672 parameters, nearly 10x fewer than the Transformer baselines
  which require 403,348 parameters to achieve 30.1% accuracy. Our ablation studies confirm the contribution of each architectural
  component, with Hebbian learning providing consistent improvements. These results suggest that brain-inspired principles
  of sparse, geometrically-organized computation offer a promising direction toward more efficient and biologically plausible
  neural architectures.

</details>


### [129] [Comparison requires valid measurement: Rethinking attack success rate comparisons in AI red teaming](https://arxiv.org/abs/2601.18076)
*Alexandra Chouldechova,A. Feder Cooper,Solon Barocas,Abhinav Palia,Dan Vann,Hanna Wallach*

Main category: cs.LG

TL;DR: 论文指出当前AI红队测试中基于攻击成功率(ASR)比较得出的系统安全性或攻击方法有效性结论往往缺乏证据支持，存在苹果与橙子比较和低效度测量问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI安全评估中，研究人员经常通过比较攻击成功率来得出系统相对安全性或攻击方法有效性的结论，但这些结论往往建立在无效的比较基础上，缺乏严谨的测量理论支持。

Method: 采用社会科学测量理论和推断统计学框架，提出攻击成功率有意义的比较条件，并以越狱攻击为例，分析苹果与橙子比较问题和测量效度挑战。

Result: 通过概念、理论和实证分析表明，许多现有研究中的ASR比较存在根本缺陷，无法有效支持关于系统安全性或攻击方法有效性的结论。

Conclusion: 需要建立更严谨的测量框架来评估AI系统安全性，攻击成功率比较只有在满足特定测量条件下才有意义，当前许多红队测试结论需要重新审视。

Abstract: We argue that conclusions drawn about relative system safety or attack method efficacy via AI red teaming are often not supported by evidence provided by attack success rate (ASR) comparisons. We show, through conceptual, theoretical, and empirical contributions, that many conclusions are founded on apples-to-oranges comparisons or low-validity measurements. Our arguments are grounded in asking a simple question: When can attack success rates be meaningfully compared? To answer this question, we draw on ideas from social science measurement theory and inferential statistics, which, taken together, provide a conceptual grounding for understanding when numerical values obtained through the quantification of system attributes can be meaningfully compared. Through this lens, we articulate conditions under which ASRs can and cannot be meaningfully compared. Using jailbreaking as a running example, we provide examples and extensive discussion of apples-to-oranges ASR comparisons and measurement validity challenges.

</details>


### [130] [DRPG (Decompose, Retrieve, Plan, Generate): An Agentic Framework for Academic Rebuttal](https://arxiv.org/abs/2601.18081)
*Peixuan Han,Yingjie Yu,Jingjun Xu,Jiaxuan You*

Main category: cs.LG

TL;DR: DRPG是一个用于自动生成学术反驳的智能体框架，通过分解评审意见、检索论文证据、规划反驳策略和生成回应四个步骤，显著优于现有方法，甚至超越人类平均水平。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在科研工作流中应用日益广泛，但学术反驳这一关键的学术交流和同行评审环节的自动化支持仍然不足。现有方法通常依赖现成的LLM或简单流程，难以处理长上下文理解，且无法生成有针对性和说服力的回应。

Method: DRPG框架包含四个步骤：1）将评审意见分解为原子化问题；2）从论文中检索相关证据；3）规划反驳策略（规划器准确率超过98%）；4）根据策略生成相应回应。该框架使用仅8B参数的模型。

Result: 在顶级会议数据上的实验表明，DRPG显著优于现有反驳流程，使用仅8B模型就达到了超越人类平均水平的性能。规划器设计有效，能提供多视角和可解释的建议，且在更复杂的多轮设置中表现良好。

Conclusion: DRPG框架展示了生成高质量反驳内容和支持学术讨论规模化的潜力，为学术交流自动化提供了有效解决方案。

Abstract: Despite the growing adoption of large language models (LLMs) in scientific research workflows, automated support for academic rebuttal, a crucial step in academic communication and peer review, remains largely underexplored. Existing approaches typically rely on off-the-shelf LLMs or simple pipelines, which struggle with long-context understanding and often fail to produce targeted and persuasive responses. In this paper, we propose DRPG, an agentic framework for automatic academic rebuttal generation that operates through four steps: Decompose reviews into atomic concerns, Retrieve relevant evidence from the paper, Plan rebuttal strategies, and Generate responses accordingly. Notably, the Planner in DRPG reaches over 98% accuracy in identifying the most feasible rebuttal direction. Experiments on data from top-tier conferences demonstrate that DRPG significantly outperforms existing rebuttal pipelines and achieves performance beyond the average human level using only an 8B model. Our analysis further demonstrates the effectiveness of the planner design and its value in providing multi-perspective and explainable suggestions. We also showed that DRPG works well in a more complex multi-round setting. These results highlight the effectiveness of DRPG and its potential to provide high-quality rebuttal content and support the scaling of academic discussions. Codes for this work are available at https://github.com/ulab-uiuc/DRPG-RebuttalAgent.

</details>


### [131] [LatentMoE: Toward Optimal Accuracy per FLOP and Parameter in Mixture of Experts](https://arxiv.org/abs/2601.18089)
*Venmugil Elango,Nidhi Bhatia,Roger Waleffe,Rasoul Shafipour,Tomer Asida,Abhinav Khattar,Nave Assaf,Maximilian Golub,Joey Guman,Tiyasa Mitra,Ritchie Zhao,Ritika Borkar,Ran Zilberstein,Mostofa Patwary,Mohammad Shoeybi,Bita Rouhani*

Main category: cs.LG

TL;DR: 该论文提出LatentMoE架构，通过软硬件协同设计优化混合专家模型，在相同计算量和参数下获得更高精度，已被Nvidia Nemotron-3模型采用。


<details>
  <summary>Details</summary>
Motivation: 现有MoE架构在推理成本和精度效率方面是否达到最优尚不明确，需要从软硬件协同设计角度重新审视MoE设计，以最大化单位计算量的精度。

Method: 采用软硬件协同设计方法，分析不同部署场景下的性能瓶颈，通过系统化设计空间探索（最高95B参数、1T token训练）和理论分析，提出LatentMoE新架构。

Result: LatentMoE在单位FLOP和单位参数精度方面持续优于标准MoE架构，已被Nemotron-3 Super和Ultra模型采用，并扩展到更大规模。

Conclusion: 通过系统化软硬件协同设计可以显著提升MoE架构的效率，LatentMoE为大规模语言模型提供了更优的精度-计算效率平衡。

Abstract: Mixture of Experts (MoEs) have become a central component of many state-of-the-art open-source and proprietary large language models. Despite their widespread adoption, it remains unclear how close existing MoE architectures are to optimal with respect to inference cost, as measured by accuracy per floating-point operation and per parameter. In this work, we revisit MoE design from a hardware-software co-design perspective, grounded in empirical and theoretical considerations. We characterize key performance bottlenecks across diverse deployment regimes, spanning offline high-throughput execution and online, latency-critical inference. Guided by these insights, we introduce LatentMoE, a new model architecture resulting from systematic design exploration and optimized for maximal accuracy per unit of compute. Empirical design space exploration at scales of up to 95B parameters and over a 1T-token training horizon, together with supporting theoretical analysis, shows that LatentMoE consistently outperforms standard MoE architectures in terms of accuracy per FLOP and per parameter. Given its strong performance, the LatentMoE architecture has been adopted by the flagship Nemotron-3 Super and Ultra models and scaled to substantially larger regimes, including longer token horizons and larger model sizes, as reported in Nvidia et al. (arXiv:2512.20856).

</details>


### [132] [From LLMs to LRMs: Rethinking Pruning for Reasoning-Centric Models](https://arxiv.org/abs/2601.18091)
*Longwei Ding,Anhao Zhao,Fanghua Ye,Ziyang Chen,Xiaoyu Shen*

Main category: cs.LG

TL;DR: 该研究对比了指令跟随型LLM和推理增强型LLM的剪枝策略，发现不同范式需要不同的剪枝方法，推理增强模型对剪枝策略更敏感。


<details>
  <summary>Details</summary>
Motivation: 现有剪枝研究主要关注指令跟随型LLM，但推理增强型LLM会生成长中间推理轨迹，不清楚现有剪枝策略是否适用于这类模型。

Method: 对指令跟随型(LLM-instruct)和推理增强型(LLM-think)模型进行对照研究，采用静态深度剪枝、静态宽度剪枝和动态剪枝三种策略，在17个分类、生成和推理任务上评估。

Result: 发现范式依赖的明显差异：深度剪枝在分类任务上表现更好，宽度剪枝在生成和推理任务上更稳健；静态剪枝能更好保持推理性能，动态剪枝在分类和生成上表现优异但对长链推理仍有挑战。

Conclusion: 推理增强型LLM需要专门考虑其特点的剪枝策略，不能简单套用指令跟随型模型的剪枝方法。

Abstract: Large language models (LLMs) are increasingly costly to deploy, motivating extensive research on model pruning. However, most existing studies focus on instruction-following LLMs, leaving it unclear whether established pruning strategies transfer to reasoning-augmented models that explicitly generate long intermediate reasoning traces. In this work, we conduct a controlled study of pruning for both instruction-following ($\textbf{LLM-instruct}$) and reasoning-augmented ($\textbf{LLM-think}$) models. To isolate the effects of pruning, we align pruning calibration and post-pruning recovery data with each model's original training distribution, which we show yields more stable and reliable pruning behavior. We evaluate static depth pruning, static width pruning, and dynamic pruning across 17 tasks spanning classification, generation, and reasoning. Our results reveal clear paradigm-dependent differences: depth pruning outperforms width pruning on classification tasks, while width pruning is more robust for generation and reasoning. Moreover, static pruning better preserves reasoning performance, whereas dynamic pruning excels on classification and generation but remains challenging for long-chain reasoning. These findings underscore the need for pruning strategies that explicitly account for the distinct characteristics of reasoning-augmented LLMs. Our code is publicly available at https://github.com/EIT-NLP/LRM-Pruning.

</details>


### [133] [Beyond Static Datasets: Robust Offline Policy Optimization via Vetted Synthetic Transitions](https://arxiv.org/abs/2601.18107)
*Pedram Agand,Mo Chen*

Main category: cs.LG

TL;DR: MoReBRAC：基于模型的不确定性感知离线强化学习框架，通过双循环世界模型合成高质量转移数据，使用分层不确定性管道确保合成数据可靠性，在D4RL基准上取得显著性能提升


<details>
  <summary>Details</summary>
Motivation: 离线强化学习在工业机器人等安全关键领域有巨大潜力，但面临静态数据集与学习策略之间的分布偏移问题，通常需要高度保守性，限制了策略改进潜力

Method: 提出MoReBRAC框架：1) 使用双循环世界模型合成高保真转移数据扩展训练流形；2) 实施分层不确定性管道，集成VAE流形检测、模型敏感性分析和MC dropout，确保只使用学习动态高置信区域的转移数据

Result: 在D4RL Gym-MuJoCo基准测试中取得显著性能提升，特别是在"随机"和"次优"数据机制下；深入分析了VAE作为几何锚点的作用，并讨论了从近最优数据集中学习时的分布权衡

Conclusion: MoReBRAC通过不确定性感知潜在合成有效解决了离线强化学习中的分布偏移问题，在保持安全性的同时提升了策略性能，为安全关键领域的应用提供了有前景的解决方案

Abstract: Offline Reinforcement Learning (ORL) holds immense promise for safety-critical domains like industrial robotics, where real-time environmental interaction is often prohibitive. A primary obstacle in ORL remains the distributional shift between the static dataset and the learned policy, which typically mandates high degrees of conservatism that can restrain potential policy improvements. We present MoReBRAC, a model-based framework that addresses this limitation through Uncertainty-Aware latent synthesis. Instead of relying solely on the fixed data, MoReBRAC utilizes a dual-recurrent world model to synthesize high-fidelity transitions that augment the training manifold. To ensure the reliability of this synthetic data, we implement a hierarchical uncertainty pipeline integrating Variational Autoencoder (VAE) manifold detection, model sensitivity analysis, and Monte Carlo (MC) dropout. This multi-layered filtering process guarantees that only transitions residing within high-confidence regions of the learned dynamics are utilized. Our results on D4RL Gym-MuJoCo benchmarks reveal significant performance gains, particularly in ``random'' and ``suboptimal'' data regimes. We further provide insights into the role of the VAE as a geometric anchor and discuss the distributional trade-offs encountered when learning from near-optimal datasets.

</details>


### [134] [AttenMIA: LLM Membership Inference Attack through Attention Signals](https://arxiv.org/abs/2601.18110)
*Pedram Zaree,Md Abdullah Al Mamun,Yue Dong,Ihsen Alouani,Nael Abu-Ghazaleh*

Main category: cs.LG

TL;DR: AttenMIA：一种利用Transformer自注意力模式进行成员推理攻击的新框架，通过分析注意力头的模式来识别训练数据成员，在低误报率下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的训练数据记忆化引发了严重的隐私和知识产权问题。现有的成员推理攻击（MIA）主要依赖输出置信度或嵌入特征，但这些信号往往脆弱，攻击成功率有限。需要更有效的攻击方法来揭示LLMs的隐私风险。

Method: 提出AttenMIA框架，利用Transformer模型内部的自注意力模式来推断成员身份。注意力机制控制Transformer内部的信息流，为记忆化暴露了不同的模式。方法收集跨层注意力头的信息，结合基于扰动的散度指标，训练有效的MIA分类器。

Result: 在LLaMA-2、Pythia和Opt等开源模型上的广泛实验表明，基于注意力的特征始终优于基线方法，特别是在重要的低误报率指标下（如在WikiMIA-32基准测试中，使用Llama2-13b达到0.996 ROC AUC和87.9% TPR@1%FPR）。注意力信号在不同数据集和架构上具有泛化性，层和头级分析显示成员信息泄露最明显的位置。在数据提取框架中使用AttenMIA替代其他MIA方法，实现了优于现有技术的训练数据提取攻击。

Conclusion: 注意力机制虽然最初是为了增强可解释性而引入的，但无意中放大了LLMs的隐私风险。AttenMIA揭示了自注意力模式是强大的成员推理信号，强调了开发新防御措施的必要性。

Abstract: Large Language Models (LLMs) are increasingly deployed to enable or improve a multitude of real-world applications. Given the large size of their training data sets, their tendency to memorize training data raises serious privacy and intellectual property concerns. A key threat is the membership inference attack (MIA), which aims to determine whether a given sample was included in the model's training set. Existing MIAs for LLMs rely primarily on output confidence scores or embedding-based features, but these signals are often brittle, leading to limited attack success. We introduce AttenMIA, a new MIA framework that exploits self-attention patterns inside the transformer model to infer membership. Attention controls the information flow within the transformer, exposing different patterns for memorization that can be used to identify members of the dataset. Our method uses information from attention heads across layers and combines them with perturbation-based divergence metrics to train an effective MIA classifier. Using extensive experiments on open-source models including LLaMA-2, Pythia, and Opt models, we show that attention-based features consistently outperform baselines, particularly under the important low-false-positive metric (e.g., achieving up to 0.996 ROC AUC & 87.9% TPR@1%FPR on the WikiMIA-32 benchmark with Llama2-13b). We show that attention signals generalize across datasets and architectures, and provide a layer- and head-level analysis of where membership leakage is most pronounced. We also show that using AttenMIA to replace other membership inference attacks in a data extraction framework results in training data extraction attacks that outperform the state of the art. Our findings reveal that attention mechanisms, originally introduced to enhance interpretability, can inadvertently amplify privacy risks in LLMs, underscoring the need for new defenses.

</details>


### [135] [Demystifying Data-Driven Probabilistic Medium-Range Weather Forecasting](https://arxiv.org/abs/2601.18111)
*Jean Kossaifi,Nikola Kovachki,Morteza Mardani,Daniel Leibovici,Suman Ravuri,Ira Shokar,Edoardo Calvello,Mohammad Shoaib Abbas,Peter Harrington,Ashay Subramaniam,Noah Brenowitz,Boris Bonev,Wonmin Byeon,Karsten Kreis,Dale Durran,Arash Vahdat,Mike Pritchard,Jan Kautz*

Main category: cs.LG

TL;DR: 论文提出一个可扩展的多尺度大气动力学学习框架，通过下采样潜在空间和历史条件局部投影器实现高分辨率物理模拟，无需复杂架构或专门训练策略即可达到最先进的概率预测性能。


<details>
  <summary>Details</summary>
Motivation: 当前数据驱动的天气预报方法存在架构复杂、训练策略碎片化的问题，这掩盖了预测准确性的根本驱动因素。作者旨在证明最先进的概率预测技能并不需要复杂的架构约束或专门的训练启发式方法。

Method: 引入一个可扩展的多尺度大气动力学学习框架，结合直接下采样的潜在空间和历史条件局部投影器来解析高分辨率物理。该框架设计对概率估计器的选择具有鲁棒性，支持随机插值、扩散模型和基于CRPS的集成训练。

Result: 与集成预报系统和深度学习概率模型GenCast相比，该框架在大多数变量上实现了统计上显著的改进，表明通用模型的扩展足以实现最先进的中期预测。

Conclusion: 扩展通用模型足以实现最先进的中期预测，无需定制训练方案，且在全谱概率框架中都有效，简化了天气预报的深度学习应用。

Abstract: The recent revolution in data-driven methods for weather forecasting has lead to a fragmented landscape of complex, bespoke architectures and training strategies, obscuring the fundamental drivers of forecast accuracy. Here, we demonstrate that state-of-the-art probabilistic skill requires neither intricate architectural constraints nor specialized training heuristics. We introduce a scalable framework for learning multi-scale atmospheric dynamics by combining a directly downsampled latent space with a history-conditioned local projector that resolves high-resolution physics. We find that our framework design is robust to the choice of probabilistic estimator, seamlessly supporting stochastic interpolants, diffusion models, and CRPS-based ensemble training. Validated against the Integrated Forecasting System and the deep learning probabilistic model GenCast, our framework achieves statistically significant improvements on most of the variables. These results suggest scaling a general-purpose model is sufficient for state-of-the-art medium-range prediction, eliminating the need for tailored training recipes and proving effective across the full spectrum of probabilistic frameworks.

</details>


### [136] [Robust Learning of a Group DRO Neuron](https://arxiv.org/abs/2601.18115)
*Guyang Cao,Shuyao Li,Sushrut Karmalkar,Jelena Diakonikolas*

Main category: cs.LG

TL;DR: 该论文研究在存在任意标签噪声和组级分布偏移的情况下，学习单个神经元的群体分布鲁棒优化问题，提出了一种计算高效的原始-对偶算法，能在最坏情况组权重下获得常数倍竞争性的解。


<details>
  <summary>Details</summary>
Motivation: 研究在现实场景中，数据通常来自不同分布（如不同用户群体、不同数据源），且存在标签噪声。传统方法假设数据独立同分布，无法处理这种群体分布偏移和噪声问题，需要开发能够应对最坏情况组权重的鲁棒学习方法。

Method: 提出群体分布鲁棒优化框架：给定K个不同分布的样本访问，寻找参数w*最小化最坏情况目标函数。目标函数包含：1) 各组的平方损失加权和；2) f-散度惩罚项（可选），用于控制组权重偏离均匀分布的程度。开发了计算高效的原始-对偶算法，通过双重外推更新处理损失函数的非凸性。

Result: 算法输出参数ŵ，在最坏情况组权重下与最优参数w*保持常数倍竞争性。该框架能处理任意标签噪声和组特定分布偏移，算法在LLM预训练基准测试中显示出良好前景。

Conclusion: 该研究为在存在群体分布偏移和标签噪声的环境下学习单个神经元提供了鲁棒的理论保证和实用算法，原始-对偶框架能有效处理非凸损失函数，为更复杂的神经网络鲁棒学习奠定了基础。

Abstract: We study the problem of learning a single neuron under standard squared loss in the presence of arbitrary label noise and group-level distributional shifts, for a broad family of covariate distributions. Our goal is to identify a ''best-fit'' neuron parameterized by $\mathbf{w}_*$ that performs well under the most challenging reweighting of the groups. Specifically, we address a Group Distributionally Robust Optimization problem: given sample access to $K$ distinct distributions $\mathcal p_{[1]},\dots,\mathcal p_{[K]}$, we seek to approximate $\mathbf{w}_*$ that minimizes the worst-case objective over convex combinations of group distributions $\boldsymbolλ \in Δ_K$, where the objective is $\sum_{i \in [K]}λ_{[i]}\,\mathbb E_{(\mathbf x,y)\sim\mathcal p_{[i]}}(σ(\mathbf w\cdot\mathbf x)-y)^2 - νd_f(\boldsymbolλ,\frac{1}{K}\mathbf1)$ and $d_f$ is an $f$-divergence that imposes (optional) penalty on deviations from uniform group weights, scaled by a parameter $ν\geq 0$. We develop a computationally efficient primal-dual algorithm that outputs a vector $\widehat{\mathbf w}$ that is constant-factor competitive with $\mathbf{w}_*$ under the worst-case group weighting. Our analytical framework directly confronts the inherent nonconvexity of the loss function, providing robust learning guarantees in the face of arbitrary label corruptions and group-specific distributional shifts. The implementation of the dual extrapolation update motivated by our algorithmic framework shows promise on LLM pre-training benchmarks.

</details>


### [137] [Enhance the Safety in Reinforcement Learning by ADRC Lagrangian Methods](https://arxiv.org/abs/2601.18142)
*Mingxu Zhang,Huicheng Zhang,Jiaming Ji,Yaodong Yang,Ying Sun*

Main category: cs.LG

TL;DR: 提出ADRC-Lagrangian方法，利用主动抗扰控制增强鲁棒性，减少振荡，在安全强化学习中显著降低安全违规


<details>
  <summary>Details</summary>
Motivation: 现有安全强化学习方法（包括PID和经典Lagrangian方法）存在振荡和频繁安全违规问题，主要由于参数敏感性和固有的相位滞后

Method: 提出ADRC-Lagrangian方法，将主动抗扰控制（ADRC）集成到安全强化学习框架中，增强鲁棒性和减少振荡，统一框架包含经典和PID Lagrangian方法作为特例

Result: 实验表明，该方法将安全违规减少74%，约束违规幅度降低89%，平均成本降低67%，在复杂环境中表现出优越的安全性能

Conclusion: ADRC-Lagrangian方法通过主动抗扰控制有效解决了现有安全强化学习方法的振荡和安全违规问题，为复杂环境中的安全强化学习提供了更有效的解决方案

Abstract: Safe reinforcement learning (Safe RL) seeks to maximize rewards while satisfying safety constraints, typically addressed through Lagrangian-based methods. However, existing approaches, including PID and classical Lagrangian methods, suffer from oscillations and frequent safety violations due to parameter sensitivity and inherent phase lag. To address these limitations, we propose ADRC-Lagrangian methods that leverage Active Disturbance Rejection Control (ADRC) for enhanced robustness and reduced oscillations. Our unified framework encompasses classical and PID Lagrangian methods as special cases while significantly improving safety performance. Extensive experiments demonstrate that our approach reduces safety violations by up to 74%, constraint violation magnitudes by 89%, and average costs by 67\%, establishing superior effectiveness for Safe RL in complex environments.

</details>


### [138] [FP8-RL: A Practical and Stable Low-Precision Stack for LLM Reinforcement Learning](https://arxiv.org/abs/2601.18150)
*Zhaopeng Qiu,Shuang Yu,Jingqi Zhang,Shuai Zhang,Xue Huang,Jingyi Yang,Junjie Lai*

Main category: cs.LG

TL;DR: 提出了一个用于大语言模型强化学习的FP8推理栈，通过W8A8线性层量化、KV缓存FP8化和重要性采样校正，实现高达44%的推理吞吐提升，同时保持与BF16基线相当的学习效果。


<details>
  <summary>Details</summary>
Motivation: 大语言模型强化学习中的推理（生成）阶段成为瓶颈，长输出序列使注意力机制和KV缓存内存占据主要时间。FP8量化可加速推理，但面临权重频繁变化和训练-推理精度不匹配的挑战。

Method: 1) 使用分块FP8量化实现W8A8线性层推理；2) 通过每步QKV尺度重校准将FP8扩展到KV缓存；3) 采用基于重要性采样的推理校正（token级TIS/MIS变体）缓解精度不匹配。

Result: 在密集和MoE模型上，该技术实现了高达44%的推理吞吐提升，同时学习行为与BF16基线相当，有效解决了FP8在RL应用中的工程和算法挑战。

Conclusion: 提出了一个实用的FP8推理栈，解决了RL中FP8量化的独特挑战，显著加速大语言模型强化学习推理，为高效RL训练提供了可行的解决方案。

Abstract: Reinforcement learning (RL) for large language models (LLMs) is increasingly bottlenecked by rollout (generation), where long output sequence lengths make attention and KV-cache memory dominate end-to-end step time. FP8 offers an attractive lever for accelerating RL by reducing compute cost and memory traffic during rollout, but applying FP8 in RL introduces unique engineering and algorithmic challenges: policy weights change every step (requiring repeated quantization and weight synchronization into the inference engine) and low-precision rollouts can deviate from the higher-precision policy assumed by the trainer, causing train-inference mismatch and potential instability. This report presents a practical FP8 rollout stack for LLM RL, implemented in the veRL ecosystem with support for common training backends (e.g., FSDP/Megatron-LM) and inference engines (e.g., vLLM/SGLang). We (i) enable FP8 W8A8 linear-layer rollout using blockwise FP8 quantization, (ii) extend FP8 to KV-cache to remove long-context memory bottlenecks via per-step QKV scale recalibration, and (iii) mitigate mismatch using importance-sampling-based rollout correction (token-level TIS/MIS variants). Across dense and MoE models, these techniques deliver up to 44% rollout throughput gains while preserving learning behavior comparable to BF16 baselines.

</details>


### [139] [Learning Fair Domain Adaptation with Virtual Label Distribution](https://arxiv.org/abs/2601.18171)
*Yuguang Zhang,Lijun Sheng,Jian Liang,Ran He*

Main category: cs.LG

TL;DR: 提出VILL框架解决无监督域自适应中的类别公平性问题，通过自适应重加权和KL散度再平衡策略提升困难类别的性能，同时保持整体准确率。


<details>
  <summary>Details</summary>
Motivation: 现有无监督域自适应方法主要关注整体准确率提升，但忽视了不同类别间的性能差异（类别公平性问题）。实证分析发现UDA分类器倾向于偏好容易类别而忽略困难类别。

Method: 提出VILL（虚拟标签分布感知学习）框架：1）自适应重加权策略，放大难以分类类别的影响；2）基于KL散度的再平衡策略，显式调整决策边界以增强类别公平性。

Result: 在常用数据集上的实验表明，VILL可以作为即插即用模块无缝集成到现有UDA方法中，显著提升类别公平性。

Conclusion: VILL是一个简单有效的框架，能够改善最坏情况性能，同时保持高整体准确率，解决了UDA中的类别公平性问题。

Abstract: Unsupervised Domain Adaptation (UDA) aims to mitigate performance degradation when training and testing data are sampled from different distributions. While significant progress has been made in enhancing overall accuracy, most existing methods overlook performance disparities across categories-an issue we refer to as category fairness. Our empirical analysis reveals that UDA classifiers tend to favor certain easy categories while neglecting difficult ones. To address this, we propose Virtual Label-distribution-aware Learning (VILL), a simple yet effective framework designed to improve worst-case performance while preserving high overall accuracy. The core of VILL is an adaptive re-weighting strategy that amplifies the influence of hard-to-classify categories. Furthermore, we introduce a KL-divergence-based re-balancing strategy, which explicitly adjusts decision boundaries to enhance category fairness. Experiments on commonly used datasets demonstrate that VILL can be seamlessly integrated as a plug-and-play module into existing UDA methods, significantly improving category fairness.

</details>


### [140] [Smooth, Sparse, and Stable: Finite-Time Exact Skeleton Recovery via Smoothed Proximal Gradients](https://arxiv.org/abs/2601.18189)
*Rui Wu,Yongjun Li*

Main category: cs.LG

TL;DR: 提出AHOC混合阶无环约束和SPG-AHOC算法，通过有限时间Oracle性质理论保证在有限迭代内精确恢复DAG结构，无需启发式截断。


<details>
  <summary>Details</summary>
Motivation: 现有连续优化方法（如NOTEARS）只能保证渐近收敛到驻点，通常产生稠密权重矩阵，需要任意后处理阈值化来恢复DAG。连续优化与离散图结构之间的差距是根本挑战。

Method: 提出混合阶无环约束（AHOC），通过平滑近端梯度法（SPG-AHOC）优化。利用近端算法的流形识别特性，提供有限时间Oracle性质的理论保证。

Result: 在标准可识别性假设下，SPG-AHOC在有限迭代内精确恢复DAG支持（结构），即使优化平滑近似。算法返回具有精确零条目的图，无需启发式截断。实证显示达到最先进精度并强有力支持有限时间识别理论。

Conclusion: SPG-AHOC填补了连续优化与离散图结构之间的差距，通过有限时间Oracle性质理论保证精确结构恢复，无需后处理阈值化，为因果发现提供了更可靠的解决方案。

Abstract: Continuous optimization has significantly advanced causal discovery, yet existing methods (e.g., NOTEARS) generally guarantee only asymptotic convergence to a stationary point. This often yields dense weighted matrices that require arbitrary post-hoc thresholding to recover a DAG. This gap between continuous optimization and discrete graph structures remains a fundamental challenge. In this paper, we bridge this gap by proposing the Hybrid-Order Acyclicity Constraint (AHOC) and optimizing it via the Smoothed Proximal Gradient (SPG-AHOC). Leveraging the Manifold Identification Property of proximal algorithms, we provide a rigorous theoretical guarantee: the Finite-Time Oracle Property. We prove that under standard identifiability assumptions, SPG-AHOC recovers the exact DAG support (structure) in finite iterations, even when optimizing a smoothed approximation. This result eliminates structural ambiguity, as our algorithm returns graphs with exact zero entries without heuristic truncation. Empirically, SPG-AHOC achieves state-of-the-art accuracy and strongly corroborates the finite-time identification theory.

</details>


### [141] [HeterCSI: Channel-Adaptive Heterogeneous CSI Pretraining Framework for Generalized Wireless Foundation Models](https://arxiv.org/abs/2601.18200)
*Chenyu Zhang,Xinchen Lyu,Chenshan Ren,Shuhan Liu,Qimei Cui,Xiaofeng Tao*

Main category: cs.LG

TL;DR: HeterCSI是一个通道自适应预训练框架，通过优化梯度动态和批次构建来解决CSI数据在规模和场景维度上的双重异质性，实现了高效的训练和强大的跨场景泛化能力。


<details>
  <summary>Details</summary>
Motivation: 无线基础模型在处理6G网络中的信道状态信息时面临双重异质性挑战：CSI数据在规模（维度）和场景（应用）上都存在显著差异。现有预训练方法要么限制输入为固定维度，要么按规模隔离训练，限制了模型的泛化能力和可扩展性。

Method: 提出HeterCSI框架，核心包括：1）揭示梯度动态规律：CSI规模异质性主要导致破坏性梯度干扰，而场景多样性在适当管理下可促进建设性梯度对齐；2）将异质CSI批次构建形式化为分区优化问题，最小化零填充开销同时保持场景多样性；3）开发尺度感知自适应批处理策略，对齐相似尺度的CSI样本；4）设计双重掩码机制，从填充伪影中隔离有效信号。

Result: 在12个数据集上的实验表明：1）无需场景特定微调即可建立通用基础模型，性能优于全样本基线；2）相比最先进的零样本基准WiFo，在CSI重建、时域预测和频域预测上分别降低NMSE 7.19 dB、4.08 dB和5.27 dB；3）训练延迟降低53%，泛化性能平均提升1.53 dB。

Conclusion: HeterCSI通过深入理解异质CSI预训练中的梯度动态，提出创新的批次构建和掩码机制，成功解决了CSI数据的双重异质性挑战，在训练效率和跨场景泛化能力方面取得了显著突破，为无线基础模型的发展提供了有效解决方案。

Abstract: Wireless foundation models promise transformative capabilities for channel state information (CSI) processing across diverse 6G network applications, yet face fundamental challenges due to the inherent dual heterogeneity of CSI across both scale and scenario dimensions. However, current pretraining approaches either constrain inputs to fixed dimensions or isolate training by scale, limiting the generalization and scalability of wireless foundation models. In this paper, we propose HeterCSI, a channel-adaptive pretraining framework that reconciles training efficiency with robust cross-scenario generalization via a new understanding of gradient dynamics in heterogeneous CSI pretraining. Our key insight reveals that CSI scale heterogeneity primarily causes destructive gradient interference, while scenario diversity actually promotes constructive gradient alignment when properly managed. Specifically, we formulate heterogeneous CSI batch construction as a partitioning optimization problem that minimizes zero-padding overhead while preserving scenario diversity. To solve this, we develop a scale-aware adaptive batching strategy that aligns CSI samples of similar scales, and design a double-masking mechanism to isolate valid signals from padding artifacts. Extensive experiments on 12 datasets demonstrate that HeterCSI establishes a generalized foundation model without scenario-specific finetuning, achieving superior average performance over full-shot baselines. Compared to the state-of-the-art zero-shot benchmark WiFo, it reduces NMSE by 7.19 dB, 4.08 dB, and 5.27 dB for CSI reconstruction, time-domain, and frequency-domain prediction, respectively. The proposed HeterCSI framework also reduces training latency by 53% compared to existing approaches while improving generalization performance by 1.53 dB on average.

</details>


### [142] [PaperSearchQA: Learning to Search and Reason over Scientific Papers with RLVR](https://arxiv.org/abs/2601.18207)
*James Burgess,Jan N. Hansen,Duo Peng,Yuhui Zhang,Alejandro Lozano,Min Woo Sun,Emma Lundberg,Serena Yeung-Levy*

Main category: cs.LG

TL;DR: 该研究提出了一种在生物医学论文摘要语料库上训练搜索代理的方法，创建了PaperSearchQA数据集和基准，通过RLVR训练使代理在技术问答任务上超越传统检索基线。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR搜索代理主要针对通用领域QA，限制了其在科学、工程和医学等专业技术AI系统中的适用性。该研究旨在训练代理在科学论文中进行搜索和推理，这对技术问答测试、实际科学家应用以及未来AI科学家系统都至关重要。

Method: 1) 发布包含1600万篇生物医学论文摘要的搜索语料库；2) 构建包含6万个样本的PaperSearchQA事实问答数据集；3) 在该环境中训练搜索代理，使用RLVR（强化学习与可验证奖励）方法；4) 基于Search-R1代码库进行训练和评估。

Result: 训练的搜索代理在技术问答任务上超越了非RL检索基线，展现出规划、推理和自我验证等有趣的行为。研究还提供了定量分析和基准测试结果。

Conclusion: 该方法成功地将RLVR搜索代理扩展到科学领域，创建了可用的语料库、数据集和基准，且数据创建方法具有可扩展性，可轻松扩展到其他科学领域。

Abstract: Search agents are language models (LMs) that reason and search knowledge bases (or the web) to answer questions; recent methods supervise only the final answer accuracy using reinforcement learning with verifiable rewards (RLVR). Most RLVR search agents tackle general-domain QA, which limits their relevance to technical AI systems in science, engineering, and medicine. In this work we propose training agents to search and reason over scientific papers -- this tests technical question-answering, it is directly relevant to real scientists, and the capabilities will be crucial to future AI Scientist systems. Concretely, we release a search corpus of 16 million biomedical paper abstracts and construct a challenging factoid QA dataset called PaperSearchQA with 60k samples answerable from the corpus, along with benchmarks. We train search agents in this environment to outperform non-RL retrieval baselines; we also perform further quantitative analysis and observe interesting agent behaviors like planning, reasoning, and self-verification. Our corpus, datasets, and benchmarks are usable with the popular Search-R1 codebase for RLVR training and released on https://huggingface.co/collections/jmhb/papersearchqa. Finally, our data creation methods are scalable and easily extendable to other scientific domains.

</details>


### [143] [Rethinking Cross-Modal Fine-Tuning: Optimizing the Interaction between Feature Alignment and Target Fitting](https://arxiv.org/abs/2601.18231)
*Trong Khiem Tran,Manh Cuong Dao,Phi Le Nguyen,Thao Nguyen Truong,Trong Nghia Hoang*

Main category: cs.LG

TL;DR: 提出理论框架分析特征对齐与目标微调间的相互作用，通过特征标签失真概念建立可证明的泛化边界，指导算法设计并显著提升性能


<details>
  <summary>Details</summary>
Motivation: 预训练模型适应新特征模态的需求日益增长，但现有方法缺乏对特征对齐与目标微调相互作用的理论理解，未校准的组合会加剧源-目标特征标签结构错配，降低目标泛化能力

Method: 建立理论框架，通过特征标签失真概念推导可证明的目标误差泛化边界，该边界揭示了特征对齐与目标拟合的相互作用机制，为算法设计提供可操作的优化指导

Result: 在广泛的基准数据集上，基于该框架的方法显著优于现有最先进方法

Conclusion: 提出的理论框架填补了特征对齐与目标微调相互作用的理论空白，通过特征标签失真概念建立的泛化边界为跨模态知识迁移提供了有效的算法设计指导

Abstract: Adapting pre-trained models to unseen feature modalities has become increasingly important due to the growing need for cross-disciplinary knowledge integration.~A key challenge here is how to align the representation of new modalities with the most relevant parts of the pre-trained model's representation space to enable accurate knowledge transfer.~This requires combining feature alignment with target fine-tuning, but uncalibrated combinations can exacerbate misalignment between the source and target feature-label structures and reduce target generalization.~Existing work however lacks a theoretical understanding of this critical interaction between feature alignment and target fitting.~To bridge this gap, we develop a principled framework that establishes a provable generalization bound on the target error, which explains the interaction between feature alignment and target fitting through a novel concept of feature-label distortion.~This bound offers actionable insights into how this interaction should be optimized for practical algorithm design. The resulting approach achieves significantly improved performance over state-of-the-art methods across a wide range of benchmark datasets.

</details>


### [144] [Tractable Gaussian Phase Retrieval with Heavy Tails and Adversarial Corruption with Near-Linear Sample Complexity](https://arxiv.org/abs/2601.18245)
*Santanu Das,Jatin Batra*

Main category: cs.LG

TL;DR: 提出了首个多项式时间算法，用于解决具有重尾噪声和对抗性损坏的鲁棒相位恢复问题，实现了近线性的样本复杂度。


<details>
  <summary>Details</summary>
Motivation: 相位恢复在光学、晶体学等领域有广泛应用，但现有算法对测量误差的鲁棒性不足。最近在鲁棒统计算法方面的突破为均值估计、协方差估计等任务提供了高效算法，但鲁棒相位恢复问题仍缺乏多项式时间算法。

Method: 通过建立鲁棒谱初始化与鲁棒主成分分析（PCA）之间的联系，利用鲁棒PCA的最新算法进展，实现了高效的鲁棒谱初始化，从而开发出多项式时间的鲁棒相位恢复算法。

Result: 提出了首个多项式时间算法，能够在存在重尾噪声和对抗性损坏（部分测量值和传感向量可能被任意破坏）的情况下进行鲁棒相位恢复，样本复杂度达到近线性（O(n log n)）。

Conclusion: 通过连接鲁棒谱初始化和鲁棒PCA，成功解决了鲁棒相位恢复中的计算效率瓶颈，为实际应用中的鲁棒相位恢复提供了可行的多项式时间解决方案。

Abstract: Phase retrieval is the classical problem of recovering a signal $x^* \in \mathbb{R}^n$ from its noisy phaseless measurements $y_i = \langle a_i, x^* \rangle^2 + ζ_i$ (where $ζ_i$ denotes noise, and $a_i$ is the sensing vector) for $i \in [m]$. The problem of phase retrieval has a rich history, with a variety of applications such as optics, crystallography, heteroscedastic regression, astrophysics, etc. A major consideration in algorithms for phase retrieval is robustness against measurement errors. In recent breakthroughs in algorithmic robust statistics, efficient algorithms have been developed for several parameter estimation tasks such as mean estimation, covariance estimation, robust principal component analysis (PCA), etc. in the presence of heavy-tailed noise and adversarial corruptions. In this paper, we study efficient algorithms for robust phase retrieval with heavy-tailed noise when a constant fraction of both the measurements $y_i$ and the sensing vectors $a_i$ may be arbitrarily adversarially corrupted. For this problem, Buna and Rebeschini (AISTATS 2025) very recently gave an exponential time algorithm with sample complexity $O(n \log n)$. Their algorithm needs a robust spectral initialization, specifically, a robust estimate of the top eigenvector of a covariance matrix, which they deemed to be beyond known efficient algorithmic techniques (similar spectral initializations are a key ingredient of a large family of phase retrieval algorithms). In this work, we make a connection between robust spectral initialization and recent algorithmic advances in robust PCA, yielding the first polynomial-time algorithms for robust phase retrieval with both heavy-tailed noise and adversarial corruptions, in fact with near-linear (in $n$) sample complexity.

</details>


### [145] [Beyond Retention: Orchestrating Structural Safety and Plasticity in Continual Learning for LLMs](https://arxiv.org/abs/2601.18255)
*Fei Meng*

Main category: cs.LG

TL;DR: 本文发现经验回放在大语言模型持续学习中存在矛盾：对非结构化任务有正向迁移，但对结构化任务（如代码生成）造成负向迁移。作者提出正交子空间唤醒方法来解决这一困境。


<details>
  <summary>Details</summary>
Motivation: 大语言模型持续学习面临平衡稳定性（保留旧知识）和可塑性（学习新任务）的挑战。经验回放作为标准方法，其在不同能力上的影响尚未充分探索，特别是对结构化领域的影响。

Method: 提出正交子空间唤醒方法：通过简短的"唤醒"阶段识别先前任务的关键参数子空间，并对新任务强制执行正交更新，为已建立的知识结构提供数学基础的"安全保证"。

Result: 在多样化的四任务序列实验中，OSW方法在经验回放失败的脆弱编码能力保护方面表现出色，同时保持对新任务的高可塑性。经验回放导致代码生成准确率显著下降。

Conclusion: 研究强调在LLM持续学习中需要同时评估结构安全性和平均保留率。OSW方法为解决经验回放在结构化领域的负向迁移问题提供了有效解决方案。

Abstract: Continual learning in Large Language Models (LLMs) faces the critical challenge of balancing stability (retaining old knowledge) and plasticity (learning new tasks). While Experience Replay (ER) is a standard countermeasure against catastrophic forgetting, its impact across diverse capabilities remains underexplored. In this work, we uncover a critical dichotomy in ER's behavior: while it induces positive backward transfer on robust, unstructured tasks (e.g., boosting performance on previous NLP classification tasks through repeated rehearsal), it causes severe negative transfer on fragile, structured domains like code generation (e.g., a significant relative drop in coding accuracy). This reveals that ER trades structural integrity for broad consolidation. To address this dilemma, we propose \textbf{Orthogonal Subspace Wake-up (OSW)}. OSW identifies essential parameter subspaces of previous tasks via a brief "wake-up" phase and enforces orthogonal updates for new tasks, providing a mathematically grounded "safety guarantee" for established knowledge structures. Empirical results across a diverse four-task sequence demonstrate that OSW uniquely succeeds in preserving fragile coding abilities where Replay fails, while simultaneously maintaining high plasticity for novel tasks. Our findings emphasize the necessity of evaluating structural safety alongside average retention in LLM continual learning.

</details>


### [146] [FGGM: Fisher-Guided Gradient Masking for Continual Learning](https://arxiv.org/abs/2601.18261)
*Chao-Hong Tan,Qian Chen,Wen Wang,Yukun Ma,Chong Zhang,Chong Deng,Qinglin Zhang,Xiangang Li,Jieping Ye*

Main category: cs.LG

TL;DR: 提出FGGM框架，通过Fisher信息动态选择参数更新，缓解大语言模型持续学习中的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在持续学习中面临灾难性遗忘问题，现有方法如MIGU基于参数幅度选择，缺乏数学原理基础，需要更有效的参数重要性估计方法。

Method: 提出Fisher引导的梯度掩码(FGGM)，使用对角Fisher信息战略性地选择参数进行更新，动态生成具有自适应阈值的二进制掩码，保留关键参数以平衡稳定性和可塑性，无需历史数据。

Result: 在TRACE基准测试中，FGGM相比监督微调(SFT)在保留通用能力方面相对提升9.6%，相比MIGU在TRACE任务上提升4.4%。代码生成任务的额外分析证实了FGGM的优越性能和减少的遗忘。

Conclusion: FGGM通过数学原理的参数重要性估计，有效缓解灾难性遗忘，在保持通用能力和任务性能方面优于现有方法，是持续学习的有效解决方案。

Abstract: Catastrophic forgetting impairs the continuous learning of large language models. We propose Fisher-Guided Gradient Masking (FGGM), a framework that mitigates this by strategically selecting parameters for updates using diagonal Fisher Information. FGGM dynamically generates binary masks with adaptive thresholds, preserving critical parameters to balance stability and plasticity without requiring historical data. Unlike magnitude-based methods such as MIGU, our approach offers a mathematically principled parameter importance estimation. On the TRACE benchmark, FGGM shows a 9.6% relative improvement in retaining general capabilities over supervised fine-tuning (SFT) and a 4.4% improvement over MIGU on TRACE tasks. Additional analysis on code generation tasks confirms FGGM's superior performance and reduced forgetting, establishing it as an effective solution.

</details>


### [147] [Neural Network Approximation: A View from Polytope Decomposition](https://arxiv.org/abs/2601.18264)
*ZeYu Li,ShiJun Zhang,TieYong Zeng,FengLei Fan*

Main category: cs.LG

TL;DR: 该论文提出了一种基于多面体分解的ReLU网络通用逼近理论，相比传统均匀划分方法能更好地处理目标函数的局部正则性，特别是在奇异点附近表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有通用逼近理论大多通过均匀划分输入空间来构建神经网络，忽略了目标函数的局部正则性。作者希望从多面体分解的角度研究ReLU网络的通用逼近能力，提供更贴近实际任务需求的方法。

Method: 1. 开发显式核多项式方法推导连续函数的通用逼近，结合精细的Totik-Ditzian型连续模和多面体域分解；2. 在每个子域中分别构建ReLU网络来逼近核多项式；3. 将方法扩展到解析函数以获得更高的逼近速率。

Result: 多面体分解使逼近在许多情况下比现有方法更高效灵活，特别是在目标函数的奇异点附近。该方法能够更好地处理函数的局部特性，并扩展到解析函数时能达到更高的逼近速率。

Conclusion: 基于多面体分解的ReLU网络通用逼近理论提供了更现实和任务导向的方法，能够更好地处理目标函数的局部正则性，特别是在奇异点附近，为神经网络的理论分析和实际应用提供了新视角。

Abstract: Universal approximation theory offers a foundational framework to verify neural network expressiveness, enabling principled utilization in real-world applications. However, most existing theoretical constructions are established by uniformly dividing the input space into tiny hypercubes without considering the local regularity of the target function. In this work, we investigate the universal approximation capabilities of ReLU networks from a view of polytope decomposition, which offers a more realistic and task-oriented approach compared to current methods. To achieve this, we develop an explicit kernel polynomial method to derive an universal approximation of continuous functions, which is characterized not only by the refined Totik-Ditzian-type modulus of continuity, but also by polytopical domain decomposition. Then, a ReLU network is constructed to approximate the kernel polynomial in each subdomain separately. Furthermore, we find that polytope decomposition makes our approximation more efficient and flexible than existing methods in many cases, especially near singular points of the objective function. Lastly, we extend our approach to analytic functions to reach a higher approximation rate.

</details>


### [148] [What Do Learned Models Measure?](https://arxiv.org/abs/2601.18278)
*Indrė Žliobaitė*

Main category: cs.LG

TL;DR: 论文指出机器学习模型作为测量工具使用时，标准评估指标（如泛化误差、校准度、鲁棒性）无法保证测量稳定性，需要新的评估维度。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型越来越多地被用作测量工具而非预测工具，但标准评估框架无法确保不同模型实现相同测量功能，存在测量不稳定性问题。

Method: 提出测量稳定性概念，形式化定义测量函数，分析标准评估标准的局限性，并通过真实案例研究展示问题。

Result: 预测性能相当的模型可能实现系统性的不等价测量函数，分布偏移会加剧这一问题，标准评估标准无法保证测量稳定性。

Conclusion: 当模型输出被识别为测量值时，现有评估框架存在局限性，需要增加测量稳定性这一新的评估维度。

Abstract: In many scientific and data-driven applications, machine learning models are increasingly used as measurement instruments, rather than merely as predictors of predefined labels. When the measurement function is learned from data, the mapping from observations to quantities is determined implicitly by the training distribution and inductive biases, allowing multiple inequivalent mappings to satisfy standard predictive evaluation criteria. We formalize learned measurement functions as a distinct focus of evaluation and introduce measurement stability, a property capturing invariance of the measured quantity across admissible realizations of the learning process and across contexts. We show that standard evaluation criteria in machine learning, including generalization error, calibration, and robustness, do not guarantee measurement stability. Through a real-world case study, we show that models with comparable predictive performance can implement systematically inequivalent measurement functions, with distribution shift providing a concrete illustration of this failure. Taken together, our results highlight a limitation of existing evaluation frameworks in settings where learned model outputs are identified as measurements, motivating the need for an additional evaluative dimension.

</details>


### [149] [TriPlay-RL: Tri-Role Self-Play Reinforcement Learning for LLM Safety Alignment](https://arxiv.org/abs/2601.18292)
*Zhewen Tan,Wenhan Yu,Jianfeng Si,Tongxin Liu,Kaiqi Guan,Huiyan Jin,Jiawen Tao,Xiaokun Yuan,Duohe Ma,Xiangzheng Zhang,Tong Yang,Lin Sun*

Main category: cs.LG

TL;DR: TriPlay-RL：一个三角色闭环强化学习框架，通过攻击者、防御者和评估者的协同进化实现LLM安全对齐，无需人工标注。


<details>
  <summary>Details</summary>
Motivation: 近年来大型语言模型的安全风险日益突出，需要减少有毒有害内容的生成。现有主流安全对齐范式通常采用攻击者、防御者、评估者三角色协作框架，但缺乏高效的协同进化机制。

Method: 提出TriPlay-RL闭环强化学习框架，使三个角色能够在近乎零人工标注的情况下进行迭代式协同改进。攻击者生成对抗性提示，防御者进行安全防御，评估者评估响应质量，三者通过强化学习相互促进。

Result: 攻击者在保持高输出多样性的同时，对抗效果提升20%-50%；防御者在安全性能上获得10%-30%的提升，且不损害一般推理能力；评估者通过迭代持续提升细粒度判断能力，能准确区分不安全响应、简单拒绝和有用指导。

Conclusion: TriPlay-RL为LLM安全对齐建立了高效可扩展的范式，在统一学习循环中实现了持续协同进化，为解决LLM安全风险提供了有效解决方案。

Abstract: In recent years, safety risks associated with large language models have become increasingly prominent, highlighting the urgent need to mitigate the generation of toxic and harmful content. The mainstream paradigm for LLM safety alignment typically adopts a collaborative framework involving three roles: an attacker for adversarial prompt generation, a defender for safety defense, and an evaluator for response assessment. In this paper, we propose a closed-loop reinforcement learning framework called TriPlay-RL that enables iterative and co-improving collaboration among three roles with near-zero manual annotation. Experimental results show that the attacker preserves high output diversity while achieving a 20%-50% improvement in adversarial effectiveness; the defender attains 10%-30% gains in safety performance without degrading general reasoning capability; and the evaluator continuously refines its fine-grained judgment ability through iterations, accurately distinguishing unsafe responses, simple refusals, and useful guidance. Overall, our framework establishes an efficient and scalable paradigm for LLM safety alignment, enabling continuous co-evolution within a unified learning loop.

</details>


### [150] [A Master Class on Reproducibility: A Student Hackathon on Advanced MRI Reconstruction Methods](https://arxiv.org/abs/2601.18314)
*Lina Felsner,Sevgi G. Kafali,Hannah Eichhorn,Agnes A. J. Leth,Aidas Batvinskas,Andre Datchev,Fabian Klemm,Jan Aulich,Puntika Leepagorn,Ruben Klinger,Daniel Rueckert,Julia A. Schnabel*

Main category: cs.LG

TL;DR: 学生可重复性黑客松：复现三篇MRI重建论文（MoDL、HUMUS-Net、物理正则化动态MRI方法），分享实验设置、复现结果及可重复代码库构建实践


<details>
  <summary>Details</summary>
Motivation: 针对医学影像重建领域的重要论文，通过学生黑客松活动促进研究可重复性，验证关键方法的实际复现效果，并建立可重复代码库的最佳实践

Method: 组织学生黑客松活动，参与者尝试复现三篇MRI重建论文：1) MoDL（基于模型的展开网络+学习去噪）；2) HUMUS-Net（混合展开多尺度CNN+Transformer架构）；3) 基于定量MR模型的物理正则化动态MRI方法（使用早期停止策略）。记录实验设置、复现过程，并进行额外实验验证

Result: 报告了黑客松的组织细节、三篇论文的复现结果，展示了复现过程中的挑战和成功案例，同时提供了额外的实验数据来验证方法的有效性

Conclusion: 通过学生黑客松成功复现了重要的MRI重建方法，验证了这些方法的可重复性，并总结了构建可重复代码库的关键实践，为医学影像研究社区提供了有价值的经验

Abstract: We report the design, protocol, and outcomes of a student reproducibility hackathon focused on replicating the results of three influential MRI reconstruction papers: (a) MoDL, an unrolled model-based network with learned denoising; (b) HUMUS-Net, a hybrid unrolled multiscale CNN+Transformer architecture; and (c) an untrained, physics-regularized dynamic MRI method that uses a quantitative MR model for early stopping. We describe the setup of the hackathon and present reproduction outcomes alongside additional experiments, and we detail fundamental practices for building reproducible codebases.

</details>


### [151] [Cognitive Fusion of ZC Sequences and Time-Frequency Images for Out-of-Distribution Detection of Drone Signals](https://arxiv.org/abs/2601.18326)
*Jie Li,Jing Li,Lu Lv,Zhanyu Ju,Fengkui Gong*

Main category: cs.LG

TL;DR: 提出基于ZC序列和时频图像认知融合的无人机信号OOD检测算法，在RID任务中优于现有方法


<details>
  <summary>Details</summary>
Motivation: 无人机远程识别(RID)需要检测未知或非标准通信协议的无人机信号(OODD)，现有方法难以有效处理不同通信协议的特性差异

Method: 结合ZC序列（识别DJI无人机协议）和时频图像（捕获未知协议特征）的双模态方法，通过特征提取、对齐、交互和融合，利用自适应注意力权重进行信号分类

Result: 在RID和OODD指标上分别提升1.7%和7.5%，在不同飞行条件和无人机类型下表现出强鲁棒性

Conclusion: 提出的基于ZC序列和时频图像认知融合的算法能有效检测无人机信号中的OOD样本，在RID任务中性能优越且鲁棒性强

Abstract: We propose a drone signal out-of-distribution detection (OODD) algorithm based on the cognitive fusion of Zadoff-Chu (ZC) sequences and time-frequency images (TFI). ZC sequences are identified by analyzing the communication protocols of DJI drones, while TFI capture the time-frequency characteristics of drone signals with unknown or non-standard communication protocols. Both modalities are used jointly to enable OODD in the drone remote identification (RID) task. Specifically, ZC sequence features and TFI features are generated from the received radio frequency signals, which are then processed through dedicated feature extraction module to enhance and align them. The resultant multi-modal features undergo multi-modal feature interaction, single-modal feature fusion, and multi-modal feature fusion to produce features that integrate and complement information across modalities. Discrimination scores are computed from the fused features along both spatial and channel dimensions to capture time-frequency characteristic differences dictated by the communication protocols, and these scores will be transformed into adaptive attention weights. The weighted features are then passed through a Softmax function to produce the signal classification results. Simulation results demonstrate that the proposed algorithm outperforms existing algorithms and achieves 1.7% and 7.5% improvements in RID and OODD metrics, respectively. The proposed algorithm also performs strong robustness under varying flight conditions and across different drone types.

</details>


### [152] [Discriminability-Driven Spatial-Channel Selection with Gradient Norm for Drone Signal OOD Detection](https://arxiv.org/abs/2601.18329)
*Chuhan Feng,Jing Li,Jie Li,Lu Lv,Fengkui Gong*

Main category: cs.LG

TL;DR: 提出一种基于可区分性驱动的空间-通道选择和梯度范数的无人机信号OOD检测算法，通过自适应加权时频图像特征并融合梯度范数度量，实现优越的判别性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 无人机信号检测中，传统方法难以有效识别分布外（OOD）样本，需要开发能够自适应利用时频特征并量化OOD样本内在不稳定性的检测算法。

Method: 1. 基于协议特定时频特征量化类间相似性和方差，自适应加权时频图像特征的空间和通道维度；2. 引入梯度范数度量扰动敏感性以捕捉OOD样本的内在不稳定性；3. 将梯度范数与基于能量的分数融合进行联合推理。

Result: 仿真结果表明，该算法在信噪比和多种无人机类型下展现出优越的判别能力和鲁棒性能。

Conclusion: 提出的可区分性驱动空间-通道选择与梯度范数融合方法为无人机信号OOD检测提供了有效的解决方案，具有实际应用价值。

Abstract: We propose a drone signal out-of-distribution (OOD) detection algorithm based on discriminability-driven spatial-channel selection with a gradient norm. Time-frequency image features are adaptively weighted along both spatial and channel dimensions by quantifying inter-class similarity and variance based on protocol-specific time-frequency characteristics. Subsequently, a gradient-norm metric is introduced to measure perturbation sensitivity for capturing the inherent instability of OOD samples, which is then fused with energy-based scores for joint inference. Simulation results demonstrate that the proposed algorithm provides superior discriminative power and robust performance via SNR and various drone types.

</details>


### [153] [Structural Gender Bias in Credit Scoring: Proxy Leakage](https://arxiv.org/abs/2601.18342)
*Navya SD,Sreekanth D,SS Uma Sankari*

Main category: cs.LG

TL;DR: 研究审计台湾信用违约数据集中的结构性性别偏见，挑战"公平盲视"理念，发现即使移除受保护属性，非敏感特征仍作为性别代理变量，传统公平审计不足以检测隐性结构偏见。


<details>
  <summary>Details</summary>
Motivation: 随着金融机构越来越多地采用机器学习进行信用风险评估，算法偏见的持续存在成为公平金融包容性的关键障碍。本研究旨在挑战"公平盲视"的主流理念，揭示即使移除显性受保护属性，结构性性别偏见仍然存在。

Method: 使用SHAP（SHapley Additive exPlanations）识别婚姻状况、年龄和信用额度等变量作为性别代理变量；采用对抗性逆建模框架从纯非敏感金融特征中重建受保护的性别属性，量化信息泄漏。

Result: 研究发现即使移除显性受保护属性并应用行业标准公平干预措施，性别预测信号仍深植于非敏感特征中。受保护的性别属性可以从纯非敏感金融特征中以ROC AUC 0.65的分数重建，表明传统公平审计不足以检测隐性结构偏见。

Conclusion: 研究结果主张从表面统计公平转向因果感知建模和金融AI中的结构性问责制，强调需要更深入的方法来确保算法公平性，而不仅仅是移除显性受保护属性。

Abstract: As financial institutions increasingly adopt machine learning for credit risk assessment, the persistence of algorithmic bias remains a critical barrier to equitable financial inclusion. This study provides a comprehensive audit of structural gender bias within the Taiwan Credit Default dataset, specifically challenging the prevailing doctrine of "fairness through blindness." Despite the removal of explicit protected attributes and the application of industry standard fairness interventions, our results demonstrate that gendered predictive signals remain deeply embedded within non-sensitive features. Utilizing SHAP (SHapley Additive exPlanations), we identify that variables such as Marital Status, Age, and Credit Limit function as potent proxies for gender, allowing models to maintain discriminatory pathways while appearing statistically fair. To mathematically quantify this leakage, we employ an adversarial inverse modeling framework. Our findings reveal that the protected gender attribute can be reconstructed from purely non-sensitive financial features with an ROC AUC score of 0.65, demonstrating that traditional fairness audits are insufficient for detecting implicit structural bias. These results advocate for a shift from surface-level statistical parity toward causal-aware modeling and structural accountability in financial AI.

</details>


### [154] [Making medical vision-language models think causally across modalities with retrieval-augmented cross-modal reasoning](https://arxiv.org/abs/2601.18356)
*Weiqin Yang,Haowen Xue,Qingyi Peng,Hexuan Hu,Qian Huang,Tingbo Zhang*

Main category: cs.LG

TL;DR: 提出多模态因果检索增强生成框架，将因果推理原则与多模态检索结合，提升医学视觉语言模型的准确性、鲁棒性和可解释性


<details>
  <summary>Details</summary>
Motivation: 当前医学视觉语言模型主要依赖相关性而非因果推理，容易产生幻觉、受数据集偏见影响，传统检索增强生成依赖语义相似性会引入新的虚假相关性

Method: 提出多模态因果检索增强生成框架，从外部源检索临床相关示例和因果图，基于反事实和干预证据而非仅相关性来调节模型推理

Result: 应用于放射学报告生成、诊断预测和视觉问答，提高了事实准确性、对分布偏移的鲁棒性和可解释性

Conclusion: 因果检索为医学视觉语言模型提供了一条可扩展的路径，使其超越模式匹配，实现高风险临床环境中可信的多模态推理

Abstract: Medical vision-language models (VLMs) achieve strong performance in diagnostic reporting and image-text alignment, yet their underlying reasoning mechanisms remain fundamentally correlational, exhibiting reliance on superficial statistical associations that fail to capture the causal pathophysiological mechanisms central to clinical decision-making. This limitation makes them fragile, prone to hallucinations, and sensitive to dataset biases. Retrieval-augmented generation (RAG) offers a partial remedy by grounding predictions in external knowledge. However, conventional RAG depends on semantic similarity, introducing new spurious correlations. We propose Multimodal Causal Retrieval-Augmented Generation, a framework that integrates causal inference principles with multimodal retrieval. It retrieves clinically relevant exemplars and causal graphs from external sources, conditioning model reasoning on counterfactual and interventional evidence rather than correlations alone. Applied to radiology report generation, diagnosis prediction, and visual question answering, it improves factual accuracy, robustness to distribution shifts, and interpretability. Our results highlight causal retrieval as a scalable path toward medical VLMs that think beyond pattern matching, enabling trustworthy multimodal reasoning in high-stakes clinical settings.

</details>


### [155] [Estimating Dense-Packed Zone Height in Liquid-Liquid Separation: A Physics-Informed Neural Network Approach](https://arxiv.org/abs/2601.18399)
*Mehmet Velioglu,Song Zhai,Alexander Mitsos,Adel Mhamdi,Andreas Jupke,Manuel Dahmen*

Main category: cs.LG

TL;DR: 使用物理信息神经网络(PINN)和扩展卡尔曼滤波框架，仅通过流量测量估计重力沉降器中液-液分散的相高度


<details>
  <summary>Details</summary>
Motivation: 重力沉降器中密集堆积区高度是重要的性能和安全指标，但传统光学测量方法昂贵且不实用，需要开发仅使用廉价流量测量的估计方法

Method: 采用两阶段训练策略：首先在合成数据和低精度机理模型推导的物理方程上预训练PINN，然后用少量实验数据微调；将可微PINN作为预测模型集成到扩展卡尔曼滤波框架中，实现从流量测量跟踪相高度

Result: 在所有评估中，两阶段训练的PINN相比机理模型、非预训练PINN以及纯数据驱动神经网络，都能提供最准确的相高度估计

Conclusion: 提出的两阶段PINN训练方法结合扩展卡尔曼滤波框架，能够仅使用流量测量有效估计重力沉降器的相高度，为工业应用提供了经济实用的解决方案

Abstract: Separating liquid-liquid dispersions in gravity settlers is critical in chemical, pharmaceutical, and recycling processes. The dense-packed zone height is an important performance and safety indicator but it is often expensive and impractical to measure due to optical limitations. We propose to estimate phase heights using only inexpensive volume flow measurements. To this end, a physics-informed neural network (PINN) is first pretrained on synthetic data and physics equations derived from a low-fidelity (approximate) mechanistic model to reduce the need for extensive experimental data. While the mechanistic model is used to generate synthetic training data, only volume balance equations are used in the PINN, since the integration of submodels describing droplet coalescence and sedimentation into the PINN would be computationally prohibitive. The pretrained PINN is then fine-tuned with scarce experimental data to capture the actual dynamics of the separator. We then employ the differentiable PINN as a predictive model in an Extended Kalman Filter inspired state estimation framework, enabling the phase heights to be tracked and updated from flow-rate measurements. We first test the two-stage trained PINN by forward simulation from a known initial state against the mechanistic model and a non-pretrained PINN. We then evaluate phase height estimation performance with the filter, comparing the two-stage trained PINN with a two-stage trained purely data-driven neural network. All model types are trained and evaluated using ensembles to account for model parameter uncertainty. In all evaluations, the two-stage trained PINN yields the most accurate phase-height estimates.

</details>


### [156] [Superlinear Multi-Step Attention](https://arxiv.org/abs/2601.18401)
*Yufeng Huang*

Main category: cs.LG

TL;DR: 提出Superlinear attention，一种可训练的多步注意力架构，在保持随机上下文访问的同时实现长序列的次二次复杂度


<details>
  <summary>Details</summary>
Motivation: 标准自注意力在长序列上存在二次复杂度问题，现有方法要么牺牲随机上下文访问能力，要么效率不足

Method: 将因果自注意力重新表述为N步搜索问题，复杂度O(L^(1+1/N))。实现N=2的基线版本，第一步进行跨度搜索选择相关序列段，第二步在选定段上应用标准注意力

Result: 在O(L^1.54)配置下，在单B200 GPU上实现1M上下文长度114 tokens/sec和10M上下文80 tokens/sec的解码吞吐量。在NIAH任务上达到256K上下文长度

Conclusion: Superlinear attention在保持随机上下文访问的同时实现了次二次复杂度，展示了架构可行性，但全面质量评估留待未来工作

Abstract: In this paper, we propose \textbf{Superlinear attention}, a fully trainable multi-step attention architecture that achieves subquadratic complexity for long sequences while preserving \textbf{random context access} (a.k.a.\ structural non-exclusion): no eligible token position is structurally excluded from being selected for attention. Superlinear attention reformulates standard causal self-attention as a multi-step search problem with $N$ steps, yielding an overall complexity of $O(L^{1+\frac{1}{N}})$. To illustrate the architecture, we present a baseline $N=2$ implementation, which is algorithmically analogous to standard jump search. In this $O(L^{3/2})$ instantiation, the first step performs $O(L^{3/2})$ span-search to select relevant spans of the sequence, and the second step applies $O(L^{3/2})$ span-attention (standard attention restricted to the selected spans). In an upscaled $O(L^{1.54})$ configuration for robustness, we achieve an average decoding throughput of 114 tokens/sec at 1M context length and 80 tokens/sec at 10M context in our implementation on a modified 30B hybrid MoE model on a single B200 GPU. With limited training, we also obtain strong performance on the NIAH (Needle In A Haystack) task up to 256K context length, demonstrating that the routed span selection is learnable end-to-end. This paper emphasizes architectural formulation, scaling analysis, and systems feasibility, and presents initial validation; comprehensive quality evaluations across diverse long-context tasks are left to future work.

</details>


### [157] [Frequency-Based Hyperparameter Selection in Games](https://arxiv.org/abs/2601.18409)
*Aniket Sanyal,Baraah A. M. Sidahmed,Rebekka Burkholz,Tatjana Chavdarova*

Main category: cs.LG

TL;DR: 提出MoLA方法，通过频率估计自适应选择LookAhead超参数，加速平滑博弈中的训练


<details>
  <summary>Details</summary>
Motivation: 平滑博弈中的旋转动力学使经典超参数调优策略失效，而LookAhead方法虽然实用但引入额外参数且性能受参数影响大，目前缺乏有效的博弈超参数调优方法

Method: 通过频率估计分析振荡动力学，在连续时间轨迹和离散动力学谱中分析振荡，基于此提出Modal LookAhead (MoLA)，自适应选择超参数

Result: 提供收敛保证，实验证明MoLA在纯旋转博弈和混合机制中都能加速训练，且计算开销最小

Conclusion: MoLA为博弈中的超参数选择提供了原则性方法，通过频率分析自适应调优，显著提升训练效率

Abstract: Learning in smooth games fundamentally differs from standard minimization due to rotational dynamics, which invalidate classical hyperparameter tuning strategies. Despite their practical importance, effective methods for tuning in games remain underexplored. A notable example is LookAhead (LA), which achieves strong empirical performance but introduces additional parameters that critically influence performance. We propose a principled approach to hyperparameter selection in games by leveraging frequency estimation of oscillatory dynamics. Specifically, we analyze oscillations both in continuous-time trajectories and through the spectrum of the discrete dynamics in the associated frequency-based space. Building on this analysis, we introduce \emph{Modal LookAhead (MoLA)}, an extension of LA that selects the hyperparameters adaptively to a given problem. We provide convergence guarantees and demonstrate in experiments that MoLA accelerates training in both purely rotational games and mixed regimes, all with minimal computational overhead.

</details>


### [158] [Gradient Regularized Natural Gradients](https://arxiv.org/abs/2601.18420)
*Satya Prakash Dash,Hossein Abdi,Wei Pan,Samuel Kaski,Mingfei Sun*

Main category: cs.LG

TL;DR: 提出GRNG算法，将梯度正则化与自然梯度结合，提升二阶优化器的训练稳定性和泛化能力


<details>
  <summary>Details</summary>
Motivation: 虽然梯度正则化能提升模型泛化能力，自然梯度能加速训练初期优化，但现有研究很少关注二阶优化器如何从梯度正则化中受益

Method: 提出GRNG框架，包含两个算法：1）频率派变体通过结构化近似避免Fisher信息矩阵显式求逆；2）贝叶斯变体基于正则化卡尔曼公式完全消除FIM求逆需求

Result: 理论证明梯度正则化提升稳定性并确保收敛到全局最小值；实验显示GRNG在优化速度和泛化性能上优于一阶方法（SGD、AdamW）和二阶基线（K-FAC、Sophia），在视觉和语言基准上表现优异

Conclusion: 梯度正则化是解锁自然梯度方法在大规模深度学习中的鲁棒性的原则性和实用工具

Abstract: Gradient regularization (GR) has been shown to improve the generalizability of trained models. While Natural Gradient Descent has been shown to accelerate optimization in the initial phase of training, little attention has been paid to how the training dynamics of second-order optimizers can benefit from GR. In this work, we propose Gradient-Regularized Natural Gradients (GRNG), a family of scalable second-order optimizers that integrate explicit gradient regularization with natural gradient updates. Our framework provides two complementary algorithms: a frequentist variant that avoids explicit inversion of the Fisher Information Matrix (FIM) via structured approximations, and a Bayesian variant based on a Regularized-Kalman formulation that eliminates the need for FIM inversion entirely. We establish convergence guarantees for GRNG, showing that gradient regularization improves stability and enables convergence to global minima. Empirically, we demonstrate that GRNG consistently enhances both optimization speed and generalization compared to first-order methods (SGD, AdamW) and second-order baselines (K-FAC, Sophia), with strong results on vision and language benchmarks. Our findings highlight gradient regularization as a principled and practical tool to unlock the robustness of natural gradient methods for large-scale deep learning.

</details>


### [159] [GCFX: Generative Counterfactual Explanations for Deep Graph Models at the Model Level](https://arxiv.org/abs/2601.18447)
*Jinlong Hu,Jiacheng Liu*

Main category: cs.LG

TL;DR: GCFX：基于深度图生成的模型级反事实解释方法，通过增强的图生成框架和全局总结算法提供高质量的全局反事实解释，提升图学习模型的可解释性和可信度。


<details>
  <summary>Details</summary>
Motivation: 深度图学习模型虽然处理图结构数据能力强，但内部架构复杂且缺乏透明度，导致决策难以解释，用户难以理解和信任这些黑盒模型。

Method: 提出GCFX方法，基于深度图生成的反事实解释框架，采用双编码器、结构感知标记器和消息传递神经网络解码器的架构，准确学习输入数据的真实潜在分布，生成高质量反事实示例，再通过全局反事实总结算法选择最具代表性的解释。

Result: 在合成数据集和多个真实数据集上的实验表明，GCFX在反事实有效性和覆盖范围方面优于现有方法，同时保持较低的解释成本。

Conclusion: GCFX为深度图学习模型提供了有效的模型级反事实解释，增强了全局反事实解释的实用性和可信度，有助于提高用户对图学习模型的信任。

Abstract: Deep graph learning models have demonstrated remarkable capabilities in processing graph-structured data and have been widely applied across various fields. However, their complex internal architectures and lack of transparency make it difficult to explain their decisions, resulting in opaque models that users find hard to understand and trust. In this paper, we explore model-level explanation techniques for deep graph learning models, aiming to provide users with a comprehensive understanding of the models' overall decision-making processes and underlying mechanisms. Specifically, we address the problem of counterfactual explanations for deep graph learning models by introducing a generative model-level counterfactual explanation approach called GCFX, which is based on deep graph generation. This approach generates a set of high-quality counterfactual explanations that reflect the model's global predictive behavior by leveraging an enhanced deep graph generation framework and a global summarization algorithm. GCFX features an architecture that combines dual encoders, structure-aware taggers, and Message Passing Neural Network decoders, enabling it to accurately learn the true latent distribution of input data and generate high-quality, closely related counterfactual examples. Subsequently, a global counterfactual summarization algorithm selects the most representative and comprehensive explanations from numerous candidate counterfactuals, providing broad insights into the model's global predictive patterns. Experiments on a synthetic dataset and several real-world datasets demonstrate that GCFX outperforms existing methods in terms of counterfactual validity and coverage while maintaining low explanation costs, thereby offering crucial support for enhancing the practicality and trustworthiness of global counterfactual explanations.

</details>


### [160] [Enhancing Control Policy Smoothness by Aligning Actions with Predictions from Preceding States](https://arxiv.org/abs/2601.18479)
*Kyoleen Kwak,Hyoseok Hwang*

Main category: cs.LG

TL;DR: 提出ASAP方法，通过过渡诱导相似状态和对齐动作来平滑强化学习中的高频振荡，提高控制稳定性


<details>
  <summary>Details</summary>
Motivation: 深度强化学习在控制任务中表现出色，但其固有的高频动作振荡限制了在实际环境中的应用。现有方法通常依赖启发式或合成的状态相似性定义来促进动作一致性，但这些定义往往无法准确反映底层系统动态。

Method: 提出ASAP方法：1）引入过渡诱导相似状态，定义为从前一状态过渡到的下一个状态的分布；2）通过将当前动作与过渡诱导相似状态中的动作对齐来强制动作平滑性；3）惩罚二阶差异来抑制高频振荡。该方法仅利用环境反馈和实际收集的数据，能更好地捕捉系统动态。

Result: 在Gymnasium和Isaac-Lab环境中的实验表明，ASAP相比现有方法能产生更平滑的控制和更好的策略性能。

Conclusion: ASAP方法通过过渡诱导相似状态有效解决了深度强化学习中的动作振荡问题，提高了控制稳定性，在实际应用中具有潜力。

Abstract: Deep reinforcement learning has proven to be a powerful approach to solving control tasks, but its characteristic high-frequency oscillations make it difficult to apply in real-world environments. While prior methods have addressed action oscillations via architectural or loss-based methods, the latter typically depend on heuristic or synthetic definitions of state similarity to promote action consistency, which often fail to accurately reflect the underlying system dynamics. In this paper, we propose a novel loss-based method by introducing a transition-induced similar state. The transition-induced similar state is defined as the distribution of next states transitioned from the previous state. Since it utilizes only environmental feedback and actually collected data, it better captures system dynamics. Building upon this foundation, we introduce Action Smoothing by Aligning Actions with Predictions from Preceding States (ASAP), an action smoothing method that effectively mitigates action oscillations. ASAP enforces action smoothness by aligning the actions with those taken in transition-induced similar states and by penalizing second-order differences to suppress high-frequency oscillations. Experiments in Gymnasium and Isaac-Lab environments demonstrate that ASAP yields smoother control and improved policy performance over existing methods.

</details>


### [161] [Nearly Optimal Bayesian Inference for Structural Missingness](https://arxiv.org/abs/2601.18500)
*Chen Liang,Donghua Yang,Yutong Wang,Tianle Zhang,Shenghe Zhou,Zhiyu Liang,Hengtong Zhang,Hongzhi Wang,Ziqi Li,Xiyang Zhang,Zheng Liang,Yifei Li*

Main category: cs.LG

TL;DR: 论文提出了一种贝叶斯框架来处理结构化缺失数据，通过解耦缺失值后验学习和标签预测，实现不确定性传播，在多个基准测试中达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 结构化缺失数据带来三个核心挑战：(1)因果循环困境：预测需要缺失特征，但推断它们又依赖于缺失机制；(2)MNAR下缺失部分可能来自分布偏移；(3)单一插值会锁定不确定性，导致过度自信的偏差决策。

Method: 采用贝叶斯视角，通过后验预测分布进行预测，解耦两个步骤：(1)学习模型内缺失值的后验分布；(2)通过优化预测后验分布进行标签预测，实现后验积分。

Result: 在43个分类基准和15个插值基准上达到SOTA，在SCM先验下具有有限样本近贝叶斯最优性保证。

Conclusion: 该框架提供了一种"几乎免费午餐"的解决方案：一旦学习到后验，预测即可即插即用，同时保持不确定性传播，有效解决了结构化缺失数据的核心挑战。

Abstract: Structural missingness breaks 'just impute and train': values can be undefined by causal or logical constraints, and the mask may depend on observed variables, unobserved variables (MNAR), and other missingness indicators. It simultaneously brings (i) a catch-22 situation with causal loop, prediction needs the missing features, yet inferring them depends on the missingness mechanism, (ii) under MNAR, the unseen are different, the missing part can come from a shifted distribution, and (iii) plug-in imputation, a single fill-in can lock in uncertainty and yield overconfident, biased decisions. In the Bayesian view, prediction via the posterior predictive distribution integrates over the full model posterior uncertainty, rather than relying on a single point estimate. This framework decouples (i) learning an in-model missing-value posterior from (ii) label prediction by optimizing the predictive posterior distribution, enabling posterior integration. This decoupling yields an in-model almost-free-lunch: once the posterior is learned, prediction is plug-and-play while preserving uncertainty propagation. It achieves SOTA on 43 classification and 15 imputation benchmarks, with finite-sample near Bayes-optimality guarantees under our SCM prior.

</details>


### [162] [Conformal Prediction Algorithms for Time Series Forecasting: Methods and Benchmark](https://arxiv.org/abs/2601.18509)
*Andro Sabashvili*

Main category: cs.LG

TL;DR: 本文综述了时间序列预测中保形预测方法的应用挑战与解决方案，重点讨论了如何克服时间依赖性与数据可交换性假设之间的冲突。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测中的可靠不确定性量化至关重要，但传统方法依赖限制性分布假设。保形预测作为无分布框架具有理论保证，但时间序列的时序依赖性违反了标准保形预测所需的数据可交换性核心假设。

Method: 本文系统回顾了解决这一冲突的主要算法类别：1) 放宽可交换性假设的方法；2) 将数据单位重新定义为独立时间序列集合的方法；3) 显式建模预测残差动态的方法；4) 适应分布漂移以维持长期覆盖的在线学习算法。

Result: 通过对这些方法的综合分析和基准测试，突出了它们在真实世界数据上的计算效率和实际性能表现。

Conclusion: 本文系统梳理了时间序列保形预测的各种解决方案，为克服时序依赖性与可交换性假设之间的冲突提供了全面的方法学框架，强调了实际应用中的计算效率和性能考量。

Abstract: Reliable uncertainty quantification is of critical importance in time series forecasting, yet traditional methods often rely on restrictive distributional assumptions. Conformal prediction (CP) has emerged as a promising distribution-free framework for generating prediction intervals with rigorous theoretical guarantees. However, applying CP to sequential data presents a primary challenge: the temporal dependencies inherent in time series fundamentally violate the core assumption of data exchangeability, upon which standard CP guarantees are built. This review critically examines the main categories of algorithmic solutions designed to address this conflict. We survey and benchmark methods that relax the exchangeability assumption, those that redefine the data unit to be a collection of independent time series, approaches that explicitly model the dynamics of the prediction residuals, and online learning algorithms that adapt to distribution shifts to maintain long-run coverage. By synthesizing these approaches, we highlight computational efficiency and practical performance on real-world data.

</details>


### [163] [Just-In-Time Reinforcement Learning: Continual Learning in LLM Agents Without Gradient Updates](https://arxiv.org/abs/2601.18510)
*Yibo Li,Zijie Lin,Ailin Deng,Xuan Zhang,Yufei He,Shuo Ji,Tri Cao,Bryan Hooi*

Main category: cs.LG

TL;DR: JitRL是一种无需训练、基于即时强化学习的框架，通过在测试时动态检索经验轨迹来估计动作优势值，直接调制LLM输出logits，实现持续适应而不需要梯度更新。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）代理在部署后权重固定，难以持续适应新任务。传统强化学习虽然能解决这个问题，但计算成本高昂且存在灾难性遗忘风险。需要一种无需训练、低成本的持续学习方法。

Method: JitRL维护动态非参数化记忆库，在测试时检索相关经验轨迹来实时估计动作优势值。这些估计值用于直接调制LLM的输出logits，无需梯度更新。理论证明这种加法更新规则是KL约束策略优化目标的精确闭式解。

Result: 在WebArena和Jericho基准测试中，JitRL在无需训练的方法中达到最先进水平。更重要的是，它超越了计算昂贵的微调方法（如WebRL），同时将成本降低了30倍以上。

Conclusion: JitRL为持续学习代理提供了一条可扩展的路径，能够在测试时优化策略而不需要训练，显著降低了计算和金钱成本，同时避免了灾难性遗忘问题。

Abstract: While Large Language Model (LLM) agents excel at general tasks, they inherently struggle with continual adaptation due to the frozen weights after deployment. Conventional reinforcement learning (RL) offers a solution but incurs prohibitive computational costs and the risk of catastrophic forgetting. We introduce Just-In-Time Reinforcement Learning (JitRL), a training-free framework that enables test-time policy optimization without any gradient updates. JitRL maintains a dynamic, non-parametric memory of experiences and retrieves relevant trajectories to estimate action advantages on-the-fly. These estimates are then used to directly modulate the LLM's output logits. We theoretically prove that this additive update rule is the exact closed-form solution to the KL-constrained policy optimization objective. Extensive experiments on WebArena and Jericho demonstrate that JitRL establishes a new state-of-the-art among training-free methods. Crucially, JitRL outperforms the performance of computationally expensive fine-tuning methods (e.g., WebRL) while reducing monetary costs by over 30 times, offering a scalable path for continual learning agents. The code is available at https://github.com/liushiliushi/JitRL.

</details>


### [164] [LipNeXt: Scaling up Lipschitz-based Certified Robustness to Billion-parameter Models](https://arxiv.org/abs/2601.18513)
*Kai Hu,Haoqi Hu,Matt Fredrikson*

Main category: cs.LG

TL;DR: LipNeXt是首个无约束、无卷积的1-Lipschitz架构，通过流形优化和空间移位模块实现高效确定性鲁棒性认证，在多个数据集上达到SOTA，并能扩展到10亿参数规模。


<details>
  <summary>Details</summary>
Motivation: 现有的Lipschitz认证方法在模型规模、训练效率和ImageNet性能方面难以扩展，需要一种既能保持确定性鲁棒性保证又能适应现代大规模模型的方法。

Method: 提出LipNeXt架构，包含两个核心技术：1) 直接在正交流形上更新参数的流形优化方法；2) 无卷积的空间移位模块来建模空间模式。网络使用正交投影、空间移位、β-Abs非线性激活和L2空间池化来保持紧致的Lipschitz控制。

Result: 在CIFAR-10/100和Tiny-ImageNet上达到最先进的干净准确率和认证鲁棒准确率；在ImageNet上能扩展到10-20亿参数的大模型，比之前的Lipschitz模型在ε=1时提升高达8%的CRA，同时保持高效稳定的低精度训练。

Conclusion: Lipschitz基础认证方法可以受益于现代规模化趋势，而无需牺牲确定性或效率，为大规模确定性鲁棒性认证提供了可行的解决方案。

Abstract: Lipschitz-based certification offers efficient, deterministic robustness guarantees but has struggled to scale in model size, training efficiency, and ImageNet performance. We introduce \emph{LipNeXt}, the first \emph{constraint-free} and \emph{convolution-free} 1-Lipschitz architecture for certified robustness. LipNeXt is built using two techniques: (1) a manifold optimization procedure that updates parameters directly on the orthogonal manifold and (2) a \emph{Spatial Shift Module} to model spatial pattern without convolutions. The full network uses orthogonal projections, spatial shifts, a simple 1-Lipschitz $β$-Abs nonlinearity, and $L_2$ spatial pooling to maintain tight Lipschitz control while enabling expressive feature mixing. Across CIFAR-10/100 and Tiny-ImageNet, LipNeXt achieves state-of-the-art clean and certified robust accuracy (CRA), and on ImageNet it scales to 1-2B large models, improving CRA over prior Lipschitz models (e.g., up to $+8\%$ at $\varepsilon{=}1$) while retaining efficient, stable low-precision training. These results demonstrate that Lipschitz-based certification can benefit from modern scaling trends without sacrificing determinism or efficiency.

</details>


### [165] [Scalable Transit Delay Prediction at City Scale: A Systematic Approach with Multi-Resolution Feature Engineering and Deep Learning](https://arxiv.org/abs/2601.18521)
*Emna Boudabbous,Mohamed Karaa,Lokman Sboui,Julio Montecinos,Omar Alam*

Main category: cs.LG

TL;DR: 提出一个城市级公交延误预测框架，结合多分辨率特征工程、降维和深度学习，在蒙特利尔公交网络上实现实时、可扩展的延误预测。


<details>
  <summary>Details</summary>
Motivation: 城市公交机构需要可靠的网络级延误预测来提供准确的到站信息并支持实时运营控制。现有系统通常只能处理少数线路，依赖手工特征，缺乏可扩展的架构设计指导。

Method: 开发城市级预测管道，包含：1) 多分辨率特征工程（生成1,683个时空特征）；2) 自适应PCA降维（保留95%方差，压缩至83个成分）；3) 混合H3+拓扑聚类方法（避免"巨型集群"问题，生成12个平衡路线集群）；4) 比较五种模型架构，采用全局LSTM模型。

Result: 全局LSTM模型在准确性和效率间达到最佳平衡，比Transformer模型性能提升18-52%，同时参数减少275倍。通过蒙特利尔公交网络6个月数据的验证，证明管道适用于实时城市级部署，并可复用至其他网络。

Conclusion: 提出的城市级公交延误预测框架实现了可扩展、可复用的实时预测，解决了现有系统的局限性，为公交机构提供了实用的网络级延误预测解决方案。

Abstract: Urban bus transit agencies need reliable, network-wide delay predictions to provide accurate arrival information to passengers and support real-time operational control. Accurate predictions help passengers plan their trips, reduce waiting time, and allow operations staff to adjust headways, dispatch extra vehicles, and manage disruptions. Although real-time feeds such as GTFS-Realtime (GTFS-RT) are now widely available, most existing delay prediction systems handle only a few routes, depend on hand-crafted features, and offer little guidance on how to design a scalable, reusable architecture.
  We present a city-scale prediction pipeline that combines multi-resolution feature engineering, dimensionality reduction, and deep learning. The framework generates 1,683 spatiotemporal features by exploring 23 aggregation combinations over H3 cells, routes, segments, and temporal patterns, and compresses them into 83 components using Adaptive PCA while preserving 95% of the variance. To avoid the "giant cluster" problem that occurs when dense urban areas fall into a single H3 region, we introduce a hybrid H3+topology clustering method that yields 12 balanced route clusters (coefficient of variation 0.608) and enables efficient distributed training.
  We compare five model architectures on six months of bus operations from the Société de transport de Montréal (STM) network in Montréal. A global LSTM with cluster-aware features achieves the best trade-off between accuracy and efficiency, outperforming transformer models by 18 to 52% while using 275 times fewer parameters. We also report multi-level evaluation at the elementary segment, segment, and trip level with walk-forward validation and latency analysis, showing that the proposed pipeline is suitable for real-time, city-scale deployment and can be reused for other networks with limited adaptation.

</details>


### [166] [From Human Labels to Literature: Semi-Supervised Learning of NMR Chemical Shifts at Scale](https://arxiv.org/abs/2601.18524)
*Yongqi Jin,Yecheng Wang,Jun-jie Wang,Rong Zhu,Guolin Ke,Weinan E*

Main category: cs.LG

TL;DR: 提出半监督框架，利用文献提取的百万级未标记NMR谱图训练化学位移预测模型，无需原子级标注，显著提升预测精度和泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有NMR化学位移预测方法依赖有限的人工标注数据集，标注成本高且数据规模受限，需要利用大规模未标注谱图数据提升模型性能

Method: 提出半监督框架，将少量标注数据与大规模未标注文献谱图结合；将化学位移预测建模为置换不变集合监督问题，在损失函数满足特定条件下，最优二分匹配简化为排序损失，实现稳定的大规模半监督训练

Result: 模型在精度和鲁棒性上显著超越现有方法，在更大更多样的分子数据集上表现出更强的泛化能力；首次在大规模上捕捉常见NMR溶剂的系统性溶剂效应

Conclusion: 文献提取的大规模未标注谱图可作为训练NMR位移模型的有效数据源，表明文献衍生的弱结构化数据在科学数据中心的AI中具有更广泛的应用潜力

Abstract: Accurate prediction of nuclear magnetic resonance (NMR) chemical shifts is fundamental to spectral analysis and molecular structure elucidation, yet existing machine learning methods rely on limited, labor-intensive atom-assigned datasets. We propose a semi-supervised framework that learns NMR chemical shifts from millions of literature-extracted spectra without explicit atom-level assignments, integrating a small amount of labeled data with large-scale unassigned spectra. We formulate chemical shift prediction from literature spectra as a permutation-invariant set supervision problem, and show that under commonly satisfied conditions on the loss function, optimal bipartite matching reduces to a sorting-based loss, enabling stable large-scale semi-supervised training beyond traditional curated datasets. Our models achieve substantially improved accuracy and robustness over state-of-the-art methods and exhibit stronger generalization on significantly larger and more diverse molecular datasets. Moreover, by incorporating solvent information at scale, our approach captures systematic solvent effects across common NMR solvents for the first time. Overall, our results demonstrate that large-scale unlabeled spectra mined from the literature can serve as a practical and effective data source for training NMR shift models, suggesting a broader role of literature-derived, weakly structured data in data-centric AI for science.

</details>


### [167] [Closing the Modality Gap Aligns Group-Wise Semantics](https://arxiv.org/abs/2601.18525)
*Eleonora Grassucci,Giordano Cicchetti,Emanuele Frasca,Aurelio Uncini,Danilo Comminiello*

Main category: cs.LG

TL;DR: 论文提出模态间隙对分组任务影响显著，传统CLIP损失虽能语义对齐但存在结构不匹配，新方法能有效减小间隙并显著提升分组任务性能


<details>
  <summary>Details</summary>
Motivation: 尽管CLIP在多模态学习中建立了共享潜在空间，但模态间隙（结构不匹配）问题仍然存在。虽然对实例级任务影响有限，但作者认为其对分组级任务有重要影响，需要验证这一假设并开发解决方案。

Method: 提出一种新颖方法，专门设计用于在双模态设置中一致地减少模态间隙，并可以简单扩展到n模态情况。该方法通过更有效的对齐策略来改善潜在空间的结构匹配。

Result: 实验表明：减少模态间隙对传统实例级任务（如检索）仅有边际或不一致的改进，但对分组级任务（如聚类）有显著性能提升。这验证了模态间隙在语义分组任务中的关键作用。

Conclusion: 模态间隙的影响在分组任务中比实例任务更为显著，这一发现可能重塑我们对模态间隙的理解，强调了其在需要语义分组的任务中的关键作用，为多模态学习提供了新的研究方向。

Abstract: In multimodal learning, CLIP has been recognized as the \textit{de facto} method for learning a shared latent space across multiple modalities, placing similar representations close to each other and moving them away from dissimilar ones. Although CLIP-based losses effectively align modalities at the semantic level, the resulting latent spaces often remain only partially shared, revealing a structural mismatch known as the modality gap. While the necessity of addressing this phenomenon remains debated, particularly given its limited impact on instance-wise tasks (e.g., retrieval), we prove that its influence is instead strongly pronounced in group-level tasks (e.g., clustering). To support this claim, we introduce a novel method designed to consistently reduce this discrepancy in two-modal settings, with a straightforward extension to the general $n$-modal case. Through our extensive evaluation, we demonstrate our novel insight: while reducing the gap provides only marginal or inconsistent improvements in traditional instance-wise tasks, it significantly enhances group-wise tasks. These findings may reshape our understanding of the modality gap, highlighting its key role in improving performance on tasks requiring semantic grouping.

</details>


### [168] [Information Hidden in Gradients of Regression with Target Noise](https://arxiv.org/abs/2601.18546)
*Arash Jamshidi,Katsiaryna Haitsiukevich,Kai Puolamäki*

Main category: cs.LG

TL;DR: 论文提出一种通过梯度恢复二阶信息的方法：通过注入高斯噪声使目标噪声方差等于批次大小，从而让经验梯度协方差近似Hessian矩阵，即使在远离最优解时也有效。


<details>
  <summary>Details</summary>
Motivation: 在许多现代设置中，只能观察到梯度信息，而二阶信息（如曲率或数据协方差）对于优化、诊断和鲁棒性至关重要。需要一种仅使用梯度就能恢复Hessian矩阵的方法。

Method: 提出方差校准方法：注入高斯噪声使总目标噪声方差等于批次大小，这样经验梯度协方差就能近似Hessian矩阵。该方法基于"将目标噪声方差设为n"的简单规则。

Result: 在次高斯输入下提供了非渐近算子范数保证，证明了经验梯度协方差能近似Hessian。实验表明该方法在合成和真实数据上都有效，且具有鲁棒性（方差O(n)足以恢复Σ到尺度）。

Conclusion: 仅使用梯度就能恢复二阶信息，该方法实用且鲁棒，可应用于预条件加速优化、对抗风险估计和分布式系统中的仅梯度训练等场景。

Abstract: Second-order information -- such as curvature or data covariance -- is critical for optimisation, diagnostics, and robustness. However, in many modern settings, only the gradients are observable. We show that the gradients alone can reveal the Hessian, equalling the data covariance $Σ$ for the linear regression. Our key insight is a simple variance calibration: injecting Gaussian noise so that the total target noise variance equals the batch size ensures that the empirical gradient covariance closely approximates the Hessian, even when evaluated far from the optimum. We provide non-asymptotic operator-norm guarantees under sub-Gaussian inputs. We also show that without such calibration, recovery can fail by an $Ω(1)$ factor. The proposed method is practical (a "set target-noise variance to $n$" rule) and robust (variance $\mathcal{O}(n)$ suffices to recover $Σ$ up to scale). Applications include preconditioning for faster optimisation, adversarial risk estimation, and gradient-only training, for example, in distributed systems. We support our theoretical results with experiments on synthetic and real data.

</details>


### [169] [An Unsupervised Tensor-Based Domain Alignment](https://arxiv.org/abs/2601.18564)
*Chong Hyun Lee,Kibae Lee,Hyun Hee Yim*

Main category: cs.LG

TL;DR: 提出基于张量的域对齐算法，通过对齐矩阵在不变子空间中对齐源和目标张量，使用斜流形约束提供比传统Stiefel流形更大的灵活性，并通过正则化项保持方差，显著提升分类精度和转换速度。


<details>
  <summary>Details</summary>
Motivation: 现有张量域对齐方法通常使用Stiefel流形约束，灵活性有限。需要更灵活的自适应方法，同时保持源和目标张量的方差特性，以提高域对齐效果和分类性能。

Method: 提出基于张量的域对齐框架，使用对齐矩阵在不变子空间中对齐源和目标张量。采用斜流形约束进行迭代优化，比传统Stiefel流形更灵活。引入正则化项保持源和目标张量的方差，确保鲁棒性。该框架可泛化为现有张量域对齐方法的特例。

Result: 实验表明，该方法不仅显著提升域对齐转换速度，还大幅提高分类准确率。在复杂域适应任务中优于当前最先进技术，成为域对齐任务的优选方案。

Conclusion: 提出的基于张量的域对齐算法通过斜流形约束和方差保持正则化，提供了更灵活高效的域对齐解决方案，在速度和精度上都优于现有方法，适用于复杂域适应任务。

Abstract: We propose a tensor-based domain alignment (DA) algorithm designed to align source and target tensors within an invariant subspace through the use of alignment matrices. These matrices along with the subspace undergo iterative optimization of which constraint is on oblique manifold, which offers greater flexibility and adaptability compared to the traditional Stiefel manifold. Moreover, regularization terms defined to preserve the variance of both source and target tensors, ensures robust performance. Our framework is versatile, effectively generalizing existing tensor-based DA methods as special cases. Through extensive experiments, we demonstrate that our approach not only enhances DA conversion speed but also significantly boosts classification accuracy. This positions our method as superior to current state-of-the-art techniques, making it a preferable choice for complex domain adaptation tasks.

</details>


### [170] [K-Myriad: Jump-starting reinforcement learning with unsupervised parallel agents](https://arxiv.org/abs/2601.18580)
*Vincenzo De Paola,Mirco Mutti,Riccardo Zamboni,Marcello Restelli*

Main category: cs.LG

TL;DR: K-Myriad是一种无监督并行强化学习方法，通过最大化并行策略群体诱导的集体状态熵，培养多样化的探索策略，提供鲁棒的初始化，提高训练效率并发现异构解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统并行强化学习通常使用相同采样分布的多个工作器来加速单个策略训练，这种设计忽视了多样化探索策略的优势，限制了并行化的潜力。

Method: 提出K-Myriad方法，通过最大化并行策略群体诱导的集体状态熵，培养专门的探索策略组合，实现无监督的多样化探索。

Result: 在高维连续控制任务和大规模并行化实验中，K-Myriad能够学习到广泛的独特策略，证明了其在集体探索方面的有效性。

Conclusion: K-Myriad通过培养多样化探索策略组合，为强化学习提供了鲁棒初始化，提高了训练效率并发现了异构解决方案，为新的并行化策略铺平了道路。

Abstract: Parallelization in Reinforcement Learning is typically employed to speed up the training of a single policy, where multiple workers collect experience from an identical sampling distribution. This common design limits the potential of parallelization by neglecting the advantages of diverse exploration strategies. We propose K-Myriad, a scalable and unsupervised method that maximizes the collective state entropy induced by a population of parallel policies. By cultivating a portfolio of specialized exploration strategies, K-Myriad provides a robust initialization for Reinforcement Learning, leading to both higher training efficiency and the discovery of heterogeneous solutions. Experiments on high-dimensional continuous control tasks, with large-scale parallelization, demonstrate that K-Myriad can learn a broad set of distinct policies, highlighting its effectiveness for collective exploration and paving the way towards novel parallelization strategies.

</details>


### [171] [Learning long term climate-resilient transport adaptation pathways under direct and indirect flood impacts using reinforcement learning](https://arxiv.org/abs/2601.18586)
*Miguel Costa,Arthur Vandervoort,Carolin Schmidt,Morten W. Petersen,Martin Drews,Karyn Morrissey,Francisco C. Pereira*

Main category: cs.LG

TL;DR: 提出结合集成评估模型与强化学习的决策支持框架，用于学习城市交通系统在气候变化下的自适应多十年投资路径


<details>
  <summary>Details</summary>
Motivation: 气候变化加剧降雨等灾害，增加城市交通系统中断；基础设施投资具有长期性、序列性，面临深度不确定性和跨部门复杂交互，需要有效的适应策略设计方法

Method: 提出通用决策支持框架：将集成评估模型与强化学习耦合，结合长期气候预测（IPCC情景路径），建立从极端天气驱动因素到灾害概率、再到基础设施影响、最后到社会成本的模型链，在强化学习循环中学习权衡投资与避免影响的适应政策

Result: 在哥本哈格市内涝案例（2024-2100）中，学习到的策略产生协调的时空路径，相比传统优化基准（不作为和随机行动）具有更好的鲁棒性

Conclusion: 该框架展示了可迁移到其他灾害和城市的潜力，为城市气候适应提供了一种新的决策支持方法

Abstract: Climate change is expected to intensify rainfall and other hazards, increasing disruptions in urban transportation systems. Designing effective adaptation strategies is challenging due to the long-term, sequential nature of infrastructure investments, deep uncertainty, and complex cross-sector interactions. We propose a generic decision-support framework that couples an integrated assessment model (IAM) with reinforcement learning (RL) to learn adaptive, multi-decade investment pathways under uncertainty. The framework combines long-term climate projections (e.g., IPCC scenario pathways) with models that map projected extreme-weather drivers (e.g. rain) into hazard likelihoods (e.g. flooding), propagate hazards into urban infrastructure impacts (e.g. transport disruption), and value direct and indirect consequences for service performance and societal costs. Embedded in a reinforcement-learning loop, it learns adaptive climate adaptation policies that trade off investment and maintenance expenditures against avoided impacts. In collaboration with Copenhagen Municipality, we demonstrate the approach on pluvial flooding in the inner city for the horizon of 2024 to 2100. The learned strategies yield coordinated spatial-temporal pathways and improved robustness relative to conventional optimization baselines, namely inaction and random action, illustrating the framework's transferability to other hazards and cities.

</details>


### [172] [LaCoGSEA: Unsupervised deep learning for pathway analysis via latent correlation](https://arxiv.org/abs/2601.18604)
*Zhiwei Zheng,Kevin Bryson*

Main category: cs.LG

TL;DR: LaCoGSEA是一种无监督通路富集分析框架，结合深度表示学习和通路统计，无需先验标签即可进行通路分析。


<details>
  <summary>Details</summary>
Motivation: 传统通路富集分析方法（如GSEA）依赖预定义表型标签和成对比较，限制了在无监督场景下的应用。现有无监督扩展方法主要捕捉线性关系，无法建模基因-通路关联。深度学习模型虽能捕捉非线性结构，但其解释方法通常依赖通用XAI技术，在通路级解释方面效果有限。

Method: LaCoGSEA使用自编码器捕捉非线性流形，提出全局基因-潜在相关度量作为差异表达代理，无需先验标签即可生成密集基因排序。该框架整合深度表示学习和稳健通路统计。

Result: LaCoGSEA在三个方面表现优异：1）相比现有无监督基线，在区分癌症亚型方面获得更好的聚类性能；2）相比线性降维和基于梯度的XAI方法，在更高排名恢复更广泛的生物学相关通路；3）在不同实验方案和数据集大小下保持高稳健性和一致性。

Conclusion: LaCoGSEA在无监督通路富集分析中达到最先进性能，为无监督转录组分析提供了有效的通路级解释框架。

Abstract: Motivation: Pathway enrichment analysis is widely used to interpret gene expression data. Standard approaches, such as GSEA, rely on predefined phenotypic labels and pairwise comparisons, which limits their applicability in unsupervised settings. Existing unsupervised extensions, including single-sample methods, provide pathway-level summaries but primarily capture linear relationships and do not explicitly model gene-pathway associations. More recently, deep learning models have been explored to capture non-linear transcriptomic structure. However, their interpretation has typically relied on generic explainable AI (XAI) techniques designed for feature-level attribution. As these methods are not designed for pathway-level interpretation in unsupervised transcriptomic analyses, their effectiveness in this setting remains limited.
  Results: To bridge this gap, we introduce LaCoGSEA (Latent Correlation GSEA), an unsupervised framework that integrates deep representation learning with robust pathway statistics. LaCoGSEA employs an autoencoder to capture non-linear manifolds and proposes a global gene-latent correlation metric as a proxy for differential expression, generating dense gene rankings without prior labels. We demonstrate that LaCoGSEA offers three key advantages: (i) it achieves improved clustering performance in distinguishing cancer subtypes compared to existing unsupervised baselines; (ii) it recovers a broader range of biologically meaningful pathways at higher ranks compared with linear dimensionality reduction and gradient-based XAI methods; and (iii) it maintains high robustness and consistency across varying experimental protocols and dataset sizes. Overall, LaCoGSEA provides state-of-the-art performance in unsupervised pathway enrichment analysis.
  Availability and implementation: https://github.com/willyzzz/LaCoGSEA

</details>


### [173] [Geometry-Free Conditional Diffusion Modeling for Solving the Inverse Electrocardiography Problem](https://arxiv.org/abs/2601.18615)
*Ramiro Valdes Jara,Adam Meyers*

Main category: cs.LG

TL;DR: 提出基于条件扩散模型的ECGI逆问题数据驱动解法，无需几何建模，通过概率采样处理非唯一性问题，相比确定性方法提升重建精度


<details>
  <summary>Details</summary>
Motivation: 传统ECGI逆问题求解方法需要患者特异性网格构建，且通常提供单一确定性解，无法处理问题的非唯一性和欠定性本质

Method: 采用条件扩散框架，学习从噪声体表信号到心脏表面电位的概率映射，无需几何建模，纯数据驱动，可生成多个可能重建结果

Result: 在真实ECGI数据集上评估，相比CNN、LSTM和Transformer等确定性基线方法，扩散模型获得更高的重建精度

Conclusion: 扩散模型为无创心脏电生理成像提供了鲁棒工具，能有效处理ECGI逆问题的非唯一性，无需患者特异性网格构建

Abstract: This paper proposes a data-driven model for solving the inverse problem of electrocardiography, the mathematical problem that forms the basis of electrocardiographic imaging (ECGI). We present a conditional diffusion framework that learns a probabilistic mapping from noisy body surface signals to heart surface electric potentials. The proposed approach leverages the generative nature of diffusion models to capture the non-unique and underdetermined nature of the ECGI inverse problem, enabling probabilistic sampling of multiple reconstructions rather than a single deterministic estimate. Unlike traditional methods, the proposed framework is geometry-free and purely data-driven, alleviating the need for patient-specific mesh construction. We evaluate the method on a real ECGI dataset and compare it against strong deterministic baselines, including a convolutional neural network, long short-term memory network, and transformer-based model. The results demonstrate that the proposed diffusion approach achieves improved reconstruction accuracy, highlighting the potential of diffusion models as a robust tool for noninvasive cardiac electrophysiology imaging.

</details>


### [174] [CASSANDRA: Programmatic and Probabilistic Learning and Inference for Stochastic World Modeling](https://arxiv.org/abs/2601.18620)
*Panagiotis Lymperopoulos,Abhiramon Rajasekharan,Ian Berlot-Attwell,Stéphane Aroca-Ouellette,Kaheer Suleman*

Main category: cs.LG

TL;DR: CASSANDRA：一种结合LLM知识先验的神经符号世界建模方法，用于商业等复杂领域的规划任务


<details>
  <summary>Details</summary>
Motivation: 现实世界领域（如商业）具有丰富的语义，需要从有限数据中建模复杂的动作效果和因果关系。传统方法难以有效利用领域知识来构建轻量级的世界模型。

Method: 提出CASSANDRA神经符号世界建模方法：1）使用LLM合成代码来建模确定性特征；2）使用LLM引导的概率图模型结构学习来捕捉随机变量间的因果关系。

Result: 在咖啡店模拟器和主题公园商业模拟器上评估，相比基线方法在状态转移预测和规划方面有显著改进。

Conclusion: CASSANDRA通过结合LLM的知识先验，能够有效构建轻量级的世界模型，在复杂领域规划任务中表现出色。

Abstract: Building world models is essential for planning in real-world domains such as businesses. Since such domains have rich semantics, we can leverage world knowledge to effectively model complex action effects and causal relationships from limited data. In this work, we propose CASSANDRA, a neurosymbolic world modeling approach that leverages an LLM as a knowledge prior to construct lightweight transition models for planning. CASSANDRA integrates two components: (1) LLM-synthesized code to model deterministic features, and (2) LLM-guided structure learning of a probabilistic graphical model to capture causal relationships among stochastic variables. We evaluate CASSANDRA in (i) a small-scale coffee-shop simulator and (ii) a complex theme park business simulator, where we demonstrate significant improvements in transition prediction and planning over baselines.

</details>


### [175] [Rank-1 Approximation of Inverse Fisher for Natural Policy Gradients in Deep Reinforcement Learning](https://arxiv.org/abs/2601.18626)
*Yingxiao Huo,Satya Prakash Dash,Radu Stoican,Samuel Kaski,Mingfei Sun*

Main category: cs.LG

TL;DR: 提出一种基于秩-1近似的自然策略优化方法，高效逼近Fisher信息矩阵逆，在多种环境中优于标准actor-critic和信任域基线


<details>
  <summary>Details</summary>
Motivation: 自然梯度在深度强化学习中具有快速收敛特性，但计算Fisher信息矩阵逆的计算成本过高，需要一种高效可扩展的自然策略优化方法

Method: 使用秩-1近似来逼近完整的Fisher信息矩阵逆，开发高效可扩展的自然策略优化技术

Result: 在多样化环境中进行基准测试，显示该方法优于标准actor-critic和信任域基线方法，在某些条件下收敛速度比策略梯度更快

Conclusion: 秩-1近似自然策略优化是一种计算高效的方法，能够实现与随机策略梯度方法相同的样本复杂度，并在实际应用中表现出优越性能

Abstract: Natural gradients have long been studied in deep reinforcement learning due to their fast convergence properties and covariant weight updates. However, computing natural gradients requires inversion of the Fisher Information Matrix (FIM) at each iteration, which is computationally prohibitive in nature. In this paper, we present an efficient and scalable natural policy optimization technique that leverages a rank-1 approximation to full inverse-FIM. We theoretically show that under certain conditions, a rank-1 approximation to inverse-FIM converges faster than policy gradients and, under some conditions, enjoys the same sample complexity as stochastic policy gradient methods. We benchmark our method on a diverse set of environments and show that it achieves superior performance to standard actor-critic and trust-region baselines.

</details>


### [176] [TwinPurify: Purifying gene expression data to reveal tumor-intrinsic transcriptional programs via self-supervised learning](https://arxiv.org/abs/2601.18640)
*Zhiwei Zheng,Kevin Bryson*

Main category: cs.LG

TL;DR: TwinPurify是一个基于Barlow Twins自监督学习的表示学习框架，用于从批量转录组数据中提取肿瘤特异性信号，无需外部参考，通过利用同一队列中的相邻正常组织作为背景指导来消除肿瘤纯度变化的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管单细胞和空间转录组技术取得了进展，但大规模患者队列研究仍依赖批量转录组数据。肿瘤纯度的变化会掩盖肿瘤内在的转录信号，限制下游发现。现有的去卷积方法在合成混合物上表现良好，但无法推广到真实患者队列，因为它们未建模生物和技术变异。

Method: TwinPurify采用Barlow Twins自监督学习目标，从批量转录组数据中学习连续的高维肿瘤嵌入。它利用同一队列中的相邻正常组织作为"背景"指导，无需外部参考即可解耦肿瘤特异性信号，而不是将批量混合物解析为离散的细胞类型分数。

Result: 在多个大型癌症队列（RNA-seq和微阵列平台）的基准测试中，TwinPurify在恢复肿瘤内在和免疫信号方面优于传统的表示学习方法（如自编码器）。纯化的嵌入改进了分子亚型和分级分类，增强了生存模型的一致性，并揭示了比原始批量谱更具生物学意义的通路活动。

Conclusion: TwinPurify通过提供可转移的批量转录组去污染框架，扩展了现有临床数据集在分子发现中的实用性，为从批量转录组数据中提取肿瘤特异性信号提供了一种新方法。

Abstract: Advances in single-cell and spatial transcriptomic technologies have transformed tumor ecosystem profiling at cellular resolution. However, large scale studies on patient cohorts continue to rely on bulk transcriptomic data, where variation in tumor purity obscures tumor-intrinsic transcriptional signals and constrains downstream discovery. Many deconvolution methods report strong performance on synthetic bulk mixtures but fail to generalize to real patient cohorts because of unmodeled biological and technical variation.
  Here, we introduce TwinPurify, a representation learning framework that adapts the Barlow Twins self-supervised objective, representing a fundamental departure from the deconvolution paradigm. Rather than resolving the bulk mixture into discrete cell-type fractions, TwinPurify instead learns continuous, high-dimensional tumor embeddings by leveraging adjacent-normal profiles within the same cohort as "background" guidance, enabling the disentanglement of tumor-specific signals without relying on any external reference.
  Benchmarked against multiple large cancer cohorts across RNA-seq and microarray platforms, TwinPurify outperforms conventional representation learning baselines like auto-encoders in recovering tumor-intrinsic and immune signals. The purified embeddings improve molecular subtype and grade classification, enhance survival model concordance, and uncover biologically meaningful pathway activities compared to raw bulk profiles. By providing a transferable framework for decontaminating bulk transcriptomics, TwinPurify extends the utility of existing clinical datasets for molecular discovery.

</details>


### [177] [FaLW: A Forgetting-aware Loss Reweighting for Long-tailed Unlearning](https://arxiv.org/abs/2601.18650)
*Liheng Yu,Zhe Zhao,Yuxuan Wang,Pengkun Wang,Binwu Wang,Yang Wang*

Main category: cs.LG

TL;DR: 该论文首次研究长尾分布下的机器遗忘问题，发现现有方法存在异质遗忘偏差和偏斜遗忘偏差，提出了一种即插即用的动态损失重加权方法FaLW来解决这些问题。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘研究主要评估相对平衡的遗忘集，忽略了现实世界中数据（如用户活动记录）通常遵循长尾分布的情况。这是该领域的重要研究空白。

Method: 提出FaLW方法：一种即插即用、实例级别的动态损失重加权方法。通过比较每个样本的预测概率与同类别未见数据的分布来评估其遗忘状态，然后使用遗忘感知的重加权方案，通过平衡因子调节，自适应调整每个样本的遗忘强度。

Result: 大量实验证明FaLW在长尾分布设置下取得了优越性能，有效解决了异质遗忘偏差和偏斜遗忘偏差问题。

Conclusion: 该研究填补了长尾分布下机器遗忘的研究空白，提出的FaLW方法能够有效处理现实世界中常见的长尾数据遗忘场景，为数据隐私保护提供了更好的解决方案。

Abstract: Machine unlearning, which aims to efficiently remove the influence of specific data from trained models, is crucial for upholding data privacy regulations like the ``right to be forgotten". However, existing research predominantly evaluates unlearning methods on relatively balanced forget sets. This overlooks a common real-world scenario where data to be forgotten, such as a user's activity records, follows a long-tailed distribution. Our work is the first to investigate this critical research gap. We find that in such long-tailed settings, existing methods suffer from two key issues: \textit{Heterogeneous Unlearning Deviation} and \textit{Skewed Unlearning Deviation}. To address these challenges, we propose FaLW, a plug-and-play, instance-wise dynamic loss reweighting method. FaLW innovatively assesses the unlearning state of each sample by comparing its predictive probability to the distribution of unseen data from the same class. Based on this, it uses a forgetting-aware reweighting scheme, modulated by a balancing factor, to adaptively adjust the unlearning intensity for each sample. Extensive experiments demonstrate that FaLW achieves superior performance. Code is available at \textbf{Supplementary Material}.

</details>


### [178] [A Dynamic Framework for Grid Adaptation in Kolmogorov-Arnold Networks](https://arxiv.org/abs/2601.18672)
*Spyros Rigas,Thanasis Papaioannou,Panagiotis Trakadas,Georgios Alexandridis*

Main category: cs.LG

TL;DR: 本文提出了一种基于曲率的KAN网格自适应框架，通过重要性密度函数将节点分配视为密度估计任务，相比传统基于输入数据密度的方法，在多个基准测试中显著降低了误差。


<details>
  <summary>Details</summary>
Motivation: 现有KAN网格自适应策略仅依赖输入数据密度，未能考虑目标函数的几何复杂性或训练过程中的计算指标，限制了网络性能的进一步提升。

Method: 提出广义框架，将节点分配视为由重要性密度函数控制的密度估计任务，引入基于曲率的自适应策略，让训练动态决定网格分辨率。

Result: 在合成函数拟合、Feynman数据集回归和Helmholtz PDE实例上，相比标准基线方法，平均相对误差分别降低25.3%、9.4%和23.3%，Wilcoxon符号秩检验确认统计显著性。

Conclusion: 基于曲率的自适应策略是KAN训练中稳健且计算高效的替代方案，能够更好地捕捉目标函数的几何特性，显著提升模型性能。

Abstract: Kolmogorov-Arnold Networks (KANs) have recently demonstrated promising potential in scientific machine learning, partly due to their capacity for grid adaptation during training. However, existing adaptation strategies rely solely on input data density, failing to account for the geometric complexity of the target function or metrics calculated during network training. In this work, we propose a generalized framework that treats knot allocation as a density estimation task governed by Importance Density Functions (IDFs), allowing training dynamics to determine grid resolution. We introduce a curvature-based adaptation strategy and evaluate it across synthetic function fitting, regression on a subset of the Feynman dataset and different instances of the Helmholtz PDE, demonstrating that it significantly outperforms the standard input-based baseline. Specifically, our method yields average relative error reductions of 25.3% on synthetic functions, 9.4% on the Feynman dataset, and 23.3% on the PDE benchmark. Statistical significance is confirmed via Wilcoxon signed-rank tests, establishing curvature-based adaptation as a robust and computationally efficient alternative for KAN training.

</details>


### [179] [Learning temporal embeddings from electronic health records of chronic kidney disease patients](https://arxiv.org/abs/2601.18675)
*Aditya Kumar,Mario A. Cypko,Oliver Amft*

Main category: cs.LG

TL;DR: 研究验证了在纵向电子健康记录上训练的时序嵌入模型能否在不牺牲预测性能的情况下学习临床有意义的表示，以及架构选择如何影响嵌入质量。发现时间感知LSTM产生更结构化的嵌入，且嵌入模型在ICU死亡率预测上始终优于端到端模型。


<details>
  <summary>Details</summary>
Motivation: 模型引导的医学需要能够捕捉疾病动态同时保持透明和任务无关的表示，而大多数临床预测模型仅针对单一任务优化。表示学习有助于学习能泛化到下游任务的嵌入，循环架构适合建模临床数据中的时序结构。

Method: 使用MIMIC-IV数据集研究慢性肾病（CKD）患者，比较三种循环架构：普通LSTM、注意力增强LSTM和时间感知LSTM（T-LSTM）。所有模型既作为嵌入模型训练，也作为直接端到端预测器训练。通过CKD阶段聚类和ICU内死亡率预测评估嵌入质量。

Result: T-LSTM产生更结构化的嵌入，获得更低的Davies-Bouldin指数（DBI=9.91）和更高的CKD阶段分类准确率（0.74），优于普通LSTM（DBI=15.85，准确率0.63）和注意力增强LSTM（DBI=20.72，准确率0.67）。对于ICU内死亡率预测，嵌入模型始终优于端到端预测器，准确率从0.72-0.75提升到0.82-0.83。

Conclusion: 时序嵌入模型能够学习临床有意义的表示而不损害预测性能，时间感知架构产生更结构化的嵌入。学习嵌入作为中间步骤比直接端到端学习更有效，为模型引导医学提供了有前景的方向。

Abstract: We investigate whether temporal embedding models trained on longitudinal electronic health records can learn clinically meaningful representations without compromising predictive performance, and how architectural choices affect embedding quality. Model-guided medicine requires representations that capture disease dynamics while remaining transparent and task agnostic, whereas most clinical prediction models are optimised for a single task. Representation learning facilitates learning embeddings that generalise across downstream tasks, and recurrent architectures are well-suited for modelling temporal structure in observational clinical data. Using the MIMIC-IV dataset, we study patients with chronic kidney disease (CKD) and compare three recurrent architectures: a vanilla LSTM, an attention-augmented LSTM, and a time-aware LSTM (T-LSTM). All models are trained both as embedding models and as direct end-to-end predictors. Embedding quality is evaluated via CKD stage clustering and in-ICU mortality prediction. The T-LSTM produces more structured embeddings, achieving a lower Davies-Bouldin Index (DBI = 9.91) and higher CKD stage classification accuracy (0.74) than the vanilla LSTM (DBI = 15.85, accuracy = 0.63) and attention-augmented LSTM (DBI = 20.72, accuracy = 0.67). For in-ICU mortality prediction, embedding models consistently outperform end-to-end predictors, improving accuracy from 0.72-0.75 to 0.82-0.83, which indicates that learning embeddings as an intermediate step is more effective than direct end-to-end learning.

</details>


### [180] [Quasi Monte Carlo methods enable extremely low-dimensional deep generative models](https://arxiv.org/abs/2601.18676)
*Miles Martinez,Alex H. Williams*

Main category: cs.LG

TL;DR: QLVMs是一种专门用于寻找高维数据极低维可解释嵌入的深度生成模型，通过准蒙特卡洛积分直接近似边际似然，在1-3维潜空间中优于传统VAE和IWAE。


<details>
  <summary>Details</summary>
Motivation: 传统变分自编码器依赖学习编码器和变分下界，难以获得极低维且可解释的潜空间表示。需要一种专门针对低维嵌入优化的方法，以支持透明的可视化和后验分析。

Method: 提出准蒙特卡洛潜变量模型（QLVMs），通过随机化准蒙特卡洛积分直接近似边际似然，而不是使用变分下界。这种方法专门针对1-3维潜空间进行优化。

Result: 在多个数据集上，QLVMs在匹配潜空间维度下持续优于传统变分自编码器（VAEs）和重要性加权自编码器（IWAEs）。生成的嵌入支持透明可视化、非参数密度估计、聚类和测地线路径计算等后验分析。

Conclusion: QLVMs为优先考虑可解释性和潜空间分析的应用提供了有吸引力的解决方案，虽然计算密集且在复杂数据集上难以生成精细细节，但在低维嵌入任务上表现出色。

Abstract: This paper introduces quasi-Monte Carlo latent variable models (QLVMs): a class of deep generative models that are specialized for finding extremely low-dimensional and interpretable embeddings of high-dimensional datasets. Unlike standard approaches, which rely on a learned encoder and variational lower bounds, QLVMs directly approximate the marginal likelihood by randomized quasi-Monte Carlo integration. While this brute force approach has drawbacks in higher-dimensional spaces, we find that it excels in fitting one, two, and three dimensional deep latent variable models. Empirical results on a range of datasets show that QLVMs consistently outperform conventional variational autoencoders (VAEs) and importance weighted autoencoders (IWAEs) with matched latent dimensionality. The resulting embeddings enable transparent visualization and post hoc analyses such as nonparametric density estimation, clustering, and geodesic path computation, which are nontrivial to validate in higher-dimensional spaces. While our approach is compute-intensive and struggles to generate fine-scale details in complex datasets, it offers a compelling solution for applications prioritizing interpretability and latent space analysis.

</details>


### [181] [Counterfactual Explanations on Robust Perceptual Geodesics](https://arxiv.org/abs/2601.18678)
*Eslam Zaher,Maciej Trzaskowski,Quan Nguyen,Fred Roosta*

Main category: cs.LG

TL;DR: PCG提出了一种基于感知黎曼度量的反事实解释方法，通过追踪测地线生成语义有效的反事实，解决了现有方法因距离度量选择不当导致的对抗性扰动问题。


<details>
  <summary>Details</summary>
Motivation: 现有反事实解释方法存在距离度量选择模糊的问题，导致生成的扰动要么缺乏语义意义，要么变成对抗性攻击。现有方法采用平坦或不对齐的几何结构，导致离流形伪影、语义漂移或对抗性崩溃。

Method: PCG方法在鲁棒视觉特征诱导的感知黎曼度量下构造反事实，通过追踪测地线实现反事实生成。这种几何结构与人类感知对齐，惩罚脆弱方向，实现平滑、在流形上、语义有效的转换。

Result: 在三个视觉数据集上的实验表明，PCG优于基线方法，并揭示了在标准度量下隐藏的失败模式。

Conclusion: PCG通过引入感知黎曼度量，解决了反事实解释中的距离度量模糊问题，能够生成语义有效且符合人类感知的反事实解释。

Abstract: Latent-space optimization methods for counterfactual explanations - framed as minimal semantic perturbations that change model predictions - inherit the ambiguity of Wachter et al.'s objective: the choice of distance metric dictates whether perturbations are meaningful or adversarial. Existing approaches adopt flat or misaligned geometries, leading to off-manifold artifacts, semantic drift, or adversarial collapse. We introduce Perceptual Counterfactual Geodesics (PCG), a method that constructs counterfactuals by tracing geodesics under a perceptually Riemannian metric induced from robust vision features. This geometry aligns with human perception and penalizes brittle directions, enabling smooth, on-manifold, semantically valid transitions. Experiments on three vision datasets show that PCG outperforms baselines and reveals failure modes hidden under standard metrics.

</details>


### [182] [ART for Diffusion Sampling: A Reinforcement Learning Approach to Timestep Schedule](https://arxiv.org/abs/2601.18681)
*Yilie Huang,Wenpin Tang,Xunyu Zhou*

Main category: cs.LG

TL;DR: ART-RL：自适应时间重参数化方法，通过强化学习优化扩散模型采样时间步长，提升采样效率和质量


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型使用均匀或手动设计的时间步长网格在有限步数预算下可能不是最优的，需要自适应的时间调度策略来最小化离散化误差

Method: 提出自适应重参数化时间（ART）方法，通过控制重参数化时间变量的时钟速度实现不均匀时间步长；进一步提出ART-RL，将时间变化建模为连续时间强化学习问题，使用高斯策略并通过actor-critic算法学习最优时间调度

Result: 在官方EDM流程基础上，ART-RL在CIFAR-10上显著改善了Fréchet Inception Distance，并在AFHQv2、FFHQ和ImageNet等数据集上表现出良好的迁移性，无需重新训练

Conclusion: ART-RL提供了一种数据驱动的方法来学习扩散模型的最优时间调度策略，能够有效提升采样效率和质量，并具有良好的泛化能力

Abstract: We consider time discretization for score-based diffusion models to generate samples from a learned reverse-time dynamic on a finite grid. Uniform and hand-crafted grids can be suboptimal given a budget on the number of time steps. We introduce Adaptive Reparameterized Time (ART) that controls the clock speed of a reparameterized time variable, leading to a time change and uneven timesteps along the sampling trajectory while preserving the terminal time. The objective is to minimize the aggregate error arising from the discretized Euler scheme. We derive a randomized control companion, ART-RL, and formulate time change as a continuous-time reinforcement learning (RL) problem with Gaussian policies. We then prove that solving ART-RL recovers the optimal ART schedule, which in turn enables practical actor--critic updates to learn the latter in a data-driven way. Empirically, based on the official EDM pipeline, ART-RL improves Fréchet Inception Distance on CIFAR-10 over a wide range of budgets and transfers to AFHQv2, FFHQ, and ImageNet without the need of retraining.

</details>


### [183] [Explainability Methods for Hardware Trojan Detection: A Systematic Comparison](https://arxiv.org/abs/2601.18696)
*Paul Whitten,Francis Wolff,Chris Papachristou*

Main category: cs.LG

TL;DR: 比较了三种硬件木马检测可解释性方法：基于属性的分析、基于案例的推理和模型无关特征归因，发现前两者在领域对齐和基于先例的可解释性方面优于通用特征排名方法。


<details>
  <summary>Details</summary>
Motivation: 硬件木马检测需要准确识别和可解释的解释，以便安全工程师验证和采取行动。本研究旨在比较不同可解释性方法在门级木马检测中的效果。

Method: 在Trust-Hub基准上比较三种可解释性方法：(1) 基于属性的分析：使用31个电路特定特征（门扇入模式、触发器距离、I/O连接性）；(2) 基于案例的推理：使用k近邻算法进行基于先例的解释；(3) 模型无关特征归因：使用LIME、SHAP和梯度方法。

Result: XGBoost分类在11,392个测试样本上达到46.15%精度和52.17%召回率，比先前工作（Hasegawa等：5.13%）精度提高9倍，误报率从5.6%降至0.25%。基于属性的分析提供电路概念解释，基于案例的推理达到97.4%预测与训练样本对应性，LIME和SHAP特征归因相关性高但缺乏电路级上下文。

Conclusion: 基于属性的分析和基于案例的推理方法在领域对齐和基于先例的可解释性方面优于通用特征排名方法，这对可解释AI部署具有重要意义，因为从业者需要验证机器学习预测。

Abstract: Hardware trojan detection requires accurate identification and interpretable explanations for security engineers to validate and act on results. This work compares three explainability categories for gate-level trojan detection on the Trust-Hub benchmark: (1) domain-aware property-based analysis of 31 circuit-specific features from gate fanin patterns, flip-flop distances, and I/O connectivity; (2) case-based reasoning using k-nearest neighbors for precedent-based explanations; and (3) model-agnostic feature attribution (LIME, SHAP, gradient).
  Results show different advantages per approach. Property-based analysis provides explanations through circuit concepts like "high fanin complexity near outputs indicates potential triggers." Case-based reasoning achieves 97.4% correspondence between predictions and training exemplars, offering justifications grounded in precedent. LIME and SHAP provide feature attributions with strong inter-method correlation (r=0.94, p<0.001) but lack circuit-level context for validation.
  XGBoost classification achieves 46.15% precision and 52.17% recall on 11,392 test samples, a 9-fold precision improvement over prior work (Hasegawa et al.: 5.13%) while reducing false positive rates from 5.6% to 0.25%. Gradient-based attribution runs 481 times faster than SHAP but provides similar domain-opaque insights.
  This work demonstrates that property-based and case-based approaches offer domain alignment and precedent-based interpretability compared to generic feature rankings, with implications for XAI deployment where practitioners must validate ML predictions.

</details>


### [184] [Mechanistic Analysis of Catastrophic Forgetting in Large Language Models During Continual Fine-tuning](https://arxiv.org/abs/2601.18699)
*Olaf Yunus Laitinen Imanov*

Main category: cs.LG

TL;DR: 论文通过系统实验揭示了Transformer大语言模型在顺序微调中灾难性遗忘的三种主要机制：注意力权重梯度干扰、中间层表征漂移和损失景观平坦化。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在顺序任务微调中普遍观察到灾难性遗忘现象，但其机制理解仍然有限。本文旨在深入分析Transformer大语言模型在顺序微调中灾难性遗忘的机制基础。

Method: 通过对多个模型规模（109B到400B参数）和任务序列进行系统实验，分析梯度干扰、表征漂移和损失景观变化，使用任务相似性和梯度对齐指标进行相关性分析。

Result: 发现遗忘严重程度与任务相似性高度相关（Pearson r=0.87），约15-23%的注意力头在微调过程中受到严重干扰，较低层表现出更大的易感性。

Conclusion: 研究揭示了灾难性遗忘的三种主要机制，为持续学习系统中针对性缓解策略的开发建立了机制基础。

Abstract: Large language models exhibit remarkable performance across diverse tasks through pre-training and fine-tuning paradigms. However, continual fine-tuning on sequential tasks induces catastrophic forgetting, where newly acquired knowledge interferes with previously learned capabilities. Despite widespread observations of this phenomenon, the mechanistic understanding remains limited. Here, we present a comprehensive mechanistic analysis of catastrophic forgetting in transformer-based LLMs during sequential fine-tuning. Through systematic experiments across multiple model scales (109B to 400B total parameters) and task sequences, we identify three primary mechanisms driving forgetting: gradient interference in attention weights, representational drift in intermediate layers, and loss landscape flattening. We demonstrate that forgetting severity correlates strongly with task similarity (Pearson r = 0.87) and gradient alignment metrics. Our analysis reveals that approximately 15 to 23 percent of attention heads undergo severe disruption during fine-tuning, with lower layers showing greater susceptibility. These findings establish mechanistic foundations for developing targeted mitigation strategies in continual learning systems.

</details>


### [185] [From Fuzzy to Exact: The Halo Architecture for Infinite-Depth Reasoning via Rational Arithmetic](https://arxiv.org/abs/2601.18702)
*Hansheng Ren*

Main category: cs.LG

TL;DR: 论文挑战深度学习优先计算吞吐量而非数值精度的范式，提出精确性假设：通用智能需要任意精度算术计算基础，并引入基于有理数算术的Halo架构来解决当前大语言模型的幻觉和逻辑不一致问题。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习范式过于注重计算吞吐量而忽视数值精度，假设智能源于大规模统计相关性。作者认为这种范式导致大语言模型出现"幻觉"和逻辑不一致问题，这些实际上是IEEE 754浮点数近似误差在深度组合函数中累积的结果。

Method: 提出精确性假设：通用智能（特别是高阶因果推理）需要能够进行任意精度算术的计算基础。引入Halo架构，这是一种基于有理数算术的范式转变，由新型精确推理单元支持。

Result: 在Huginn-0125原型上的实证验证表明，当6000亿参数的BF16基线在混沌系统中崩溃时，Halo架构能够无限期保持零数值发散。这证明了精确算术在减少系统2 AGI逻辑不确定性方面的有效性。

Conclusion: 精确算术是减少系统2通用人工智能逻辑不确定性的先决条件。这项工作挑战了当前深度学习范式，为构建更可靠、逻辑一致的AGI系统提供了新的计算基础。

Abstract: Current paradigms in Deep Learning prioritize computational throughput over numerical precision, relying on the assumption that intelligence emerges from statistical correlation at scale. In this paper, we challenge this orthodoxy. We propose the Exactness Hypothesis: that General Intelligence (AGI), specifically high-order causal inference, requires a computational substrate capable of Arbitrary Precision Arithmetic. We argue that the "hallucinations" and logical incoherence seen in current Large Language Models (LLMs) are artifacts of IEEE 754 floating-point approximation errors accumulating over deep compositional functions. To mitigate this, we introduce the Halo Architecture, a paradigm shift to Rational Arithmetic ($\mathbb{Q}$) supported by a novel Exact Inference Unit (EIU). Empirical validation on the Huginn-0125 prototype demonstrates that while 600B-parameter scale BF16 baselines collapse in chaotic systems, Halo maintains zero numerical divergence indefinitely. This work establishes exact arithmetic as a prerequisite for reducing logical uncertainty in System 2 AGI.

</details>


### [186] [SMART: Scalable Mesh-free Aerodynamic Simulations from Raw Geometries using a Transformer-based Surrogate Model](https://arxiv.org/abs/2601.18707)
*Jan Hagnberger,Mathias Niepert*

Main category: cs.LG

TL;DR: SMART是一种无需仿真网格的神经代理模型，仅使用几何点云即可预测任意位置的物理量，性能媲美甚至优于依赖网格的方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于网格的代理模型需要计算昂贵的仿真网格生成，而无网格方法通常误差较高。需要开发既高效又准确的网格无关替代方案。

Method: 提出SMART模型，将几何和仿真参数编码到共享潜在空间，通过物理解码器关注中间潜在表示，实现几何特征与物理场的联合更新。

Result: 实验表明SMART与依赖网格的方法竞争且常优于它们，展示了工业级仿真的能力。

Conclusion: SMART成功实现了无需仿真网格的高精度物理量预测，为复杂几何的工业仿真提供了高效替代方案。

Abstract: Machine learning-based surrogate models have emerged as more efficient alternatives to numerical solvers for physical simulations over complex geometries, such as car bodies. Many existing models incorporate the simulation mesh as an additional input, thereby reducing prediction errors. However, generating a simulation mesh for new geometries is computationally costly. In contrast, mesh-free methods, which do not rely on the simulation mesh, typically incur higher errors. Motivated by these considerations, we introduce SMART, a neural surrogate model that predicts physical quantities at arbitrary query locations using only a point-cloud representation of the geometry, without requiring access to the simulation mesh. The geometry and simulation parameters are encoded into a shared latent space that captures both structural and parametric characteristics of the physical field. A physics decoder then attends to the encoder's intermediate latent representations to map spatial queries to physical quantities. Through this cross-layer interaction, the model jointly updates latent geometric features and the evolving physical field. Extensive experiments show that SMART is competitive with and often outperforms existing methods that rely on the simulation mesh as input, demonstrating its capabilities for industry-level simulations.

</details>


### [187] [Riemannian AmbientFlow: Towards Simultaneous Manifold Learning and Generative Modeling from Corrupted Data](https://arxiv.org/abs/2601.18728)
*Willem Diepeveen,Oscar Leong*

Main category: cs.LG

TL;DR: 提出Riemannian AmbientFlow框架，能从噪声或线性损坏的观测数据中同时学习概率生成模型和底层非线性数据流形结构。


<details>
  <summary>Details</summary>
Motivation: 在科学和成像应用中，通常无法获得干净样本，只能观测到噪声或线性损坏的测量数据。同时，数据中的潜在结构（如流形几何）对下游科学分析很重要，需要提取。

Method: 基于AmbientFlow的变分推断框架，结合由归一化流诱导的数据驱动黎曼几何，通过拉回度量和黎曼自编码器提取流形结构。

Result: 理论保证表明，在适当的几何正则化和测量条件下，学习到的模型能以可控误差恢复底层数据分布，并获得平滑的双李普希茨流形参数化。平滑解码器可作为逆问题的原则性生成先验，具有恢复保证。

Conclusion: Riemannian AmbientFlow框架能直接从损坏观测中学习生成模型和底层流形结构，在低维合成流形和MNIST数据集上得到实证验证。

Abstract: Modern generative modeling methods have demonstrated strong performance in learning complex data distributions from clean samples. In many scientific and imaging applications, however, clean samples are unavailable, and only noisy or linearly corrupted measurements can be observed. Moreover, latent structures, such as manifold geometries, present in the data are important to extract for further downstream scientific analysis. In this work, we introduce Riemannian AmbientFlow, a framework for simultaneously learning a probabilistic generative model and the underlying, nonlinear data manifold directly from corrupted observations. Building on the variational inference framework of AmbientFlow, our approach incorporates data-driven Riemannian geometry induced by normalizing flows, enabling the extraction of manifold structure through pullback metrics and Riemannian Autoencoders. We establish theoretical guarantees showing that, under appropriate geometric regularization and measurement conditions, the learned model recovers the underlying data distribution up to a controllable error and yields a smooth, bi-Lipschitz manifold parametrization. We further show that the resulting smooth decoder can serve as a principled generative prior for inverse problems with recovery guarantees. We empirically validate our approach on low-dimensional synthetic manifolds and on MNIST.

</details>


### [188] [Self-Distilled Reasoner: On-Policy Self-Distillation for Large Language Models](https://arxiv.org/abs/2601.18734)
*Siyan Zhao,Zhihui Xie,Mengchen Liu,Jing Huang,Guan Pang,Feiyu Chen,Aditya Grover*

Main category: cs.LG

TL;DR: 提出On-Policy Self-Distillation (OPSD)框架，让单个LLM同时扮演教师和学生角色，通过在不同上下文条件下生成推理轨迹，实现自我蒸馏，提升数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有知识蒸馏方法存在两个问题：1) 需要单独的教师模型（通常更大），2) 没有充分利用推理数据集中可用的真实解决方案。受"足够强大的LLM能够基于特权信息进行推理并教导其较弱版本"的直觉启发，提出单模型自我蒸馏框架。

Method: OPSD框架中，单个模型同时作为教师和学生：教师策略基于特权信息（如已验证的推理轨迹），学生策略仅看到问题。训练时在学生自己的推理轨迹上最小化教师和学生分布之间的每token差异。

Result: 在多个数学推理基准测试中，相比强化学习方法（如GRPO）实现了4-8倍的token效率提升，性能优于离策略蒸馏方法。

Conclusion: 提出的On-Policy Self-Distillation框架通过单模型自我蒸馏，有效解决了传统蒸馏方法的分布不匹配问题，显著提升了推理效率和性能。

Abstract: Knowledge distillation improves large language model (LLM) reasoning by compressing the knowledge of a teacher LLM to train smaller LLMs. On-policy distillation advances this approach by having the student sample its own trajectories while a teacher LLM provides dense token-level supervision, addressing the distribution mismatch between training and inference in off-policy distillation methods. However, on-policy distillation typically requires a separate, often larger, teacher LLM and does not explicitly leverage ground-truth solutions available in reasoning datasets. Inspired by the intuition that a sufficiently capable LLM can rationalize external privileged reasoning traces and teach its weaker self (i.e., the version without access to privileged information), we introduce On-Policy Self-Distillation (OPSD), a framework where a single model acts as both teacher and student by conditioning on different contexts. The teacher policy conditions on privileged information (e.g., verified reasoning traces) while the student policy sees only the question; training minimizes the per-token divergence between these distributions over the student's own rollouts. We demonstrate the efficacy of our method on multiple mathematical reasoning benchmarks, achieving 4-8x token efficiency compared to reinforcement learning methods such as GRPO and superior performance over off-policy distillation methods.

</details>


### [189] [Benchmarking Machine Learning Models for IoT Malware Detection under Data Scarcity and Drift](https://arxiv.org/abs/2601.18736)
*Jake Lyon,Ehsan Saeedizade,Shamik Sengupta*

Main category: cs.LG

TL;DR: 该研究评估了四种监督学习模型在IoT恶意软件检测与分类中的效果，发现树基模型在有限训练数据下表现优异，但性能随时间推移而下降。


<details>
  <summary>Details</summary>
Motivation: IoT设备在智能城市、交通和工业系统中的快速扩展加剧了安全漏洞问题。这些设备通常计算资源有限、物理防护薄弱，部署在异构动态网络中，容易成为网络攻击和恶意软件的目标。机器学习为自动化恶意软件检测提供了有前景的方法，但实际部署需要既有效又轻量级的模型。

Method: 研究调查了四种监督学习模型（随机森林、LightGBM、逻辑回归和多层感知器）在IoT-23数据集上的恶意软件检测与分类效果。评估包括二元和多类别分类任务，对训练数据量的敏感性分析，以及时间鲁棒性评估以模拟不断演变的威胁环境。

Result: 树基模型（随机森林和LightGBM）在准确性和泛化能力方面表现优异，即使在有限训练数据下也能保持良好性能。然而，随着恶意软件多样性增加，所有模型的性能都会随时间推移而下降。

Conclusion: 研究强调了自适应、资源高效的机器学习模型对于在现实环境中保护IoT系统的重要性。树基模型在资源受限的IoT环境中具有实用价值，但需要持续更新以适应不断演变的威胁环境。

Abstract: The rapid expansion of the Internet of Things (IoT) in domains such as smart cities, transportation, and industrial systems has heightened the urgency of addressing their security vulnerabilities. IoT devices often operate under limited computational resources, lack robust physical safeguards, and are deployed in heterogeneous and dynamic networks, making them prime targets for cyberattacks and malware applications. Machine learning (ML) offers a promising approach to automated malware detection and classification, but practical deployment requires models that are both effective and lightweight. The goal of this study is to investigate the effectiveness of four supervised learning models (Random Forest, LightGBM, Logistic Regression, and a Multi-Layer Perceptron) for malware detection and classification using the IoT-23 dataset. We evaluate model performance in both binary and multiclass classification tasks, assess sensitivity to training data volume, and analyze temporal robustness to simulate deployment in evolving threat landscapes. Our results show that tree-based models achieve high accuracy and generalization, even with limited training data, while performance deteriorates over time as malware diversity increases. These findings underscore the importance of adaptive, resource-efficient ML models for securing IoT systems in real-world environments.

</details>


### [190] [Trust, Don't Trust, or Flip: Robust Preference-Based Reinforcement Learning with Multi-Expert Feedback](https://arxiv.org/abs/2601.18751)
*Seyed Amir Hosseini,Maryam Abdolali,Amirhosein Tavakkoli,Fardin Ayar,Ehsan Javanmardi,Manabu Tsukada,Mahdi Javanmardi*

Main category: cs.LG

TL;DR: TriTrust-PBRL (TTP) 是一个统一框架，通过联合学习共享奖励模型和专家特定信任参数来处理异构标注者的偏好数据，能自动反转对抗性偏好而非丢弃，在对抗性污染下保持接近最优性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的偏好数据通常来自具有不同可靠性的异构标注者，包括准确、噪声和系统性对抗的标注者。现有的PBRL方法要么平等对待所有反馈，要么试图过滤不可靠来源，但在面对系统性提供错误偏好的对抗性标注者时都会失败。

Method: 引入TriTrust-PBRL (TTP)框架，联合学习共享奖励模型和专家特定信任参数。关键洞察是信任参数在基于梯度的优化过程中自然演变为正值（信任）、接近零（忽略）或负值（翻转），使模型能自动反转对抗性偏好并恢复有用信号，而非仅仅丢弃被污染的反馈。

Result: 在四个不同领域（MetaWorld操作任务和DM Control运动任务）的各种污染场景下进行评估，TTP实现了最先进的鲁棒性，在对抗性污染下保持接近最优性能，而标准PBRL方法则完全失败。TTP成功从包含可靠和对抗性标注者的混合专家池中学习，且仅需标注者标识索引，无需额外专家特征。

Conclusion: TTP提供了一个统一的框架来处理异构标注者偏好数据，通过自动学习信任参数来区分可靠、噪声和对抗性标注者，特别在对抗性污染场景下表现出色，能无缝集成到现有PBRL流程中。

Abstract: Preference-based reinforcement learning (PBRL) offers a promising alternative to explicit reward engineering by learning from pairwise trajectory comparisons. However, real-world preference data often comes from heterogeneous annotators with varying reliability; some accurate, some noisy, and some systematically adversarial. Existing PBRL methods either treat all feedback equally or attempt to filter out unreliable sources, but both approaches fail when faced with adversarial annotators who systematically provide incorrect preferences. We introduce TriTrust-PBRL (TTP), a unified framework that jointly learns a shared reward model and expert-specific trust parameters from multi-expert preference feedback. The key insight is that trust parameters naturally evolve during gradient-based optimization to be positive (trust), near zero (ignore), or negative (flip), enabling the model to automatically invert adversarial preferences and recover useful signal rather than merely discarding corrupted feedback. We provide theoretical analysis establishing identifiability guarantees and detailed gradient analysis that explains how expert separation emerges naturally during training without explicit supervision. Empirically, we evaluate TTP on four diverse domains spanning manipulation tasks (MetaWorld) and locomotion (DM Control) under various corruption scenarios. TTP achieves state-of-the-art robustness, maintaining near-oracle performance under adversarial corruption while standard PBRL methods fail catastrophically. Notably, TTP outperforms existing baselines by successfully learning from mixed expert pools containing both reliable and adversarial annotators, all while requiring no expert features beyond identification indices and integrating seamlessly with existing PBRL pipelines.

</details>


### [191] [HalluGuard: Demystifying Data-Driven and Reasoning-Driven Hallucinations in LLMs](https://arxiv.org/abs/2601.18753)
*Xinyue Zeng,Junhong Lin,Yujun Yan,Feng Guo,Liang Shi,Jun Wu,Dawei Zhou*

Main category: cs.LG

TL;DR: 提出Hallucination Risk Bound理论框架，将幻觉风险分解为数据驱动和推理驱动两部分，并基于此开发HalluGuard检测方法，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: LLM在医疗、法律等高风险领域应用时，幻觉问题严重影响可靠性。现有检测方法通常只针对单一幻觉来源（数据驱动或推理驱动），且依赖任务特定启发式方法，难以推广到复杂场景。

Method: 1. 提出Hallucination Risk Bound统一理论框架，将幻觉风险形式化分解为数据驱动（训练时失配）和推理驱动（推理时不稳定性）两部分；2. 基于此开发HalluGuard检测方法，利用NTK（神经正切核）的几何结构和捕获的表示来联合识别两种幻觉类型。

Result: 在10个多样化基准测试、11个竞争基线方法和9个流行LLM骨干网络上评估HalluGuard，在检测多种LLM幻觉形式方面始终达到最先进的性能。

Conclusion: Hallucination Risk Bound为分析幻觉产生和演化提供了理论基础，而HalluGuard作为基于该理论的检测方法，能够有效联合识别数据驱动和推理驱动的幻觉，具有更好的泛化能力。

Abstract: The reliability of Large Language Models (LLMs) in high-stakes domains such as healthcare, law, and scientific discovery is often compromised by hallucinations. These failures typically stem from two sources: data-driven hallucinations and reasoning-driven hallucinations. However, existing detection methods usually address only one source and rely on task-specific heuristics, limiting their generalization to complex scenarios. To overcome these limitations, we introduce the Hallucination Risk Bound, a unified theoretical framework that formally decomposes hallucination risk into data-driven and reasoning-driven components, linked respectively to training-time mismatches and inference-time instabilities. This provides a principled foundation for analyzing how hallucinations emerge and evolve. Building on this foundation, we introduce HalluGuard, an NTK-based score that leverages the induced geometry and captured representations of the NTK to jointly identify data-driven and reasoning-driven hallucinations. We evaluate HalluGuard on 10 diverse benchmarks, 11 competitive baselines, and 9 popular LLM backbones, consistently achieving state-of-the-art performance in detecting diverse forms of LLM hallucinations.

</details>


### [192] [Beyond Preferences: Learning Alignment Principles Grounded in Human Reasons and Values](https://arxiv.org/abs/2601.18760)
*Henry Bell,Lara Neubauer da Costa Schertel,Bochu Ding,Brandon Fain*

Main category: cs.LG

TL;DR: 提出Grounded Constitutional AI (GCAI)框架，通过结合用户对AI的普遍期望和交互时偏好，生成更具代表性、道德基础更强、更连贯且多元化的AI宪法原则。


<details>
  <summary>Details</summary>
Motivation: 当前LLM对齐框架中的宪法原则确定缺乏公平性和广泛利益相关者参与，需要开发能够代表用户普遍期望和具体交互偏好的宪法生成方法。

Method: 扩展Inverse Constitutional AI (ICAI)方法，从人类偏好标注数据中生成情境原则（利用用户提供的偏好原因），并补充从用户AI价值观陈述中提取的普遍原则，形成统一的宪法生成框架。

Result: 人类参与者更偏好GCAI生成的宪法（无论是个人使用还是广泛治理AI行为），认为其更具道德基础、更连贯、更多元化，优于ICAI生成的宪法。

Conclusion: GCAI框架能够生成更全面代表用户价值观的AI宪法，为LLM对齐提供了更公平、更具代表性的宪法确定方法，有助于开发更符合人类期望的AI系统。

Abstract: A crucial consideration when developing and deploying Large Language Models (LLMs) is the human values to which these models are aligned. In the constitutional framework of alignment models are aligned to a set of principles (the constitution) specified in natural language. However, it is unclear how to fairly determine this constitution with widespread stakeholder input. In this work we propose Grounded Constitutional AI (GCAI), a unified framework for generating constitutions of principles that are representative of both users' general expectations toward AI (general principles) and their interaction-time preferences (contextual principles). We extend the Inverse Constitutional AI (ICAI) approach to generate contextual principles from human preference annotation data by leveraging human-provided \textit{reasons} for their preferences. We supplement these contextual principles with general principles surfaced from user statements of \textit{values} regarding AI. We show that a constitution generated by GCAI is preferred by humans over one generated through ICAI both personally, and for widespread use in governing AI behavior. Additionally participants consider the GCAI constitution to be more morally grounded, coherent, and pluralistic.

</details>


### [193] [PRECISE: Reducing the Bias of LLM Evaluations Using Prediction-Powered Ranking Estimation](https://arxiv.org/abs/2601.18777)
*Abhishek Divekar,Anirban Majumder*

Main category: cs.LG

TL;DR: 提出PRECISE框架，结合少量人工标注和LLM判断来评估搜索/RAG系统质量，显著减少标注需求，降低计算复杂度并校正LLM偏差。


<details>
  <summary>Details</summary>
Motivation: 传统搜索、排序和RAG系统评估需要大量人工相关性标注，成本高昂。虽然LLM可作为自动评估工具，但其固有偏差限制了直接用于指标估计。

Method: 扩展预测驱动推理(PPI)框架，结合少量人工标注查询(100个)和大量未标注示例(10,000个)，通过重新定义指标集成空间将计算复杂度从O(2^|C|)降至O(2^K)，其中|C|为语料库规模，K为较小常数。

Result: 在多个检索数据集上的实验表明，该方法显著降低了Precision@K等关键业务指标的估计方差，在低资源设置下有效校正了LLM偏差，大幅减少了标注需求。

Conclusion: PRECISE框架为搜索/RAG系统评估提供了一种高效、可靠的统计方法，通过结合少量人工标注和LLM判断，在保证质量的同时大幅降低评估成本。

Abstract: Evaluating the quality of search, ranking and RAG systems traditionally requires a significant number of human relevance annotations. In recent times, several deployed systems have explored the usage of Large Language Models (LLMs) as automated judges for this task while their inherent biases prevent direct use for metric estimation. We present a statistical framework extending Prediction-Powered Inference (PPI) that combines minimal human annotations with LLM judgments to produce reliable estimates of metrics which require sub-instance annotations. Our method requires as few as 100 human-annotated queries and 10,000 unlabeled examples, reducing annotation requirements significantly compared to traditional approaches. We formulate our proposed framework (PRECISE) for inference of relevance uplift for an LLM-based query reformulation application, extending PPI to sub-instance annotations at the query-document level. By reformulating the metric-integration space, we reduced the computational complexity from O(2^|C|) to O(2^K), where |C| represents corpus size (in order of millions). Detailed experiments across prominent retrieval datasets demonstrate that our method reduces the variance of estimates for the business-critical Precision@K metric, while effectively correcting for LLM bias in low-resource settings.

</details>


### [194] [Teaching Models to Teach Themselves: Reasoning at the Edge of Learnability](https://arxiv.org/abs/2601.18778)
*Shobhita Sundaram,John Quan,Ariel Kwiatkowski,Kartik Ahuja,Yann Ollivier,Julia Kempe*

Main category: cs.LG

TL;DR: SOAR框架通过元强化学习让LLM生成自动课程，在初始成功率极低的问题上实现自我提升，无需额外标注数据。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在初始成功率低的困难问题上会陷入学习停滞，因为缺乏训练信号。研究探索预训练LLM是否能利用潜在知识为无法解决的问题生成自动课程。

Method: 提出SOAR框架：教师模型为学生模型生成合成问题，根据学生在困难问题子集上的进步获得奖励。采用基于实际学生进步的接地奖励，而非内在代理奖励。

Result: 在数学基准最困难子集（0/128成功率）上：1）实现了双层元RL解锁稀疏二元奖励下的学习；2）接地奖励优于先前内在奖励方案，避免不稳定和多样性崩溃；3）生成问题的结构质量和明确性比解答正确性更重要。

Conclusion: 模型生成有用"垫脚石"的能力不需要预先具备解决困难问题的能力，这为无需额外标注数据即可突破推理瓶颈提供了原则性路径。

Abstract: Can a model learn to escape its own learning plateau? Reinforcement learning methods for finetuning large reasoning models stall on datasets with low initial success rates, and thus little training signal. We investigate a fundamental question: Can a pretrained LLM leverage latent knowledge to generate an automated curriculum for problems it cannot solve? To explore this, we design SOAR: A self-improvement framework designed to surface these pedagogical signals through meta-RL. A teacher copy of the model proposes synthetic problems for a student copy, and is rewarded with its improvement on a small subset of hard problems. Critically, SOAR grounds the curriculum in measured student progress rather than intrinsic proxy rewards. Our study on the hardest subsets of mathematical benchmarks (0/128 success) reveals three core findings. First, we show that it is possible to realize bi-level meta-RL that unlocks learning under sparse, binary rewards by sharpening a latent capacity of pretrained models to generate useful stepping stones. Second, grounded rewards outperform intrinsic reward schemes used in prior LLM self-play, reliably avoiding the instability and diversity collapse modes they typically exhibit. Third, analyzing the generated questions reveals that structural quality and well-posedness are more critical for learning progress than solution correctness. Our results suggest that the ability to generate useful stepping stones does not require the preexisting ability to actually solve the hard problems, paving a principled path to escape reasoning plateaus without additional curated data.

</details>


### [195] [POPE: Learning to Reason on Hard Problems via Privileged On-Policy Exploration](https://arxiv.org/abs/2601.18779)
*Yuxiao Qu,Amrith Setlur,Virginia Smith,Ruslan Salakhutdinov,Aviral Kumar*

Main category: cs.LG

TL;DR: 提出POPE方法，利用特权信息（如人类解决方案）引导强化学习在困难问题上的探索，解决传统RL方法在硬问题上探索失败的问题


<details>
  <summary>Details</summary>
Motivation: 当前强化学习方法在训练LLMs时，对于困难问题经常无法探索到任何正确的解决方案，导致零奖励和没有学习信号。传统的探索方法（如熵奖励、重要性比率裁剪等）无法解决这个问题，而混合简单和困难问题训练反而会产生"射线干扰"效应，阻碍在困难问题上的进展。

Method: POPE（特权在线探索）方法：利用人类或其他oracle解决方案作为特权信息来引导困难问题的探索。通过在困难问题前添加oracle解决方案的前缀，使RL能够在引导的rollouts中获得非零奖励。关键是通过指令跟随和推理的协同作用，将学习到的行为迁移回原始的无引导问题。

Result: POPE方法显著扩展了可解决问题的集合，并在具有挑战性的推理基准测试中大幅提升了性能表现。

Conclusion: POPE通过利用特权信息引导探索，有效解决了RL在困难推理问题上的探索失败问题，提供了一种将oracle解决方案作为探索引导而非训练目标的新方法，相比传统方法具有更好的效果。

Abstract: Reinforcement learning (RL) has improved the reasoning abilities of large language models (LLMs), yet state-of-the-art methods still fail to learn on many training problems. On hard problems, on-policy RL rarely explores even a single correct rollout, yielding zero reward and no learning signal for driving improvement. We find that natural solutions to remedy this exploration problem from classical RL, such as entropy bonuses, more permissive clipping of the importance ratio, or direct optimization of pass@k objectives, do not resolve this issue and often destabilize optimization without improving solvability. A natural alternative is to leverage transfer from easier problems. However, we show that mixing easy and hard problems during RL training is counterproductive due to ray interference, where optimization focuses on already-solvable problems in a way that actively inhibits progress on harder ones. To address this challenge, we introduce Privileged On-Policy Exploration (POPE), an approach that leverages human- or other oracle solutions as privileged information to guide exploration on hard problems, unlike methods that use oracle solutions as training targets (e.g., off-policy RL methods or warmstarting from SFT). POPE augments hard problems with prefixes of oracle solutions, enabling RL to obtain non-zero rewards during guided rollouts. Crucially, the resulting behaviors transfer back to the original, unguided problems through a synergy between instruction-following and reasoning. Empirically, POPE expands the set of solvable problems and substantially improves performance on challenging reasoning benchmarks.

</details>


### [196] [Multi-Objective Reinforcement Learning for Efficient Tactical Decision Making for Trucks in Highway Traffic](https://arxiv.org/abs/2601.18783)
*Deepthi Pathare,Leo Laine,Morteza Haghir Chehreghani*

Main category: cs.LG

TL;DR: 提出基于PPO的多目标强化学习框架，为重型卡车学习连续帕累托最优策略集，平衡安全、能效和时间效率的权衡


<details>
  <summary>Details</summary>
Motivation: 高速公路驾驶中，重型车辆需要在安全、效率和运营成本之间做出复杂权衡决策。传统的标量奖励函数通过聚合这些竞争目标，往往模糊了它们之间的权衡结构，需要更明确的权衡表示方法。

Method: 基于近端策略优化（PPO）的多目标强化学习框架，在卡车战术决策的模拟平台上学习连续的政策集合，明确表示安全（碰撞和成功完成）、能效（能源成本）和时间效率（驾驶员成本）三个冲突目标之间的权衡。

Result: 该方法学习到平滑且可解释的连续帕累托最优策略集，能够捕获三个冲突目标之间的权衡关系。得到的帕累托前沿平滑可解释，允许在不同冲突目标之间灵活选择驾驶行为。

Conclusion: 该框架无需重新训练即可在不同驾驶策略之间无缝切换，为自动驾驶卡车应用提供了稳健且自适应的决策策略，能够明确表示和平衡安全、能效和时间效率之间的复杂权衡。

Abstract: Balancing safety, efficiency, and operational costs in highway driving poses a challenging decision-making problem for heavy-duty vehicles. A central difficulty is that conventional scalar reward formulations, obtained by aggregating these competing objectives, often obscure the structure of their trade-offs. We present a Proximal Policy Optimization based multi-objective reinforcement learning framework that learns a continuous set of policies explicitly representing these trade-offs and evaluates it on a scalable simulation platform for tactical decision making in trucks. The proposed approach learns a continuous set of Pareto-optimal policies that capture the trade-offs among three conflicting objectives: safety, quantified in terms of collisions and successful completion; energy efficiency and time efficiency, quantified using energy cost and driver cost, respectively. The resulting Pareto frontier is smooth and interpretable, enabling flexibility in choosing driving behavior along different conflicting objectives. This framework allows seamless transitions between different driving policies without retraining, yielding a robust and adaptive decision-making strategy for autonomous trucking applications.

</details>


### [197] [Reuse your FLOPs: Scaling RL on Hard Problems by Conditioning on Very Off-Policy Prefixes](https://arxiv.org/abs/2601.18795)
*Amrith Setlur,Zijian Wang,Andrew Cohen,Paria Rashidinejad,Sang Michael Xie*

Main category: cs.LG

TL;DR: PrefixRL：通过重用离策略轨迹的前缀来提升强化学习效率，避免离策略不稳定性，在困难推理问题上实现2倍加速和3倍奖励提升


<details>
  <summary>Details</summary>
Motivation: 传统RL方法在困难推理问题上效率低下，因为正确轨迹稀少、策略梯度消失、学习停滞。需要重用旧采样计算（来自先前推理或RL训练）来提升效率，但标准离策略方法会导致优化不稳定。

Method: 提出PrefixRL：基于成功离策略轨迹的前缀进行条件化，然后运行在策略RL来完成剩余部分，避免离策略不稳定性。通过调整前缀长度来调节问题难度，并创建自我改进循环（使用基础模型进行拒绝采样获取离策略轨迹）。

Result: 在困难推理问题上，PrefixRL达到相同训练奖励的速度比最强基线（离策略数据SFT后RL）快2倍（即使考虑初始拒绝采样计算），最终奖励提升3倍。发现后泛化现象：仅在前缀问题上训练能泛化到无前缀性能，且学习策略常与前缀不同。

Conclusion: PrefixRL通过重用离策略轨迹前缀有效提升RL效率，避免不稳定性，在困难推理问题上显著优于现有方法，且具有灵活性（可跨模型族使用）。

Abstract: Typical reinforcement learning (RL) methods for LLM reasoning waste compute on hard problems, where correct on-policy traces are rare, policy gradients vanish, and learning stalls. To bootstrap more efficient RL, we consider reusing old sampling FLOPs (from prior inference or RL training) in the form of off-policy traces. Standard off-policy methods supervise against off-policy data, causing instabilities during RL optimization. We introduce PrefixRL, where we condition on the prefix of successful off-policy traces and run on-policy RL to complete them, side-stepping off-policy instabilities. PrefixRL boosts the learning signal on hard problems by modulating the difficulty of the problem through the off-policy prefix length. We prove that the PrefixRL objective is not only consistent with the standard RL objective but also more sample efficient. Empirically, we discover back-generalization: training only on prefixed problems generalizes to out-of-distribution unprefixed performance, with learned strategies often differing from those in the prefix. In our experiments, we source the off-policy traces by rejection sampling with the base model, creating a self-improvement loop. On hard reasoning problems, PrefixRL reaches the same training reward 2x faster than the strongest baseline (SFT on off-policy data then RL), even after accounting for the compute spent on the initial rejection sampling, and increases the final reward by 3x. The gains transfer to held-out benchmarks, and PrefixRL is still effective when off-policy traces are derived from a different model family, validating its flexibility in practical settings.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [198] [Physics-guided curriculum learning for the identification of reaction-diffusion dynamics from partial observations](https://arxiv.org/abs/2601.17382)
*Hanyu Zhou,Yuansheng Cao,Yaomin Zhao*

Main category: physics.comp-ph

TL;DR: 提出CLIP方法，基于物理信息神经网络和课程学习，用于反应-扩散系统的参数估计和隐藏状态重建


<details>
  <summary>Details</summary>
Motivation: 反应-扩散系统在自然界和工程中广泛存在，但参数估计困难，特别是当观测数据稀疏、有噪声且仅限于部分状态变量时

Method: 基于物理信息神经网络，采用课程学习策略，从反应主导区域逐步扩展到完整的时空动力学，使用锚定扩展转移策略

Result: 在三个经典反应-扩散基准测试中，CLIP比基线方法获得更准确和鲁棒的识别；成功应用于细菌Min系统动力学推断

Conclusion: CLIP框架有效解决了反应-扩散系统的参数估计问题，课程学习和锚定转移策略提高了可训练性和收敛性

Abstract: Reaction-diffusion (RD) systems provide fundamental models for understanding self-organized spatiotemporal patterns across diverse natural and engineered settings, but reliable parameter estimation remains challenging, particularly when observations are sparse, noisy, and restricted to a subset of state variables. Based on physics-informed neural networks (PINNs), a physics-guided Curriculum Learning Identification via PINNs (CLIP) method is introduced in this work, for joint parameter inference and hidden state reconstruction. Leveraging the physical separability of RD systems, the CLIP training progresses from reaction-dominated regimes to full spatiotemporal dynamics using curriculum learning and an anchored widening transfer strategy. Across three canonical reaction-diffusion benchmarks, CLIP achieves more accurate and robust identification than baseline methods. Furthermore, the CLIP framework is successfully applied to infer the dynamics of Min system in bacteria, where only membrane bound species are observed and key kinetic rates span multiple orders of magnitude. Moreover, ablation experiments and loss landscape analyses provide mechanistic evidence that the curriculum stages and anchored transfer enhance trainability and convergence.

</details>


### [199] [Conformal Quantile Regression for Probabilistic Constitutive Modeling of Anisotropic Soft Materials](https://arxiv.org/abs/2601.17437)
*Bahador Bahmani*

Main category: physics.comp-ph

TL;DR: 提出一种概率性数据驱动本构建模框架，用于各向异性软材料，通过保形分位数回归量化预测不确定性，确保热力学一致性并保持计算效率。


<details>
  <summary>Details</summary>
Motivation: 生物软组织存在显著的个体间差异，需要自动化本构建模进行个性化分析。现有数据驱动方法多为确定性模型，无法量化预测不确定性，限制了其在机械分析中的可靠性。

Method: 基于应变不变量和多重凸性公式，应用保形分位数回归处理张量场，建立概率性数据驱动本构模型。该方法可即插即用地为现有确定性模型添加概率预测，无需假设数据分布。

Result: 该方法在多个基准数据集上得到验证，能够提供可靠的不确定性量化，在包括外推区域在内的各种情况下保持稳健预测性能，且计算效率高。

Conclusion: 提出的概率性本构建模框架能够有效处理生物软组织的内在随机性，为大规模机械模拟中的不确定性传播提供实用解决方案，提高了患者特异性分析的可靠性。

Abstract: Biological soft tissues exhibit substantial inter-subject variability, making the automation of constitutive material modeling essential for patient-specific analysis and design. Such materials are not only highly nonlinear but also display intrinsic stochasticity arising from their complex and heterogeneous microstructure. Despite recent advances in data-driven constitutive modeling, most existing approaches remain deterministic and fail to quantify predictive uncertainty, thereby limiting their reliability in downstream mechanical analyses. In this work, we propose a probabilistic, data-driven constitutive modeling framework for anisotropic soft materials that explicitly accounts for uncertainty through conformalized quantile regression applied to tensor-valued fields. The proposed framework is built upon a strain-invariant, polyconvex formulation that ensures thermodynamic consistency and promotes robust predictive performance, including in extrapolative regimes. A key advantage of the proposed approach is its simplicity: it can be applied in a plug-and-play manner to endow existing deterministic models with probabilistic predictions, while remaining distribution-free and requiring no assumptions on the underlying data distribution. Moreover, the method is straightforward to train, scalable to models with a large number of parameters, and avoids Monte Carlo sampling at inference, making it computationally efficient and well suited for uncertainty propagation in large-scale mechanical simulations. The proposed method is validated using several benchmark datasets synthesized and collected from the literature.

</details>


### [200] [Frequency-domain general synthetic iterative scheme for efficient simulation of oscillatory rarefied gas flows](https://arxiv.org/abs/2601.17484)
*Pengshuo Li,Lei Wu*

Main category: physics.comp-ph

TL;DR: 提出频率域通用合成迭代方案(GSIS)用于高效模拟振荡稀薄气体流动，通过同时求解介观动力学方程和宏观合成方程实现超收敛和渐近保持特性。


<details>
  <summary>Details</summary>
Motivation: MEMS中常见的振荡稀薄气体流动数值模拟面临挑战，因为Boltzmann动力学方程具有时间依赖性和高维特性，传统方法计算效率低下。

Method: 聚焦周期性稳态，采用频率域GSIS方法，同时求解介观动力学方程和宏观合成方程。动力学方程提供高阶本构关系，合成方程加速收敛到周期性稳态。

Result: GSIS实现超收敛和渐近保持特性，可在粗网格上使用，在近连续流区域比传统动力学方案快三个数量级。

Conclusion: GSIS方法为振荡稀薄气体流动提供了高效数值模拟方案，结合傅里叶稳定性分析和Chapman-Enskog展开验证了其快速收敛和渐近保持特性。

Abstract: Oscillatory rarefied gas flows are frequently encountered in MEMS, and their efficient numerical simulation remains a major challenge due to the time dependent nature of the problem and the high dimensionality of the Boltzmann kinetic equation. Here, we address this challenge by focusing on the periodic steady state and solving the resulting problem using the frequency domain general synthetic iterative scheme (GSIS). The key idea of GSIS is to simultaneously solve the mesoscopic kinetic equation and the macroscopic synthetic equation. The kinetic equation provides high-order constitutive relations, beyond those given by the Newton law of viscosity and the Fourier law of heat conduction, to the synthetic equation. In turn, the synthetic equation, which converges to the periodic steady state much faster than the kinetic equation, boosts the evolution of the kinetic equation toward the periodic steady state. As a result, super convergence is achieved, together with an asymptotic preserving property that allows the use of coarse spatial grids. The analytical Fourier stability analysis and the Chapman-Enskog expansion, together with challenging numerical simulations, are employed to demonstrate the fast convergence and asymptotic-preserving properties of GSIS, revealing that it can be three orders of magnitude faster than conventional kinetic schemes in near continuum flow regimes.

</details>


### [201] [Smooth Polar B-Splines with High-Order Regularity at the Origin](https://arxiv.org/abs/2601.17841)
*Peiyou Jiang,Roman Hatzky,Zhixin Lu,Eric Sonnendrücker,Matthias Borchardt,Ralf Kleiber,Martin Campos Pinto,Ronald Remmerswaal*

Main category: physics.comp-ph

TL;DR: 提出一种在单位圆盘上使用极坐标的平滑B样条离散化方法，通过调和极函数构造"平滑极坐标样条"，修正了标准张量积B样条在原点处因坐标奇异性导致的正则性损失。


<details>
  <summary>Details</summary>
Motivation: 标准张量积B样条在极坐标下存在原点处的正则性损失问题，这会影响物理模拟的数值稳定性、矩阵条件数、电荷守恒和特征值计算精度。

Method: 通过Galerkin投影将调和极函数（源于笛卡尔单项式的极坐标表示）投影到最内层径向区域的标准张量积B样条基上，构造平滑极坐标样条。径向分量精确再现r^l（0≤l≤p），满足原点附近的规则性条件。

Result: 平滑极坐标样条保持了标准张量积B样条在原点外的特性，改善了质量和刚度矩阵的条件数，在粒子网格模拟中守恒电荷并减少统计误差，消除了特征值问题中的虚假特征值。

Conclusion: 该方法为极坐标下的物理模拟提供了稳健、高阶、高效的张量积B样条适配方案，通过保持局部支持和稀疏性，在保持计算效率的同时解决了原点奇异性问题。

Abstract: We introduce a smooth B-spline discretization in polar coordinates on the unit disc that corrects the loss of regularity present at the origin caused by the coordinate singularity in standard tensor-product B-spline formulations. The method constructs "smooth polar splines" via a Galerkin projection of harmonic polar functions $S_l^{-m}(r,θ) := r^l \sin(mθ)$ and $S_l^{m}(r,θ) := r^l \cos(mθ)$, derived from the polar representation of Cartesian monomials, onto the central tensor-product B-spline basis in the innermost radial region. The radial component reproduces $r^l$ exactly for $0 \le l \leq p$, where $p$ is the B-spline degree, satisfying the near-origin regularity condition. However, exact compatibility with $C^\infty$-regularity at the origin is recovered only in the limit $Δθ\to 0$, when the angular component resolves all angular harmonics accurately. The smooth polar splines are linear combinations of standard tensor-product B-splines and lie in the same function space, enabling mapping between the $C^\infty$-regular subspace and the original discretization space via an exact prolongation operator and a corresponding restriction operator acting on the discrete variables. They match standard tensor-product B-splines away from the origin, preserve orthogonality among the newly constructed origin-centered basis functions, and maintain local support and sparse matrices. This smoothness and locality improve the conditioning of mass and stiffness matrices, conserve charge, and reduce statistical errors in particle-in-cell simulations near the origin, while eliminating spurious eigenvalues in eigenvalue problems. The approach provides a robust, high-order, and efficient adaptation of tensor-product B-splines for polar coordinates in physics simulations.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [202] [The Double Covariance Model: A Stochastic Reconstruction of Quantum Entangled States via Interplay of Micro-Macro Time Scales](https://arxiv.org/abs/2601.17070)
*Andrei Khrennikov*

Main category: quant-ph

TL;DR: 提出一个从经典随机过程生成纠缠量子态的具体数学框架，通过双尺度时间方案和双协方差模型，将量子态视为底层经典概率空间的四阶矩结构


<details>
  <summary>Details</summary>
Motivation: 探索量子纠缠的经典起源，试图从经典随机过程的角度解释量子关联现象，为量子理论提供新的经典概率基础

Method: 采用双尺度时间方案（微观时间和宏观时间），提出双协方差模型（DCM），将复合系统的密度算子表示为两个底层随机过程X(t)和Y(t)的关联

Result: 证明了任何复合系统的密度算子ρ_AB都可以从两个底层随机过程的关联中推导出来，量子关联作为从底层微观关联中涌现的宏观关联

Conclusion: 量子理论的基本性质可以通过将量子态视为底层经典概率空间的四阶矩结构来重现，为量子-经典对应关系提供了具体的数学框架

Abstract: This article presents a concrete mathematical framework for the generation of entangled quantum states from classical stochastic processes. We demonstrate that any density operator $ρ_{AB}$ of a composite system can be derived from the correlations between two underlying stochastic processes, $X(t)$ and $Y(t)$, representing the random fluctuations of its subsystems. This construction utilizes a two-scale temporal scheme - micro and macro time - where quantum correlations emerge as macro-correlations derived from underlying micro-correlations. We propose the Double Covariance Model (DCM), which reproduces the fundamental properties of quantum theory by treating the quantum state as the fourth-order moment structure of an underlying classical probability space.

</details>


### [203] [Qhronology: A Python package for studying quantum models of closed timelike curves](https://arxiv.org/abs/2601.17459)
*Lachlan G. Bishop*

Main category: quant-ph

TL;DR: Qhronology是一个用于研究闭合类时曲线量子模型和模拟量子信息处理的Python科学计算包，提供分析反时序时间旅行量子理论的功能，同时作为完整的量子电路模拟器。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在介绍Qhronology这一新型科学计算包，该包专门用于研究闭合类时曲线的量子模型和模拟量子信息处理，填补了在分析量子时间旅行理论和进行量子电路模拟方面的工具空白。

Method: 论文首先讨论了Qhronology的设计理念和架构，然后概述了其基本使用方法，并通过一系列示例展示了其在多种不同场景下的各种功能。最后通过简单的经验基准测试来表征该包电路模拟组件的性能。

Result: Qhronology提供了一个全面的框架来分析反时序时间旅行的量子理论，包括计算时间悖论的量子解决方案。它还能作为完整的量子电路模拟器，支持数值和符号两种方式检查量子算法和协议。

Conclusion: Qhronology是一个功能强大的Python包，为研究闭合类时曲线的量子模型和模拟量子信息处理提供了全面的工具集，其设计考虑了易用性和性能，并通过基准测试验证了其电路模拟能力。

Abstract: Qhronology is a novel scientific-computing package for studying quantum models of closed timelike curves (CTCs) and simulating general quantum information processing and computation. Written in Python, the program provides a comprehensive framework for analyzing quantum theories of antichronological time travel, including functionality to calculate quantum resolutions to temporal paradoxes. It also operates as a complete quantum circuit simulator, enabling the examination of quantum algorithms and protocols in both numerical and symbolic capacities. In this paper, we formally introduce Qhronology, beginning with discussion on aspects of its design philosophy and architecture. An overview of its basic usage is then presented, along with a collection of examples demonstrating its various capabilities within a variety of distinct contexts. Lastly, the performance of the package's circuit simulation component is characterized by way of some simple empirical benchmarking.

</details>


### [204] [A pedagogical derivation of the first-order effective Hamiltonian for the two-mode Jaynes-Cummings model](https://arxiv.org/abs/2601.17208)
*Alejandro R. Urzúa*

Main category: quant-ph

TL;DR: 该论文提供了二模Jaynes-Cummings模型在色散区的一阶有效哈密顿量的教学推导，通过微扰变换消除非共振项，揭示原子诱导的场模间有效分束器相互作用。


<details>
  <summary>Details</summary>
Motivation: 论文旨在提供清晰、自洽的教学推导，使有效哈密顿量方法在多模光-物质相互作用的教学和学习中更易理解，强调物理洞察力而非复杂计算。

Method: 采用微扰幺正变换消除非共振原子-场项，得到色散频率移动，然后通过二模玻色空间的简单几何旋转对角化哈密顿量，提供对底层动力学的透明解释。

Result: 推导出的一阶有效哈密顿量显示原子诱导的有效分束器相互作用，哈密顿量对角化后能清晰解释系统动力学，为多模光-物质相互作用提供了教学友好的理论框架。

Conclusion: 该工作成功提供了二模Jaynes-Cummings模型色散区有效哈密顿量的教学推导，强调清晰性和物理洞察力，使有效哈密顿量方法在多模光-物质相互作用教学中更易理解。

Abstract: This work presents a pedagogical and self-contained derivation of the first-order effective Hamiltonian for the two-mode Jaynes-Cummings model in the dispersive regime. A perturbative unitary transformation removes nonresonant atom-field terms, revealing dispersive frequency shifts leading to an atom-induced effective beam-splitter interaction between the field modes. The resulting Hamiltonian is diagonalized through a simple geometric rotation in the two-mode bosonic space, providing a transparent interpretation of the underlying dynamics. The exposition emphasized clarity and physical insight, making effective Hamiltonian methods accessible for teaching and learning in multimode light-matter interactions.

</details>


### [205] [Feedback-Based Quantum Control for Safe and Synergistic Drug Combination Design](https://arxiv.org/abs/2601.18082)
*Mai Nguyen Phuong Nhi,Lan Nguyen Tran,Le Bin Ho*

Main category: quant-ph

TL;DR: 量子控制框架用于优化药物组合，考虑药物相互作用，使用FALQON算法解决最大安全子集和协同约束优化问题


<details>
  <summary>Details</summary>
Motivation: 药物相互作用严重影响联合疗法的安全性和有效性，尽管有大型DDI数据库，但选择平衡安全性、疗效和方案大小的最佳多药组合仍是一个具有挑战性的组合优化问题

Method: 提出基于量子控制的DDI感知药物组合优化框架，将有害和协同相互作用编码为伊辛哈密顿量中的惩罚和奖励项，使用无梯度变分方法FALQON算法进行优化

Result: 使用Drugs.com和SYNERGxDB数据的数值模拟显示，对于包括COVID-19案例研究在内的临床相关药物集，算法能高效收敛并获得高质量解决方案

Conclusion: 量子控制框架为DDI感知的药物组合优化提供了一种有前景的方法，能够解决临床相关的组合优化问题

Abstract: Drug-drug interactions (DDIs) strongly affect the safety and efficacy of combination therapies. Despite the availability of large DDI databases, selecting optimal multi-drug combinations that balance safety, therapeutic benefit, and regimen size remains a challenging combinatorial optimization problem. Here, we present a quantum-control-based framework for DDI-aware drug combination optimization, in which known harmful and synergistic interactions are encoded into Ising Hamiltonians as penalties and rewards, respectively. The optimization is performed using the feedback-based quantum algorithm FALQON, a gradient-free variational approach. We study two clinically motivated tasks: the Maximum Safe Subset problem and the Synergy-Constrained Optimization problem. Numerical simulations using interaction data from Drugs.com and SYNERGxDB demonstrate efficient convergence and high-quality solutions for clinically relevant drug sets, including COVID-19 case studies.

</details>


### [206] [The Universe as a Detector: A Quantum Filtering Formulation of the Diósi-Penrose Model](https://arxiv.org/abs/2601.17384)
*John Gough,Dylon Rees*

Main category: quant-ph

TL;DR: 该论文通过量子随机模型和时空零差探测，从量子滤波角度重新审视Diósi-Penrose问题，建立了量子Kushner-Stratonovich方程来描述波函数坍缩过程。


<details>
  <summary>Details</summary>
Motivation: 传统Diósi-Penrose问题假设背景引力涨落，本文旨在避免这种假设，从量子测量和滤波理论的角度重新构建波函数坍缩的连续时间模型。

Method: 采用开放量子随机模型，通过时空零差探测连续输出正交分量，推导出量子Kushner-Stratonovich方程，该方程形式类似于量子退相干理论中的连续时间波函数坍缩模型。

Result: 建立了基于量子滤波理论的波函数坍缩新框架，避免了传统方法对背景引力涨落的依赖，为Diósi-Penrose问题提供了不同的理论视角。

Conclusion: 通过量子随机模型和滤波理论可以重新表述波函数坍缩问题，为理解量子引力与测量理论的联系提供了新的数学工具和理论框架。

Abstract: We consider the Diósi-Penrose problem but rather than postulating background gravitational fluctuations, we instead consider the quantum filter that arises from space-time homodyning the continuum of output quadrature described in the open quantum stochastic model presented here. This is described by a quantum Kushner-Stratonovich equation, typical of the form appearing in continuous-time collapse of the wave-function models in Quantum Decoherence Theory

</details>


### [207] [Non-Markovian Decoherence Times in Finite-Memory Environments](https://arxiv.org/abs/2601.17394)
*Ramandeep Dewan*

Main category: quant-ph

TL;DR: 该论文提出了一种基于时间非局域退相干泛函的通用退相干理论框架，揭示了有限记忆环境下退相干时间的普适平方根标度律，并区分了退相干速率与量子特征消失的关系。


<details>
  <summary>Details</summary>
Motivation: 传统马尔可夫主方程假设环境记忆为零，预测指数退相干，但这对应物理奇异极限。实际环境具有有限时间关联，需要建立更一般的非马尔可夫退相干理论。

Method: 使用由环境力关联函数决定的时间非局域退相干泛函描述退相干，马尔可夫动力学作为极限情况恢复。分析高斯关联、软幂律和Ornstein-Uhlenbeck环境，通过伪模映射进行精确数值模拟。

Result: 有限记忆环境下退相干泛函呈现模型无关的二次短时增长，操作定义的退相干时间与环境关联时间的平方根成正比。指数退相干仅在无记忆极限下出现，退相干速率与不可逆熵产生不一定一致。

Conclusion: 建立了超越马尔可夫近似的通用退相干理论框架，揭示了有限记忆环境下退相干时间的普适标度律，提出了从动力学数据提取环境关联时间的操作化方法。

Abstract: Decoherence is often modeled using Markovian master equations that predict exponential suppression of coherence and are frequently used as effective bounds on quantum behavior in complex environments. Such descriptions, however, correspond to the singular physical limit of vanishing environmental memory. Here we formulate decoherence using a general time-nonlocal decoherence functional determined solely by the environmental force correlation function, with Markovian dynamics recovered explicitly as a limiting case.
  For arbitrary stationary environments with finite temporal correlations, we show that the decoherence functional exhibits quadratic short-time growth that is model-independent within the finite-memory class considered. Consequently, the decoherence time defined operationally-without assuming exponential decay-scales as the square root of the environmental correlation time, independent of the detailed form of the bath correlation kernel.
  These results are illustrated analytically for Gaussian-correlated, soft power-law, and Ornstein-Uhlenbeck environments. In the Ornstein-Uhlenbeck case, the non-Markovian dynamics admit an exact analytical closure, yielding a closed evolution equation for the coherence. Exact numerical simulations based on a pseudomode mapping confirm the predicted scaling and show that exponential decoherence emerges only in the memoryless limit.
  Beyond coherence decay, we distinguish decoherence rates from observable loss of quantum signatures by analyzing purity and von Neumann entropy dynamics. We show that suppression of a specific coherence element need not coincide with irreversible entropy production. Finally, we introduce an inferred-memory perspective in which the environmental correlation time is treated as an operationally extractable parameter from dynamical data.

</details>


### [208] [Efficient Trotter-Suzuki Schemes for Long-time Quantum Dynamics](https://arxiv.org/abs/2601.18756)
*Marko Maležič,Johann Ostmeyer*

Main category: quant-ph

TL;DR: 提出一种构建高效高阶Trotter-Suzuki方案的框架，通过识别结构并直接优化参数，发现了比传统方法更高效的4阶和6阶方案，在Heisenberg模型和量子谐振子中表现出色。


<details>
  <summary>Details</summary>
Motivation: 准确模拟多体系统的长时间动力学在经典和量子计算中都是挑战，因为Trotter误差会累积。低阶Trotter-Suzuki分解虽然易于实现，但其快速增长的误差限制了长时间可观测量的获取。

Method: 通过识别高阶Trotter-Suzuki方案的结构，直接在参数的高维空间中进行优化，构建高效的分解方案。该方法能够发现比Suzuki和Yoshida传统构造更高效的新方案。

Result: 推荐了两个新颖高效的4阶和6阶方案，在Heisenberg模型和量子谐振子中表现出色。即使在较大时间步长下，这些方案也超越了Leapfrog等传统低阶方案。发现系数更均匀的分解方案在长时间误差累积方面表现更好。

Conclusion: 提出的优化框架能够构建比传统方法更高效的高阶Trotter-Suzuki方案，推荐的4阶和6阶方案在实际应用中表现出色，特别是系数更均匀的方案在长时间模拟中具有更好的误差控制能力。

Abstract: Accurately simulating long-time dynamics of many-body systems is a challenge in both classical and quantum computing due to the accumulation of Trotter errors. While low-order Trotter-Suzuki decompositions are straightforward to implement, their rapidly growing error limits access to long-time observables. We present a framework for constructing efficient high-order Trotter-Suzuki schemes by identifying their structure and directly optimizing their parameters over a high-dimensional space. This method enables the discovery of new schemes with significantly improved efficiency compared to traditional constructions, such as those by Suzuki and Yoshida. Based on the theoretical efficiency and practical performance, we recommend two novel highly efficient schemes at $4^{\textrm{th}}$ and $6^{\textrm{th}}$ order. We also demonstrate the effectiveness of these decompositions on the Heisenberg model and the quantum harmonic oscillator, and find that for a fixed final time they perform better across the computational cost. Even when using large time steps, they surpass established low-order schemes like the Leapfrog. Finally, we investigate the in-practice performance of different Trotter schemes and find the decompositions with more uniform coefficients tend to feature improved error accumulation over long times. We have included this observation into our choice of recommended schemes.

</details>


### [209] [Bayesian quantum sensing using graybox machine learning](https://arxiv.org/abs/2601.17465)
*Akram Youssry,Stefan Todd,Patrick Murton,Muhammad Junaid Arshad,Alberto Peruzzo,Cristian Bonato*

Main category: quant-ph

TL;DR: 该研究首次实验实现了固态开放量子系统的灰盒建模策略，将基于物理的系统模型与数据驱动的实验缺陷描述相结合，在单自旋量子传感器上验证了该方法，相比纯物理模型实现了几个数量级的均方误差改进。


<details>
  <summary>Details</summary>
Motivation: 量子传感器在空间分辨率和灵敏度方面具有显著优势，但其实际性能常受到未建模效应（如噪声、不完美的状态准备和非理想控制场）的限制。现有方法要么过于依赖物理模型（白盒），要么需要大量训练数据（黑盒），需要一种折中方案。

Method: 采用灰盒建模框架，将基于物理的系统模型与数据驱动的实验缺陷描述相结合。在单自旋量子传感器上实验验证该方法，使用约10,000个训练数据点训练灰盒模型，然后执行贝叶斯推理来估计静态磁场。

Result: 灰盒模型相比相应的纯物理模型实现了几个数量级的均方误差改进。该方法仅需约10,000个训练数据点，比完全深度学习模型需要更少的训练资源，同时比纯分析方法具有更高的保真度。

Conclusion: 灰盒建模策略为量子传感平台提供了一种有效的折中方案，特别适用于实时自适应协议，其中模型不准确性可能导致次优控制和性能下降。该方法广泛适用于各种量子传感平台，不限于单自旋系统。

Abstract: Quantum sensors offer significant advantages over classical devices in spatial resolution and sensitivity, enabling transformative applications across materials science, healthcare, and beyond. Their practical performance, however, is often constrained by unmodelled effects, including noise, imperfect state preparation, and non-ideal control fields.
  In this work, we report the first experimental implementation of a graybox modelling strategy for a solid-state open quantum system. The graybox framework integrates a physics-based system model with a data-driven description of experimental imperfections, achieving higher fidelity than purely analytical (whitebox) approaches while requiring fewer training resources than fully deep-learning models. We experimentally validate the method on the task of estimating a static magnetic field using a single-spin quantum sensor, performing Bayesian inference with a graybox model trained on prior experimental data. Using roughly 10,000 training datapoints, the graybox model yields several orders of magnitude improvement in mean squared error over the corresponding physics-only model. These results are broadly applicable to a wide range of quantum sensing platforms, not limited to single-spin systems, and are particularly valuable for real-time adaptive protocols, where model inaccuracies can otherwise lead to suboptimal control and degraded performance.

</details>


### [210] [Are Quantum Voting Protocols Practical?](https://arxiv.org/abs/2601.17514)
*Nitin Jha,Abhishek Parakh*

Main category: quant-ph

TL;DR: 该论文调查量子投票协议的实用性，涵盖量子力学原理、系统模型、代表性协议家族，并评估实施挑战和近期部署场景。


<details>
  <summary>Details</summary>
Motivation: 量子投票协议旨在利用量子力学的物理保证（而非仅依赖计算复杂性）提供选票保密性和公开可验证的计票结果。本文调查此类协议是否具有实际应用价值。

Method: 首先概述量子力学核心数学概念（叠加原理、不可克隆定理、量子纠缠），定义通用系统和威胁模型，识别关键参与者、信任假设和安全目标。然后回顾代表性协议家族，包括基于纠缠的中心计票方案、支持公开验证的自计票设计，以及通过可观测相关性认证不可信设备的权威最小化方法。

Result: 论文评估了量子投票协议的实施挑战，包括损耗、噪声、设备缺陷、可扩展性和抗胁迫性，并讨论了小规模选举的现实近期部署场景。

Conclusion: 量子投票协议在理论上具有潜力，但面临实际实施挑战。虽然近期可能仅限于小规模应用，但该领域的研究为未来更安全的投票系统奠定了基础。

Abstract: Quantum voting protocols aim to offer ballot secrecy and publicly verifiable tallies using physical guarantees from quantum mechanics, rather than relying solely on computational hardness. This article surveys whether such quantum voting protocols are practical. We begin by outlining core mathematical ideas such as the superposition principle, the no-cloning theorem, and quantum entanglement. We then define a common system and threat model, identifying key actors, trust assumptions, and security goals. Representative protocol families are reviewed, including entanglement-based schemes with central tallying, self-tallying designs that enable public verification, and authority-minimized approaches that certify untrusted devices through observable correlations. Finally, we evaluate implementation challenges, including loss, noise, device imperfections, scalability, and coercion resistance, and discuss realistic near-term deployment scenarios for small-scale elections.

</details>


### [211] [Quantum Phase Transitions in the Transverse-Field Ising Model: A Comparative Study of Exact, Variational, and Hardware-Based Approaches](https://arxiv.org/abs/2601.17515)
*Rudraksh Sharma*

Main category: quant-ph

TL;DR: 研究使用量子计算模拟一维横场伊辛模型的量子相变，结合精确对角化、变分量子本征求解器(VQE)和真实量子设备，分析基态性质和量子临界动力学。


<details>
  <summary>Details</summary>
Motivation: 量子相变为研究由非对易相互作用竞争产生的集体量子现象提供了范例。本文旨在通过量子计算方法研究一维横场伊辛模型的基态性质和量子临界动力学，评估当前含噪声中等规模量子(NISQ)设备在模拟量子临界现象方面的能力与局限。

Method: 采用综合研究方法：1）精确对角化作为基准；2）深度为二、基于物理启发的变分近似进行VQE模拟；3）在IQM Garnet量子处理器上运行优化后的电路，使用资源高效的批量协议。研究聚焦于四个自旋的晶格系统，计算基态能量、磁序参数和相关函数。

Result: 浅层变分电路在整个参数空间内可靠地捕捉基态能量；磁序参数和对相关敏感的观测量显示出显著噪声。定量误差分析揭示硬件上临界交叉的强烈展宽，这与长程相关的噪声衰减一致。

Conclusion: 研究结果突显了当前含噪声中等规模量子系统在模拟量子临界现象方面的能力与基本限制，为未来量子硬件改进和量子算法发展提供了基准。

Abstract: The quantum phase transitions provide a paradigm for studying collective quantum phenomena that are a result of competing non-commuting interactions. This paper will study the ground state properties and quantum critical dynamics of the one-dimensional transverse field Ising model through a combined perspective that includes exact diagonalisation, variational quantum eigensolver (VQE) simulations, and simulations on realistic physical quantum devices. We focus on a lattice of four spins, where we calculate the ground-state energies, magnetic order parameters and correlation functions at uniformly applied conditions, which is repeated by all systems. Precise diagonalisation provides both a benchmark, which is symmetry-conserving, and a depth-two, physics inspired variational approximation, which provides simulations accessible to hardware. The circuits that have been optimised identically are then placed on the IQM Garnet quantum processor, using a resource-efficient batched protocol. We find that the ground-state energies of shallow variational circuits are reliably captured by the circuit over the entire parameter space; the magnetic arrangement parameters and observables sensitive to correlation signal significantly more noise. The error analysis of quantitative analysis reveals a strong broadening of critical crossover on hardware, which is consistent with the noise attenuation of long-range correlations. These findings highlight the current capabilities as well as the fundamental limitations of noisy intermediate-scale quantum systems in modelling quantum critical phenomena as a benchmark to future enhancements in obtaining quantum hardware and quantum algorithms development.

</details>


### [212] [Autonomous phonon maser in levitated spin-mechanics](https://arxiv.org/abs/2601.17552)
*Mohamed Hatifi*

Main category: quant-ph

TL;DR: 悬浮纳米金刚石中的NV中心可作为机械振动的增益介质，实现自主声子微波激射器


<details>
  <summary>Details</summary>
Motivation: 探索如何利用悬浮纳米金刚石中的NV中心自旋作为机械振动的增益介质，实现自主的声子微波激射器，为量子控制和传感提供新平台

Method: 通过微波调谐和光学泵浦调控NV中心自旋，使其作为倒置增益介质作用于质心运动；采用绝热消除法推导简化机械主方程；进行全主方程模拟验证

Result: 实现了自主声子微波激射器，仅需百分之几的调谐基态反转即可达到阈值，小信号增益可超过固有机械损耗数个数量级；确认了阈值以上的自激振荡和相位扩散的相干稳态

Conclusion: 悬浮纳米金刚石中的NV中心可作为有效的机械振动增益介质，实现自主声子微波激射器，为量子声子学和机械量子控制提供了新途径

Abstract: Levitated nanodiamonds hosting a single nitrogen-vacancy (NV) center provide an ultra-low-frequency mechanical mode with widely tunable dissipation and spin backaction under microwave dressing and optical pumping. We demonstrate that the driven NV spin can be tuned to act as an inverted gain medium for the center-of-mass motion, thereby stabilizing an autonomous phonon maser. In the separation-of-timescales regime where spin dynamics is fast, adiabatic elimination yields a reduced mechanical master equation with closed-form, detuning-dependent transition rates and a sharp threshold given by the sign change of the phonon-number damping. For representative levitated-NV parameters, we find that a percent-level dressed-basis inversion is sufficient to reach the threshold, and the small-signal gain can exceed the intrinsic mechanical loss by orders of magnitude. Full master-equation simulations confirm above-threshold self-oscillation and a phase-diffusing, coherent steady state, whose saturation follows the Maxwell-Bloch prediction.

</details>


### [213] [PropHunt: Automated Optimization of Quantum Syndrome Measurement Circuits](https://arxiv.org/abs/2601.17580)
*Joshua Viszlai,Satvik Maurya,Swamit Tannu,Margaret Martonosi,Frederic T. Chong*

Main category: quant-ph

TL;DR: PropHunt是一个自动化工具，用于优化CSS量子纠错码的综合征测量电路，通过控制错误传播来提高逻辑错误率，并支持Hook-ZNE误差缓解策略。


<details>
  <summary>Details</summary>
Motivation: 现有电路优化工具主要面向NISQ时代，优化目标如门深度或门数量以减少错误发生概率，但未考虑量子纠错码中错误在综合征测量电路内部的传播特性，这直接影响哪些错误可被检测和纠正，从而决定代码的逻辑错误率。

Method: 开发了PropHunt自动化工具，专门针对CSS量子纠错码的综合征测量电路进行优化。该工具能够迭代改进性能，自动恢复现有手工设计的电路，并提供对逻辑错误率的细粒度控制。

Result: 在相关量子纠错码套件上评估PropHunt，证明其能够迭代改进性能并自动恢复现有手工设计的电路。同时提出了Hook-ZNE这一近期量子纠错应用，利用PropHunt对逻辑错误率的细粒度控制来改进零噪声外推误差缓解策略。

Conclusion: PropHunt填补了现有电路优化工具在量子纠错码综合征测量电路优化方面的空白，通过专门针对错误传播特性进行优化，提高了量子纠错码的实际效果，并为近期量子纠错应用提供了新的可能性。

Abstract: Fault-Tolerant Quantum Computing (FTQC) relies on Quantum Error Correction (QEC) codes to reach error rates necessary for large scale quantum applications. At a physical level, QEC codes perform parity checks on data qubits, producing syndrome information, through Syndrome Measurement (SM) circuits. These circuits define a code's logical error rate and must be run repeatedly throughout the entire program. The performance of SM circuits is therefore critical to the success of a FTQC system.
  While ultimately implemented as physical circuits, SM circuits have challenges that are not addressed by existing circuit optimization tools. Importantly, inside SM circuits themselves errors are expected to occur, and how errors propagate through SM circuits directly impacts which errors are detectable and correctable, defining the code's logical error rate. This is not modeled in NISQ-era tools, which instead optimize for targets such as gate depth or gate count to mitigate the chance that any error occurs. This gap leaves key questions unanswered about the expected real-world effectiveness of QEC codes.
  In this work we address this gap and present PropHunt, an automated tool for optimizing SM circuits for CSS codes. We evaluate PropHunt on a suite of relevant QEC codes and demonstrate PropHunt's ability to iteratively improve performance and recover existing hand-designed circuits automatically. We also propose a near-term QEC application, Hook-ZNE, which leverages PropHunt's fine-grained control over logical error rate to improve Zero-Noise Extrapolation (ZNE), a promising error mitigation strategy.

</details>


### [214] [Holstein Primakoff spin codes for local and collective noise](https://arxiv.org/abs/2601.17592)
*Sivaprasad Omanakuttan,Tyler Thurtell,Andrew K. Forbes,Vikas Buchemmavari,Ben Q. Baragiola*

Main category: quant-ph

TL;DR: 基于Holstein-Primakoff变换，将连续变量玻色编码映射到置换对称自旋系综，构建抗集体和局域噪声的自旋编码，并提出免测量的局域纠错恢复方案。


<details>
  <summary>Details</summary>
Motivation: 量子纠错对容错量子计算至关重要，但现有编码大多依赖局域控制和稳定子测量，这在集体相互作用主导的系统中难以实现。需要开发适用于集体相互作用系统的纠错编码方案。

Method: 通过Holstein-Primakoff近似将连续变量玻色编码映射到置换对称自旋系综，构建Holstein-Primakoff自旋编码框架，并提出测量自由的局域纠错恢复程序。

Result: HP编码对集体和局域自旋噪声都具有鲁棒性，提出的局域纠错恢复程序能将局域噪声映射为可纠正的集体自旋误差。

Conclusion: Holstein-Primakoff自旋编码为集体相互作用系统提供了一种有效的量子纠错框架，通过测量自由的局域恢复程序实现了对混合噪声的鲁棒性。

Abstract: Quantum error correction is essential for fault-tolerant quantum computation, yet most existing codes rely on local control and stabilizer measurements that are difficult to implement in systems dominated by collective interactions. Inspired by spin-GKP codes in PhysRevA.108.022428, we develop a general framework for Holstein-Primakoff spin codes, which maps continuous-variable bosonic codes onto permutation-symmetric spin ensembles via the Holstein-Primakoff approximation. We show that HP codes are robust to both collective and local-spin noise and propose an explicit measurement-free local error recovery procedure to map local noise into correctable collective-spin errors.

</details>


### [215] [Generalized Aharonov-Bohm Effect](https://arxiv.org/abs/2601.17659)
*Shan Gao*

Main category: quant-ph

TL;DR: 该研究探讨了时变磁通下的Aharonov-Bohm效应，发现对于准静态圆形路径，AB相移正比于时间平均的磁通量；对于非圆形路径，相移取决于磁通历史和路径几何，揭示了该效应的混合性质。


<details>
  <summary>Details</summary>
Motivation: Aharonov-Bohm效应在静态磁通下已确立，但时变磁通下的行为仍存在争议和未解问题。研究旨在澄清时变磁通下AB效应的物理本质，特别是规范势和感应电场的相对作用。

Method: 采用WKB方法推导时变磁矢势下的AB相移，分析圆形和非圆形路径，验证规范选择与麦克斯韦方程的一致性，并将结果推广到非零外磁场情形。

Result: 对于准静态圆形路径，AB相移正比于时间平均磁通量Δφ_AB = (1/T)∫₀ᵀ eΦ(t)dt，总相移（含动能贡献）等于eΦ(0)。对于非圆形路径，相移依赖于磁通历史和路径几何。在非零外磁场下，圆形路径的AB相移仍正比于时间平均磁通，总相移仅取决于初始磁通。

Conclusion: 研究阐明了广义AB效应中规范相关势和感应电场的作用，为量子技术应用提供了新理论见解，并有助于澄清AB效应的局域与非局域解释争议。

Abstract: The Aharonov-Bohm (AB) effect highlights the fundamental role of electromagnetic potentials in quantum mechanics, manifesting as a phase shift for a charged particle in field-free regions. While well-established for static magnetic fluxes, the effect's behavior under time-varying fluxes remains an open and debated question. Employing the WKB method, we derive the AB phase shift for a time-dependent magnetic vector potential, demonstrating that for circular paths in the quasistatic regime, it is proportional to the time-averaged enclosed magnetic flux, \(Δφ_{\rm AB} = \frac{1}{T} \int_0^T e Φ(t) \, dt\), with the total phase shift, including kinetic contributions, equaling \(e Φ(0)\). For non-circular paths, the phase shift depends on both the flux history and path geometry, revealing the effect's hybrid nature involving gauge potentials and induced electric fields. We verify the consistency of our gauge choice with Maxwell's equations and discuss the implications for local versus nonlocal interpretations of the AB effect. We also generalize the results to scenarios with nonzero external magnetic fields, where the enclosed flux is through the actual electron paths, and for circular paths of radius $R$, the AB phase shift is also proportional to the time average of the enclosed flux \(Φ_{\rm enc}(R,t)\), with the total phase shift depending only on the initial enclosed flux \(e Φ_{\rm enc}(R,0)\); for general non-circular paths, the external magnetic field affects trajectories and phase accumulation through the Lorentz force, leading to additional path dependence. These findings clarify the role of gauge-dependent potentials and induced fields in the generalized AB effect, offering new theoretical insights and potential applications in quantum technologies.

</details>


### [216] [From Joint to Single-System Psi-Onticity Without Preparation Independence](https://arxiv.org/abs/2601.17662)
*Shan Gao*

Main category: quant-ph

TL;DR: PBR定理无需PIP假设即可证明单个量子系统的ψ-本体性：一旦对复合系统建立ψ-本体性，单个子系统的ψ-本体性可直接从量子力学的张量积结构得出。


<details>
  <summary>Details</summary>
Motivation: 传统PBR定理依赖准备独立性假设(PIP)来证明单个量子系统的ψ-本体性，这导致人们认为拒绝PIP可能保留ψ-认识模型的可能性。本文旨在消除这一误解，展示无需PIP也能证明单个系统的ψ-本体性。

Method: 首先利用PBR定理证明复合系统（处于乘积态）的ψ-本体性，然后基于量子力学的张量积结构，直接推导出单个子系统的ψ-本体性，无需引入PIP或其他辅助假设。

Result: 成功移除了PBR定理中的关键辅助假设(PIP)，闭合了保留ψ-认识模型的持久漏洞，强化了ψ-本体性的概念基础。

Conclusion: 单个量子系统的ψ-本体性可以从复合系统的ψ-本体性直接得出，无需依赖PIP，这消除了对PBR定理解释的一个重要限制，为量子力学基础提供了更强的本体论支持。

Abstract: The Pusey-Barrett-Rudolph (PBR) theorem establishes $ψ$-onticity for individual quantum systems, but its standard formulation relies on the Preparation Independence Postulate (PIP). This has led to a prevalent view that rejecting PIP leaves open the possibility of $ψ$-epistemic models for individual systems. In this work, we show that this understanding is incomplete: once the PBR theorem establishes $ψ$-onticity for composite systems prepared in product states, the $ψ$-onticity of the individual subsystems follows directly from the tensor-product structure of quantum mechanics, without invoking PIP or any further auxiliary assumptions. This result removes a key auxiliary assumption from the PBR theorem, closes a persistent loophole for preserving $ψ$-epistemic models, and strengthens the conceptual foundations of $ψ$-ontology.

</details>


### [217] [Comment on "Aharonov-Bohm Phase is Locally Generated Like All Other Quantum Phases"](https://arxiv.org/abs/2601.17665)
*Shan Gao*

Main category: quant-ph

TL;DR: 该评论文章批评了Marletto和Vedral关于Aharonov-Bohm相位的解释，指出其模型存在数学错误，且AB相位实际上由矢量势A驱动，而非纠缠。


<details>
  <summary>Details</summary>
Motivation: 针对Marletto和Vedral提出的AB相位由带电粒子与量子化电磁场之间的纠缠局部介导的观点进行批判性分析，澄清AB相位的物理本质。

Method: 通过分析Marletto和Vedral的模型，指出其数学错误：场基能量公式中存在错误的前因子，在库仑规范下得到+qv·A_s，与QED的-qv·A_s相矛盾。证明该等效性仅在静态条件下近似成立，不适用于时变场和其他规范。

Result: 1. Marletto和Vedral的模型存在数学错误；2. AB相位由矢量势A驱动，而非纠缠；3. 纠缠是QED框架的副产品，无因果作用；4. 对于非闭合路径，AB相位是规范依赖的，反驳了原论文的规范独立性主张。

Conclusion: AB相位的传统半经典解释是正确的：由矢量势A驱动，纠缠在其产生中不扮演因果角色。Marletto和Vedral的模型存在根本性缺陷。

Abstract: Marletto and Vedral [Phys. Rev. Lett. 125, 040401 (2020)] propose that the Aharonov-Bohm (AB) phase is locally mediated by entanglement between a charged particle and the quantized electromagnetic field, asserting gauge independence for non-closed paths. In this Comment, we critically analyze their model and demonstrate that the AB phase arises from the interaction with the vector potential \(\mathbf{A}\), not from entanglement, which is a byproduct of the quantum electrodynamics (QED) framework. We show that their field-based energy formulation, intended to reflect local electromagnetic interactions, is mathematically flawed due to an incorrect prefactor and yields \( +q \mathbf{v} \cdot \mathbf{A}_{\mathbf{s}} \) in the Coulomb gauge, conflicting with QED's \( -q \mathbf{v} \cdot \mathbf{A}_{\mathbf{s}} \). This equivalence to \( q \mathbf{v} \cdot \mathbf{A}_{\mathbf{s}} \) holds only approximately in the Coulomb gauge under static conditions, failing for time-dependent fields and other gauges, undermining their claim of a gauge-independent local mechanism. Furthermore, we confirm that the AB phase is gauge-dependent for non-closed paths, contradicting their assertion. Our analysis reaffirms the conventional explanation in the semi-classical picture, where the AB phase is driven by the vector potential \(\mathbf{A}\), with entanglement playing no causal role in its generation.

</details>


### [218] [Realisation of Protected Cat Qutrit via Engineered Quantum Tunnelling](https://arxiv.org/abs/2601.17675)
*Sangil Kwon,Daisuke Hoshi,Toshiaki Nagase,Daichi Sugiyama,Hiroto Mukai,Kengo Takemura,Rintaro Kojima,Yu Zhou,Shohei Watabe,Fumiki Yoshihara,Jaw-Shen Tsai*

Main category: quant-ph

TL;DR: 本文实现并研究了三光子Kerr参量振荡器作为受保护qutrit平台的潜力，展示了量子相干性、三组分猫态以及揭示qutrit空间保护的呼吸动力学。


<details>
  <summary>Details</summary>
Motivation: 通过量子隧穿工程创建具有偏置噪声特性的受保护量子比特，结合Kerr非线性和多光子跃迁的Kerr参量振荡器是实现这一目标的有前景方法。

Method: 实现三光子Kerr参量振荡器，通过三光子Rabi振荡和直接Wigner函数测量验证量子相干性，观察相位空间中的呼吸动力学来研究qutrit保护特性。

Result: 成功展示了三光子Rabi振荡，观测到三组分猫态，发现了qutrit与激发态之间奇异时间干涉导致的呼吸动力学，其频率对应能隙，验证了qutrit空间保护。同时识别出高阶泵浦项是抑制光子占据的主要机制。

Conclusion: 研究阐明了三光子KPO的基本量子特性，为将其作为替代qutrit平台迈出了第一步，为创建受保护量子比特提供了新途径。

Abstract: Engineering quantum tunnelling in phase space has emerged as a viable method for creating a protected qubit with biased-noise properties. A promising approach is to combine a Kerr nonlinearity with multi-photon transitions, resulting in a system known as a Kerr parametric oscillator (KPO). In this work, we implement a three-photon KPO and explore its potential as a protected qutrit. We confirm quantum coherence by demonstrating three-photon Rabi oscillations and performing direct Wigner function measurements that reveal three-component cat-like states. We observe breathing-like dynamics in phase space, arising from exotic temporal interference between the qutrit and excited states. The frequency of this interference corresponds to the energy gap between the qutrit and excited manifolds, thereby providing an experimental hallmark of qutrit space protection. We also identify a higher-order pump term as the main mechanism suppressing photon occupation; mitigating this term is necessary to maximize protection. Our findings elucidate the basic quantum properties of the three-photon KPO and establish the first step toward its use as an alternative qutrit platform.

</details>


### [219] [Exponential Quantum Speedup on Structured Hard Instances of Maximum Independent Set](https://arxiv.org/abs/2601.17686)
*Vicky Choi*

Main category: quant-ph

TL;DR: 该论文提出了一种非斯托夸斯绝热量子优化算法，在特定最大独立集问题上实现了相对于经典算法和传统量子退火的指数级加速。


<details>
  <summary>Details</summary>
Motivation: 为实际相关的组合优化问题建立量子加速是量子计算的核心挑战。本文旨在设计能在特定困难问题上实现量子加速的算法。

Method: 识别了一类结构定义的困难最大独立集实例，设计并分析了利用该结构的非斯托夸斯绝热量子优化算法，使用XX驱动访问更大的符号结构允许子空间。

Result: 算法在多项式时间内运行，在假设支持下，对这些实例实现了相对于横向场量子退火和最先进经典求解器的指数级加速。

Conclusion: 量子加速的关键机制是通过非斯托夸斯XX驱动访问更大的符号结构子空间，利用符号生成量子干涉创建平滑演化路径绕过隧穿，这解释了为什么高效经典模拟可能不存在。

Abstract: Establishing quantum speedup for computationally hard problems of practical relevance, particularly combinatorial optimization problems, remains a central challenge in quantum computation. In this work, we identify a structurally defined family of classically hard maximum independent set (MIS) instances, and design and analyze a non-stoquastic adiabatic quantum optimization algorithm that exploits this structure. The algorithm runs in polynomial time and achieves an exponential speedup over both transverse-field quantum annealing and state-of-the-art classical solvers on these instances, under assumptions supported by analytical and numerical evidence. We identify the essential quantum mechanism enabling the speedup as the use of a non-stoquastic XX-driver to access a larger sign-structured admissible subspace beyond the stoquastic regime, which allows sign-generating quantum interference to create smooth evolution paths that bypass tunneling. This identifies a distinctive quantum mechanism underlying the speedup and explains why no efficient classical analogue is likely to exist. In addition, our analysis produces scalable small-scale models, derived from our structural reduction, that capture the essential dynamics of the algorithm. These models provide a concrete opportunity for verification of the quantum advantage mechanism on currently available universal quantum computers.

</details>


### [220] [Traversability dynamics of minimal Sachdev-Ye-Kitaev Wormhole-inspired teleportation protocol with a parity-time ($\mathcal{PT}$)-symmetric non-Hermitian deformation](https://arxiv.org/abs/2601.17688)
*Sudhanva Joshi,Sunil Kumar Mishra*

Main category: quant-ph

TL;DR: 研究PT对称非幺正变形对虫洞启发的量子隐形传态协议的影响，发现PT破缺相可作为放大器，增强信号同时保持因果时间窗口，并观察到深度破缺相的"纯化"效应。


<details>
  <summary>Details</summary>
Motivation: 研究全息启发的量子隐形传态在量子多体系统中的非幺正变形效应，探索如何利用非厄米拓扑增强全息量子通信，为噪声环境下的最小量子多体系统提供信号放大机制。

Method: 在耦合Sachdev-Ye-Kitaev系统的热场双重态浴中引入平衡增益和损失项到边界哈密顿量，通过谱异常点驱动的相变研究虫洞可穿越性，并对无序实现进行统计研究。

Result: PT破缺相作为放大器使隐形传态信号范数指数增长，同时保持虫洞可穿越性的因果时间窗口；临界非厄米阈值γ_c服从对数正态分布；深度破缺相出现"纯化"效应，对后选择态实现近乎完美的隐形传态保真度。

Conclusion: 非厄米拓扑可用于增强全息量子通信，为噪声环境下的最小量子多体系统提供稳健的信号放大机制，PT对称变形为量子信息处理提供了新的调控维度。

Abstract: Holography-inspired teleportation has recently emerged as a significant area of research in quantum many-body systems. In this work, we investigate the effects of $\mathcal{PT}$ symmetric non-unitary deformations on the traversability of the wormhole-inspired teleportation protocol modeled by coupled Sachdev-Ye-Kitaev systems prepared in a Thermofield Double state bath. By introducing balanced gain and loss terms to the boundary Hamiltonians, we identify a phase transition driven by spectral exceptional points, where the real energy eigenvalues of the effective Hamiltonian coalesce and bifurcate into complex conjugate pairs. We demonstrate that the $\mathcal{PT}$-broken phase acts as an amplifier, enabling exponential growth in the norm of the teleported signal while preserving the causal time window for the wormhole's traversability. A statistical study of disorder realizations reveals that the critical non-Hermiticity threshold $γ_c$ follows a log-normal distribution, reflecting the sensitivity of the transition to the microscopic level spacing of the chaotic SYK spectrum. Furthermore, we observe a ``Purification" effect deep in the broken phase, where the teleportation channel acts as an entanglement distiller, yielding near-perfect teleportation fidelity for post-selected states. Our results suggest that the non-Hermitian topology can be harnessed to enhance holographic quantum communication, providing a robust mechanism for signal amplification in noisy, minimal quantum many-body systems.

</details>


### [221] [Quantum-Inspired Algorithms beyond Unitary Circuits: the Laplace Transform](https://arxiv.org/abs/2601.17724)
*Noufal Jaseem,Sergi Ramos-Calderer,Gauthameshwar S.,Dingzu Wang,José Ignacio Latorre,Dario Poletti*

Main category: quant-ph

TL;DR: 提出一种基于张量网络的量子启发算法，用于计算离散拉普拉斯变换，通过非酉阻尼变换和量子傅里叶变换的分解实现高效压缩，支持大规模数据处理。


<details>
  <summary>Details</summary>
Motivation: 量子启发算法能在传统硬件上实现量子算法的加速，但传统量子电路模型受限于酉变换。张量网络天然支持非酉映射，这为设计超越酉变换限制的量子启发方法提供了可能。离散拉普拉斯变换作为一种非酉、非周期变换，需要新的高效计算方法。

Method: 将长度为N的信号编码在两个配对的n量子比特寄存器上，将整体变换分解为非酉的指数阻尼变换和量子傅里叶变换，两者压缩在单个矩阵乘积算子中。这种分解允许强MPO压缩到低键维度，从而实现显著加速。

Result: 成功模拟了高达N=2^30个输入数据点和2^60个输出数据点的计算，量化了键维度如何控制运行时间和精度，包括精确高效的极点识别。

Conclusion: 该张量网络方法为计算非酉变换提供了高效框架，展示了量子启发算法超越传统量子电路限制的能力，通过非酉映射实现实际加速，为大规模数据处理开辟了新途径。

Abstract: Quantum-inspired algorithms can deliver substantial speedups over classical state-of-the-art methods by executing quantum algorithms with tensor networks on conventional hardware. Unlike circuit models restricted to unitary gates, tensor networks naturally accommodate non-unitary maps. This flexibility lets us design quantum-inspired methods that start from a quantum algorithmic structure, yet go beyond unitarity to achieve speedups. Here we introduce a tensor-network approach to compute the discrete Laplace transform, a non-unitary, aperiodic transform (in contrast to the Fourier transform). We encode a length-$N$ signal on two paired $n$-qubit registers and decompose the overall map into a non-unitary exponential Damping Transform followed by a Quantum Fourier Transform, both compressed in a single matrix-product operator. This decomposition admits strong MPO compression to low bond dimension resulting in significant acceleration. We demonstrate simulations up to $N=2^{30}$ input data points, with up to $2^{60}$ output data points, and quantify how bond dimension controls runtime and accuracy, including precise and efficient pole identification.

</details>


### [222] [Reducing Circuit Resources in Grover's Algorithm via Constraint-Aware Initialization](https://arxiv.org/abs/2601.17725)
*Eunok Bae,Jeonghyeon Shin,Minjin Choi*

Main category: quant-ph

TL;DR: 提出一个系统框架，通过预处理在Grover算法中实现约束感知初始化，针对线性约束问题，在电路层面提高资源效率。


<details>
  <summary>Details</summary>
Motivation: Grover算法在组合问题中广泛应用，但标准均匀初始化未充分利用问题约束。通过约束感知初始化可以减少搜索空间，但需要评估其电路成本是否值得。

Method: 开发了一个系统框架，包含简单的预处理程序，用于在Grover算法中实现约束感知初始化，特别关注线性约束问题。提供保守的电路级资源分析。

Result: 约束感知初始化可以减少oracle查询次数，同时电路层面的门数量和深度也能得到改善。通过exact-cover问题的数值实验验证了框架的有效性。

Conclusion: 该方法为Grover算法提供了比标准均匀初始化更资源高效的实现基准，具有实际应用价值。

Abstract: Grover's search algorithm provides a quadratic speedup over classical brute-force search in terms of query complexity and is widely used as a versatile subroutine in numerous quantum algorithms, including those for combinatorial problems with large search spaces. For such problems, it is natural to reduce the effective search space by incorporating problem constraints at the initialization step, which in Grover's algorithm can be achieved by preparing structured initial states that encode constraint information. In this work, we present a systematic framework with a simple preprocessing procedure for constraint-aware initialization in Grover's algorithm, focusing on problems with linear constraints. While such structured initial states can reduce the number of oracle queries required to obtain a solution, their preparation incurs additional circuit-level costs. We therefore offer a conservative circuit-level resource analysis, showing that the resulting constraint-aware initialization can improve resource efficiency in terms of gate counts and circuit depth. The validity of the framework is further demonstrated numerically using the exact-cover problem. Overall, our results indicate that this approach serves as a practical baseline for achieving more resource-efficient implementations of Grover's algorithm compared to the standard uniform initialization.

</details>


### [223] [Quantum fast-forwarding fermion-boson interactions via the polaron transform](https://arxiv.org/abs/2601.17732)
*Harriet Apel,Burak Şahinoğlu*

Main category: quant-ph

TL;DR: 提出了一种用于模拟费米子-玻色子相互作用的量子算法，将计算复杂度从Λ的多项式降低到Λ的多对数级别


<details>
  <summary>Details</summary>
Motivation: 费米子-玻色子相互作用系统对理解关联现象至关重要，但经典计算难以处理。现有量子算法对玻色子截断参数Λ的依赖是多项式复杂度，限制了计算效率。

Method: 识别了能够快速推进费米子-玻色子相互作用项演化的高效幺正变换，构建了基于相互作用绘景的模拟算法，复杂度为Λ的多对数级别。将该变换应用于Hubbard-Holstein模型，并推广到其他费米子-玻色子相互作用模型。

Result: 实现了对玻色子截断参数Λ依赖关系的渐进改进，复杂度从多项式降低到多对数级别。对于某些模型，模拟费米子-玻色子相互作用的资源需求可与纯费米子系统相当。

Conclusion: 该方法显著提高了费米子-玻色子相互作用系统的量子模拟效率，为研究相关物理现象提供了更有效的计算工具，并展示了在某些情况下这类系统的模拟复杂度可降低到与纯费米子系统相当的水平。

Abstract: Simulating interactions between fermions and bosons is central to understanding correlated phenomena, yet these systems are inherently difficult to treat classically. Previous quantum algorithms for fermion-boson models exhibit computation costs that scale polynomially with the bosonic truncation parameter, $Λ$. In this work we identify the efficient unitary transformation enabling fast-forwarded evolution of the fermion-boson interaction term, yielding an interaction-picture based simulation algorithm with complexity polylogarithmic in $Λ$. We apply this transformation to explicitly construct an efficient quantum algorithm for the Hubbard-Holstein model and discuss its generalisation to other fermion-boson interacting models. This approach yields an important asymptotic improvement in the dependence on the bosonic cutoff and establishes that, for certain models, fermion-boson interactions can be simulated with resources comparable to those required for purely fermionic systems.

</details>


### [224] [Simple, Efficient, and Generic Post-Selection Decoding for qLDPC codes](https://arxiv.org/abs/2601.17757)
*Haipeng Xie,Nobuyuki Yoshioka,Kento Tsubouchi,Ying Li*

Main category: quant-ph

TL;DR: 提出了一种名为"argument reweighting"的后选择解码策略，通过重新加权错误模型进行额外解码轮次，显著降低量子纠错中的逻辑错误率。


<details>
  <summary>Details</summary>
Motivation: 量子纠错对可扩展量子计算至关重要，但现有硬件上实现足够低的逻辑错误率仍然具有挑战性。需要更有效的解码策略来提升量子容错性能。

Method: 引入argument reweighting方法，这是一种简单且广泛适用的后选择解码策略。它在重新加权的错误模型下执行额外的解码轮次，接受高置信度的综合征结果，从而提升最大似然型解码器（包括最小权重完美匹配和置信传播家族）的性能。

Result: 电路级仿真显示，argument reweighting能显著抑制逻辑错误。对于[[144,12,12]]双变量自行车码，仅需1.44×10⁻⁵的拒绝率就能将逻辑错误率降低近两个数量级。该方法在多种解码器和qLDPC码上都表现出良好效果。

Conclusion: argument reweighting是一种实用且资源高效的量子容错增强方法，为提升量子纠错性能提供了有效途径。

Abstract: Quantum error correction is indispensable for scalable quantum computation. Although encoding logical qubits substantially enhances noise resilience, achieving logical error rates low enough for practical algorithms remains challenging on existing hardware. Here we introduce argument reweighting, a simple and broadly applicable post-selection decoding strategy that boosts the performance of maximum-likelihood-type decoders, including minimum-weight perfect matching and belief-propagation families. The method suppresses logical errors by performing additional decoding rounds under reweighted error models, enabling acceptance of high-confidence syndrome outcomes. Circuit-level simulations across multiple decoders and qLDPC codes show that argument reweighting substantially suppresses logical errors, requiring a rejection rate of only $1.44\times10^{-5}$ to reduce the logical error rate by almost two orders of magnitude for the $[[144,12,12]]$ bivariate bicycle code. These results establish argument reweighting as a practical and resource-efficient approach for enhancing quantum fault tolerance.

</details>


### [225] [Kirkwood-Dirac Quasiprobability as a Universal Framework for Quantum Measurements Across All Regimes](https://arxiv.org/abs/2601.17788)
*Bo Zhang,Yusuf Turek*

Main category: quant-ph

TL;DR: Kirkwood-Dirac准概率通过指针诱导退相干机制，为所有测量强度提供统一框架，连接弱测量到强测量的连续过渡。


<details>
  <summary>Details</summary>
Motivation: Kirkwood-Dirac准概率在不同测量强度下的适用性一直未解决，特别是其从弱测量中的异常弱值到投影测量中经典概率的连续转变机制不明确。

Method: 识别指针诱导退相干作为控制KD准概率转变的普适机制，使用退相干因子F(t)同时量化量子相干性损失并插值测量强度。

Result: KD准概率通过退相干因子自然地从完整的复数形式（控制弱值）变形为实数非负的Wigner公式（描述投影测量），在整个过渡过程中保持信息完整性。

Conclusion: KD分布通过物理透明的退相干路径，作为无缝连接所有量子测量机制的普适框架，解决了其适用性的基本问题。

Abstract: The question of when the Kirkwood-Dirac quasiprobability serves as the most appropriate description for quantum measurements has remained unresolved, particularly across different measurement strengths. While known to generate anomalous weak values in the weak measurement regime and to reduce to classical probabilities under projective measurement, the physical mechanism governing its continuous transformation has been lacking. Here we demonstrate that the KD quasiprobability provides a general framework for all measurement regimes by identifying pointer-induced decoherence as the universal mechanism controlling this transition. We show that the decoherence factor F(t) simultaneously quantifies the loss of quantum coherence and interpolates the measurement strength from weak to strong. Within this framework, the KD quasiprobability naturally deforms from its full complex form-governing weak values-to the real, non-negative Wigner formula describing projective measurements, while maintaining informational completeness throughout the transition. Our work resolves the fundamental question of the KD distribution's applicability by establishing it as the universal framework that seamlessly connects all quantum measurement regimes through a physically transparent decoherence pathway.

</details>


### [226] [Bosonic Diffusive Channel: Quantum Metrology via Finite Non-Gaussian Resource](https://arxiv.org/abs/2601.17804)
*Arman,Prasanta K. Panigrahi*

Main category: quant-ph

TL;DR: 研究使用非高斯探针态估计连续变量量子系统中的退相干效应，通过量子费希尔信息识别最优探针态（压缩猫态和对称压缩罗盘态），并提出了在腔内场不可访问时的辅助量子比特测量方案。


<details>
  <summary>Details</summary>
Motivation: 在连续变量量子系统中，准确估计退相干效应对于量子信息处理至关重要。传统方法在腔内场不可访问或标准测量不切实际的情况下存在局限，需要开发新的估计策略。

Method: 通过纯化开放系统，使用量子费希尔信息识别最优非高斯探针态（压缩猫态和对称压缩罗盘态）。在腔内场不可访问时，采用辅助量子比特方法：让量子比特穿过或与腔场相互作用，然后测量量子比特，通过维格纳函数重构或成本更低的边际分布来估计退相速率。

Result: 识别出压缩猫态和对称压缩罗盘态作为最优探针态，量子费希尔信息分析结果与数值模拟一致。辅助量子比特方法能够在腔内场不可访问的情况下有效估计退相速率。

Conclusion: 非高斯探针态在连续变量量子系统的退相干估计中具有优势，特别是压缩猫态和对称压缩罗盘态。辅助量子比特测量方案为实际实验中的退相干估计提供了可行的替代方法。

Abstract: We investigate the estimation of dephasing-induced decoherence in continuous-variable quantum systems using non-Gaussian probe states. By purifying the open system, we identify optimal probes, specifically squeezed cat and symmetric squeezed compass states, via quantum Fisher information. These results are in agreement with numerical simulation. In settings where the intra-cavity field is inaccessible and standard measurements are impractical, utilizing an ancilla approach where a qubit traverses or interacts with the cavity field, leading to measurement of the qubit, hence allowing estimation of the dephasing rate via Wigner function reconstruction or less costly marginal distribution.

</details>


### [227] [Experimental Phase-Matching Quantum Cryptographic Conferencing in Symmetric and Asymmetric Fiber Channels](https://arxiv.org/abs/2601.17819)
*Mi Zou,Bin-Chen Li,Shuai Zhao,Yingqiu Mao,Dandan Qin,Xiao Jiang,Teng-Yun Chen,Jian-Wei Pan*

Main category: quant-ph

TL;DR: 实验演示了考虑有限尺寸效应的三强度相位匹配量子密码会议协议，在对称光纤通道中实现100公里距离的三方密钥分发，并在非对称通道中验证了网络适应性。


<details>
  <summary>Details</summary>
Motivation: 当前量子密码会议(QCC)的安全传输距离仍局限于城域范围，需要扩展至城际量子网络的实际应用。

Method: 采用频率锁定和相位跟踪技术，实现三强度相位匹配(PM) QCC协议，考虑有限尺寸效应，在对称和非对称光纤通道中进行实验验证。

Result: 在对称光纤通道中，每个参与方到测量站点的距离可达100公里；在非对称光纤通道中，协议展现出良好的网络适应性，模拟了真实网络的通道配置。

Conclusion: 相位匹配QCC协议在对称和非对称通道中都具备可行性，为实际城际量子网络的应用提供了验证。

Abstract: Quantum cryptographic conferencing (QCC) allows multiple parties to establish common secure keys in quantum networks with information-theoretic security. However, the secure transmission distances of current QCC implementations are still limited to the metropolitan areas. Here, we experimentally demonstrate the three-intensity phase-matching (PM) QCC protocol considering finite-size effects by employing frequency-locking and phase-tracking techniques for three parties. The key distribution capability of the PM QCC protocol is demonstrated in the symmetric fiber channels with the distance from each party to the measurement site up to 100 km. The network adaptability of the PM QCC protocol is demonstrated in asymmetric fiber channels used to simulate fiber channel configurations in real networks. Thus, the feasibility of applying the PM QCC protocol to practical intercity quantum networks with both symmetric and asymmetric channels is verified.

</details>


### [228] [Multivariate Rényi divergences characterise betting games with multiple lotteries](https://arxiv.org/abs/2601.17850)
*Andrés F. Ducuara,Erkka Haapasalo,Ryo Takakura*

Main category: quant-ph

TL;DR: 该论文为多元Rényi散度提供了基于博彩、风险厌恶和多彩票的经济理论解释，建立了信息论、物理学和经济学之间的定量联系。


<details>
  <summary>Details</summary>
Motivation: 为多元Rényi散度提供操作解释，将其与经济学中的博彩、风险厌恶和彩票理论联系起来，建立信息论、物理学和经济学之间的桥梁。

Method: 通过经济理论框架分析多元Rényi散度，引入条件多元Rényi散度，证明数据处理不等式，并将其应用于一般概率理论中的信息测量资源理论。

Result: 证明多元Rényi散度量化了理性代理人对d个彩票的经济理论价值，当赔率公平且代理最大化所有博彩策略时，该价值等于exp[D_α(P_X)]。新引入的条件多元Rényi散度满足数据处理不等式，反映了侧信息提供的经济价值增量。

Conclusion: 该框架为多元Rényi散度提供了新颖的操作基础，建立了信息论、经济学和物理学之间的定量联系，特别为量子资源理论中的量子态博彩游戏提供了理论基础。

Abstract: We provide an operational interpretation of the multivariate Rényi divergence in terms of economic-theoretic tasks based on betting, risk aversion, and multiple lotteries. We show that the multivariate Rényi divergence $D_{\underlineα}(\vec{P}_X)$ of probability distributions $\vec{P}_X =(p^{(0)}_X,\dots,p^{(d)}_X)$ and real-valued orders $\underlineα = (α_0, \dots, α_d)$ quantifies the economic-theoretic value that a rational agent assigns to $d$ lotteries with odds $o^{(k)}_X \propto (p_X^{(k)})^{-1}$ ($k=1,\dots,d$) on a random event described by $p^{(0)}_X$. In particular, when the odds are fair and the rational agent maximises over all betting strategies, the economic-theoretic value (the isoelastic certainty equivalent) that the agent assigns to the lotteries is exactly given by $w^{\mathrm{ICE}}_{\underline{R}}=\exp[D_{\underlineα}(\vec{P}_X)]$, where $\underline{R}=(R_1,\dots,R_d)$ is a risk-aversion vector with $R_k = 1+α_k/α_0$ being the risk-aversion parameter for lottery $k$. Furthermore, we introduce a new conditional multivariate Rényi divergence that characterises a generalised scenario where the agent uses side information. We prove that this new quantity satisfies a data processing inequality which can be interpreted as the increment in the economic-theoretic value provided by side information; crucially, such a data processing inequality is a consequence of the agent's economic-theoretically consistent risk-averse attitude towards every lottery and vice versa. Finally, we apply these results to the resource theory of informative measurements in general probabilistic theories (GPTs). By establishing quantitative connections between information theory, physics, and economics, our framework provides a novel operational foundation for quantum state betting games with multiple lotteries in the realm of quantum resource theories.

</details>


### [229] [On Tunneling in the Quantum Multiverse](https://arxiv.org/abs/2601.17856)
*S. E. Ennadifi*

Main category: quant-ph

TL;DR: 该论文在Everett量子多重宇宙框架下重新解释量子隧穿现象，将隧穿视为波函数在环境作用下分裂为反射和透射分支，观测者位于隧穿世界中体验隧穿过程。


<details>
  <summary>Details</summary>
Motivation: 受到量子力学中长期存在的解释性争议的启发，作者希望在Everett量子多重宇宙框架下对量子隧穿进行启发性探讨，为这一量子现象提供新的解释视角。

Method: 采用Everett量子多重宇宙框架，分析波函数在遇到势垒后如何在环境作用下退相干并分裂为反射和透射分支。通过隧穿世界的相对权重研究隧穿概率，通过分支持续时间研究隧穿时间。

Result: 在Everett框架下重新解释了量子隧穿概率和隧穿时间的概念，将隧穿概率与隧穿世界的相对权重联系起来，隧穿时间与分支持续时间联系起来。同时讨论了最近备受关注的宏观量子隧穿现象，并基于获得的结果和已知数据探讨了相应的宏观隧穿时间。

Conclusion: 量子隧穿可以在Everett量子多重宇宙框架下得到一致的解释，观测者位于隧穿世界中体验隧穿过程。该框架为理解量子隧穿现象提供了新的视角，并能扩展到宏观量子隧穿的研究中。

Abstract: Prompted by the longstanding interpretational controversy in quantum mechanics, quantum tunneling is heuristically addressed within the Everettian quantum multiverse. In this framework, the universal wavefunction splits into decohered reflected and transmitted branches under the environmetal effect after encountring a potential barrier. The observed tunneling is then experienced by the observer located in a tunneled world. The tunneling probability and the tunneling time are investigated in terms of the tunneled world relative weights and the branching duration, respectively. The macroscopic quantum tunneling, recently honored, is also discussed and the corresponding macroscopic tunneling time is approached based on the obtained results and known data.

</details>


### [230] [Quantum Machine Learning Using Quantum Illumination With Quantum Enhanced Interference](https://arxiv.org/abs/2601.17870)
*Pallab Biswas,Tamal Maity*

Main category: quant-ph

TL;DR: 该论文提出将量子增强技术与量子神经网络反向传播结合，用于分析量子比特在叠加态中的位置信息，这对量子优化和搜索算法很重要。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习结合量子力学原理与经典机器学习技术，能提供更快、指数级、更高效的量子计算能力。量子照明技术连接量子原理与硬件实现。量子计算中的信息量子比特处理需要叠加和纠缠控制。测量和性能的改进直接关系到弱信号或强度的检测。

Method: 使用量子增强技术分析量子比特状态的先前叠加，通过双缝实验清晰分析量子干涉衍射模式及其叠加。然后构建量子神经网络反向传播技术，能够提供量子比特在任何先前叠加态中的位置信息。

Result: 该方法能够分析量子干涉衍射模式，并确定量子比特在叠加态中的位置信息，这对量子优化和搜索算法具有重要意义。

Conclusion: 量子增强技术与量子神经网络反向传播的结合为量子比特状态分析提供了新方法，对量子优化和搜索算法的发展有重要价值。

Abstract: Quantum Machine Learning(QML) is developed by combining quantum mechanics principles with classical machine learning techniques in a hybrid framework that can give faster, exponential, more efficient power of quantum computing with the data driven intelligence. Quantum illumination(QI) is the quantum mechanical technique along with analysis of light matter interaction from source to detection end that connects quantum principle to hardware implementation. Superposition and entanglement control are deeply needed for the information-qubit processing in quantum computing. Improvement of measurement and performance are directly linked to detecting weak signal or intensity. This paper motivated that using quantum-enhanced technique how we can analysis previous superposition of qubit state which can clearly analyzed quantum interference diffraction patterns and its superposition using double slit experiment. Then constructed quantum neural network back propagation technique such that can give information of qubit position in any previous superposition state. Which is very import for any quantum optimization and search algorithm.

</details>


### [231] [Coherent Amplifier-Empowered Quantum Interferometer: Preserving Sensitivity and Quantum Advantage under High Loss](https://arxiv.org/abs/2601.17876)
*Jie Zhao,Zeliang Wu,Haoran Liu,Yueya Liu,Xin Chen,Xinyun Liang,Wenfeng Huang,Chun-Hua Yuan,L. Q. Chen*

Main category: quant-ph

TL;DR: 提出一种相干放大器增强的量子干涉仪，通过相位敏感的光子放大和保护量子态，显著抑制高损耗条件下相位灵敏度和量子增强因子的衰减，使量子干涉测量在损耗超过90%的环境中仍能保持超越标准量子极限的性能。


<details>
  <summary>Details</summary>
Motivation: 量子干涉仪虽然能超越标准量子极限进行相位测量，但在实际应用中不可避免的损耗会导致相位灵敏度和量子增强因子严重退化，这是量子干涉测量走向实际应用的主要障碍。

Method: 提出相干放大器增强的量子干涉仪方案，利用相干放大器的相位敏感光子放大特性来保护量子态，在高损耗条件下维持量子增强性能。

Result: 实验中使用4.2 dB压缩真空态，在90%损耗条件下：量子增强退化从传统量子干涉仪的3.7 dB降至仅1.5 dB；相位灵敏度退化从11.2 dB降至仅4.0 dB，即使在超过90%损耗下仍能保持超越原始标准量子极限的相位灵敏度。

Conclusion: 相干放大器增强的量子干涉仪突破了量子干涉测量在实际部署中的关键障碍，能够在有损耗环境中实现稳健的量子增强测量，为量子干涉技术的实际应用铺平道路。

Abstract: Quantum interferometers offer phase measurement capabilities that surpass the standard quantum limit (SQL), with phase sensitivity and quantum enhancement factor serving as key performance metrics. However, practical implementations face severe degradation of both metrics due to unavoidable losses, representing the foremost challenge in advancing quantum interferometry toward real-world applications. To address this challenge, we propose a coherent-amplifier-empowered quantum interferometer. The coherent amplifier dramatically suppresses the decay of both sensitivity and quantum enhancement under high-loss conditions, maintaining phase sensitivity beyond the original SQL even for losses exceeding 90%. Using an injected 4.2 dB squeezed-vacuum state in experimental demonstration, our scheme reduces the quantum enhancement degradation under 90% loss from 3.7 dB in a conventional quantum interferometer (CQI) to only 1.5 dB. More importantly, the phase sensitivity degradation under the same loss is limited to 4.0 dB, markedly outperforming the 11.2 dB degradation observed in a CQI. This improvement is enabled by the coherent amplifier's phase-sensitive photon amplification and its protection of the quantum state. This breakthrough in amplifier-empowered quantum interferometry overcomes the critical barrier to practical deployment, enabling robust quantum-enhanced measurements in lossy environments.

</details>


### [232] [Colour Centre Formation in Silicon-On-Insulator for On-Chip Photonic Integration](https://arxiv.org/abs/2601.17919)
*Arnulf J. Snedker-Nielsen,David R. Gongora,Magnus L. Madsen,Christian H. Christiansen,Eike L. Piehorsch,Mathias Ø. Augustesen,Elvedin Memisevic,Sangeeth Kallatt,Rodrigo A. Thomas,Mark Kamper Svendsen,Peter Krogstrup Jeppesen,Marianne E. Bathen,Lasse Vines,Peter Granum,Stefano Paesani*

Main category: quant-ph

TL;DR: 研究硅中色心生成工艺，探索热退火和纳米加工对量子发射器的影响，发现色心间的耦合形成动力学，识别稳定光学信号


<details>
  <summary>Details</summary>
Motivation: 硅中色心（如T中心）作为单光子源和自旋-光子界面在量子技术中具有巨大潜力，需要研究适合大规模制造的硅基量子器件中色心的生成工艺

Method: 研究不同工艺步骤对量子发射器存在的影响，包括热退火和光学纳米结构制造步骤，分析色心形成动力学和退火参数优化

Result: 揭示了不同色心间的耦合形成动力学，确定了退火过程的最佳参数，发现了对退火持续时间和光子集成电路纳米制造工艺的敏感性，识别了之前未发现的稳定光学信号

Conclusion: 该研究为大规模制造硅基量子器件中的色心生成提供了重要工艺指导，发现了新的稳定色心信号，推动了硅基量子技术的发展

Abstract: Colour centres in silicon have great potential as single photon sources for quantum technologies. Some of them - like the T centre - also possess optically-active spins that enable spin-photon interfaces for generating entangled photons and multi-spin registers. This paper explores the generation of several types of colour centres in silicon for mass-manufacturable silicon-on-insulator quantum devices. We investigate how different processes in the device development affect the presence of the quantum emitters, including thermal annealing and fabrication steps for optical nanostructures. The study reveals coupled formation dynamics between different colour centres, identifies optimal parameters for annealing processes, and reports on the sensitivity to annealing duration and nanofabrication procedures for photonic integrated circuits. Furthermore, we discern stable optical signals from colour centres in silicon which have not been identified before.

</details>


### [233] [Perturbation Theory and the Quantum Rabi-model](https://arxiv.org/abs/2601.17924)
*Marcello Malagutti,Alberto Parmeggiani*

Main category: quant-ph

TL;DR: 论文研究量子光学中Rabi系统的微扰模型，证明有限族特征值的Braak猜想，并推广到N能级原子系统的Weyl谱计数渐近分析


<details>
  <summary>Details</summary>
Motivation: 研究量子光学中Rabi系统的谱特性，特别是特征值的解析展开和Braak猜想的验证，并将分析推广到更一般的N能级原子系统

Method: 采用微扰模型和Rellich理论分析Rabi系统，研究有限族特征值的解析展开；使用Weyl谱计数函数分析N能级原子系统的渐近行为

Result: 证明了有限族特征值的Braak猜想成立；获得了推广到N能级原子系统的Weyl谱计数函数的渐近特性

Conclusion: 论文成功建立了Rabi系统的微扰理论框架，验证了Braak猜想，并将分析方法扩展到更复杂的多能级量子系统

Abstract: In the first part of the paper we study a perturbative model of the Rabi system of Quantum Optics. We therefore are able to describe, through Rellich's theory, an analytic expansion of finite families, but of any fixed length, of eigenvalues. In particular, we prove that for finite families of eigenvalues the Braak conjecture holds. In the second part we study the asymptotics of the Weyl spectral counting function of a class of systems that generalize the Quantum Rabi Model to an $N$-level atom ($N\geq3$) with $N-1$ cavity modes of the electromagnetic field.

</details>


### [234] [The hyperlink representation of entanglement and the inclusion-exclusion principle](https://arxiv.org/abs/2601.17926)
*Silvia N. Santalla,Sudipto Singha Roy,Germán Sierra,Javier Rodríguez-Laguna*

Main category: quant-ph

TL;DR: 论文提出了纠缠超链接(EHLs)作为纠缠链接(ELs)的精确扩展，用于精确描述纯态的多体纠缠结构，并展示了其在量子信息论和量子多体物理中的应用。


<details>
  <summary>Details</summary>
Motivation: 现有的纠缠链接(ELs)只能近似表达纯态二分划的纠缠熵，需要一种精确的扩展来描述多体纠缠中不可约简到低阶项的贡献。

Method: 通过包含-排除原理定义纠缠超链接(EHLs)，这是一种广义互信息，能够精确捕捉多体纠缠中不可约简到低阶项的贡献。证明了EHLs在因子化划分处必须消失，并且任意块集之间的EHLs可以表示为连接所有这些块的EHLs之和。

Result: 建立了纯态任意块纠缠熵的精确表示，即边界交叉的所有EHLs之和。通过局部哈密顿量基态的数值例子展示了EHLs的丰富结构。

Conclusion: 纠缠超链接(EHLs)为量子信息论和量子多体物理中的多体纠缠表征提供了重要工具，能够精确描述纠缠结构并捕捉不可约简的多体纠缠贡献。

Abstract: The entanglement entropy (EE) of any bipartition of a pure state can be approximately expressed as a sum of entanglement links (ELs). In this work, we introduce their exact extension, i.e. the entanglement hyperlinks (EHLs), a type of generalized mutual informations defined through the inclusion-exclusion principle, each of which captures contributions to the multipartite entanglement that are not reducible to lower-order terms. We show that any EHL crossing a factorized partition must vanish, and that the EHLs between any set of blocks can be expressed as a sum of all the EHLs that join all of them. This last result allows us to provide an exact representation of the EE of any block of a pure state, from the sum of the EHLs which cross its boundary. In order to illustrate their rich structure, we discuss some explicit numerical examples using ground states of local Hamiltonians. The EHLs thus provide a remarkable tool to characterize multipartite entanglement in quantum information theory and quantum many-body physics.

</details>


### [235] [A Rigorous and Self--Contained Proof of the Grover--Rudolph State Preparation Algorithm](https://arxiv.org/abs/2601.17930)
*Antonio Falco,Daniela Falco-Pomares,Hermann G. Matthies*

Main category: quant-ph

TL;DR: 本文对Grover-Rudolph量子态制备算法进行了严格的形式化分析，提供了完整的数学证明和电路实现方案


<details>
  <summary>Details</summary>
Motivation: Grover-Rudolph算法是量子计算中基于幅度编码和幅度估计的基本原语，用于制备编码经典概率分布的量子态。然而，该算法通常以非正式的正确性论证和隐含的二元树约定呈现，缺乏严格的分析

Method: 1. 形式化二元概率树结构；2. 通过条件质量定义角度映射；3. 推导三角分解；4. 通过归纳法证明电路在计算基中精确制备目标测量定律；5. 提供电路实现方案，将每个阶段转换为均匀控制的RY旋转，并使用Gray码梯子和Walsh-Hadamard角度变换编译为{RY(·),X,CNOT}门集

Result: 提供了Grover-Rudolph构造的严格自包含分析，证明了电路能够精确制备目标概率分布的量子态，并给出了无辅助比特的电路编译方案

Conclusion: 本文填补了Grover-Rudolph算法形式化分析的空白，为量子算法中概率分布编码提供了坚实的理论基础和实用的电路实现方法

Abstract: Preparing quantum states whose amplitudes encode classical probability distributions is a fundamental primitive in quantum algorithms based on amplitude encoding and amplitude estimation. Given a probability distribution $\{p_k\}_{k=0}^{2^n-1}$, the Grover--Rudolph procedure constructs an $n$-qubit state $\ketψ=\sum_{k=0}^{2^n-1}\sqrt{p_k}\ket{k}$ by recursively applying families of controlled one-qubit rotations determined by a dyadic refinement of the target distribution. Despite its widespread use, the algorithm is often presented with informal correctness arguments and implicit conventions on the underlying dyadic tree. In this work we give a rigorous and self-contained analysis of the Grover--Rudolph construction: we formalize the dyadic probability tree, define the associated angle map via conditional masses, derive the resulting trigonometric factorizations, and prove by induction that the circuit prepares exactly the desired measurement law in the computational basis. As a complementary circuit-theoretic contribution, we show that each Grover--Rudolph stage is a uniformly controlled $\RY$ rotation on an active register and provide an explicit ancilla-free transpilation into the gate dictionary $\{\RY(\cdot),X,\CNOT(\cdot\to\cdot)\}$ using Gray-code ladders and a Walsh--Hadamard angle transform.

</details>


### [236] [Elementary Quantum Gates from Lie Group Embeddings in $U(2^n)$: Geometry, Universality, and Discretization](https://arxiv.org/abs/2601.17936)
*Antonio Falco,Daniela Falco-Pomares,Hermann G. Matthies*

Main category: quant-ph

TL;DR: 该论文提出了一种基于SU(2)嵌入的量子电路内在描述方法，证明了相位无关的通用性，并建立了模块化有限字母表接口。


<details>
  <summary>Details</summary>
Motivation: 传统量子电路模型中，基本门是相对于选择的张量分解定义的，因此是外在的。本文旨在为U(2^n)群引入内在的描述层，通过将忠实嵌入的SU(2)副本中的运动声明为基本操作。

Method: 定义相位无关字典G^{SU}_{elem}(n)为所有忠实嵌入SU(2)到U(N)的并集。分析嵌入空间分解为有限个U(N)-齐次层，使用希尔伯特-施密特双不变度量。通过两级QR/Givens分解和两级相位旋转生成对角环面，证明通用性。

Result: 证明了相位无关通用性：⟨G^{SU}_{2lvl}(n)⟩=SU(N)和⟨G^{SU}_{elem}(n)⟩=SU(N)。通过添加对角/全局U(1)因子实现U(N)的完全通用性。建立了通过两级嵌入提升Solovay-Kitaev近似的模块化有限字母表接口。

Conclusion: 该工作为量子计算提供了一种内在的门集描述方法，证明了其通用性，并展示了如何通过SU(2)嵌入实现高效的电路近似，为量子电路设计提供了新的理论基础。

Abstract: In the standard circuit model, elementary gates are specified relative to a chosen tensor factorization and are therefore extrinsic to the ambient group $U(2^n)$. Writing $N=2^n$, we introduce an intrinsic descriptor layer in $U(N)$ by declaring as primitive the motions inside faithful embedded copies of $SU(2)$, leading to the phase-free dictionary $\mathcal{G}^{SU}_{\mathrm{elem}}(n)=\bigcup_{φ\in\Emb(SU(2),U(N))}φ(SU(2))$, and we also discuss the phase-inclusive $U(2)$ variant. We show that $\Emb(SU(2),U(N))$ decomposes into finitely many $U(N)$-homogeneous strata indexed by isotypic multiplicities, with stabilizers given by centralizers; the canonical two-level sector is organized by $\Gr_2(\C^N)$ up to a $PSU(2)$ gauge. Equipping $U(N)$ with the Hilbert--Schmidt bi-invariant metric, each embedded subgroup is totally geodesic. Using two-level QR/Givens factorization together with an explicit generation of diagonal tori by two-level phase rotations, we prove phase-free universality $\langle\mathcal{G}^{SU}_{\mathrm{2lvl}}(n)\rangle=SU(N)$ and hence $\langle\mathcal{G}^{SU}_{\mathrm{elem}}(n)\rangle=SU(N)$. Full universality in $U(N)$ follows by adjoining the abelian diagonal/global $U(1)$ factors (equivalently, by passing to the $U(2)$ two-level dictionary). Finally, we record a modular finite-alphabet interface by lifting Solovay--Kitaev approximation in $SU(2)$ through two-level embeddings.

</details>


### [237] [Quantum Radar System Using Born-Feynman path integrals approach](https://arxiv.org/abs/2601.17956)
*Kumar Gautam,Akshit Dutta,Kumar Shubham*

Main category: quant-ph

TL;DR: 基于量子点的Born-Feynman路径积分方法实现量子雷达部署，系统包含纠缠光子发生器、传输模块、延迟线、检测模块和信号处理单元，利用量子关联进行精确目标探测。


<details>
  <summary>Details</summary>
Motivation: 开发一种基于量子点技术的量子雷达系统，利用量子纠缠和Born-Feynman路径积分方法，实现比传统雷达更高精度的目标探测和识别能力。

Method: 采用量子点基纠缠光子发生器产生纠缠光子对，通过微波天线和波束成形元件传输信号光子，延迟线同步保留闲光子与返回信号光子，使用超导纳米线单光子探测器检测，信号处理单元分析量子相关性。

Result: 构建了一个完整的量子雷达系统架构，能够产生、传输、同步和检测纠缠光子，通过量子态比较实现精确目标探测。

Conclusion: 基于Born-Feynman路径积分和量子点技术的量子雷达系统具有实现高精度量子传感的潜力，为下一代雷达技术提供了新的发展方向。

Abstract: The paper relates to a quantum radar deployment by the Born-Feynman path integrals approach based on quantum dots. The radar system comprises a quantum dot-based entangled photon generator, a transmission module, a delay line, a detection module, and a signal processing unit. The quantum dot-based entangled photon generator produces entangled photon pairs via spontaneous parametric down-conversion or stimulated emission. The signal transmission module, equipped with a microwave antenna and beamforming elements, directs the signal photon toward a target. The delay line module synchronizes the retained idler photon with the returning signal photon, preserving quantum coherence. The detection module collects the reflected signal photon and uses a cryogenically cooled superconducting nanowire single photon detector (SNSPD) for detection. Finally, the signal processing unit analyzes the quantum correlation between the scattered and idler photons to enable precise quantum state comparison.

</details>


### [238] [Authentication in Security Proofs for Quantum Key Distribution](https://arxiv.org/abs/2601.17960)
*Devashish Tupkary,Shlok Nahar,Ernest Y. -Z. Tan*

Main category: quant-ph

TL;DR: QKD安全证明通常假设理想认证信道，但实际认证信道存在非对称中止和消息延迟等问题。本文证明在温和条件下，任何在理想认证下安全的QKD协议在实际认证下也安全，可通过小修改让现有证明适用于实际场景。


<details>
  <summary>Details</summary>
Motivation: QKD协议依赖认证的经典通信，但现有安全证明假设理想认证信道（从不中止、消息按时按序传递）。实际认证信道可能非对称中止（仅接收方检测到认证失败）且允许消息被延迟、重排或阻塞，这导致标准QKD安全定义和现有证明在实际场景中无效。

Method: 提出一个归约定理，证明在温和且易满足的协议条件下，任何在理想认证设置下被证明安全的QKD协议，在实际认证设置下也保持安全。这允许通过小修改将现有QKD证明提升到实际认证设置。

Result: 主要结果是归约定理，解决了QKD安全证明在实际认证场景中的有效性问题。该定理使得所有现有QKD安全证明可以通过小协议调整，追溯性地适用于实际认证设置。

Conclusion: 本文解决了QKD安全证明中理想认证假设与实际认证实现之间的差距问题。通过归约定理，证明了在温和条件下，理想认证下的安全保证可以扩展到实际认证场景，为QKD的实际部署提供了理论保障。

Abstract: Quantum Key Distribution (QKD) protocols rely on authenticated classical communication. Typical QKD security proofs are carried out in an idealized setting where authentication is assumed to behave honestly: it never aborts, and all classical messages are delivered faithfully with their original timing preserved. Authenticated channels that can be constructed in practice have different properties. Most critically, such channels may abort asymmetrically, such that only the receiving party may detect an authentication failure while the sending party remains unaware. Furthermore, an adversary may delay, reorder, or block classical messages. This discrepancy renders the standard QKD security definition and existing QKD security proofs invalid in the practical authentication setting. In this work we resolve this issue. Our main result is a reduction theorem showing that, under mild and easily satisfied protocol conditions, any QKD protocol proven secure under the honest authentication setting remains secure under a practical authentication setting. This result allows all existing QKD proofs to be retroactively lifted to the practical authentication setting with a minor protocol tweak.

</details>


### [239] [Quantum Paradoxes and the Quantum-Classical Transition under Unitary Measurement Dynamics with Random Hamiltonians](https://arxiv.org/abs/2601.17976)
*Alexey A. Kryukov*

Main category: quant-ph

TL;DR: 基于随机但幺正的投影态空间演化，提出量子测量的动力学框架，无需引入非幺正坍缩或额外假设，统一解释测量、态约化和量子-经典过渡。


<details>
  <summary>Details</summary>
Motivation: 传统量子测量理论需要引入非幺正的坍缩假设，这破坏了量子力学的幺正性。本文旨在建立一个完全基于幺正演化的测量理论，从动力学角度统一解释量子测量、态约化和量子-经典过渡。

Method: 使用高斯幺正系综的随机哈密顿量生成投影态空间的随机幺正演化。通过有限探测器分辨率定义的等价类构造经典可观测量和经典构型空间/相空间子流形。将演化约束到这些子流形上，分别得到牛顿运动（相空间约束）和经典布朗运动（构型空间约束）。

Result: 随机动力学下的跃迁概率满足玻恩规则，约束的经典演化产生经典测量的正态概率分布。测量、态约化和量子-经典过渡都从纯幺正动力学中涌现，无需额外假设。纠缠和EPR关联从复合态空间中联合态的几何演化中产生，保持时空局域性。

Conclusion: 该框架提供了与量子力学结构兼容的测量和经典性的统一动力学解释，完全基于幺正演化，消除了对非幺正坍缩假设的需求，为量子-经典过渡提供了自然的几何解释。

Abstract: We develop a dynamical framework for quantum measurement based on stochastic but unitary evolution in projective state space. Random Hamiltonians drawn from the Gaussian Unitary Ensemble generate stochastic unitary dynamics of the quantum state, while equivalence classes reflecting finite detector resolution define classical observables as well as classical configuration-space and phase-space submanifolds. When the evolution is constrained to the phase-space submanifold, free Schrödinger dynamics reduces to Newtonian motion, while stochastic motion constrained to the classical configuration-space submanifold yields ordinary Brownian motion in classical space. Transition probabilities under the stochastic dynamics satisfy the Born rule, whereas the constrained classical evolution produces the normal probability distributions characteristic of classical measurements. We show that, in this setting, measurement, state reduction, and the quantum-classical transition emerge from unitary dynamics alone, without invoking nonunitary collapse or additional postulates. Entanglement and EPR correlations arise geometrically from the evolution of joint states in composite state space, preserving locality in spacetime. The framework provides a unified dynamical account of measurement and classicality compatible with the structure of quantum mechanics.

</details>


### [240] [Linear combination of unitaries with exponential convergence](https://arxiv.org/abs/2601.18024)
*Peter Brearley,Thomas Howarth*

Main category: quant-ph

TL;DR: 提出一种将非酉算子分解为酉算子线性组合的通用方法，近似误差呈指数衰减，子归一化规模与误差倒数的双对数成正比，显著优于现有方法的多项式关系。


<details>
  <summary>Details</summary>
Motivation: 现有方法在量子电路中实现非酉算子时，子归一化规模与误差倒数的关系是多项式的，这限制了计算效率和精度。需要一种更高效的分解方法来降低子归一化成本。

Method: 基于傅里叶延拓方法，通过光滑周期延拓恒等映射得到正弦级数，其系数呈指数衰减。将正弦级数重写为复指数形式，然后应用于非酉算子的厄米和反厄米部分，得到酉算子的线性组合近似。

Result: 该方法实现了指数衰减的近似误差，子归一化规模与误差倒数的双对数成正比，显著优于现有多项式关系。通过正则化程序可以建立误差-子归一化的帕累托前沿，在固定误差预算下最小化子归一化。

Conclusion: 傅里叶酉算子线性组合方法为非酉量子计算提供了一个精确且通用的框架，显著提高了实现效率，为硬件和应用提供了优化策略。

Abstract: We present a general method for decomposing non-unitary operators into a linear combination of unitary operators, where the approximation error decays exponentially. The decomposition is based on a smooth periodic extension of the identity map via the Fourier extension method, resulting in a sine series with exponentially decaying coefficients. Rewriting the sine series in terms of complex exponentials, then evaluating it on the Hermitian and anti-Hermitian parts of a non-unitary operator, yields its approximation by a linear combination of unitaries. When implemented in a quantum circuit, the subnormalisation of the resulting block encoding scales with the double logarithm of the inverse error, substantially improving over the polynomial relationship in existing methods. For hardware or applications with a fixed error budget, we discuss a strategy to minimise subnormalisation by exploiting the overcomplete nature of the Fourier extension basis. This regularisation procedure traces an error-subnormalisation Pareto front, identifying coefficients that maximise the subnormalisation at a fixed error budget. Fourier linear combinations of unitaries thus provides an accurate and versatile framework for non-unitary quantum computing.

</details>


### [241] [A rigorous and complete security proof of decoy-state BB84 quantum key distribution](https://arxiv.org/abs/2601.18035)
*Devashish Tupkary,Shlok Nahar,Amir Arqand,Ernest Y. -Z. Tan,Norbert Lütkenhaus*

Main category: quant-ph

TL;DR: 本文为诱骗态BB84量子密钥分发协议提供了严格完整的安 全证明，并构建了一个模块化框架，可适用于多种QKD协议，统一了现实QKD分析所需的所有关键技术要素。


<details>
  <summary>Details</summary>
Motivation: 为诱骗态BB84 QKD协议提供数学上严格完整的安全证明，为认证和标准化工作奠定基础。同时开发一个通用模块化框架，能够适应多种QKD协议，统一QKD文献中分散的技术方法。

Method: 开发了一个通用模块化安全分析框架，统一了经典认证与处理、源替换方案、有限尺寸分析、源映射、压缩映射和诱骗态技术等QKD安全分析的所有主要要素。该框架可适用于制备-测量和基于纠缠的QKD协议。

Result: 成功为诱骗态BB84协议提供了严格的安全证明，并将QKD文献中分散的各种技术整合到一个统一的形式化框架中，为QKD安全提供了通用且严格的处理方法。

Conclusion: 这项工作不仅建立了特定协议的安全性，还为未来分析实现安全性奠定了基础，通过统一框架为实际缺陷的纳入提供了清晰路径，代表了QKD安全分析的重要进展。

Abstract: We present a rigorous and complete security proof of the decoy-state BB84 quantum key distribution (QKD) protocol. Our analysis aims to achieve a high standard of mathematical rigour and completeness, thereby providing the necessary foundation for certification and standardization efforts. Beyond establishing the security of a specific protocol, this work develops a general and modular framework that can be readily adapted to a broad class of QKD protocols, including both prepare-and-measure and entanglement-based variants. Our framework unifies all major ingredients required for the analysis of realistic QKD protocols, including the analysis of classical authentication and classical processing, source-replacement schemes, finite-size analysis, source maps, squashing maps, and decoy-state techniques. In doing so, this work consolidates a diverse range of techniques scattered across the QKD literature into a unified formalism, representing a general and rigorous treatment of QKD security. Finally, it outlines a clear path towards incorporating practical imperfections within the same framework, thereby laying the groundwork for addressing implementation security in future analysis.

</details>


### [242] [Differentiable Architecture Search for Adversarially Robust Quantum Computer Vision](https://arxiv.org/abs/2601.18058)
*Mohamed Afane,Quanjiang Long,Haoting Shen,Ying Mao,Junaid Farooq,Ying Wang,Juntao Chen*

Main category: quant-ph

TL;DR: 提出混合量子-经典可微分量子架构搜索框架，通过联合优化电路结构和鲁棒性，解决量子神经网络对对抗扰动和硬件噪声的极端敏感问题。


<details>
  <summary>Details</summary>
Motivation: 当前量子神经网络对对抗扰动和硬件噪声极度敏感，现有鲁棒性技术要么牺牲干净准确率，要么需要过高计算资源，阻碍实际部署。

Method: 提出混合量子-经典可微分量子架构搜索框架，在传统DQAS基础上增加轻量级经典噪声层，通过梯度方法联合优化门选择和噪声参数，保持量子电路完整性的同时引入可训练扰动。

Result: 在MNIST、FashionMNIST和CIFAR数据集上，相比现有量子架构搜索方法，在干净和对抗准确率上均取得一致改进；在各种攻击场景和实际量子噪声条件下保持优越性能；在真实量子硬件上验证了架构的实用性。

Conclusion: 策略性经典预处理结合可微分量子架构优化能显著增强量子神经网络鲁棒性，同时保持计算效率，为量子神经网络的实际部署提供了可行方案。

Abstract: Current quantum neural networks suffer from extreme sensitivity to both adversarial perturbations and hardware noise, creating a significant barrier to real-world deployment. Existing robustness techniques typically sacrifice clean accuracy or require prohibitive computational resources. We propose a hybrid quantum-classical Differentiable Quantum Architecture Search (DQAS) framework that addresses these limitations by jointly optimizing circuit structure and robustness through gradient-based methods. Our approach enhances traditional DQAS with a lightweight Classical Noise Layer applied before quantum processing, enabling simultaneous optimization of gate selection and noise parameters. This design preserves the quantum circuit's integrity while introducing trainable perturbations that enhance robustness without compromising standard performance. Experimental validation on MNIST, FashionMNIST, and CIFAR datasets shows consistent improvements in both clean and adversarial accuracy compared to existing quantum architecture search methods. Under various attack scenarios, including Fast Gradient Sign Method (FGSM), Projected Gradient Descent (PGD), Basic Iterative Method (BIM), and Momentum Iterative Method (MIM), and under realistic quantum noise conditions, our hybrid framework maintains superior performance. Testing on actual quantum hardware confirms the practical viability of discovered architectures. These results demonstrate that strategic classical preprocessing combined with differentiable quantum architecture optimization can significantly enhance quantum neural network robustness while maintaining computational efficiency.

</details>


### [243] [Overcoming Barren Plateaus in Variational Quantum Circuits using a Two-Step Least Squares Approach](https://arxiv.org/abs/2601.18060)
*Francis Boabang,Samuel Asante Gyamerah*

Main category: quant-ph

TL;DR: 提出两阶段优化框架解决变分量子算法中的贫瘠高原问题，通过凸初始化阶段平滑能量景观，再通过非凸细化阶段提升表达能力，在BB84协议量子密码分析中优于随机初始化方法。


<details>
  <summary>Details</summary>
Motivation: 变分量子算法在量子计算中至关重要，但随着系统规模扩大，梯度会迅速消失（贫瘠高原现象），使得训练深度或随机初始化电路几乎不可能，需要解决这一关键瓶颈。

Method: 提出两阶段优化框架：1) 凸初始化阶段：将量子能量景观（希尔伯特景观）塑造成平滑的低能盆地，使梯度易于检测并减少噪声影响；2) 非凸细化阶段：允许算法探索不同能量最小值，提升模型表达能力。

Result: 将两阶段解决方案应用于BB84量子密钥分发协议的量子密码分析，以确定最优克隆策略。仿真结果表明，提出的两阶段解决方案优于随机初始化对应方法。

Conclusion: 两阶段优化框架有效解决了变分量子算法中的贫瘠高原问题，通过先平滑能量景观再细化的策略，在量子密码分析等应用中展现出优越性能。

Abstract: Variational Quantum Algorithms are a vital part of quantum computing. It is a blend of quantum and classical methods for tackling tough problems in machine learning, chemistry, and combinatorial optimization. Yet as these algorithms scale up, they cannot escape the barren-plateau phenomenon. As systems grow, gradients can vanish so quickly that training deep or randomly initialized circuits becomes nearly impossible. To overcome the barren plateau problem, we introduce a two-stage optimization framework. First comes the convex initialization stage. Here, we shape the quantum energy landscape, the Hilmaton landscape, into a smooth, low-energy basin. This step makes gradients easier to spot and keeps noise from derailing the process. Once we have gotten a stable gradient flow, we move to the second stage: nonconvex refinement. In this phase, we allow the algorithm to explore different energy minima, thereby making the model more expressive. Finally, we used our two-stage solution to perform quantum cryptanalysis of the quantum key distribution protocol (i.e., BB84) to determine the optimal cloning strategies. The simulation results showed that our proposed two-stage solution outperforms its random initialization counterpart.

</details>


### [244] [Two-Polariton Blockade via Ultrastrong Light-Matter Coupling](https://arxiv.org/abs/2601.18083)
*Ting-Ting Ma,Jian Tang,Yun-Lan Zuo,Ran Huang. Adam Miranowicz,Franco Nori,Hui Jing*

Main category: quant-ph

TL;DR: 在超强耦合（USC）原子-腔系统中，单极化子共振驱动可实现双极化子阻塞（2PB），表现为双极化子聚束和三极化子抑制，为多粒子量子光源提供新途径。


<details>
  <summary>Details</summary>
Motivation: 探索超强耦合（USC）体系中独特的量子光学现象，区别于传统强耦合和弱耦合体系，为开发新型多粒子量子光源提供理论基础。

Method: 在原子-腔超强耦合系统中，采用适用于USC体系的修正二阶和三阶关联函数，分析单极化子共振驱动下的量子统计特性。

Result: 预测并证实了双极化子阻塞（2PB）现象，表现为显著的双极化子聚束和抑制的三极化子符合计数，这是传统耦合体系无法实现的独特效应。

Conclusion: 超强耦合体系为实现双极化子阻塞提供了新途径，对开发多粒子量子光源具有重要应用前景。

Abstract: We demonstrate that a two-polariton blockade (2PB) can occur under resonant single-polariton driving in an atom-cavity system operating in the ultrastrong coupling (USC) regime-a phenomenon qualitatively distinct from, and unattainable in, both the strong and weak coupling regimes. In the USC regime, where the ratio of the atom-cavity coupling strength to the cavity resonance frequency exceeds 0.1, hybrid light-matter quasiparticles known as polaritons emerge. By employing modified second- and third-order correlation functions appropriate for the USC regime, we predict the emergence of 2PB, characterized by pronounced two-polariton bunching accompanied by suppressed three-polariton coincidences. This Letter introduces a novel route to achieving 2PB, with promising implications for the realization of multiparticle quantum light sources in the USC regime.

</details>


### [245] [Sparse QUBO Formulation for Efficient Embedding via Network-Based Decomposition of Equality and Inequality Constraints](https://arxiv.org/abs/2601.18108)
*Kohei Suda,Soshun Naito,Yoshihiko Hasegawa*

Main category: quant-ph

TL;DR: 提出一种构建稀疏逻辑QUBO模型的方法，通过添加基于特定网络结构的辅助变量，将稠密约束分解为更小约束，显著减少量子退火中所需的量子比特数和连接数。


<details>
  <summary>Details</summary>
Motivation: 量子退火在解决组合优化问题时，由于需要将逻辑QUBO模型嵌入到量子退火器中，通常需要额外的量子比特开销。当逻辑QUBO模型具有稠密连接性时（这在等式和不等式约束中经常出现），这种开销变得尤为严重，限制了量子退火的性能。

Method: 提出一种构建稀疏逻辑QUBO模型的方法，通过添加基于特定网络结构的辅助变量，将原始约束分解为更小、更易管理的约束。这种方法将one-hot约束的边数从O(N²)减少到O(N)，将一般等式约束的边数在最坏情况下减少到O(N log N)。

Result: 在D-Wave硬件上的实验结果表明，与传统方法相比，该公式显著减少了嵌入所需的量子比特数，缩短了平均链长度，降低了链断裂率，并提高了可行解率。

Conclusion: 这项工作为在当前和未来的量子退火器上高效解决约束优化问题提供了一个实用工具，通过构建稀疏逻辑QUBO模型来减少量子比特开销，从而提升量子退火性能。

Abstract: Quantum annealing is a promising approach for solving combinatorial optimization problems. However, its performance is often limited by the overhead of additional qubits required for embedding logical QUBO models onto quantum annealers. This overhead becomes severe when logical QUBO models have dense connectivity. Such dense structures frequently arise when formulating equality and inequality constraints. To address this issue, we propose a method to construct a significantly sparser logical QUBO model for these constraints. By adding auxiliary variables based on specific network structures, our approach decomposes the original constraint into smaller, more manageable constraints. We demonstrate that this method reduces the number of edges (quadratic terms) from $O(N^2)$ to $O(N)$ for the one-hot constraint and to $O(N\log N)$ in the worst case for general equality constraints, where $N$ is the number of variables. Experimental results on D-Wave's hardware show that our formulation leads to substantial reductions in the number of qubits required for embedding, shorter average chain lengths, lower chain break rates, and higher feasible solution rates compared to conventional methods. This work provides a practical tool for efficiently solving constrained optimization problems on current and future quantum annealers.

</details>


### [246] [Quantum Recurrent Unit: A Parameter-Efficient Quantum Neural Network Component](https://arxiv.org/abs/2601.18164)
*Tzong-Daw Wu,Hsi-Sheng Goan*

Main category: quant-ph

TL;DR: QRU是一种新型量子循环神经网络架构，利用量子受控SWAP门实现信息选择机制，在保持恒定电路深度和参数数量的同时，达到与经典神经网络相当或更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习模型参数数量和计算资源需求快速增长，需要开发参数效率高且兼容NISQ（嘈杂中等规模量子）设备的量子神经网络架构。

Method: QRU采用量子受控SWAP（C-SWAP；Fredkin）门实现信息选择机制，受经典门控循环单元（GRU）启发，通过测量结果前馈状态传播和时间步共享参数，实现恒定电路深度和恒定参数数量。

Result: 在三个实验中：振荡行为预测（72参数QRU匹配197参数GRU）、乳腺癌分类（35参数达到96.13%准确率）、MNIST手写数字识别（132参数达到98.05%准确率，优于27,265参数CNN），QRU均以显著更少的参数实现可比或更优性能。

Conclusion: QRU展示了作为下一代机器学习系统基础构建模块的潜力，为更高效、可扩展的量子机器学习架构提供了有前景的途径。

Abstract: The rapid growth of modern machine learning (ML) models presents fundamental challenges in parameter efficiency and computational resource requirements. This study introduces the Quantum Recurrent Unit (QRU), a novel quantum neural network (NN) architecture specifically designed to address these challenges while remaining compatible with Noisy Intermediate-Scale Quantum (NISQ) devices. QRU leverages quantum controlled-SWAP (C-SWAP; Fredkin) gates to implement an information selection mechanism inspired by classical Gated Recurrent Units (GRUs), enabling selective processing of temporal information via quantum operations. Through its innovative recurrent architecture featuring measurement results feedforward state propagation and shared parameters across time steps, QRU achieves constant circuit depth and constant parameter count regardless of input sequence length, effectively circumventing stringent NISQ hardware constraints. We systematically validate QRU through three progressive experiments: (1) oscillatory behavior prediction, where 72-parameter QRU matches 197-parameter classical GRU performance; (2) Wisconsin Diagnostic Breast Cancer classification, where 35 parameters achieve 96.13% accuracy comparable to 167-parameter artificial NNs; and (3) MNIST handwritten digit recognition, where 132 parameters reach 98.05% accuracy, outperforming a 27,265-parameter convolutional NN. These results demonstrate that QRU consistently achieves comparable or superior performance with significantly fewer parameters than classical NNs while maintaining constant quantum circuit depth. The architecture's quantum-native design, combining C-SWAP-based information selection with novel recurrent processing, suggests QRU's potential as a fundamental building block for next-generation ML systems, offering a promising pathway toward more efficient and scalable quantum ML architectures.

</details>


### [247] [Resource-Efficient Noise Spectroscopy for Generic Quantum Dephasing Environments](https://arxiv.org/abs/2601.18290)
*Yuan-De Jin,Zheng-Fei Ye,Wen-Long Ma*

Main category: quant-ph

TL;DR: 提出基于重复弱测量的资源高效方法，直接测量导致量子比特相位退相干的环境噪声谱


<details>
  <summary>Details</summary>
Motivation: 传统基于动力学解耦的噪声谱方法存在频率范围受限、资源效率低的问题，需要更高效的方法来直接测量量子环境噪声谱

Method: 使用基于Ramsey干涉测量的重复弱测量，在环境自由演化期间周期性应用，测量相关性近似对应噪声相关函数的直接采样

Result: 该方法能够高效测量完整噪声谱，检测频率范围不受量子比特相干时间限制，资源效率优于相关谱方法（O(N) vs O(N²)）

Conclusion: 提出的重复弱测量方法为量子环境噪声谱提供了一种资源高效、频率范围不受限的直接测量方案

Abstract: We present a resource-efficient method based on repetitive weak measurements to directly measure the noise spectrum of a generic quantum environment that causes qubit phase decoherence. The weak measurement is induced by a Ramsey interferometry measurement (RIM) on the qubit and periodically applied during the free evolution of the environment. We prove that the measurement correlation of such repetitive RIMs approximately corresponds to a direct sampling of the noise correlation function, thus enabling direct noise spectroscopy of the environment. Compared to dynamical-decoupling-based noise spectroscopy, this method can efficiently measure the full noise spectrum with the detected frequency range not limited by qubit coherence time. This method is also more resource-efficient than the correlation spectroscopy, as for the same detection accuracy with $N$ sampling times, it takes total detection time $O(N)$ while the latter one takes time $O(N^2)$. We numerically demonstrate this method for both bosonic and spin baths.

</details>


### [248] [Scalable Repeater Architecture for Long-Range Quantum Energy Teleportation in Gapped Systems](https://arxiv.org/abs/2601.18327)
*M. Y. Abd-Rabbou,Irfan Siddique,Saeed Haddadi,Cong-Feng Qiao*

Main category: quant-ph

TL;DR: 本文提出了一种分层量子中继器架构，用于解决量子能量隐形传态（QET）在长距离扩展中的可行性危机，将资源消耗从指数级降低到多项式级，首次证明了在任意距离上激活真空能量的物理可行性和计算可处理性。


<details>
  <summary>Details</summary>
Motivation: 量子能量隐形传态（QET）协议虽然理论上允许通过消耗预存纠缠和经典通信来激活局部真空能量，但在实际应用中受到能隙多体系统基本局域性的严重限制。由于基态关联的指数聚类，能量提取被限制在微观尺度，形成了QET的可扩展性危机。

Method: 首先严格分析了单体测量诱导策略的局限性，然后提出并分析了一种适用于能量隐形传态的分层量子中继器架构。该架构通过协调：1）预示纠缠生成，2）迭代纠缠纯化，3）嵌套纠缠交换，有效对抗噪声量子信道固有的保真度退化。

Result: 该分层架构从根本上改变了操作资源的缩放关系，从指数级转变为多项式级。这首次证明了在任意距离上激活真空能量的物理可行性和计算可处理性。

Conclusion: 本文的意义不在于获得净能量增益，而在于确立长距离QET作为远程量子控制和资源分配的可行协议。通过解决可扩展性危机，为量子能量隐形传态的实际应用铺平了道路。

Abstract: Quantum Energy Teleportation (QET) constitutes a paradigm-shifting protocol that permits the activation of local vacuum energy through the consumption of pre-existing entanglement and classical communication. Nevertheless, the implementation of QET is severely impeded by the fundamental locality of gapped many-body systems, where the exponential clustering of ground-state correlations restricts energy extraction to microscopic scales. In this work, we address this scalability crisis within the framework of the one-dimensional anisotropic XY model. We initially provide a rigorous characterization of a monolithic measurement-induced strategy, demonstrating that while bulk projective measurements can theoretically induce long-range couplings, the approach is rendered physically untenable by exponentially diverging thermodynamic costs and vanishing success probabilities. To circumvent this impasse, we propose and analyze a hierarchical quantum repeater architecture adapted for energy teleportation. By orchestrating heralded entanglement generation, iterative entanglement purification, and nested entanglement swapping, our protocol effectively counteracts the fidelity degradation inherent in noisy quantum channels. We establish that this architecture fundamentally alters the operational resource scaling from exponential to polynomial. This proves, for the first time, the physical permissibility and computational tractability of activating vacuum energy at arbitrary distances. The significance lies not in net energy gain, but in establishing long-range QET as a viable protocol for remote quantum control and resource distribution.

</details>


### [249] [Scaling of multicopy constructive interference of Gaussian states](https://arxiv.org/abs/2601.18347)
*Matthieu Arnhem,Radim Filip*

Main category: quant-ph

TL;DR: 该论文分析了多路复用非经典高斯态在不同多模干涉架构中的标度律，引入增益-不稳定性比来量化大规模干涉方案中的资源不稳定性效应。


<details>
  <summary>Details</summary>
Motivation: 量子技术的进步关键依赖于基本量子资源的规模化。理想的多路复用能在应用中提供更大增益，但对于非相同、脆弱且变化的资源，其规模化在理论和实验上都尚未明确。多模干涉是玻色子系统中已被广泛用于开发量子技术的重要工具。

Method: 分析、预测和比较了通过位移携带信息且具有弱涨落压缩的多路复用非经典高斯态在不同多模干涉架构中的建设性干涉标度律。使用信噪比量化位移相对于噪声的增加，并引入增益-不稳定性比来数值估计大规模干涉方案中未探索的资源不稳定性效应。

Result: 提出了用于量化标度律的增益-不稳定性比，这为其他玻色子资源的广泛理论研究和后续可行的实验验证开辟了道路。

Conclusion: 增益-不稳定性比的使用为量化标度律提供了新方法，为其他玻色子资源的广泛理论研究和后续可行的实验验证开辟了步骤，这对于这些平台的进一步发展是必要的。

Abstract: Quantum technology advances crucially depend on the scaling up of essential quantum resources. Their ideal multiplexing offers more significant gains in applications; however, the scaling of the nonidentical, fragile and varying resources is neither theoretically nor experimentally known. For bosonic systems, multimode interference is an essential tool already widely exploited to develop quantum technology. Here, we analyze, predict and compare essential scaling laws for a constructive interference of multiplexed nonclassical Gaussian states carrying information by displacement with weakly fluctuating squeezing in different multimode interference architectures. The signal-to-noise ratio quantifies the increase in displacement relative to the noise. We introduce the gain-to-instability ratio to numerically estimate the effect of unexplored resource instabilities in a large scale interference scheme. The use of the gain-to-instability ratio to quantify the scaling laws opens steps for extensive theoretical investigation of other bosonic resources and follow-up feasible experimental verification necessary for further development of these platforms.

</details>


### [250] [An Adaptive Purification Controller for Quantum Networks: Dynamic Protocol Selection and Multipartite Distillation](https://arxiv.org/abs/2601.18351)
*Pranav Kulkarni,Leo Sünkel,Michael Kölle*

Main category: quant-ph

TL;DR: 提出自适应纯化控制器(APC)，动态优化纠缠蒸馏序列以最大化满足严格保真度阈值的纠缠对交付率，消除静态协议的"保真度悬崖"问题。


<details>
  <summary>Details</summary>
Motivation: 量子互联网中纠缠分发的效率受光子损耗、存储器相干时间、门错误率等物理链路参数动态波动的影响，静态纯化策略无法适应这种动态变化，导致性能下降。

Method: 将协议选择视为资源分配问题，提出自适应纯化控制器(APC)，采用动态规划规划器配合帕累托剪枝，动态切换纯化深度和协议家族（如BBPSSW vs. DEJMPS），在生成速率和状态质量之间进行权衡。

Result: 仿真结果表明，该方法消除了静态协议固有的"保真度悬崖"，防止了高噪声区域中的资源浪费，并扩展到异构场景（多体GHZ态生成和连续变量系统），计算开销在毫秒级，具有实时可行性。

Conclusion: 自适应纯化控制器能够自主优化纠缠蒸馏序列，在动态变化的量子链路条件下最大化"有效吞吐量"，为量子互联网的实际部署提供了实用的动态资源管理方案。

Abstract: Efficient entanglement distribution is the cornerstone of the Quantum Internet. However, physical link parameters such as photon loss, memory coherence time, and gate error rates fluctuate dynamically, rendering static purification strategies suboptimal. In this paper, we propose an Adaptive Purification Controller (APC) that autonomously optimizes the entanglement distillation sequence to maximize the "goodput," the rate of delivered pairs meeting a strict fidelity threshold. By treating protocol selection as a resource allocation problem, the APC dynamically switches between purification depths and protocol families (e.g., BBPSSW vs. DEJMPS) to navigate the trade-off between generation rate and state quality. Using a dynamic programming planner with Pareto pruning, simulation results demonstrate that our approach eliminates the "fidelity cliffs" inherent in static protocols and prevents resource wastage in high-noise regimes. Furthermore, we extend the controller to heterogeneous scenarios, demonstrating robustness for both multipartite GHZ state generation and continuous variable systems using effective noiseless linear amplification models. We benchmark its computational overhead, confirming real-time feasibility with decision latencies in the millisecond range per link.

</details>


### [251] [Bohr's complementarity principle tested on a real quantum computer via interferometer experiments](https://arxiv.org/abs/2601.18366)
*Celia Álvarez Álvarez,Mariamo Mussa Juane*

Main category: quant-ph

TL;DR: 本文通过量子电路实验验证了波粒二象性的互补关系，在一比特和两比特电路中实现了干涉实验，并通过量子态层析重建密度矩阵来测试互补关系。


<details>
  <summary>Details</summary>
Motivation: 玻尔的互补原理是量子力学的核心概念，本文旨在提出并讨论量子系统波动性和粒子性方面更新的互补关系，并通过实验验证。

Method: 在一比特和两比特量子电路中实现两个干涉实验，在真实硬件上执行，使用量子态层析重建最终态密度矩阵，通过直接计算测试互补关系。

Result: 实验结果以图形方式呈现，并通过均方误差分析进行展示，以更好地理解互补关系的验证结果。

Conclusion: 通过量子电路实验成功验证了波粒二象性的互补关系，为量子力学基本原理提供了实验支持。

Abstract: Bohr's Complementarity Principle is a core concept of quantum mechanics. In this article, an updated complementarity relation for the wave and ondulatory aspects of a quantum system is presented and discussed. Two interferometric experiments are implemented in one and two qubit circuits and executed on real hardware. The final state density matrices are reconstructed using quantum state tomography and the complementarity relation is tested via direct computation. Results of the executions are presented both graphically and with a mean squared error analysis for a better comprehension.

</details>


### [252] [Atom-light hybrid interferometer for atomic sensing with quantum memory](https://arxiv.org/abs/2601.18373)
*Xingchang Wang,Xinyun Liang,Liang Dong,Ying Zuo,Jianmin Wang,Dasen Yang,Linyu Chen,Georgios A. Siviloglou,Z. Y. Ou,J. F. Chen*

Main category: quant-ph

TL;DR: 提出一种基于量子记忆的原子光干涉仪新协议，通过外差混频记录光电流，无需光学延迟线即可从光与原子自旋波的干涉图案中恢复携带磁场信息的复正交振幅。


<details>
  <summary>Details</summary>
Motivation: 传统原子光干涉仪需要额外光学延迟线来补偿记忆时间，限制了其利用量子记忆终极传感性能的效率。需要开发新协议来克服这一限制。

Method: 采用外差混频协议，将光电流与稳定本地振荡器混合记录。通过分析光与原子自旋波之间的干涉图案，恢复携带外部磁场相位信息的复正交振幅，无需光与自旋波在时间上重叠。

Result: 成功从干涉图案中恢复信息，证明灵敏度随量子记忆寿命呈有利比例缩放。无需光学延迟线即可实现高效传感。

Conclusion: 该协议为构建分布式量子网络中的量子记忆辅助原子光干涉仪提供了重要应用前景，突破了传统方法的限制。

Abstract: Quantum memories feature a reversible conversion of optical fields into long-lived atomic spin waves, and are therefore ideal for operating as sensitive atomic sensors. However, up to now, atom-light interferometers have lacked an efficient approach to exploit their ultimate atomic sensing performance, since an extra optical delay line is required to compensate for the memory time. Here, we report a new protocol that records the photocurrent via heterodyne mixing with a stable local oscillator. The obtained complex quadrature amplitude that carries information imprinted on its phase by an external magnetic field, is successfully recovered from the interference patterns between the light and the atomic spin wave, without the stringent requirement of having them overlap in time. Our results reveal that the sensitivity scales favorably with the lifetime of the quantum memory. Our work may have important applications in building distributed quantum networks through quantum memory-assisted atom-light interferometers.

</details>


### [253] [Quantum Error Correction on Error-mitigated Physical Qubits](https://arxiv.org/abs/2601.18384)
*Minjun Jeon,Zhenyu Cai*

Main category: quant-ph

TL;DR: 提出一个通用框架，将线性量子误差缓解技术直接应用于逻辑量子比特内的物理量子比特，通过利用量子纠错的线性特性，在不修改QEC解码器的情况下抑制逻辑错误。


<details>
  <summary>Details</summary>
Motivation: 在早期容错量子计算架构中，逻辑量子比特的性能受限于物理量子比特的错误率。传统方法需要大量物理量子比特来实现高距离纠错码，资源消耗大。需要一种更高效的策略来提升逻辑性能。

Method: 提出一个通用框架，利用量子纠错的线性特性，将任何线性QEM方法（如PEC、ZNE、对称性验证）集成到物理层。特别应用PEC到存储实验中，分析和数值验证了可以消除逻辑误差的主导阶贡献。

Result: 理论证明和数值模拟显示，距离-3代码配合物理级PEC可以实现比距离-5未缓解代码更低的逻辑错误率，同时分别减少40%和64%的量子比特使用。有效代码距离增加2。

Conclusion: 物理级量子误差缓解是一种广泛兼容且资源高效的策略，能够显著提升早期容错架构中的逻辑性能，为实用量子计算提供了有前景的途径。

Abstract: We present a general framework for applying linear quantum error mitigation (QEM) techniques directly to physical qubits within a logical qubit to suppress logical errors. By exploiting the linearity of quantum error correction (QEC), we demonstrate that any linear QEM method$\unicode{x2014}$including probabilistic error cancellation (PEC), zero-noise extrapolation (ZNE), and symmetry verification$\unicode{x2014}$can be integrated into the physical layer without requiring modifications to the subsequent QEC decoder. Applying this framework to memory experiments using PEC, we analytically prove and numerically verify that the leading-order contribution to the logical error can be removed, increasing the effective code distance by 2. Our simulations on repetition and rotated surface codes show that a distance-3 code with physical-level PEC achieves logical error rates lower than or similar to a distance-5 unmitigated code while using 40% and 64% fewer qubits, respectively. These results establish physical-level QEM as a widely compatible and resource-efficient strategy for enhancing logical performance in early fault-tolerant architectures.

</details>


### [254] [Emergent Cooperation in Quantum Multi-Agent Reinforcement Learning Using Communication](https://arxiv.org/abs/2601.18419)
*Michael Kölle,Christian Reff,Leo Sünkel,Julian Hager,Gerhard Stenzel,Claudia Linnhoff-Popien*

Main category: quant-ph

TL;DR: 量子多智能体强化学习中，通过通信协议（MATE、MEDIATE等）在顺序社会困境中实现高效合作


<details>
  <summary>Details</summary>
Motivation: 经典多智能体强化学习在顺序社会困境中已展现合作涌现能力，但量子多智能体强化学习中的合作研究，特别是通过通信机制的研究仍然有限

Method: 将四种通信方法应用于量子Q学习智能体：MATE协议、MEDIATE协议、Gifting奖励机制和RIAL，在三种顺序社会困境（囚徒困境、猎鹿博弈、斗鸡博弈）中进行评估

Result: 实验结果显示，使用MATE_TD、AutoMATE、MEDIATE-I和MEDIATE-S的方法在所有困境中都实现了高合作水平，证明通信是促进量子多智能体强化学习中合作涌现的有效机制

Conclusion: 通信机制在量子多智能体强化学习中能够有效促进合作涌现，为量子强化学习在复杂多智能体环境中的应用提供了新途径

Abstract: Emergent cooperation in classical Multi-Agent Reinforcement Learning has gained significant attention, particularly in the context of Sequential Social Dilemmas (SSDs). While classical reinforcement learning approaches have demonstrated capability for emergent cooperation, research on extending these methods to Quantum Multi-Agent Reinforcement Learning remains limited, particularly through communication. In this paper, we apply communication approaches to quantum Q-Learning agents: the Mutual Acknowledgment Token Exchange (MATE) protocol, its extension Mutually Endorsed Distributed Incentive Acknowledgment Token Exchange (MEDIATE), the peer rewarding mechanism Gifting, and Reinforced Inter-Agent Learning (RIAL). We evaluate these approaches in three SSDs: the Iterated Prisoner's Dilemma, Iterated Stag Hunt, and Iterated Game of Chicken. Our experimental results show that approaches using MATE with temporal-difference measure (MATE\textsubscript{TD}), AutoMATE, MEDIATE-I, and MEDIATE-S achieved high cooperation levels across all dilemmas, demonstrating that communication is a viable mechanism for fostering emergent cooperation in Quantum Multi-Agent Reinforcement Learning.

</details>


### [255] [A Theory of Single-Antenna Atomic Beamforming](https://arxiv.org/abs/2601.18426)
*Mingyao Cui,Qunsong Zeng,Kaibin Huang*

Main category: quant-ph

TL;DR: 该论文分析了里德堡原子接收器的空间响应特性，揭示了增加蒸汽室长度会产生与本地振荡器场对齐的接收波束，并提出了分段蒸汽室架构来克服激光功率指数衰减的限制，实现原子波束成形增益。


<details>
  <summary>Details</summary>
Motivation: 现有研究将里德堡原子接收器建模为各向同性的点接收器，忽略了蒸汽室内原子量子态的空间变化，从而无法准确表征其接收模式。需要解决这一问题以准确理解RAREs的空间响应特性。

Method: 对标准本地振荡器驱动的里德堡原子接收器进行理论分析，研究蒸汽室长度对接收波束的影响。提出分段蒸汽室架构，将蒸汽室分成由空气间隙分隔的多个段，以在保持总蒸汽室长度不变的情况下增加有效相互作用长度。

Result: 增加蒸汽室长度会产生与本地振荡器场对齐的接收波束，波束宽度与蒸汽室长度成反比。分段蒸汽室设计能够在保持总蒸汽室长度（从而保持传播损耗）不变的情况下增加有效相互作用面积，相比传统连续蒸汽室产生更窄的波束宽度和更高的波束成形增益。

Conclusion: 该研究揭示了里德堡原子接收器的空间响应特性，实现了单天线RARE的原子波束成形以增强接收信噪比。提出的分段蒸汽室架构克服了激光功率指数衰减的限制，为高性能量子无线电接收器设计提供了新思路。

Abstract: Leveraging the quantum advantages of highly excited atoms, Rydberg atomic receivers (RAREs) represent a paradigm shift in radio wave detection, offering high sensitivity and broadband reception. However, existing studies largely model RAREs as isotropic point receivers and overlook the spatial variations of atomic quantum states within vapor cells, thus inaccurately characterizing their reception patterns. To address this issue, we present a theoretical analysis of the aforementioned spatial responses of a standard local-oscillator (LO)- dressed RARE. Our results reveal that increasing the vapor-cell length produces a receive beam aligned with the LO field, with a beamwidth inversely proportional to the cell length. This finding enables atomic beamforming to enhance received signal-to-noise ratio using only a single-antenna RARE. Furthermore, we derive the achievable beamforming gain by characterizing and balancing the fundamental tradeoff between the effects of increasing the vapor cell length and the exponential power decay of laser propagating through the cell. To overcome the limitation imposed by exponential decay, we propose a novel RARE architecture termed segmental vapor cell. This architecture consists of vapor-cell segments separated by clear-air gaps, allowing the total cell length (and hence propagation loss) to remain fixed while the effective cell length increases. As a result, this segmented design expands the effective atom-field interaction area without increasing the total vapor cell length, yielding a narrower beamwidth and thus higher beamforming gain as compared with a traditional continuous vapor cell.

</details>


### [256] [Physics-Informed Hybrid Quantum-Classical Dispatching for Large-Scale Renewable Power Systems:A Noise-Resilient Framework](https://arxiv.org/abs/2601.18482)
*Fu Zhang,Yuming Zhao*

Main category: quant-ph

TL;DR: 提出PI-HQCD框架，将物理约束嵌入量子计算，解决可再生能源调度中的随机性和非凸性问题，相比传统方法提升经济性和可再生能源利用率。


<details>
  <summary>Details</summary>
Motivation: 高渗透率可再生能源引入的随机性和非凸性挑战传统优化计算极限，现有量子算法将电网视为"黑箱"，存在可扩展性差（贫瘠高原）和物理约束违反问题。

Method: 提出物理信息混合量子经典调度框架，构建拓扑感知哈密顿量嵌入线性化潮流方程、储能动态和多时间尺度耦合，并设计噪声自适应正则化机制保证收敛稳定性。

Result: 在IEEE 39节点和118节点区域电网测试中，PI-HQCD相比随机对偶动态规划实现更优经济效率和更高可再生能源利用率，理论分析证实梯度方差按O(1/N)缩放，有效缓解贫瘠高原。

Conclusion: 该工作建立了将工程物理嵌入量子计算的严谨范式，为下一代电网运行中实现实用量子优势铺平道路。

Abstract: The integration of high-penetration renewable energy introduces significant stochasticity and non-convexity into power system dispatching, challenging the computational limits of classical optimization. While Variational Quantum Algorithms (VQAs) on Noisy Intermediate-Scale Quantum (NISQ) devices offer a promising path for combinatorial acceleration, existing approaches typically treat the power grid as a "black box", suffering from poor scalability (barren plateaus) and frequent violations of physical constraints. Bridging these gaps, this paper proposes a Physics-Informed Hybrid Quantum-Classical Dispatching (PI-HQCD) framework. We construct a topology-aware Hamiltonian that explicitly embeds linearized power flow equations, storage dynamics, and multi-timescale coupling directly into the quantum substrate, significantly reducing the search space dimensionality. We further derive a noise-adaptive regularization mechanism that theoretically bounds the effective Lipschitz constant of the objective function, guaranteeing convergence stability under realistic quantum measurement noise. Numerical experiments on the IEEE 39-bus benchmark and a 118-bus regional grid demonstrate that PI-HQCD achieves superior economic efficiency and higher renewable utilization compared to stochastic dual dynamic programming (SDDP). Theoretical analysis confirms that this topology-aware design leads to an O(1/N) gradient variance scaling, effectively mitigating barren plateaus and ensuring scalability for larger networks. This work establishes a rigorous paradigm for embedding engineering physics into quantum computing, paving the way for practical quantum advantage in next-generation grid operations.

</details>


### [257] [Qubit-parity interference despite unknown interaction phases](https://arxiv.org/abs/2601.18499)
*Kratveer Singh,Kimin Park,Vojtěch Švarc,Artem Kovalenko,Tuan Pham,Ondřej Číp,Lukáš Slodička,Radim Filip*

Main category: quant-ph

TL;DR: 实验展示了在未知相位下量子系统间的干涉现象，通过交替红蓝边带脉冲实现与相位无关的量子比特奇偶性干涉，接近理论极限可见度。


<details>
  <summary>Details</summary>
Motivation: 量子干涉通常需要精确控制相互作用相位，但本文探索在相位稳定但未知的情况下是否仍能观测到干涉现象，这对于量子技术具有重要意义。

Method: 使用囚禁的钙离子，通过交替施加红蓝边带脉冲制备薛定谔猫态，构建对驱动激光相位不敏感的量子比特奇偶性干涉仪。

Result: 实现了20%和40%的特征可见度，接近理论极限，无需完整态层析即可作为高维态的可扩展相干性见证。

Conclusion: 证明了在未知相位下量子干涉的可能性，为量子技术中相位不敏感干涉提供了新方法，简化了高维量子态相干性检测。

Abstract: Quantum interference between interacting systems is fundamental to basic science and quantum technology, but it typically requires precise control of the interaction phases of lasers or microwave generators. Can interference be observed if those interaction phases are stable but unknown, usually prohibitive for complex state without active control? Here, we answer this question by experimentally preparing a Schrödinger-cat-like state of an internal qubit and a motional oscillator of a trapped $^{40}$Ca$^{+}$ ion, and its robustness to such uncontrolled phase. By applying alternating red and blue sideband pulses, we enforce a strict qubit-parity correlation and interference inherently insensitive to stable but unknown phases of the driving laser. For this qubit-parity interference, we use a minimal two-pulse interferometric sequence to demonstrate characteristic visibilities of $20\%$ and $40\%$, which approach the theoretical visibility limit, providing a scalable coherence witness without full state tomography for high-dimensional states.

</details>


### [258] [Imperfect blockade in Rydberg superatoms](https://arxiv.org/abs/2601.18506)
*Valentin Magro,Sébastien Garcia,Alexei Ourjoumtsev*

Main category: quant-ph

TL;DR: 该论文提出了一个从第一性原理推导的模型，用于准确描述大型无序原子系综中里德堡相互作用，这对于评估超原子量子网络节点的性能至关重要。


<details>
  <summary>Details</summary>
Motivation: 超原子作为量子网络节点的构建模块受到广泛关注，但评估其性能需要准确、物理信息丰富且数值可扩展的方法来描述大型无序原子系综中的相互作用。

Method: 从第一性原理推导出一个理论模型，用于描述里德堡原子系综中的相互作用，并通过暴力数值计算和实验数据进行验证。

Result: 该模型成功通过了暴力数值计算和实验数据的测试，证明能够准确描述大型无序原子系综中的里德堡相互作用。

Conclusion: 该模型对于定量预测门保真度或光子发射效率至关重要，并能指导实验朝着大规模超原子基系统发展。

Abstract: Ensembles of atoms interacting via their Rydberg levels, known as "superatoms" for their ability to encode qubits and to emit single photons, attract increasing attention as building blocks for quantum network nodes. Assessing their performance requires an accurate, physically informative and numerically scalable description of interactions in a large and disordered ensemble. We derive such a description from first principles and successfully test it against brute-force numerics and experimental data. This model proves essential to make quantitative predictions about gate fidelities or photon emission efficiencies, and to guide experiments towards large-scale superatom-based systems.

</details>


### [259] [Simultaneous determination of multiple low-lying energy levels on a superconducting quantum processor](https://arxiv.org/abs/2601.18514)
*Huili Zhang,Yibin Guo,Guanglei Xu,Yulong Feng,Jingning Zhang,Hai-feng Yu,S. P. Zhao*

Main category: quant-ph

TL;DR: 实验实现了辅助比特纠缠变分量子本征求解器（AEVQE），在超导量子云平台上求解H₂分子和横向场伊辛模型的低能级，展示了算法的实验可行性。


<details>
  <summary>Details</summary>
Motivation: 确定基态和低激发态在许多场景中至关重要，需要实验验证AEVQE算法在实际量子平台上的可行性。

Method: 在超导量子云平台上实验实现AEVQE算法，利用辅助比特与物理比特的纠缠同时求解多个低能级，应用于H₂分子和横向场伊辛模型。

Result: 成功获得了H₂的势能曲线，从平均绝对磁化强度中观察到横向场伊辛模型的铁磁到顺磁相变迹象，并与无辅助比特的VQE算法进行了性能比较。

Conclusion: AEVQE算法在公开可访问的量子平台上具有实验可行性，为VQE方法解决实际问题提供了指导。

Abstract: Determining the ground and low-lying excited states is critical in numerous scenarios. Recent work has proposed the ancilla-entangled variational quantum eigensolver (AEVQE) that utilizes entanglement between ancilla and physical qubits to simultaneously tagert multiple low-lying energy levels. In this work, we report the experimental implementation of the AEVQE on a superconducting quantum cloud platform, demonstrating the full procedure of solving the low-lying energy levels of the H$_2$ molecule and the transverse-field Ising models (TFIMs). We obtain the potential energy curves of H$_2$ and show an indication of the ferromagnetic to paramagnetic phase transition in the TFIMs from the average absolute magnetization. Moreover, we investigate multiple factors that affect the algorithmic performance and provide a comparison with ancilla-free VQE algorithms. Our work demonstrates the experimental feasibility of the AEVQE algorithm and offers a guidance for the VQE approach in solving realistic problems on publicly-accessible quantum platforms.

</details>


### [260] [Quantum Key Distribution with a Negatively Charged Quantum Dot Single-Photon Source](https://arxiv.org/abs/2601.18518)
*Parvendra Kumar*

Main category: quant-ph

TL;DR: 该研究比较了不同激发方式下量子点单光子源的性能，发现绝热快速通道激发比共振激发能更好地抑制多光子发射并提高光子不可区分性，在短中距离量子密钥分发中优于泊松分布光源，但在长距离下泊松分布光源表现更优。


<details>
  <summary>Details</summary>
Motivation: 量子密钥分发协议需要高质量的单光子源，要求多光子发射概率极低。现有量子点单光子源在不同激发方式下的性能差异及其在量子密钥分发中的实际应用效果需要系统评估。

Method: 研究采用椭圆柱微腔中的带负电荷量子点，比较共振激发和绝热快速通道激发两种方式。评估了BB84和双场量子密钥分发协议的密钥率，并与泊松分布光源（如弱相干脉冲和降频转换源）进行性能对比。

Result: 绝热快速通道激发显著抑制多光子发射概率并提高光子不可区分性；在量子密钥分发中，绝热激发相比共振激发带来适度但一致的密钥率提升；量子点单光子源在短中距离优于泊松分布光源，但在长距离下被超越。

Conclusion: 绝热激发是提升量子点单光子源性能的有效方法，量子点源在短中距离量子密钥分发中具有优势，但长距离应用需要考虑光源选择策略。

Abstract: Various quantum key distribution protocols require bright single-photon sources with a very low probability of multiphoton emission. In this work, we investigate single-photon generation from a negatively charged quantum dot embedded in an elliptical pillar microcavity, driven using either resonant excitation or adiabatic rapid passage (ARP). Our results show that ARP excitation significantly suppresses multiphoton emission probability and improves photon indistinguishability compared to resonant excitation. We further evaluate the secure key rate of both BB84 and twin-field quantum key distribution (TF-QKD) using quantum-dot single-photon sources and compare their performance with that of Poisson-distributed photon sources (PDS) such as weak coherent pulses and down-conversion sources. The analysis reveals that adiabatic excitation offers a modest but consistent enhancement in secure key rate relative to resonant excitation. Moreover, quantum-dot single-photon sources outperform PDS sources over short and intermediate distances; however, at longer distances, PDS sources eventually surpass quantum-dot sources in both infinite decoy-state BB84 and TF-QKD.

</details>


### [261] [Certifying optimal device-independent quantum randomness in quantum networks](https://arxiv.org/abs/2601.18534)
*Shuai Zhao,Rong Wang,Qi Zhao*

Main category: quant-ph

TL;DR: 提出基于GHZ态稳定子群的多体贝尔不等式族，可在非最大贝尔值下高效认证量子随机性和自测试GHZ态，优于现有不等式。


<details>
  <summary>Details</summary>
Motivation: 当前设备无关量子随机性认证策略在非最大贝尔值下效率受限，特别是多体情况。需要更高效的多体贝尔不等式来改进设备无关量子密码学应用。

Method: 从GHZ态的稳定子群出发，构造一族结构简单的多体贝尔不等式。该不等式族易于扩展到更多参与方，并推导了Holevo量的通用解析上界。

Result: 相比Mermin型不等式，该不等式族在非最大贝尔值下能更高效认证量子随机性。在三体情况下，其性能优于MABK、Parity-CHSH和Holz不等式。

Conclusion: 提出的贝尔不等式族为量子网络中的设备无关量子密码学实验研究提供了更高效的工具，特别适用于非理想实验条件下的随机性认证。

Abstract: Bell nonlocality provides a device-independent (DI) way to certify quantum randomness, based on which true random numbers can be extracted from the observed correlations without detail characterizations on devices for quantum state preparation and measurement. However, the efficiency of current strategies for DI randomness certification is still heavily constrained when it comes to non-maximal Bell values, especially for multiple parties. Here, we present a family of multipartite Bell inequalities that allows to certify optimal quantum randomness and self-test GHZ (Greenberger-Horne-Zeilinger) states, which are inspired from the stabilizer group of the GHZ state. Due to the simple representation of stabilizer group for GHZ states, this family of Bell inequalities is of simple structure and can be easily expanded to more parties. Compared with the Mermin-type inequalities, this family of Bell inequality is more efficient in certifying quantum randomness when non-maximal Bell values achieved. Meanwhile, the general analytical upper bound for the Holevo quantity is presented, and achieves better performance compared with the MABK (Mermin-Ardehali-Belinskii-Klyshko) inequality, Parity-CHSH (Clauser-Horne-Shimony-Holt) inequality and Holz inequality at $N=3$, which is of particular interests for experimental researches on DI quantum cryptography in quantum networks.

</details>


### [262] [Sufficient conditions for additivity of the zero-error classical capacity of quantum channels](https://arxiv.org/abs/2601.18538)
*Jeonghoon Park,Jeong San Kim*

Main category: quant-ph

TL;DR: 本文研究量子信道的一次性零误差经典容量与对应的非交换图独立数之间的乘性关系，给出了独立数乘性的充分条件及具体量子信道示例。


<details>
  <summary>Details</summary>
Motivation: 量子信道的一次性零误差经典容量等于其诱导的非交换图独立数的对数值，但独立数通常不满足乘性，何时满足乘性关系尚不清楚，需要深入研究。

Method: 提出独立数乘性的充分条件，构造具体量子信道示例进行验证，并考虑块状非交换图形式，分析其独立数乘性条件。

Result: 建立了独立数乘性的充分条件，给出了满足乘性关系的具体量子信道实例，并针对块状非交换图形式提供了乘性条件。

Conclusion: 本文明确了量子信道一次性零误差经典容量与独立数乘性的关系，为理解量子信道容量特性提供了新的理论工具和具体实例。

Abstract: The one-shot zero-error classical capacity of a quantum channel is the amount of classical information that can be transmitted with zero probability of error by a single use. Then the one-shot zero-error classical capacity equals to the logarithmic value of the independence number of the noncommutative graph induced by the channel. Thus the additivity of the one-shot zero-error classical capacity of a quantum channel is equivalent to the multiplicativity of the independence number of the noncommutative graph. The independence number is not multiplicative in general, and it is not clearly understood when the multiplicativity occurs. In this work, we present sufficient conditions for multiplicativity of the independence number, and we give explicit examples of quantum channels. Furthermore, we consider a block form of noncommutative graphs, and provide conditions when the independence number is multiplicative.

</details>


### [263] [Bayesian Optimization for Quantum Error-Correcting Code Discovery](https://arxiv.org/abs/2601.18562)
*Yihua Chengyu,Richard Meister,Conor Carty,Sheng-Ku Lin,Roberto Bondesan*

Main category: quant-ph

TL;DR: 提出贝叶斯优化框架，通过多视图链复形神经嵌入预测量子LDPC码的逻辑错误率，无需昂贵模拟，发现了性能优于gross码的[[144,36]]和[[144,16]]码。


<details>
  <summary>Details</summary>
Motivation: 量子纠错码需要冗余编码保护量子信息，但寻找实际性能好、开销小的码很困难，因为搜索空间组合爆炸且逻辑错误率评估成本高。

Method: 提出贝叶斯优化框架，采用多视图链复形神经嵌入来预测量子LDPC码的逻辑错误率，避免昂贵模拟，提高数据效率和可扩展性。

Result: 发现了高码率码[[144,36]]，其每量子比特错误率与gross码竞争；以及低错误码[[144,16]]，在每量子比特错误率上优于gross码。

Conclusion: 该框架能自动发现平衡码率和噪声抑制的码，其通用性适用于多种码族、解码器和噪声模型。

Abstract: Quantum error-correcting codes protect fragile quantum information by encoding it redundantly, but identifying codes that perform well in practice with minimal overhead remains difficult due to the combinatorial search space and the high cost of logical error rate evaluation. We propose a Bayesian optimization framework to discover quantum error-correcting codes that improves data efficiency and scalability with respect to previous machine learning approaches to this task. Our main contribution is a multi-view chain-complex neural embedding that allows us to predict the logical error rate of quantum LDPC codes without performing expensive simulations. Using bivariate bicycle codes and code capacity noise as a testbed, our algorithm discovers a high-rate code [[144,36]] that achieves competitive per-qubit error rate compared to the gross code, as well as a low-error code [[144,16]] that outperforms the gross code in terms of error rate per qubit. These results highlight the ability of our pipeline to automatically discover codes balancing rate and noise suppression, while the generality of the framework enables application across diverse code families, decoders, and noise models.

</details>


### [264] [Universality of Many-body Projected Ensemble for Learning Quantum Data Distribution](https://arxiv.org/abs/2601.18637)
*Quoc Hoan Tran,Koki Chinzei,Yasuhiro Endo,Hirotaka Oshima*

Main category: quant-ph

TL;DR: 该论文证明了多体投影系综（MPE）框架在量子机器学习中的普适性定理，表明MPE可以近似任意纯态分布，并提出增量MPE变体提升可训练性。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习中一个基本问题是近似普适性：参数化的QML模型能否近似任意量子分布。理解量子系统需要生成量子数据，但学习底层量子分布在理论和实践上都面临挑战。

Method: 提出多体投影系综（MPE）框架，这是一种使用单个多体波函数制备随机态的量子态设计方法。证明MPE的普适性定理，并提出增量MPE变体，采用分层训练提升可训练性。

Result: 证明了MPE可以在1-Wasserstein距离误差内近似任意纯态分布，为QML提供了严格的普适表达能力保证。在聚类量子态和量子化学数据集上的数值实验验证了MPE学习复杂量子数据分布的有效性。

Conclusion: MPE框架在理论上具有普适表达能力，增量MPE变体提升了实际可训练性，为量子机器学习中学习量子分布提供了理论基础和实践方法。

Abstract: Generating quantum data by learning the underlying quantum distribution poses challenges in both theoretical and practical scenarios, yet it is a critical task for understanding quantum systems. A fundamental question in quantum machine learning (QML) is the universality of approximation: whether a parameterized QML model can approximate any quantum distribution. We address this question by proving a universality theorem for the Many-body Projected Ensemble (MPE) framework, a method for quantum state design that uses a single many-body wave function to prepare random states. This demonstrates that MPE can approximate any distribution of pure states within a 1-Wasserstein distance error. This theorem provides a rigorous guarantee of universal expressivity, addressing key theoretical gaps in QML. For practicality, we propose an Incremental MPE variant with layer-wise training to improve the trainability. Numerical experiments on clustered quantum states and quantum chemistry datasets validate MPE's efficacy in learning complex quantum data distributions.

</details>


### [265] [Error-mitigation aware benchmarking strategy for quantum optimization problems](https://arxiv.org/abs/2601.18680)
*Marine Demarty,Bo Yang,Kenza Hammam,Pauline Besserve*

Main category: quant-ph

TL;DR: 提出一个结合有限样本统计和量子误差缓解(QEM)的量子优势评估框架，用于优化任务中的实用量子优势判断


<details>
  <summary>Details</summary>
Motivation: 现有熵基准测试方法未考虑有限样本效应和量子误差缓解(QEM)的资源开销，需要开发能评估实际量子优势的框架

Method: 开发包含有限样本统计和QEM资源开销的基准测试框架，通过置信度量化量子优势，使用概率误差消除(PEC)作为代表性QEM方法

Result: 在8×8二维Fermi-Hubbard模型上验证框架有效性，识别出PEC操作优势的噪声和样本预算区域，证明量子优势不受有限样本效应阻碍

Conclusion: 该框架为终端用户提供基于轻量数值计算的工具，可在近未来量子硬件上评估优化任务中的实用量子优势

Abstract: Assessing whether a noisy quantum device can potentially exhibit quantum advantage is essential for selecting practical quantum utility tasks that are not efficiently verifiable by classical means. For optimization, a prominent candidate for quantum advantage, entropy benchmarking provides insights based concomitantly on the specifics of the application and its implementation, as well as hardware noise. However, such an approach still does not account for finite-shot effects or for quantum error mitigation (QEM), a key near-term error suppression strategy that reduces estimation bias at the cost of increased sampling overhead. We address this limitation by developing a benchmarking framework that explicitly incorporates finite-shot statistics and the resource overhead induced by QEM. Our framework quantifies quantum advantage through the confidence that an estimated energy lies within an interval defined by the best-known classical upper and lower bounds. Using a proof-of-principle numerical study of the two-dimensional Fermi-Hubbard model at size $8\times8$, we demonstrate that the framework effectively identifies noise and shot-budget regimes in which the probabilistic error cancellation (PEC), a representative QEM method, is operationally advantageous, and potential quantum advantage is not hindered by finite-shot effects. Overall, our approach equips end-users with a framework based on lightweight numerics for assessing potential practical quantum advantage in optimization on near-future quantum hardware, in light of the allocated shot budget.

</details>


### [266] [Data-Driven Qubit Characterization and Optimal Control using Deep Learning](https://arxiv.org/abs/2601.18704)
*Paul Surrey,Julian D. Teske,Tobias Hangleiter,Hendrik Bluhm,Pascal Cerfontaine*

Main category: quant-ph

TL;DR: 使用循环神经网络预测量子比特行为，实现无需详细系统模型的梯度脉冲优化


<details>
  <summary>Details</summary>
Motivation: 量子计算需要优化控制脉冲以实现高保真量子门，但传统方法面临梯度评估和复杂系统动力学建模的挑战

Method: 1) 使用随机控制脉冲采样量子比特动力学；2) 训练RNN预测系统响应；3) 利用训练模型优化高保真控制脉冲

Result: 在单$ST_0$量子比特模拟中证明了该方法的有效性

Conclusion: 基于机器学习的协议能够实现高效的梯度脉冲优化，无需详细系统模型，为量子控制提供了新方法

Abstract: Quantum computing requires the optimization of control pulses to achieve high-fidelity quantum gates. We propose a machine learning-based protocol to address the challenges of evaluating gradients and modeling complex system dynamics. By training a recurrent neural network (RNN) to predict qubit behavior, our approach enables efficient gradient-based pulse optimization without the need for a detailed system model. First, we sample qubit dynamics using random control pulses with weak prior assumptions. We then train the RNN on the system's observed responses, and use the trained model to optimize high-fidelity control pulses. We demonstrate the effectiveness of this approach through simulations on a single $ST_0$ qubit.

</details>


### [267] [Nontrivial bounds on extractable energy in quantum energy teleportation for gapped manybody systems with a unique ground state](https://arxiv.org/abs/2601.18718)
*Taisanul Haque*

Main category: quant-ph

TL;DR: 该论文建立了量子能量隐形传输协议中可提取平均能量的普遍指数衰减上界，适用于具有唯一基态的有限范围有能隙晶格系统。


<details>
  <summary>Details</summary>
Motivation: 研究量子能量隐形传输协议中能量提取的极限，特别是在实际物理系统中，由于系统特性（如能隙、相互作用范围）的限制，能量提取能力可能受到约束。

Method: 基于哈密顿量的变分特征和谱隙隐含的指数聚类性质，在哈密顿量满足正则性假设且局部测量算符有统一算子范数界的条件下，推导出能量提取的上界。

Result: 证明了存在正常数C和μ（由谱隙、相互作用范围和局部算子范数决定），使得对于任何在区域A进行的局部测量和任何在距离d的分离区域B中实现的与结果相关的局部幺正操作，能量差满足|E_A-E_B| ≤ C e^{-μd}。

Conclusion: 量子能量隐形传输协议中可提取的能量受到指数衰减上界的限制，该界限是非微扰的、明确的（除模型相关常数外），并适用于广泛的物理系统。

Abstract: We establish a universal, exponentially decaying upper bound on the average energy that can be extracted in quantum energy teleportation (QET) protocols executed on finite-range gapped lattice systems possessing a unique ground state. Under mild regularity assumptions on the Hamiltonian and uniform operator-norm bounds on the local measurement operators, there exist positive constants $C$ and $μ$ (determined by the spectral gap, interaction range and local operator norms) such that for any local measurement performed in a region $A$ and any outcome-dependent local unitaries implemented in a disjoint region $B$ separated by distance $d=\operatorname{dist}(A,B)$ one has $|E_A-E_B|\le C\,e^{-μd}.$ The bound is nonperturbative, explicit up to model-dependent constants, and follows from the variational characterization of the ground state combined with exponential clustering implied by the spectral gap.

</details>


### [268] [On the Stochastic-Quantum Correspondence](https://arxiv.org/abs/2601.18720)
*Sami Calvo*

Main category: quant-ph

TL;DR: 本文更清晰地解释了Barandes（2023）提出的随机-量子对应，用量子力学Dirac符号阐明先前结果，从单一公理（物理系统按不可分随机律演化）推导量子力学六大公理，推广到连续基揭示空间可能离散，讨论实际应用问题，解释经典极限和测量问题解决方案。


<details>
  <summary>Details</summary>
Motivation: 更清晰地解释Barandes（2023）提出的随机-量子对应关系，用量子力学的Dirac符号阐明先前结果，从单一基本公理推导标准量子力学的全部公理体系，并探讨其对物理基础问题的启示。

Method: 使用量子力学Dirac符号重新表述随机-量子对应，从"每个物理系统按照一般不可分的随机律演化"这一单一公理出发，推导量子力学的六个公理。推广到连续基，分析其问题，扩展到经典和量子场论，讨论实际应用方法，并分析经典极限和测量问题。

Result: 成功从单一随机公理推导出量子力学六大公理，发现连续基存在问题暗示空间可能离散，提出测量问题解决方案：环境由自由度数量区分，测量装置是低熵类型环境，波函数坍缩由此产生。

Conclusion: 随机方法为量子力学提供了更基础的公理体系，从单一随机公理可推导标准量子力学，连续基问题暗示物理变量可能离散，测量问题可通过环境自由度数量和熵特性解决，但实际问题求解仍以传统方法最易处理。

Abstract: This paper aims to first explain, somewhat more clearly, the Stochastic-Quantum correspondence put forward in by Barandes in 2023. Specifically, the quantum-mechanical bra-ket notation is used, illuminating some results of previous results. With this, we prove the six axioms of textbook quantum mechanics from a single axiom: every physical system evolves according to a, generally indivisible, stochastic law. Afterwards, we generalise the treatment to continuous bases, which showcases a problem with them, indicating that space (and other physical variables) may be discrete in nature. Some concrete examples are also given, including the generalisation to classical and quantum fields. Then, we treat some practical issues of this new stochastic approach, regarding the solving of problems in physics, which turns out to still be most tractable in the traditional way. Finally, we explain the classical limit, where a system of many particles is found to behave classically according to Newton's second law. Along with that, we present a way of solving the measurement problem, characterising what is an environment and a measuring device and explaining how the wavefunction collapse comes about. Specifically, it is found that what distinguishes an environment is its number of degrees of freedom, while a measuring device is a low-entropy type of environment.

</details>


### [269] [Approximate level-by-level maximum-likelihood decoding based on the Chase algorithm for high-rate concatenated stabilizer codes](https://arxiv.org/abs/2601.18743)
*Takeshi Kakizaki*

Main category: quant-ph

TL;DR: 提出了一种用于高率级联稳定子码的高性能解码器，通过结合Chase算法扩展了逐级最小距离解码器，在比特翻转噪声下优于传统解码器


<details>
  <summary>Details</summary>
Motivation: 为了实现大规模容错量子计算，需要使用量子纠错码编码逻辑量子比特。高率级联码因其常数空间开销和对数多项式时间开销的容错协议理论进展而受到关注，但需要高性能解码器

Method: 提出了一种通用高性能解码器，通过利用Chase算法生成合适的候选错误集，扩展了逐级最小距离解码器（LMDD），适用于高率级联稳定子码

Result: 仿真结果表明，在比特翻转噪声下，所提出的解码器在高率级联汉明码上优于传统解码器

Conclusion: 提出的解码器为高率级联稳定子码提供了高性能解码方案，有助于实现大规模容错量子计算

Abstract: Fault-tolerant quantum computation (FTQC) is expected to address a wide range of computational problems. To realize large-scale FTQC, it is essential to encode logical qubits using quantum error-correcting codes. High-rate concatenated codes have recently attracted attention due to theoretical advances in fault-tolerant protocols with constant-space-overhead and polylogarithmic-time-overhead, as well as practical developments of high-rate many-hypercube codes equipped with a high-performance level-by-level minimum-distance decoder (LMDD). We propose a general, high-performance decoder for high-rate concatenated stabilizer codes that extends LMDD by leveraging the Chase algorithm to generate a suitable set of candidate errors. Our simulation results demonstrate that the proposed decoder outperforms conventional decoders for high-rate concatenated Hamming codes under bit-flip noise.

</details>


### [270] [Practical block encodings of matrix polynomials that can also be trivially controlled](https://arxiv.org/abs/2601.18767)
*Martina Nibbi,Filippo Della Chiara,Yizhi Shen,Aaron Szasz,Roel Van Beeumen*

Main category: quant-ph

TL;DR: 本文提出了一种实用的块编码电路实现矩阵多项式变换，利用FOQCS-LCU框架将电路深度开销从d倍降低到与d线性相关，且不依赖系统规模或原始矩阵编码成本。


<details>
  <summary>Details</summary>
Motivation: 块编码虽然理论上有很多应用，但在当前量子硬件上的实际实现成本过高。特别是编码d阶矩阵多项式时，传统方法需要d倍于原始矩阵编码的电路深度，这限制了实际应用。

Method: 利用最近提出的FOQCS-LCU（快速单量子比特控制选择LCU）框架，设计块编码电路实现矩阵多项式变换。该方法显著降低了电路深度开销，使其仅与多项式阶数d线性相关，而不依赖系统规模或原始矩阵编码成本。

Result: 实现了矩阵多项式变换的实用块编码电路，将额外电路深度开销降低到与d线性相关。电路可以以可忽略的开销进行控制，支持Hadamard测试等高效应用。提供了代表性自旋模型的显式电路及详细的非渐近门计数和电路深度分析。

Conclusion: FOQCS-LCU框架为矩阵多项式变换提供了高效的块编码实现方案，显著降低了实际量子硬件上的实现成本，使块编码技术更接近实际应用。

Abstract: Quantum circuits naturally implement unitary operations on input quantum states. However, non-unitary operations can also be implemented through block encodings, where additional ancilla qubits are introduced and later measured. While block encoding has a number of well-established theoretical applications, its practical implementation has been prohibitively expensive for current quantum hardware. In this paper, we present practical and explicit block encoding circuits implementing matrix polynomial transformations of a target matrix. With standard approaches, block-encoding a degree-$d$ matrix polynomial requires a circuit depth scaling as $d$ times the depth for block-encoding the original matrix alone. By leveraging the recently introduced Fast One-Qubit Controlled Select LCU (FOQCS-LCU) framework, we show that the additional circuit-depth overhead required for encoding matrix polynomials can be reduced to scale linearly in $d$ with no dependence on system size or the cost of block encoding the original matrix. Moreover, we demonstrate that the FOQCS-LCU circuits and their associated matrix polynomial transformations can be controlled with negligible overhead, enabling efficient applications such as Hadamard tests. Finally, we provide explicit circuits for representative spin models, together with detailed non-asymptotic gate counts and circuit depths.

</details>


### [271] [Hamiltonian Decoded Quantum Interferometry for General Pauli Hamiltonians](https://arxiv.org/abs/2601.18773)
*Kaifeng Bu,Weichen Gu,Xiang Li*

Main category: quant-ph

TL;DR: 本文提出了一种用于一般哈密顿量的哈密顿解码量子干涉测量方法，能够高效制备与多项式函数相关的量子态，用于吉布斯态制备和哈密顿量优化。


<details>
  <summary>Details</summary>
Motivation: 传统HDQI方法主要局限于稳定子类哈密顿量，需要扩展到更一般的哈密顿量系统，以处理物理和计算相关的更广泛量子系统。

Method: 使用哈密顿解码量子干涉测量技术，通过解码预言机访问，设计高效量子算法来制备状态ρ_P(H) = P^2(H)/Tr[P^2(H)]，其中P(H)是由单变量多项式P(x)诱导的矩阵函数。

Result: 证明了对于一般哈密顿量H=∑_i c_i P_i，存在高效量子算法制备相关量子态，这些态可用于通过适当多项式选择来近似吉布斯态，且算法对解码过程中的缺陷具有鲁棒性。

Conclusion: 该工作显著扩展了HDQI的应用范围，超越了稳定子类哈密顿量，为广泛物理和计算相关量子系统提供了吉布斯态制备和哈密顿量优化的通用方法。

Abstract: In this work, we study the Hamiltonian Decoded Quantum Interferometry (HDQI) for the general Hamiltonians $H=\sum_ic_iP_i$ on an $n$-qubit system, where the coefficients $c_i\in \mathbb{R}$ and $P_i$ are Pauli operators. We show that, given access to an appropriate decoding oracle, there exist efficient quantum algorithms for preparing the state $ρ_{\mathcal P}(H) = \frac{\mathcal P^2(H)}{\text{Tr}[\mathcal P^2(H)]}$, where $\mathcal P(H)$ denotes the matrix function induced by a univariate polynomial $\mathcal P(x)$. Such states can be used to approximate the Gibbs states of $H$ for suitable choices of polynomials. We further demonstrate that the proposed algorithms are robust to imperfections in the decoding procedure. Our results substantially extend the scope of HDQI beyond stabilizer-like Hamiltonians, providing a method for Gibbs-state preparation and Hamiltonian optimization in a broad class of physically and computationally relevant quantum systems.

</details>
