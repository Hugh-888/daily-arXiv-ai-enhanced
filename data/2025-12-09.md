<div id=toc></div>

# Table of Contents

- [quant-ph](#quant-ph) [Total: 84]
- [physics.comp-ph](#physics.comp-ph) [Total: 4]
- [cs.LG](#cs.LG) [Total: 145]
- [gr-qc](#gr-qc) [Total: 31]


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [1] [Tractatus Quanticum](https://arxiv.org/abs/2512.06034)
*Niccolò Covoni,Carlo Rovelli*

Main category: quant-ph

TL;DR: 将维特根斯坦的《逻辑哲学论》用量子力学重新诠释，探索关系性量子力学解释的哲学意涵


<details>
  <summary>Details</summary>
Motivation: 探索关系性量子力学解释在哲学上的可能意义，形式化这种解释所探讨的介于实在论与工具主义之间的第三条自然主义路径

Method: 用量子力学重新编辑维特根斯坦的《逻辑哲学论》，形式上具有游戏性，但实质上是严肃的哲学分析

Result: 提出了一个基于关系性量子力学解释的哲学框架，试图在实在论和工具主义之间找到第三条自然主义路径

Conclusion: 关系性量子力学解释为哲学提供了新的视角，能够形式化一种介于传统实在论和工具主义之间的自然主义立场

Abstract: This is a re-editing, which takes quantum mechanics into account, of Wittgenstein's famous Tractatus. The operation has a playful side in the form, but is a serious attempt to capture possible philosophical implications of the Relational Interpretation of Quantum Mechanics, and formalize the naturalistic third-way between realism and instrumentalism explored by this interpretation.

</details>


### [2] [Entanglement is protected by acceleration-induced transparency in thermal field](https://arxiv.org/abs/2512.06043)
*Yongjie Pan,Baocheng Zhang,Qingyu Cai*

Main category: quant-ph

TL;DR: 研究热场背景下加速探测器的量子纠缠，发现AIT效应能有效保护纠缠免受热场退相干影响


<details>
  <summary>Details</summary>
Motivation: 探索AIT效应对热场背景下加速探测器量子纠缠的影响，因为实验无法完全避免热背景场

Method: 研究两个在热场背景中加速的探测器的量子纠缠，分析AIT效应的影响

Result: 虽然热背景场通常会降低探测器间的纠缠，但AIT效应能有效保护纠缠

Conclusion: AIT效应在热场环境中对量子纠缠具有保护作用，为实验探测Unruh效应提供了新视角

Abstract: The acceleration-induced transparency (AIT) effect has been suggested recently to amply the transition probability of the two-level detctor and offers a potential avenue for the experimental detection of the Unruh effect. In this paper, we explore the influence of the AIT effect on quantum entanglement between two detectors accelerated in a thermal field background, since the thermal backgound field cannot be avoided completely in any experiments. Interestingly, we find that although the backgound thermal field generally degrade the entanglement between the detectors, the AIT effect can effectively protect it.

</details>


### [3] [RedCarD: A Quantum Assisted Algorithm for Fixed-Depth Unitary Synthesis via Cartan Decomposition](https://arxiv.org/abs/2512.06070)
*Omar Alsheikh,Efekan Kökcü,Bojko N. Bakalov,A. F. Kemper*

Main category: quant-ph

TL;DR: 提出一种混合量子-经典算法，通过进一步划分动力学李代数，将优化问题分解为更小的独立子问题，并将代价函数评估转移到量子计算机上，减少经典计算开销。


<details>
  <summary>Details</summary>
Motivation: 量子模拟电路合成中，基于动力学李代数Cartan分解的算法虽然能产生与模拟时间无关的电路深度，但经典计算开销大，包括代价函数评估和高维优化问题。

Method: 通过进一步划分动力学李代数，将优化问题分解为更小的独立子问题；利用代数结构将代价函数评估转移到量子计算机上，形成混合量子-经典算法。

Result: 在多个IBM设备和Quantinuum H1-1量子计算机上成功合成了4位点横向场Ising模型的时间演化幺正算符。

Conclusion: 提出的混合算法显著减少了经典计算开销，实现了更高效的量子电路合成，为量子模拟应用提供了实用工具。

Abstract: A critical step in developing circuits for quantum simulation is to synthesize a desired unitary operator using the circuit building blocks. Studying unitaries and their generators from the Lie algebraic perspective has given rise to several algorithms for synthesis based on a Cartan decomposition of the dynamical Lie algebra. For unitaries of the form $e^{-itH}$, such as time-independent Hamiltonian simulation, the resulting circuits have depth that does not depend on simulation time $t$. However, finding such circuits has a large classical overhead in the cost function evaluation and the high dimensional optimization problem. In this work, by further partitioning the dynamical Lie algebra, we break down the optimization problem into smaller independent subproblems. Moreover, the resulting algebraic structure allows us to easily shift the evaluation of the cost function to the quantum computer, further cutting the classical overhead of the algorithm. As an application of the new hybrid algorithm, we synthesize the time evolution unitary for the 4-site transverse field Ising model on several IBM devices and Quantinuum's H1-1 quantum computer.

</details>


### [4] [The Twin Paradox in Quantum Field Theory](https://arxiv.org/abs/2512.06076)
*Matheus H. Zambianco,T. Rick Perche*

Main category: quant-ph

TL;DR: 提出基于量子系统真空衰变概率的时钟模型，研究微观双生子佯谬，发现最小尺度下时间不仅依赖于事件间轨迹，还受真空涨落与时钟微观细节相互作用的影响。


<details>
  <summary>Details</summary>
Motivation: 量子场论中的真空涨落对短时间尺度测量施加了基本限制。为了研究普遍量子场论效应对观测者相关时间测量的影响，需要建立适当的理论框架。

Method: 引入基于有限大小量子系统真空衰变概率的时钟模型，使用该模型研究微观双生子佯谬场景。

Result: 在最小尺度下，时间不仅依赖于连接两个事件的轨迹，还取决于真空涨落如何与时钟的微观细节相互作用。

Conclusion: 真空涨落对微观时间测量有重要影响，量子场论效应在最小尺度上显著改变了时间测量的性质，时间概念在微观尺度上具有更复杂的依赖关系。

Abstract: Vacuum fluctuations in quantum field theory impose fundamental limitations on our ability to measure time in short scales. To investigate the impact of universal quantum field theory effects on observer-dependent time measurements, we introduce a clock model based on the vacuum decay probability of a finite-sized quantum system. Using this model, we study a microscopic twin paradox scenario and find that, in the smallest scales, time is not only dependent on the trajectory connecting two events, but also on how vacuum fluctuations interact with the microscopic details of the clocks.

</details>


### [5] [Entanglement transition in unitary system-bath dynamics](https://arxiv.org/abs/2512.06081)
*Bo Xing,Giuliano Chiriacò,Paola Cappellaro,Rosario Fazio,Dario Poletti*

Main category: quant-ph

TL;DR: 在系统-浴场耦合的自由费米子模型中，随着耦合强度增加，纠缠标度会从对数律向面积律转变，这种转变在轨迹平均的约化密度矩阵中不可见，但体现在浴场-浴场关联中。


<details>
  <summary>Details</summary>
Motivation: 传统主方程方法在长时间极限下给出稳态密度矩阵，但量子轨迹展开显示系统纠缠标度随系统-浴场耦合增强会发生转变，这种转变在轨迹平均的约化密度矩阵中不可见。本文探索在系统-浴场的幺正演化中是否也存在类似的纠缠标度转变现象。

Method: 研究一个幺正量子系统：二维自由费米子晶格，每个格点耦合到一个费米子浴场。通过改变系统-浴场耦合强度，分析对数费米子负性、互信息和关联的标度行为。

Result: 随着系统-浴场耦合增强，纠缠标度从对数律向面积律转变。这种转变在系统的稳态性质是平凡的情况下发生，转变的迹象体现在浴场-浴场关联中。

Conclusion: 在系统-浴场的幺正演化中确实存在纠缠标度转变，这种转变在轨迹平均的约化密度矩阵中不可见，但可以通过浴场-浴场关联来探测，为理解开放量子系统中的纠缠动力学提供了新视角。

Abstract: The evolution of a system coupled to baths is commonly described by a master equation that, in the long-time limit, yields a steady-state density matrix. However, when the same evolution is unraveled into quantum trajectories, it is possible to observe a transition in the scaling of entanglement within the system as the system-bath coupling increases - a phenomenon that is invisible in the trajectory-averaged reduced density matrix of the system. Here, we go beyond the paradigm of trajectories from master equations and explore whether a qualitatively analogous entanglement-scaling transition emerges in the unitary evolution of the combined system-bath setup. We investigate the scaling of entanglement in a unitary quantum setup composed of a 2D lattice of free fermions, where each site is coupled to a fermionic bath. Varying the system-bath coupling reveals a transition from logarithmic-law to area-law scaling, visible in the logarithmic fermionic negativity, mutual information, and also in the correlations. This occurs while the system's steady-state properties are trivial, highlighting that the signatures of these different scalings are within the bath-bath correlations.

</details>


### [6] [High-Performance Labyrinth Circular Bragg Grating Design for Charge and Stark-Tunable Quantum Light Sources Spanning Visible to Telecom Wavelengths](https://arxiv.org/abs/2512.06117)
*Rohit Prasad,Quirin Buchinger,Fei Chi Kristy Yuen,Yorick Reum,Sven Höfling,Tobias Huber-Loyola*

Main category: quant-ph

TL;DR: 提出周期性迷宫式圆形布拉格光栅设计，在保持高光学性能的同时实现电学集成，为量子点单光子源提供可电调谐平台。


<details>
  <summary>Details</summary>
Motivation: 传统圆形布拉格光栅的完全蚀刻环限制了通过电接触实现电荷和斯塔克调谐，而现有的迷宫式设计虽然解决了电集成问题，但严重降低了光学性能。

Method: 提出周期性迷宫式圆形布拉格光栅设计，在引入电连接桥后重新优化结构，在780nm、930nm和1550nm三个波长下进行数值模拟，并设计包含势垒层的器件布局以实现选择性充电。

Result: 在所有三个波长下实现了超过90%的收集效率（数值孔径0.7）和大于25的珀塞尔因子，同时保持了高光学性能并实现了电学集成能力。

Conclusion: 迷宫式圆形布拉格光栅为高效、可扩展的电可调谐量子点单光子源提供了一个有前景的平台。

Abstract: Semiconductor quantum dots embedded in circular Bragg gratings (CBGs) are among the most efficient integrated single-photon sources. However, the fully etched rings of conventional CBGs restrict the implementation of charge and Stark tuning via electrical contacts. To overcome this limitation, a labyrinth CBG geometry with four bridges has been proposed, yet the added bridges significantly degraded optical performance. In this work, we numerically demonstrate that a periodic labyrinth CBG design preserves both high coupling efficiency and strong Purcell enhancement while enabling electrical integration if optimized after introducing the bridges. We show three optimized designs at emission wavelengths of 780 nm, 930 nm, and 1550 nm, because these wavelengths are among the most relevant for quantum dots and show the general applicability of our approach. At all three wavelengths collection efficiencies exceeding 90% into a numerical aperture of 0.7 and Purcell factors greater than 25 are achieved. Furthermore, we propose a device layout incorporating a barrier layer that separates p- and n-doped semiconductor regions, which is incorporated to prevent tunneling of one of the charge carriers for selective charging. Also this design can be reoptimized to retain the performance of a device without tunnel barrier. These results establish labyrinth CBGs as a platform for electrically tunable quantum dot single-photon sources with high efficiency and scalability.

</details>


### [7] [Deadline-Aware Scheduling of Distributed Quantum Circuits in Near-Term Quantum Cloud](https://arxiv.org/abs/2512.06157)
*Nour Dehaini,Christia Chahoud,Mahdi Chehimi*

Main category: quant-ph

TL;DR: 提出面向近量子云的截止时间感知分布式量子计算调度框架，结合高效线切割技术，显著提升截止时间前请求服务率


<details>
  <summary>Details</summary>
Motivation: 当前分布式量子计算调度框架存在三个主要问题：1) 未考虑用户定义的执行截止时间；2) 采用低效的线切割技术；3) 近量子云缺乏量子通信网络，只能依赖经典通信

Method: 提出截止时间感知的DQC调度框架，考虑电路截止时间和QPU容量限制，捕获分区子电路间的依赖关系，在不同QPU上分布采样执行以实现高效线切割和快速执行。使用模拟退火算法解决调度优化问题

Result: 相比现有方法显著提升：紧急截止时间下请求服务率提高12.8%；平均服务请求数比依赖感知基线高8.16%，比依赖和采样感知基线高9.60%；执行时间更短；比贪心、列表调度和随机调度分别多服务23.7%、24.5%和25.38%的请求

Conclusion: 该截止时间感知调度框架能有效应对近量子云环境下的分布式量子计算调度挑战，显著提升系统性能和请求服务能力

Abstract: Distributed quantum computing (DQC) enables scalable quantum computations by distributing large quantum circuits on multiple quantum processing units (QPUs) in the quantum cloud. In DQC, after partitioning quantum circuits, they must be scheduled and executed on heterogenous QPUs while balancing latency, overhead, QPU communication resource limits. However, since fully functioning quantum communication networks have not been realized yet, near-term quantum clouds will only rely on local operations and classical communication settings between QPUs, without entangled quantum links. Additionally, existing DQC scheduling frameworks do not account for user-defined execution deadlines and adopt inefficient wire cutting techniques. Accordingly, in this work, a deadline aware DQC scheduling framework with efficient wire cutting for near-term quantum cloud is proposed. The proposed framework schedules partitioned quantum subcircuits while accounting for circuit deadlines and QPU capacity limits. It also captures dependencies between partitioned subcircuits and distributes the execution of the sampling shots on different QPUs to have efficient wire cutting and faster execution. In this regard, a deadline-aware circuit scheduling optimization problem is formulated, and solved using simulated annealing. Simulation results show a marked improvement over existing shot-agnostic frameworks under urgent deadlines, reaching a 12.8% increase in requests served before their deadlines. Additionally, the proposed framework serves 8.16% more requests, on average, compared to state-of-the-art dependency-agnostic baseline frameworks, and by 9.60% versus the dependency-and-shot-agnostic baseline, all while achieving a smaller makespan of the DQC execution. Moreover, the proposed framework serves 23.7%, 24.5%, and 25.38% more requests compared to greedy, list scheduling, and random schedulers, respectively.

</details>


### [8] [Collective three-body interactions enable a robust quantum speedup](https://arxiv.org/abs/2512.06170)
*Haoqing Zhang,Anjun Chu,Chengyi Luo,Chitose Maruko,Eliot A. Bohr,James K. Thompson,Ana Maria Rey*

Main category: quant-ph

TL;DR: 三体相互作用相比传统二体相互作用在制备多体纠缠态方面具有显著优势，包括N倍加速制备GHZ态、达到海森堡极限的相位估计精度，以及在腔损耗和退相干环境下更好的灵敏度增益。


<details>
  <summary>Details</summary>
Motivation: 传统基于全对全二体伊辛相互作用的方法在制备复杂多体纠缠态方面存在效率限制，需要探索更高效的相互作用机制来加速纠缠制备并提升量子传感性能。

Method: 利用光学腔中装载的N个原子实现集体三体相互作用，通过时间反转协议（包含简单旋转和集体自旋测量）进行相位估计，并与二体相互作用在腔损耗和单粒子退相干条件下进行对比分析。

Result: 三体相互作用相比二体相互作用：1）以~N倍加速制备广义GHZ态；2）通过时间反转协议达到海森堡极限的相位估计精度；3）在中等原子数下获得更高的灵敏度增益，在大系综中实现快速纠缠生成。

Conclusion: 集体三体相互作用为制备复杂多体纠缠态提供了显著优势，在量子信息处理和量子传感应用中具有重要潜力，特别是在存在实验约束的条件下仍能保持高性能。

Abstract: We show that collective three-body interactions (3BIs), implementable with $N$ atoms loaded inside an optical cavity, offer a significant advantage for preparing complex multipartite entangled states. Firstly, they enable a speedup of order $\sim N$ in preparing generalized Greenberger-Horne-Zeilinger (GHZ) states, outperforming conventional methods based on all-to-all two-body Ising interactions. Secondly, they saturate the Heisenberg bound in phase estimation tasks using a time-reversal protocol realized through simple rotations and followed by experimentally accessible collective spin measurements. Lastly, compared with two-body interactions (2BIs), in the presence of cavity losses and single particle decoherence, 3BIs feature a high gain in sensitivity for moderate atom numbers and in large ensembles a fast entanglement generation despite constraints in parameter regimes where they are implementable.

</details>


### [9] [Deterministic and Universal Frequency-Bin Gate for High-Dimensional Quantum Technologies](https://arxiv.org/abs/2512.06191)
*Xin Chen*

Main category: quant-ph

TL;DR: 提出基于腔辅助和频产生过程的确定性、通用、可编程高维量子门，实现近单位保真度，可在频率模式上执行M×N截断酉变换，维度可达10^4量级。


<details>
  <summary>Details</summary>
Motivation: 高维光子系统为量子信息处理提供大希尔伯特空间，在量子计算、通信和传感方面具有优势，但实现跨多模式的可扩展、低损耗酉门仍是核心挑战。

Method: 基于腔辅助和频产生过程，实现确定性、通用、可编程的高维量子门，在频率模式上执行M×N截断酉变换（1≤M<N），当M=N时实现完整酉变换。

Result: 该设备可实现近单位保真度，当前技术下可达维度M×N约10^4量级，N可达约1000，使用多个脉冲整形器可进一步提升维度。

Conclusion: 结合兼容的SPDC源、高效率探测和快速前馈，该方法为高维频率模式量子处理提供了可扩展、光纤兼容的平台。

Abstract: High-dimensional photonic systems access large Hilbert spaces for quantum information processing. They offer proven advantages in quantum computation, communication, and sensing. However, implementing scalable, low-loss unitary gates across many modes remains a central challenge. Here we propose a deterministic, universal, and fully programmable high-dimensional quantum gate based on a cavity-assisted sum-frequency-generation process, achieving near-unity fidelity. The device implements an M-by-N truncated unitary transformation (with 1 <= M < N), or a full unitary when M = N, on frequency-bin modes. With current technology, the attainable dimensionality reaches M-by-N on the order of ten to the power of four, with N up to about one thousand, and can be further increased using multiple pulse shapers. Combined with compatible SPDC sources, high-efficiency detection, and fast feed-forward, this approach provides a scalable, fiber-compatible platform for high-dimensional frequency-bin quantum processing.

</details>


### [10] [Highly robust logical qubit encoding in an ensemble of V-symmetrical qutrits](https://arxiv.org/abs/2512.06219)
*Luis Octavio Castaños-Cervantes,Manuel Calixto,Julio Guerrero*

Main category: quant-ph

TL;DR: 该论文提出使用U(3)相干态构成的偶数和奇数薛定谔猫态来编码逻辑量子比特，这些态对耗散和集体退相干具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 构建对耗散和退相干具有鲁棒性的逻辑量子比特编码方案，特别是针对qutrit系统中的单量子比特衰减和双量子比特过程。

Method: 使用U(3)相干态构成的偶数和奇数薛定谔猫态编码逻辑量子比特，这些态是有效主方程的稳态解，并通过两个参数耦合腔与三能级原子系综的物理系统实现。

Result: 逻辑量子比特态对单qutrit衰减和双qutrit过程具有免疫力，偶数逻辑态完全免疫于非均匀展宽和局部相关退相干，而奇数态则敏感，但可以定义另一种具有混合置换对称性的奇数态来免疫这些过程。

Conclusion: 提出的编码方案为构建鲁棒的量子比特提供了有效方法，结果可推广到任意数量的qutrits，为量子计算中的容错编码提供了新途径。

Abstract: We propose using even and odd Schödinger cat states formed from coherent states of U(3) of an ensemble of qutrits with a symmetrical V-configuration (a qubit-disguised qutrit) to encode a logical qubit. These carefully engineered logical qubit states are parameter independent stationary states of the effective master equation governing the evolution of the ensemble and, consequently, constitute dark states and are invulnerable to dissipation and correlated collective dephasing. In particular, the logical qubit states are immune to single qutrit decay (the analogous of single photon loss process for qutrits) and simultaneous decay and driving of two qutrits (the analogous two-photon loss and driving processes for qutrits). In addition, we show how to implement the single-qubit quantum NOT gate and the Hadamard gate followed by either the phase gate or the phase and $Z$ gates. We study analytically the case of two qutrits and conclude that the logical qubit states exhibit parity-sensitive inhomogeneous broadening and local correlated dephasing: the even logical state is completely immune to these processes, while odd one is vulnerable. Nevertheless, in the presence of these interactions one can also define another odd state with mixed permutation symmetry that is immune to both inhomogeneous broadening and local correlated dephasing. We suggest that these results can be extrapolated to an arbitrary number of qutrits. The effective master equation is deduced from a physical system composed of two parametrically coupled cavities with one of them interacting dispersively with an ensemble of three-level atoms (the qutrits). In principle this physical system can be implemented by means of two coplanar waveguide resonators, a SQUID parametrically coupling them, and a cloud of alkali atoms close to one of the resonators.

</details>


### [11] [Quantum Interior Point Methods: A Review of Developments and An Optimally Scaling Framework](https://arxiv.org/abs/2512.06224)
*Mohammadhossein Mohammadisiahroudi,Zeguan Wu,Pouya Sampourmahani,Adrian Harkness,Tamás Terlaky*

Main category: quant-ph

TL;DR: 本文综述了量子内点法(QIPMs)的最新研究进展，重点介绍了作者提出的几乎精确的量子内点法框架，该框架利用量子计算加速线性优化问题的求解。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能和机器学习等领域对大规模、数据密集型线性和锥优化问题的需求增长，经典内点法(IPMs)在处理密集问题实例时面临高昂的每迭代计算成本。量子线性系统求解器为加速IPMs中最耗计算量的步骤提供了有前景的途径。

Method: 提出了一种混合量子-经典方法：在量子计算机上完全构建和求解牛顿系统，而在经典计算机上执行解更新。所有矩阵-向量操作都在量子硬件上执行，结合了可行性维护、迭代细化和预处理等技术来应对量子误差和条件数问题。

Result: 该方法在维度方面实现了最优的最坏情况可扩展性，超越了现有经典和量子内点法的可扩展性。量子硬件执行所有矩阵-向量操作，使得方法能够处理大规模优化问题。

Conclusion: 量子内点法为解决大规模优化问题提供了有前景的方向，通过量子-经典混合方法克服了量子计算的实际挑战，在维度可扩展性方面取得了显著改进。

Abstract: The growing demand for solving large-scale, data-intensive linear and conic optimization problems, particularly in applications such as artificial intelligence and machine learning, has highlighted the limitations of classical interior point methods (IPMs). Despite their favorable polynomial-time convergence, conventional IPMs often suffer from high per-iteration computational costs, especially for dense problem instances. Recent advances in quantum computing, particularly quantum linear system solvers, offer promising avenues to accelerate the most computationally intensive steps of IPMs. However, practical challenges such as quantum error, hardware noise, and sensitivity to poorly conditioned systems remain significant obstacles. In response, a series of Quantum IPMs (QIPMs) has been developed to address these challenges, incorporating techniques such as feasibility maintenance, iterative refinement, and preconditioning. In this work, we review this line of research with a focus on our recent contributions, including an almost-exact QIPM framework. This hybrid quantum-classical approach constructs and solves the Newton system entirely on a quantum computer, while performing solution updates classically. Crucially, all matrix-vector operations are executed on quantum hardware, enabling the method to achieve an optimal worst-case scalability w.r.t dimension, surpassing the scalability of existing classical and quantum IPMs.

</details>


### [12] [Tradeoffs between quantum and classical resources in linear combination of unitaries](https://arxiv.org/abs/2512.06260)
*Kaito Wada,Hiroyuki Harada,Yasunari Suzuki,Yuuki Tokunaga,Naoki Yamamoto,Suguru Endo*

Main category: quant-ph

TL;DR: 提出一种介于原始LCU和随机化LCU之间的混合量子算法，通过分组策略在采样开销和电路规模之间取得平衡，并证明分组大小与采样开销的单调关系。


<details>
  <summary>Details</summary>
Motivation: 线性组合单元(LCU)算法是许多量子算法的基础构件，但通常需要辅助系统和复杂的受控单元操作，不够硬件高效。随机化LCU虽然减少了电路深度和辅助比特使用，但带来了二次增长的采样开销。需要在电路复杂度和采样开销之间找到更好的平衡点。

Method: 提出混合LCU算法：将单元操作集划分为若干组，然后从这些组中随机采样LCU电路来评估目标期望值。引入"缩减因子"这一量度，分析证明分组大小与采样开销之间的单调关系：更大的分组对应更小的采样开销。

Result: 算法能够显著减少电路深度和辅助比特使用，同时几乎保持基于LCU的非厄米动力学模拟器的采样开销。在线性系统求解器中实现了虚拟和相干方法之间的中间缩放，并提供了仅需单个可重置辅助比特的虚拟基态制备方案。

Conclusion: 该混合算法在采样开销和硬件开销之间提供了灵活的权衡。通过将量子错误检测视为LCU过程，阐明了何时应选择性地应用传统和虚拟检测方法，从而平衡采样和硬件开销。

Abstract: The linear combination of unitaries (LCU) algorithm is a building block of many quantum algorithms. However, because LCU generally requires an ancillary system and complex controlled unitary operators, it is not regarded as a hardware-efficient routine. Recently, a randomized LCU implementation with many applications to early FTQC algorithms has been proposed that computes the same expectation values as the original LCU algorithm using a shallower quantum circuit with a single ancilla qubit, at the cost of a quadratically larger sampling overhead. In this work, we propose a quantum algorithm intermediate between the original and randomized LCU that manages the tradeoff between sampling cost and the circuit size. Our algorithm divides the set of unitary operators into several groups and then randomly samples LCU circuits from these groups to evaluate the target expectation value. Notably, we analytically prove an underlying monotonicity: larger group sizes entail smaller sampling overhead, by introducing a quantity called the reduction factor, which determines the sampling overhead across all grouping strategies. Our hybrid algorithm not only enables substantial reductions in circuit depth and ancilla-qubit usage while nearly maintaining the sampling overhead of LCU-based non-Hermitian dynamics simulators, but also achieves intermediate scaling between virtual and coherent quantum linear system solvers. It further provides a virtual ground-state preparation scheme that requires only a resettable single-ancilla qubit and asymptotically shows advantages in both virtual and coherent LCU methods. Finally, by viewing quantum error detection as an LCU process, our approach clarifies when conventional and virtual detection should be applied selectively, thereby balancing sampling and hardware overhead.

</details>


### [13] [Adiabaticity Crossover: From Anderson Localization to Planckian Diffusion](https://arxiv.org/abs/2512.06263)
*Tiange Xiang,Yubo Zhang,Joonas Keski-Rahkonen,Anton M. Graf,Eric J. Heller*

Main category: quant-ph

TL;DR: 该论文从量子声学角度研究一维电子输运，发现声速、温度和电子-晶格耦合共同决定形变势，提出了基于加速度的绝热判据，识别出普朗克扩散区域，并解释了奇异金属中T线性电阻率的起源。


<details>
  <summary>Details</summary>
Motivation: 研究一维电子输运中的量子声学效应，特别是晶格振动如何通过形变势影响电子动力学，旨在理解绝热性、退相干和普朗克扩散之间的统一关系，并为奇异金属中的T线性电阻率现象提供解释。

Method: 采用晶格振动的相干态表示，得到时间依赖的形变势；引入基于加速度的绝热判据来区分绝热和穿越动力学；通过相干长度与初始波包宽度的比值衡量相干性；在(T,v)平面上分析扩散行为。

Result: 识别出普朗克扩散区域，其中无量纲扩散率α≈1且对参数依赖弱；该区域在穿越区域和退相干增强区域更普遍，表明从安德森局域化到普朗克扩散的退相干驱动转变；通过爱因斯坦关系得到1/τ_tr∝T的低温趋势。

Conclusion: 研究提供了绝热性、退相干和普朗克扩散在动态无序量子声学中的统一图像，为奇异金属中的T线性电阻率现象提供了理论解释，建立了电子输运中量子声学效应与宏观输运性质之间的联系。

Abstract: We investigate electron transport in one dimension from the quantum-acoustic perspective, where the coherent-state representation of lattice vibrations results in a time-dependent deformation potential whose rate is set by the sound speed, fluctuation spectrum is set by the temperature, and overall amplitude is set by the electron-lattice coupling strength. We introduce an acceleration-based adiabatic criterion, consistent with the adiabatic theorem and Landau-Zener theory, that separates adiabatic and diabatic dynamics across the $(T,v)$ plane. The discrete classification agrees with a continuous mean-squared acceleration scale and correlates with a coherence measure given by the ratio of coherence length to the initial packet width $L_φ(t)/σ_0$. We identify a broad Planckian domain in which the dimensionless diffusivity $α\!=\!Dm/\hbar$ is of order unity and only weakly depends on the parameters. This domain is more prevalent in diabatic regions and in areas of reduced phase coherence, indicating a dephasing driven crossover from Anderson localization to Planckian diffusion. Using the Einstein relation together with nearly constant $α$, we directly obtain a low temperature tendency $1/τ_{\rm tr}\propto T$, offering a insight to $T$-linear resistivity in strange metals. These results provide a unified picture that links adiabaticity, dephasing, and Planckian diffusion in dynamically disordered quantum-acoustics.

</details>


### [14] [Spin-photon Qubits for Scalable Quantum Network](https://arxiv.org/abs/2512.06285)
*Md Sakibul Islam,Kuldeep Singh,Yunhe Zhao,Nitesh Singh,Wayesh Qarony*

Main category: quant-ph

TL;DR: 该论文综述了固态量子光源在构建量子网络中的关键作用，特别关注电信波段自旋-光子量子比特，分析了不同材料平台（金刚石、碳化硅、量子点、二维材料）的性能，重点讨论了硅基发射器与CMOS技术的集成潜力，并展望了量子光子集成电路的发展方向。


<details>
  <summary>Details</summary>
Motivation: 构建未来量子网络需要可扩展的固态量子光源，这些光源能够将静止的自旋量子比特与飞行的光子量子比特连接起来。电信波段（1260-1675 nm）的自旋-光子量子比特由于在标准光纤中损耗最小，特别适合长距离量子通信。然而，实现可扩展性需要满足多个严格要求。

Method: 研究通过系统综述固态平台（包括金刚石色心、碳化硅缺陷中心、量子点、二维材料）中最先进的自旋-光子量子比特技术。特别关注硅基发射器（G、T、C-和Ci-中心），这些系统有望与CMOS技术单片集成并在电信波段工作。研究根据自旋-光子接口可用性、CMOS工艺兼容性和发射器可扩展性对这些系统进行分类。同时讨论了腔量子电动力学（cQED）的最新进展，包括Purcell增强和集成光子环境中的品质因数工程。

Result: 研究展示了不同固态平台在实现相干自旋控制、确定性不可区分单光子发射以及与纳米光子结构集成方面的进展。特别强调了硅基发射器在CMOS兼容性和电信波段操作方面的优势。研究还总结了量子网络在城域尺度上的新兴演示，以及向芯片级量子光子集成电路（QPICs）发展的轨迹。

Conclusion: 该综述为全球量子网络的发展铺平了道路，这些网络将实现安全通信、分布式量子计算和量子增强传感。通过结合确定性发射器创建、相干自旋操纵和量子信息处理，固态量子光源技术正在朝着可扩展的量子光子集成电路方向发展，这将成为未来量子技术基础设施的核心组成部分。

Abstract: Solid-state quantum light sources offer a scalable pathway for interfacing stationary spin qubits with flying photonic qubits, forming the backbone of future quantum networks. Telecom-band spin-photonic qubits, operating in the 1260-1675 nm wavelength range, are particularly well-suited for long-distance quantum communication due to minimal loss in standard optical fibers. Achieving scalability, however, hinges on fulfilling several stringent criteria: coherent spin-state control, deterministic and indistinguishable single-photon emission, and integration with nanophotonic structures that enhance radiative properties, such as lifetime, coherence, and photon indistinguishability. This study explores the state-of-the-art spin-photonic qubits across solid-state platforms, including diamond color centers, silicon carbide defect centers, quantum dots, and two-dimensional materials. Special attention is given to silicon-based emitters, particularly G, T, C- and Ci-centers, which promise monolithic integration with complementary metal-oxide-semiconductor (CMOS) technology and telecom-band operation. We classify these systems based on spin-photon interface availability, CMOS process compatibility, and emitter scalability. We also discuss recent advances in cavity quantum electrodynamics (cQED), including Purcell enhancement and quality factor engineering in integrated photonic (circuits) environments. The work highlights emerging demonstrations of quantum networking over metropolitan scales and outlines the trajectory toward chip-scale quantum photonic integrated circuits (QPICs). It combines deterministic emitter creation, coherent spin manipulation, and quantum information processing. These developments pave the way for global quantum networks, enabling secure communication, distributed quantum computing, and quantum-enhanced sensing.

</details>


### [15] [Wigner-Husimi phase-space structure of quasi-exactly solvable sextic potential](https://arxiv.org/abs/2512.06295)
*Angelina N. Mendoza Tavera,Adrian M. Escobar Ruiz,Robin P. Sagar*

Main category: quant-ph

TL;DR: 比较Wigner函数、其模和Husimi分布在单阱到双阱转变量子系统中的表现，发现Wigner函数对干涉效应最敏感，能显示非单调熵行为，而模Wigner和Husimi分布仅反映几何分裂或粗粒化离域。


<details>
  <summary>Details</summary>
Motivation: 研究不同相空间表示（Wigner函数、其模、Husimi分布）在量子系统从单阱到双阱转变过程中描述结构变化的能力差异，建立评估不同相空间表示描述能力的定量框架。

Method: 使用准精确可解六次振子作为代表系统，采用高精度变分波函数计算最低态，分析二维相空间结构、一维边际分布，以及相应的香农熵、互信息和累积残差Jeffreys散度。

Result: Wigner表示对干涉效应响应独特，在阱分离时显示清晰非单调熵行为；模Wigner和Husimi分布仅能描述几何分裂或粗粒化离域。建立了W、|W|和H在解析量子态结构变化能力上的定量层次。

Conclusion: Wigner函数在描述量子态结构变化方面最具描述力，特别对干涉效应敏感，为评估不同相空间表示在双模或隧穿系统中的描述能力提供了通用框架。

Abstract: In this study, we compare the Wigner function $W$, its modulus, and the Husimi distribution $H$ in a one-dimensional quantum system exhibiting a transition from a single-well to a double-well configuration, using the quasi-exactly solvable sextic oscillator as a representative example. High-accuracy variational wavefunctions for the lowest states are used to compute two-dimensional phase-space structures, one-dimensional marginals, and the corresponding Shannon entropies, mutual information, and Cumulative Residual Jeffreys divergences. The analysis shows that the Wigner representation is uniquely responsive to interference effects and displays clear, nonmonotonic entropic behavior as the wells separate, whereas the modulus-Wigner and Husimi distributions account only for geometric splitting or coarse-grained delocalization. These findings establish a quantitative hierarchy in the ability of $W$, $|W|$, and $H$ to resolve structural changes in a quantum state and provide a general framework for assessing the descriptive power of different phase-space representations in systems with emerging bimodality or tunneling.

</details>


### [16] [Entanglement Witness Derived By Using Kolmogorov-Arnold Networks](https://arxiv.org/abs/2512.06298)
*Fatemeh Lajevardi,Azam Mani,Ali Fahim*

Main category: quant-ph

TL;DR: 使用Kolmogorov-Arnold网络设计可解释的量子纠缠检测模型，在九参数双量子比特态中达到94%准确率，并通过特征分析开发出需要更少参数的新纠缠见证函数。


<details>
  <summary>Details</summary>
Motivation: 开发一个可解释的量子纠缠检测模型，能够在不依赖完整态层析的情况下识别双量子比特系统的纠缠状态，减少检测所需的参数数量。

Method: 使用Kolmogorov-Arnold网络（KAN）作为纠缠见证器，分析九参数双量子比特态。通过分析KAN模型的输出函数，评估每个参数在识别纠缠中的重要性，并基于特征重要性排名开发新的纠缠见证函数。

Result: KAN模型在区分纠缠态方面达到94%的准确率。通过特征重要性分析，能够识别出对纠缠检测最关键的特征，从而开发出仅需较少参数的新纠缠见证函数，无需完整态层析即可评估。

Conclusion: Kolmogorov-Arnold网络为量子纠缠检测提供了一种有效的可解释方法，不仅实现了高准确率，还能通过特征分析简化纠缠见证函数，降低实验要求，为量子信息处理中的纠缠检测提供了实用工具。

Abstract: We utilize Kolmogorov-Arnold Networks to design an interpretable model capable of detecting quantum entanglement within a set of nine-parameter two-qubit states. This network serves as an entanglement witness, achieving an accuracy of $94\%$ in distinguishing entangled states. Additionally, by analyzing the output functions of the KAN models, we explore the significance of each parameter (feature) in identifying the presence of entanglement. This analysis enables us to rank the features and eliminate the less significant ones, leading to the development of new entanglement witness functions that rely on fewer number of features, and hence do not require complete state tomography for their evaluation.

</details>


### [17] [Exploring the topology induced by non-Markovian Liouvillian exceptional points](https://arxiv.org/abs/2512.06311)
*Hao-Long Zhang,Yan Wang,Wen Ning,Shou-Bang Yang,Jia-Hao Lü,Fan Wu,Pei-Rong Han,Zhen-Biao Yang,Shi-Biao Zheng*

Main category: quant-ph

TL;DR: 该论文研究了非马尔可夫系统中Liouvillian超算子的拓扑特性，发现单个路径环绕双重LEP2可同时产生两个不同的绕数，并通过超导量子电路实验验证了这一现象。


<details>
  <summary>Details</summary>
Motivation: 现有非厄米拓扑研究主要局限于NH哈密顿量的异常点，而Liouvillian超算子（结合量子跃迁和NH哈密顿量动力学）的异常点（LEPs）与对应NH哈密顿量的异常点有显著差异，特别是在非马尔可夫系统中尚未充分探索。

Method: 研究由量子比特耦合到非马尔可夫库组成的系统，分析扩展Liouvillian超算子的拓扑特征，重点关注由两个重合的LEP2形成的双重LEP2结构。通过超导量子比特与衰减谐振器（作为具有记忆效应的库）耦合的电路进行实验验证。

Result: 发现单个闭合路径环绕双重LEP2可同时产生两个不同的绕数，这一现象纯粹源于非马尔可夫效应。实验成功观测到这一拓扑特征，将异常拓扑的研究从马尔可夫区域扩展到非马尔可夫区域。

Conclusion: 该工作揭示了Liouvillian异常点在非马尔可夫系统中的独特拓扑特性，通过实验验证了单个路径可同时产生多个绕数的现象，为非厄米拓扑研究开辟了新的非马尔可夫方向。

Abstract: Non-Hermitian (NH) systems can display exotic topological phenomena without Hermitian counterparts, enabled by exceptional points (EPs). So far, investigations of NH topology have been restricted to EPs of the NH Hamiltonian, which governs the system dynamics conditional upon no quantum jumps occurring. The Liouvillian superoperator, which combines the effects of quantum jumps with NH Hamiltonian dynamics, possesses EPs (LEPs) that are significantly different from those of the corresponding NH Hamiltonian. We here study the topological features of the LEPs in the system consisting of a qubit coupled to a non-Markovian reservoir. We find that two distinct winding numbers can be simultaneously produced by executing a single closed path encircling the twofold LEP2, formed by two coinciding LEP2s, each involving a pair of coalescing eigenvectors of the extended Liouvillian superoperator. We experimentally demonstrate this purely non-Markovian phenomenon with a circuit, where a superconducting qubit is coupled to a decaying resonator which acts as a reservoir with memory effects. The results push the exploration of exceptional topology from the Markovian to non-Markovian regime.

</details>


### [18] [Testing the weak equivalence principle for nonclassical matter with torsion balances](https://arxiv.org/abs/2512.06333)
*Roberto Onofrio,Alexander R. H. Smith,Lorenza Viola*

Main category: quant-ph

TL;DR: 该论文提出使用扭秤测试弱等效原理，通过创建可控的量子叠加态，并考虑惯性质量和引力质量作为算符，利用加速度算符的均值和方差来检测量子相干性导致的WEP违反。


<details>
  <summary>Details</summary>
Motivation: 传统弱等效原理测试主要针对经典物体，而量子系统的WEP测试需要新的方法。作者认为需要考虑惯性质量和引力质量作为算符，并开发能够检测量子相干性导致WEP违反的鲁棒测试方案。

Method: 1. 建立模型推导自由落体算符的矩阵元；2. 利用加速度算符的均值和方差来估计WEP违反；3. 在扭秤实验中引入并量子化扭矩算符；4. 提出动态设置，通过时间相关引力场测量角加速度来编码WEP违反。

Result: 提出了一个能够检测量子相干性导致弱等效原理违反的鲁棒测试框架，通过加速度算符的方差（而不仅仅是均值）来克服实验中的涨落影响，并设计了具体的扭秤实验方案。

Conclusion: 该研究为量子尺度下的弱等效原理测试提供了新方法，通过考虑量子相干性和算符形式的质量概念，能够更精确地探测可能的WEP违反，特别是在量子叠加态存在的情况下。

Abstract: We propose tests of the weak equivalence principle (WEP) using a torsion balance, in which superposition of energy eigenstates are created in a controllable way for the test masses. After general considerations on the significance of tests of the WEP using quantum states and the need for considering inertial and gravitational masses as operators, we develop a model to derive the matrix elements of the free-fall operator, showing that the variance of the acceleration operator, in addition to its mean, enables estimation of violations of the WEP due to quantum coherence in a way that is robust with respect to shot-to-shot fluctuations. Building on this analysis, we demonstrate how the validity of the WEP may be tested in a torsion balance setup, by accessing the mean and variance of a torque operator we introduce and quantize. Due to the long acquisition times of the signal as compared to the timescale on which coherent superposition states may survive, we further propose a dynamical setting, where the torsion balance is subject to a time-dependent gravitational field, and measurements of angular acceleration encode possible violations of the WEP.

</details>


### [19] [Bound state in the continuum and multiple atom state transfer applications in a waveguide QED setup](https://arxiv.org/abs/2512.06365)
*Xiang Guo,Xiaojun Zhang,Mingzhu Weng,Qian Bin,Hao-di Liu,Hai-Jun Xing,Xin-You Lü,Zhihai Wang*

Main category: quant-ph

TL;DR: 该论文研究了耦合谐振器波导中原子-波导修饰的连续谱束缚态，展示了其在两个空间分离的原子阵列间实现高保真量子态传输的能力。


<details>
  <summary>Details</summary>
Motivation: 虽然连续谱束缚态在超材料中已被广泛用于增强光-物质相互作用，但在多原子波导平台中的出现和应用仍较少探索。本文旨在研究原子-波导修饰的BICs在量子信息处理中的潜力。

Method: 使用一维耦合谐振器波导系统，其中两个空间分离的原子阵列以时间依赖的强度耦合到不同的谐振器。通过分析原子-波导修饰的连续谱束缚态特性，特别是其支持的驻波光子模式。

Result: BICs支持驻波光子模式，能够实现两个原子阵列间任意未知量子态的传输，保真度超过99%。该协议对无序和本征耗散具有鲁棒性。

Conclusion: 连续谱束缚态可作为波导-QED架构中高保真量子信息处理的长寿命资源，为量子态传输提供了有效方案。

Abstract: Bound states in the continuum (BICs) have been extensively exploited to enhance light--matter interactions in metamaterials, yet their emergence and utility in multi-atom waveguide platforms remain far less explored. Here we study atom--waveguide-dressed BICs in a one-dimensional coupled-resonator waveguide, where two spatially separated atomic arrays couple to distinct resonators with time-dependent strengths. We show that these BICs support a standing-wave photonic mode and enable the transfer of an arbitrary unknown quantum state between the two arrays with fidelities exceeding $99\%$. The protocol remains robust against both disorder and intrinsic dissipation. Our results establish BICs as long-lived resources for high-fidelity quantum information processing in waveguide-QED architectures.

</details>


### [20] [Mitigating the Transition of SiV$^-$ in Diamond to an Optically Dark State](https://arxiv.org/abs/2512.06389)
*Manuel Rieger,Rubek Poudel,Tobias Waldmann,Lina M. Todenhagen,Stefan Kresta,Nori N. Chavira Leal,Viviana Villafañe,Martin S. Brandt,Kai Müller,Jonathan J. Finley*

Main category: quant-ph

TL;DR: 通过施加静电场结合共振激光，可有效稳定金刚石中硅空位中心(SiV⁻)的电荷态，提高其光致发光强度并实现单光子源的电荷态控制。


<details>
  <summary>Details</summary>
Motivation: 金刚石中的硅空位中心(SiV⁻)在量子光子技术中具有潜力，但在共振光激发下容易转变为零自旋的暗态，这限制了其实际应用。需要找到方法来稳定和控制其电荷态。

Method: 在金刚石表面制备叉指金属电极，施加静电场结合共振激光激发。通过时间分辨三色实验研究电荷态转换动力学，分析不同单个发射体的电荷态可控性差异。

Result: 静电场使大多数发射体的稳态SiV⁻光致发光强度提高至少3倍，某些单个发射体几乎保持恒定。成功激活了原本完全暗态的单个SiV⁻。共振激光不仅激发SiV⁻，还能产生自由空穴，在毫秒时间尺度上将SiV²⁻转换为SiV⁻。

Conclusion: 基于电场的稳定方案增强了IV族色心的确定性电荷态控制，提高了对其物理机制的理解，为量子纠缠生成和量子密钥分发等应用提供了可扩展的路径。

Abstract: Negatively charged silicon vacancy centers in diamond (SiV$^-$) are promising for quantum photonic technologies. However, when subject to resonant optical excitation, they can inadvertently transfer into a zero-spin optically dark state. We show that this unwanted change of charge state can be quickly reversed by the resonant laser itself in combination with static electric fields. By defining interdigitated metallic contacts on the diamond surface, we increase the steady-state SiV$^-$ photoluminescence under resonant excitation by a factor $\ge3$ for most emitters, making it practically constant for certain individual emitters. We electrically activate single \sivs near the positively biased electrode, which are entirely dark without applying local electric fields. Using time-resolved 3-color experiments, we show that the resonant laser not only excites the SiV$^-$, but also creates free holes that convert SiV$^{2-}$ to SiV$^-$ on a timescale of milliseconds. Through analysis of several individual emitters, our results show that the degree of electrical charge state controllability differs between individual emitters, indicating that their local environment plays a key role. Our proposed electric-field-based stabilization scheme enhances deterministic charge state control in group-IV color centers and improves its understanding, offering a scalable path toward quantum applications such as entanglement generation and quantum key distribution.

</details>


### [21] [Generalized product-form monogamy relations in multi-qubit systems](https://arxiv.org/abs/2512.06418)
*Wen Zhou,Zhong-Xi Shen,Hong-Xing Wu,Zhi-Xi Wang,Shao-Ming Fei*

Main category: quant-ph

TL;DR: 本文提出了基于concurrence和negativity的乘积形式纠缠单配性不等式，比现有不等式更紧致，且适用于高维量子态


<details>
  <summary>Details</summary>
Motivation: 纠缠单配性描述了量子系统中纠缠的分布特性，现有研究主要关注求和形式的单配性不等式。本文旨在探索更紧致的乘积形式单配性不等式，特别是在高维量子态中的应用

Method: 提出基于concurrence的ν次幂（ν≥2）的乘积形式单配性不等式，并通过具体例子证明其紧致性；进一步建立基于negativity的乘积形式单配性不等式

Result: 提出的乘积形式单配性不等式比现有不等式更紧致；基于negativity的乘积形式不等式即使在CKW不等式失效的高维量子态中仍然成立

Conclusion: 乘积形式的单配性不等式提供了比传统求和形式更紧致的纠缠分布描述，特别是在高维量子系统中具有更好的适用性，为纠缠单配性研究提供了新的理论工具

Abstract: Monogamy of entanglement essentially characterizes the entanglement distributions among the subsystems. Generally it is given by summation-form monogamy inequalities. In this paper, we present the product-form monogamy inequalities satisfied by the $ν$-th ($ν\geq2$) power of the concurrence. We show that they are tighter than the existing ones by detailed example. We then establish tighter product-form monogamy inequalities based on the negativity. We show that they are valid even for high dimensional states to which the well-known CKW inequality is violated.

</details>


### [22] [Hybrid qubit-oscillator module with motional states of two trapped interacting atoms](https://arxiv.org/abs/2512.06429)
*Jaeyong Hwang,Tianrui Xu,Sean R. Muleady,Steven Pampel,Gur Lubin,Dawson Hewatt,Cindy A. Regal,Ana Maria Rey*

Main category: quant-ph

TL;DR: 利用双原子在光学镊子势阱中的运动状态实现类电路QED和离子阱的量子比特-振子系统，其中质心运动作为振子模式，相对运动作为量子比特，无需内部态参与。


<details>
  <summary>Details</summary>
Motivation: 提出一种新型的量子比特-振子系统实现方案，利用原子运动状态而非内部态来构建量子比特，从而避免自旋相关噪声的影响，同时借鉴电路量子电动力学和离子阱系统的成功经验。

Method: 通过光学镊子的精确时间调制来工程化势阱，实现双原子系统的运动状态控制。质心自由度作为振子模式，相互作用的相对模式作为量子比特。通过调制光学镊子实现位移、旋转、压缩等玻色子操作以及量子比特控制的通用门集合。

Result: 数值模拟显示这些量子门可以实现高保真度，讨论了初始态制备和最终态读取的可能方案。系统可以扩展到通过偶极或里德堡修饰相互作用耦合的原子阵列。

Conclusion: 提出了一种基于原子运动状态的新型量子比特-振子系统实现方案，该系统对自旋相关噪声具有鲁棒性，能够实现通用量子操作，并具有良好的可扩展性前景。

Abstract: We propose the use of motional states of two interacting atoms trapped in a potential stroboscopically engineered by an optical tweezer as a means to implement a qubit-oscillator system, in analogy to those implemented in circuit quantum electrodynamics and trapped ions. In our setting, the center of mass degree of freedom of the atoms plays the role of a photon or phonon mode, while the interacting, relative mode acts as a qubit. No internal state is involved in our system, which makes this motional qubit robust to spin-dependent noise. We show that a universal set of bosonic operations, including displacement, rotation, squeezing, and the corresponding set of gates controlled by the qubit, can be implemented through precise temporal modulation of the optical tweezers. We numerically check that these gates can be generated with high fidelity, and discuss possible schemes for initial state preparation and final state readout. While we restrict the discussion to a single qubit-oscillator module, scalability can be achieved by coupling arrays of atoms via dipolar or Rydberg-dressed interactions.

</details>


### [23] [Nonreciprocal photon blockade in a spinning microwave magnomechanical system through kerr-magnon and optical parametric amplifier](https://arxiv.org/abs/2512.06453)
*S. K. Singh,Mohamed Amazioug,Jia-Xin Peng,Mohammad Khalid*

Main category: quant-ph

TL;DR: 提出在旋转微波磁机械系统中实现非互易光子阻塞的方案，利用克尔诱导磁振子相互作用和光学参量放大器的组合非线性效应，通过萨尼亚克-菲佐位移实现强光子阻塞的主动控制。


<details>
  <summary>Details</summary>
Motivation: 非常规量子反聚束效应源于量子干涉，能产生高质量单量子源，受到广泛关注。本文旨在实现并主动控制旋转微波磁机械系统中的强光子阻塞。

Method: 利用克尔诱导磁振子相互作用和光学参量放大器的组合非线性效应，通过萨尼亚克-菲佐位移建立非互易光子阻塞。采用薛定谔方程解析解近似等时二阶相关函数，并与林德布拉德主方程的全数值解进行比较。

Result: 成功实现了非互易光子阻塞，在弱耦合条件下研究了热噪声、探测场振幅和磁偶极耦合强度的影响。使用曼德尔参数表征系统的非经典性，并分析了二阶相关函数的时间演化。

Conclusion: 该工作为在非线性旋转微波磁机械系统中实现非互易光子阻塞提供了一条途径，为高质量单光子源的产生和控制提供了新方法。

Abstract: Unconventional quantum antibunching, arising from quantum interference effects, represents a notable form of quantum correlation that has attracted significant attention for its ability to generate high-quality single-quantum sources. In this work, we propose a scheme to achieve and actively control strong photon blockade in a spinning microwave magnomechanical system by leveraging the combined nonlinear effects of Kerr-induced magnon interactions and an optical parametric amplifier. By exploiting the Sagnac-Fizeau shift, we establish nonreciprocal photon blockade and verify this effect through a combination of analytical modelling and numerical simulations. To gain intuitive insight into the underlying nonreciprocity, we approximate the equal-time second-order correlation function using the analytical solution of the Schrödinger equation. This analytical result is then compared with the full numerical solution derived from the Lindblad master equation. The influences of thermal noise, the probe field amplitude, and the magnetic-dipole coupling strength are investigated within the constraints of the weak-coupling regime. The system's nonclassicality is characterized using the Mandel parameter, complemented by an analysis of the time evolution of the second-order correlation function. Our work provides a pathway for realizing nonreciprocal photon blockade in a nonlinear spinning microwave magnomechanical system.

</details>


### [24] [Scheduling Lattice Surgery with Magic State Cultivation](https://arxiv.org/abs/2512.06484)
*Steven Hofmeyr,Mathias Weiden,Justin Kalloor,John Kubiatowicz,Costin Iancu*

Main category: quant-ph

TL;DR: Pure Magic调度通过动态重用魔态培养量子比特进行路由，消除专用总线架构，显著提升表面码量子计算的调度效率和魔态准备时间


<details>
  <summary>Details</summary>
Motivation: 传统表面码量子计算中，魔态调度使用专用总线量子比特进行路由，并采用分离的外围辅助量子比特工厂进行魔态准备，导致资源利用率低下。随着魔态培养技术的发展，准备量子比特可以放置在表面码架构的任何位置，这为改进调度方法创造了机会。

Method: 提出Pure Magic调度方法，动态地将魔态培养量子比特重新用于路由操作，消除专用总线基础设施。通过当量子比特需要用于路由时中断培养过程，该方法自然地倾向于较短的培养时间，同时确保没有辅助量子比特保持空闲状态。

Result: 在17个基准电路上的评估显示，与传统总线路由相比，调度效率提高了19%到223%，平均魔态准备时间减少了2.6倍到9.7倍。优势随着电路并行度的增加而扩大，使得Pure Magic特别适用于高度并行的量子算法。

Conclusion: Pure Magic架构代表了容错量子架构从静态调度到动态、需求驱动调度的范式转变，通过消除专用总线基础设施和动态重用魔态培养量子比特，显著提升了资源利用率和调度效率。

Abstract: Fault-tolerant quantum computation using surface codes relies on efficient scheduling of non-Clifford operations, realized via the injection of magic states produced through a probabilistic process that dominates spacetime costs. Existing scheduling approaches use dedicated bus qubits for routing and separate peripheral ancilla qubit factories for magic state preparation, leading to inefficient resource utilization. With the advent of magic state cultivation, preparation qubits can be placed anywhere within the surface code architecture. We introduce Pure Magic scheduling, which dynamically re-purposes magic state cultivation qubits for routing operations, eliminating dedicated bus infrastructure. By interrupting cultivation when qubits are needed for routing, Pure Magic naturally favors shorter cultivation times while ensuring no ancilla qubit remains idle. Our evaluation across 17 benchmark circuits improves scheduling efficiency by 19% to 223% compared to traditional bus routing and decreases average magic state preparation time by 2.6x to 9.7x. Benefits scale with circuit parallelism, making Pure Magic particularly valuable for highly parallel quantum algorithms. The Pure Magic architecture represents a paradigm shift from static to dynamic, demand-driven scheduling in fault-tolerant quantum architectures.

</details>


### [25] [Efficient quantum algorithm for solving differential equations with Fourier nonlinearity via Koopman linearization](https://arxiv.org/abs/2512.06488)
*Judd Katz,Gopikrishnan Muraleedharan,Abhijeet Alase*

Main category: quant-ph

TL;DR: 本文提出了一种高效的量子算法，用于求解具有傅里叶非线性项的常微分方程，通过推广Carleman线性化技术（Koopman线性化）来处理非多项式非线性项，并放宽了耗散性条件限制。


<details>
  <summary>Details</summary>
Motivation: 现有量子算法主要局限于处理多项式非线性项的ODE，这大大限制了其应用范围。本文旨在解决具有傅里叶非线性项（如e^{iu}形式）的ODE，这类非线性项无法用有限多项式表示，但在实际应用中很常见。

Method: 采用Koopman线性化技术（Carleman线性化的推广）将具有傅里叶非线性项的高维非线性ODE转化为更高维的线性ODE。同时改进了解决方案提取的耗散性条件要求，并集成了从量子态中读取经典量的方法。

Result: 成功构建了处理傅里叶非线性项的高效量子算法，能够求解形式为d𝐮/dt = G₀ + G₁e^{i𝐮}的ODE，其中𝐮是n维复变量向量。算法在变量数量上具有指数优势。

Conclusion: 该工作为处理更广泛类别的高维非线性ODE开辟了新途径，显著扩展了量子算法在非线性微分方程求解中的应用范围，特别是针对非多项式非线性项的情况。

Abstract: Quantum algorithms offer an exponential advantage with respect to the number of dependent variables for solving certain nonlinear ordinary differential equations (ODEs). These algorithms typically begin by transforming the original nonlinear ODE into a higher-dimensional linear ODE using a linearization technique, most commonly Carleman linearization. Existing works restrict their analysis to ODEs where the nonlinearities are polynomial functions of the dependent variables, significantly limiting their applicability. In this work we construct an efficient quantum algorithm for solving ODEs with `Fourier' nonlinear terms expressible as $d{\bf u}/dt = G_0 + G_1 e^{i{\bf u}}$, where ${\bf u}$ denotes a vector of $n$ complex variables evolving with $t$, $G_0$ is an $n$-dimensional complex vector, $G_1$ is an $n \times n$ complex matrix and $e^{i{\bf u}}$ denotes the vector with entries $\{e^{iu_j}\}$. To tackle the Fourier nonlinear term, which is not expressible as a finite sum of polynomials of ${\bf u}$, our algorithm employs a generalization of the Carleman linearization technique known as Koopman linearization. We also make other methodological advances towards relaxing the stringent dissipativity condition required for efficient solution extraction and towards integrated readout of classical quantities from the solution state. Our results open avenues to the development of efficient quantum algorithms for a significantly wider class of high-dimensional nonlinear ODEs, thereby broadening the scope of their applications.

</details>


### [26] [Solving larger Travelling Salesman Problem networks with a penalty-free Variational Quantum Algorithm](https://arxiv.org/abs/2512.06523)
*Daniel Goldsmith,Xing Liang,Dimitrios Makris,Hongwei Wu*

Main category: quant-ph

TL;DR: 本文提出了一种混合无惩罚变分量子算法，在无噪声Qiskit模拟中成功求解了最多12个地点的旅行商问题，相比传统方法大幅减少了量子比特需求。


<details>
  <summary>Details</summary>
Motivation: 旅行商问题是著名的NP难组合优化问题，在物流配送等领域有重要应用。虽然量子计算已广泛研究TSP，但现有量子解决方案通常只能处理十几个地点的小规模问题。本文旨在开发能够处理更大规模TSP的量子算法。

Method: 采用混合无惩罚变分量子算法，使用多种编码策略（阶乘、非阶乘、格雷编码），通过同时扰动随机逼近梯度估计和成本函数缓存减少计算时间。算法复杂度为O(nlog₂(n))量子比特，相比传统O(n²)方法大幅减少资源需求。

Result: 在无噪声模拟中成功求解12个地点的TSP，仅需29个量子比特（传统方法需100+）。计算时间减少近两个数量级。VQA性能优于经典机器学习方法，与蒙特卡洛方法相当，且随着问题规模增大呈现性能提升趋势。

Conclusion: 该研究展示了变分量子算法在解决大规模旅行商问题上的潜力，为在量子设备上求解更大规模TSP实例提供了可行路径，同时证明了量子方法在资源效率和性能方面的优势。

Abstract: The Travelling Salesman Problem (TSP) is a well-known NP-Hard combinatorial optimisation problem, with industrial use cases such as last-mile delivery. Although TSP has been studied extensively on quantum computers, it is rare to find quantum solutions of TSP network with more than a dozen locations. In this paper, we present high quality solutions in noise-free Qiskit simulations of networks with up to twelve locations using a hybrid penalty-free, circuit-model, Variational Quantum Algorithm (VQA). Noisy qubits are also simulated. To our knowledge, this is the first successful VQA simulation of a twelve-location TSP on circuit-model devices. Multiple encoding strategies, including factorial, non-factorial, and Gray encoding are evaluated. Our formulation scales as $\mathcal{O}(nlog_2(n))$ qubits, requiring only 29 qubits for twelve locations, compared with over 100 qubits for conventional approaches scaling as $\mathcal{O}(n^2)$. Computational time is further reduced by almost two orders of magnitude through the use of Simultaneous Perturbation Stochastic Approximation (SPSA) gradient estimation and cost-function caching. We also introduce a novel machine-learning model, and benchmark both quantum and classical approaches against a Monte Carlo baseline. The VQA outperforms the classical machine-learning approach, and performs similarly to Monte Carlo for the small networks simulated. Additionally, the results indicate a trend toward improved performance with problem size, outlining a pathway to solving larger TSP instances on quantum devices.

</details>


### [27] [High-harmonic generation driven by temporal-mode quantum states of light](https://arxiv.org/abs/2512.06602)
*Juan M. González-Monge,Johannes Feist*

Main category: quant-ph

TL;DR: 该论文建立了基于光场时间模式展开的高次谐波生成理论框架，解决了平面波非归一化问题，证明了自由空间HHG中量子效应可忽略，并指出纳米光子环境可能展现量子特征。


<details>
  <summary>Details</summary>
Motivation: 现有高次谐波生成理论主要基于单平面波模式处理，存在非归一化无限平面波的概念不一致问题，且需要扩展到实际脉冲配置。同时需要澄清量子光场在HHG中是否会产生可观测的量子效应。

Method: 采用电磁场的时间模式展开方法，将理论从单平面波模式扩展到实际脉冲配置。推导了量化单模近似偏差的修正因子，并通过分析典型HHG强度下的光子数来评估量子效应的重要性。

Result: 修正因子在典型HHG强度（~10^14 W/cm^2）下低于10^-4，表明单模近似非常准确。自由空间HHG中量子效应可忽略，因为所需光子数巨大（~10^11），量子涨落微不足道。HHG可通过Husimi分布对半经典计算进行平均来准确描述。

Conclusion: 自由空间高次谐波生成中任何量子光态都不会产生可观测的量子效应，因为所需的高光子数使量子涨落可忽略。纳米光子环境因其超小模式体积可能成为展示少光子强场过程量子特征的潜在平台。

Abstract: We develop a theoretical framework for high-harmonic generation (HHG) driven by quantum states of light based on a temporal-mode expansion of the electromagnetic field. This approach extends previous single plane-wave mode treatments to realistic pulse configurations, resolving conceptual inconsistencies arising from non-normalizable infinite plane waves and establishing consistency between analytical and numerical methods. We derive a correction factor that quantifies deviations from the single-mode approximation and show that it remains below $10^{-4}$ for intensities typical of HHG ($\sim 10^{14}~$W/cm$^2$). This result confirms that free-space HHG driven by any quantum state of light is accurately described by averaging semi-classical calculations over the Husimi distribution, with no observable genuine quantum effects. The absence of such effects is attributed to the large photon numbers ($\sim 10^{11}$) required to reach HHG intensities in free space, which render quantum fluctuations negligible. We discuss nanophotonic environments with ultrasmall mode volumes as potential platforms where few-photon strong-field processes could exhibit genuine quantum signatures.

</details>


### [28] [Fault-Tolerant Information Processing with Quantum Weak Measurement](https://arxiv.org/abs/2512.06619)
*Qi Song,Hongjing Li,Chengxi Yu,Jingzheng Huang,Ding Wang,Peng Huang,Guihua Zeng*

Main category: quant-ph

TL;DR: 提出基于量子弱测量的容错信息处理方法，通过选择微小角度的正交后选择测量基和优化测量结果组合作为解码规则，在噪声信道中最小化信号失真。


<details>
  <summary>Details</summary>
Motivation: 噪声严重影响信息获取、传输、处理和存储的可靠性，需要开发能够抑制噪声影响的容错信息处理方法。

Method: 采用量子弱测量技术，选择成对正交的后选择测量基（具有各种微小角度）和测量结果的最优组合作为解码规则，使受保护信号在通过噪声信道传输后能以最小失真恢复。

Result: 通过两能级叠加态或EPR态在随机电报噪声和退相干噪声信道中传输的典型示例，均方误差失真可接近0，容错能力可达1，且仅需有限量子资源。实验中使用经典相干光和量子相干态编码信息验证了方法的有效性。

Conclusion: 该方法为长距离量子通信、高灵敏度量子传感和精确量子计算中的噪声抑制问题提供了潜在解决方案。

Abstract: Noise is an important factor that influences the reliability of information acquisition, transmission, processing, and storage. In order to suppress the inevitable noise effects, a fault-tolerant information processing approach via quantum weak measurement is proposed, where pairwise orthogonal postselected measurement bases with various tiny angles and optimal compositions of measured results are chosen as a decoding rule. The signal to be protected can be retrieved with a minimal distortion after having been transmitted through a noisy channel. Demonstrated by typical examples of encoding signal on two-level superposition state or Einstein-Podolsky-Rossen state transmitted through random telegraph noise and decoherence noises channel, the mean squared error distortion may be close to $0$ and the fault-tolerant capability could reach $1$ with finite quantum resources. To verify the availability of the proposed approach, classic coherent light and quantum coherent state are used for encoding information in the experiment. Potentially, the proposed approach may provide a solution for suppressing noise effects in long-distance quantum communication, high-sensitivity quantum sensing, and accurate quantum computation.

</details>


### [29] [Efficient graph-diagonal characterization of noisy states distributed over quantum networks via Bell sampling](https://arxiv.org/abs/2512.06650)
*Zherui Jerry Wang,Joshua Carlo A. Casapao,Naphan Benchasattabuse,Ananda G. Maity,Jordi Tura,Akihito Soeda,Michal Hajdušek,Rodney Van Meter,David Elkouss*

Main category: quant-ph

TL;DR: 提出一种利用贝尔采样子程序来表征网络中噪声图态对角元素的协议，相比直接对角估计具有指数级资源节省优势。


<details>
  <summary>Details</summary>
Motivation: 图态是量子网络中分布式信息处理和通信的关键资源，但在实际网络中会受噪声影响。需要高效表征噪声图态的方法，特别是大规模网络中的状态评估。

Method: 采用贝尔采样子程序来表征图基中的对角元素，避免了直接对角估计所需的单量子比特测量。该方法通过测量贝尔态来提取图态的对角信息。

Result: 1. 估计完整对角元素向量所需的样本复杂度为O(n)，相比已知最佳直接估计的O(2^n)实现指数级减少；2. 全局性质（如状态保真度）的估计样本复杂度与网络规模无关；3. 数值结果显示实际估计效率优于理论界限。

Conclusion: 该工作建立了一种在现实实验条件下高效估计大规模网络中噪声图态的有前景技术，为量子网络中的状态表征提供了可扩展的解决方案。

Abstract: Graph states are an important class of entangled states that serve as a key resource for distributed information processing and communication in quantum networks. In this work, we propose a protocol that utilizes a Bell sampling subroutine to characterize the diagonal elements in the graph basis of noisy graph states distributed across a network. Our approach offers significant advantages over direct diagonal estimation using unentangled single-qubit measurements in terms of scalability. Specifically, we prove that estimating the full vector of diagonal elements requires a sample complexity that scales linearly with the number of qubits ($\mathcal{O}(n)$), providing an exponential reduction in resource overhead compared to the best known $\mathcal{O}(2^n)$ scaling of direct estimation. Furthermore, we demonstrate that global properties, such as state fidelity, can be estimated with a sample complexity independent of the network size. Finally, we present numerical results indicating that the estimation in practice is more efficient than the derived theoretical bounds. Our work thus establishes a promising technique for efficiently estimating noisy graph states in large networks under realistic experimental conditions.

</details>


### [30] [Experimental demonstration of scalable quantum cryptographic conferencing](https://arxiv.org/abs/2512.06661)
*Haotao Zhu,Zhenhua Li,Shuai Zhao,Xiaodan Lyu,Shihao Ru,Yizhi Huang,Zitong Xu,Rui Qu,Weibo Gao*

Main category: quant-ph

TL;DR: 实验实现了无需符合探测的量子密码会议，通过关联相干时间内的探测事件构建GHZ态，显著提高成功率，在331.5公里光纤上实现5.4比特/秒的密钥率，超越多用户无中继界限。


<details>
  <summary>Details</summary>
Motivation: 现有量子密码会议(QCC)实现受限于多用户符合探测的低概率，限制了GHZ纠缠态的测量或构建，阻碍了量子网络中多用户安全通信的发展。

Method: 1. 消除符合探测需求，通过关联相干时间内的探测事件构建GHZ态；2. 开发三方相位补偿方案，结合精确的时间和偏振对准；3. 设计高效配对策略简化数据处理；4. 在时间-相位编码框架下实现。

Result: 在总信道损耗66.3 dB（对应331.5公里商用光纤）条件下，实现了5.4比特/秒的安全密钥率，远超之前QCC实验的100公里限制，超越了量子网络中的多用户无中继界限。

Conclusion: 该工作开创了可扩展的多用户量子通信新范式，为城域量子网络铺平了道路，通过消除符合探测限制和开发高效相位补偿技术，显著提升了量子密码会议的性能和实用性。

Abstract: Quantum network enables a variety of quantum information processing tasks, where multi-user quantum communication is one of the important objectives. Quantum cryptographic conferencing serves as an essential solution to establish secure keys to realize secure multi-user communications. However, existing QCC implementations have been fundamentally limited by the low probability of multi-user coincidence detection to measure or construct the Greenberger-Horne-Zeilinger (GHZ) entangled state. In this work, we report the experimental realization of QCC eliminating the need for coincidence detection, where the GHZ state is constructed by correlating detection events occurring within the coherence time, thereby greatly enhancing the success probability of GHZ-state measurement. Meanwhile, to establish and maintain high-visibility GHZ measurement among three independent users, we developed a three-party phase compensation scheme combined with precise temporal and polarization alignment within a time-bin-phase encoding framework. Furthermore, we designed an efficient pairing strategy to simplify subsequent data processing and enhance processing efficiency. Based on these techniques, we successfully performed QCC experiments over total channel losses of 66.3 dB, corresponding to 331.5 km of commercial fiber (0.2 dB/km), achieving secure key rates of 5.4 bit/s, whereas previous QCC experiments have been limited to 100 km. The results surpass the multi-user repeaterless bound in quantum networks, establishing a new regime of scalable, multi-user quantum communication and paving the way for metropolitan quantum networks.

</details>


### [31] [Interplay between Standard Quantum Detailed Balance and Thermodynamically Consistent Entropy Production](https://arxiv.org/abs/2512.06707)
*Xin-Hai Tong,Kohei Yoshimura,Tan Van Vu,Naruo Ohga*

Main category: quant-ph

TL;DR: 量子马尔可夫半群满足标准量子细致平衡条件当且仅当其生成元具有特殊表示形式，导致熵产生率为零


<details>
  <summary>Details</summary>
Motivation: 研究量子开放系统中热力学一致性与细致平衡条件之间的关系，探讨熵产生率在量子马尔可夫过程中的作用

Method: 通过分析量子马尔可夫半群的生成元表示，建立标准量子细致平衡条件与特殊生成元表示之间的等价关系

Result: 证明了标准量子细致平衡条件等价于生成元具有热力学一致的特殊表示，且该表示导致熵产生率为零

Conclusion: 量子细致平衡条件与热力学一致性密切相关，熵产生率为零是两者等价的关键判据

Abstract: We demonstrate that if a quantum Markovian semigroup satisfies the standard quantum detailed balance condition, its generator admits a special representation that yields a vanishing entropy production rate. Conversely, if the generator admits a special representation adhering to the condition of thermodynamic consistency and leading to a vanishing entropy production rate, then the corresponding quantum Markovian semigroup must satisfy the standard quantum detailed balance condition. In this context, we adopt the definition of entropy production rate that is motivated by the physics literature and standard for thermodynamically consistent Lindbladians.

</details>


### [32] [Witnessing Spin-Orbital Entanglement using Resonant Inelastic X-Ray Scattering](https://arxiv.org/abs/2512.06718)
*Zecheng Shen,Shuhan Ding,Zijun Zhao,Francesco A. Evangelista,Yao Wang*

Main category: quant-ph

TL;DR: 提出利用共振非弹性X射线散射(RIXS)检测自旋-轨道纠缠的协议，通过构建厄米生成元计算量子费希尔信息(QFI)，作为自旋-轨道纠缠的稳健见证


<details>
  <summary>Details</summary>
Motivation: 纠缠在量子技术中至关重要，但在材料中的表征和控制仍然具有挑战性。需要开发实验可访问的方法来检测和量化自旋-轨道纠缠

Method: 开发基于RIXS的协议，从实验可测量的光谱构建厄米生成元，计算自旋-轨道系统的量子费希尔信息(QFI)，QFI为k-可产生态提供上界，从而作为纠缠见证。还扩展框架以处理缺乏完全偏振分辨率的实验限制

Result: 建立了通过RIXS检测自旋-轨道纠缠的完整协议，QFI提供了纠缠的稳健见证，并开发了适用于实际实验限制的松弛QFI界限

Conclusion: 该工作为在材料中实验表征自旋-轨道纠缠提供了实用框架，将谱基纠缠见证扩展到自旋-轨道系统，并考虑了实际实验约束

Abstract: Entanglement plays a central role in quantum technologies, yet its characterization and control in materials remain challenging. Recent developments in spectrum-based entanglement witnesses have enabled new strategies for quantifying many-body entanglement in macroscopic materials. Here, we develop a protocol for detecting spin--orbital entanglement using experiment-accessible resonant inelastic x-ray scattering (RIXS). Central to our approach is the construction of a Hermitian generator from experimentally measurable spectra, which allows us to compute the quantum Fisher information (QFI) available in spin--orbital systems. The resulting QFI provides upper bounds for $k$-producible states and thus serves as a robust witness of spin--orbital entanglement. To account for realistic experimental limitations, we further extend our framework to include relaxed QFI bounds applicable to measurements lacking full polarization resolution.

</details>


### [33] [Non-Orthogonal Multiple-Access for Coherent-State Optical Quantum Communications Under Lossy Photon Channels](https://arxiv.org/abs/2512.06739)
*Zhichao Dong,Xiaolin Zhou,Yongkang Chen,Wei Ni,Ekram Hossain,Xin Wang*

Main category: quant-ph

TL;DR: 提出基于SIC的Kennedy接收机和新的功率分配算法，显著提升NOMA-OQC系统性能


<details>
  <summary>Details</summary>
Motivation: 相干态在光量子通信中应用日益广泛，但其非正交特性在NOMA多用户系统中的潜力尚未被探索

Method: 提出SIC-based Kennedy接收机，推导渐近和速率，考虑大气湍流、背景噪声和光子信道损耗，使用变量替换和SCA优化功率分配

Result: 算法相比现有方案提升NOMA-OQC系统和速率超过20%，适用于中小用户数和大用户数场景

Conclusion: 成功将相干态的非正交特性应用于NOMA-OQC系统，提出的算法显著提升系统性能，为多用户光量子通信提供有效解决方案

Abstract: Coherent states have been increasingly considered in optical quantum communications (OQCs). With the inherent non-orthogonality of coherent states, non-orthogonal multiple-access (NOMA) naturally lends itself to the implementation of multi-user OQC. However, this remains unexplored in the literature. This paper proposes a novel successive interference cancellation (SIC)-based Kennedy receiver for uplink NOMA-OQC systems, along with a new approach for power allocation of the coherent states emitted by users. The key idea is to rigorously derive the asymptotic sum-rate of the considered systems, taking into account the impact of atmospheric turbulence, background noise, and lossy photon channel. With the asymptotic sum-rate, we optimize the average number of photons (or powers) of the coherent states emitted by the users. Variable substitution and successive convex approximation (SCA) are employed to convexify and maximize the asymptotic sum-rate iteratively. A new coherent-state power allocation algorithm is developed for a small-to-medium number of users. We further develop its low-complexity variant using adaptive importance sampling, which is suitable for scenarios with a medium-to-large number of users. Simulations demonstrate that our algorithms significantly enhance the sum-rate of uplink NOMA-OQC systems using coherent states by over 20\%, compared to their alternatives.

</details>


### [34] [Non-Orthogonal Multiple Access-Based Continuous-Variable Quantum Key Distribution: Secret Key Rate Analysis and Power Allocation](https://arxiv.org/abs/2512.06748)
*Zhichao Dong,Xiaolin Zhou,Huang Peng,Wei Ni,Ekram Hossain,Xin Wang*

Main category: quant-ph

TL;DR: 提出一种基于非正交多址接入的连续变量量子密钥分发系统，通过功率分配算法在恶意量子攻击下最大化总密钥率，相比正交多址方案提升23%性能。


<details>
  <summary>Details</summary>
Motivation: 解决大规模量子互联网中的多用户量子密钥分发问题，特别是在恶意量子攻击下如何最大化系统总密钥率，这是实现大规模量子网络的关键挑战。

Method: 采用高斯调制相干态和基于量子连续干扰消除的外差接收器，通过熵功率不等式和最大熵原理推导合法用户可达密钥率的闭式渐近界，基于Holevo信息分析窃听者截获信息，开发基于连续凸近似的功率分配算法。

Result: 所提NOMA-CVQKD系统在集体攻击下比量子正交多址方案提升23%总密钥率，支持16个用户在0.1过量噪声方差下工作，在不同湍流强度和传输距离下保持鲁棒性。

Conclusion: 提出的NOMA-CVQKD系统与功率分配算法能有效提升多用户量子密钥分发性能，为大规模量子互联网的实现提供了有前景的解决方案。

Abstract: We address the multi-user quantum key distribution (QKD) problem under malicious quantum attacks, which is critical for realizing a large-scale quantum Internet. This paper maximizes the sum secret key rate (SKR) of a novel uplink non-orthogonal multiple access based continuous-variable QKD (NOMA-CVQKD) system under collective attacks. The proposed system uses Gaussian-modulated coherent states and a quantum successive interference cancellation based heterodyne receiver. We derive closed-form asymptotic bounds for the legitimate users' achievable key rates via the entropy power inequality and maximum entropy principle, as well as for the eavesdropper's intercepted information based on Holevo information. A successive convex approximation based power allocation algorithm is developed to maximize the asymptotic sum SKR of the NOMA-CVQKD system under collective attacks, with guaranteed convergence to a locally optimal Karush-Kuhn-Tucker solution. Simulation results show that the proposed NOMA-CVQKD system with the power allocation algorithm achieves up to 23% higher sum SKR than quantum-orthogonal multiple access, supports 16 users at excess noise variance 0.1, and remains robust under varying turbulence intensities and transmission distances.

</details>


### [35] [Virtual Qudits for Simon's Problem: Dimension-Lifted Algorithms on Qubit Hardware](https://arxiv.org/abs/2512.06756)
*Abed Semre,Steven Frankel*

Main category: quant-ph

TL;DR: 将Simon问题的高维量子算法映射到量子比特硬件上，通过虚拟量子比特实现维度提升的oracle，在现有设备上运行高维量子算法。


<details>
  <summary>Details</summary>
Motivation: Simon问题虽然存在指数级量子加速，但当前量子设备仅支持量子比特。为了在现有硬件上实现高维量子算法的优势，需要将量子比特算法映射到量子比特硬件上。

Method: 提出通用构造方法，通过受控置换和量子比特相位操作实现虚拟量子比特，构建维度提升的oracle来编码隐藏位移，仅使用量子比特门实现其作用。

Result: 数学验证提升后的电路能产生正确的测量统计，分析维度d与深度开销的权衡关系，并通过QuTiP数值模拟验证示例值。

Conclusion: 该方法展示了如何将高维结构嵌入量子比特设备，为将量子比特算法扩展到当前硬件提供通用方法，弥合了理论高维算法与实际硬件限制之间的差距。

Abstract: Simon's problem admits an exponential quantum speedup, but current quantum devices support only qubits. This work introduces a general construction for simulating qudit versions of Simon's algorithm on qubit hardware by defining virtual qudits implemented through controlled permutations and qudit phase operations. We build a dimension lifted oracle that encodes the hidden shift in dimension d and show how to realize its action using only qubit gates. We mathematically verify that the lifted circuit reproduces the correct measurement statistics, analyze the depth overhead tradeoffs as a function of d, and provide numerical simulations in QuTiP for example values. Our approach demonstrates how higher-dimensional structures can be embedded into qubit devices and provides a general method for extending qudit algorithms to current hardware.

</details>


### [36] [Enhancing ground-state interaction strength of neutral atoms via Floquet stroboscopic dynamics](https://arxiv.org/abs/2512.06760)
*Y. Wei,M. Artoni,G. C. La Rocca,J. H. Wu,X. Q. Shao*

Main category: quant-ph

TL;DR: 通过Floquet调制增强中性原子基态相互作用，实现高保真度W态制备和单光子源应用


<details>
  <summary>Details</summary>
Motivation: 中性原子系统具有长相干时间，但基态相互作用弱，限制了可扩展量子模拟和计算的发展。需要增强基态相互作用强度。

Method: 提出通过Floquet调制里德堡原子系综来增强基态相互作用。每个Floquet周期包含基态耦合和从基态到里德堡态的脉冲驱动。

Result: 理论分析和数值模拟表明，经过特定演化时间，里德堡系综中的中性原子可以在基态流形中集体形成W态。即使在里德堡相互作用远低于阻塞区域时，保真度仍然很高。

Conclusion: 该机制为里德堡原子系综中的量子态制备提供了高效可控的方法，显著提高了量子态工程的精度和稳定性，为单光子生成提供了良好控制的量子环境。

Abstract: Neutral atom systems are promising platforms for quantum simulation and computation, owing to their long coherence times. However, their intrinsically weak ground-state interactions pose a major limitation to the advancement of scalable quantum simulation and computation. To address this challenge, we propose an approach to enhancing the ground-state interaction strength of neutral atoms via Floquet modulation of a Rydberg atomic ensemble. Each Floquet period consists of ground-state coupling followed by a pulse driving the transition from the ground state to the Rydberg state. Theoretical analysis and numerical simulations demonstrate that after a defined evolution time, neutral atoms within Rydberg ensembles can collectively form a $W$ state in the ground-state manifold. Even when the Rydberg interaction strength is far below the blockade regime, the fidelity remains remarkably high. Finally, we analyze the application of this scheme in the preparation of single-photon sources. In general, our proposed mechanism offers an efficient and highly controllable method for quantum state preparation within the Rydberg atomic ensembles, significantly enhancing the accuracy and stability of quantum state engineering while providing a well-controlled quantum environment for single-photon generation.

</details>


### [37] [Quantum Mpemba effect in long-ranged U(1)-symmetric random circuits](https://arxiv.org/abs/2512.06775)
*Han-Ze Li,Ching Hua Lee,Shuo Liu,Shi-Xin Zhang,Jian-Xin Zhong*

Main category: quant-ph

TL;DR: 该研究探讨了长程相互作用系统中的量子Mpemba效应，发现在倾斜铁磁态中始终存在该效应，而在倾斜反铁磁态中不存在，对于畴壁态仅在有效短程电路中存在，并揭示了相互作用范围与初始态电荷偏置之间的相互作用如何调控量子Mpemba效应。


<details>
  <summary>Details</summary>
Motivation: 量子Mpemba效应在守恒电荷系统中已被观察到，但在长程相互作用系统中的命运仍是一个开放问题。研究者希望探索长程相互作用如何影响量子Mpemba效应的存在性和特征。

Method: 使用长程U(1)对称随机幺正电路，通过副本张量网络计算退火Rényi-2纠缠不对称性，并结合精确对角化方法，追踪三种倾斜乘积态（铁磁、反铁磁、带中心畴壁的铁磁态）的对称性恢复过程。

Result: 量子Mpemba效应在倾斜铁磁态中存在于所有相互作用范围，在倾斜反铁磁态中不存在，在畴壁态中仅存在于有效短程电路中。在有效短程电路中，Mpemba时间t_M与子系统尺寸N_A的标度关系为t_M∼N_A^z，其中动力学指数z=min(α-1,2)。

Conclusion: 量子Mpemba效应在长程混沌系统中受到相互作用范围与初始态电荷偏置之间相互作用的调控，揭示了该效应在不同初始态和相互作用范围下的不同表现。

Abstract: The Mpemba effect, where a state prepared farther from equilibrium relaxes faster to equilibrium than one prepared closer, has a quantum counterpart where relaxation is resolved by conserved charge. However, the fate of the quantum Mpemba effect in systems with long-range interactions remains an open question. Here, we study the quantum Mpemba effect in long-ranged, U(1)-symmetric random unitary circuits. Using annealed Rényi-2 entanglement asymmetry computed via replica tensor networks and exact diagonalization, we track the symmetry restoration from three types of tilted product states: ferromagnetic, antiferromagnetic, and ferromagnetic with a central domain wall. The quantum Mpemba effect is present for tilted ferromagnetic states at all interaction ranges, but absent for tilted antiferromagnetic states, and occurs for the domain-wall state only in effectively short-ranged circuits, where the Mpemba time $t_{\rm M}$ is found to scale with the subsystem size $N_A$ as $t_{\rm M}\!\sim\!N_{A}^{\,z}$, with the dynamical exponent $z=\min(α-1,2)$. These results reveal how the quantum Mpemba effect is governed by the interplay between interaction range and initial-state charge bias in long-ranged chaotic systems.

</details>


### [38] [Maximum Independent Set via Probabilistic and Quantum Cellular Automata](https://arxiv.org/abs/2512.06778)
*Federico Dell'Anna,Matteo Grotti,Vito Giardinelli*

Main category: quant-ph

TL;DR: 该论文研究了概率元胞自动机(PCA)和量子元胞自动机(QCA)在解决最大独立集(MIS)问题中的应用，展示了两种方法都能有效收敛到MIS解。


<details>
  <summary>Details</summary>
Motivation: 探索基于局部和平移不变规则的元胞自动机方法来解决组合优化问题，为量子优化提供替代方案。传统量子优化方法如绝热量子计算和变分量子算法存在局限性，需要探索新的量子计算范式。

Method: 1. 首先设计同步PCA，其动力学驱动系统趋向最大独立集流形；2. 基于PCA行为构建QCA，结合纯耗散相和约束保持的幺正演化，在流形内重新分布概率；3. 使用张量网络模拟验证方法有效性。

Result: 1. PCA的MIS收敛概率随激活概率p趋近1而显著增加；2. 表征了到达吸收态所需步数与系统规模和图连通性的标度关系；3. QCA的耗散-幺正循环能将概率集中在MIS构型上；4. 提供了收敛时间与图大小的经验估计。

Conclusion: QCA动力学为基于局部和平移不变规则的绝热量子计算和变分量子优化方法提供了高效替代方案，展示了元胞自动机在组合优化问题中的潜力。

Abstract: We study probabilistic cellular automata (PCA) and quantum cellular automata (QCA) as frameworks for solving the Maximum Independent Set (MIS) problem. We first introduce a synchronous PCA whose dynamics drives the system toward the manifold of maximal independent sets. Numerical evidence shows that the MIS convergence probability increases significantly as the activation probability p tends to 1, and we characterize how the steps required to reach the absorbing state scale with system size and graph connectivity. Motivated by this behavior, we construct a QCA combining a pure dissipative phase with a constraint-preserving unitary evolution that redistributes probability within this manifold. Tensor Network simulations reveal that repeated dissipative--unitary cycles concentrate population on MIS configurations. We also provide an empirical estimate of how the convergence time scales with graph size, suggesting that QCA dynamics can provide an efficient alternative to adiabatic and variational quantum optimization methods based exclusively on local and translationally invariant rules.

</details>


### [39] [Physics Informed Generative Machine Learning for Accelerated Quantum-centric Supercomputing](https://arxiv.org/abs/2512.06858)
*Chayan Patra,Dibyendu Mondal,Sonaldeep Halder,Dipanjali Halder,Mostafizur Rahaman Laskar,Richa Goel,Rahul Maitra*

Main category: quant-ph

TL;DR: PIGen-SQD：结合生成式机器学习和物理信息剪枝的量子中心超计算框架，用于从噪声量子硬件中准确重建费米子态，显著降低对角化成本并保持化学精度。


<details>
  <summary>Details</summary>
Motivation: 量子中心超计算框架（如SQD）在解决挑战性问题方面具有巨大潜力，但噪声量子硬件会产生错误的采样结果，需要鲁棒且高效的配置恢复策略来实现可扩展的QCSC流程。

Method: 提出PIGen-SQD工作流：结合生成式机器学习与基于隐式低秩张量分解的物理信息配置筛选。通过扰动度量与硬件采样提供与目标态的重叠，引导生成模型在希尔伯特空间的主导区域进行随机探索，以自洽方式识别重要配置。

Result: 在IBM Heron R2量子处理器上的实验表明，该协同工作流能产生紧凑、高保真度的子空间，在强电子关联下显著降低对角化成本的同时保持化学精度。

Conclusion: PIGen-SQD通过将经典多体直觉嵌入生成式机器学习模型，提升了QCSC算法的鲁棒性和可扩展性，为在实用规模量子硬件上实现化学可靠的量子模拟提供了有前景的途径。

Abstract: Quantum centric supercomputing (QCSC) framework, such as sample-based quantum diagonalization (SQD) holds immense promise toward achieving practical quantum utility to solve challenging problems. QCSC leverages quantum computers to perform the classically intractable task of sampling the dominant fermionic configurations from the Hilbert space that have substantial support to a target state, followed by Hamiltonian diagonalization on a classical processor. However, noisy quantum hardware produces erroneous samples upon measurements, making robust and efficient configuration-recovery strategies essential for a scalable QCSC pipeline. Toward this, in this work, we introduce PIGen-SQD, an efficiently designed QCSC workflow that utilizes the capability of generative machine learning (ML) along with physics-informed configuration screening via implicit low-rank tensor decompositions for accurate fermionic state reconstruction. The physics-informed pruning is based on a class of efficient perturbative measures that, in conjunction with hardware samples, provide a substantial overlap with the target state. This distribution induces an anchoring effect on the generative ML models to stochastically explore only the dominant sector of the Hilbert space for effective identification of additional important configurations in a self-consistent manner. Our numerical experiments performed on IBM Heron R2 quantum processors demonstrate this synergistic workflow produces compact, high-fidelity subspaces that substantially reduce diagonalization cost while maintaining chemical accuracy under strong electronic correlations. By embedding classical many body intuitions directly into the generative ML model, PIGen-SQD advances the robustness and scalability of QCSC algorithms, offering a promising pathway toward chemically reliable quantum simulations on utility-scale quantum hardware.

</details>


### [40] [Single Flux Quantum Circuit Operation at Millikelvin Temperatures](https://arxiv.org/abs/2512.06895)
*Jason Walter,Adam C. Weis,Kan-Ting Tsai,Meng-Ju Yu,Naveen Katam,Alex F. Kirichenko,Oleg A. Mukhanov,Shu-Jen Han,Igor V. Vernik*

Main category: quant-ph

TL;DR: SFQ电路在毫开尔文温度下用于量子比特控制，测试显示工作裕度下降但可通过热退火恢复，约瑟夫森结临界电流增加约15%


<details>
  <summary>Details</summary>
Motivation: 随着量子处理器规模扩大，需要开发低温电子学来解决系统扩展的挑战。单磁通量子(SFQ)电路有望替代庞大、高功耗的室温电子设备，用于量子比特的数字控制、读取和协同处理。

Method: 采用SEEQC的SFQuClass数字量子管理方法，将能量高效的ERSFQ电路和量子比特集成在多芯片模块中。在4K到10mK温度范围内系统测试ERSFQ单元电路、可编程计数器和解复用器等复杂电路，并测试相关的模拟工艺控制监测器(PCMs)。

Result: 在毫开尔文温度下，偏置裕度下降，最佳偏置电流值增加约15%。通过热退火降低约瑟夫森结临界电流可以恢复裕度。PCM测试显示约瑟夫森结临界电流从4.2K到毫开尔文增加约15%，与理论和数字电路测试结果一致。

Conclusion: SFQ电路可以在毫开尔文温度下有效工作，为量子处理器的数字控制提供了可行的解决方案。温度变化对电路参数的影响可以通过热退火等方法进行补偿，确保系统稳定运行。

Abstract: As quantum computing processors increase in size, there is growing interest in developing cryogenic electronics to overcome significant challenges to system scaling. Single flux-quantum (SFQ) circuits offer a promising alternative to remote, bulky, and power-hungry room temperature electronics. To meet the need for digital qubit control, readout, and co-processing, SFQ circuits must be adapted to operate at millikelvin temperatures near quantum processors. SEEQC's SFQuClass digital quantum management approach proximally places energy-efficient SFQ (ERSFQ) circuits and qubits in a multi-chip module. This enables extremely low power dissipation, compatible with a typical dilution cryostat's limited cooling power, while maintaining high processing speed and low error rates. We report on systematic testing from 4 K to 10 mK of a comprehensive set of ERSFQ cells, as well as more complex circuits such as programmable counters and demultiplexers used in digital qubit control. We compare the operating margins and error rates of these circuits and find that, at millikelvin, bias margins decrease and the center of the margins (i.e., the optimal bias current value) increases by ~15%, compared to 4.2 K. The margins can be restored by thermal annealing by reducing Josephson junction (JJ) critical current Ic. To provide guidance for how circuit parameters vary from 4.2 K to millikelvin, relevant analog process control monitors (PCMs) were tested in the temperature range of interest. The measured JJ critical current (of the PCM JJ arrays) increases by ~15% when decreasing temperature from 4.2 K to millikelvin, in good agreement with both theory and the empirically measured change in the center of bias margins for the tested digital circuits.

</details>


### [41] [Optimal Transport of a Free Quantum Particle and its Shape Space Interpretation](https://arxiv.org/abs/2512.06940)
*Bernadette Lessel*

Main category: quant-ph

TL;DR: 该论文使用最优传输理论分析自由薛定谔方程的解，证明其定义的测度曲线在Wasserstein空间中绝对连续，并计算了最优传输映射、Wasserstein距离和Fisher信息，最后将该解解释为形状空间中的测度曲线。


<details>
  <summary>Details</summary>
Motivation: 研究自由薛定谔方程的解与最优传输理论之间的联系，探索量子力学中的概率测度演化如何在Wasserstein几何框架下描述，并建立与形状空间的联系。

Method: 使用最优传输理论分析自由薛定谔方程解定义的测度曲线，证明其在Wasserstein空间中的绝对连续性，计算最优传输映射、Wasserstein距离和Fisher信息，并将该解解释为形状空间中的测度曲线。

Result: 证明了自由薛定谔方程解定义的测度曲线在Wasserstein空间W₂(ℝ³)中是绝对连续曲线，计算了最优传输映射、Wasserstein距离和Fisher信息，并表明该解在形状空间中仍然是最短路径测地线。

Conclusion: 自由薛定谔方程的解可以通过最优传输理论在Wasserstein几何框架下分析，该解不仅描述了量子概率测度的演化，还可以自然地解释为形状空间中的测度曲线，且在形状空间中保持测地线性质。

Abstract: A solution of the free Schrödinger equation is investigated by means of Optimal transport. The curve of probability measures $μ_t$ this solution defines is shown to be an absolutely continuous curve in the Wasserstein space $W_2(\mathbb{R}^3)$. The optimal transport map from $μ_t$ to $μ_s$, the cost for this transport (i.e. the Wasserstein distance) and the value of the Fisher information along $μ_t$ are being calculated. It is finally shown that this solution of the free Schrödinger equation can naturally be interpreted as a curve in so-called Shape space, which forgets any positioning in space but only describes properties of shapes. In Shape space, $μ_t$ continues to be a shortest path geodesic.

</details>


### [42] [Suppressing Fast Dipolar Noise in Solid-State Spin Qubits](https://arxiv.org/abs/2512.06948)
*Jaime García Oliván,Ainitze Biteri-Uribarren,Oliver T. Whaites,Jorge Casanova*

Main category: quant-ph

TL;DR: 提出Hybrid-LG解耦机制，抑制自旋量子比特中的快速噪声，在NV色心系统中实现相干时间至少两倍提升


<details>
  <summary>Details</summary>
Motivation: 固态平台中的自旋退相干主要受晶格中磁活性环境影响，限制了量子技术的应用。传统的动态解耦技术（如Hahn回波）虽然能延长中心自旋相干性，但无法抑制由浴中强偶极相互作用产生的快速噪声。

Method: 提出Hybrid-LG解耦机制，通过抑制浴内偶极相互作用来减少快速噪声。使用高效的内部CCE模拟验证方法，研究金刚石中氮空位（NV）色心与大量密集的替代氮顺磁杂质（P1中心）浴耦合的系统。

Result: Hybrid-LG机制相对于包括P1中心驱动的标准技术，至少实现了NV相干时间的两倍增强，且无需额外的控制功率。

Conclusion: Hybrid-LG解耦机制能有效抑制固态量子平台中的快速噪声，显著延长自旋量子比特的相干时间，为量子技术的发展提供了重要资源。

Abstract: Spin qubit coherence is a fundamental resource for the realization of quantum technologies. For solid-state platforms, spin decoherence is dominated by the magneto-active environment in the lattice, limiting their applicability. While standard dynamical decoupling techniques, such as the Hahn echo, extend central spin coherence, they fail to suppress the fast noise arising from strong dipolar interactions within the bath. Here, we present a decoupling mechanism, Hybrid-LG, that suppresses intra-bath dipolar interactions -- thus, fast noise acting on spin qubits- and demonstrate its effectiveness in extending spin coherence through efficient in-house CCE simulations. Specifically, we investigate one of the most widely exploited solid-state quantum platforms: an ensemble of nitrogen-vacancy (NV) centers in diamond coupled to a large and dense bath of substitutional nitrogen paramagnetic impurities (P1 centers). Our results reveal at least a twofold enhancement in NV coherence time relative to standard techniques including P1 center driving, without requiring additional control power.

</details>


### [43] [On possible extensions of quantum mechanics](https://arxiv.org/abs/2512.06964)
*Yiruo Lin*

Main category: quant-ph

TL;DR: 该论文指出[1]中关于量子力学预测能力极限的no-go定理存在错误，认为量子力学仅在完全确定和完全不确定测量结果的情况下具有最大预测能力，并研究了纠缠量子比特对局部自旋测量的最优预测改进。


<details>
  <summary>Details</summary>
Motivation: 重新审视量子力学预测能力的极限问题，纠正先前文献中的错误，探讨在更宽松的测量假设下量子力学与替代理论之间的预测能力关系。

Method: 分析先前文献[1]证明中的隐含假设错误，提出更宽松的测量假设框架，研究纠缠量子比特对局部自旋测量的最优预测改进，并推测严格上界。

Result: 指出[1]的no-go定理存在错误，量子力学仅在完全确定和完全不确定情况下具有最大预测能力；在更宽松测量假设下结论不变；对纠缠量子比特的局部自旋测量，推测了替代理论预测改进的严格上界。

Conclusion: 量子力学的预测能力并非在所有情况下都是最大的，只有在完全确定和完全不确定测量结果的情况下才达到极限；对纠缠量子比特系统，替代理论的预测改进存在严格限制。

Abstract: It was argued [1] that there can be no extension of quantum mechanics with improved predictive power on a measurement freely chosen, independently of any event that is not in its future light cone. The assumption of measurement choice was criticized [2] to be too strong to be physically necessary and extensions of quantum mechanics were shown [3] to be possible under a more relaxed measurement assumption. Here I point out an error in the criticism and observe that the actual mistake of the no-go theorem lies in an unwarranted assumption implicitly made in the proof of [1]. Hence, quantum mechanics is guaranteed to have the maximal predictive power only in situations of complete certainty and complete uncertainty about measurement outcomes. I then show that the measurement assumption can be further relaxed without affecting the conclusion on the predictive power of quantum mechanics versus alternative theories. I further study the optimal predicative improvement over quantum mechanics of local spin measurements on a pair of entangled qubits by any alternative theory and conjecture a strict upper bound.

</details>


### [44] [Quantum Correlation Assisted Cooling of Microwave Cavities Below the Ambient Temperature](https://arxiv.org/abs/2512.06996)
*Daryoosh Vashaee,Jahanfar Abouie*

Main category: quant-ph

TL;DR: 该论文提出了一种利用相关原子对流冷却微波腔的理论框架，分析了两种耦合构型，发现双原子构型能实现量子增强冷却，可将腔温降至远低于储层温度，并提出了超导量子比特实验实现方案。


<details>
  <summary>Details</summary>
Motivation: 开发一种在量子硬件中实现自主、片上微波模式制冷的方法，利用相关原子对流的量子特性来增强冷却效果，克服传统冷却方法的限制。

Method: 从Lindblad模型出发，推导了稳态腔占据数和有效温度的闭式表达式。研究了两种耦合构型：单原子构型（每对中只有一个原子与腔相互作用）和双原子构型（两个原子集体耦合）。分析了参数空间包括失谐、耦合强度、阻尼和原子对内交换。

Result: 单原子模型能冷却到低于声子浴温度但无法低于储层温度，而双原子方案表现出增强的制冷效果——原子对相关性改变了腔的上下跃迁速率，使得在弱声子阻尼下稳态温度可远低于储层温度。识别了共振附近的冷却谷以及储层主导和声子主导机制之间的交叉区域。

Conclusion: 双原子构型实现了单原子情况下不存在的真正量子增强冷却机制。通过超导量子比特在3D腔中重复制备、耦合和重置的实验方案，可实现MHz速率的相互作用循环，即使低温恒温器在~1K时也能将腔温降至50-120mK，为可扩展量子硬件中的微波模式自主片上制冷提供了途径。

Abstract: We develop a theoretical framework for cooling a microwave cavity mode using a Poisson stream of internally correlated pairs of two-level systems and analyze its performance under realistic dissipation. Starting from a Lindblad model of a phonon-tethered cavity interacting with sequentially injected atom pairs, we derive closed-form expressions for the steady-state cavity occupation and effective temperature. Two coupling geometries are examined: a one-atom configuration, where only one member of each pair interacts with the cavity, and a two-atom configuration, where both atoms couple collectively. The single-atom model enables cooling below the phonon bath but not below the reservoir temperature, whereas the two-atom scheme exhibits enhanced refrigeration - pair correlations modify the cavity's upward and downward transition rates so that the steady-state temperature can fall well below that of the reservoir for weak phonon damping. We map the parameter space including detuning, coupling strength, damping, and intra-pair exchange, identifying cooling valleys near resonance and the crossover between reservoir- and phonon-dominated regimes. The two-atom configuration thus realizes a genuine quantum-enhanced cooling mechanism absent in the single-atom case. We further outline an experimental implementation using two superconducting qubits repeatedly prepared, coupled, and reset inside a 3D cavity. Realistic reset and flux-tuning protocols support MHz-rate interaction cycles, enabling engineered reservoirs to impose cavity temperatures of 50-120 mK even when the cryostat is at ~1 K, offering a pathway to autonomous, on-chip refrigeration of microwave modes in scalable quantum hardware.

</details>


### [45] [Bohmian Trajectories Within Hilbert Space Based Quantum Mechanics. Solution of the Measurement Problem](https://arxiv.org/abs/2512.07007)
*Tulsi Dass*

Main category: quant-ph

TL;DR: 该论文提出了一种将传统量子力学状态-可观测量框架与德布罗意-玻姆理论相结合的形式体系，通过引入随机过程和扩展构型空间来处理自旋等离散可观测量。


<details>
  <summary>Details</summary>
Motivation: 德布罗意-玻姆理论虽然能解决量子测量问题，但在处理自旋、相对论性以及与希尔伯特空间框架的整合方面存在困难。本文旨在建立一个一致的形式体系，将传统量子力学框架与德布罗意-玻姆理论的优点相结合。

Method: 采用薛定谔波函数的系综解释，在概率空间上引入与海森堡位置算符对应的随机过程，推导出玻姆轨迹的引导方程。通过扩展构型空间到谱空间来处理离散本征值的可观测量（如自旋），并以泡利方程为例进行说明。

Result: 建立了将传统量子力学状态-可观测量框架与德布罗意-玻姆理论整合的形式体系，能够处理连续和离散可观测量，给出了冯·诺依曼投影规则的直接推导，并展示了如何应用于宇宙量子力学。

Conclusion: 该工作成功构建了一个一致的形式体系，将传统量子力学框架与德布罗意-玻姆理论相结合，解决了后者在自旋处理和与希尔伯特空间整合方面的问题，为量子测量问题提供了新的解决方案。

Abstract: de Broglie-Bohm theory (dBBT), treating quantum particles as point objects moving along well defined (Bohmian) trajectories, offers an appealing solution of the measurement problem in quantum mechanics; it has, however, problems relating to spin, relativity and lack of proper integration with the Hilbert space based framework. In this work, we present a consistent formalism which has the traditional state-observable framework integrated with the desirable features of dBBT. We adopt ensemble interpretation for the Schrodinger wave function $ψ$. Given a Schrodinger wave function $ψ$, we use its value $ψ_0$ at some fixed time (say, $t = 0$) to define the probability measure $|ψ_0|^2 {\rm d}x$ on the system configuration space $M$ ($=\mathbb{R}^n$). On the resulting probability space $\mathcal{M}_0$, we introduce a stochastic process $ξ(t)$ corresponding to the Heisenberg position operator $X_H(t)$ such that, in the Heisenberg state $|ψ_h\rangle$ corresponding to $ψ_0$, the expectation value of $X_H(t)$ equals that of $ξ(t)$ in $\mathcal{M}_0$. This condition leads to the de Broglie-Bohm guidance equation for the sample paths of the process $ξ(t)$ which are, therefore, Bohmian trajectories supposedly representing time-evolutions of individual members of the $ψ_0$-ensemble. Stochastic processes and Bohmian trajectories corresponding to observables with discrete eigenvalues (in particular spin) are treated by extending the configuration space to the spectral space of the commutative algebra obtained by adding appropriate discrete observables to the position observables. Pauli's equation is treated as an example. A straightforward derivation of von Neumann's projection rule employing the Schrodinger-Bohm evolution of individual systems along their Bohmian trajectories is given. Some comments on the potential application of the formalism developed here to quantum mechanics of the universe are included.

</details>


### [46] [From Quantum Chaos to Classical Chaos via Gain-Induced Measurement Dynamics in a Photon Gas](https://arxiv.org/abs/2512.07045)
*Violetta Sharoglazova,Marius Puplauskis,Lotte Hof,Jan Klaers*

Main category: quant-ph

TL;DR: 量子混沌光子气体中的增益竞争作为量子测量机制，从初始叠加态中随机选择单模，自然产生经典混沌行为


<details>
  <summary>Details</summary>
Motivation: 探索量子力学如何涌现经典混沌行为，解决量子系统如何产生对初始条件指数敏感性的核心问题

Method: 利用混沌光子气体中的增益竞争作为量子测量机制，通过随机非线性放大从初始叠加态中选择单模

Result: 该机制自然产生经典混沌行为，特别是对初始条件的敏感性，为混沌系统中的量子-经典转变提供了具体物理机制

Conclusion: 增益动力学可以自然地涌现量子测量的关键方面（态投影、玻恩规则选择、不可逆性），为量子-经典过渡提供了具体物理机制

Abstract: How classical chaos emerges from quantum mechanics remains a central open question, as the unitary evolution of isolated quantum systems forbids exponential sensitivity to initial conditions. A key insight is that this quantum-classical link is provided by measurement processes. In this work, we identify gain competition in a chaotic photon gas as an operational quantum measurement that selects single motional modes from an initial superposition through stochastic, nonlinear amplification. We show that this mechanism naturally gives rise to classical chaotic behavior, most notably sensitivity to initial conditions. Our results provide a concrete physical mechanism for the quantum-classical transition in a chaotic system and demonstrate that essential aspects of quantum measurement-state projection, Born-rule-like selection, and irreversibility-can naturally emerge from intrinsic gain dynamics.

</details>


### [47] [The uncharted space of non-Hermitian solutions to the Hartree-Fock and Kohn-Sham equations](https://arxiv.org/abs/2512.07048)
*Matthias Ernzerhof,Mohamed Loutis,Pierre-Olivier Roy,Didier Mayou*

Main category: quant-ph

TL;DR: 论文提出在Hartree-Fock和Kohn-Sham方程中存在一类新的非厄米特解，这些解对应单电子与其余N-1电子系统之间的电流密度交换，扩展了传统量子化学方法的适用范围。


<details>
  <summary>Details</summary>
Motivation: 传统量子化学方法主要处理封闭系统，但许多物理化学问题涉及系统与环境耦合（如分子与表面相互作用）。作者发现即使在无外部环境耦合的系统中，HF和KS方程中的单电子与其余电子之间也存在类似环境耦合，可能产生新的物理状态。

Method: 采用非厄米特量子力学框架重新表述Hartree-Fock和Kohn-Sham方法，考虑单电子与其余N-1电子系统之间的电流密度交换，寻找自洽方程的新解。

Result: 发现了HF和KS方程中一类先前未被注意的新解，这些解对应开放系统条件下的物理状态，在开放系统计算中总是会出现这类解。

Conclusion: 非厄米特HF和KS方法能够描述更广泛的物理化学现象，包括电子密度转移过程，扩展了传统量子化学方法的应用范围，为研究分子-表面相互作用等问题提供了新工具。

Abstract: Many problems in physical chemistry involve systems that are coupled to an environment, such as a molecule interacting with an adjacent surface, possibly resulting in meta-stable molecular states where electron density is transferred to the surface. Such systems can be described by non-Hermitian quantum mechanics (NHQM), where the Hamiltonian includes dissipative terms. Within NHQM, one can also formulate the Hartree-Fock (HF) and Kohn-Sham (KS) methods and, as in the conventional theory, an effective independent-particle picture is employed. The crucial observation of the present work is that even for systems that are not coupled to an environment, in the HF or KS equation a single electron is coupled to a bath of the remaining electrons which can act as an environment, opening up the possibility for the exchange of current density between the one-electron and the remaining N-1 electron system. The corresponding self-consistent states represent a new uncharted space of solutions to the HF and KS equations. We show that the additional solutions can have a physical interpretation and thus extend the range of problems HF and KS can be applied to. If open-system HF and KS calculations are performed, the new class of solutions is always encountered but this has also not been noted previously.

</details>


### [48] [Timing quantum emission: coherence, superradiance, and entanglement in order](https://arxiv.org/abs/2512.07055)
*Nur Fadhillah Binti Rahimi,Norman Koo Tze Wei,Daniel Schumayer,Christopher Gies,Leong Chuan Kwek,David. A. W. Hutchinson*

Main category: quant-ph

TL;DR: 研究紧密排列量子发射体的超辐射短期时间动力学，发现相干性、超辐射和纠缠之间存在明确的时间层次：相对相干性最先出现，然后是相关发射峰值，接着是最小纠缠，最后是相关退相干。


<details>
  <summary>Details</summary>
Motivation: 基于Dicke 1954年的框架，研究紧密排列量子发射体中超辐射的短期时间动力学，探索相干性、超辐射和纠缠之间的时间演化关系。

Method: 在Dicke框架基础上，分析紧密排列量子发射体的时间演化，研究相对相干性、相关发射、纠缠和相关退相干的顺序出现过程。

Result: 发现了一个明确的时间层次：相对相干性最先发展，随后是相关发射峰值，然后是最小纠缠，最后是相关退相干。增强的相对相干性会引发相关发射，当相关退相干可忽略时，纠缠和相关发射在时间上紧密关联。

Conclusion: 紧密排列量子发射体的超辐射过程存在明确的时间层次，相对相干性在引发相关发射中起关键作用，当退相干效应较小时，纠缠和相关发射表现出紧密的时间关联。

Abstract: We investigate the short-term temporal dynamics of superradiance in closely spaced quantum emitters. Building on Dicke's 1954 framework, we analyze the sequential emergence of coherence, superradiance, and entanglement, revealing a distinct temporal hierarchy in their extremal values: relative coherence develops first, followed by the peak of correlated emission, then minimal entanglement, and finally correlated dephasing. These findings suggest that enhanced relative coherence initiates correlated emission and when correlated dephasing is negligible, entanglement and correlated emission become tightly linked in time.

</details>


### [49] [Beam search decoder for quantum LDPC codes](https://arxiv.org/abs/2512.07057)
*Min Ye,Dave Wecker,Nicolas Delfosse*

Main category: quant-ph

TL;DR: 提出基于波束搜索启发式算法的量子LDPC码解码器，通过调整波束宽度实现速度-准确率权衡，在特定参数下相比BP-OSD解码器显著降低逻辑错误率或运行时间。


<details>
  <summary>Details</summary>
Motivation: 现有量子LDPC码解码器（如BP-OSD）在性能和速度方面存在局限，需要一种更灵活的解码方法，能够根据实际应用需求在速度和准确率之间进行权衡。

Method: 提出基于波束搜索启发式算法的解码器，使用置信传播（BP）作为引导，适用于所有量子LDPC码。通过调整波束宽度等参数实现不同的速度-准确率权衡。

Result: 在[[144,12,12]]双变量自行车码的电路级噪声模拟中：波束宽度64时逻辑错误率降低17倍；波束宽度8时达到与BP-OSD相同的逻辑错误率，但99.9百分位运行时间减少26.2倍；波束宽度32时逻辑错误率降低5.6倍，运行时间低于1ms，适合离子阱架构。

Conclusion: 波束搜索解码器为量子LDPC码提供了灵活的速度-准确率权衡方案，在软件单核上即可实现高性能解码，有望仅用三个32核CPU解码1000逻辑量子比特的离子阱量子计算机。

Abstract: We propose a decoder for quantum low density parity check (LDPC) codes based on a beam search heuristic guided by belief propagation (BP). Our beam search decoder applies to all quantum LDPC codes and achieves different speed-accuracy tradeoffs by tuning its parameters such as the beam width. We perform numerical simulations under circuit level noise for the $[[144, 12, 12]]$ bivariate bicycle (BB) code at noise rate $p=10^{-3}$ to estimate the logical error rate and the 99.9 percentile runtime and we compare with the BP-OSD decoder which has been the default quantum LDPC decoder for the past six years. A variant of our beam search decoder with a beam width of 64 achieves a $17\times$ reduction in logical error rate. With a beam width of 8, we reach the same logical error rate as BP-OSD with a $26.2\times$ reduction in the 99.9 percentile runtime. We identify the beam search decoder with beam width of 32 as a promising candidate for trapped ion architectures because it achieves a $5.6\times$ reduction in logical error rate with a 99.9 percentile runtime per syndrome extraction round below 1ms at $p=5 \times10^{-4}$. Remarkably, this is achieved in software on a single core, without any parallelization or specialized hardware (FPGA, ASIC), suggesting one might only need three 32-core CPUs to decode a trapped ion quantum computer with 1000 logical qubits.

</details>


### [50] [Hidden Structural Variants in ALD NbN Superconducting Trilayers Revealed by Atomistic Analysis](https://arxiv.org/abs/2512.07095)
*Prachi Garg,Danqing Wang,Hong X. Tang,Baishakhi Mazumder*

Main category: quant-ph

TL;DR: 该研究通过先进显微技术和机器学习方法，识别了NbN/AlN/NbN约瑟夫森结中限制性能的原子尺度缺陷，发现电极中ε-Nb₂N₂纳米夹杂物与δ-NbN相共存是导致超导电流抑制和软转变的主要原因。


<details>
  <summary>Details</summary>
Motivation: 超导薄膜的微观不均匀性是限制量子电路性能和可扩展性的关键瓶颈。全氮化物约瑟夫森结因其潜在的高相干时间和高温操作能力而备受关注，但其性能常受多晶型、杂质和界面质量等局部变化限制。

Method: 结合电学测量（临界电流密度、准粒子电流）和先进显微技术（识别纳米尺度缺陷），采用机器学习集成方法分析NbN电极中的相共存现象，建立材料缺陷与器件性能的关联。

Result: 电学测量显示临界电流密度被抑制且准粒子电流呈软转变，但电阻与结面积的反比关系证实势垒厚度均匀。研究发现电极中ε-Nb₂N₂纳米夹杂物与主要δ-NbN相共存，这些缺陷导致未解析的超电流和向正常态的软转变。

Conclusion: 通过识别特定原子尺度缺陷、追溯其起源于薄膜初始成核过程，并将其与有害电学特征关联，本研究建立了材料与器件的相关性，为相工程提供了针对性策略，以实现可重复、高相干和可扩展的量子器件。

Abstract: Microscopic inhomogeneity within superconducting films is a critical bottleneck hindering the performance and scalability of quantum circuits. All-nitride Josephson Junctions (JJs) have attracted substantial attention for their potential to provide enhanced coherence times and enable higher temperature operation. However, their performance is often limited by local variations caused by polymorphism, impurities, and interface quality. This work diagnoses atomic-scale limitations preventing superconducting NbN/AlN/NbN JJs from reaching their full potential. Electrical measurements reveal suppressed critical current density and soft onset of quasiparticle current. However, inverse proportionality between resistance and junction area confirms homogenous barrier thickness. This isolates structural and chemical variations in electrodes and barrier as the source of performance limitation. The observed characteristics are attributed to complex materials problems: NbN polymorphism, phase coexistence, and oxygen impurities. Using advanced microscopy and machine learning integrated approach, nanoscale inclusions of epsilon-Nb2N2 are found to coexist within dominant delta-NbN electrodes. DC performance of JJs may be affected by these defects, leading to unresolved supercurrent and soft transition to normal state. By identifying specific atomic scale defects, tracing its origin to initial film nucleation, and linking to its detrimental electrical signature, this work establishes a material-to-device correlation and provides targeted strategy for phase engineering towards reproducible, high coherence and scalable quantum devices.

</details>


### [51] [Wigner's Frame](https://arxiv.org/abs/2512.07101)
*Emily Adlam*

Main category: quant-ph

TL;DR: 通过参考系视角分析扩展维格纳朋友场景，区分系统属性的相对性与绝对性，挑战量子力学中观察者结果联合分布的必然性


<details>
  <summary>Details</summary>
Motivation: 为扩展维格纳朋友场景提供新的分析视角，通过参考系概念解决量子力学中观察者相对性问题，避免无限相对化回归

Method: 运用对称性原理区分系统属性的相对性与绝对性，提出观察者观测事实始终明确，但参考系间关系不一定明确的理论框架

Result: 观察者观测结果存在明确事实，但参考系间关系可能不明确，因此不一定存在可比较的联合分布，反对无限相对化回归

Conclusion: 参考系分析为扩展维格纳朋友场景提供新见解，区分相对与绝对属性，解决量子观测中的相对性问题

Abstract: This article suggests that thinking about the role of reference frames can provide new insight into Extended Wigner's Friend scenarios. This involves appealing to symmetries to make a principled distinction between properties of a system which are meaningful only relative to an external reference system and properties which are meaningful without further relativization. Thus we may propose that there are always well-defined facts about what observers have observed, but there are not necessarily well-defined facts about the relations between their reference frames, so there will not always exist a joint distribution over their outcomes which can meaningfully be compared to the predictions of quantum mechanics. In addition, this approach also offers a general argument against the idea that there should be a regress of relativization.

</details>


### [52] [Scheduling in Quantum Satellite Networks: Fairness and Performance Optimization](https://arxiv.org/abs/2512.07108)
*Ashutosh Jayant Dikshit,Naga Lakshmi Anipeddi,Prajit Dhara,Saikat Guha,Deirdre Kilbane,Leandros Tassiulas,Don Towsley,Nitish K. Panigrahy*

Main category: quant-ph

TL;DR: 提出基于整数线性规划的量子卫星网络调度优化框架，解决卫星-地面站配对问题，考虑资源限制、公平性、保真度阈值及实际环境因素


<details>
  <summary>Details</summary>
Motivation: 量子卫星网络是实现长距离量子通信的关键技术，但需要有效调度卫星与地面站之间的配对，以应对资源限制、环境因素和多卫星中继等复杂挑战

Method: 采用整数线性规划（ILP）优化框架，综合考虑卫星和地面站资源限制、公平性、纠缠保真度阈值、大气损耗、天气、背景噪声以及多卫星中继链路等实际约束

Result: 开发了支持多种调度目标的优化框架，能够分析最大化总纠缠分布率与确保地面站对之间公平性的权衡，并可作为评估其他传输调度策略性能的基准工具

Conclusion: 该ILP优化框架为量子卫星网络调度提供了系统解决方案，能够有效处理实际环境约束，平衡不同性能指标，并为未来调度策略设计提供基准参考

Abstract: Quantum satellite networks offer a promising solution for achieving long-distance quantum communication by enabling entanglement distribution across global scales. This work formulates and solves the quantum satellite network scheduling problem by optimizing satellite-to-ground station pair assignments under realistic system and environmental constraints. Our framework accounts for limited satellite and ground station resources, fairness, entanglement fidelity thresholds, and real world non-idealities including atmospheric losses, weather and background noise. In addition, we incorporate the complexities of multi-satellite relays enabled via inter-satellite links. We propose an integer linear programming (ILP) based optimization framework that supports multiple scheduling objectives, allowing us to analyze tradeoffs between maximizing total entanglement distribution rate and ensuring fairness across ground station pairs. Our framework can also be used as a benchmark tool to measure the performance of other potential transmission scheduling policies.

</details>


### [53] [Digital-Analog-Digital Quantum Supremacy](https://arxiv.org/abs/2512.07127)
*Daniel Lidar*

Main category: quant-ph

TL;DR: 该论文提出了一个用于混合数字-模拟-数字量子计算模型的量子霸权框架，证明其输出分布与IQP电路相近，并表明在特定假设下，经典计算机无法有效模拟，为当前量子退火器等设备提供了量子霸权测试的可能性。


<details>
  <summary>Details</summary>
Motivation: 量子霸权研究主要集中在门模型设置中，但许多实际量子设备（如量子退火器）采用混合数字-模拟架构。需要为这类设备建立量子霸权框架，以评估其计算能力并证明其相对于经典计算机的优势。

Method: 提出混合数字-模拟-数字量子计算模型：初始单量子比特门层 + 横向场伊辛模拟块 + 最终单量子比特门层 + Z基测量。证明该模型输出分布与IQP电路在常数总变差距离内相近。考虑全连接和有界度硬件图，匹配多种量子平台架构。

Result: 证明了在反集中假设（全连接图已证明，有界度图推测）和相关复温度伊辛配分函数的平均情况硬度猜想下，任何实现常数TV误差的高效经典采样器将导致多项式层次结构坍塌。这意味着量子霸权测试在当前量子退火器等设备上是可行的。

Conclusion: 该研究为混合数字-模拟量子设备建立了量子霸权框架，表明量子霸权测试不仅限于门模型量子计算机，也可在当今的量子退火器和其他混合数字-模拟量子演化设备上实现，扩展了量子霸权实验的平台范围。

Abstract: Quantum supremacy has been explored extensively in gate-model settings. Here, we introduce a quantum-supremacy framework for a hybrid digital-analog-digital quantum computing (DADQC) model. We consider a device that applies an initial layer of single-qubit gates, a single transverse-field Ising analog block, and a final single-qubit layer before $Z$-basis readout. The analog block approximates $Z$-diagonal Ising evolution, and we prove that the resulting output distribution is within constant total-variation (TV) distance of an Instantaneous Quantum Polynomial-time (IQP) circuit. Our bounds and constructions are established for fully connected as well as bounded-degree hardware graphs, matching a variety of architectures, including trapped-ion, neutral atom, and superconducting platforms. Assuming anticoncentration (which we prove for all-to-all hardware graphs and conjecture for bounded-degree hardware graphs) and an average-case hardness conjecture for the associated complex-temperature Ising partition functions, standard reductions imply that any efficient classical sampler achieving constant TV error collapses the polynomial hierarchy. Our results imply that quantum-supremacy tests are possible on today's quantum annealers, as well as other devices capable of hybrid digital-analog quantum evolution.

</details>


### [54] [A manufacturable surface code architecture for spin qubits with fast transversal logic](https://arxiv.org/abs/2512.07131)
*Jason D. Chadwick,Willers Yang,Joshua Viszlai,Frederic T. Chong*

Main category: quant-ph

TL;DR: 提出SNAQ架构，利用硅自旋量子比特的快速穿梭能力，通过时间复用减少读出组件数量，显著降低芯片面积并提升逻辑时钟速度。


<details>
  <summary>Details</summary>
Motivation: 硅量子点自旋量子比特平台面临读出组件物理尺寸远大于量子比特的架构瓶颈，导致无法实现所有量子比特同时测量的密集布局，这阻碍了量子纠错的实施。

Method: 提出SNAQ（Shuttling-capable Narrow Array of spin Qubits）表面码架构，利用自旋穿梭能力时间复用辅助量子比特的初始化和读出，放松了1:1读出-量子比特比例假设。

Result: SNAQ架构在足够高的量子比特相干时间下，可实现芯片面积每逻辑量子比特数量级减少，通过更密集的物理量子比特网格实现4.0-22.3倍的本地逻辑时钟速度提升，15-to-1魔法态蒸馏的时空成本降低57-60%。

Conclusion: SNAQ架构为近期可制造的硅自旋量子比特阵列提供了实现高性能容错计算的有力路径，并确定了关键硬件指标。

Abstract: Spin qubits in silicon quantum dot arrays are a promising quantum computation platform for long-term scalability due to their small qubit footprint and compatibility with advanced semiconductor manufacturing. However, spin qubit devices face a key architectural bottleneck: the large physical footprint of readout components relative to qubits prevents a dense layout where all qubits can be measured simultaneously, complicating the implementation of quantum error correction. This challenge is offset by the platform's unique rapid shuttling capability, which can be used to transport qubits to distant readout ports. In this work, we explore the design constraints and capabilities of spin qubits in silicon and propose the SNAQ (Shuttling-capable Narrow Array of spin Qubits) surface code architecture, which relaxes the 1:1 readout-to-qubit assumption by leveraging spin shuttling to time-multiplex ancilla qubit initialization and readout. Our analysis shows that, given sufficiently high (experimentally demonstrated) qubit coherence times, SNAQ delivers an orders-of-magnitude reduction in chip area per logical qubit. Additionally, by using a denser grid of physical qubits, SNAQ enables fast transversal logic for short-distance logical operations, achieving 4.0-22.3x improvement in local logical clock speed while still supporting global operations via lattice surgery. This translates to a 57-60% reduction in spacetime cost of 15-to-1 magic state distillation, a key fault-tolerant subroutine. Our work pinpoints critical hardware metrics and provides a compelling path toward high-performance fault-tolerant computation on near-term-manufacturable spin qubit arrays.

</details>


### [55] [Beyond real: Investigating the role of complex numbers in self-testing](https://arxiv.org/abs/2512.07160)
*Ranyiliu Chen,Laura Mančinska,Jurij Volčič*

Main category: quant-ph

TL;DR: 论文研究了复杂自测试，这是标准自测试的推广，考虑了量子策略的统计特性与其复共轭不可区分的情况。主要贡献包括：将标准自测试的结构结果扩展到复杂设置，给出了算子代数特征描述，建立了非局域策略的分类，并构造了涉及四元数的策略。


<details>
  <summary>Details</summary>
Motivation: 研究复杂自测试的动机在于理解量子策略中复数的微妙作用，特别是当策略的统计特性与其复共轭不可区分时的情况。这扩展了标准自测试的框架，揭示了在标准自测试不适用时需要复杂自测试的边界条件。

Method: 采用算子代数方法，证明了复杂自测试等价于高阶矩实部的唯一性，从而得到了基于实C*代数的基无关表述。通过构造涉及四元数的策略来建立首个真正复杂策略的标准自测试。

Result: 1) 将标准自测试的结构结果扩展到复杂设置；2) 给出了复杂自测试的算子代数特征描述；3) 建立了非局域策略的分类；4) 确定了标准自测试不适用而需要复杂自测试的紧边界；5) 构造了首个真正复杂策略的标准自测试。

Conclusion: 该工作阐明了复杂自测试的结构，突出了复数在双粒子贝尔非局域性中的微妙作用。通过算子代数特征描述和策略分类，为理解量子策略中复数的必要性提供了理论基础，并建立了标准自测试与复杂自测试之间的明确边界。

Abstract: We investigate complex self-testing, a generalization of standard self-testing that accounts for quantum strategies whose statistics is indistinguishable from their complex conjugate's. We show that many structural results from standard self-testing extend to the complex setting, including lifting of common assumptions. Our main result is an operator-algebraic characterization: complex self-testing is equivalent to uniqueness of the real parts of higher moments, leading to a basis-independent formulation in terms of real C* algebras. This leads to a classification of non-local strategies, and a tight boundary where standard self-testing do not apply and complex self-testing is necessary. We further construct a strategy involving quaternions, establishing the first standard self-test for genuinely complex strategy. Our work clarifies the structure of complex self-testing and highlights the subtle role of complex numbers in bipartite Bell non-locality.

</details>


### [56] [A versatile coherent Ising computing platform](https://arxiv.org/abs/2512.07182)
*Hai Wei,Chengjun Ai,Putuo Guo,Bingjie Jia,Lixin Yuan,Hanquan Song,Shaobo Chen,Chongyu Cao,Jie Wu,Chao Ju,Yin Ma,Jintao Fan,Minglie Hu,Chuan Wang,Kai Wen*

Main category: quant-ph

TL;DR: 该论文展示了通过飞秒激光泵浦实现的相干伊辛机在解决NP完全问题上的性能提升，在100节点莫比乌斯梯图上达到55%的平均成功率，并保持8小时稳定运行。


<details>
  <summary>Details</summary>
Motivation: 相干伊辛机作为解决NP完全问题的混合量子计算设备具有巨大潜力，但面临噪声诱导局部极小值等挑战。研究旨在提高CIM的计算精度和稳定性，探索其在分子对接和信用评分等实际应用中的可行性。

Method: 采用飞秒激光泵浦技术实现相干伊辛机，在光学和结构维度集成优化策略。飞秒脉冲产生更高峰值功率，增强量子效应并降低光纤CIM的泵浦功率。

Result: 在100个顶点的莫比乌斯梯图上达到55%的平均最优解识别成功率，相比其他方案性能显著提升。系统能连续8小时保持高成功率，展示了实际应用的稳定性。

Conclusion: 飞秒激光泵浦的相干伊辛机在解决NP完全问题上表现出优越性能，验证了CIM的理论潜力，为其在大规模实际应用中的集成铺平了道路。

Abstract: Coherent Ising Machines (CIMs) have emerged as a hybrid form of quantum computing devices designed to solve NP-complete problems, offering an exciting opportunity for discovering optimal solutions. Despite challenges such as susceptibility to noise-induced local minima, we achieved notable advantages in improving the computational accuracy and stability of CIMs. We conducted a successful experimental demonstration of CIM via femto-second laser pumping that integrates optimization strategies across optical and structural dimensions, resulting in significant performance enhancements. The results are particularly promising. An average success rate of 55% was achieved to identify optimal solutions within a Mobius Ladder graph comprising 100 vertices. Compared with other alternatives, the femto-second pulse results in significantly higher peak power, leading to more pronounced quantum effects and lower pump power in optical fiber based CIMs. In addition, we have maintained an impressive success rate for a continuous period of 8 hours, emphasizing the practical applicability of CIMs in real-world scenarios. Furthermore, our research extends to the application of these principles in practical applications such as molecular docking and credit scoring. The results presented substantiate the theoretical promise of CIMs, paving the way for their integration into large-scale practical applications.

</details>


### [57] [Non-Hermitian Bose-Hubbard-like quantum models](https://arxiv.org/abs/2512.07250)
*Miloslav Znojil*

Main category: quant-ph

TL;DR: 提出一类非厄米大三角矩阵量子哈密顿量，其结构类似于Bose-Hubbard模型，可通过"厄米化"薛定谔方程计算奇异值，并给出两种紧凑的矩阵连分式形式的格林函数。


<details>
  <summary>Details</summary>
Motivation: 研究非厄米大三角矩阵量子哈密顿量，特别是与Bose-Hubbard模型结构相似的子类，旨在开发用户友好的数值计算方法。

Method: 选择一类结构类似于Bose-Hubbard模型的非厄米大三角矩阵哈密顿量，通过"厄米化"薛定谔方程计算奇异值，并推导出两种紧凑的矩阵连分式形式的格林函数。

Result: 成功将这类非厄米哈密顿量的奇异值计算转化为"厄米化"薛定谔方程问题，并获得了两种数值高效的矩阵连分式格林函数表达式。

Conclusion: 该方法为处理特定类型的非厄米大三角矩阵哈密顿量提供了用户友好的数值计算框架，特别是其格林函数的矩阵连分式形式具有计算效率优势。

Abstract: Among all of the non-Hermitian large-tridiagonal-matrix quantum Hamiltonians we choose a subclass with the structure resembling the ``benchmark'' realistic Bose-Hubbard model. We demonstrate that this choice can be declared user-friendly in the sense that the underlying singular values can be specified via a ``Hermitized'' Schrödinger-like equation. In particular, the related ``Hermitized'' Green's functions is shown given the two alternative compact and numerically efficient matrix continued fraction forms.

</details>


### [58] [Quantum geometrical effects in non-Hermitian systems](https://arxiv.org/abs/2512.07264)
*Anton Montag,Tomoki Ozawa*

Main category: quant-ph

TL;DR: 本文探讨了非厄米系统中量子几何与物理可观测现象之间的关系，展示了量子几何如何解释非厄米系统的行为，并提出了通过时间周期调制实验测量非厄米量子度量的方法。


<details>
  <summary>Details</summary>
Motivation: 研究非厄米系统中量子几何与物理可观测现象之间的关联，探索如何通过量子几何概念更好地理解非厄米系统的行为，并寻找实验测量非厄米量子度量的方法。

Method: 通过分析非厄米系统中的绝热势和周期非厄米系统中Wannier态的局域化行为，建立量子几何框架；提出通过时间周期调制来探测系统响应，其中非厄米量子度量会显现；通过具体示例系统的数值模拟验证理论结果。

Result: 发现非厄米系统的行为可以通过量子几何概念得到最佳理解；证明了非厄米量子度量在系统对时间周期调制的响应中出现，这为实验测量非厄米量子度量提供了可行方案；数值模拟验证了理论预测的有效性。

Conclusion: 量子几何为非厄米系统提供了重要的理论框架，非厄米量子度量可以通过实验测量，这为理解和表征非厄米系统的几何特性开辟了新途径。

Abstract: We explore the relation between quantum geometry in non-Hermitian systems and physically measurable phenomena. We highlight various situations in which the behavior of a non-Hermitian system is best understood in terms of quantum geometry, namely the notion of adiabatic potentials in non-Hermitian systems and the localization of Wannier states in periodic non-Hermitian systems. Further, we show that the non-Hermitian quantum metric appears in the response of the system upon time-periodic modulation, which one can use to experimentally measure the non-Hermitian quantum metric. We validate our results by providing numerical simulations of concrete exemplary systems.

</details>


### [59] [Simulating general noise nearly as cheaply as Pauli noise](https://arxiv.org/abs/2512.07304)
*Mark Myers,Mariesa H. Teo,Rajesh Mishra,Jing Hao Chai,Hui Khoon Ng*

Main category: quant-ph

TL;DR: 通过分层重要性采样，在稳定子形式中高效模拟一般噪声（包括相干误差），显著改进传统方法


<details>
  <summary>Details</summary>
Motivation: 传统稳定子模拟只能处理泡利型噪声，但实际设备噪声通常是非泡利的，包括相干误差可能对电路性能产生更严重影响

Method: 采用分层重要性采样方法，在稳定子形式框架内模拟一般噪声，非酉噪声模拟成本接近泡利噪声，酉噪声（相干误差）模拟时间增加但仍在合理范围内

Result: 成功实现了对一般噪声的高效模拟，非酉噪声模拟成本接近泡利噪声，酉噪声模拟时间增加一个数量级但仍在合理范围内，显著优于传统方法

Conclusion: 该方法使得在稳定子形式中详细研究超越泡利噪声的电路性能成为可能，为理解真实设备噪声对电路性能的影响提供了有力工具

Abstract: Stabilizer simulation of Clifford quantum circuits - error-correction circuits, Clifford subroutines, etc. - on classical computers has played a central role in our understanding of circuit performance. The stabilizer description, however, restricts the accessible noise one can incorporate into the simulation to Pauli-type noise. More general noise, including coherent errors, may have more severe impact on circuit performance than Pauli noise; yet, such general noise have been difficult to access, much less investigate fully, in numerical simulations. Here, through the use of stratified importance sampling, we show how general noise can be simulated within the stabilizer formalism in reasonable time, with non-unitary noise being nearly as cheap as Pauli noise. Unitary (or coherent) noise can require an order of magnitude more time for the simulation, but nevertheless completes in very reasonable times, a drastic improvement over past approaches that typically fail to converge altogether. Our work thus enables detailed beyond-Pauli understanding of circuit performance in the presence of real device noise, which is rarely Pauli in nature. Among other examples, we present direct simulation results for the performance of the popular rotated planar surface codes under circuit-level general noise, previously available only in limited situations and/or through mappings to efficiently simulatable physical models.

</details>


### [60] [Single-cell identification with quantum-enhanced nuclear magnetic resonance](https://arxiv.org/abs/2512.07307)
*Zhiyuan Zhao,Qian Shi,Shaoyi Xu,Xiangyu Ye,Mengze Shen,Jia Su,Ya Wang,Tianyu Xie,Qingsong Hu,Fazhan Shi,Jiangfeng Du*

Main category: quant-ph

TL;DR: 该研究提出了一种基于量子增强NMR和金刚石氮空位中心的单细胞识别方法，通过检测细胞内质子信号实现无标记细胞区分。


<details>
  <summary>Details</summary>
Motivation: 传统标记分选方法（如荧光激活细胞分选和磁激活细胞分选）在缺乏明确标记物或对标记敏感的细胞中应用受限，因为标记可能损害细胞活性和功能。需要开发无标记的细胞识别技术。

Method: 采用量子增强核磁共振技术，利用金刚石氮空位中心检测细胞内质子（¹H）信号，通过测量质子自旋-晶格（T₁）弛豫时间来区分不同细胞系。

Result: 成功区分了两种人类肿瘤细胞系，利用其质子T₁弛豫时间作为细胞固有的物理化学特征，实现了无标记细胞识别。

Conclusion: 该方法为无标记细胞分选在稀有细胞分析、个性化医疗和单细胞诊断中的应用奠定了基础。

Abstract: Identification of individual cells within heterogeneous populations is essential for biomedical research and clinical diagnostics. Conventional labeling-based sorting methods, such as fluorescence-activated cell sorting and magnetic-activated cell sorting, enable precise sorting when reliable markers are available. However, their applicability is limited in cells lacking defined markers or sensitive to labeling, as labeling can compromise cellular viability and function. We present a single-cell identification approach using quantum-enhanced NMR with diamond nitrogen-vacancy centers for label-free detection of intracellular proton ($^1$H) signals. Using this method, we distinguish two human tumor cell lines by their proton spin-lattice ($T_1$) relaxation times, which serve as a cell-intrinsic physicochemical signature. It lays the groundwork for label-free sorting applications in rare cell analysis, personalized medicine, and single-cell diagnostics.

</details>


### [61] [Revisiting Quantum Supremacy: Simulating Sycamore-Class Circuits Using Hybrid CPU/GPU HPC Workloads](https://arxiv.org/abs/2512.07311)
*Bob Wold,Venkateswaran Kasirajan*

Main category: quant-ph

TL;DR: 提出一个框架，利用高性能计算基础设施有效模拟原本用于展示量子霸权的量子电路，在53比特Sycamore电路上实现了超越谷歌量子处理器的性能表现。


<details>
  <summary>Details</summary>
Motivation: 量子霸权声称量子计算机在特定任务上超越经典计算机，但这一界限是动态的。本研究旨在展示利用现有高性能计算资源可以模拟原本被认为需要量子计算机才能高效执行的任务，挑战量子霸权的固定观念。

Method: 开发了一个混合计算框架：使用单个NVIDIA A100 GPU进行量子态构建，然后通过N个并行CPU作业进行分布式测量采样。该方法结合了GPU的高效计算和CPU的分布式处理能力。

Result: 成功模拟了53比特、14周期的Sycamore电路，获得线性交叉熵基准分数0.549，远超谷歌参考数据的0.002。在更复杂的53比特、20周期电路上，使用100个CPU作业在1小时15分钟内完成250万次采样，相比谷歌原始经典估计加速了6.95×10^7倍。如果使用1000个CPU作业，预计时间仅比原始量子实验慢12分钟。

Conclusion: 量子霸权不是固定不变的，而是持续移动的目标。混合经典-量子策略可能比以往认为的具有更广泛的近期量子实用性，经典计算方法仍能通过优化不断挑战量子优势的界限。

Abstract: We present a framework for effectively simulating the execution of quantum circuits originally designed to demonstrate quantum supremacy using accessible high-performance computing (HPC) infrastructure. Building on prior CPU-only approaches, our pipeline combines a single NVIDIA A100 GPU for quantum state construction, followed by N parallel CPU jobs that perform distributed measurement sampling. We validate the fidelity by simulating the 53-qubit, 14-cycle Sycamore circuit and achieving a linear cross-entropy benchmarking (XEB) score of 0.549, exceeding the published XEB score of 0.002 from Google's reference data. We then evaluate execution time performance with the more complex 53-qubit, 20-cycle circuit, completing the full 2.5 million-shot workload over 100 CPU jobs in 01:15:36, representing a 6.95 x 10^7 speedup compared to Google's original classical estimate. Further, we show that if 1,000 CPU jobs were employed, the estimated duration would be approximately 00:17:35, only 12 minutes slower than the time taken by the original QPU-based experiment. These results illustrate that 'quantum supremacy' is not fixed and continues to be a moving target. In addition, hybrid classical-quantum strategies may provide broader near-term quantum utility than once thought.

</details>


### [62] [33 Gbit/s source-device-independent quantum random number generator based on heterodyne detection with real-time FPGA-integrated extraction](https://arxiv.org/abs/2512.07319)
*Marius Cizauskas,Hamid Tebyanian,Mark Fox,Manfred Bayer,Marc Assmann,Alex Greilich*

Main category: quant-ph

TL;DR: 基于真空涨落外差检测的高速连续变量量子随机数发生器，采用源设备无关安全模型，通过FPGA实时处理实现33.92 Gbit/s的持续生成速率。


<details>
  <summary>Details</summary>
Motivation: 开发高速、安全的量子随机数发生器，满足量子通信和密钥分发系统对高质量随机数的需求。传统QRNG可能受到源端攻击，需要更安全的源设备无关模型。

Method: 采用真空涨落外差检测技术，使用90°光学混合器将光场分成两路，由平衡光电二极管同时测量真空态的两个正交分量。使用双通道12位ADC以3.2 GS/s采样率数字化，FPGA实时实现Toeplitz哈希进行随机性提取。

Result: 系统在1.6 GHz检测带宽内确认了真空噪声主导，通过功率谱密度测量和时域交叉验证。提取后实现33.92 Gbit/s的持续生成速率，所有随机比特通过NIST和Dieharder统计测试。

Conclusion: 该平台提供了一个紧凑的、基于FPGA的实用外差连续变量源无关QRNG实现，适用于高速量子通信和安全密钥分发系统，具有源设备无关的安全优势。

Abstract: We present a high-speed continuous-variable quantum random number generator (QRNG) based on heterodyne detection of vacuum fluctuations. The scheme follows a source-device-independent (SDI) security model in which the entropy originates from quantum measurement uncertainty and no model of the source is required; security depends only on the trusted measurement device and the calibrated discretization, and thus remains valid even under adversarial state preparation. The optical field is split by a 90$^\circ$ optical hybrid and measured by two balanced photodiodes to obtain both quadratures of the vacuum state simultaneously. The analog outputs are digitized using a dual-channel 12-bit analog-to-digital converter operating at a sampling rate of 3.2 GS/s per channel, and processed in real time by an FPGA implementing Toeplitz hashing for randomness extraction. The quantum-to-classical noise ratio was verified through calibrated power spectral density measurements and cross-checked in the time domain, confirming vacuum-noise dominance within the 1.6 GHz detection bandwidth. After extraction, the system achieves a sustained generation rate of $R_{\rm net}= 33.92~\mathrm{Gbit/s}$ of uniformly distributed random bits, which pass all NIST and Dieharder statistical tests. The demonstrated platform provides a compact, FPGA-based realization of a practical heterodyne continuous-variable source-independent QRNG suitable for high-rate quantum communication and secure key distribution systems.

</details>


### [63] [Tunable Dynamics of a Dipolar Quantum Battery: Role of Spin-Spin Interactions and Coherence](https://arxiv.org/abs/2512.07325)
*J. Ramya Parkavi,R. Muthuganesan,V. K. Chandrasekar*

Main category: quant-ph

TL;DR: 该研究探索了具有Dzyaloshinskii-Moriya相互作用的偶极自旋系统量子电池的能量存储动力学，分析外部参数对充电行为和量子资源的影响，发现量子相干性和DM相互作用能显著提升量子电池性能。


<details>
  <summary>Details</summary>
Motivation: 研究量子电池的能量存储性能，探索如何通过量子相干性和DM相互作用来提升量子能量存储设备的效率和功率输出，为设计高性能量子能量存储设备提供策略。

Method: 使用具有Dzyaloshinskii-Moriya相互作用的偶极自旋系统作为量子电池模型，采用双量子比特模型，通过求解系统在循环幺正过程下的时间演化，分析温度、磁场和DM相互作用等外部参数的影响。

Result: 量子相干性和DM相互作用显著增强了量子电池的能量存储效率和功率输出；在共同退相干环境影响下，偶极量子电池的长期功提取能力受到限制。

Conclusion: 量子相干性和DM相互作用是提升量子电池性能的关键因素，为设计高性能量子能量存储设备提供了有前景的策略，但需要注意退相干环境对长期性能的限制。

Abstract: This study explores the energy storage dynamics of a quantum battery (QB) modeled using a dipolar spin system with Dzyaloshinskii-Moriya (DM) interaction. We examine the performance of this system in terms of ergotropy, instantaneous power, capacity, and quantum coherence using a two-qubit model. By solving the system's time evolution under cyclic unitary processes, we analyze how external parameters such as temperature, magnetic field, and DM interaction influence the charging behavior and quantum resources of the battery. The findings demonstrate that quantum coherence and DM interaction significantly enhance the energy storage efficiency and power output of the quantum battery, offering promising strategies for designing high-performance quantum energy storage devices. Furthermore, we investigate the performance of quantum battery under the influence of a common dephasing environment, which limits the long-term work-extraction capability of dipolar quantum batteries.

</details>


### [64] [Dispersive readout with two orthogonal modes of a dielectric cavity](https://arxiv.org/abs/2512.07356)
*A. M. Kozodaev,I. S. Cojocaru,S. M. Drofa,P. G. Vilyuzhanina,A. Chernyavskiy,V. G. Vins,A. N. Smolyaninov,S. Ya. Kilin,S. V. Bolshedvorskii,V. V. Soshenko,A. V. Akimov*

Main category: quant-ph

TL;DR: 提出基于金刚石氮空位色心的双通道色散读出方案，显著提升磁力计灵敏度


<details>
  <summary>Details</summary>
Motivation: 传统NV中心磁力计主要采用光探测磁共振技术，近期有研究提出使用介电腔的色散读出方法来增强灵敏度，但仍有改进空间

Method: 采用双通道色散读出方案，相比单通道方案进行改进，利用金刚石氮空位色心作为磁敏感元件

Result: 双通道色散读出方案相比单通道方案能显著提升磁力计的灵敏度

Conclusion: 双通道色散读出方案是提升基于NV中心的磁力计灵敏度的有效改进方法

Abstract: Nitrogen-vacancy color centers in diamond have proven themselves as a good, sensitive element for the measurement of magnetic fields. While the mainstream of magnetometers based on NV centers uses so-called optically detected magnetic resonance, there has recently been a suggestion to use dispersive readout of a dielectric cavity to enhance the sensitivity of magnetometers. Here, we demonstrate that the dispersive readout approach can be significantly improved if a two-channel scheme is considered.

</details>


### [65] [Intrinsic non-Markovian magnetisation dynamics](https://arxiv.org/abs/2512.07378)
*Felix Hartmann,Vivek Unikandanunni,Matias Bargheer,Eric E. Fullerton,Stefano Bonetti,Janet Anders*

Main category: quant-ph

TL;DR: 在钴晶体中首次观测到非马尔可夫动力学，通过太赫兹电磁场驱动磁化并测量响应，发现多峰谱结构，用开放量子系统理论成功解释


<details>
  <summary>Details</summary>
Motivation: 非马尔可夫动力学在复杂系统中普遍存在，但在基础物理系统中仅限于特定设计案例。本研究旨在探索元素材料中是否存在非马尔可夫效应

Method: 使用强太赫兹电磁场驱动钴晶体磁化进入非平衡态，测量低温磁响应时域信号，通过傅里叶变换得到频谱，采用开放量子系统理论建立非马尔可夫记忆核模型

Result: 观测到意外的多峰频谱结构，传统模型无法解释；基于非马尔可夫记忆核的模拟成功复现测量谱，并能解释高温下谱的变化

Conclusion: 非马尔可夫效应在比预期更基础的层面可观测，为在凝聚态系统中探索和控制这类效应开辟了新途径

Abstract: Memory effects arise in many complex systems, from protein folding, to the spreading of epidemics and financial decisions. While so-called non-Markovian dynamics is common in larger systems with interacting components, observations in fundamental physical systems have been confined to specifically engineered cases. Here, we report the experimental observation of non-Markovian dynamics in an elemental material, crystalline cobalt. By driving this material with an intense terahertz electromagnetic field, we bring its magnetisation into a non-equilibrium state and follow its evolution. We measure the sample's low temperature magnetic response in the time domain which leads to an unexpectedly rich multi-peaked spectrum in the Fourier domain, that cannot be explained by established models. We use open quantum system theory, which predicts a non-Markovian memory kernel in the dynamical equations to capture the fundamental interaction between the spin system and the phonon bath. Simulations based on this theory produce a multi-peaked spectrum, which matches the measured one. Our non-Markovian approach is also able to reproduce the modification of the spectrum at higher temperatures. Our findings demonstrate that non-Markovian effects are observable at a much more fundamental level than previously thought, opening the door to their exploration and control in a broad range of condensed matter systems.

</details>


### [66] [Resonator-assisted single-photon frequency convertion in a conventional waveguide with a giant V-type atom](https://arxiv.org/abs/2512.07455)
*Ge Sun,Hongzheng Wu,Jing Lu,Lan Zhou*

Main category: quant-ph

TL;DR: 提出一种利用V型巨原子量子干涉实现单光子频率转换的方案，通过谐振器中的光子数调控转换效率和单向传输特性


<details>
  <summary>Details</summary>
Motivation: 传统波导中单光子频率转换效率有限，需要开发基于量子干涉效应的新方案来提升转换效率和可控性

Method: 利用V型巨原子与谐振器耦合产生的量子干涉效应，通过调节两个耦合点距离和单光子跃迁路径，实现频率转换

Result: 在马尔可夫和非马尔可夫区域研究了散射谱和转换对比度，发现光子数n能诱导非互易传输，增强转换概率

Conclusion: 该方案通过量子干涉和光子数调控实现了高效的单光子频率转换，为非互易量子器件设计提供了新思路

Abstract: We propose a scheme to achieve efficient frequency conversion for a single photon propagating in a 1D conventional waveguide by exploiting the quantum interference induced by the scale of a V-type giant atom (GA) characterized by the distance between the two coupling points as well as single-photon transition pathways originated from the coupling between the GA and the resonator. The presence of photons in the resonator triggers the frequency conversion of photons. The scattering spectra and the conversion contrast are studied in both the Markovian and the non-Markovian regimes. The disappearance of frequency conversion is rooted in the complete suppression of the emission from the excited state to either of lower states in the $n+1$ subspace where $n$ is the photon number of the resonator, and the non-Markovicity-induced nonreciprocity is found under specific conditions. Altering the photon number $n$ induces the non-reciprocal transmission of single photons in the waveguide, hence, enhance the conversion probability.

</details>


### [67] [On the emergence of preferred structures in quantum theory](https://arxiv.org/abs/2512.07468)
*Antoine Soulas,Guilherme Franzmann,Andrea Di Biagio*

Main category: quant-ph

TL;DR: 论文评估希尔伯特空间基本主义，研究哈密顿量是否能唯一确定张量积结构，调和了两个看似冲突的定理，并提出用哈密顿量和态来唯一选择张量积结构的方法。


<details>
  <summary>Details</summary>
Motivation: 探讨希尔伯特空间基本主义的可能性，即所有物理结构（子系统、局域性、时空、首选可观测量）都应从最小量子成分（希尔伯特空间、哈密顿量、态）中涌现。特别关注哈密顿量是否能唯一确定张量积结构这一量子部分学关键问题。

Method: 1. 回顾、澄清并批判性检验Cotler等人和Stoica的两个看似冲突的定理；2. 调和两者的紧张关系，指出前者的广泛误解和后者的局限性；3. 提出解决量子理论中首选结构问题的正确数学方法，基于酉不变性质来表征涌现对象；4. 将该形式应用于张量积结构问题。

Result: 1. 解决了两个定理之间的紧张关系，表明Cotler等人的定理被广泛误解，而Stoica的定理只在较弱版本中正确；2. 建立了处理量子理论中首选结构问题的正确数学框架；3. 证明哈密顿量和态足以唯一选择首选张量积结构。

Conclusion: 论文成功调和了关于哈密顿量确定张量积结构的两个冲突结果，提出了基于酉不变性质的数学框架，并证明哈密顿量和态的组合能够唯一确定张量积结构，为希尔伯特空间基本主义提供了有力支持。

Abstract: We assess the possibilities offered by Hilbert space fundamentalism, an attitude towards quantum physics according to which all physical structures (e.g. subsystems, locality, spacetime, preferred observables) should emerge from minimal quantum ingredients (typically a Hilbert space, Hamiltonian, and state). As a case study, we first mainly focus on the specific question of whether the Hamiltonian can uniquely determine a tensor product structure, a crucial challenge in the growing field of quantum mereology. The present paper reviews, clarifies, and critically examines two apparently conflicting theorems by Cotler et al. and Stoica. We resolve the tension, show how the former has been widely misinterpreted and why the latter is correct only in some weaker version. We then propose a correct mathematical way to address the general problem of preferred structures in quantum theory, relative to the characterization of emergent objects by unitary-invariant properties. Finally, we apply this formalism in the particular case we started with, and show that a Hamiltonian and a state are enough structure to uniquely select a preferred tensor product structure.

</details>


### [68] [RuleSet Generation Framework for Application Layer Integration in Quantum Internet](https://arxiv.org/abs/2512.07475)
*Rei Kawano,Shin Nishio,Hideaki Kawaguchi,Shota Nagayama,Takahiko Satoh*

Main category: quant-ph

TL;DR: 提出了基于RuleSet的量子互联网应用层框架，将用户请求转换为可执行的量子网络操作，实现从应用层到物理层的透明集成


<details>
  <summary>Details</summary>
Motivation: 量子互联网的底层技术（如纠缠生成和分发）已得到广泛研究，但应用层（负责将用户请求转换为可执行的量子网络操作）仍未被充分探索。主要挑战在于如何将应用级请求转换为底层可执行的具体指令

Method: 引入基于RuleSet的框架，将应用层明确纳入量子互联网的分层架构。该框架建立在RuleSet协议基础上，通过将应用规范嵌入RuleSets来澄清通信流程、组织应用请求信息，并引入新的应用执行规则。通过从生成的RuleSets构建状态机来评估可行性

Result: 该框架实现了从应用层到物理层的透明集成，降低了在量子互联网上部署新应用的门槛

Conclusion: 基于RuleSet的框架成功将应用层整合到量子互联网的分层架构中，通过明确通信流程和嵌入应用规范，为量子互联网的应用开发提供了系统化方法

Abstract: Layered architectures for the Quantum Internet have been proposed, inspired by that of the classical Internet, which has demonstrated high maintainability even in large-scale systems. While lower layers in the Quantum Internet, such as entanglement generation and distribution, have been extensively studied, the application layer - responsible for translating user requests into executable quantum-network operations - remains largely unexplored. A significant challenge is translating application-level requests into the concrete instructions executable at lower layers. In this work, we introduce a RuleSet-based framework that explicitly incorporates the application layer into the layered architecture of the Quantum Internet. Our framework builds on a RuleSet-based protocol, clarifying communication procedures, organizing application request information, and introducing new Rules for application execution by embedding application specifications into RuleSets. To evaluate feasibility, we constructed state machines from the generated RuleSets. This approach enables a transparent integration from the application layer down to the physical layer, thereby lowering barriers to deploying new applications on the Quantum Internet.

</details>


### [69] [Mediated Transmission of Quantum Synchronization in Star Networks](https://arxiv.org/abs/2512.07496)
*Shuo Dai,Ran Qi*

Main category: quant-ph

TL;DR: 量子星形网络中通过中间节点实现远程同步与准爆炸同步，揭示了经典系统中不存在的量子同步传输新特性


<details>
  <summary>Details</summary>
Motivation: 研究量子星形网络中通过中间节点介导的同步传输现象，探索量子系统中远程同步和爆炸同步的新特性，这些特性在经典对应系统中不存在

Method: 构建由spin-1振荡器组成的星形网络，分析相同和非相同振荡器在不同耦合机制下的行为，研究对称和非对称耗散对同步传输的影响

Result: 相同振荡器中，对称和非对称耗散导致不同传输行为：远程同步和准爆炸同步出现在不同耦合区域；非相同网络中，大失谐下弱耦合出现远程同步，强耦合演变为准爆炸同步

Conclusion: 量子介导同步展现出丰富的动力学特性，为探索更大更复杂量子系统中的同步传输提供了新可能性

Abstract: Synchronization transmission describes the emergence of coherence between two uncoupled oscillators mediated by their mutual coupling to an intermediate one. In classical star networks, such mediated coupling gives rise to remote synchronization--where nonadjacent leaf nodes synchronize through a nonsynchronous hub--and to explosive synchronization, characterized by an abrupt collective transition to coherence. In the quantum regime, analogous effects can arise from the interplay between 1:1 phase locking and 2:1 phase-locking blockade in coupled spin-1 oscillators. In this work, we investigate a star network composed of spin-1 oscillators. For identical oscillators, symmetric and asymmetric dissipation lead to distinct transmission behaviors: remote synchronization and quasi-explosive synchronization appear in different coupling regimes, a phenomenon absent in classical counterparts. For nonidentical networks, we find that at large detuning remote synchronization emerges in the weak-coupling regime and evolves into quasi-explosive synchronization as the coupling increases, consistent with classical star-network dynamics. These findings reveal the rich dynamical characteristics of mediated quantum synchronization and point toward new possibilities for exploring synchronization transmission in larger and more complex quantum systems.

</details>


### [70] [Exponentially accelerated relaxation and quantum Mpemba effect in open quantum systems](https://arxiv.org/abs/2512.07561)
*Emerson Lima Caldas,Diego Paiva Pires*

Main category: quant-ph

TL;DR: 该论文研究了开放量子系统中的量子姆潘巴效应，提出了一种基于置换矩阵的酉变换协议，能够加速系统向稳态的弛豫过程，实现真正的量子姆潘巴效应。


<details>
  <summary>Details</summary>
Motivation: 研究开放量子系统中的量子姆潘巴效应，即初始状态离平衡态更远的系统反而比离平衡态更近的系统更快弛豫到稳态的现象。旨在为量子系统提供一种通用的加速弛豫框架。

Method: 提出基于置换矩阵的酉变换协议，作用于系统初始状态：(1)抑制非幺正动力学中最慢衰减模式的贡献；(2)确保初始状态与稳态尽可能可区分。证明对于任何初始状态，总存在置换矩阵能在给定信息论可区分度量下最大化其与平衡态的距离。

Result: 该协议实现了真正的量子姆潘巴效应，数值模拟计算量低。在横向场伊辛链和XXZ链的非幺正动力学中展示了量子姆潘巴效应，通过希尔伯特-施密特距离、量子相对熵和迹距离等度量捕获。

Conclusion: 研究结果为开放量子系统中的真正量子姆潘巴效应提供了一个通用且多功能的工程框架，能够指数加速系统向稳态的收敛。

Abstract: We investigate the quantum Mpemba effect in the relaxation of open quantum systems whose effective dynamics is described by Davies maps. We present a class of unitary transformations based on permutation matrices that, acting on the initial state of the system, (i) suppress the contribution of slowest decaying modes of the nonunitary dynamics; (ii) ensure that it is as distinguishable as possible from the steady state. The first requirement guarantees an exponentially accelerating convergence to the steady state, while the second implies that a quantum system initially farther from equilibrium approaches it more rapidly than an initial state closer to it. This protocol provides a genuine Mpemba effect, and its numerical simulation requires low computational effort. We prove that, for any initial state, there always exists a permutation matrix that maximizes its distance from the equilibrium for a given information-theoretic distinguishability measure. We illustrate our findings for the nonunitary dynamics of the transverse field Ising chain and XXZ chain, each weakly coupled to a bosonic thermal bath, showing the quantum Mpemba effect captured by the Hilbert-Schmidt distance, quantum relative entropy, and trace distance. Our results provide a universal and versatile framework to engineer the genuine quantum Mpemba effect in open quantum systems.

</details>


### [71] [Uniform relativistic motion through a thermal bath as a thermodynamic resource](https://arxiv.org/abs/2512.07567)
*Rahul Shastri*

Main category: quant-ph

TL;DR: 量子系统在热浴中以相对论速度运动时，即使没有外部驱动或多个热浴，也会进入非平衡稳态，这源于相对运动破坏了细致平衡。


<details>
  <summary>Details</summary>
Motivation: 研究量子系统在相对论运动下与热浴的相互作用，探索相对运动如何破坏热平衡并产生非平衡稳态。

Method: 分析量子系统在质量为零的标量场热浴中以均匀相对论速度运动的情况，研究其稳态行为。

Result: 发现两类非平衡稳态：1) 具有持续概率流的NESS；2) 无电流的非吉布斯稳态，具有频率依赖的有效逆温度。

Conclusion: 具有概率流的NESS可作为噪声随机时钟，而无电流的非吉布斯稳态具有非零非平衡自由能，可作为量子电池用于功的提取或存储。

Abstract: We show that a quantum system undergoing motion with uniform relativistic velocity through a thermal bath consisting of a massless scalar field is generically driven into a non-equilibrium steady-state (NESS) solely due to its motion, even in the absence of external driving or multiple baths. The relative motion between the system and the bath breaks detailed balance, preventing thermalization to a Gibbs state. We find that the resulting steady-states fall into two distinct classes: (i) NESSs with persistent probability currents, and (ii) current-free non-Gibbs steady states characterized by a frequency-dependent effective inverse temperature. We demonstrate, using a three-level system, that NESSs with probability current can function as noisy stochastic clock, while current-free non-Gibbs steady states possess non-zero non-equilibrium free energy, indicating their potential as a quantum battery for work extraction or storage.

</details>


### [72] [On-Demand Microwave Single-Photon Source Based on Tantalum Thin Film](https://arxiv.org/abs/2512.07589)
*Ying Hu,Sheng-Yong Li,En-Qi Chen,Jing Zhang,Yu-xi Liu,Jia-Gui Feng,Zhihui Peng*

Main category: quant-ph

TL;DR: 本文展示了一种基于钽薄膜的微波单光子源，利用钽的优良材料特性实现高质量稳定的光子发射，并通过二阶相关测量验证了反聚束行为，同时使用行波参量放大器作为前置放大器显著提高了信噪比和测量效率。


<details>
  <summary>Details</summary>
Motivation: 单光子源是量子信息技术的关键组件。本文旨在开发一种基于钽超导器件的可靠微波单光子源平台，利用钽的优良材料特性实现高质量稳定的光子发射。

Method: 使用钽基薄膜制造微波单光子源，通过二阶相关测量验证光子发射的反聚束行为。在检测链中使用行波参量放大器作为前置放大器，显著提高信噪比。

Result: 成功实现了基于钽薄膜的微波单光子源，观察到明显的反聚束行为。使用行波参量放大器后，信噪比大幅提升，二阶相关测量的采集时间显著减少。

Conclusion: 钽基超导器件是微波量子光子学的可靠平台，其优良的材料特性能够支持高质量的单光子发射，结合先进的检测技术可以实现高效的量子光子测量。

Abstract: Single-photon sources are crucial for quantum information technologies. Here, we demonstrate a microwave single-photon source fabricated using a tantalum-based thin film, whose favorable material properties enable high-quality and stable photon emission. The antibunching behavior of the emitted radiation is revealed by second-order correlation measurements. Furthermore, traveling-wave parametric amplifiers are used as the pre-amplifier in the detection chains, we substantially improve the signal-to-noise ratio and thereby greatly reduce the acquisition time required for second-order correlation measurements. These results demonstrate the viability of tantalum-based superconducting devices as reliable platforms for microwave quantum photonics.

</details>


### [73] [Sharp values for all dynamical variables via Anti-Wick quantization](https://arxiv.org/abs/2512.07616)
*Simon Friederich*

Main category: quant-ph

TL;DR: 该论文提出通过反Wick量子化将量子期望值解释为相空间上的加权平均，从而为量子测量问题提供一种经典概率解释


<details>
  <summary>Details</summary>
Motivation: 解决量子测量问题，弥合量子期望值与经典期望值之间的解释差异。量子期望值通常通过希尔伯特空间内积计算，而经典期望值则是相空间上的加权积分，两者解释方式不同。

Method: 使用反Wick量子化将动力学变量与自伴线性算子关联，在Segal-Bargmann空间中，量子期望值可解释为相空间上的加权平均。在此框架下，Husimi Q函数（量子态的相干态表示）可视为相空间中的真实概率密度。

Result: 量子期望值可被解释为相空间上的真正加权平均，与经典对应物平行。Husimi Q函数可作为相空间中的概率密度，提供了一种经典概率解释量子统计的途径。

Conclusion: 该方法保留了动力学变量与自伴算子的标准对应关系，同时为量子统计提供了类似经典的概率解释，与玻姆力学不同，为量子测量问题提供了新的解决思路。

Abstract: This paper proposes an approach to interpreting quantum expectation values that may help address the quantum measurement problem. Quantum expectation values are usually calculated via Hilbert space inner products and, thereby, differently from expectation values in classical mechanics, which are weighted phase-space integrals. It is shown that, by using Anti-Wick quantization to associate dynamical variables with self-adjoint linear operators, quantum expectation values can be interpreted as genuine weighted averages over phase space, paralleling their classical counterparts. This interpretation arises naturally in the Segal-Bargmann space, where creation and annihilation operators act as simple multiplication and differentiation operators. In this setting, the Husimi Q-function - the coherent-state representation of the quantum state - can be seen as a true probability density in phase space. Unlike Bohmian mechanics, the present approach retains the standard correspondence between dynamical variables and self-adjoint operators while paving the way for a classical-like probabilistic interpretation of quantum statistics.

</details>


### [74] [Quantum Diamond Microscopy for Non-Destructive Failure Analysis of an Integrated Fan-Out Package-on-Package iPhone Chip](https://arxiv.org/abs/2512.07619)
*Bartu Bisgin,Marwa Garsi,Andreas Welscher,Michael Hanke,Fleming Bruckmaier*

Main category: quant-ph

TL;DR: 量子钻石显微镜（QDM）作为非破坏性故障定位方法，通过磁电流路径成像在封装级别验证，显著提升先进半导体封装的故障分析能力。


<details>
  <summary>Details</summary>
Motivation: 先进半导体封装（如小芯片架构和2.5D/3D集成）的复杂性增加，挑战了传统故障定位方法（如锁相热成像），密集的再分布层和埋入式互连限制了非破坏性理解故障机制的能力。

Method: 使用基于金刚石中氮空位（NV）中心的量子钻石显微镜（QDM）进行非破坏性磁电流路径成像定位。采用iPhone的商业集成扇出型封装上封装（InFO-PoP）器件，展示完整的故障分析流程，包括使用QDM在封装背面定位集成无源器件（IPD）的短路故障。

Result: QDM结果提供了超越传统技术的宝贵信息，能显著增强封装级别故障分析流程中的根本原因识别。成功定位了IPD的短路故障，展示了QDM在半导体芯片和封装分析工作流程中的潜力。

Conclusion: 量子钻石显微镜（QDM）作为非破坏性故障定位方法具有巨大潜力，可更广泛地集成到半导体芯片和封装分析工作流程中，解决先进半导体封装的故障分析挑战。

Abstract: The increasing complexity of advanced semiconductor packages, driven by chiplet architectures and 2.5D/3D integration, challenges conventional failure localization methods such as lock-in thermography (LIT) and complicates current Failure Analysis (FA) workflows. Dense redistribution layers and buried interconnects limit the ability of established techniques to understand failure mechanisms non-destructively. In this work, we validate quantum diamond microscopy (QDM) based on nitrogen-vacancy (NV) centers in diamond as a non-destructive localization method through magnetic current path imaging at the package level. Using commercial Integrated Fan-Out Package-on- Package (InFO-PoP) devices from iPhones, we showcase a complete FA workflow that includes QDM to localize a short-type failure at an Integrated Passive Device (IPD) at the package backside. We showcase that the QDM results provide invaluable information on top of conventional techniques and can significantly enhance root-cause identification in package-level FA workflows. This work demonstrates the potential of QDM for broader integration into semiconductor chip and package analysis workflows.

</details>


### [75] [Enhanced charging power in nonreciprocal quantum battery by reservoir engineering](https://arxiv.org/abs/2512.07626)
*Qi-Yin Lin,Guang-Zheng Ye,Can Li,Wan-Jun Su,Huai-Zhi Wu*

Main category: quant-ph

TL;DR: 提出在非厄米系统中实现非互易量子电池的方案，利用环境耗散抑制反向能量传输，在共振条件下实现电池能量与充电器能量4:1的比例，并在异常点操作时表现出更好的参数波动鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 克服量子电池系统中的固有耗散和反向能量流限制，利用非厄米系统的特性实现非互易能量传输，为开放量子系统中的定向能量转移、可控耗散和熵管理提供新方法。

Method: 设计包含充电器和电池的系统，两者相干耦合并共同与坏腔相互作用。通过引入辅助坏腔并利用非互易条件，利用环境耗散抑制反向能量转移。在共振条件下优化阻尼参数，实现高效率的短时充电功率。

Result: 在共振条件下实现了电池能量与充电器能量4:1的比例；通过阻尼优化获得了高效率的短时充电功率；与完全非互易方案相比，在异常点操作的量子电池对参数波动表现出更强的鲁棒性。

Conclusion: 非厄米量子工程在推进量子电池技术方面具有巨大潜力，特别是在涉及定向能量转移、可控耗散和开放量子系统熵管理的领域，为克服传统量子电池的限制提供了新途径。

Abstract: We propose a scheme to achieve a nonreciprocal quantum battery (QB) in the non-Hermitian (NH) system, which can overcome the intrinsic dissipation and reverse flow constraints. The design is based on a charger and a battery, which are coherently coupled and jointly interact with a bad cavity. By introducing the auxiliary bad cavity and exploiting the nonreciprocal condition, this model can harness the environmental dissipation to suppress the reverse energy transfer. Under resonant conditions, we have achieved a four ratio of the battery energy to the charger energy; in contrast, this ratio is significantly reduced under large detuning. Through damping optimization, high efficiency of the short-time charging power is attained. In comparison to the fully nonreciprocal scheme, the QB operating at the exceptional point (EP) exhibits greater resilience to parameter fluctuations. These findings highlight the potential of NH quantum engineering for advancing QB technology, particularly in regimes involving directional energy transfer, controlled dissipation, and entropy management in open quantum systems.

</details>


### [76] [Single-Operation Rydberg Phase Gates via Dynamic Population Suppression](https://arxiv.org/abs/2512.07656)
*Sebastian C. Carrasco,Jabir Chathanathil,Svetlana A. Malinovskaya,Ignacio Sola,Vladimir S. Malinovsky*

Main category: quant-ph

TL;DR: 提出基于调制零脉冲面积场的通用控制协议，动态抑制里德堡激发同时保留里德堡-里德堡相互作用作为纠缠相位资源，实现单步完美纠缠相位门


<details>
  <summary>Details</summary>
Motivation: 传统里德堡阻塞量子逻辑在有限阻塞强度下存在误差，当拉比频率接近或超过相互作用能时性能受限，需要同时实现速度、保真度和鲁棒性的新操作机制

Method: 使用调制零脉冲面积场动态抑制里德堡激发，同时保留里德堡-里德堡相互作用作为纠缠相位资源，实现单步完美纠缠相位门

Result: 该方法消除了有限阻塞误差，即使拉比频率接近或超过相互作用能也能工作，为里德堡阻塞量子逻辑定义了新的操作机制，同时实现速度、保真度和鲁棒性

Conclusion: 该技术简单通用，兼容多种中性原子架构，为可扩展、高保真度的量子计算和模拟提供了有前景的途径

Abstract: We propose a versatile control protocol based on modulated zero-pulse-area fields that dynamically suppresses Rydberg excitation while retaining Rydberg-Rydberg interactions as an entangling phase resource. This mechanism enables single-step, perfectly entangling phase gates for arbitrary blockade strengths, eliminating finite-blockade errors even when the Rabi frequency approaches or exceeds the interaction energy. The approach defines a new operational regime for Rydberg-blockade quantum logic in which speed, fidelity, and robustness are achieved simultaneously within a simple dynamical framework. Owing to its simplicity and generality, the technique is compatible with a wide range of neutral-atom architectures and offers a promising route toward scalable, high-fidelity quantum computation and simulation.

</details>


### [77] [Brazilian Twin Photons 32nd anniversary](https://arxiv.org/abs/2512.07670)
*Renné Medeiros de Araújo,Raphael César Souza Pimenta,Lucas Marques Fagundes,Gustavo Henrique dos Santos,Nara Rubiano da Silva,Stephen Patrick Walborn,Paulo Henrique Souto Ribeiro*

Main category: quant-ph

TL;DR: 本文回顾了巴西自发参量下转换（SPDC）领域三十多年的发展历程，重点介绍了关键实验、研究机构和学者，展示了巴西量子光学社区如何将基础研究转化为量子应用。


<details>
  <summary>Details</summary>
Motivation: 记录巴西在自发参量下转换（SPDC）领域三十多年的发展历史，展示该国在量子光学领域的贡献和影响力，强调从基础研究到量子应用的转化过程。

Method: 采用历史回顾的方法，通过梳理关键实验、研究机构和学者的贡献，呈现巴西SPDC研究的发展脉络，包括空间关联、纠缠和退相干等基础研究。

Result: 展示了巴西在SPDC领域形成了强大的科学社区，通过一系列基础实验探索了量子力学的深刻概念，并在国际上产生了重要影响，同时正在将基础知识转化为量子应用。

Conclusion: 巴西的SPDC研究经过三十多年发展，已从基础实验成长为具有国际影响力的量子光学领域，形成了强大的科学社区，并正在向实际量子应用转化。

Abstract: We present a historical review of the development and impact of spontaneous parametric down-conversion (SPDC) in Brazil, marking over three decades since the first twin-photon experiments were performed in the country. This article traces the pioneering efforts that initiated the field, highlighting key experiments, institutions, and researchers who contributed to its growth. We discuss seminal works that established SPDC as a fundamental tool in the Brazilian Quantum Optics community, including studies on spatial correlations, entanglement, and decoherence. By presenting a curated sequence of experiments, we offer an overview of how Brazilian research in twin-photon systems has explored profound concepts through fundamental demonstrations, leading to significant international impact. This review also highlights the formation of a strong scientific community and its ongoing efforts to turn fundamental knowledge into quantum applications.

</details>


### [78] [A scalable and real-time neural decoder for topological quantum codes](https://arxiv.org/abs/2512.07737)
*Andrew W. Senior,Thomas Edlich,Francisco J. H. Heras,Lei M. Zhang,Oscar Higgott,James S. Spencer,Taylor Applebaum,Sam Blackwell,Justin Ledford,Akvilė Žemgulytė,Augustin Žídek,Noah Shutty,Andrew Cowie,Yin Li,George Holland,Peter Brooks,Charlie Beattie,Michael Newman,Alex Davies,Cody Jones,Sergio Boixo,Hartmut Neven,Pushmeet Kohli,Johannes Bausch*

Main category: quant-ph

TL;DR: AlphaQubit 2 是一种神经网络解码器，在真实噪声下对表面码和颜色码实现接近最优的逻辑错误率，速度比其他高精度解码器快几个数量级，支持实时解码。


<details>
  <summary>Details</summary>
Motivation: 容错量子计算需要远低于物理量子比特可实现的错误率，量子纠错（QEC）需要同时满足快速、准确和可扩展的解码器要求，但目前机器学习解码器或资源高效编码（如颜色码）的解码器尚未满足这些要求。

Method: 开发了AlphaQubit 2神经网络解码器，针对表面码和颜色码进行优化，能够在当前商用加速器上实现实时解码。

Result: 对颜色码比其他高精度解码器快几个数量级；对表面码在距离11时实现每周期小于1微秒的实时解码，准确率优于领先的实时解码器。

Conclusion: AlphaQubit 2支持更多有前景的QEC码的实际应用，为容错量子计算所需规模的高精度实时神经解码提供了可行路径。

Abstract: Fault-tolerant quantum computing will require error rates far below those achievable with physical qubits. Quantum error correction (QEC) bridges this gap, but depends on decoders being simultaneously fast, accurate, and scalable. This combination of requirements has not yet been met by a machine-learning decoder, nor by any decoder for promising resource-efficient codes such as the colour code. Here we introduce AlphaQubit 2, a neural-network decoder that achieves near-optimal logical error rates for both surface and colour codes at large scales under realistic noise. For the colour code, it is orders of magnitude faster than other high-accuracy decoders. For the surface code, we demonstrate real-time decoding faster than 1 microsecond per cycle up to distance 11 on current commercial accelerators with better accuracy than leading real-time decoders. These results support the practical application of a wider class of promising QEC codes, and establish a credible path towards high-accuracy, real-time neural decoding at the scales required for fault-tolerant quantum computation.

</details>


### [79] [Real-time collisions of fractional charges in a trapped-ion Jackiw-Rebbi field theory](https://arxiv.org/abs/2512.07748)
*Alan Kahan,Pablo Viñas,Torsten V. Zache,Alejandro Bermudez*

Main category: quant-ph

TL;DR: 提出并分析了一种基于囚禁离子的Jackiw-Rebbi模型量子模拟器，研究标量场孤子与费米子零模耦合系统中的背反应和量子涨落效应。


<details>
  <summary>Details</summary>
Motivation: 研究量子场论中孤子激发与费米子零模耦合系统的背反应和量子涨落效应，这些效应在传统理论中通常被忽略，但在实际物理系统中可能显著影响分数化激发的稳定性和动力学。

Method: 采用囚禁离子量子模拟器实现Jackiw-Rebbi模型：标量场由离子位移的锯齿形结构描述，费米子场由离子内部电子态编码。使用Born-Oppenheimer近似获得有效Peierls-Nabarro势，结合截断Wigner近似和费米子高斯态方法研究量子动力学。

Result: 费米子背反应可导致拓扑扭结的局域化，量子涨落影响扭结的量子扩散和扭结-反扭结散射。预测了在现有囚禁离子架构中可观测的实验信号。

Conclusion: 背反应和量子涨落显著改变分数化费米子的稳定性和实时演化，囚禁离子平台为研究量子场论中耦合系统的完整量子动力学提供了可行途径。

Abstract: We propose and analyze a trapped-ion quantum simulator of the Jackiw-Rebbi model, a paradigmatic quantum field theory in (1+1) dimensions where solitonic excitations of a scalar field can bind fermionic zero modes leading to fractionally charged excitations. In our approach, the scalar field is a coarse-grained description of the planar zigzag ion displacements in the vicinity of a structural phase transition. The internal electronic states of the ions encode spins with interactions mediated by the transverse phonons and in-plane spin-phonon couplings with a zigzag pattern, which together correspond to a Yukawa-coupled Dirac field. Instead of assuming a fixed soliton background, we study the effect of back-reaction and quantum fluctuations on the coupled dynamics of the full fermion-boson system. We start by applying a Born-Oppenheimer approximation to obtain an effective Peierls-Nabarro potential for the topological kink, unveiling how the fermionic back-reaction can lead to localization of the kink. Beyond this limit, a truncated Wigner approximation combined with fermionic Gaussian states captures the quantum spreading and localization of a kink and kink-antikink scattering. Our results reveal how back-reaction and quantum fluctuations modify the stability and real-time evolution of fractionalized fermions, predicting experimentally accessible signatures in current trapped-ion architectures.

</details>


### [80] [Statistical properties of quantum jumps between macroscopic states of light: reading an operational coherence record](https://arxiv.org/abs/2512.07754)
*Th. K. Mavrogordatos*

Main category: quant-ph

TL;DR: 提出一种实验装置，通过振幅双稳态的下跃迁量子跳跃揭示量子相干性，将宏观量子态的相干叠加转化为探测器电路中积分电荷的统计特性。


<details>
  <summary>Details</summary>
Motivation: 研究振幅双稳态系统中的量子相干现象，特别是下跃迁量子跳跃中宏观量子态的相干叠加特性，探索如何通过检测统计特性来揭示这些量子效应。

Method: 采用模式匹配的外差/零差检测方案，首先利用辅助腔传输信号的动态演化定位双稳态主腔中的宏观切换事件，然后让主腔模式自由衰减到真空态，监测产生的积分电荷分布。

Result: 在长时间极限下，跳跃过程中产生的纯态集合的电荷分布收敛于Q函数（外差检测）或Wigner函数的边缘分布（零差检测），统计特性与腔场关联相关，反映了光子阻塞的破坏。

Conclusion: 该实验装置能够揭示振幅双稳态下跃迁量子跳跃中的量子相干性，将宏观量子态的相干叠加转化为可观测的电荷统计特性，为研究光子阻塞破坏相关的腔场关联提供了新方法。

Abstract: We propose an experimental apparatus to reveal the quantum coherence manifested in downward quantum jumps of amplitude bistability. The underlying coherent superposition of macroscopic quantum states is translated into the statistical properties of the integrated charge deposited in the detector circuit of a mode-matched heterodyne/homodyne detection scheme. At first, the dynamical evolution of a signal transmitted from an auxiliary cavity is employed to pinpoint a macroscopic switching event in a bistable main cavity subject to direct photodetection. Once the decision is made on the occurrence of a downward switch, the main cavity mode is let to freely decay to the vacuum, monitored to the production of an integrated charge. In the long-time limit, the charge distribution over an identical collection of pure states generated during the jumps converges to the Q function (heterodyne detection) or marginals of the Wigner function (homodyne detection) dictated by the phase of the local oscillator. When fluctuations over the ensemble step in, we connect the statistical properties of several switching events and the ensuing production of current records, to the cavity field correlations associated with the breakdown of photon blockade.

</details>


### [81] [Strongly driven cavity quantum electrodynamical-optomechanical hybrid system](https://arxiv.org/abs/2512.07788)
*Xuxin Wang,Jiahe Pan,Tobias J. Kippenberg,Shingo Kono*

Main category: quant-ph

TL;DR: 提出并演示了一种利用强驱动混合系统（腔QED+腔光力学）生成非高斯机械态的方案，通过腔QED制备非高斯腔态，再利用光力学相互作用将其转移到机械振子。


<details>
  <summary>Details</summary>
Motivation: 混合量子系统结合不同物理平台的优势，但集成面临操作原理不兼容的挑战。腔QED中非高斯腔态控制已有基础，但在强腔驱动下的行为（对腔光力学至关重要）尚未充分探索。

Method: 在腔QED的色散区制备非高斯腔态，然后利用相干腔驱动增强的光力学相互作用将其转移到机械振子。开发了高效模拟框架来建模高光子数区域的腔QED动力学。

Result: 强腔驱动可以相干地位移腔态且扰动最小，有效地使其与量子比特解耦。产生的大相干腔场增强了光力学耦合强度，实现了非高斯腔态到机械模式的高保真度转移。

Conclusion: 揭示了驱动腔QED的新动力学特性，为实现非高斯机械量子存储器和传感器开辟了新途径。

Abstract: Hybrid quantum systems harness the distinct advantages of different physical platforms, yet their integration is not always trivial due to potential incompatibilities in operational principles. Here, we theoretically propose and demonstrate a scheme for generating non-Gaussian mechanical states using a strongly driven hybrid system that combines cavity quantum electrodynamics (QED) and cavity optomechanics. Our protocol prepares a non-Gaussian cavity state in the dispersive regime of cavity QED and subsequently transfers it to a mechanical oscillator using the optomechanical interaction enhanced by a coherent cavity drive. While non-Gaussian cavity state control in cavity QED is well established in the dispersive regime, its behavior under strong cavity drive, essential for cavity optomechanics, remains largely unexplored. To bridge this gap, we develop an efficient simulation framework to model cavity QED dynamics in the high-photon-number regime. We show that a strong cavity drive can coherently displace the cavity state with minimal perturbations, effectively decoupling it from the qubit. The resulting large coherent cavity field enhances the optomechanical coupling strength, enabling high-fidelity transfer of non-Gaussian cavity states to the mechanical mode. These results reveal new dynamical features of driven cavity QED and open a pathway toward realizing non-Gaussian mechanical quantum memories and sensors.

</details>


### [82] [LUNA: LUT-Based Neural Architecture for Fast and Low-Cost Qubit Readout](https://arxiv.org/abs/2512.07808)
*M. A. Farooq,G. Di Guglielmo,A. Rajagopala,N. Tran,V. A. Chhabria,A. Arora*

Main category: quant-ph

TL;DR: LUNA：基于查找表的神经网络加速器，用于超导量子比特读取，通过积分器预处理和LUT神经网络实现低延迟、低资源消耗的量子比特状态分类。


<details>
  <summary>Details</summary>
Motivation: 量子比特读取是量子计算中的关键操作，需要将模拟响应映射为离散经典状态。现有基于深度神经网络的读取方案硬件实现资源密集、推理延迟高，限制了其在低延迟解码和量子纠错循环中的实际应用。

Method: 提出LUNA架构：1）使用低成本积分器进行预处理和维度缩减；2）采用基于查找表的神经网络（LogicNets）进行分类；3）结合差分进化算法进行设计和优化探索。

Result: 相比现有最优方案，LUNA实现了10.95倍面积缩减和30%延迟降低，同时保持几乎无损的保真度。

Conclusion: LUNA实现了可扩展、低资源占用、高速的量子比特读取，支持构建更大规模、更可靠的量子计算系统。

Abstract: Qubit readout is a critical operation in quantum computing systems, which maps the analog response of qubits into discrete classical states. Deep neural networks (DNNs) have recently emerged as a promising solution to improve readout accuracy . Prior hardware implementations of DNN-based readout are resource-intensive and suffer from high inference latency, limiting their practical use in low-latency decoding and quantum error correction (QEC) loops. This paper proposes LUNA, a fast and efficient superconducting qubit readout accelerator that combines low-cost integrator-based preprocessing with Look-Up Table (LUT) based neural networks for classification. The architecture uses simple integrators for dimensionality reduction with minimal hardware overhead, and employs LogicNets (DNNs synthesized into LUT logic) to drastically reduce resource usage while enabling ultra-low-latency inference. We integrate this with a differential evolution based exploration and optimization framework to identify high-quality design points. Our results show up to a 10.95x reduction in area and 30% lower latency with little to no loss in fidelity compared to the state-of-the-art. LUNA enables scalable, low-footprint, and high-speed qubit readout, supporting the development of larger and more reliable quantum computing systems.

</details>


### [83] [Fast-feedback protocols for calibration and drift control in quantum computers](https://arxiv.org/abs/2512.07815)
*Alicia B. Magann,Nathan E. Miller,Robin Blume-Kohout,Peter Maunz,Kevin C. Young*

Main category: quant-ph

TL;DR: 提出两种基于快速反馈的轻量级自适应量子计算机校准协议，分别支持基于不确定结果电路的实时参数更新和基于确定结果电路的高效校准，并通过数值模拟验证了在退相干、SPAM误差和参数漂移情况下的有效性。


<details>
  <summary>Details</summary>
Motivation: 量子计算机需要频繁校准来维持性能，但传统校准方法耗时且无法实时应对参数漂移。需要开发轻量级、自适应的校准协议，能够利用快速反馈在量子计算过程中实时调整设备参数。

Method: 提出两种校准协议：1) 基于简单不确定结果量子电路的测量结果进行逐次参数更新，支持低延迟实时调谐；2) 基于确定结果电路（如量子纠错码的校验子提取电路）的测量结果进行参数更新，平衡效率与经典控制开销。两种方法都包含自适应超参数调优策略。

Result: 数值模拟表明，两种方法都能在存在退相干、状态制备和测量误差以及参数漂移的情况下，快速准确地校准1-和2-量子比特门。特别展示了仅使用校验子数据对[[5,1,3]]码进行实时原位量子纠错校准的可行性。

Conclusion: 提出的自适应校准协议为量子计算机提供了轻量级、高效的校准解决方案，能够实时应对参数漂移，特别适用于量子纠错等需要持续稳定操作的应用场景，为实现可靠的量子计算奠定了基础。

Abstract: We introduce two classes of lightweight, adaptive calibration protocols for quantum computers that leverage fast feedback. The first enables shot-by-shot updates to device parameters using measurement outcomes from simple, indefinite-outcome quantum circuits. This low-latency approach supports rapid tuning of one or more parameters in real time to mitigate drift. The second protocol updates parameters after collecting measurements from definite-outcome circuits (e.g.~syndrome extraction circuits for quantum error correction), balancing efficiency with classical control overheads. We use numerical simulations to demonstrate that both methods can calibrate 1- and 2-qubit gates rapidly and accurately even in the presence of decoherence, state preparation and measurement (SPAM) errors, and parameter drift. We propose and demonstrate effective adaptive strategies for tuning the hyperparameters of both protocols. Finally, we demonstrate the feasibility of real-time in-situ calibration of qubits performing quantum error correction, using only syndrome data, via numerical simulations of syndrome extraction in the [[5,1,3]] code.

</details>


### [84] [Comparing quantum channels using Hermitian-preserving trace-preserving linear maps: A physically meaningful approach](https://arxiv.org/abs/2512.07822)
*Arindam Mitra,Jatin Ghai*

Main category: quant-ph

TL;DR: 该论文提出了一种基于Hermitian保持迹保持线性映射的量子通道比较方法，建立了量子通道间的预序关系，并探讨了其对量子设备不兼容性的影响。


<details>
  <summary>Details</summary>
Motivation: 量子通道在传输量子态时通常会引入噪声，降低信息含量。需要一种物理上有意义的方法来比较不同量子通道的性能，特别是当两个通道的输出状态可以通过量子测量相互转换时。

Method: 使用Hermitian保持迹保持线性映射来比较量子通道对。证明如果一对量子通道中，一个通道的输出状态可以通过量子测量从另一个通道的输出统计中获得，那么后者可以通过前者与一个Hermitian保持迹保持线性映射的串联得到。

Result: 建立了量子通道间的预序关系，这种关系可以通过Hermitian保持迹保持线性映射来描述。通过示例说明了该结果对量子设备不兼容性的影响。

Conclusion: 提出了一种基于Hermitian保持迹保持映射的量子通道比较框架，为量子通道的性能评估和量子设备不兼容性分析提供了新的数学工具。

Abstract: In quantum technologies, quantum channels are essential elements for the transmission of quantum states. The action of a quantum channel usually introduces noise in the quantum state and thereby reduces the information contained in it. Concatenating a quantum channel with another quantum channel makes it more noisy and degrades its information and resource preservability. These are mathematically described by completely positive trace-preserving linear maps that represent the generic evolution of quantum systems. These are special cases of Hermitian-preserving trace-preserving linear maps. In this work, we demonstrate a physically meaningful way to compare a pair of quantum channels using Hermitian-preserving trace-preserving linear maps. More precisely, given a pair of quantum channels and an arbitrary unknown input state, we show that if the output state of one quantum channel from the pair can be obtained from the output statistics of the other channel from the pair using some quantum measurement, then the latter channel from the pair can be obtained from the former channel by concatenating it with a Hermitian-preserving trace-preserving linear map. This relation between these two channels is a preorder, and we try to study its characterization in this work. We also illustrate the implications of our results for the incompatibility of quantum devices through an example.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [85] [Physics Enhanced Deep Surrogates for the Phonon Boltzmann Transport Equation](https://arxiv.org/abs/2512.05976)
*Antonio Varagnolo,Giuseppe Romano,Raphaël Pestourie*

Main category: physics.comp-ph

TL;DR: 提出PEDS方法，结合可微分傅里叶求解器和神经网络，通过物理增强的深度学习代理模型，显著降低纳米尺度热材料设计中的计算成本和数据需求。


<details>
  <summary>Details</summary>
Motivation: 纳米尺度热流控制对微电子、热电和能量转换技术至关重要。现有方法存在速度与精度权衡：宏观求解器误差大，数据驱动方法需要大量高保真模拟。需要一种快速、数据高效且可靠的代理模型。

Method: PEDS方法结合可微分傅里叶求解器（物理归纳偏置）和神经网络生成器，学习几何依赖修正和混合系数，通过不确定性驱动的主动学习减少训练数据需求。

Result: 相比纯数据驱动基线减少70%训练数据需求，仅用300次高保真BTE模拟实现约5%分数误差，设计孔隙几何的平均误差为4%，混合参数能捕捉弹道-扩散转变。

Conclusion: 嵌入简单可微分的低保真物理模型能显著提高代理模型的数据效率和可解释性，使PDE约束优化在纳米尺度热材料设计中变得实用。

Abstract: Designing materials with controlled heat flow at the nano-scale is central to advances in microelectronics, thermoelectrics, and energy-conversion technologies. At these scales, phonon transport follows the Boltzmann Transport Equation (BTE), which captures non-diffusive (ballistic) effects but is too costly to solve repeatedly in inverse-design loops. Existing surrogate approaches trade speed for accuracy: fast macroscopic solvers can overestimate conductivities by hundreds of percent, while recent data-driven operator learners often require thousands of high-fidelity simulations. This creates a need for a fast, data-efficient surrogate that remains reliable across ballistic and diffusive regimes. We introduce a Physics-Enhanced Deep Surrogate (PEDS) that combines a differentiable Fourier solver with a neural generator and couples it with uncertainty-driven active learning. The Fourier solver acts as a physical inductive bias, while the network learns geometry-dependent corrections and a mixing coefficient that interpolates between macroscopic and nano-scale behavior. PEDS reduces training-data requirements by up to 70% compared with purely data-driven baselines, achieves roughly 5% fractional error with only 300 high-fidelity BTE simulations, and enables efficient design of porous geometries spanning 12-85 W m$^{-1}$ K$^{-1}$ with average design errors of 4%. The learned mixing parameter recovers the ballistic-diffusive transition and improves out of distribution robustness. These results show that embedding simple, differentiable low-fidelity physics can dramatically increase surrogate data-efficiency and interpretability, making repeated PDE-constrained optimization practical for nano-scale thermal-materials design.

</details>


### [86] [MaxwellLink: A unified framework for self-consistent light-matter simulations](https://arxiv.org/abs/2512.06173)
*Xinwei Ji,Andres Felipe Bocanegra Vargas,Gang Meng,Tao E. Li*

Main category: physics.comp-ph

TL;DR: MaxwellLink是一个开源Python框架，通过TCP/UNIX套接字接口耦合电磁求解器和分子动力学模拟器，实现大规模并行、自洽的光-物质相互作用模拟。


<details>
  <summary>Details</summary>
Motivation: 当前光-物质模拟面临的主要挑战是电磁动力学和分子动力学在时间和长度尺度上的巨大差异。现有计算方法通常依赖对电磁或材料组分的启发式近似，这阻碍了对复杂光-物质系统的探索。

Method: 开发了模块化的MaxwellLink框架，采用TCP/UNIX套接字接口将电磁求解器与外部分子驱动程序耦合。这种解耦架构允许用户在不修改对应组件的情况下，自由切换电磁求解器或分子的理论级别。支持从单模腔到三维FDTD的电磁求解器，以及多级开放量子系统、力场、第一性原理分子动力学和非绝热实时Ehrenfest动力学等分子描述方法。

Result: 套接字设计使电磁引擎和分子驱动程序能够在多个高性能计算节点上独立扩展，实现了现有数值方案无法进行的大规模模拟。通过超辐射、辐射能量转移、布拉格谐振器中的振动强耦合以及分子气体的等离子体加热等应用展示了代码的多功能性和准确性。

Conclusion: MaxwellLink提供了一个统一、可扩展的引擎，为光谱学、量子光学、等离子体学和极化子学等研究前沿的新兴现象探索提供了一个强大的平台。

Abstract: A major challenge in light-matter simulations is bridging the disparate time and length scales of electrodynamics and molecular dynamics. Current computational approaches often rely on heuristic approximations of either the electromagnetic (EM) or material component, hindering the exploration of complex light-matter systems. Herein, MaxwellLink -- a modular, open-source Python framework -- is developed for the massively parallel, self-consistent propagation of classical EM fields interacting with a large heterogeneous molecular ensemble. The package utilizes a robust TCP/UNIX socket interface to couple EM solvers with a wide range of external molecular drivers. This decoupled architecture allows users to seamlessly switch between levels of theory of either the EM solver or molecules without modifying the counterpart. Crucially, MaxwellLink supports EM solvers spanning from single-mode cavities to full-feature three-dimensional finite-difference time-domain (FDTD) engines, and molecules described by multilevel open quantum systems, force-field and first-principles molecular dynamics, and nonadiabatic real-time Ehrenfest dynamics. Benefiting from the socket-based design, the EM engine and molecular drivers scale independently across multiple high-performance computing (HPC) nodes, facilitating large-scale simulations previously inaccessible to existing numerical schemes. The versatility and accuracy of this code are demonstrated through applications including superradiance, radiative energy transfer, vibrational strong coupling in Bragg resonators, and plasmonic heating of molecular gases. By providing a unified, extensible engine, MaxwellLink potentially offers a powerful platform for exploring emerging phenomena across the research fronts of spectroscopy, quantum optics, plasmonics, and polaritonics.

</details>


### [87] [Optimized Machine Learning Methods for Studying the Thermodynamic Behavior of Complex Spin Systems](https://arxiv.org/abs/2512.07458)
*Dmitrii Kapitan,Pavel Ovchinnikov,Konstantin Soldatov,Petr Andriushchenko,Vitalii Kapitan*

Main category: physics.comp-ph

TL;DR: 使用卷积神经网络分析自旋系统的临界和低温相态，构建了适用于多种晶格的相态分类器，能准确确定临界温度并降低误差。


<details>
  <summary>Details</summary>
Motivation: 研究卷积神经网络作为高效通用工具，用于分析自旋系统模型的临界和低温相态，特别是计算能量对交换积分空间分布的依赖关系，并构建适用于不同晶格的相态分类器。

Method: 针对Edwards-Anderson模型计算平均能量对交换积分空间分布的依赖；使用Swendsen-Wang团簇算法生成配置，训练单个卷积分类器来分析方形、三角形、蜂窝和kagome晶格的铁磁Ising模型相态。

Result: 高温相平均后验概率的温度分布形成清晰的S形曲线，在理论临界温度附近相交，无需额外训练即可确定kagome晶格的临界温度；卷积模型相比全连接架构显著降低均方根误差，能有效捕捉热力学特性与磁关联系统结构之间的复杂相关性。

Conclusion: 卷积神经网络是分析自旋系统相态的高效通用工具，能够准确确定临界温度，捕捉复杂相关性，并在多种晶格上表现出良好的泛化能力。

Abstract: This paper presents a systematic study of the application of convolutional neural networks (CNNs) as an efficient and versatile tool for the analysis of critical and low-temperature phase states in spin system models. The problem of calculating the dependence of the average energy on the spatial distribution of exchange integrals for the Edwards-Anderson model on a square lattice with frustrated interactions is considered. We further construct a single convolutional classifier of phase states of the ferromagnetic Ising model on square, triangular, honeycomb, and kagome lattices, trained on configurations generated by the Swendsen-Wang cluster algorithm. Computed temperature profiles of the averaged posterior probability of the high-temperature phase form clear S-shaped curves that intersect in the vicinity of the theoretical critical temperatures and allow one to determine the critical temperature for the kagome lattice without additional retraining. It is shown that convolutional models substantially reduce the root-mean-square error (RMSE) compared with fully connected architectures and efficiently capture complex correlations between thermodynamic characteristics and the structure of magnetic correlated systems.

</details>


### [88] [Conservative adaptive-precision interatomic potentials](https://arxiv.org/abs/2512.07693)
*David Immel,Ralf Drautz,Godehard Sutmann*

Main category: physics.comp-ph

TL;DR: 提出了一种新的自适应精度分子动力学方法，通过哈密顿量描述实现能量和动量守恒，相比纯ACE模拟可获得1-2个数量级的加速。


<details>
  <summary>Details</summary>
Motivation: 现有的自适应精度分子动力学方法大多基于固定空间区域，无法实现一致的动量守恒哈密顿描述。需要一种能够保证能量和动量守恒的保守描述方法。

Method: 提出了一种新的哈密顿量耦合方法，将耦合完全整合到哈密顿量中，实现保守描述。通过将快速EAM势与高精度ACE势耦合来验证。

Result: 数值验证了守恒特性，根据势函数和原子系统的不同，相比纯ACE模拟可获得1-2个数量级的加速。

Conclusion: 该方法实现了能量和动量守恒的自适应精度分子动力学，显著提高了计算效率，为多尺度模拟提供了新的保守耦合框架。

Abstract: Adaptive precision molecular dynamics simulations have developed along energy- and force-coupling approaches, which allow for a continuous transition between different particle descriptions or interaction potentials. Most approaches consider different (fixed) spatial regions, which control the transition between the descriptions and consequently avoid a consistent momentum-conserving Hamiltonian description. We present here a new approach to fully integrate the coupling into a Hamiltonian, therefore allowing for a conservative description, which, by design, guarantees both energy and momentum conservation. By coupling a fast EAM potential to a highly accurate ACE potential, we verify numerically the conservation properties and show that one can achieve - dependent on both the potential and the atomistic system - a speedup of one or two orders of magnitude compared to a pure ACE simulation.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [89] [A self-driving lab for solution-processed electrochromic thin films](https://arxiv.org/abs/2512.05989)
*Selma Dahms,Luca Torresi,Shahbaz Tareq Bandesha,Jan Hansmann,Holger Röhm,Alexander Colsmann,Marco Schott,Pascal Friederich*

Main category: cs.LG

TL;DR: 利用自驱动实验室结合自动化和机器学习加速电致变色涂层开发，通过贝叶斯优化高效探索工艺参数


<details>
  <summary>Details</summary>
Motivation: 溶液处理的电致变色材料在智能窗户和显示器中具有高潜力，但旋涂电致变色薄膜层的优化复杂，阻碍了快速开发

Method: 结合自动数据采集、图像处理、光谱分析和贝叶斯优化的自驱动实验室系统，高效探索处理参数

Result: 该方法不仅提高了通量，还能有针对性地搜索最优处理参数，可应用于各种溶液处理材料

Conclusion: 自驱动实验室在材料发现和工艺优化方面具有巨大潜力，能够加速电致变色涂层等溶液处理材料的开发

Abstract: Solution-processed electrochromic materials offer high potential for energy-efficient smart windows and displays. Their performance varies with material choice and processing conditions. Electrochromic thin film electrodes require a smooth, defect-free coating for optimal contrast between bleached and colored states. The complexity of optimizing the spin-coated electrochromic thin layer poses challenges for rapid development. This study demonstrates the use of self-driving laboratories to accelerate the development of electrochromic coatings by coupling automation with machine learning. Our system combines automated data acquisition, image processing, spectral analysis, and Bayesian optimization to explore processing parameters efficiently. This approach not only increases throughput but also enables a pointed search for optimal processing parameters. The approach can be applied to various solution-processed materials, highlighting the potential of self-driving labs in enhancing materials discovery and process optimization.

</details>


### [90] [Memory-Amortized Inference: A Topological Unification of Search, Closure, and Structure](https://arxiv.org/abs/2512.05990)
*Xin Li*

Main category: cs.LG

TL;DR: 提出MAI框架，用代数拓扑统一学习和记忆，通过同调奇偶性区分内容与上下文，将高复杂度搜索转化为低复杂度查找


<details>
  <summary>Details</summary>
Motivation: 现代机器学习将参数静态结构与推理动态流程分离，缺乏生物认知的样本效率和热力学经济性，需要统一理论框架

Method: 基于代数拓扑的MAI框架，提出同调奇偶原则：偶维同调表示稳定内容，奇维同调表示动态上下文。通过拓扑三位一体转换（搜索→闭合→结构）实现认知过程

Result: 将高复杂度递归搜索（NPSPACE）转化为低复杂度查找（P），通过拓扑循环闭合机制，用拓扑版Wake-Sleep算法协调推理与学习

Conclusion: MAI为从慢思考到快思考的涌现提供严格解释，为后图灵架构提供蓝图，通过拓扑共振进行计算

Abstract: Contemporary ML separates the static structure of parameters from the dynamic flow of inference, yielding systems that lack the sample efficiency and thermodynamic frugality of biological cognition. In this theoretical work, we propose \textbf{Memory-Amortized Inference (MAI)}, a formal framework rooted in algebraic topology that unifies learning and memory as phase transitions of a single geometric substrate. Central to our theory is the \textbf{Homological Parity Principle}, which posits a fundamental dichotomy: even-dimensional homology ($H_{even}$) physically instantiates stable \textbf{Content} (stable scaffolds or ``what''), while odd-dimensional homology ($H_{odd}$) instantiates dynamic \textbf{Context} (dynamic flows or ``where''). We derive the logical flow of MAI as a topological trinity transformation: \textbf{Search $\to$ Closure $\to$ Structure}. Specifically, we demonstrate that cognition operates by converting high-complexity recursive search (modeled by \textit{Savitch's Theorem} in NPSPACE) into low-complexity lookup (modeled by \textit{Dynamic Programming} in P) via the mechanism of \textbf{Topological Cycle Closure}. We further show that this consolidation process is governed by a topological generalization of the Wake-Sleep algorithm, functioning as a coordinate descent that alternates between optimizing the $H_{odd}$ flow (inference/wake) and condensing persistent cycles into the $H_{even}$ scaffold (learning/sleep). This framework offers a rigorous explanation for the emergence of fast-thinking (intuition) from slow-thinking (reasoning) and provides a blueprint for post-Turing architectures that compute via topological resonance.

</details>


### [91] [Deep learning recognition and analysis of Volatile Organic Compounds based on experimental and synthetic infrared absorption spectra](https://arxiv.org/abs/2512.06059)
*Andrea Della Valle,Annalisa D'Arco,Tiziana Mancini,Rosanna Mosetti,Maria Chiara Paolozzi,Stefano Lupi,Sebastiano Pilati,Andrea Perali*

Main category: cs.LG

TL;DR: 该研究开发了一种基于红外光谱和神经网络的VOC检测方法，通过实验数据和生成式神经网络增强的数据集训练了能够可靠识别9种VOC并预测其浓度的判别性神经网络。


<details>
  <summary>Details</summary>
Motivation: 挥发性有机化合物(VOCs)对健康构成重大风险，需要准确检测。虽然红外光谱能够实现超灵敏检测，但复杂的光谱限制了实时识别和定量分析的可能性。深度学习需要大量数据集进行训练，而实验数据有限。

Method: 创建了9种不同类别化合物的实验VOC数据集，使用其红外吸收光谱。通过条件生成神经网络创建合成光谱来增强数据集，增加光谱数量和浓度多样性。然后训练判别性神经网络进行VOC识别和浓度预测。

Result: 训练出的神经网络能够可靠识别9种VOC，并精确预测其浓度。该网络适合集成到VOC识别和分析的传感设备中。

Conclusion: 通过结合实验数据和生成式神经网络增强的数据集，成功开发了能够实现VOC实时识别和定量分析的神经网络方法，为环境监测提供了有效的技术方案。

Abstract: Volatile Organic Compounds (VOCs) are organic molecules that have low boiling points and therefore easily evaporate into the air. They pose significant risks to human health, making their accurate detection the crux of efforts to monitor and minimize exposure. Infrared (IR) spectroscopy enables the ultrasensitive detection at low-concentrations of VOCs in the atmosphere by measuring their IR absorption spectra. However, the complexity of the IR spectra limits the possibility to implement VOC recognition and quantification in real-time. While deep neural networks (NNs) are increasingly used for the recognition of complex data structures, they typically require massive datasets for the training phase. Here, we create an experimental VOC dataset for nine different classes of compounds at various concentrations, using their IR absorption spectra. To further increase the amount of spectra and their diversity in term of VOC concentration, we augment the experimental dataset with synthetic spectra created via conditional generative NNs. This allows us to train robust discriminative NNs, able to reliably identify the nine VOCs, as well as to precisely predict their concentrations. The trained NN is suitable to be incorporated into sensing devices for VOCs recognition and analysis.

</details>


### [92] [When Privacy Isn't Synthetic: Hidden Data Leakage in Generative AI Models](https://arxiv.org/abs/2512.06062)
*S. M. Mustaqim,Anantaa Kotal,Paul H. Yi*

Main category: cs.LG

TL;DR: 提出一种基于聚类中位数和邻域分析的黑盒成员推理攻击，利用生成模型合成数据与原始训练数据在流形结构上的重叠来推断成员信息，即使在差分隐私等噪声机制下仍存在可测量的隐私泄露。


<details>
  <summary>Details</summary>
Motivation: 生成模型被广泛用于生成隐私保护的合成数据，但现有方法主要关注样本级别的记忆化问题，忽略了数据流形结构重叠可能导致的隐私泄露风险。

Method: 提出黑盒成员推理攻击：1) 重复查询生成模型获取大量合成样本；2) 无监督聚类识别合成分布中的密集区域；3) 分析聚类中位数和邻域，这些区域对应原始训练数据的高密度区域；4) 利用这些邻域作为训练样本的代理来推断成员信息或重建近似记录。

Result: 在医疗、金融等敏感领域的实验表明，即使生成器使用差分隐私或其他噪声机制训练，真实数据与合成数据之间的聚类重叠仍会导致可测量的成员信息泄露。

Conclusion: 合成数据生成管道存在未充分探索的攻击面，需要更强的隐私保证机制，不仅要考虑样本级别的记忆化，还要考虑分布邻域推理问题，这对隐私保护数据发布具有重要意义。

Abstract: Generative models are increasingly used to produce privacy-preserving synthetic data as a safe alternative to sharing sensitive training datasets. However, we demonstrate that such synthetic releases can still leak information about the underlying training samples through structural overlap in the data manifold. We propose a black-box membership inference attack that exploits this vulnerability without requiring access to model internals or real data. The attacker repeatedly queries the generative model to obtain large numbers of synthetic samples, performs unsupervised clustering to identify dense regions of the synthetic distribution, and then analyzes cluster medoids and neighborhoods that correspond to high-density regions in the original training data. These neighborhoods act as proxies for training samples, enabling the adversary to infer membership or reconstruct approximate records. Our experiments across healthcare, finance, and other sensitive domains show that cluster overlap between real and synthetic data leads to measurable membership leakage-even when the generator is trained with differential privacy or other noise mechanisms. The results highlight an under-explored attack surface in synthetic data generation pipelines and call for stronger privacy guarantees that account for distributional neighborhood inference rather than sample-level memorization alone, underscoring its role in privacy-preserving data publishing. Implementation and evaluation code are publicly available at:github.com/Cluster-Medoid-Leakage-Attack.

</details>


### [93] [Hierarchical geometric deep learning enables scalable analysis of molecular dynamics](https://arxiv.org/abs/2512.06520)
*Zihan Pengmei,Spencer C. Guo,Chatipat Lorpaiboon,Aaron R. Dinner*

Main category: cs.LG

TL;DR: 提出一种基于图神经网络的方法，通过局部信息聚合来高效分析大规模生物分子系统的分子动力学模拟轨迹，降低内存和计算需求，同时保持原子级细节。


<details>
  <summary>Details</summary>
Motivation: 分子动力学模拟能生成原子级细节的复杂系统轨迹，但对于缺乏定量描述符的大系统（如超过几百个残基的生物分子系统），分析具有挑战性。现有图神经网络方法在分析大规模系统动力学时面临长程相互作用捕获困难以及大图带来的内存和运行时限制。

Method: 开发了一种基于图神经网络的局部信息聚合方法，通过有效聚合局部信息来减少内存和运行时需求，同时保持原子级细节。该方法能够处理包含数千个残基的蛋白质-核酸复合物系统。

Result: 该方法使得在单GPU上几分钟内分析数千个残基的蛋白质-核酸复合物模拟成为可能。对于数百个残基的系统，该方法在性能和可解释性方面都有所提升。

Conclusion: 局部信息聚合方法为分析大规模生物分子系统的分子动力学模拟提供了一种高效解决方案，突破了传统图神经网络在内存和计算上的限制，同时保持了分析精度和可解释性。

Abstract: Molecular dynamics simulations can generate atomically detailed trajectories of complex systems, but analyzing these dynamics can be challenging when systems lack well-established quantitative descriptors (features). Graph neural networks (GNNs) in which messages are passed between nodes that represent atoms that are spatial neighbors promise to obviate manual feature engineering, but the use of GNNs with biomolecular systems of more than a few hundred residues has been limited in the context of analyzing dynamics by both difficulties in capturing the details of long-range interactions with message passing and the memory and runtime requirements associated with large graphs. Here, we show how local information can be aggregated to reduce memory and runtime requirements without sacrificing atomic detail. We demonstrate that this approach opens the door to analyzing simulations of protein-nucleic acid complexes with thousands of residues on single GPUs within minutes. For systems with hundreds of residues, for which there are sufficient data to make quantitative comparisons, we show that the approach improves performance and interpretability.

</details>


### [94] [JaxWildfire: A GPU-Accelerated Wildfire Simulator for Reinforcement Learning](https://arxiv.org/abs/2512.06102)
*Ufuk Çakır,Victor-Alexandru Darvariu,Bruno Lacerda,Nick Hawes*

Main category: cs.LG

TL;DR: JaxWildfire是一个基于JAX的高性能野火模拟器，使用概率细胞自动机模型，通过GPU向量化实现6-35倍加速，支持梯度优化和强化学习训练


<details>
  <summary>Details</summary>
Motivation: 现有野火模拟器速度慢，限制了强化学习等AI方法在自然灾害管理中的应用，需要高性能模拟器来支持大量环境交互训练

Method: 基于概率细胞自动机的野火传播模型，使用JAX框架实现，通过vmap实现向量化模拟，充分利用GPU并行计算能力

Result: 相比现有软件实现6-35倍速度提升，支持基于梯度的模拟器参数优化，并能用于训练强化学习智能体学习野火抑制策略

Conclusion: JaxWildfire为强化学习技术在自然灾害管理中的发展提供了重要工具，解决了现有模拟器速度瓶颈问题

Abstract: Artificial intelligence methods are increasingly being explored for managing wildfires and other natural hazards. In particular, reinforcement learning (RL) is a promising path towards improving outcomes in such uncertain decision-making scenarios and moving beyond reactive strategies. However, training RL agents requires many environment interactions, and the speed of existing wildfire simulators is a severely limiting factor. We introduce $\texttt{JaxWildfire}$, a simulator underpinned by a principled probabilistic fire spread model based on cellular automata. It is implemented in JAX and enables vectorized simulations using $\texttt{vmap}$, allowing high throughput of simulations on GPUs. We demonstrate that $\texttt{JaxWildfire}$ achieves 6-35x speedup over existing software and enables gradient-based optimization of simulator parameters. Furthermore, we show that $\texttt{JaxWildfire}$ can be used to train RL agents to learn wildfire suppression policies. Our work is an important step towards enabling the advancement of RL techniques for managing natural hazards.

</details>


### [95] [ARC-AGI Without Pretraining](https://arxiv.org/abs/2512.06104)
*Isaac Liao,Albert Gu*

Main category: cs.LG

TL;DR: 76K参数模型CompressARC无需预训练，通过推理时最小化描述长度(MDL)解决20%的ARC-AGI视觉谜题，展现极端泛化能力


<details>
  <summary>Details</summary>
Motivation: 挑战传统观点：解决ARC-AGI视觉谜题通常需要大规模预训练。研究者希望探索在极有限数据条件下（仅使用目标谜题本身）实现智能推理的替代方法

Method: 提出CompressARC模型（仅76K参数），不进行任何预训练，在推理时通过最小化描述长度(MDL)来求解目标谜题。模型仅使用单个样本（目标推理谜题本身，不含最终答案）进行训练，不使用ARC-AGI提供的训练集

Result: 模型成功解决了20%的评估谜题，在极端数据限制条件下（通常认为不可能解决任何谜题）展现了多样化的创造性谜题解决能力

Conclusion: 最小化描述长度(MDL)是除传统预训练外，实现智能推理的可行替代途径，展示了极端泛化能力，挑战了深度学习对大规模数据的依赖

Abstract: Conventional wisdom in the age of LLMs dictates that solving IQ-test-like visual puzzles from the ARC-AGI-1 benchmark requires capabilities derived from massive pretraining. To counter this, we introduce CompressARC, a 76K parameter model without any pretraining that solves 20% of evaluation puzzles by minimizing the description length (MDL) of the target puzzle purely during inference time. The MDL endows CompressARC with extreme generalization abilities typically unheard of in deep learning. To our knowledge, CompressARC is the only deep learning method for ARC-AGI where training happens only on a single sample: the target inference puzzle itself, with the final solution information removed. Moreover, CompressARC does not train on the pre-provided ARC-AGI "training set". Under these extremely data-limited conditions, we do not ordinarily expect any puzzles to be solvable at all. Yet CompressARC still solves a diverse distribution of creative ARC-AGI puzzles, suggesting MDL to be an alternative feasible way to produce intelligence, besides conventional pretraining.

</details>


### [96] [A Prescriptive Framework for Determining Optimal Days for Short-Term Traffic Counts](https://arxiv.org/abs/2512.06111)
*Arthur Mukwaya,Nancy Kasamala,Nana Kankam Gyimah,Judith Mwakalonge,Gurcan Comert,Saidi Siuhi,Denis Ruganuza,Mark Ngotonie*

Main category: cs.LG

TL;DR: 提出机器学习框架选择最优代表日进行短期交通计数，提高年度日均交通量预测精度


<details>
  <summary>Details</summary>
Motivation: 美国各州交通部门难以获取准确的年度日均交通量数据，特别是未监测道路。连续计数站成本高难以广泛部署，需要依赖短期计数数据，但现有方法缺乏优化选择计数日期的策略。

Method: 提出机器学习框架，通过迭代选择对AADT估计最具信息量的最优代表日。使用得克萨斯州2022-2023年交通量数据，比较"最优日"方法和"非最优日"基线。利用连续计数数据模拟24小时短期计数，采用留一法生成无偏的代表性日交通特征。

Result: 最优日方法在Top 5天均优于基线，最佳日（第186天）的RMSE（7,871.15）、MAE（3,645.09）、MAPE（11.95%）均低于基线（11,185.00、5,118.57、14.42%），R²（0.9756）高于基线（0.9499）。

Conclusion: 该研究为交通部门提供了改进传统短期计数实践的替代方案，能提高AADT估计精度，支持公路性能监测系统合规性，并降低全州交通数据收集的运营成本。

Abstract: The Federal Highway Administration (FHWA) mandates that state Departments of Transportation (DOTs) collect reliable Annual Average Daily Traffic (AADT) data. However, many U.S. DOTs struggle to obtain accurate AADT, especially for unmonitored roads. While continuous count (CC) stations offer accurate traffic volume data, their implementation is expensive and difficult to deploy widely, compelling agencies to rely on short-duration traffic counts. This study proposes a machine learning framework, the first to our knowledge, to identify optimal representative days for conducting short count (SC) data collection to improve AADT prediction accuracy. Using 2022 and 2023 traffic volume data from the state of Texas, we compare two scenarios: an 'optimal day' approach that iteratively selects the most informative days for AADT estimation and a 'no optimal day' baseline reflecting current practice by most DOTs. To align with Texas DOT's traffic monitoring program, continuous count data were utilized to simulate the 24 hour short counts. The actual field short counts were used to enhance feature engineering through using a leave-one-out (LOO) technique to generate unbiased representative daily traffic features across similar road segments. Our proposed methodology outperforms the baseline across the top five days, with the best day (Day 186) achieving lower errors (RMSE: 7,871.15, MAE: 3,645.09, MAPE: 11.95%) and higher R^2 (0.9756) than the baseline (RMSE: 11,185.00, MAE: 5,118.57, MAPE: 14.42%, R^2: 0.9499). This research offers DOTs an alternative to conventional short-duration count practices, improving AADT estimation, supporting Highway Performance Monitoring System compliance, and reducing the operational costs of statewide traffic data collection.

</details>


### [97] [Physics-Informed Neural Koopman Machine for Interpretable Longitudinal Personalized Alzheimer's Disease Forecasting](https://arxiv.org/abs/2512.06134)
*Georgi Hrusanov,Duy-Thanh Vu,Duy-Cat Can,Sophie Tascedda,Margaret Ryan,Julien Bodelet,Katarzyna Koscielska,Carsten Magnus,Oliver Y. Chén*

Main category: cs.LG

TL;DR: 提出Neural Koopman Machine (NKM)架构，结合动态系统和注意力机制，使用多模态数据预测阿尔茨海默病认知衰退轨迹，在ADNI数据集上优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病早期认知衰退预测对疾病评估和管理至关重要，但现有方法难以整合多模态数据进行纵向个性化预测同时保持可解释性。

Method: 提出Neural Koopman Machine (NKM)架构，结合动态系统理论和注意力机制，通过Fusion Group-Aware Hierarchical Attention在Koopman算子框架内将非线性轨迹转换为可解释的线性表示，整合分析知识和生物学知识指导特征分组。

Result: 在ADNI数据集上，NKM在预测认知衰退轨迹方面优于传统机器学习和深度学习模型，能同时预测多个认知评分变化，量化不同生物标志物对特定认知评分的贡献，并识别与认知恶化最相关的大脑区域。

Conclusion: NKM通过可解释的显式系统推进了使用多模态数据进行阿尔茨海默病认知衰退的个性化预测，揭示了疾病进展的潜在多模态生物学基础。

Abstract: Early forecasting of individual cognitive decline in Alzheimer's disease (AD) is central to disease evaluation and management. Despite advances, it is as of yet challenging for existing methodological frameworks to integrate multimodal data for longitudinal personalized forecasting while maintaining interpretability. To address this gap, we present the Neural Koopman Machine (NKM), a new machine learning architecture inspired by dynamical systems and attention mechanisms, designed to forecast multiple cognitive scores simultaneously using multimodal genetic, neuroimaging, proteomic, and demographic data. NKM integrates analytical ($α$) and biological ($β$) knowledge to guide feature grouping and control the hierarchical attention mechanisms to extract relevant patterns. By implementing Fusion Group-Aware Hierarchical Attention within the Koopman operator framework, NKM transforms complex nonlinear trajectories into interpretable linear representations. To demonstrate NKM's efficacy, we applied it to study the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset. Our results suggest that NKM consistently outperforms both traditional machine learning methods and deep learning models in forecasting trajectories of cognitive decline. Specifically, NKM (1) forecasts changes of multiple cognitive scores simultaneously, (2) quantifies differential biomarker contributions to predicting distinctive cognitive scores, and (3) identifies brain regions most predictive of cognitive deterioration. Together, NKM advances personalized, interpretable forecasting of future cognitive decline in AD using past multimodal data through an explainable, explicit system and reveals potential multimodal biological underpinnings of AD progression.

</details>


### [98] [gp2Scale: A Class of Compactly-Supported Non-Stationary Kernels and Distributed Computing for Exact Gaussian Processes on 10 Million Data Points](https://arxiv.org/abs/2512.06143)
*Marcus M. Noack,Mark D. Risser,Hengrui Luo,Vardaan Tekriwal,Ronald J. Pandolfi*

Main category: cs.LG

TL;DR: 提出gp2Scale方法，无需近似技术即可将精确高斯过程扩展到千万级数据点，利用灵活核函数自然产生的稀疏性实现高效计算。


<details>
  <summary>Details</summary>
Motivation: 现有高斯过程扩展方法存在计算速度、预测精度和不确定性量化之间的权衡，主要依赖各种近似技术，降低了准确性并限制了核函数和噪声模型设计的灵活性，特别是在表达性非平稳核函数日益重要的背景下。

Method: 提出gp2Scale方法，不依赖诱导点、核插值或邻域近似，而是利用灵活、紧支撑、非平稳核函数在协方差矩阵中自然产生的稀疏结构，高效计算线性系统解和对数行列式进行训练。

Result: 方法能够扩展到超过1000万个数据点，在多个真实数据集上展示功能，与最先进近似算法相比，在许多情况下表现出优越的近似性能，同时保持对任意高斯过程定制（核设计、噪声、均值函数）和输入空间类型的不可知性。

Conclusion: gp2Scale方法通过利用核函数设计自然产生的稀疏性，解决了高斯过程扩展中的核心权衡问题，特别适合现代高斯过程应用，能够处理大规模数据同时保持灵活性和精确性。

Abstract: Despite a large corpus of recent work on scaling up Gaussian processes, a stubborn trade-off between computational speed, prediction and uncertainty quantification accuracy, and customizability persists. This is because the vast majority of existing methodologies exploit various levels of approximations that lower accuracy and limit the flexibility of kernel and noise-model designs -- an unacceptable drawback at a time when expressive non-stationary kernels are on the rise in many fields. Here, we propose a methodology we term \emph{gp2Scale} that scales exact Gaussian processes to more than 10 million data points without relying on inducing points, kernel interpolation, or neighborhood-based approximations, and instead leveraging the existing capabilities of a GP: its kernel design. Highly flexible, compactly supported, and non-stationary kernels lead to the identification of naturally occurring sparse structure in the covariance matrix, which is then exploited for the calculations of the linear system solution and the log-determinant for training. We demonstrate our method's functionality on several real-world datasets and compare it with state-of-the-art approximation algorithms. Although we show superior approximation performance in many cases, the method's real power lies in its agnosticism toward arbitrary GP customizations -- core kernel design, noise, and mean functions -- and the type of input space, making it optimally suited for modern Gaussian process applications.

</details>


### [99] [Learning Invariant Graph Representations Through Redundant Information](https://arxiv.org/abs/2512.06154)
*Barproda Halder,Pasan Dissanayake,Sanghamitra Dutta*

Main category: cs.LG

TL;DR: 提出RIG框架，利用部分信息分解(PID)识别冗余信息，通过多级优化学习不变图表示，提升OOD泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有基于经典信息论的方法在OOD图泛化中存在局限，学习到的表示常保留虚假成分，需要更精确地识别虚假子图和不变子图之间的冗余信息

Method: 提出RIG框架：1)使用PID识别虚假子图G_s和不变子图G_c之间的冗余信息；2)采用多级优化，交替估计冗余信息下界并最大化该下界；3)同时隔离虚假和因果子图

Result: 在合成和真实图数据集上的实验表明，RIG框架在各种分布偏移下具有更好的泛化能力

Conclusion: PID为不变图表示学习提供了新工具，RIG框架通过精确处理冗余信息，有效提升了OOD泛化性能

Abstract: Learning invariant graph representations for out-of-distribution (OOD) generalization remains challenging because the learned representations often retain spurious components. To address this challenge, this work introduces a new tool from information theory called Partial Information Decomposition (PID) that goes beyond classical information-theoretic measures. We identify limitations in existing approaches for invariant representation learning that solely rely on classical information-theoretic measures, motivating the need to precisely focus on redundant information about the target $Y$ shared between spurious subgraphs $G_s$ and invariant subgraphs $G_c$ obtained via PID. Next, we propose a new multi-level optimization framework that we call -- Redundancy-guided Invariant Graph learning (RIG) -- that maximizes redundant information while isolating spurious and causal subgraphs, enabling OOD generalization under diverse distribution shifts. Our approach relies on alternating between estimating a lower bound of redundant information (which itself requires an optimization) and maximizing it along with additional objectives. Experiments on both synthetic and real-world graph datasets demonstrate the generalization capabilities of our proposed RIG framework.

</details>


### [100] [PMA-Diffusion: A Physics-guided Mask-Aware Diffusion Framework for TSE from Sparse Observations](https://arxiv.org/abs/2512.06183)
*Lindong Liu,Zhixiong Jin,Seongjin Choi*

Main category: cs.LG

TL;DR: PMA-Diffusion：一种物理引导的掩码感知扩散框架，用于从稀疏观测中重建高速公路速度场，在5%可见度下仍优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 高速公路交通状态信息对智能交通系统至关重要，但现有数据（如环形检测器和探测车辆）通常过于稀疏和嘈杂，无法捕捉交通流的详细动态。

Method: 提出PMA-Diffusion框架，采用两种掩码感知训练策略（单掩码和双掩码）直接在稀疏观测的速度场上训练扩散先验。推理阶段使用物理引导的后验采样器，交替进行反向扩散更新、观测投影和基于自适应各向异性平滑的物理引导投影。

Result: 在I-24 MOTION数据集上测试，即使只有5%可见度的极端稀疏情况下，PMA-Diffusion在三个重建误差指标上都优于其他基线方法。使用稀疏观测训练的模型性能接近基于完整观测训练的基线模型。

Conclusion: 将掩码感知扩散先验与物理引导后验采样器相结合，为实际传感稀疏条件下的交通状态估计提供了可靠且灵活的解决方案。

Abstract: High-resolution highway traffic state information is essential for Intelligent Transportation Systems, but typical traffic data acquired from loop detectors and probe vehicles are often too sparse and noisy to capture the detailed dynamics of traffic flow. We propose PMA-Diffusion, a physics-guided mask-aware diffusion framework that reconstructs unobserved highway speed fields from sparse, incomplete observations. Our approach trains a diffusion prior directly on sparsely observed speed fields using two mask-aware training strategies: Single-Mask and Double-Mask. At the inference phase, the physics-guided posterior sampler alternates reverse-diffusion updates, observation projection, and physics-guided projection based on adaptive anisotropic smoothing to reconstruct the missing speed fields. The proposed framework is tested on the I-24 MOTION dataset with varying visibility ratios. Even under severe sparsity, with only 5% visibility, PMA-Diffusion outperforms other baselines across three reconstruction error metrics. Furthermore, PMA-diffusion trained with sparse observation nearly matches the performance of the baseline model trained on fully observed speed fields. The results indicate that combining mask-aware diffusion priors with a physics-guided posterior sampler provides a reliable and flexible solution for traffic state estimation under realistic sensing sparsity.

</details>


### [101] [How Should We Evaluate Data Deletion in Graph-Based ANN Indexes?](https://arxiv.org/abs/2512.06200)
*Tomohiro Yamashita,Daichi Amagata,Yusuke Matsui*

Main category: cs.LG

TL;DR: 提出一个评估ANNS索引数据删除效率的实验框架和综合评估指标，将图基ANNS的数据删除方法分为三类并数学形式化，应用于HNSW分析删除效果，提出动态选择删除方法的Deletion Control方法


<details>
  <summary>Details</summary>
Motivation: 近似最近邻搜索在动态数据应用中越来越重要，但缺乏针对数据删除的综合评估方法。需要建立系统性的评估框架来评估ANNS索引在数据删除场景下的性能

Method: 提出实验框架和综合评估指标，将图基ANNS的数据删除方法分为三类并数学形式化，在准确性、查询速度等指标上评估性能，应用于HNSW分析删除效果，提出Deletion Control方法动态选择删除策略

Result: 建立了ANNS数据删除的评估框架，形式化了三种删除方法，通过HNSW实验分析了数据删除的影响，提出的Deletion Control方法能在保持搜索准确性的前提下动态选择最优删除策略

Conclusion: 该研究填补了ANNS数据删除评估的空白，提出的框架和Deletion Control方法为动态ANNS系统的设计和优化提供了重要工具，有助于在实际应用中平衡删除效率和搜索性能

Abstract: Approximate Nearest Neighbor Search (ANNS) has recently gained significant attention due to its many applications, such as Retrieval-Augmented Generation. Such applications require ANNS algorithms that support dynamic data, so the ANNS problem on dynamic data has attracted considerable interest. However, a comprehensive evaluation methodology for data deletion in ANNS has yet to be established. This study proposes an experimental framework and comprehensive evaluation metrics to assess the efficiency of data deletion for ANNS indexes under practical use cases. Specifically, we categorize data deletion methods in graph-based ANNS into three approaches and formalize them mathematically. The performance is assessed in terms of accuracy, query speed, and other relevant metrics. Finally, we apply the proposed evaluation framework to Hierarchical Navigable Small World, one of the state-of-the-art ANNS methods, to analyze the effects of data deletion, and propose Deletion Control, a method which dynamically selects the appropriate deletion method under a required search accuracy.

</details>


### [102] [K2-V2: A 360-Open, Reasoning-Enhanced LLM](https://arxiv.org/abs/2512.06201)
*K2 Team,Zhengzhong Liu,Liping Tang,Linghao Jin,Haonan Li,Nikhil Ranjan,Desai Fan,Shaurya Rohatgi,Richard Fan,Omkar Pangarkar,Huijuan Wang,Zhoujun Cheng,Suqi Sun,Seungwook Han,Bowen Tan,Gurpreet Gosal,Xudong Han,Varad Pimpalkhute,Shibo Hao,Ming Shan Hee,Joel Hestness,Haolong Jia,Liqun Ma,Aaryamonvikram Singh,Daria Soboleva,Natalia Vassilieva,Renxi Wang,Yingquan Wu,Yuekai Sun,Taylor Killian,Alexander Moreno,John Maggs,Hector Ren,Guowei He,Hongyi Wang,Xuezhe Ma,Yuqi Wang,Mikhail Yurochkin,Eric P. Xing*

Main category: cs.LG

TL;DR: K2-V2是一个从头开始构建的360度开放LLM，作为推理适应的优秀基础模型，在72B规模级别中表现最强，超越Qwen2.5-72B并接近Qwen3-235B的性能。


<details>
  <summary>Details</summary>
Motivation: 构建一个专门为复杂推理任务优化的开放基础模型，为社区提供强大的推理中心化基础，同时支持对话、知识检索等通用功能。

Method: 从头开始训练，在训练过程中主动注入领域知识、推理能力、长上下文和工具使用能力，使用简单的监督微调建立强基线，并发布完整的训练历史和数据组成。

Result: K2-V2成为最强的完全开放模型，在相同规模级别中与开放权重领导者相媲美，超越Qwen2.5-72B并接近Qwen3-235B的性能。

Conclusion: K2-V2作为一个强大的推理中心化基础模型，通过发布完整的训练历史和数据，为社区提供了持续训练的有效基础，展示了在高级对齐方面仍有显著提升空间。

Abstract: We introduce K2-V2, a 360-open LLM built from scratch as a superior base for reasoning adaptation, in addition to functions such as conversation and knowledge retrieval from general LLMs. It stands as the strongest fully open model, rivals open-weight leaders in its size class, outperforms Qwen2.5-72B and approaches the performance of Qwen3-235B. We actively infuse domain knowledge, reasoning, long-context, and tool use throughout the training process. This explicitly prepares the model for complex reasoning tasks. We demonstrate this potential using simple supervised fine-tuning, establishing a strong baseline that indicates significant headroom for advanced alignment. By releasing the full training history and data composition, we maximize the effectiveness of continuous training, a key open source production scenario. We release the model weights and signature LLM360 artifacts, such as complete training data, to empower the community with a capable, reasoning-centric foundation.

</details>


### [103] [Quantifying Memory Use in Reinforcement Learning with Temporal Range](https://arxiv.org/abs/2512.06204)
*Rodney Lafuente-Mercado,Daniela Rus,T. Konstantin Rusch*

Main category: cs.LG

TL;DR: 提出Temporal Range指标，用于量化RL策略对历史观测的依赖程度，通过计算输出对输入序列的时间敏感性来测量平均滞后


<details>
  <summary>Details</summary>
Motivation: 需要量化训练后的RL策略实际使用历史观测的程度，以比较不同智能体和环境，并选择最短的足够上下文

Method: 提出Temporal Range指标，通过反向自动微分计算Jacobian块，将多个向量输出对输入序列的一阶敏感性作为时间影响剖面，用幅度加权平均滞后进行总结

Result: 在诊断和控制任务中，Temporal Range：(i)在完全观测控制中保持较小；(ii)在Copy-k任务中随任务真实滞后缩放；(iii)与实现接近最优回报所需的最小历史窗口对齐

Conclusion: Temporal Range为比较智能体和环境以及选择最短足够上下文提供了实用的每序列内存依赖读数，可作为任务级内存的代理读数

Abstract: How much does a trained RL policy actually use its past observations? We propose \emph{Temporal Range}, a model-agnostic metric that treats first-order sensitivities of multiple vector outputs across a temporal window to the input sequence as a temporal influence profile and summarizes it by the magnitude-weighted average lag. Temporal Range is computed via reverse-mode automatic differentiation from the Jacobian blocks $\partial y_s/\partial x_t\in\mathbb{R}^{c\times d}$ averaged over final timesteps $s\in\{t+1,\dots,T\}$ and is well-characterized in the linear setting by a small set of natural axioms. Across diagnostic and control tasks (POPGym; flicker/occlusion; Copy-$k$) and architectures (MLPs, RNNs, SSMs), Temporal Range (i) remains small in fully observed control, (ii) scales with the task's ground-truth lag in Copy-$k$, and (iii) aligns with the minimum history window required for near-optimal return as confirmed by window ablations. We also report Temporal Range for a compact Long Expressive Memory (LEM) policy trained on the task, using it as a proxy readout of task-level memory. Our axiomatic treatment draws on recent work on range measures, specialized here to temporal lag and extended to vector-valued outputs in the RL setting. Temporal Range thus offers a practical per-sequence readout of memory dependence for comparing agents and environments and for selecting the shortest sufficient context.

</details>


### [104] [Average-reward reinforcement learning in semi-Markov decision processes via relative value iteration](https://arxiv.org/abs/2512.06218)
*Huizhen Yu,Yi Wan,Richard S. Sutton*

Main category: cs.LG

TL;DR: 将异步随机逼近理论应用于平均奖励半马尔可夫决策过程的强化学习，证明了RVI Q-learning算法的收敛性，并引入了新的单调性条件来估计最优奖励率。


<details>
  <summary>Details</summary>
Motivation: 将作者最近在Borkar-Meyn框架下的异步随机逼近结果应用于平均奖励半马尔可夫决策过程的强化学习，扩展了现有算法框架并解决收敛性问题。

Method: 应用异步随机逼近理论到Schweitzer经典相对值迭代算法的异步版本——RVI Q-learning，针对有限状态空间、弱通信的半马尔可夫决策过程，并引入新的单调性条件来估计最优奖励率。

Result: 证明了算法几乎必然收敛到平均奖励最优方程解的紧致连通子集，在额外步长和异步条件下收敛到唯一的样本路径依赖解，新单调性条件显著扩展了先前考虑的算法框架。

Conclusion: 成功将异步随机逼近理论应用于平均奖励半马尔可夫决策过程的强化学习，建立了RVI Q-learning的收敛性理论，并通过新颖的稳定性分析扩展了算法框架。

Abstract: This paper applies the authors' recent results on asynchronous stochastic approximation (SA) in the Borkar-Meyn framework to reinforcement learning in average-reward semi-Markov decision processes (SMDPs). We establish the convergence of an asynchronous SA analogue of Schweitzer's classical relative value iteration algorithm, RVI Q-learning, for finite-space, weakly communicating SMDPs. In particular, we show that the algorithm converges almost surely to a compact, connected subset of solutions to the average-reward optimality equation, with convergence to a unique, sample path-dependent solution under additional stepsize and asynchrony conditions. Moreover, to make full use of the SA framework, we introduce new monotonicity conditions for estimating the optimal reward rate in RVI Q-learning. These conditions substantially expand the previously considered algorithmic framework and are addressed through novel arguments in the stability and convergence analysis of RVI Q-learning.

</details>


### [105] [Back to Author Console Empowering GNNs for Domain Adaptation via Denoising Target Graph](https://arxiv.org/abs/2512.06236)
*Haiyang Yu,Meng-Chieh Lee,Xiang song,Qi Zhu,Christos Faloutsos*

Main category: cs.LG

TL;DR: 提出GraphDeT框架，通过加入辅助边去噪任务提升图神经网络在域适应中的节点分类性能


<details>
  <summary>Details</summary>
Motivation: 图结构域偏移（如不同时间或区域收集的数据）导致GNN在目标图上性能下降，需要提升图域适应能力

Method: 提出GraphDeT框架，在GNN训练中加入辅助边去噪损失函数，通过理论分析连接该任务与图泛化边界

Result: 实验结果显示在处理时间和区域域图偏移时，性能优于现有基线方法

Conclusion: 简单的辅助边去噪任务能有效提升GNN在目标图上的泛化能力，GraphDeT框架在域适应中表现优异

Abstract: We explore the node classification task in the context of graph domain adaptation, which uses both source and target graph structures along with source labels to enhance the generalization capabilities of Graph Neural Networks (GNNs) on target graphs. Structure domain shifts frequently occur, especially when graph data are collected at different times or from varying areas, resulting in poor performance of GNNs on target graphs. Surprisingly, we find that simply incorporating an auxiliary loss function for denoising graph edges on target graphs can be extremely effective in enhancing GNN performance on target graphs. Based on this insight, we propose our framework, GraphDeT, a framework that integrates this auxiliary edge task into GNN training for node classification under domain adaptation. Our theoretical analysis connects this auxiliary edge task to the graph generalization bound with -distance, demonstrating such auxiliary task can imposes a constraint which tightens the bound and thereby improves generalization. The experimental results demonstrate superior performance compared to the existing baselines in handling both time and regional domain graph shifts.

</details>


### [106] [Quantization Blindspots: How Model Compression Breaks Backdoor Defenses](https://arxiv.org/abs/2512.06243)
*Rohan Pandey,Eric Ye*

Main category: cs.LG

TL;DR: 量化（INT8/INT4）显著降低现有后门防御检测率至0%，而后门攻击成功率仍保持90%以上，暴露了防御评估与模型实际部署之间的不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界ML系统部署时普遍采用量化技术（INT8或更低精度）来减少内存和延迟，但现有的后门防御研究主要在FP32精度下评估，这种评估方式与实际部署情况存在脱节。

Method: 对五种代表性后门防御方法进行系统性实证研究，在三种精度设置（FP32、INT8动态量化、INT4模拟量化）和两个标准视觉基准（GTSRB、CIFAR-10）上，使用经典的BadNet攻击进行测试。

Result: INT8量化将所有防御方法的检测率降至0%，而攻击成功率仍高于99%。INT4量化表现出明显的数据集依赖性：Neural Cleanse在GTSRB上有效但在CIFAR-10上失效，而后门攻击在量化后仍保持90%以上的成功率。

Conclusion: 量化鲁棒性应成为未来后门防御评估和设计的必要维度，需要解决防御评估（FP32）与模型实际部署（量化形式）之间的不匹配问题。

Abstract: Backdoor attacks embed input-dependent malicious behavior into neural networks while preserving high clean accuracy, making them a persistent threat for deployed ML systems. At the same time, real-world deployments almost never serve full-precision models: post-training quantization to INT8 or lower precision is now standard practice for reducing memory and latency. This work asks a simple question: how do existing backdoor defenses behave under standard quantization pipelines? We conduct a systematic empirical study of five representative defenses across three precision settings (FP32, INT8 dynamic, INT4 simulated) and two standard vision benchmarks using a canonical BadNet attack. We observe that INT8 quantization reduces the detection rate of all evaluated defenses to 0% while leaving attack success rates above 99%. For INT4, we find a pronounced dataset dependence: Neural Cleanse remains effective on GTSRB but fails on CIFAR-10, even though backdoors continue to survive quantization with attack success rates above 90%. Our results expose a mismatch between how defenses are commonly evaluated (on FP32 models) and how models are actually deployed (in quantized form), and they highlight quantization robustness as a necessary axis in future evaluations and designs of backdoor defenses.

</details>


### [107] [Auto-exploration for online reinforcement learning](https://arxiv.org/abs/2512.06244)
*Caleb Ju,Guanghui Lan*

Main category: cs.LG

TL;DR: 提出具有自动探索功能的新RL方法，无需先验参数知识，实现O(ε⁻²)样本复杂度


<details>
  <summary>Details</summary>
Motivation: 现有RL算法需要假设充分的探索，导致算法不可实现且性能次优，需要参数无关的自动探索方法

Method: 提出两种变体：表格设置和线性函数逼近，采用动态混合时间、折扣状态分布采样、鲁棒梯度估计器和优势差距函数

Result: 在存在探索最优策略的假设下，两种方法都达到O(ε⁻²)样本复杂度，且复杂度不包含算法依赖参数

Conclusion: 新方法实现了参数无关的自动探索，简单易实现，解决了传统RL算法的探索-利用困境

Abstract: The exploration-exploitation dilemma in reinforcement learning (RL) is a fundamental challenge to efficient RL algorithms. Existing algorithms for finite state and action discounted RL problems address this by assuming sufficient exploration over both state and action spaces. However, this yields non-implementable algorithms and sub-optimal performance. To resolve these limitations, we introduce a new class of methods with auto-exploration, or methods that automatically explore both state and action spaces in a parameter-free way, i.e.,~without a priori knowledge of problem-dependent parameters. We present two variants: one for the tabular setting and one for linear function approximation. Under algorithm-independent assumptions on the existence of an exploring optimal policy, both methods attain $O(ε^{-2})$ sample complexity to solve to $ε$ error. Crucially, these complexities are novel since they are void of algorithm-dependent parameters seen in prior works, which may be arbitrarily large. The methods are also simple to implement because they are parameter-free and do not directly estimate the unknown parameters. These feats are achieved by new algorithmic innovations for RL, including a dynamic mixing time, a discounted state distribution for sampling, a simple robust gradient estimator, and a recent advantage gap function to certify convergence.

</details>


### [108] [Learning When to Switch: Adaptive Policy Selection via Reinforcement Learning](https://arxiv.org/abs/2512.06250)
*Chris Tava*

Main category: cs.LG

TL;DR: 提出基于强化学习的自适应策略切换方法，让智能体在迷宫导航中动态切换系统探索和目标导向策略，相比固定阈值方法显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 自主智能体需要多种策略解决复杂任务，但何时切换策略是挑战。现有固定阈值方法不够灵活，需要设计启发式规则或先验知识。

Method: 使用Q-learning学习两个正交导航策略（系统探索和目标导向）之间的切换阈值。将状态空间离散化为覆盖率和距离桶，基于覆盖百分比和目标距离自适应调整切换阈值（20-60%）。仅需迷宫尺寸和目标位置等最小领域知识。

Result: 在240个测试配置中，自适应阈值学习优于单策略智能体和固定40%阈值基线：完成时间提升23-55%，运行时方差减少83%，最坏情况改善71%。性能增益随问题复杂度增加而扩大。

Conclusion: 强化学习驱动的自适应策略切换能有效提升自主智能体在复杂任务中的性能，无需先验知识或手工启发式规则。随着问题复杂度增加，自适应方法相比固定启发式的优势更加明显。

Abstract: Autonomous agents often require multiple strategies to solve complex tasks, but determining when to switch between strategies remains challenging. This research introduces a reinforcement learning technique to learn switching thresholds between two orthogonal navigation policies. Using maze navigation as a case study, this work demonstrates how an agent can dynamically transition between systematic exploration (coverage) and goal-directed pathfinding (convergence) to improve task performance. Unlike fixed-threshold approaches, the agent uses Q-learning to adapt switching behavior based on coverage percentage and distance to goal, requiring only minimal domain knowledge: maze dimensions and target location. The agent does not require prior knowledge of wall positions, optimal threshold values, or hand-crafted heuristics; instead, it discovers effective switching strategies dynamically during each run. The agent discretizes its state space into coverage and distance buckets, then adapts which coverage threshold (20-60\%) to apply based on observed progress signals. Experiments across 240 test configurations (4 maze sizes from 16$\times$16 to 128$\times$128 $\times$ 10 unique mazes $\times$ 6 agent variants) demonstrate that adaptive threshold learning outperforms both single-strategy agents and fixed 40\% threshold baselines. Results show 23-55\% improvements in completion time, 83\% reduction in runtime variance, and 71\% improvement in worst-case scenarios. The learned switching behavior generalizes within each size class to unseen wall configurations. Performance gains scale with problem complexity: 23\% improvement for 16$\times$16 mazes, 34\% for 32$\times$32, and 55\% for 64$\times$64, demonstrating that as the space of possible maze structures grows, the value of adaptive policy selection over fixed heuristics increases proportionally.

</details>


### [109] [Learning Without Time-Based Embodiment Resets in Soft-Actor Critic](https://arxiv.org/abs/2512.06252)
*Homayoon Farrahi,A. Rupam Mahmood*

Main category: cs.LG

TL;DR: 研究探索在无终止和无重置条件下强化学习，提出持续SAC算法并分析重置对探索的重要性，通过增加策略熵来补偿无重置的性能损失


<details>
  <summary>Details</summary>
Motivation: 传统强化学习任务常使用终止和重置等辅助组件加速学习，但这些设置不自然且可能阻碍现实世界的长期性能。研究探索在没有终止和机器人身体重置条件下的学习挑战。

Method: 提出持续SAC算法，通过简单修改奖励函数实现无终止学习。分析无重置条件下的学习失败原因，提出通过增加策略熵来改善探索。

Result: 持续SAC在无终止条件下表现与或优于周期性SAC，且降低对折扣率γ的敏感性。无重置会导致状态空间探索不足和学习失败，增加策略熵能有效恢复性能。

Conclusion: 身体重置对SAC算法的状态空间探索至关重要，无重置条件下通过增加策略熵可以补偿探索不足，使学习在无终止和无重置条件下仍能有效进行。

Abstract: When creating new reinforcement learning tasks, practitioners often accelerate the learning process by incorporating into the task several accessory components, such as breaking the environment interaction into independent episodes and frequently resetting the environment. Although they can enable the learning of complex intelligent behaviors, such task accessories can result in unnatural task setups and hinder long-term performance in the real world. In this work, we explore the challenges of learning without episode terminations and robot embodiment resets using the Soft Actor-Critic (SAC) algorithm. To learn without terminations, we present a continuing version of the SAC algorithm and show that, with simple modifications to the reward functions of existing tasks, continuing SAC can perform as well as or better than episodic SAC while reducing the sensitivity of performance to the value of the discount rate $γ$. On a modified Gym Reacher task, we investigate possible explanations for the failure of continuing SAC when learning without embodiment resets. Our results suggest that embodiment resets help with exploration of the state space in the SAC algorithm, and removing embodiment resets can lead to poor exploration of the state space and failure of or significantly slower learning. Finally, on additional simulated tasks and a real-robot vision task, we show that increasing the entropy of the policy when performance trends worse or remains static is an effective intervention for recovering the performance lost due to not using embodiment resets.

</details>


### [110] [Networked Restless Multi-Arm Bandits with Reinforcement Learning](https://arxiv.org/abs/2512.06274)
*Hanmo Zhang,Zenghui Sun,Kai Wang*

Main category: cs.LG

TL;DR: 该论文提出了Networked RMAB框架，将传统多臂老虎机与独立级联模型结合以捕捉网络环境中的个体交互，通过证明Bellman方程的子模性并应用爬山算法获得近似保证，开发了高效的Q学习算法并在真实图数据上验证了其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统Restless Multi-Armed Bandits（RMABs）假设各臂独立，无法捕捉现实世界中个体间的交互作用，这在公共卫生等资源分配和干预优化应用中尤为重要。网络环境中的个体互动可能显著影响决策效果。

Method: 提出Networked RMAB框架，将RMAB模型与独立级联模型结合以建模网络环境中的个体交互。通过证明Bellman方程的子模性，应用爬山算法获得1-1/e的近似保证，并开发了针对网络设置的Q学习算法。

Result: 理论分析表明Bellman更新具有1-1/e的近似保证且保证收敛。在真实图数据上的实验结果显示，提出的Q学习方法优于k步前瞻方法和忽略网络的方法，验证了捕捉网络效应的重要性。

Conclusion: Networked RMAB框架成功解决了传统RMAB忽略网络交互的局限性，通过理论分析和实验验证展示了在网络环境中考虑个体互动能显著提升决策性能，为资源分配和干预优化提供了更有效的工具。

Abstract: Restless Multi-Armed Bandits (RMABs) are a powerful framework for sequential decision-making, widely applied in resource allocation and intervention optimization challenges in public health. However, traditional RMABs assume independence among arms, limiting their ability to account for interactions between individuals that can be common and significant in a real-world environment. This paper introduces Networked RMAB, a novel framework that integrates the RMAB model with the independent cascade model to capture interactions between arms in networked environments. We define the Bellman equation for networked RMAB and present its computational challenge due to exponentially large action and state spaces. To resolve the computational challenge, we establish the submodularity of Bellman equation and apply the hill-climbing algorithm to achieve a $1-\frac{1}{e}$ approximation guarantee in Bellman updates. Lastly, we prove that the approximate Bellman updates are guaranteed to converge by a modified contraction analysis. We experimentally verify these results by developing an efficient Q-learning algorithm tailored to the networked setting. Experimental results on real-world graph data demonstrate that our Q-learning approach outperforms both $k$-step look-ahead and network-blind approaches, highlighting the importance of capturing and leveraging network effects where they exist.

</details>


### [111] [Theoretical Compression Bounds for Wide Multilayer Perceptrons](https://arxiv.org/abs/2512.06288)
*Houssam El Cheairi,David Gamarnik,Rahul Mazumder*

Main category: cs.LG

TL;DR: 本文提出了一种随机贪心压缩算法，用于后训练剪枝和量化，并理论证明了多层感知机（MLP）和卷积神经网络（CNN）中存在性能优异的剪枝/量化子网络。


<details>
  <summary>Details</summary>
Motivation: 尽管剪枝和量化技术在实践中能有效减少大型神经网络的参数量，但其理论依据不足。本文旨在为这些压缩技术的经验成功提供理论支持，弥合理论与应用之间的差距。

Method: 提出了一种随机贪心压缩算法，可视为后训练随机版本的Optimal Brain Damage（OBD）。该算法用于多层感知机（MLP）的结构化剪枝和量化，并扩展到卷积神经网络（CNN）。

Result: 理论证明了在宽神经网络中存在性能具有竞争力的剪枝/量化子网络，展示了压缩性与网络宽度之间的权衡关系。结果不依赖于数据假设，为压缩技术在多层感知机中的经验成功提供了理论依据。

Conclusion: 本文为剪枝和量化技术的经验成功提供了严格的理论支持，证明了在宽神经网络中存在高性能的压缩子网络，弥合了压缩技术的理论与应用之间的差距。

Abstract: Pruning and quantization techniques have been broadly successful in reducing the number of parameters needed for large neural networks, yet theoretical justification for their empirical success falls short. We consider a randomized greedy compression algorithm for pruning and quantization post-training and use it to rigorously show the existence of pruned/quantized subnetworks of multilayer perceptrons (MLPs) with competitive performance. We further extend our results to structured pruning of MLPs and convolutional neural networks (CNNs), thus providing a unified analysis of pruning in wide networks. Our results are free of data assumptions, and showcase a tradeoff between compressibility and network width. The algorithm we consider bears some similarities with Optimal Brain Damage (OBD) and can be viewed as a post-training randomized version of it. The theoretical results we derive bridge the gap between theory and application for pruning/quantization, and provide a justification for the empirical success of compression in wide multilayer perceptrons.

</details>


### [112] [Importance-aware Topic Modeling for Discovering Public Transit Risk from Noisy Social Media](https://arxiv.org/abs/2512.06293)
*Fatima Ashraf,Muhammad Ayub Sabir,Jiaxin Deng,Junbiao Pang,Haitao Yu*

Main category: cs.LG

TL;DR: 该论文提出了一种基于社交媒体的城市交通服务风险监测方法，通过联合建模语言交互和用户影响力，构建影响力加权的关键词共现图，并使用泊松反卷积分解提取可解释的主题结构。


<details>
  <summary>Details</summary>
Motivation: 城市交通机构越来越多地使用社交媒体监测服务风险（如拥挤、延误、安全事故），但相关信号稀疏、简短且容易被日常聊天淹没，需要更有效的方法来提取有意义的主题。

Method: 首先构建影响力加权的关键词共现图，使有社会影响力的帖子按比例贡献证据；然后使用泊松反卷积分解将图分解为低秩主题结构和主题局部残差交互；加入去相关正则化器促进主题区分；通过一致性驱动的扫描选择主题数量。

Result: 在大规模社交数据流上，该模型实现了最先进的主题一致性，与领先基线相比具有强多样性，能够有效提取城市交通服务风险相关的主题。

Conclusion: 提出的框架能够从稀疏、嘈杂的社交媒体数据中有效提取可解释的主题，为城市交通机构提供更好的服务风险监测工具，代码和数据集已公开。

Abstract: Urban transit agencies increasingly turn to social media to monitor emerging service risks such as crowding, delays, and safety incidents, yet the signals of concern are sparse, short, and easily drowned by routine chatter. We address this challenge by jointly modeling linguistic interactions and user influence. First, we construct an influence-weighted keyword co-occurrence graph from cleaned posts so that socially impactful posts contributes proportionally to the underlying evidence. The core of our framework is a Poisson Deconvolution Factorization (PDF) that decomposes this graph into a low-rank topical structure and topic-localized residual interactions, producing an interpretable topic--keyword basis together with topic importance scores. A decorrelation regularizer \emph{promotes} distinct topics, and a lightweight optimization procedure ensures stable convergence under nonnegativity and normalization constraints. Finally, the number of topics is selected through a coherence-driven sweep that evaluates the quality and distinctness of the learned topics. On large-scale social streams, the proposed model achieves state-of-the-art topic coherence and strong diversity compared with leading baselines. The code and dataset are publicly available at https://github.com/pangjunbiao/Topic-Modeling_ITS.git

</details>


### [113] [Entropic Confinement and Mode Connectivity in Overparameterized Neural Networks](https://arxiv.org/abs/2512.06297)
*Luca Di Carlo,Chase Goddard,David J. Schwab*

Main category: cs.LG

TL;DR: 神经网络损失函数景观中的吸引盆通过低损失路径连接，但优化动态通常局限于单个凸盆，很少探索中间点。该研究通过识别曲率变化与优化噪声相互作用产生的熵势垒来解释这一悖论。


<details>
  <summary>Details</summary>
Motivation: 解决神经网络优化中的一个关键悖论：虽然损失景观中的吸引盆通过低损失路径连接，但优化算法通常只停留在单个凸盆内，很少探索中间区域。需要理解这种连接性与实际优化行为之间的差异。

Method: 通过分析曲率变化与优化动态噪声的相互作用，识别熵势垒的形成机制。实证研究发现，沿着连接路径远离最小值时曲率系统性上升，产生将噪声动态偏转回端点的有效力。

Result: 发现曲率变化产生的熵势垒比能量势垒持续更长时间，主导了参数空间中解的后期定位。即使损失保持平坦，这些势垒仍然存在并限制优化动态的探索。

Conclusion: 曲率诱导的熵力在深度学习景观中同时控制着连接性和限制性，解释了为什么优化算法很少探索连接路径上的中间点，尽管这些路径在损失景观中是连通的。

Abstract: Modern neural networks exhibit a striking property: basins of attraction in the loss landscape are often connected by low-loss paths, yet optimization dynamics generally remain confined to a single convex basin and rarely explore intermediate points. We resolve this paradox by identifying entropic barriers arising from the interplay between curvature variations along these paths and noise in optimization dynamics. Empirically, we find that curvature systematically rises away from minima, producing effective forces that bias noisy dynamics back toward the endpoints - even when the loss remains nearly flat. These barriers persist longer than energetic barriers, shaping the late-time localization of solutions in parameter space. Our results highlight the role of curvature-induced entropic forces in governing both connectivity and confinement in deep learning landscapes.

</details>


### [114] [Chemistry Integrated Language Model using Hierarchical Molecular Representation for Polymer Informatics](https://arxiv.org/abs/2512.06301)
*Jihun Ahn,Gabriella Pasya Irianti,Vikram Thapar,Su-Mi Hur*

Main category: cs.LG

TL;DR: CI-LLM框架结合HAPPY分子表示和数值描述符，实现了聚合物性质预测和逆向设计，解决了聚合物机器学习中的数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 机器学习已成功应用于无机化合物和小分子材料发现，但聚合物领域仍难以应用这些方法。虽然数据稀缺常被认为是主要瓶颈，但研究表明通过策略性分子表示可以克服这一限制。

Method: 提出CI-LLM框架，结合HAPPY（分层抽象聚合物重复单元）表示法，将化学子结构编码为token，并与数值描述符一起集成到transformer架构中。使用De$^3$BERTa进行性质预测，基于GPT的生成器进行逆向设计。

Result: De$^3$BERTa比基于SMILES的模型推理速度快3.5倍，在四个性质上的R²分数提升0.9-4.1%。GPT生成器实现100%骨架保留，成功优化负相关目标的多性质设计。

Conclusion: 通过策略性分子表示，CI-LLM框架展示了聚合物科学中机器学习的前向预测和逆向设计能力，为聚合物材料发现提供了全面解决方案。

Abstract: Machine learning has transformed material discovery for inorganic compounds and small molecules, yet polymers remain largely inaccessible to these methods. While data scarcity is often cited as the primary bottleneck, we demonstrate that strategic molecular representations can overcome this limitation. We introduce CI-LLM (Chemically Informed Language Model), a framework combining HAPPY (Hierarchically Abstracted rePeat unit of PolYmer), which encodes chemical substructures as tokens, with numerical descriptors within transformer architectures. For property prediction, De$^3$BERTa, our descriptor-enriched encoder, achieves 3.5x faster inference than SMILES-based models with improved accuracy ($R^2$ score gains of 0.9-4.1 percent across four properties), while providing interpretable structure-property insights at the subgroup level. For inverse design, our GPT-based generator produces polymers with targeted properties, achieving 100 percent scaffold retention and successful multi-property optimization for negatively correlated objectives. This comprehensive framework demonstrates both forward prediction and inverse design capabilities, showcasing how strategic molecular representation advances machine learning applications in polymer science.

</details>


### [115] [Multimodal Graph Neural Networks for Prognostic Modeling of Brain Network Reorganization](https://arxiv.org/abs/2512.06303)
*Preksha Girish,Rachana Mysore,Kiran K. N.,Hiranmayee R.,Shipra Prashanth,Shrey Kumar*

Main category: cs.LG

TL;DR: 提出多模态图神经网络框架，整合结构MRI、扩散张量成像和功能MRI，建模脑网络的时空重组动态，生成可解释的生物标志物用于预测认知衰退风险。


<details>
  <summary>Details</summary>
Motivation: 理解脑网络的动态重组对于预测认知衰退、神经疾病进展和个体临床结果变异性至关重要。现有方法需要新的数据收集，而本研究旨在从现有影像数据中提取临床意义的生物标志物。

Method: 提出多模态图神经网络框架：将脑区表示为节点，结构和功能连接表示为边，构建纵向脑图。使用分数随机微分算子嵌入图循环网络，捕捉长期依赖和随机波动。注意力机制融合多模态信息，生成网络能量熵、图曲率、分数记忆指数等可解释生物标志物，组合成预后指数。

Result: 在纵向神经影像数据集上的实验证明了预测准确性和可解释性。该方法能够从现有影像数据中提取临床意义的生物标志物，无需新数据收集。

Conclusion: 数学严谨的多模态图方法具有从现有影像数据中提取临床意义生物标志物的潜力，为预测网络不稳定性和认知衰退风险提供了有效框架。

Abstract: Understanding the dynamic reorganization of brain networks is critical for predicting cognitive decline, neurological progression, and individual variability in clinical outcomes. This work proposes a multimodal graph neural network framework that integrates structural MRI, diffusion tensor imaging, and functional MRI to model spatiotemporal brain network reorganization. Brain regions are represented as nodes and structural and functional connectivity as edges, forming longitudinal brain graphs for each subject. Temporal evolution is captured via fractional stochastic differential operators embedded within graph-based recurrent networks, enabling the modeling of long-term dependencies and stochastic fluctuations in network dynamics. Attention mechanisms fuse multimodal information and generate interpretable biomarkers, including network energy entropy, graph curvature, fractional memory indices, and modality-specific attention scores. These biomarkers are combined into a composite prognostic index to quantify individual risk of network instability or cognitive decline. Experiments on longitudinal neuroimaging datasets demonstrate both predictive accuracy and interpretability. The results highlight the potential of mathematically rigorous, multimodal graph-based approaches for deriving clinically meaningful biomarkers from existing imaging data without requiring new data collection.

</details>


### [116] [Interpretive Efficiency: Information-Geometric Foundations of Data Usefulness](https://arxiv.org/abs/2512.06341)
*Ronald Katende*

Main category: cs.LG

TL;DR: 提出Interpretive Efficiency（解释效率）这一新指标，用于量化解释性表示如何有效传递任务相关信息，具有理论保证和实际应用价值。


<details>
  <summary>Details</summary>
Motivation: 当前可解释性指标很少能有效量化数据对解释性表示的支持程度，需要一种理论严谨且实用的度量方法来评估解释性表示的设计质量。

Method: 提出Interpretive Efficiency这一归一化、任务感知的函数，基于五个公理（有界性、Blackwell式单调性、数据处理稳定性、容许不变性、渐近一致性），将其与互信息关联，推导局部Fisher几何展开，并使用经验过程工具建立渐近和有限样本估计保证。

Result: 在受控图像和信号任务上的实验表明，该度量能恢复理论排序、揭示被准确性掩盖的表示冗余，并与鲁棒性相关，成为表示设计的实用理论支持诊断工具。

Conclusion: Interpretive Efficiency是一个理论严谨、实用的解释性表示评估指标，为表示设计提供了可靠的理论支持诊断工具。

Abstract: Interpretability is central to trustworthy machine learning, yet existing metrics rarely quantify how effectively data support an interpretive representation. We propose Interpretive Efficiency, a normalized, task-aware functional that measures the fraction of task-relevant information transmitted through an interpretive channel. The definition is grounded in five axioms ensuring boundedness, Blackwell-style monotonicity, data-processing stability, admissible invariance, and asymptotic consistency. We relate the functional to mutual information and derive a local Fisher-geometric expansion, then establish asymptotic and finite-sample estimation guarantees using standard empirical-process tools. Experiments on controlled image and signal tasks demonstrate that the measure recovers theoretical orderings, exposes representational redundancy masked by accuracy, and correlates with robustness, making it a practical, theory-backed diagnostic for representation design.

</details>


### [117] [When Distance Distracts: Representation Distance Bias in BT-Loss for Reward Models](https://arxiv.org/abs/2512.06343)
*Tong Xie,Andrew Bai,Yuanhao Ban,Yunqi Hong,Haoyu Li,Cho-jui Hsieh*

Main category: cs.LG

TL;DR: 论文分析了Bradley-Terry损失函数的梯度问题，发现其受表示距离影响，导致小距离对更新弱、大距离对更新强，提出了NormBT归一化方案来平衡这种效应。


<details>
  <summary>Details</summary>
Motivation: 标准Bradley-Terry损失函数在奖励建模中存在梯度问题：梯度范数不仅取决于预测误差（选择的与拒绝的响应之间的奖励差），还受最后一层表示空间中表示距离的影响。这导致小距离对即使被错误排序也获得弱更新，而大距离对获得过强更新，影响学习效果。

Method: 提出NormBT方法，一种自适应成对归一化方案。通过平衡表示驱动效应，将学习信号集中在预测误差上。NormBT是轻量级的，可直接集成到BT损失中，开销可忽略。

Result: 在各种LLM骨干网络和数据集上，NormBT持续提升奖励模型性能。在RewardBench的推理类别中（包含许多小距离对）获得了超过5%的显著提升。

Conclusion: 这项工作揭示了广泛使用的BT目标函数的关键局限性，并提供了一种简单有效的修正方案，通过归一化表示距离效应来改善奖励模型学习。

Abstract: Reward models are central to Large Language Model (LLM) alignment within the framework of RLHF. The standard objective used in reward modeling is the Bradley-Terry (BT) loss, which learns from pairwise data consisting of a pair of chosen and rejected responses. In this work, we analyze the per-sample gradient of BT-loss and show that its norm scales with two distinct components: (1) the difference in predicted rewards between chosen and rejected responses, which reflects the prediction error, and critically, (2) representation distance between the pair measured in the output space of the final layer. While the first term captures the intended training signal, we show that the second term can significantly impact the update magnitude and misalign learning. Specifically, pairs with small representation distance often receive vanishingly weak updates, even when misranked, while pairs with large distance receive disproportionately strong updates. This leads to gradients from large-distance pairs to overshadow those from small-distance pairs, where fine-grained distinctions are especially important. To overcome this limitation, we propose NormBT, an adaptive pair-wise normalization scheme that balances representation-driven effects and focuses learning signals on prediction error. NormBT is a lightweight, drop-in integration to BT loss with negligible overhead. Across various LLM backbones and datasets, NormBT improves reward model performance consistently, with notable gains of over 5% on the Reasoning category of RewardBench, which contains numerous small-distance pairs. This work reveals a key limitation in the widely used BT objective and provides a simple, effective correction.

</details>


### [118] [Zero Generalization Error Theorem for Random Interpolators via Algebraic Geometry](https://arxiv.org/abs/2512.06347)
*Naoki Yoshida,Isao Ishikawa,Masaaki Imaizumi*

Main category: cs.LG

TL;DR: 在师生框架下，随机采样插值器的泛化误差在训练样本超过阈值后会变为零，该阈值由参数空间中插值器集合的几何结构决定。


<details>
  <summary>Details</summary>
Motivation: 理解大规模模型（如深度神经网络）的高泛化能力是机器学习理论的核心开放问题。虽然现有理论将这种现象归因于SGD向良好泛化解的隐式偏置，但实证证据表明这主要源于模型本身的性质——即使是随机采样的插值器（达到零训练误差的参数）也能有效泛化。

Method: 在师生框架下，使用代数几何工具数学刻画插值器集合在参数空间中的几何结构，证明随机采样插值器的泛化误差在训练样本超过特定阈值后会变为零。

Result: 证明了随机采样插值器的泛化误差在训练样本数量超过由插值器集合几何结构决定的阈值后会精确变为零。

Conclusion: 模型本身的性质（而非优化算法）是导致高泛化能力的关键因素，随机插值器在足够样本下也能实现完美泛化，这为理解大规模模型的泛化能力提供了新的理论视角。

Abstract: We theoretically demonstrate that the generalization error of interpolators for machine learning models under teacher-student settings becomes 0 once the number of training samples exceeds a certain threshold. Understanding the high generalization ability of large-scale models such as deep neural networks (DNNs) remains one of the central open problems in machine learning theory. While recent theoretical studies have attributed this phenomenon to the implicit bias of stochastic gradient descent (SGD) toward well-generalizing solutions, empirical evidences indicate that it primarily stems from properties of the model itself. Specifically, even randomly sampled interpolators, which are parameters that achieve zero training error, have been observed to generalize effectively. In this study, under a teacher-student framework, we prove that the generalization error of randomly sampled interpolators becomes exactly zero once the number of training samples exceeds a threshold determined by the geometric structure of the interpolator set in parameter space. As a proof technique, we leverage tools from algebraic geometry to mathematically characterize this geometric structure.

</details>


### [119] [LLM-Upgraded Graph Reinforcement Learning for Carbon-Aware Job Scheduling in Smart Manufacturing](https://arxiv.org/abs/2512.06351)
*Zhiying Yang,Fang Liu,Wei Zhang,Xin Lou,Malcolm Yoke Hean Low,Boon Ping Gan*

Main category: cs.LG

TL;DR: LUCA是一个结合图神经网络和大语言模型的强化学习框架，用于碳感知柔性作业车间调度，在保持相同排放水平下显著降低制造周期


<details>
  <summary>Details</summary>
Motivation: 解决智能制造系统中动态和可持续调度的挑战，需要同时优化制造周期和碳排放目标

Method: 集成图神经网络和LLM，通过精心设计的提示策略生成融合嵌入，捕捉调度状态的结构特征和上下文语义，然后由深度强化学习策略网络生成实时调度决策

Result: 在合成数据集上平均降低4.1%，最高降低12.2%的制造周期（相同排放水平）；在公共数据集上对制造周期和排放都有额外增益

Conclusion: LUCA在智能制造碳感知调度中既有效又实用，能够同时优化能源效率和调度及时性

Abstract: This paper presents \textsc{Luca}, a \underline{l}arge language model (LLM)-\underline{u}pgraded graph reinforcement learning framework for \underline{c}arbon-\underline{a}ware flexible job shop scheduling. \textsc{Luca} addresses the challenges of dynamic and sustainable scheduling in smart manufacturing systems by integrating a graph neural network and an LLM, guided by a carefully designed in-house prompting strategy, to produce a fused embedding that captures both structural characteristics and contextual semantics of the latest scheduling state. This expressive embedding is then processed by a deep reinforcement learning policy network, which generates real-time scheduling decisions optimized for both makespan and carbon emission objectives. To support sustainability goals, \textsc{Luca} incorporates a dual-objective reward function that encourages both energy efficiency and scheduling timeliness. Experimental results on both synthetic and public datasets demonstrate that \textsc{Luca} consistently outperforms comparison algorithms. For instance, on the synthetic dataset, it achieves an average of 4.1\% and up to 12.2\% lower makespan compared to the best-performing comparison algorithm while maintaining the same emission level. On public datasets, additional gains are observed for both makespan and emission. These results demonstrate that \textsc{Luca} is effective and practical for carbon-aware scheduling in smart manufacturing.

</details>


### [120] [DDFI: Diverse and Distribution-aware Missing Feature Imputation via Two-step Reconstruction](https://arxiv.org/abs/2512.06356)
*Yifan Song,Fenglin Yu,Yihong Luo,Xingjian Tao,Siya Qiu,Kai Han,Jing Tang*

Main category: cs.LG

TL;DR: DDFI：一种结合特征传播和图掩码自编码器的多样化、分布感知缺失特征填补方法，解决图神经网络中节点特征不完整问题


<details>
  <summary>Details</summary>
Motivation: 现实世界图中节点特征普遍不完整（如用户隐私属性），导致GNN性能显著下降。现有特征传播方法存在三个问题：1）难以处理非全连接图；2）填补特征面临过平滑问题；3）仅适用于直推式任务，忽略归纳式任务中的特征分布偏移。

Method: 提出DDFI方法：1）设计CLL算法，随机连接训练集中相同标签的节点以增强多连通分量图的性能；2）在推理阶段采用新颖的两步表示生成过程，通过整个MAE重构特征而非直接使用FP填补特征，减少归纳任务中的特征分布偏移并增强特征多样性。

Result: 在六个公共数据集和新收集的Sailing数据集（包含自然缺失特征的航海记录）上进行了广泛实验，DDFI在直推式和归纳式设置下均优于现有最先进方法。

Conclusion: DDFI通过结合特征传播和图掩码自编码器，有效解决了图神经网络中缺失特征填补的三个关键问题，并在真实和模拟缺失场景中都表现出优越性能。

Abstract: Incomplete node features are ubiquitous in real-world scenarios, e.g., the attributes of web users may be partly private, which causes the performance of Graph Neural Networks (GNNs) to decline significantly. Feature propagation (FP) is a well-known method that performs well for imputation of missing node features on graphs, but it still has the following three issues: 1) it struggles with graphs that are not fully connected, 2) imputed features face the over-smoothing problem, and 3) FP is tailored for transductive tasks, overlooking the feature distribution shift in inductive tasks. To address these challenges, we introduce DDFI, a Diverse and Distribution-aware Missing Feature Imputation method that combines feature propagation with a graph-based Masked AutoEncoder (MAE) in a nontrivial manner. It first designs a simple yet effective algorithm, namely Co-Label Linking (CLL), that randomly connects nodes in the training set with the same label to enhance the performance on graphs with numerous connected components. Then we develop a novel two-step representation generation process at the inference stage. Specifically, instead of directly using FP-imputed features as input during inference, DDFI further reconstructs the features through the whole MAE to reduce feature distribution shift in the inductive tasks and enhance the diversity of node features. Meanwhile, since existing feature imputation methods for graphs only evaluate by simulating the missing scenes with manually masking the features, we collect a new dataset called Sailing from the records of voyages that contains naturally missing features to help better evaluate the effectiveness. Extensive experiments conducted on six public datasets and Sailing show that DDFI outperforms the state-of-the-art methods under both transductive and inductive settings.

</details>


### [121] [Proportional integral derivative booster for neural networks-based time-series prediction: Case of water demand prediction](https://arxiv.org/abs/2512.06357)
*Tony Sallooma,Okyay Kaynak,Xinbo Yub,Wei He*

Main category: cs.LG

TL;DR: 提出基于PID控制的增强方法，用于提升神经网络在多步时间序列预测中的准确性，同时保持系统复杂度基本不变。


<details>
  <summary>Details</summary>
Motivation: 多步时间序列预测在工业决策中至关重要，但现有神经网络方法结构复杂，影响预测精度。需要一种既能提升性能又不显著增加系统复杂度的方法。

Method: 受PID控制方法启发，在每个时间步对神经网络的预测值进行PID校正，使其更接近真实值。该方法作为"增强器"应用于现有神经网络模型上。

Result: 在水需求预测和小时能耗预测两个案例研究中，应用PID增强方法后的模型在预测精度上显著优于原始模型，同时系统复杂度基本保持不变。

Conclusion: PID增强方法能有效提升神经网络在多步周期性时间序列预测中的准确性，且不显著增加系统复杂度，具有广泛适用性。

Abstract: Multi-step time-series prediction is an essential supportive step for decision-makers in several industrial areas. Artificial intelligence techniques, which use a neural network component in various forms, have recently frequently been used to accomplish this step. However, the complexity of the neural network structure still stands up as a critical problem against prediction accuracy. In this paper, a method inspired by the proportional-integral-derivative (PID) control approach is investigated to enhance the performance of neural network models used for multi-step ahead prediction of periodic time-series information while maintaining a negligible impact on the complexity of the system. The PID-based method is applied to the predicted value at each time step to bring that value closer to the real value. The water demand forecasting problem is considered as a case study, where two deep neural network models from the literature are used to prove the effectiveness of the proposed boosting method. Furthermore, to prove the applicability of this PID-based booster to other types of periodic time-series prediction problems, it is applied to enhance the accuracy of a neural network model used for multi-step forecasting of hourly energy consumption. The comparison between the results of the original prediction models and the results after using the proposed technique demonstrates the superiority of the proposed method in terms of prediction accuracy and system complexity.

</details>


### [122] [Optimizing Optimizers for Fast Gradient-Based Learning](https://arxiv.org/abs/2512.06370)
*Jaerin Lee,Kyoung Mu Lee*

Main category: cs.LG

TL;DR: 该论文为梯度学习中的优化器自动化设计建立了理论基础，通过贪婪原则将优化器设计问题转化为最大化损失瞬时下降的凸优化问题，能够推导出多种流行优化器及其最优超参数。


<details>
  <summary>Details</summary>
Motivation: 当前优化器设计主要依赖经验和启发式方法，缺乏系统化的理论基础。作者希望建立自动化优化器设计的理论框架，使优化器设计和超参数调优能够基于数学原理而非经验。

Method: 基于贪婪原则，将优化器设计问题形式化为最大化损失瞬时下降。将优化器视为将梯度信号映射为参数更新的函数，转化为一系列凸优化问题。在不同约束条件下求解这些问题，推导出优化器的闭式解。

Result: 该方法不仅能够恢复多种流行优化器（如SGD、Adam等）作为闭式解，还能自动推导出针对具体问题的最优超参数。实现了基于训练过程中收集的梯度统计信息来系统化设计优化器和调优超参数。

Conclusion: 建立了自动化优化器设计的理论基础，实现了"优化的优化"，能够在训练过程中动态调整优化器设计，为梯度学习提供了系统化的优化器设计方法。

Abstract: We lay the theoretical foundation for automating optimizer design in gradient-based learning. Based on the greedy principle, we formulate the problem of designing optimizers as maximizing the instantaneous decrease in loss. By treating an optimizer as a function that translates loss gradient signals into parameter motions, the problem reduces to a family of convex optimization problems over the space of optimizers. Solving these problems under various constraints not only recovers a wide range of popular optimizers as closed-form solutions, but also produces the optimal hyperparameters of these optimizers with respect to the problems at hand. This enables a systematic approach to design optimizers and tune their hyperparameters according to the gradient statistics that are collected during the training process. Furthermore, this optimization of optimization can be performed dynamically during training.

</details>


### [123] [RLAX: Large-Scale, Distributed Reinforcement Learning for Large Language Models on TPUs](https://arxiv.org/abs/2512.06392)
*Runlong Zhou,Lefan Zhang,Shang-Chen Wu,Kelvin Zou,Hanzhi Zhou,Ke Ye,Yihao Feng,Dong Yin,Alex Guillen Garcia,Dmytro Babych,Rohit Chatterjee,Matthew Hopkins,Xiang Kong,Chang Lan,Lezhi Li,Yiping Ma,Daniele Molinari,Senyu Tong,Yanchao Sun,Thomas Voice,Jianyu Wang,Chong Wang,Simon Wang,Floris Weers,Yechen Xu,Guolin Yin,Muyang Yu,Yi Zhang,Zheng Zhou,Danyang Zhuo,Ruoming Pang,Cheng Leong*

Main category: cs.LG

TL;DR: RLAX是一个在TPU上可扩展的强化学习框架，采用参数服务器架构，通过系统优化和数据集技术，在12小时内将QwQ-32B的pass@8准确率提升12.8%


<details>
  <summary>Details</summary>
Motivation: 强化学习已成为提升大语言模型推理能力的主流方法，但需要可扩展且能处理训练中断的框架来加速收敛和提高模型质量

Method: 采用参数服务器架构，主训练器定期推送更新权重，推理工作器拉取最新权重生成新数据；引入系统技术实现可扩展和可中断的RL；开发新的数据集整理和对齐技术

Result: 在1024个v5p TPU上，仅用12小时48分钟就将QwQ-32B的pass@8准确率提升12.8%，同时在训练中断时保持鲁棒性

Conclusion: RLAX是一个高效可扩展的RL框架，能显著加速LLM推理能力的提升，同时具备处理训练中断的鲁棒性

Abstract: Reinforcement learning (RL) has emerged as the de-facto paradigm for improving the reasoning capabilities of large language models (LLMs). We have developed RLAX, a scalable RL framework on TPUs. RLAX employs a parameter-server architecture. A master trainer periodically pushes updated model weights to the parameter server while a fleet of inference workers pull the latest weights and generates new rollouts. We introduce a suite of system techniques to enable scalable and preemptible RL for a diverse set of state-of-art RL algorithms. To accelerate convergence and improve model quality, we have devised new dataset curation and alignment techniques. Large-scale evaluations show that RLAX improves QwQ-32B's pass@8 accuracy by 12.8% in just 12 hours 48 minutes on 1024 v5p TPUs, while remaining robust to preemptions during training.

</details>


### [124] [Hankel-FNO: Fast Underwater Acoustic Charting Via Physics-Encoded Fourier Neural Operator](https://arxiv.org/abs/2512.06417)
*Yifan Sun,Lei Cheng,Jianlong Li,Peter Gerstoft*

Main category: cs.LG

TL;DR: Hankel-FNO：基于傅里叶神经算子的高效水下声学制图方法，结合声传播知识和地形数据，在保持高计算速度的同时实现高精度预测


<details>
  <summary>Details</summary>
Motivation: 传统水下声学制图方法依赖计算昂贵的数值求解器，无法满足大规模或实时应用需求。现有深度学习替代模型存在固定分辨率限制或依赖显式偏微分方程公式的问题，限制了其在不同环境中的适用性和泛化能力。

Method: 提出Hankel-FNO模型，基于傅里叶神经算子（FNO），结合声传播知识和水深地形数据，实现高效准确的水下声学制图。

Result: Hankel-FNO在速度上优于传统求解器，在精度上超越数据驱动替代方法，特别是在长距离预测方面表现突出。实验表明模型能够适应不同环境和声源设置，只需少量微调。

Conclusion: Hankel-FNO为水下声学制图提供了一种高效准确的解决方案，能够支持环境感知传感器部署优化和自主车辆路径规划等下游任务。

Abstract: Fast and accurate underwater acoustic charting is crucial for downstream tasks such as environment-aware sensor placement optimization and autonomous vehicle path planning. Conventional methods rely on computationally expensive while accurate numerical solvers, which are not scalable for large-scale or real-time applications. Although deep learning-based surrogate models can accelerate these computations, they often suffer from limitations such as fixed-resolution constraints or dependence on explicit partial differential equation formulations. These issues hinder their applicability and generalization across diverse environments. We propose Hankel-FNO, a Fourier Neural Operator (FNO)-based model for efficient and accurate acoustic charting. By incorporating sound propagation knowledge and bathymetry, our method has high accuracy while maintaining high computational speed. Results demonstrate that Hankel-FNO outperforms traditional solvers in speed and surpasses data-driven alternatives in accuracy, especially in long-range predictions. Experiments show the model's adaptability to diverse environments and sound source settings with minimal fine-tuning.

</details>


### [125] [A new initialisation to Control Gradients in Sinusoidal Neural network](https://arxiv.org/abs/2512.06427)
*Andrea Combette,Antoine Venaille,Nelly Pustelnik*

Main category: cs.LG

TL;DR: 提出一种新的SIREN网络初始化方法，通过控制梯度和预激活分布来改善训练稳定性和泛化性能


<details>
  <summary>Details</summary>
Motivation: 现有初始化策略对梯度爆炸/消失问题缺乏精确理论理解，特别是对于正弦激活函数的网络，需要更好的初始化方法来控制梯度并改善泛化

Method: 推导出参数初始化的闭式表达式，基于预激活分布收敛的固定点和Jacobian序列方差，控制梯度并实现预激活消失，防止不适当频率出现

Result: 新初始化方法在函数拟合和图像重建任务中一致优于原始SIREN和其他基线方法，包括物理信息神经网络任务

Conclusion: 提出的初始化策略通过精确控制梯度和预激活分布，显著改善了SIREN网络的训练动态和泛化能力，在多种重建任务中表现优异

Abstract: Proper initialisation strategy is of primary importance to mitigate gradient explosion or vanishing when training neural networks. Yet, the impact of initialisation parameters still lacks a precise theoretical understanding for several well-established architectures. Here, we propose a new initialisation for networks with sinusoidal activation functions such as \texttt{SIREN}, focusing on gradients control, their scaling with network depth, their impact on training and on generalization. To achieve this, we identify a closed-form expression for the initialisation of the parameters, differing from the original \texttt{SIREN} scheme. This expression is derived from fixed points obtained through the convergence of pre-activation distribution and the variance of Jacobian sequences. Controlling both gradients and targeting vanishing pre-activation helps preventing the emergence of inappropriate frequencies during estimation, thereby improving generalization. We further show that this initialisation strongly influences training dynamics through the Neural Tangent Kernel framework (NTK). Finally, we benchmark \texttt{SIREN} with the proposed initialisation against the original scheme and other baselines on function fitting and image reconstruction. The new initialisation consistently outperforms state-of-the-art methods across a wide range of reconstruction tasks, including those involving physics-informed neural networks.

</details>


### [126] [Neural expressiveness for beyond importance model compression](https://arxiv.org/abs/2512.06440)
*Angelos-Christos Maroudis,Sotirios Xydis*

Main category: cs.LG

TL;DR: 提出基于"表达力"的新剪枝准则，强调神经元激活重叠的信息重分配能力，实现数据无关剪枝，相比权重重要性方法获得10倍参数压缩增益。


<details>
  <summary>Details</summary>
Motivation: 现有剪枝方法主要依赖权重"重要性"，但忽略了神经元激活重叠所体现的信息重分配能力。需要建立与学习状态无关的剪枝准则，解决"何时剪枝"问题，并探索数据无关策略。

Method: 提出"表达力"剪枝准则，基于神经元或神经元组激活重叠的信息重分配能力。该准则与网络初始化状态强相关，独立于学习状态，可用任意数据或有限代表性样本近似计算。支持与重要性剪枝的混合策略。

Result: 相比权重方法获得10倍参数压缩增益，性能仅下降1%。在YOLOv8上实现55.4%参数移除和46.1%MACs减少，COCO数据集上mAP50-95提升3%。表达力独立剪枝在压缩效率上优于现有方法。

Conclusion: 表达力准则为剪枝提供了新的理论基础，解决了"何时剪枝"问题，支持数据无关策略，与重要性剪枝互补，显著提升压缩效率。

Abstract: Neural Network Pruning has been established as driving force in the exploration of memory and energy efficient solutions with high throughput both during training and at test time. In this paper, we introduce a novel criterion for model compression, named "Expressiveness". Unlike existing pruning methods that rely on the inherent "Importance" of neurons' and filters' weights, ``Expressiveness" emphasizes a neuron's or group of neurons ability to redistribute informational resources effectively, based on the overlap of activations. This characteristic is strongly correlated to a network's initialization state, establishing criterion autonomy from the learning state stateless and thus setting a new fundamental basis for the expansion of compression strategies in regards to the "When to Prune" question. We show that expressiveness is effectively approximated with arbitrary data or limited dataset's representative samples, making ground for the exploration of Data-Agnostic strategies. Our work also facilitates a "hybrid" formulation of expressiveness and importance-based pruning strategies, illustrating their complementary benefits and delivering up to 10x extra gains w.r.t. weight-based approaches in parameter compression ratios, with an average of 1% in performance degradation. We also show that employing expressiveness (independently) for pruning leads to an improvement over top-performing and foundational methods in terms of compression efficiency. Finally, on YOLOv8, we achieve a 46.1% MACs reduction by removing 55.4\% of the parameters, with an increase of 3% in the mean Absolute Precision ($mAP_{50-95}$) for object detection on COCO dataset.

</details>


### [127] [BitStopper: An Efficient Transformer Attention Accelerator via Stage-fusion and Early Termination](https://arxiv.org/abs/2512.06457)
*Huizheng Wang,Hongbin Wang,Shaojun Wei,Yang Hu,Shouyi Yin*

Main category: cs.LG

TL;DR: BitStopper：一种无需稀疏预测器的细粒度算法-架构协同设计，通过比特级稀疏推测、比特串行使能阶段融合和比特级异步处理，显著降低Transformer注意力计算的内存访问和计算开销。


<details>
  <summary>Details</summary>
Motivation: 基于注意力的大语言模型存在二次方计算成本，动态稀疏注意力虽然能缓解但受限于预测阶段开销和内存流量。现有方法硬件效率不足，需要更高效的解决方案。

Method: 1) 比特串行使能阶段融合(BESF)：重用并最小化内存访问，逐步终止不重要token，将预测阶段合并到执行阶段；2) 轻量自适应token选择(LATS)：与比特级稀疏推测协同工作；3) 比特级异步处理(BAP)：在按需比特粒度内存获取时提高计算利用率；4) 精心设计的架构实现理论复杂度降低到实际性能提升。

Result: 相比最先进的Transformer加速器，BitStopper在Sanger上实现2.03倍加速，SOFA上实现1.89倍加速，同时能效分别提升2.4倍和2.1倍。

Conclusion: BitStopper通过算法-架构协同设计，无需稀疏预测器即可实现高效的动态稀疏注意力，显著提升Transformer加速器的性能和能效。

Abstract: Attention-based large language models (LLMs) have transformed modern AI applications, but the quadratic cost of self-attention imposes significant compute and memory overhead. Dynamic sparsity (DS) attention mitigates this, yet its hardware efficiency is limited by the added prediction stage and the heavy memory traffic it entails. To address these limitations, this paper proposes BitStopper, a fine-grained algorithm-architecture co-design that operates without a sparsity predictor. First, a bit-serial enable stage fusion (BESF) mechanism is proposed to reuse and minimize the memory access by progressively terminating trivial tokens and merging the prediction stage into the execution stage. Second, a lightweight and adaptive token selection (LATS) strategy is developed to work in concert with the bit-level sparsity speculation. Third, a bit-level asynchronous processing (BAP) strategy is employed to improve compute utilization during the on-demand bit-grained memory fetching. Finally, an elaborate architecture is designed to translate the theoretical complexity reduction into practical performance improvement. Extensive evaluations demonstrate that, compared to state-of-the-art (SOTA) Transformer accelerators, BitStopper achieves 2.03x and 1.89x speedups over Sanger and SOFA, respectively, while delivering 2.4x and 2.1x improvements in energy efficiency.

</details>


### [128] [Why Goal-Conditioned Reinforcement Learning Works: Relation to Dual Control](https://arxiv.org/abs/2512.06471)
*Nathan P. Lawrence,Ali Mesbah*

Main category: cs.LG

TL;DR: 本文分析了基于最优控制的目标条件强化学习，推导了传统二次目标与目标条件奖励之间的最优性差距，并将状态估计与概率奖励联系起来，验证了目标条件策略在非线性不确定环境中的优势。


<details>
  <summary>Details</summary>
Motivation: 目标条件强化学习旨在训练智能体最大化到达目标状态的概率，但传统密集奖励（如二次型）在此类任务中可能失效。本文旨在从最优控制角度分析目标条件设置，解释为什么传统奖励方法会失败，以及为什么目标条件RL能成功。

Method: 基于最优控制理论，推导了传统二次目标与目标条件奖励之间的最优性差距。考虑了部分可观测马尔可夫决策过程，将状态估计与概率奖励联系起来，使目标条件奖励适用于双重控制问题。在非线性和不确定环境中使用强化学习和预测控制技术验证方法。

Result: 阐明了目标条件RL成功的原因以及传统密集奖励失败的原因。建立了状态估计与概率奖励之间的理论联系，使目标条件奖励适用于双重控制问题。在非线性和不确定环境中的实验验证了目标条件策略的优势。

Conclusion: 目标条件强化学习在到达目标状态的任务中具有理论优势，特别是在部分可观测和不确定环境中。通过最优控制分析揭示了传统奖励方法的局限性，为目标条件RL提供了理论依据，并展示了其在双重控制问题中的应用潜力。

Abstract: Goal-conditioned reinforcement learning (RL) concerns the problem of training an agent to maximize the probability of reaching target goal states. This paper presents an analysis of the goal-conditioned setting based on optimal control. In particular, we derive an optimality gap between more classical, often quadratic, objectives and the goal-conditioned reward, elucidating the success of goal-conditioned RL and why classical ``dense'' rewards can falter. We then consider the partially observed Markov decision setting and connect state estimation to our probabilistic reward, further making the goal-conditioned reward well suited to dual control problems. The advantages of goal-conditioned policies are validated on nonlinear and uncertain environments using both RL and predictive control techniques.

</details>


### [129] [Optimizing LLMs Using Quantization for Mobile Execution](https://arxiv.org/abs/2512.06490)
*Agatsya Yadav,Renta Chintala Bhargavi*

Main category: cs.LG

TL;DR: 本文研究使用4位后训练量化（PTQ）压缩大语言模型，使其能在移动设备上运行，成功将Llama 3.2 3B模型量化并部署到Android设备。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）虽然功能强大，但其巨大的模型规模和计算需求阻碍了在资源受限的移动设备上的部署，需要寻找有效的压缩和优化方法。

Method: 使用BitsAndBytes库和Hugging Face Transformers框架对Meta的Llama 3.2 3B模型进行4位后训练量化（PTQ），然后将量化模型转换为GGUF格式，最后在Android设备的Termux环境和Ollama框架中部署运行。

Result: 通过4位量化实现了68.66%的模型大小缩减，量化后的模型能够在Android设备上成功执行推理任务，证明了在移动设备上运行量化LLM的可行性。

Conclusion: 4位PTQ结合GGUF等移动优化格式，为在移动设备上部署功能强大的LLMs提供了实用途径，在模型大小和性能之间取得了良好平衡。

Abstract: Large Language Models (LLMs) offer powerful capabilities, but their significant size and computational requirements hinder deployment on resource-constrained mobile devices. This paper investigates Post-Training Quantization (PTQ) for compressing LLMs for mobile execution. We apply 4-bit PTQ using the BitsAndBytes library with the Hugging Face Transformers framework to Meta's Llama 3.2 3B model. The quantized model is converted to GGUF format using llama.cpp tools for optimized mobile inference. The PTQ workflow achieves a 68.66% reduction in model size through 4-bit quantization, enabling the Llama 3.2 3B model to run efficiently on an Android device. Qualitative validation shows that the 4-bit quantized model can perform inference tasks successfully. We demonstrate the feasibility of running the quantized GGUF model on an Android device using the Termux environment and the Ollama framework. PTQ, especially at 4-bit precision combined with mobile-optimized formats like GGUF, provides a practical pathway for deploying capable LLMs on mobile devices, balancing model size and performance.

</details>


### [130] [Diagnosis-based mortality prediction for intensive care unit patients via transfer learning](https://arxiv.org/abs/2512.06511)
*Mengqi Xu,Subha Maity,Joel Dubin*

Main category: cs.LG

TL;DR: 该研究评估了在ICU诊断特异性死亡率预测中应用迁移学习方法，发现迁移学习优于仅使用诊断特异性数据或APACHE IVa评分的模型，且在不同决策阈值下保持高性能。


<details>
  <summary>Details</summary>
Motivation: ICU中危重疾病的病因在不同诊断间差异很大，但现有预测模型未能系统性地考虑诊断异质性。需要开发能够处理诊断特异性差异的预测方法。

Method: 使用eICU协作研究数据库，评估基于GLM和XGBoost的迁移学习方法，用于诊断特异性死亡率预测，并与仅使用诊断特异性数据、APACHE IVa评分以及合并数据训练的模型进行比较。

Result: 迁移学习方法在诊断特异性死亡率预测中始终优于仅使用诊断特异性数据的模型和APACHE IVa评分，同时比合并数据训练的模型具有更好的校准性。Youden截断值比传统的0.5阈值更适合二元结果预测。

Conclusion: 迁移学习是处理ICU诊断异质性的有效方法，能够提高死亡率预测性能，且在不同决策阈值下保持稳定的预测能力。Youden截断值应作为二元结果预测的更合适决策阈值。

Abstract: In the intensive care unit, the underlying causes of critical illness vary substantially across diagnoses, yet prediction models accounting for diagnostic heterogeneity have not been systematically studied. To address the gap, we evaluate transfer learning approaches for diagnosis-specific mortality prediction and apply both GLM- and XGBoost-based models to the eICU Collaborative Research Database. Our results demonstrate that transfer learning consistently outperforms models trained only on diagnosis-specific data and those using a well-known ICU severity-of-illness score, i.e., APACHE IVa, alone, while also achieving better calibration than models trained on the pooled data. Our findings also suggest that the Youden cutoff is a more appropriate decision threshold than the conventional 0.5 for binary outcomes, and that transfer learning maintains consistently high predictive performance across various cutoff criteria.

</details>


### [131] [Beyond Token-level Supervision: Unlocking the Potential of Decoding-based Regression via Reinforcement Learning](https://arxiv.org/abs/2512.06533)
*Ming Chen,Sheng Tang,Rong-Xi Tan,Ziniu Li,Jiacheng Chen,Ke Xue,Chao Qian*

Main category: cs.LG

TL;DR: 该论文提出使用强化学习（RL）改进基于解码的回归方法，通过序列级奖励来增强数值预测的全局一致性，在表格回归和代码度量回归任务中超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 基于解码的回归将回归任务重新定义为序列生成任务，但现有方法存在离散token级目标（如交叉熵）与连续数值之间的不匹配问题，token级约束难以捕捉目标值的全局幅度，限制了预测精度和泛化能力。

Method: 将生成过程建模为马尔可夫决策过程，使用序列级奖励来强制全局数值一致性，具体采用ReMax和GRPO等强化学习方法，通过序列级信号来优化解码过程。

Result: 在表格回归和代码度量回归任务上的大量实验表明，该方法（特别是使用ReMax和GRPO）一致优于最先进的token级基线和传统回归头，显示出引入序列级信号的优势。

Conclusion: 强化学习显著提高了采样效率和预测精度，确立了基于解码的回归作为通用数值预测的稳健且准确的范式，为将大语言模型应用于数值预测任务提供了有效解决方案。

Abstract: Decoding-based regression, which reformulates regression as a sequence generation task, has emerged as a promising paradigm of applying large language models for numerical prediction. However, its progress is hindered by the misalignment between discrete token-level objectives (e.g., cross-entropy) and continuous numerical values. Existing approaches relying on token-level constraints often fail to capture the global magnitude of the target value, limiting their precision and generalization. In this paper, we propose to unlock the potential of decoding-based regression via Reinforcement Learning (RL). We formulate the generation process as a Markov Decision Process, utilizing sequence-level rewards to enforce global numerical coherence. Extensive experiments on tabular regression and code metric regression demonstrate that our method (specifically with ReMax and GRPO) consistently outperforms both state-of-the-art token-level baselines and traditional regression heads, showing the superiority of introducing sequence-level signals. Our analysis further reveals that RL significantly enhances sampling efficiency and predictive precision, establishing decoding-based regression as a robust and accurate paradigm for general-purpose numerical prediction.

</details>


### [132] [A-3PO: Accelerating Asynchronous LLM Training with Staleness-aware Proximal Policy Approximation](https://arxiv.org/abs/2512.06547)
*Xiaocan Li,Shiliang Wu,Zheng Shen*

Main category: cs.LG

TL;DR: A-3PO通过近似计算解耦损失中的近端策略，消除了异步强化学习中额外的前向传播计算开销，在保持性能的同时减少18%训练时间。


<details>
  <summary>Details</summary>
Motivation: 解耦损失在异步强化学习中能处理数据陈旧性问题，但其中的近端策略需要在每个训练步骤中进行额外的网络前向传播，对大型语言模型造成计算瓶颈。

Method: 提出A-3PO方法，通过简单插值近似近端策略，避免显式计算。近端策略仅作为行为策略和目标策略之间的信任区域锚点，可以通过插值有效近似。

Result: A-3PO消除了近端策略的计算开销，减少18%的训练时间，同时保持与原始方法相当的性能。

Conclusion: A-3PO通过近似近端策略有效解决了异步强化学习中解耦损失的计算瓶颈问题，在保持稳定性的同时显著提升训练效率。

Abstract: Decoupled loss has been a successful reinforcement learning (RL) algorithm to deal with the high data staleness under the asynchronous RL setting. Decoupled loss improves coupled-loss style of algorithms' (e.g., PPO, GRPO) learning stability by introducing a proximal policy to decouple the off-policy corrections (importance weight) from the controlling policy updates (trust region). However, the proximal policy requires an extra forward pass through the network at each training step, creating a computational bottleneck for large language models. We observe that since the proximal policy only serves as a trust region anchor between the behavior and target policies, we can approximate it through simple interpolation without explicit computation. We call this approach A-3PO (APproximated Proximal Policy Optimization). A-3PO eliminates this overhead, reducing training time by 18% while maintaining comparable performance. Code & off-the-shelf example are available at: https://github.com/inclusionAI/AReaL/blob/main/docs/algorithms/prox_approx.md

</details>


### [133] [Deep Manifold Part 2: Neural Network Mathematics](https://arxiv.org/abs/2512.06563)
*Max Y. Ma,Gen-Hua Shi*

Main category: cs.LG

TL;DR: 该论文提出从流形几何、不动点理论和边界条件迭代的角度重新理解神经网络，将神经网络视为由数据复杂性和学习动态塑造的可学习数值计算，而非固定坐标和算子的组合。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络理论基于固定坐标和算子，无法充分解释现实世界数据的高复杂性、无限范围和训练动态。作者希望通过几何和不动点理论，建立更符合实际数据和学习过程的神经网络理论框架。

Method: 采用堆叠分段流形、不动点理论和边界条件迭代的方法，将神经网络视为由数据复杂性、学习动态和边界条件共同塑造的几何结构，强调不动点区域在能力涌现中的关键作用。

Result: 提出神经网络不是从不动点开始，而是通过残差驱动迭代构建不动点。只有当不动点区域稳定时，神经网络的能力才会涌现。这解释了为什么单一模型在几何和数据诱导可塑性方面存在局限。

Conclusion: 该视角揭示了单一模型的局限性，并激励设计分布式流形复杂性的架构和联邦系统，形成基于几何、代数、不动点和真实数据复杂性的连贯世界建模框架。

Abstract: This work develops the global equations of neural networks through stacked piecewise manifolds, fixed-point theory, and boundary-conditioned iteration. Once fixed coordinates and operators are removed, a neural network appears as a learnable numerical computation shaped by manifold complexity, high-order nonlinearity, and boundary conditions. Real-world data impose strong data complexity, near-infinite scope, scale, and minibatch fragmentation, while training dynamics produce learning complexity through shifting node covers, curvature accumulation, and the rise and decay of plasticity. These forces constrain learnability and explain why capability emerges only when fixed-point regions stabilize. Neural networks do not begin with fixed points; they construct them through residual-driven iteration. This perspective clarifies the limits of monolithic models under geometric and data-induced plasticity and motivates architectures and federated systems that distribute manifold complexity across many elastic models, forming a coherent world-modeling framework grounded in geometry, algebra, fixed points, and real-data complexity.

</details>


### [134] [QL-LSTM: A Parameter-Efficient LSTM for Stable Long-Sequence Modeling](https://arxiv.org/abs/2512.06582)
*Isaac Kofi Nti*

Main category: cs.LG

TL;DR: QL-LSTM通过参数共享统一门控和分层门控递归两个组件，在减少48%参数的同时保持性能，解决了传统RNN参数冗余和长距离信息保留问题。


<details>
  <summary>Details</summary>
Motivation: 传统LSTM和GRU等循环神经网络存在两个核心限制：1）门控机制中的参数冗余问题，每个门都有独立的参数矩阵；2）长距离信息保留能力下降，容易发生遗忘门退化。

Method: 提出QL-LSTM架构，包含两个独立组件：1）参数共享统一门控机制，用单一共享权重矩阵替代所有门特定变换；2）分层门控递归与加法跳跃连接，添加无乘法路径改善长距离信息流。

Result: 在IMDB数据集的情感分类任务中，QL-LSTM在显著减少参数（约48%）的情况下达到竞争性准确率。但受限于循环模型的顺序特性，当前原型尚未实现实际运行时间改进。

Conclusion: QL-LSTM有效解决了传统RNN的参数冗余和长距离信息保留问题，但需要进一步的核级优化才能在实际运行时间上获得改进。

Abstract: Recurrent neural architectures such as LSTM and GRU remain widely used in sequence modeling, but they continue to face two core limitations: redundant gate-specific parameters and reduced ability to retain information across long temporal distances. This paper introduces the Quantum-Leap LSTM (QL-LSTM), a recurrent architecture designed to address both challenges through two independent components. The Parameter-Shared Unified Gating mechanism replaces all gate-specific transformations with a single shared weight matrix, reducing parameters by approximately 48 percent while preserving full gating behavior. The Hierarchical Gated Recurrence with Additive Skip Connections component adds a multiplication-free pathway that improves long-range information flow and reduces forget-gate degradation. We evaluate QL-LSTM on sentiment classification using the IMDB dataset with extended document lengths, comparing it to LSTM, GRU, and BiLSTM reference models. QL-LSTM achieves competitive accuracy while using substantially fewer parameters. Although the PSUG and HGR-ASC components are more efficient per time step, the current prototype remains limited by the inherent sequential nature of recurrent models and therefore does not yet yield wall-clock speed improvements without further kernel-level optimization.

</details>


### [135] [On fine-tuning Boltz-2 for protein-protein affinity prediction](https://arxiv.org/abs/2512.06592)
*James King,Lewis Cornwall,Andrei Cristian Nica,James Day,Aaron Sim,Neil Dalchau,Lilly Wollman,Joshua Meyers*

Main category: cs.LG

TL;DR: 将蛋白质-配体亲和力预测模型Boltz-2适配用于蛋白质-蛋白质亲和力回归，但在TCR3d和PPB-affinity数据集上表现不如序列模型，结合两者可互补提升


<details>
  <summary>Details</summary>
Motivation: 准确预测蛋白质-蛋白质结合亲和力对于理解分子相互作用和设计治疗方法至关重要。需要评估结构基方法在蛋白质-蛋白质亲和力预测中的表现

Method: 将最先进的结构基蛋白质-配体亲和力预测模型Boltz-2适配为蛋白质-蛋白质亲和力回归模型(Boltz-2-PPI)，在TCR3d和PPB-affinity两个数据集上进行评估，并与序列基方法比较，还尝试结合两种方法的嵌入表示

Result: 尽管结构准确性高，但Boltz-2-PPI在小规模和较大规模数据体系下都表现不如序列基替代方法。将Boltz-2-PPI的嵌入与序列基嵌入结合可产生互补改进，特别是对于较弱的序列模型，表明序列和结构基模型学习了不同的信号

Conclusion: 结果呼应了与结构数据训练相关的已知偏差，表明当前的结构基表示尚未准备好用于高性能的亲和力预测，需要进一步改进结构基方法

Abstract: Accurate prediction of protein-protein binding affinity is vital for understanding molecular interactions and designing therapeutics. We adapt Boltz-2, a state-of-the-art structure-based protein-ligand affinity predictor, for protein-protein affinity regression and evaluate it on two datasets, TCR3d and PPB-affinity. Despite high structural accuracy, Boltz-2-PPI underperforms relative to sequence-based alternatives in both small- and larger-scale data regimes. Combining embeddings from Boltz-2-PPI with sequence-based embeddings yields complementary improvements, particularly for weaker sequence models, suggesting different signals are learned by sequence- and structure-based models. Our results echo known biases associated with training with structural data and suggest that current structure-based representations are not primed for performant affinity prediction.

</details>


### [136] [A Fast and Effective Solution to the Problem of Look-ahead Bias in LLMs](https://arxiv.org/abs/2512.06607)
*Humzah Merchant,Bradford Levy*

Main category: cs.LG

TL;DR: 提出一种在推理时调整大模型logits的方法，通过一对专门的小模型来移除金融预测中的前瞻偏差，避免昂贵的重新训练。


<details>
  <summary>Details</summary>
Motivation: 将LLMs应用于金融预测任务时面临前瞻偏差的挑战，因为大模型在长时间序列数据上训练，无法进行金融中常用的回测，而从头重新训练前沿模型成本过高。

Method: 在推理时通过调整大基础模型的logits来引导生成，使用一对专门的小模型：一个在要遗忘的信息上微调，另一个在要保留的信息上微调。

Result: 该方法能有效移除逐字和语义知识，纠正偏差，并且优于先前的方法。

Conclusion: 提出了一种快速、有效且低成本的替代方案，解决了LLMs在金融预测中的前瞻偏差问题，避免了昂贵的重新训练。

Abstract: Applying LLMs to predictive tasks in finance is challenging due to look-ahead bias resulting from their training on long time-series data. This precludes the backtests typically employed in finance since retraining frontier models from scratch with a specific knowledge cutoff is prohibitive. In this paper, we introduce a fast, effective, and low-cost alternative. Our method guides generation at inference time by adjusting the logits of a large base model using a pair of smaller, specialized models -- one fine-tuned on information to be forgotten and another on information to be retained. We demonstrate that our method effectively removes both verbatim and semantic knowledge, corrects biases, and outperforms prior methods.

</details>


### [137] [Vector Quantization using Gaussian Variational Autoencoder](https://arxiv.org/abs/2512.06609)
*Tongda Xu,Wendi Zheng,Jiajun He,Jose Miguel Hernandez-Lobato,Yan Wang,Ya-Qin Zhang,Jie Tang*

Main category: cs.LG

TL;DR: 提出Gaussian Quant (GQ)技术，将高斯VAE转换为VQ-VAE而无需额外训练，通过理论证明和实践验证优于现有方法


<details>
  <summary>Details</summary>
Motivation: VQ-VAE由于离散化难以训练，需要寻找更简单有效的离散化方法

Method: 提出Gaussian Quant (GQ)：使用随机高斯噪声作为码本，寻找与后验均值最接近的噪声；并提出目标散度约束(TDC)来训练高斯VAE以优化GQ效果

Result: GQ在UNet和ViT架构上优于VQGAN、FSQ、LFQ、BSQ等现有VQ-VAE方法；TDC也优于TokenBridge等高斯VAE离散化方法

Conclusion: GQ提供了一种简单有效的VQ-VAE构建方法，理论上有保证，实践上表现优异

Abstract: Vector quantized variational autoencoder (VQ-VAE) is a discrete auto-encoder that compresses images into discrete tokens. It is difficult to train due to discretization. In this paper, we propose a simple yet effective technique, dubbed Gaussian Quant (GQ), that converts a Gaussian VAE with certain constraint into a VQ-VAE without training. GQ generates random Gaussian noise as a codebook and finds the closest noise to the posterior mean. Theoretically, we prove that when the logarithm of the codebook size exceeds the bits-back coding rate of the Gaussian VAE, a small quantization error is guaranteed. Practically, we propose a heuristic to train Gaussian VAE for effective GQ, named target divergence constraint (TDC). Empirically, we show that GQ outperforms previous VQ-VAEs, such as VQGAN, FSQ, LFQ, and BSQ, on both UNet and ViT architectures. Furthermore, TDC also improves upon previous Gaussian VAE discretization methods, such as TokenBridge. The source code is provided in https://github.com/tongdaxu/VQ-VAE-from-Gaussian-VAE.

</details>


### [138] [Quantum Temporal Convolutional Neural Networks for Cross-Sectional Equity Return Prediction: A Comparative Benchmark Study](https://arxiv.org/abs/2512.06630)
*Chi-Sheng Chen,Xinyu Zhang,Rong Fu,Qiuzhe Xie,Fan Zhang*

Main category: cs.LG

TL;DR: 量子时间卷积神经网络(QTCNN)结合经典时间编码器和参数高效的量子卷积电路，用于股票收益预测，在JPX东京证券交易所数据集上实现了0.538的夏普比率，比最佳经典基准提高了约72%。


<details>
  <summary>Details</summary>
Motivation: 传统预测模型在处理噪声输入、制度转换和有限泛化能力方面存在困难，特别是在复杂、噪声大、动态性强的金融环境中。量子机器学习为增强股票市场预测提供了有前景的途径。

Method: 提出量子时间卷积神经网络(QTCNN)，结合经典时间编码器提取时序技术指标的多尺度模式，以及量子卷积电路利用量子叠加和纠缠增强特征表示并抑制过拟合。

Result: 在JPX东京证券交易所数据集上进行综合基准测试，通过构建多空投资组合并使用样本外夏普比率作为主要性能指标。QTCNN实现了0.538的夏普比率，比最佳经典基准提高了约72%。

Conclusion: 研究结果突显了量子增强预测模型QTCNN在量化金融中稳健决策的实际潜力，表明量子机器学习能够有效处理金融环境中的复杂性和噪声。

Abstract: Quantum machine learning offers a promising pathway for enhancing stock market prediction, particularly under complex, noisy, and highly dynamic financial environments. However, many classical forecasting models struggle with noisy input, regime shifts, and limited generalization capacity. To address these challenges, we propose a Quantum Temporal Convolutional Neural Network (QTCNN) that combines a classical temporal encoder with parameter-efficient quantum convolution circuits for cross-sectional equity return prediction. The temporal encoder extracts multi-scale patterns from sequential technical indicators, while the quantum processing leverages superposition and entanglement to enhance feature representation and suppress overfitting. We conduct a comprehensive benchmarking study on the JPX Tokyo Stock Exchange dataset and evaluate predictions through long-short portfolio construction using out-of-sample Sharpe ratio as the primary performance metric. QTCNN achieves a Sharpe ratio of 0.538, outperforming the best classical baseline by approximately 72\%. These results highlight the practical potential of quantum-enhanced forecasting model, QTCNN, for robust decision-making in quantitative finance.

</details>


### [139] [The Impact of Data Characteristics on GNN Evaluation for Detecting Fake News](https://arxiv.org/abs/2512.06638)
*Isha Karn,David Jensen*

Main category: cs.LG

TL;DR: 现有假新闻检测基准数据集（GossipCop和PolitiFact）的图结构过于简单，无法有效评估GNN模型的结构建模能力，导致GNN与简单MLP性能相近。


<details>
  <summary>Details</summary>
Motivation: 当前假新闻检测领域广泛使用GNN模型，但缺乏对基准数据集是否真正能评估结构建模能力的验证。研究者发现常用数据集可能存在结构过于简单的问题，无法区分不同建模方法的优劣。

Method: 1) 系统比较5种GNN架构与使用相同节点特征的结构无关MLP；2) 通过特征打乱和边结构随机化的控制实验分离结构和特征的贡献；3) 对数据集进行结构分析，计算节点距离分布；4) 在合成数据集上验证GNN的真正优势。

Result: 1) MLP与GNN性能相近（差距1-2%，置信区间重叠）；2) 特征打乱导致性能崩溃，但边随机化后性能稳定，表明结构贡献可忽略；3) 超过75%的节点距离根节点仅一跳，结构多样性极低；4) 在特征噪声大、结构信息丰富的合成数据集上，GNN显著优于MLP。

Conclusion: 当前广泛使用的假新闻检测基准数据集无法有效评估GNN的结构建模能力，因为它们具有浅层、自我中心式的图拓扑结构。这呼吁开发具有更丰富、更多样化图拓扑结构的数据集。

Abstract: Graph neural networks (GNNs) are widely used for the detection of fake news by modeling the content and propagation structure of news articles on social media. We show that two of the most commonly used benchmark data sets - GossipCop and PolitiFact - are poorly suited to evaluating the utility of models that use propagation structure. Specifically, these data sets exhibit shallow, ego-like graph topologies that provide little or no ability to differentiate among modeling methods. We systematically benchmark five GNN architectures against a structure-agnostic multilayer perceptron (MLP) that uses the same node features. We show that MLPs match or closely trail the performance of GNNs, with performance gaps often within 1-2% and overlapping confidence intervals. To isolate the contribution of structure in these datasets, we conduct controlled experiments where node features are shuffled or edge structures randomized. We find that performance collapses under feature shuffling but remains stable under edge randomization. This suggests that structure plays a negligible role in these benchmarks. Structural analysis further reveals that over 75% of nodes are only one hop from the root, exhibiting minimal structural diversity. In contrast, on synthetic datasets where node features are noisy and structure is informative, GNNs significantly outperform MLPs. These findings provide strong evidence that widely used benchmarks do not meaningfully test the utility of modeling structural features, and they motivate the development of datasets with richer, more diverse graph topologies.

</details>


### [140] [Financial Fraud Identification and Interpretability Study for Listed Companies Based on Convolutional Neural Network](https://arxiv.org/abs/2512.06648)
*Xiao Li*

Main category: cs.LG

TL;DR: 提出基于卷积神经网络的中国A股上市公司财务舞弊检测框架，通过将面板数据转换为类图像表示来捕捉横截面和时间模式，实现提前预测，并在准确性、鲁棒性和预警性能上优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 上市公司财务舞弊屡禁不止，传统统计模型难以处理非线性特征交互，机器学习模型缺乏可解释性，且现有方法多基于当年数据判断当年舞弊，时效性不足。

Method: 设计特征工程方案，将公司年度面板数据转换为类图像表示，使用卷积神经网络捕捉横截面和时间模式，实现提前预测舞弊；采用局部解释技术从实体、特征和时间三个维度分析模型。

Result: CNN在准确性、鲁棒性和预警性能上优于逻辑回归和LightGBM；发现偿债能力、比率结构、治理结构和内部控制是舞弊的通用预测因子；非舞弊公司特征模式稳定，舞弊公司特征模式异质且集中在短期窗口。

Conclusion: 基于CNN的财务舞弊检测框架能有效提前识别舞弊，通过适当的分类阈值调整和可解释性分析，为高风险环境下的舞弊检测提供了实用解决方案，案例研究验证了模型预测与实际舞弊的一致性。

Abstract: Since the emergence of joint-stock companies, financial fraud by listed firms has repeatedly undermined capital markets. Fraud is difficult to detect because of covert tactics and the high labor and time costs of audits. Traditional statistical models are interpretable but struggle with nonlinear feature interactions, while machine learning models are powerful but often opaque. In addition, most existing methods judge fraud only for the current year based on current year data, limiting timeliness.
  This paper proposes a financial fraud detection framework for Chinese A-share listed companies based on convolutional neural networks (CNNs). We design a feature engineering scheme that transforms firm-year panel data into image like representations, enabling the CNN to capture cross-sectional and temporal patterns and to predict fraud in advance. Experiments show that the CNN outperforms logistic regression and LightGBM in accuracy, robustness, and early-warning performance, and that proper tuning of the classification threshold is crucial in high-risk settings.
  To address interpretability, we analyze the model along the dimensions of entity, feature, and time using local explanation techniques. We find that solvency, ratio structure, governance structure, and internal control are general predictors of fraud, while environmental indicators matter mainly in high-pollution industries. Non-fraud firms share stable feature patterns, whereas fraud firms exhibit heterogeneous patterns concentrated in short time windows. A case study of Guanong Shares in 2022 shows that cash flow analysis, social responsibility, governance structure, and per-share indicators are the main drivers of the model's fraud prediction, consistent with the company's documented misconduct.

</details>


### [141] [Estimating Black Carbon Concentration from Urban Traffic Using Vision-Based Machine Learning](https://arxiv.org/abs/2512.06649)
*Camellia Zakaria,Aryan Sadeghi,Weaam Jaafar,Junshi Xu,Alex Mariakakis,Marianne Hatzopoulou*

Main category: cs.LG

TL;DR: 利用交通监控视频和天气数据，通过机器学习模型估计街道级黑碳浓度，填补交通与环境影响数据缺口


<details>
  <summary>Details</summary>
Motivation: 城市黑碳排放主要来自交通，但监测成本高导致数据缺乏，而交通监控系统广泛部署，存在交通状况与环境影响数据不平衡问题

Method: 从交通视频中提取车辆行为和状况的视觉信息，结合天气数据，构建机器学习模型估计街道级黑碳浓度

Result: 模型达到R平方值0.72，RMSE为129.42 ng/m³，能够有效估计街道级黑碳浓度

Conclusion: 利用现有城市基础设施和建模技术，为污染减排、城市规划、公共卫生和环境正义提供可操作的黑碳浓度数据

Abstract: Black carbon (BC) emissions in urban areas are primarily driven by traffic, with hotspots near major roads disproportionately affecting marginalized communities. Because BC monitoring is typically performed using costly and specialized instruments. there is little to no available data on BC from local traffic sources that could help inform policy interventions targeting local factors. By contrast, traffic monitoring systems are widely deployed in cities around the world, highlighting the imbalance between what we know about traffic conditions and what do not know about their environmental consequences. To bridge this gap, we propose a machine learning-driven system that extracts visual information from traffic video to capture vehicles behaviors and conditions. Combining these features with weather data, our model estimates BC at street level, achieving an R-squared value of 0.72 and RMSE of 129.42 ng/m3 (nanogram per cubic meter). From a sustainability perspective, this work leverages resources already supported by urban infrastructure and established modeling techniques to generate information relevant to traffic emission. Obtaining BC concentration data provides actionable insights to support pollution reduction, urban planning, public health, and environmental justice at the local municipal level.

</details>


### [142] [Adaptive Test-Time Training for Predicting Need for Invasive Mechanical Ventilation in Multi-Center Cohorts](https://arxiv.org/abs/2512.06652)
*Xiaolei Lu,Shamim Nemati*

Main category: cs.LG

TL;DR: AdaTTT：一种针对ICU患者有创机械通气预测的自适应测试时训练框架，通过信息论分析、自监督学习和原型学习提升模型在跨机构部署时的泛化能力。


<details>
  <summary>Details</summary>
Motivation: ICU患者有创机械通气预测模型在跨机构部署时，由于患者群体、临床实践和电子健康记录系统的差异导致领域偏移，影响模型泛化性能。需要一种能在推理时动态适应、无需目标域标注数据的解决方案。

Method: 提出自适应测试时训练框架AdaTTT：1) 基于信息论分析主任务与辅助任务的不确定性关系；2) 引入自监督学习框架，包含重建和掩码特征建模任务，采用动态掩码策略强调主任务关键特征；3) 结合原型学习和部分最优传输进行灵活的特征对齐，保持临床有意义的患者表示。

Result: 在多中心ICU队列实验中，在不同测试时适应基准上展示了具有竞争力的分类性能。

Conclusion: AdaTTT框架通过信息论指导的自适应测试时训练，有效缓解了ICU预测模型在跨机构部署时的领域偏移问题，提升了有创机械通气预测的泛化能力。

Abstract: Accurate prediction of the need for invasive mechanical ventilation (IMV) in intensive care units (ICUs) patients is crucial for timely interventions and resource allocation. However, variability in patient populations, clinical practices, and electronic health record (EHR) systems across institutions introduces domain shifts that degrade the generalization performance of predictive models during deployment. Test-Time Training (TTT) has emerged as a promising approach to mitigate such shifts by adapting models dynamically during inference without requiring labeled target-domain data. In this work, we introduce Adaptive Test-Time Training (AdaTTT), an enhanced TTT framework tailored for EHR-based IMV prediction in ICU settings. We begin by deriving information-theoretic bounds on the test-time prediction error and demonstrate that it is constrained by the uncertainty between the main and auxiliary tasks. To enhance their alignment, we introduce a self-supervised learning framework with pretext tasks: reconstruction and masked feature modeling optimized through a dynamic masking strategy that emphasizes features critical to the main task. Additionally, to improve robustness against domain shifts, we incorporate prototype learning and employ Partial Optimal Transport (POT) for flexible, partial feature alignment while maintaining clinically meaningful patient representations. Experiments across multi-center ICU cohorts demonstrate competitive classification performance on different test-time adaptation benchmarks.

</details>


### [143] [GSAE: Graph-Regularized Sparse Autoencoders for Robust LLM Safety Steering](https://arxiv.org/abs/2512.06655)
*Jehyeok Yeon,Federico Cinus,Yifan Wu,Luca Luceri*

Main category: cs.LG

TL;DR: GSAE通过图正则化稀疏自编码器学习安全概念的分布式表示，采用两阶段门控机制实现运行时安全引导，在保持良性查询效用的同时有效拒绝有害内容。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全防御方法通常将安全概念视为单一潜在特征，但研究表明抽象概念（如拒绝、时间性）实际上是分布在多个特征中的。这种简化假设限制了安全防御的效果。

Method: 提出图正则化稀疏自编码器(GSAE)，在标准SAE基础上增加神经元共激活图的拉普拉斯平滑惩罚，学习平滑的分布式安全表示。采用两阶段门控机制：检测到有害提示或生成内容时激活干预，将多个特征组装成加权安全相关方向进行控制。

Result: GSAE引导在安全基准上平均达到82%的选择性拒绝率，显著优于标准SAE引导(42%)，同时在TriviaQA(70%)、TruthfulQA(65%)、GSM8K(74%)等任务上保持良好准确性。在LLaMA-3、Mistral、Qwen、Phi等模型家族上具有良好泛化性，对GCG、AutoDAN等越狱攻击保持≥90%的有害内容拒绝率。

Conclusion: GSAE能够学习安全概念的分布式表示，通过有效的运行时引导机制在保持模型实用性的同时显著提升安全性，为LLM安全防御提供了新的有效方法。

Abstract: Large language models (LLMs) face critical safety challenges, as they can be manipulated to generate harmful content through adversarial prompts and jailbreak attacks. Many defenses are typically either black-box guardrails that filter outputs, or internals-based methods that steer hidden activations by operationalizing safety as a single latent feature or dimension. While effective for simple concepts, this assumption is limiting, as recent evidence shows that abstract concepts such as refusal and temporality are distributed across multiple features rather than isolated in one. To address this limitation, we introduce Graph-Regularized Sparse Autoencoders (GSAEs), which extends SAEs with a Laplacian smoothness penalty on the neuron co-activation graph. Unlike standard SAEs that assign each concept to a single latent feature, GSAEs recover smooth, distributed safety representations as coherent patterns spanning multiple features. We empirically demonstrate that GSAE enables effective runtime safety steering, assembling features into a weighted set of safety-relevant directions and controlling them with a two-stage gating mechanism that activates interventions only when harmful prompts or continuations are detected during generation. This approach enforces refusals adaptively while preserving utility on benign queries. Across safety and QA benchmarks, GSAE steering achieves an average 82% selective refusal rate, substantially outperforming standard SAE steering (42%), while maintaining strong task accuracy (70% on TriviaQA, 65% on TruthfulQA, 74% on GSM8K). Robustness experiments further show generalization across LLaMA-3, Mistral, Qwen, and Phi families and resilience against jailbreak attacks (GCG, AutoDAN), consistently maintaining >= 90% refusal of harmful content.

</details>


### [144] [Rethinking Robustness: A New Approach to Evaluating Feature Attribution Methods](https://arxiv.org/abs/2512.06665)
*Panagiota Kiourti,Anu Singh,Preeti Duraipandian,Weichao Zhou,Wenchao Li*

Main category: cs.LG

TL;DR: 本文提出了一种新的特征归因方法鲁棒性评估框架，挑战了现有忽略模型输出差异的评估方式，通过定义相似输入、新鲁棒性指标和GAN生成方法，为归因方法提供更客观的评估。


<details>
  <summary>Details</summary>
Motivation: 当前的特征归因方法鲁棒性评估主要关注输入扰动下的归因图变化，但忽略了模型输出本身的差异。这种评估方式可能导致对归因方法鲁棒性的误判，需要更客观的评估框架来揭示归因方法本身的弱点而非神经网络的弱点。

Method: 提出三方面创新：1) 新的相似输入定义；2) 新的鲁棒性评估指标；3) 基于生成对抗网络(GAN)的方法来生成这些相似输入。通过综合评估现有指标和最先进的归因方法，验证新框架的有效性。

Result: 研究发现现有评估指标存在局限性，新提出的评估框架能够更准确地揭示归因方法的弱点。通过GAN生成的相似输入和新的鲁棒性指标，提供了对归因方法鲁棒性更客观的评估。

Conclusion: 需要更客观的评估指标来准确评估特征归因方法的鲁棒性，新提出的框架通过关注归因方法本身的弱点而非神经网络的弱点，为归因方法鲁棒性评估提供了更准确的方法。

Abstract: This paper studies the robustness of feature attribution methods for deep neural networks. It challenges the current notion of attributional robustness that largely ignores the difference in the model's outputs and introduces a new way of evaluating the robustness of attribution methods. Specifically, we propose a new definition of similar inputs, a new robustness metric, and a novel method based on generative adversarial networks to generate these inputs. In addition, we present a comprehensive evaluation with existing metrics and state-of-the-art attribution methods. Our findings highlight the need for a more objective metric that reveals the weaknesses of an attribution method rather than that of the neural network, thus providing a more accurate evaluation of the robustness of attribution methods.

</details>


### [145] [The Meta-Learning Gap: Combining Hydra and Quant for Large-Scale Time Series Classification](https://arxiv.org/abs/2512.06666)
*Urav Maniar*

Main category: cs.LG

TL;DR: 结合Hydra和Quant两种高效算法，通过六种集成配置在大型时间序列数据集上测试，发现特征拼接方法优于预测组合，当前元学习策略未能充分利用算法互补性，改进组合策略可显著提升集成效果。


<details>
  <summary>Details</summary>
Motivation: 解决时间序列分类中准确性与计算效率之间的基本权衡问题。虽然像HIVE-COTE 2.0这样的全面集成能达到最先进的准确性，但其在UCR基准测试上340小时的训练时间对于大规模数据集来说不切实际。研究是否可以通过结合两种来自互补范式的高效算法来获得集成优势，同时保持计算可行性。

Method: 结合Hydra（竞争卷积核）和Quant（分层区间分位数）两种高效算法，设计了六种集成配置。在10个大规模MONSTER数据集（7,898到1,168,774个训练实例）上评估性能，包括预测组合和特征拼接两种主要方法。

Result: 最强配置将平均准确率从0.829提高到0.836，在10个数据集中的7个上取得成功。但预测组合集成仅捕捉到11%的理论oracle潜力，显示出显著的元学习优化差距。特征拼接方法通过学习新的决策边界超过了oracle界限，而预测级互补性与集成增益呈中等相关性。

Conclusion: 核心发现：挑战已从确保算法不同转变为学习如何有效组合它们。当前的元学习策略难以利用oracle分析确认存在的互补性。改进的组合策略可能使集成增益在多样化时间序列分类应用中翻倍或三倍增长。

Abstract: Time series classification faces a fundamental trade-off between accuracy and computational efficiency. While comprehensive ensembles like HIVE-COTE 2.0 achieve state-of-the-art accuracy, their 340-hour training time on the UCR benchmark renders them impractical for large-scale datasets. We investigate whether targeted combinations of two efficient algorithms from complementary paradigms can capture ensemble benefits while maintaining computational feasibility. Combining Hydra (competing convolutional kernels) and Quant (hierarchical interval quantiles) across six ensemble configurations, we evaluate performance on 10 large-scale MONSTER datasets (7,898 to 1,168,774 training instances). Our strongest configuration improves mean accuracy from 0.829 to 0.836, succeeding on 7 of 10 datasets. However, prediction-combination ensembles capture only 11% of theoretical oracle potential, revealing a substantial meta-learning optimization gap. Feature-concatenation approaches exceeded oracle bounds by learning novel decision boundaries, while prediction-level complementarity shows moderate correlation with ensemble gains. The central finding: the challenge has shifted from ensuring algorithms are different to learning how to combine them effectively. Current meta-learning strategies struggle to exploit the complementarity that oracle analysis confirms exists. Improved combination strategies could potentially double or triple ensemble gains across diverse time series classification applications.

</details>


### [146] [GradientSpace: Unsupervised Data Clustering for Improved Instruction Tuning](https://arxiv.org/abs/2512.06678)
*Shrihari Sridharan,Deepak Ravikumar,Anand Raghunathan,Kaushik Roy*

Main category: cs.LG

TL;DR: GradientSpace：通过在全维梯度空间聚类样本，训练专用LoRA专家和轻量级路由器，解决指令调优中的梯度干扰问题，提升性能并降低推理延迟。


<details>
  <summary>Details</summary>
Motivation: 真实世界数据集通常异构，包含多样信息，导致梯度干扰（冲突梯度将模型拉向相反方向），降低性能。现有基于语义相似度的聚类方法无法捕捉数据如何影响模型参数学习，而基于梯度聚类的方法因随机降维导致精度损失，且依赖专家集成增加推理成本。

Method: 提出GradientSpace框架：1）在全维梯度空间直接聚类样本；2）引入基于在线SVD的算法，在LoRA梯度上操作，识别潜在技能，避免存储所有样本梯度的不可行成本；3）为每个聚类训练专用LoRA专家；4）训练轻量级路由器在推理时选择最佳专家。

Result: 在数学推理、代码生成、金融和创意写作任务上的实验表明：GradientSpace产生连贯的专家专业化，相比最先进的聚类方法和微调技术获得一致的精度提升。路由到单个合适专家优于先前工作的专家集成，同时显著降低推理延迟。

Conclusion: GradientSpace通过在全维梯度空间聚类有效解决了指令调优中的梯度干扰问题，实现了更好的专家专业化和性能提升，同时通过单专家路由而非专家集成降低了推理成本。

Abstract: Instruction tuning is one of the key steps required for adapting large language models (LLMs) to a broad spectrum of downstream applications. However, this procedure is difficult because real-world datasets are rarely homogeneous; they consist of a mixture of diverse information, causing gradient interference, where conflicting gradients pull the model in opposing directions, degrading performance. A common strategy to mitigate this issue is to group data based on semantic or embedding similarity. However, this fails to capture how data influences model parameters during learning. While recent works have attempted to cluster gradients directly, they randomly project gradients into lower dimensions to manage memory, which leads to accuracy loss. Moreover, these methods rely on expert ensembles which necessitates multiple inference passes and expensive on-the-fly gradient computations during inference. To address these limitations, we propose GradientSpace, a framework that clusters samples directly in full-dimensional gradient space. We introduce an online SVD-based algorithm that operates on LoRA gradients to identify latent skills without the infeasible cost of storing all sample gradients. Each cluster is used to train a specialized LoRA expert along with a lightweight router trained to select the best expert during inference. We show that routing to a single, appropriate expert outperforms expert ensembles used in prior work, while significantly reducing inference latency. Our experiments across mathematical reasoning, code generation, finance, and creative writing tasks demonstrate that GradientSpace leads to coherent expert specialization and consistent accuracy gains over state-of-the-art clustering methods and finetuning techniques.

</details>


### [147] [State Diversity Matters in Offline Behavior Distillation](https://arxiv.org/abs/2512.06692)
*Shiye Lei,Zhihao Cheng,Dacheng Tao*

Main category: cs.LG

TL;DR: 本文发现离线行为蒸馏中原始数据集与合成数据集存在不对齐问题，提出状态多样性在训练损失较大时比状态质量更重要，并设计了状态密度加权算法来提升蒸馏性能。


<details>
  <summary>Details</summary>
Motivation: 离线行为蒸馏将大量离线RL数据压缩成紧凑的合成行为数据集，但研究发现高质量原始数据集不一定产生优质合成数据集，存在不对齐问题，需要深入理解影响蒸馏效果的关键因素。

Method: 通过实证分析不同训练损失下的策略性能，理论分析状态质量和多样性对关键误差和周围误差的影响，提出状态密度加权算法，使用状态密度的倒数加权蒸馏目标以增强状态多样性。

Result: 实验表明：1）训练损失大时状态多样性更重要，损失小时状态质量更重要；2）周围误差在关键误差大时对策略性能影响更大；3）SDW算法在原始数据集状态多样性有限时显著提升OBD性能。

Conclusion: 状态多样性在离线行为蒸馏中至关重要，特别是在训练损失较大时。提出的SDW算法通过强调状态多样性有效解决了原始与合成数据集的不对齐问题，在状态多样性有限的原始数据集上表现优异。

Abstract: Offline Behavior Distillation (OBD), which condenses massive offline RL data into a compact synthetic behavioral dataset, offers a promising approach for efficient policy training and can be applied across various downstream RL tasks. In this paper, we uncover a misalignment between original and distilled datasets, observing that a high-quality original dataset does not necessarily yield a superior synthetic dataset. Through an empirical analysis of policy performance under varying levels of training loss, we show that datasets with greater state diversity outperforms those with higher state quality when training loss is substantial, as is often the case in OBD, whereas the relationship reverses under minimal loss, which contributes to the misalignment. By associating state quality and diversity in reducing pivotal and surrounding error, respectively, our theoretical analysis establishes that surrounding error plays a more crucial role in policy performance when pivotal error is large, thereby highlighting the importance of state diversity in OBD scenario. Furthermore, we propose a novel yet simple algorithm, state density weighted (SDW) OBD, which emphasizes state diversity by weighting the distillation objective using the reciprocal of state density, thereby distilling a more diverse state information into synthetic data. Extensive experiments across multiple D4RL datasets confirm that SDW significantly enhances OBD performance when the original dataset exhibits limited state diversity.

</details>


### [148] [Mitigating Barren plateaus in quantum denoising diffusion probabilistic models](https://arxiv.org/abs/2512.06695)
*Haipeng Cao,Kaining Zhang,Dacheng Tao,Zhaofeng Su*

Main category: cs.LG

TL;DR: 量子去噪扩散概率模型(QuDDPM)存在贫瘠高原问题，本文提出改进方案通过使用与Haar分布保持距离的输入分布来缓解该问题，提升训练效果和样本质量。


<details>
  <summary>Details</summary>
Motivation: 量子生成模型利用量子叠加和纠缠提升学习效率，QuDDPM作为量子生成学习框架表现出色，但研究发现其存在贫瘠高原问题，严重影响模型性能，需要解决这一训练难题。

Method: 通过理论分析和实验验证确认原始QuDDPM存在贫瘠高原问题，提出改进的QuDDPM，使用与Haar分布保持一定距离的分布作为去噪过程的输入，确保更好的可训练性。

Result: 实验结果表明，改进方法有效缓解了贫瘠高原问题，生成的样本质量更高，为可扩展和高效的量子生成学习铺平了道路。

Conclusion: 本文揭示了QuDDPM中贫瘠高原问题的根源，并提出有效的解决方案，通过调整输入分布特性来改善量子生成模型的训练效果，推动了量子生成学习的发展。

Abstract: Quantum generative models leverage quantum superposition and entanglement to enhance learning efficiency for both classical and quantum data. The quantum denoising diffusion probabilistic model (QuDDPM), inspired by its classical counterpart, has been proposed as a promising framework for quantum generative learning. QuDDPM is capable of efficiently learning and generating quantum data, and it demonstrates excellent performance in learning correlated quantum noise models, quantum many-body phases, and the topological structure of quantum data. However, we show that barren plateaus emerge in QuDDPMs due to the use of 2-design states as the input for the denoising process, which severely undermines the performance of QuDDPM. Through theoretical analysis and experimental validation, we confirm the presence of barren plateaus in the original QuDDPM. To address this issue, we introduce an improved QuDDPM that utilizes a distribution maintaining a certain distance from the Haar distribution, ensuring better trainability. Experimental results demonstrate that our approach effectively mitigates the barren plateau problem and generates samples with higher quality, paving the way for scalable and efficient quantum generative learning.

</details>


### [149] [Pathway to $O(\sqrt{d})$ Complexity bound under Wasserstein metric of flow-based models](https://arxiv.org/abs/2512.06702)
*Xiangjun Meng,Zhongjian Wang*

Main category: cs.LG

TL;DR: 论文为流式生成模型提供了在Wasserstein度量下估计误差的分析工具，证明了最优采样迭代复杂度为O(√d)，误差由两部分控制：与维度无关的反向流推前映射的Lipschitz性，以及维度相关的局部离散误差O(√d)。


<details>
  <summary>Details</summary>
Motivation: 为流式生成模型提供可实现的误差估计分析工具，特别是在高维情况下理解采样迭代复杂度与维度的关系，这对于实际应用中的计算效率至关重要。

Method: 通过分析流式生成模型在Wasserstein度量下的误差，将误差分解为两部分：反向流推前映射的Lipschitz性（与维度无关）和局部离散误差（与维度相关O(√d)）。这些分析适用于Föllmer过程和1-整流流相关的流式生成模型。

Result: 证明了采样迭代复杂度随协方差算子迹的平方根线性增长，这与前向过程不变分布相关。在Föllmer过程和1-整流流下，最优采样迭代复杂度为O(√d)。

Conclusion: 论文为流式生成模型提供了严格的误差分析框架，揭示了采样复杂度与维度的平方根关系，为高维生成模型的实际应用提供了理论指导。

Abstract: We provide attainable analytical tools to estimate the error of flow-based generative models under the Wasserstein metric and to establish the optimal sampling iteration complexity bound with respect to dimension as $O(\sqrt{d})$. We show this error can be explicitly controlled by two parts: the Lipschitzness of the push-forward maps of the backward flow which scales independently of the dimension; and a local discretization error scales $O(\sqrt{d})$ in terms of dimension. The former one is related to the existence of Lipschitz changes of variables induced by the (heat) flow. The latter one consists of the regularity of the score function in both spatial and temporal directions.
  These assumptions are valid in the flow-based generative model associated with the Föllmer process and $1$-rectified flow under the Gaussian tail assumption. As a consequence, we show that the sampling iteration complexity grows linearly with the square root of the trace of the covariance operator, which is related to the invariant distribution of the forward process.

</details>


### [150] [A Novel Multimodal RUL Framework for Remaining Useful Life Estimation with Layer-wise Explanations](https://arxiv.org/abs/2512.06708)
*Waleed Razzaq,Yun-Bo Zhao*

Main category: cs.LG

TL;DR: 提出了一种基于多模态融合的轴承剩余使用寿命预测框架，结合图像表示和时间频率表示，具有更好的泛化性、鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 滚动轴承是机械故障的常见原因，现有RUL预测方法存在泛化性差、鲁棒性不足、数据需求高、可解释性有限等问题，需要更有效的解决方案。

Method: 提出多模态RUL框架：1) 图像表示分支(ImR)使用Bresenham线算法转换振动信号；2) 时间频率表示分支(TFR)使用连续小波变换；3) 融合分支通过残差连接的多层扩张卷积提取空间特征，LSTM建模时间模式，多头注意力机制突出重要特征，最后线性层回归RUL。还提出多模态层相关传播(multimodal-LRP)增强可解释性。

Result: 在XJTU-SY和PRONOSTIA基准数据集上验证，性能达到或超越现有最佳方法，在未见工况下表现良好。XJTU-SY上减少约28%训练数据，PRONOSTIA上减少约48%。模型具有强噪声鲁棒性，multimodal-LRP可视化证实了预测的可解释性和可信度。

Conclusion: 该多模态RUL框架在性能、数据效率、鲁棒性和可解释性方面均有优势，非常适合实际工业部署。

Abstract: Estimating the Remaining Useful Life (RUL) of mechanical systems is pivotal in Prognostics and Health Management (PHM). Rolling-element bearings are among the most frequent causes of machinery failure, highlighting the need for robust RUL estimation methods. Existing approaches often suffer from poor generalization, lack of robustness, high data demands, and limited interpretability. This paper proposes a novel multimodal-RUL framework that jointly leverages image representations (ImR) and time-frequency representations (TFR) of multichannel, nonstationary vibration signals. The architecture comprises three branches: (1) an ImR branch and (2) a TFR branch, both employing multiple dilated convolutional blocks with residual connections to extract spatial degradation features; and (3) a fusion branch that concatenates these features and feeds them into an LSTM to model temporal degradation patterns. A multi-head attention mechanism subsequently emphasizes salient features, followed by linear layers for final RUL regression. To enable effective multimodal learning, vibration signals are converted into ImR via the Bresenham line algorithm and into TFR using Continuous Wavelet Transform. We also introduce multimodal Layer-wise Relevance Propagation (multimodal-LRP), a tailored explainability technique that significantly enhances model transparency. The approach is validated on the XJTU-SY and PRONOSTIA benchmark datasets. Results show that our method matches or surpasses state-of-the-art baselines under both seen and unseen operating conditions, while requiring ~28 % less training data on XJTU-SY and ~48 % less on PRONOSTIA. The model exhibits strong noise resilience, and multimodal-LRP visualizations confirm the interpretability and trustworthiness of predictions, making the framework highly suitable for real-world industrial deployment.

</details>


### [151] [A Novel Deep Neural Network Architecture for Real-Time Water Demand Forecasting](https://arxiv.org/abs/2512.06714)
*Tony Salloom,Okyay Kaynak,Wei He*

Main category: cs.LG

TL;DR: 提出一种结合数据扩展和轻量级深度学习模型的短期用水需求预测方法，通过插入虚拟数据缓解极端点误差，使用GRU和K-means特征工程降低模型复杂度


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在短期用水需求预测中存在两个主要问题：1) 模型参数过多导致复杂度高；2) 在极端点（峰值/谷值）预测误差较大。需要一种既能降低复杂度又能提高极端点预测准确性的方法

Method: 提出两种创新方法：1) 数据扩展技术：在实际数据中插入虚拟数据以缓解极端点周围的非线性问题；2) 轻量级深度学习模型：使用GRU处理时序关系，结合K-means无监督分类创建新特征，减少参数数量

Result: 1) 模型复杂度降低至文献中方法的六分之一，同时保持相同精度；2) 数据扩展使预测误差降低约30%；3) 使用中国两个不同水厂的真实数据进行验证，证明了方法的有效性

Conclusion: 该方法成功解决了短期用水需求预测中的复杂度和极端点误差问题，虽然数据扩展增加了训练时间，但在降低误差方面效果显著，为水供应系统优化控制提供了更实用的解决方案

Abstract: Short-term water demand forecasting (StWDF) is the foundation stone in the derivation of an optimal plan for controlling water supply systems. Deep learning (DL) approaches provide the most accurate solutions for this purpose. However, they suffer from complexity problem due to the massive number of parameters, in addition to the high forecasting error at the extreme points. In this work, an effective method to alleviate the error at these points is proposed. It is based on extending the data by inserting virtual data within the actual data to relieve the nonlinearity around them. To our knowledge, this is the first work that considers the problem related to the extreme points. Moreover, the water demand forecasting model proposed in this work is a novel DL model with relatively low complexity. The basic model uses the gated recurrent unit (GRU) to handle the sequential relationship in the historical demand data, while an unsupervised classification method, K-means, is introduced for the creation of new features to enhance the prediction accuracy with less number of parameters. Real data obtained from two different water plants in China are used to train and verify the model proposed. The prediction results and the comparison with the state-of-the-art illustrate that the method proposed reduces the complexity of the model six times of what achieved in the literature while conserving the same accuracy. Furthermore, it is found that extending the data set significantly reduces the error by about 30%. However, it increases the training time.

</details>


### [152] [Decoding Motor Behavior Using Deep Learning and Reservoir Computing](https://arxiv.org/abs/2512.06725)
*Tian Lan*

Main category: cs.LG

TL;DR: 提出ESNNet，结合CNN与回声状态网络(ESN)来改进EEG解码，特别针对运动行为分类，能更好地建模长程时间依赖性和非线性动态。


<details>
  <summary>Details</summary>
Motivation: 传统卷积架构如EEGNet和DeepConvNet能有效捕捉局部空间模式，但不适合建模长程时间依赖性和非线性动态，限制了EEG解码性能。

Method: 将回声状态网络(ESN)整合到解码流程中，ESN构建高维稀疏连接的循环储备池，擅长追踪时间动态，与CNN的空间表征能力互补。

Result: 在滑板技巧EEG数据集上，ESNNet达到83.2%的受试者内准确率和51.3%的留一受试者外准确率，超越了基于CNN的基线方法。

Conclusion: ESNNet通过结合CNN的空间表征能力和ESN的时间动态建模能力，显著提升了EEG解码性能，为脑机接口提供了更有效的解决方案。

Abstract: We present a novel approach to EEG decoding for non-invasive brain machine interfaces (BMIs), with a focus on motor-behavior classification. While conventional convolutional architectures such as EEGNet and DeepConvNet are effective in capturing local spatial patterns, they are markedly less suited for modeling long-range temporal dependencies and nonlinear dynamics. To address this limitation, we integrate an Echo State Network (ESN), a prominent paradigm in reservoir computing into the decoding pipeline. ESNs construct a high-dimensional, sparsely connected recurrent reservoir that excels at tracking temporal dynamics, thereby complementing the spatial representational power of CNNs. Evaluated on a skateboard-trick EEG dataset preprocessed via the PREP pipeline and implemented in MNE-Python, our ESNNet achieves 83.2% within-subject and 51.3% LOSO accuracies, surpassing widely used CNN-based baselines. Code is available at https://github.com/Yutiankunkun/Motion-Decoding-Using-Biosignals

</details>


### [153] [KV-CAR: KV Cache Compression using Autoencoders and KV Reuse in Large Language Models](https://arxiv.org/abs/2512.06727)
*Sourjya Roy,Shrihari Sridharan,Surya Selvam,Anand Raghunathan*

Main category: cs.LG

TL;DR: KV CAR：一个统一的架构无关框架，通过轻量级自编码器和相似性驱动重用机制，显著减少KV缓存内存占用，实现高达47.85%的压缩率，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模和上下文长度的增加，KV缓存在自回归解码过程中的内存需求成为主要瓶颈。KV缓存随序列长度和嵌入维度增长，常常超过模型本身的内存占用，限制了可实现的批处理大小和上下文窗口。

Method: KV CAR结合两种互补技术：1）轻量级自编码器沿嵌入维度学习键值张量的紧凑表示，在存储到KV缓存前压缩并在检索时恢复；2）相似性驱动重用机制识别跨相邻层重用特定注意力头KV张量的机会。这些方法无需改变Transformer架构即可减少KV张量的维度和结构冗余。

Result: 在GPT-2和TinyLLaMA模型上的评估显示，KV CAR在Wikitext、C4、PIQA和Winogrande数据集上实现高达47.85%的KV缓存内存减少，对困惑度和零样本准确率影响极小。在NVIDIA A40 GPU上的系统级测量表明，减少的KV占用直接转化为推理时更长的序列长度和更大的批处理大小。

Conclusion: KV CAR通过有效减少KV缓存内存占用，实现了内存高效的大语言模型推理，为解决KV缓存瓶颈问题提供了有效解决方案。

Abstract: As Large Language Models (LLMs) scale in size and context length, the memory requirements of the key value (KV) cache have emerged as a major bottleneck during autoregressive decoding. The KV cache grows with sequence length and embedding dimension, often exceeding the memory footprint of the model itself and limiting achievable batch sizes and context windows. To address this challenge, we present KV CAR, a unified and architecture agnostic framework that significantly reduces KV cache storage while maintaining model fidelity. KV CAR combines two complementary techniques. First, a lightweight autoencoder learns compact representations of key and value tensors along the embedding dimension, compressing them before they are stored in the KV cache and restoring them upon retrieval. Second, a similarity driven reuse mechanism identifies opportunities to reuse KV tensors of specific attention heads across adjacent layers. Together, these methods reduce the dimensional and structural redundancy in KV tensors without requiring changes to the transformer architecture. Evaluations on GPT 2 and TinyLLaMA models across Wikitext, C4, PIQA, and Winogrande datasets demonstrate that KV CAR achieves up to 47.85 percent KV cache memory reduction with minimal impact on perplexity and zero shot accuracy. System level measurements on an NVIDIA A40 GPU show that the reduced KV footprint directly translates into longer sequence lengths and larger batch sizes during inference. These results highlight the effectiveness of KV CAR in enabling memory efficient LLM inference.

</details>


### [154] [Enhancing Interpretability of AR-SSVEP-Based Motor Intention Recognition via CNN-BiLSTM and SHAP Analysis on EEG Data](https://arxiv.org/abs/2512.06730)
*Lin Yang,Xiang Li,Xin Ma,Xinxin Zhao*

Main category: cs.LG

TL;DR: 提出基于增强现实的SSVEP-BCI系统，结合多注意力CNN-BiLSTM模型，用于提高运动功能障碍患者的康复训练参与度和运动意图识别


<details>
  <summary>Details</summary>
Motivation: 解决运动功能障碍患者康复训练主观参与度低的问题，传统SSVEP-BCI系统依赖外部视觉刺激设备，在实际应用中受限，且治疗师工作负担重

Method: 1. 设计基于HoloLens 2的四种EEG类别，收集7名健康受试者数据；2. 在传统CNN-BiLSTM架构基础上集成多头注意力机制（MACNN-BiLSTM）；3. 提取10个时频EEG特征，通过CNN学习高级表征；4. 使用BiLSTM建模序列依赖，应用多头注意力突出运动意图相关模式；5. 应用SHAP方法可视化EEG特征对神经网络决策的贡献

Result: 该方法增强了实时运动意图识别能力，支持运动障碍患者的康复恢复

Conclusion: AR-SSVEP系统结合MACNN-BiLSTM模型能有效提高患者康复训练参与度，增强模型可解释性，为运动障碍康复提供实用解决方案

Abstract: Patients with motor dysfunction show low subjective engagement in rehabilitation training. Traditional SSVEP-based brain-computer interface (BCI) systems rely heavily on external visual stimulus equipment, limiting their practicality in real-world settings. This study proposes an augmented reality steady-state visually evoked potential (AR-SSVEP) system to address the lack of patient initiative and the high workload on therapists. Firstly, we design four HoloLens 2-based EEG classes and collect EEG data from seven healthy subjects for analysis. Secondly, we build upon the conventional CNN-BiLSTM architecture by integrating a multi-head attention mechanism (MACNN-BiLSTM). We extract ten temporal-spectral EEG features and feed them into a CNN to learn high-level representations. Then, we use BiLSTM to model sequential dependencies and apply a multi-head attention mechanism to highlight motor-intention-related patterns. Finally, the SHAP (SHapley Additive exPlanations) method is applied to visualize EEG feature contributions to the neural network's decision-making process, enhancing the model's interpretability. These findings enhance real-time motor intention recognition and support recovery in patients with motor impairments.

</details>


### [155] [Arc Gradient Descent: A Mathematically Derived Reformulation of Gradient Descent with Phase-Aware, User-Controlled Step Dynamics](https://arxiv.org/abs/2512.06737)
*Nikhil Verma,Joonas Linnosmaa,Espinosa-Leal Leonardo,Napat Vajragupta*

Main category: cs.LG

TL;DR: ArcGD优化器在非凸基准函数和真实ML数据集上均优于Adam等先进优化器，表现出更好的泛化能力和抗过拟合特性


<details>
  <summary>Details</summary>
Motivation: 开发一种新的优化器，能够在高维非凸问题和真实机器学习任务中超越现有优化器，特别是在泛化能力和抗过拟合方面

Method: 提出ArcGD优化器，首先在具有挑战性的Rosenbrock函数上进行评估（2D到50,000D），然后在CIFAR-10数据集上使用8种不同MLP架构与Adam、AdamW、Lion、SGD进行比较

Result: ArcGD在Rosenbrock函数上优于Adam；在CIFAR-10上获得最高平均测试准确率（50.7%），在8种架构中6种获胜或持平，且能持续改进而不像Adam/W会回归

Conclusion: ArcGD在几何压力测试和深度学习基准测试中表现优异，具有广泛适用性，且与Lion优化器存在理论联系，值得进一步探索

Abstract: The paper presents the formulation, implementation, and evaluation of the ArcGD optimiser. The evaluation is conducted initially on a non-convex benchmark function and subsequently on a real-world ML dataset. The initial comparative study using the Adam optimiser is conducted on a stochastic variant of the highly non-convex and notoriously challenging Rosenbrock function, renowned for its narrow, curved valley, across dimensions ranging from 2D to 1000D and an extreme case of 50,000D. Two configurations were evaluated to eliminate learning-rate bias: (i) both using ArcGD's effective learning rate and (ii) both using Adam's default learning rate. ArcGD consistently outperformed Adam under the first setting and, although slower under the second, achieved super ior final solutions in most cases. In the second evaluation, ArcGD is evaluated against state-of-the-art optimizers (Adam, AdamW, Lion, SGD) on the CIFAR-10 image classification dataset across 8 diverse MLP architectures ranging from 1 to 5 hidden layers. ArcGD achieved the highest average test accuracy (50.7%) at 20,000 iterations, outperforming AdamW (46.6%), Adam (46.8%), SGD (49.6%), and Lion (43.4%), winning or tying on 6 of 8 architectures. Notably, while Adam and AdamW showed strong early convergence at 5,000 iterations, but regressed with extended training, whereas ArcGD continued improving, demonstrating generalization and resistance to overfitting without requiring early stopping tuning. Strong performance on geometric stress tests and standard deep-learning benchmarks indicates broad applicability, highlighting the need for further exploration. Moreover, it is also shown that a variant of ArcGD can be interpreted as a special case of the Lion optimiser, highlighting connections between the inherent mechanisms of such optimisation methods.

</details>


### [156] [Multi-Scale Protein Structure Modelling with Geometric Graph U-Nets](https://arxiv.org/abs/2512.06752)
*Chang Liu,Vivian Li,Linus Leong,Vladimir Radenkovic,Pietro Liò,Chaitanya K. Joshi*

Main category: cs.LG

TL;DR: 提出Geometric Graph U-Nets，一种用于3D蛋白质结构学习的层次化几何图神经网络，通过递归粗化和细化蛋白质图来学习多尺度表示，在蛋白质折叠分类任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有几何GNN和Transformer依赖消息传递，无法捕捉蛋白质功能所需的层次化相互作用（如全局结构域和长程变构调节），需要网络架构本身反映这种生物层次结构。

Method: 引入Geometric Graph U-Nets，通过递归粗化和细化蛋白质图来学习多尺度表示，构建层次化架构，理论上比标准几何GNN更具表达力。

Result: 在蛋白质折叠分类任务中，Geometric U-Nets显著优于不变和等变基线模型，证明其能够学习定义蛋白质折叠的全局结构模式。

Conclusion: 该工作为设计能够学习生物分子多尺度结构的几何深度学习架构提供了理论基础，层次化设计能更好地捕捉蛋白质的生物学层次结构。

Abstract: Geometric Graph Neural Networks (GNNs) and Transformers have become state-of-the-art for learning from 3D protein structures. However, their reliance on message passing prevents them from capturing the hierarchical interactions that govern protein function, such as global domains and long-range allosteric regulation. In this work, we argue that the network architecture itself should mirror this biological hierarchy. We introduce Geometric Graph U-Nets, a new class of models that learn multi-scale representations by recursively coarsening and refining the protein graph. We prove that this hierarchical design can theoretically more expressive than standard Geometric GNNs. Empirically, on the task of protein fold classification, Geometric U-Nets substantially outperform invariant and equivariant baselines, demonstrating their ability to learn the global structural patterns that define protein folds. Our work provides a principled foundation for designing geometric deep learning architectures that can learn the multi-scale structure of biomolecules.

</details>


### [157] [Optimal Analysis for Bandit Learning in Matching Markets with Serial Dictatorship](https://arxiv.org/abs/2512.06758)
*Zilong Wang,Shuai Li*

Main category: cs.LG

TL;DR: 本文提出了一种多级连续选择算法，在序列独裁假设下实现了与已知下界匹配的遗憾上界，解决了双边匹配市场中在线学习偏好问题的遗憾上下界差距问题。


<details>
  <summary>Details</summary>
Motivation: 双边匹配市场中的在线学习偏好问题存在已知的遗憾下界和上界之间的差距（从N到K），不清楚是需要改进下界还是上界。本文旨在填补这一理论空白。

Method: 提出多级连续选择算法，在序列独裁假设下工作，该假设认为所有参与者（arms）具有相同的偏好标准。

Result: 算法实现了O(Nlog(T)/Δ² + Klog(T)/Δ)的遗憾上界，与已知的Ω(Nlog(T)/Δ² + Klog(T)/Δ)下界完全匹配。

Conclusion: 这是首个在带赌博机的匹配市场问题中达到已知下界的算法，解决了该领域长期存在的理论差距问题。

Abstract: The problem of two-sided matching markets is well-studied in computer science and economics, owing to its diverse applications across numerous domains. Since market participants are usually uncertain about their preferences in various online matching platforms, an emerging line of research is dedicated to the online setting where one-side participants (players) learn their unknown preferences through multiple rounds of interactions with the other side (arms). Sankararaman et al. provide an $Ω\left( \frac{N\log(T)}{Δ^2} + \frac{K\log(T)}Δ \right)$ regret lower bound for this problem under serial dictatorship assumption, where $N$ is the number of players, $K (\geq N)$ is the number of arms, $Δ$ is the minimum reward gap across players and arms, and $T$ is the time horizon. Serial dictatorship assumes arms have the same preferences, which is common in reality when one side participants have a unified evaluation standard. Recently, the work of Kong and Li proposes the ET-GS algorithm and achieves an $O\left( \frac{K\log(T)}{Δ^2} \right)$ regret upper bound, which is the best upper bound attained so far. Nonetheless, a gap between the lower and upper bounds, ranging from $N$ to $K$, persists. It remains unclear whether the lower bound or the upper bound needs to be improved. In this paper, we propose a multi-level successive selection algorithm that obtains an $O\left( \frac{N\log(T)}{Δ^2} + \frac{K\log(T)}Δ \right)$ regret bound when the market satisfies serial dictatorship. To the best of our knowledge, we are the first to propose an algorithm that matches the lower bound in the problem of matching markets with bandits.

</details>


### [158] [Measuring Over-smoothing beyond Dirichlet energy](https://arxiv.org/abs/2512.06782)
*Weiqi Guan,Zihao Shi*

Main category: cs.LG

TL;DR: 论文提出基于高阶特征导数的节点相似性度量家族，用于更全面量化图神经网络中的过平滑现象，建立了过平滑衰减率与图拉普拉斯谱隙的内在联系。


<details>
  <summary>Details</summary>
Motivation: 现有基于Dirichlet能量的过平滑度量仅捕获一阶特征导数，存在局限性，需要更全面的度量方法来量化图神经网络中的过平滑现象。

Method: 提出基于高阶特征导数能量的广义节点相似性度量家族，通过理论分析建立这些度量之间的关系，并分析连续热扩散和离散聚合算子下Dirichlet能量的衰减率。

Result: 理论分析揭示了过平滑衰减率与图拉普拉斯谱隙的内在联系，实证结果表明基于注意力的图神经网络在这些新度量下确实存在过平滑问题。

Conclusion: 提出的高阶特征导数能量度量提供了更全面的过平滑量化框架，揭示了过平滑现象与图结构谱特性之间的深层联系，为理解图神经网络性能提供了新视角。

Abstract: While Dirichlet energy serves as a prevalent metric for quantifying over-smoothing, it is inherently restricted to capturing first-order feature derivatives. To address this limitation, we propose a generalized family of node similarity measures based on the energy of higher-order feature derivatives. Through a rigorous theoretical analysis of the relationships among these measures, we establish the decay rates of Dirichlet energy under both continuous heat diffusion and discrete aggregation operators. Furthermore, our analysis reveals an intrinsic connection between the over-smoothing decay rate and the spectral gap of the graph Laplacian. Finally, empirical results demonstrate that attention-based Graph Neural Networks (GNNs) suffer from over-smoothing when evaluated under these proposed metrics.

</details>


### [159] [Angular Regularization for Positive-Unlabeled Learning on the Hypersphere](https://arxiv.org/abs/2512.06785)
*Vasileios Sevetlidis,George Pavlidis,Antonios Gasteratos*

Main category: cs.LG

TL;DR: AngularPU：一种基于角度相似度和原型向量的PU学习方法，无需显式负样本建模，通过角度正则化防止未标记样本聚集


<details>
  <summary>Details</summary>
Motivation: 现有PU学习方法要么依赖强分布假设，要么在高维设置中容易崩溃，需要一种更稳健、无需显式负样本建模的方法

Method: 在单位超球面上使用余弦相似度和角度间隔，正类由可学习的原型向量表示，分类简化为比较嵌入向量与原型之间的余弦相似度阈值，并引入角度正则化器分散未标记样本

Result: 在基准数据集上取得竞争性或优于现有PU方法的性能，特别是在正样本稀缺和高维嵌入设置中，同时提供几何可解释性和可扩展性

Conclusion: AngularPU提供了一种无需显式负样本建模的稳健PU学习框架，具有理论保证和实际优势

Abstract: Positive-Unlabeled (PU) learning addresses classification problems where only a subset of positive examples is labeled and the remaining data is unlabeled, making explicit negative supervision unavailable. Existing PU methods often rely on negative-risk estimation or pseudo-labeling, which either require strong distributional assumptions or can collapse in high-dimensional settings. We propose AngularPU, a novel PU framework that operates on the unit hypersphere using cosine similarity and angular margin. In our formulation, the positive class is represented by a learnable prototype vector, and classification reduces to thresholding the cosine similarity between an embedding and this prototype-eliminating the need for explicit negative modeling. To counteract the tendency of unlabeled embeddings to cluster near the positive prototype, we introduce an angular regularizer that encourages dispersion of the unlabeled set over the hypersphere, improving separation. We provide theoretical guarantees on the Bayes-optimality of the angular decision rule, consistency of the learned prototype, and the effect of the regularizer on the unlabeled distribution. Experiments on benchmark datasets demonstrate that AngularPU achieves competitive or superior performance compared to state-of-the-art PU methods, particularly in settings with scarce positives and high-dimensional embeddings, while offering geometric interpretability and scalability.

</details>


### [160] [Small-Gain Nash: Certified Contraction to Nash Equilibria in Differentiable Games](https://arxiv.org/abs/2512.06791)
*Vedansh Sharma*

Main category: cs.LG

TL;DR: 提出SGN（Small-Gain Nash）方法，通过自定义块加权几何中的块小增益条件，为梯度学习在非单调博弈中提供收敛保证，即使伪梯度在欧几里得几何中不满足单调性条件。


<details>
  <summary>Details</summary>
Motivation: 传统博弈中梯度学习的收敛保证需要伪梯度在欧几里得几何中满足（强）单调性条件（Rosen, 1965），但这一条件在具有强跨玩家耦合的简单博弈中经常失效，限制了现有方法的适用范围。

Method: 引入SGN（Small-Gain Nash）方法，在自定义块加权几何中建立块小增益条件。该方法将局部曲率和跨玩家Lipschitz耦合边界转化为可处理的收缩证书，构造加权块度量使伪梯度在满足这些边界的任何区域都变得强单调，即使它在欧几里得意义下是非单调的。

Result: 连续流在设计的几何中指数收缩，投影欧拉和RK4离散化在显式步长边界下收敛。该方法揭示了"时间尺度带"证书，这是一个非渐近的、基于度量的证书，类似于TTUR的作用。在二次博弈中验证了框架的有效性，并扩展到镜像/Fisher几何用于马尔可夫博弈中的熵正则化策略梯度。

Conclusion: SGN提供了一个离线认证流程，可在紧凑区域估计曲率、耦合和Lipschitz参数，优化块权重以扩大SGN边界，并返回一个结构化的、可计算的收敛证书，包括度量、收缩率和安全步长，适用于非单调博弈。

Abstract: Classical convergence guarantees for gradient-based learning in games require the pseudo-gradient to be (strongly) monotone in Euclidean geometry as shown by rosen(1965), a condition that often fails even in simple games with strong cross-player couplings. We introduce Small-Gain Nash (SGN), a block small-gain condition in a custom block-weighted geometry. SGN converts local curvature and cross-player Lipschitz coupling bounds into a tractable certificate of contraction. It constructs a weighted block metric in which the pseudo-gradient becomes strongly monotone on any region where these bounds hold, even when it is non-monotone in the Euclidean sense. The continuous flow is exponentially contracting in this designed geometry, and projected Euler and RK4 discretizations converge under explicit step-size bounds derived from the SGN margin and a local Lipschitz constant. Our analysis reveals a certified ``timescale band'', a non-asymptotic, metric-based certificate that plays a TTUR-like role: rather than forcing asymptotic timescale separation via vanishing, unequal step sizes, SGN identifies a finite band of relative metric weights for which a single-step-size dynamics is provably contractive. We validate the framework on quadratic games where Euclidean monotonicity analysis fails to predict convergence, but SGN successfully certifies it, and extend the construction to mirror/Fisher geometries for entropy-regularized policy gradient in Markov games. The result is an offline certification pipeline that estimates curvature, coupling, and Lipschitz parameters on compact regions, optimizes block weights to enlarge the SGN margin, and returns a structural, computable convergence certificate consisting of a metric, contraction rate, and safe step-sizes for non-monotone games.

</details>


### [161] [Partial Inverse Design of High-Performance Concrete Using Cooperative Neural Networks for Constraint-Aware Mix Generation](https://arxiv.org/abs/2512.06813)
*Agung Nugraha,Heungjun Im,Jihwan Lee*

Main category: cs.LG

TL;DR: 提出一种用于高性能混凝土部分逆向设计的协作神经网络框架，通过耦合的插补模型和代理模型，在单次前向传播中生成满足约束且性能一致的配合比设计。


<details>
  <summary>Details</summary>
Motivation: 高性能混凝土配合比设计涉及众多相互依赖的变量和实际约束。虽然数据驱动方法在正向设计预测方面取得进展，但逆向设计（确定达到目标性能的配合比）仍然有限，特别是在某些变量被约束固定、只需确定剩余变量的部分逆向设计场景。

Method: 提出协作神经网络框架，包含两个耦合的神经网络模型：1）插补模型推断未确定的变量；2）代理模型预测抗压强度。通过协作学习，模型在单次前向传播中生成有效且性能一致的配合比设计，无需重新训练即可适应不同的约束组合。

Result: 在基准数据集上评估，该模型获得稳定的R平方值0.87-0.92，与自编码器基线相比平均减少50%均方误差，与贝叶斯推理相比平均减少70%均方误差。

Conclusion: 协作神经网络为混凝土工程中约束感知、数据驱动的配合比设计提供了准确、鲁棒且计算高效的基础。

Abstract: High-performance concrete offers exceptional strength and durability but requires complex mix designs involving many interdependent variables and practical constraints. While data-driven methods have advanced predictive modeling for forward design, inverse design, which focuses on determining mix compositions that achieve target performance, remains limited, particularly in design situations where some mix variables are fixed by constraints and only the remaining variables must be determined. This study proposes a cooperative neural network framework for the partial inverse design of high-performance concrete. The framework combines two coupled neural network models, an imputation model that infers the undetermined variables and a surrogate model that predicts compressive strength. Through cooperative learning, the model generates valid and performance-consistent mix designs in a single forward pass while accommodating different constraint combinations without retraining. Its performance is compared with both probabilistic and generative approaches, including Bayesian inference based on a Gaussian process surrogate and autoencoder-based models. Evaluated on a benchmark dataset, the proposed model achieves stable and higher R-squared values of 0.87-0.92 and reduces mean squared error by an average of 50 percent compared with autoencoder baselines and by an average of 70 percent compared with Bayesian inference. The results demonstrate that the cooperative neural network provides an accurate, robust, and computationally efficient foundation for constraint-aware, data-driven mix proportioning in concrete engineering.

</details>


### [162] [Neural Factorization-based Bearing Fault Diagnosis](https://arxiv.org/abs/2512.06837)
*Zhenhao Li,Xu Cheng,Yi Zhou*

Main category: cs.LG

TL;DR: 提出基于神经分解的分类框架NFC用于高铁轴承故障诊断，通过多模态潜在特征嵌入和神经分解融合，显著提升复杂条件下的诊断精度


<details>
  <summary>Details</summary>
Motivation: 高铁轴承作为列车运行系统的核心部件，其健康状况直接关系到运行安全。传统诊断方法在复杂条件下面临诊断精度不足的挑战，需要更有效的故障诊断方法。

Method: 提出神经分解分类框架NFC：1）将振动时间序列嵌入到多个模态潜在特征向量中，捕捉不同的故障相关模式；2）利用神经分解原理将这些向量融合成统一的振动表示。基于CP和Tucker融合方案分别实例化为CP-NFC和Tucker-NFC模型。

Result: 实验结果表明，两种模型相比传统机器学习方法都实现了优越的诊断性能。比较分析为高铁轴承监测中选择有效诊断策略提供了有价值的实证证据和实践指导。

Conclusion: 提出的NFC框架能够从原始时间序列数据中有效挖掘复杂的潜在故障特征，为解决高铁轴承故障诊断中的关键问题提供了创新解决方案。

Abstract: This paper studies the key problems of bearing fault diagnosis of high-speed train. As the core component of the train operation system, the health of bearings is directly related to the safety of train operation. The traditional diagnostic methods are facing the challenge of insufficient diagnostic accuracy under complex conditions. To solve these problems, we propose a novel Neural Factorization-based Classification (NFC) framework for bearing fault diagnosis. It is built on two core idea: 1) Embedding vibration time series into multiple mode-wise latent feature vectors to capture diverse fault-related patterns; 2) Leveraging neural factorization principles to fuse these vectors into a unified vibration representation. This design enables effective mining of complex latent fault characteristics from raw time-series data. We further instantiate the framework with two models CP-NFC and Tucker-NFC based on CP and Tucker fusion schemes, respectively. Experimental results show that both models achieve superior diagnostic performance compared with traditional machine learning methods. The comparative analysis provides valuable empirical evidence and practical guidance for selecting effective diagnostic strategies in high-speed train bearing monitoring.

</details>


### [163] [Know your Trajectory -- Trustworthy Reinforcement Learning deployment through Importance-Based Trajectory Analysis](https://arxiv.org/abs/2512.06917)
*Clifford F,Devika Jay,Abhishek Sarkar,Satheesh K Perepu,Santhosh G S,Kaushik Dey,Balaraman Ravindran*

Main category: cs.LG

TL;DR: 提出一个新颖的轨迹级解释框架，通过结合Q值差异和"激进项"的状态重要性度量来排名轨迹，识别最优行为并提供对比解释。


<details>
  <summary>Details</summary>
Motivation: 当前可解释强化学习主要关注局部单步决策，缺乏对智能体长期行为的解释。为确保RL智能体在现实应用中的透明性和可信度，需要能够解释轨迹级行为的框架。

Method: 引入新的状态重要性度量，结合经典Q值差异和捕捉智能体到达目标亲和力的"激进项"。通过聚合这些度量来排名整个轨迹，并从关键状态生成反事实推演来提供对比解释。

Result: 方法成功从异构智能体经验中识别出最优轨迹，证明智能体选择的路径明显优于替代方案。在标准OpenAI Gym环境中验证了所提重要性度量比经典方法更有效地识别最优行为。

Conclusion: 该框架为可信自主系统提供了重要进展，通过轨迹级分析和"为什么是这个而不是那个"的解释，增强了RL智能体的透明性和可信度。

Abstract: As Reinforcement Learning (RL) agents are increasingly deployed in real-world applications, ensuring their behavior is transparent and trustworthy is paramount. A key component of trust is explainability, yet much of the work in Explainable RL (XRL) focuses on local, single-step decisions. This paper addresses the critical need for explaining an agent's long-term behavior through trajectory-level analysis. We introduce a novel framework that ranks entire trajectories by defining and aggregating a new state-importance metric. This metric combines the classic Q-value difference with a "radical term" that captures the agent's affinity to reach its goal, providing a more nuanced measure of state criticality. We demonstrate that our method successfully identifies optimal trajectories from a heterogeneous collection of agent experiences. Furthermore, by generating counterfactual rollouts from critical states within these trajectories, we show that the agent's chosen path is robustly superior to alternatives, thereby providing a powerful "Why this, and not that?" explanation. Our experiments in standard OpenAI Gym environments validate that our proposed importance metric is more effective at identifying optimal behaviors compared to classic approaches, offering a significant step towards trustworthy autonomous systems.

</details>


### [164] [Parent-Guided Semantic Reward Model (PGSRM): Embedding-Based Reward Functions for Reinforcement Learning of Transformer Language Models](https://arxiv.org/abs/2512.06920)
*Alexandr Plashchinsky*

Main category: cs.LG

TL;DR: PGSRM是一种轻量级强化学习奖励框架，使用父模型参考输出嵌入与子模型生成输出的余弦相似度作为语义奖励，无需人工标注或额外训练


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法需要二元正确性信号、人类偏好数据或训练奖励模型，这些方法成本高且复杂。PGSRM旨在提供一种简单、语义丰富的奖励信号，避免这些限制

Method: 使用父模型的参考输出嵌入与子模型生成输出的余弦相似度作为奖励信号，形成密集的语义奖励。在五个语言任务上应用该方法，并与二元奖励基线进行比较

Result: PGSRM相比二元奖励基线产生更平滑的奖励改进和更稳定的PPO动态，表明基于嵌入的语义奖励是RLHF风格奖励建模的实用替代方案

Conclusion: 嵌入语义奖励为小型transformer模型的父引导对齐提供了一种实用替代方案，无需人工标注或额外模型训练，简化了强化学习过程

Abstract: We introduce the Parent-Guided Semantic Reward Model (PGSRM), a lightweight reward framework for reinforcement learning (RL) of transformer language models. PGSRM replaces binary correctness signals, human preference data, and trained reward models with a simple signal: cosine similarity between a parent model's reference output embedding and a child model's generated output for the same input. This yields a dense, semantically meaningful reward with no human annotation or additional model training. We apply PGSRM on five language tasks and find that it produces smoother reward improvement and more stable PPO dynamics than a binary reward baseline, suggesting that embedding-based semantic rewards are a practical alternative to RLHF-style reward modeling for parent-guided alignment in smaller transformer models.

</details>


### [165] [Deep Reinforcement Learning for Phishing Detection with Transformer-Based Semantic Features](https://arxiv.org/abs/2512.06925)
*Aseer Al Faisal*

Main category: cs.LG

TL;DR: 提出QR-DQN方法，结合RoBERTa语义嵌入和手工特征，通过分位数回归建模回报分布，在105,000个URL数据集上实现99.86%的钓鱼检测准确率。


<details>
  <summary>Details</summary>
Motivation: 钓鱼攻击通过欺诈消息、误导广告和网站劫持窃取个人信息造成经济损失，传统DQN方法使用单一标量Q值估计存在局限性，需要更稳定、泛化能力强的检测方法。

Method: 提出Quantile Regression Deep Q-Network (QR-DQN)方法，整合RoBERTa语义嵌入和手工词汇特征，使用分位数回归建模回报分布而非单一标量值，在105,000个URL数据集上训练测试。

Result: 测试准确率99.86%，精确率99.75%，召回率99.96%，F1分数99.85%；相比传统DQN，泛化差距从1.66%降至0.04%；五折交叉验证平均准确率99.90%±0.04%。

Conclusion: 混合QR-DQN方法能有效检测钓鱼威胁，适应攻击策略演变，对未见数据泛化能力强，显著提升检测鲁棒性和稳定性。

Abstract: Phishing is a cybercrime in which individuals are deceived into revealing personal information, often resulting in financial loss. These attacks commonly occur through fraudulent messages, misleading advertisements, and compromised legitimate websites. This study proposes a Quantile Regression Deep Q-Network (QR-DQN) approach that integrates RoBERTa semantic embeddings with handcrafted lexical features to enhance phishing detection while accounting for uncertainties. Unlike traditional DQN methods that estimate single scalar Q-values, QR-DQN leverages quantile regression to model the distribution of returns, improving stability and generalization on unseen phishing data. A diverse dataset of 105,000 URLs was curated from PhishTank, OpenPhish, Cloudflare, and other sources, and the model was evaluated using an 80/20 train-test split. The QR-DQN framework achieved a test accuracy of 99.86%, precision of 99.75%, recall of 99.96%, and F1-score of 99.85%, demonstrating high effectiveness. Compared to standard DQN with lexical features, the hybrid QR-DQN with lexical and semantic features reduced the generalization gap from 1.66% to 0.04%, indicating significant improvement in robustness. Five-fold cross-validation confirmed model reliability, yielding a mean accuracy of 99.90% with a standard deviation of 0.04%. These results suggest that the proposed hybrid approach effectively identifies phishing threats, adapts to evolving attack strategies, and generalizes well to unseen data.

</details>


### [166] [Evaluating the Sensitivity of BiLSTM Forecasting Models to Sequence Length and Input Noise](https://arxiv.org/abs/2512.06926)
*Salma Albelali,Moataz Ahmed*

Main category: cs.LG

TL;DR: 本文系统分析了BiLSTM时间序列预测中两个关键数据因素：输入序列长度和加性噪声的影响，发现长序列增加过拟合风险，噪声降低预测精度，两者同时存在时模型稳定性下降最显著。


<details>
  <summary>Details</summary>
Motivation: 尽管双向LSTM在时间序列预测中表现出色，但其鲁棒性和泛化能力对输入数据特征高度敏感，而现有文献对此研究不足。本文旨在系统分析输入序列长度和加性噪声这两个关键数据因素对模型性能的影响。

Method: 开发了一个模块化、可复现的预测流程，包含标准化预处理、序列生成、模型训练、验证和评估。在三个具有不同采样频率的真实世界数据集上进行控制实验，评估BiLSTM在不同输入条件下的性能。

Result: 三个关键发现：1) 长输入序列显著增加过拟合和数据泄露风险，尤其在数据受限环境中；2) 加性噪声在不同采样频率下都持续降低预测精度；3) 两个因素同时存在时模型稳定性下降最显著。高采样频率数据集虽更鲁棒，但在两个挑战同时存在时仍很脆弱。

Conclusion: 研究揭示了当前基于深度学习的预测流程的重要局限性，强调需要数据感知的设计策略。为深入理解深度学习模型在动态时间序列环境中的行为提供了见解，并为开发更可靠、可泛化的预测系统提供了实用指导。

Abstract: Deep learning (DL) models, a specialized class of multilayer neural networks, have become central to time-series forecasting in critical domains such as environmental monitoring and the Internet of Things (IoT). Among these, Bidirectional Long Short-Term Memory (BiLSTM) architectures are particularly effective in capturing complex temporal dependencies. However, the robustness and generalization of such models are highly sensitive to input data characteristics - an aspect that remains underexplored in existing literature. This study presents a systematic empirical analysis of two key data-centric factors: input sequence length and additive noise. To support this investigation, a modular and reproducible forecasting pipeline is developed, incorporating standardized preprocessing, sequence generation, model training, validation, and evaluation. Controlled experiments are conducted on three real-world datasets with varying sampling frequencies to assess BiLSTM performance under different input conditions. The results yield three key findings: (1) longer input sequences significantly increase the risk of overfitting and data leakage, particularly in data-constrained environments; (2) additive noise consistently degrades predictive accuracy across sampling frequencies; and (3) the simultaneous presence of both factors results in the most substantial decline in model stability. While datasets with higher observation frequencies exhibit greater robustness, they remain vulnerable when both input challenges are present. These findings highlight important limitations in current DL-based forecasting pipelines and underscore the need for data-aware design strategies. This work contributes to a deeper understanding of DL model behavior in dynamic time-series environments and provides practical insights for developing more reliable and generalizable forecasting systems.

</details>


### [167] [Adaptive Normalization Mamba with Multi Scale Trend Decomposition and Patch MoE Encoding](https://arxiv.org/abs/2512.06929)
*MinCheol Jeon*

Main category: cs.LG

TL;DR: AdaMamba是一个统一的时间序列预测架构，通过自适应归一化、多尺度趋势提取和上下文序列建模来解决非平稳性、多尺度时间模式和分布偏移问题，在稳定性和准确性上优于传统Transformer基线。


<details>
  <summary>Details</summary>
Motivation: 现实世界时间序列预测面临非平稳性、多尺度时间模式和分布偏移等挑战，这些会降低模型的稳定性和准确性。现有方法在处理这些复杂动态时存在不足。

Method: AdaMamba包含自适应归一化块（通过多尺度卷积趋势提取和通道级重新校准去除非平稳成分）、上下文编码器（结合补丁嵌入、位置编码和Mamba增强的Transformer层）以及轻量级预测头。使用去归一化机制通过重新整合局部趋势来重建输出。

Result: 实验评估表明，AdaMamba的自适应归一化和专家增强的上下文建模相结合，在稳定性和准确性方面相比传统Transformer基线有持续改进，有效缓解了协变量偏移并增强了预测可靠性。

Conclusion: AdaMamba通过集成自适应归一化、多尺度趋势提取和上下文序列建模，提供了一个具有强大表示能力和模块化可扩展性的统一预测架构，能够有效处理现实世界时间序列预测的挑战。

Abstract: Time series forecasting in real world environments faces significant challenges non stationarity, multi scale temporal patterns, and distributional shifts that degrade model stability and accuracy. This study propose AdaMamba, a unified forecasting architecture that integrates adaptive normalization, multi scale trend extraction, and contextual sequence modeling to address these challenges. AdaMamba begins with an Adaptive Normalization Block that removes non stationary components through multi scale convolutional trend extraction and channel wise recalibration, enabling consistent detrending and variance stabilization. The normalized sequence is then processed by a Context Encoder that combines patch wise embeddings, positional encoding, and a Mamba enhanced Transformer layer with a mixture of experts feed forward module, allowing efficient modeling of both long range dependencies and local temporal dynamics. A lightweight prediction head generates multi horizon forecasts, and a denormalization mechanism reconstructs outputs by reintegrating local trends to ensure robustness under varying temporal conditions. AdaMamba provides strong representational capacity with modular extensibility, supporting deterministic prediction and compatibility with probabilistic extensions. Its design effectively mitigates covariate shift and enhances predictive reliability across heterogeneous datasets. Experimental evaluations demonstrate that AdaMamba's combination of adaptive normalization and expert augmented contextual modeling yields consistent improvements in stability and accuracy over conventional Transformer based baselines.

</details>


### [168] [Hidden Leaks in Time Series Forecasting: How Data Leakage Affects LSTM Evaluation Across Configurations and Validation Strategies](https://arxiv.org/abs/2512.06932)
*Salma Albelali,Moataz Ahmed*

Main category: cs.LG

TL;DR: 该研究评估了数据泄露对LSTM时间序列预测模型性能的影响，发现验证设计（特别是10折交叉验证）对泄露敏感，而2路和3路分割更稳健，输入窗口大小和滞后步长显著影响泄露敏感性。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测中，深度学习模型（特别是LSTM）常因数据泄露而评估失真。数据泄露发生在数据集划分前构建输入输出序列时，导致未来信息无意中影响训练。本研究旨在探究数据泄露对性能的影响，以及验证设计如何调节泄露敏感性。

Method: 研究评估了三种常用验证技术（2路分割、3路分割和10折交叉验证）在泄露（分割前序列生成）和干净（分割后序列生成）条件下的表现。使用RMSE增益衡量泄露影响，计算泄露与干净设置之间的相对RMSE增加百分比。分析了输入窗口大小和滞后步长对泄露敏感性的影响。

Result: 10折交叉验证在较长滞后步长下表现出高达20.5%的RMSE增益，而2路和3路分割通常保持RMSE增益低于5%。较小的输入窗口和较长的滞后步长会增加泄露风险，而较大的窗口有助于减少泄露。

Conclusion: 验证设计对数据泄露敏感性有显著影响，10折交叉验证特别容易受到泄露影响。需要配置感知、抗泄露的评估流程来确保可靠的性能估计，特别是在使用较小窗口和较长滞后步长时。

Abstract: Deep learning models, particularly Long Short-Term Memory (LSTM) networks, are widely used in time series forecasting due to their ability to capture complex temporal dependencies. However, evaluation integrity is often compromised by data leakage, a methodological flaw in which input-output sequences are constructed before dataset partitioning, allowing future information to unintentionally influence training. This study investigates the impact of data leakage on performance, focusing on how validation design mediates leakage sensitivity. Three widely used validation techniques (2-way split, 3-way split, and 10-fold cross-validation) are evaluated under both leaky (pre-split sequence generation) and clean conditions, with the latter mitigating leakage risk by enforcing temporal separation during data splitting prior to sequence construction. The effect of leakage is assessed using RMSE Gain, which measures the relative increase in RMSE caused by leakage, computed as the percentage difference between leaky and clean setups. Empirical results show that 10-fold cross-validation exhibits RMSE Gain values of up to 20.5% at extended lag steps. In contrast, 2-way and 3-way splits demonstrate greater robustness, typically maintaining RMSE Gain below 5% across diverse configurations. Moreover, input window size and lag step significantly influence leakage sensitivity: smaller windows and longer lags increase the risk of leakage, whereas larger windows help reduce it. These findings underscore the need for configuration-aware, leakage-resistant evaluation pipelines to ensure reliable performance estimation.

</details>


### [169] [A Unifying Human-Centered AI Fairness Framework](https://arxiv.org/abs/2512.06944)
*Munshi Mahbubur Rahman,Shimei Pan,James R. Foulds*

Main category: cs.LG

TL;DR: 提出一个统一的人类中心公平性框架，系统覆盖八种公平性指标，帮助利益相关者根据价值观和情境考虑调整公平性干预，并在四个真实数据集上展示权重调整如何揭示不同公平性指标间的权衡。


<details>
  <summary>Details</summary>
Motivation: AI在关键社会领域应用的增加加剧了对公平性的担忧，特别是在种族、性别和社会经济地位等敏感属性上的不平等对待。现有研究在平衡不同公平性概念与预测准确性方面存在挑战，阻碍了公平AI系统的实际部署。

Method: 引入统一的人类中心公平性框架，系统覆盖八种公平性指标（结合个体与群体公平、边际内与交叉假设、结果导向与机会均等视角），采用一致且易于理解的公式，允许利益相关者为多个公平性目标分配权重。

Result: 在四个真实数据集（UCI Adult收入预测、COMPAS犯罪再犯、德国信用风险评估、MEPS医疗保健利用）上应用该框架，展示调整权重如何揭示不同公平性指标间的细微权衡，并通过司法决策和医疗保健案例研究展示框架的实际应用价值。

Conclusion: 该框架为利益相关者提供了一个灵活的工具，能够根据具体情境和价值观调整公平性干预，促进多利益相关者妥协，支持公平AI系统的实际和价值敏感部署。

Abstract: The increasing use of Artificial Intelligence (AI) in critical societal domains has amplified concerns about fairness, particularly regarding unequal treatment across sensitive attributes such as race, gender, and socioeconomic status. While there has been substantial work on ensuring AI fairness, navigating trade-offs between competing notions of fairness as well as predictive accuracy remains challenging, creating barriers to the practical deployment of fair AI systems. To address this, we introduce a unifying human-centered fairness framework that systematically covers eight distinct fairness metrics, formed by combining individual and group fairness, infra-marginal and intersectional assumptions, and outcome-based and equality-of-opportunity (EOO) perspectives. This structure allows stakeholders to align fairness interventions with their values and contextual considerations. The framework uses a consistent and easy-to-understand formulation for all metrics to reduce the learning curve for non-experts. Rather than privileging a single fairness notion, the framework enables stakeholders to assign weights across multiple fairness objectives, reflecting their priorities and facilitating multi-stakeholder compromises. We apply this approach to four real-world datasets: the UCI Adult census dataset for income prediction, the COMPAS dataset for criminal recidivism, the German Credit dataset for credit risk assessment, and the MEPS dataset for healthcare utilization. We show that adjusting weights reveals nuanced trade-offs between different fairness metrics. Finally, through case studies in judicial decision-making and healthcare, we demonstrate how the framework can inform practical and value-sensitive deployment of fair AI systems.

</details>


### [170] [Comparing BFGS and OGR for Second-Order Optimization](https://arxiv.org/abs/2512.06969)
*Adrian Przybysz,Mikołaj Kołek,Franciszek Sobota,Jarek Duda*

Main category: cs.LG

TL;DR: 比较BFGS的Sherman-Morrison更新与新型在线梯度回归(OGR)方法在Hessian矩阵估计上的表现，OGR在非凸优化中表现更优


<details>
  <summary>Details</summary>
Motivation: 神经网络训练中Hessian矩阵估计面临高维度和计算成本的挑战，传统BFGS方法基于凸性假设保持正定Hessian近似，但无法处理非凸结构

Method: 提出在线梯度回归(OGR)方法，使用指数移动平均对梯度与位置进行回归，在线估计二阶导数而无需Hessian求逆，可处理非正定Hessian

Result: 在标准测试函数上评估两种方法，OGR在非凸设置中实现更快的收敛速度和更低的损失

Conclusion: OGR方法相比传统BFGS在非凸优化中具有优势，能够处理更一般的Hessian结构，为神经网络训练提供更好的二阶优化方法

Abstract: Estimating the Hessian matrix, especially for neural network training, is a challenging problem due to high dimensionality and cost. In this work, we compare the classical Sherman-Morrison update used in the popular BFGS method (Broy-den-Fletcher-Goldfarb-Shanno), which maintains a positive definite Hessian approximation under a convexity assumption, with a novel approach called Online Gradient Regression (OGR). OGR performs regression of gradients against positions using an exponential moving average to estimate second derivatives online, without requiring Hessian inversion. Unlike BFGS, OGR allows estimation of a general (not necessarily positive definite) Hessian and can thus handle non-convex structures. We evaluate both methods across standard test functions and demonstrate that OGR achieves faster convergence and improved loss, particularly in non-convex settings.

</details>


### [171] [Prediction with Expert Advice under Local Differential Privacy](https://arxiv.org/abs/2512.06971)
*Ben Jacobsen,Kassem Fawaz*

Main category: cs.LG

TL;DR: 论文研究了在本地差分隐私约束下的专家建议预测问题，提出了两种改进算法RW-AdaBatch和RW-Meta，在真实COVID-19医院数据上表现优于经典基线和最先进的中心差分隐私算法。


<details>
  <summary>Details</summary>
Motivation: 在本地差分隐私约束下，传统的专家建议预测算法性能受限。作者旨在设计新的算法，在保护隐私的同时提高预测性能，特别是在处理真实世界数据（如COVID-19医院报告数据）时。

Method: 1. 首先证明经典算法自然满足LDP；2. 提出RW-AdaBatch算法，利用LDP诱导的有限切换行为实现隐私放大，类似于离线学习中的混洗模型；3. 提出RW-Meta算法，开发了一种在非平凡学习算法专家之间进行私有选择的方法，且不增加额外隐私成本；4. 基于随机游走理论进行分析。

Result: 1. RW-AdaBatch在更简单的数据上隐私放大效果更强，且几乎没有效用损失；2. RW-Meta能够处理非平凡学习算法专家，而先前工作仅考虑数据无关专家；3. 推导了与专家独立性程度成反比的遗憾界限；4. 在COVID-19医院数据上，RW-Meta比经典基线和最先进的中心差分隐私算法性能提升1.5-3倍。

Conclusion: 该研究在本地差分隐私约束下的专家建议预测问题上取得了重要进展，提出的RW-AdaBatch和RW-Meta算法在隐私保护和预测性能之间实现了更好的平衡，特别是在处理真实世界复杂数据时表现出色，为隐私保护机器学习提供了新的工具。

Abstract: We study the classic problem of prediction with expert advice under the constraint of local differential privacy (LDP). In this context, we first show that a classical algorithm naturally satisfies LDP and then design two new algorithms that improve it: RW-AdaBatch and RW-Meta. For RW-AdaBatch, we exploit the limited-switching behavior induced by LDP to provide a novel form of privacy amplification that grows stronger on easier data, analogous to the shuffle model in offline learning. Drawing on the theory of random walks, we prove that this improvement carries essentially no utility cost. For RW-Meta, we develop a general method for privately selecting between experts that are themselves non-trivial learning algorithms, and we show that in the context of LDP this carries no extra privacy cost. In contrast, prior work has only considered data-independent experts. We also derive formal regret bounds that scale inversely with the degree of independence between experts. Our analysis is supplemented by evaluation on real-world data reported by hospitals during the COVID-19 pandemic; RW-Meta outperforms both the classical baseline and a state-of-the-art \textit{central} DP algorithm by 1.5-3$\times$ on the task of predicting which hospital will report the highest density of COVID patients each week.

</details>


### [172] [LLM-Driven Composite Neural Architecture Search for Multi-Source RL State Encoding](https://arxiv.org/abs/2512.06982)
*Yu Yu,Qian Xie,Nairen Cao,Li Jin*

Main category: cs.LG

TL;DR: 提出基于LLM的神经架构搜索方法，用于多源强化学习中的状态编码器设计，相比传统NAS和GENIUS框架，在交通控制任务中能以更少的候选评估发现性能更高的架构。


<details>
  <summary>Details</summary>
Motivation: 多源强化学习（包含传感器测量、时序信号、图像观测和文本指令等多种信息源）的状态编码器设计仍未被充分探索且通常需要手动设计，现有NAS方法忽略了模块中间输出的有用信息，限制了多源RL设置中的样本效率。

Method: 将问题形式化为复合神经架构搜索问题，提出基于LLM的NAS流程，利用语言模型先验和中间输出信号来指导高效搜索高性能复合状态编码器。

Result: 在混合自主交通控制任务中，该方法比传统NAS基线和基于LLM的GENIUS框架以更少的候选评估发现了性能更高的架构。

Conclusion: 提出的LLM驱动NAS方法能够有效解决多源RL中的状态编码器设计问题，通过利用语言模型先验和中间输出信号实现样本高效的架构搜索。

Abstract: Designing state encoders for reinforcement learning (RL) with multiple information sources -- such as sensor measurements, time-series signals, image observations, and textual instructions -- remains underexplored and often requires manual design. We formalize this challenge as a problem of composite neural architecture search (NAS), where multiple source-specific modules and a fusion module are jointly optimized. Existing NAS methods overlook useful side information from the intermediate outputs of these modules -- such as their representation quality -- limiting sample efficiency in multi-source RL settings. To address this, we propose an LLM-driven NAS pipeline that leverages language-model priors and intermediate-output signals to guide sample-efficient search for high-performing composite state encoders. On a mixed-autonomy traffic control task, our approach discovers higher-performing architectures with fewer candidate evaluations than traditional NAS baselines and the LLM-based GENIUS framework.

</details>


### [173] [OXtal: An All-Atom Diffusion Model for Organic Crystal Structure Prediction](https://arxiv.org/abs/2512.06987)
*Emily Jin,Andrei Cristian Nica,Mikhail Galkin,Jarrid Rector-Brooks,Kin Long Kelvin Lee,Santiago Miret,Frances H. Arnold,Michael Bronstein,Avishek Joey Bose,Alexander Tong,Cheng-Hao Liu*

Main category: cs.LG

TL;DR: OXtal是一个100M参数的全原子扩散模型，直接从2D化学图预测3D分子晶体结构，在晶体结构预测任务上取得显著改进


<details>
  <summary>Details</summary>
Motivation: 准确预测分子晶体结构是计算化学中长期存在的开放挑战，对制药和有机半导体等领域至关重要，因为晶体堆积直接影响有机固体的物理化学性质

Method: 采用大规模扩散模型直接学习分子内构象和周期性堆积的条件联合分布；放弃显式等变架构，使用数据增强策略；提出新的晶化训练方案S^4，避免显式晶格参数化

Result: 在60万实验验证晶体结构数据集上，OXtal比先前机器学习方法提高数个数量级，比传统量子化学方法便宜数个数量级；恢复实验结构的RMSD<0.5Å，达到80%以上堆积相似率

Conclusion: OXtal能够有效建模分子晶化的热力学和动力学规律，为晶体结构预测提供了高效准确的解决方案

Abstract: Accurately predicting experimentally-realizable 3D molecular crystal structures from their 2D chemical graphs is a long-standing open challenge in computational chemistry called crystal structure prediction (CSP). Efficiently solving this problem has implications ranging from pharmaceuticals to organic semiconductors, as crystal packing directly governs the physical and chemical properties of organic solids. In this paper, we introduce OXtal, a large-scale 100M parameter all-atom diffusion model that directly learns the conditional joint distribution over intramolecular conformations and periodic packing. To efficiently scale OXtal, we abandon explicit equivariant architectures imposing inductive bias arising from crystal symmetries in favor of data augmentation strategies. We further propose a novel crystallization-inspired lattice-free training scheme, Stoichiometric Stochastic Shell Sampling ($S^4$), that efficiently captures long-range interactions while sidestepping explicit lattice parametrization -- thus enabling more scalable architectural choices at all-atom resolution. By leveraging a large dataset of 600K experimentally validated crystal structures (including rigid and flexible molecules, co-crystals, and solvates), OXtal achieves orders-of-magnitude improvements over prior ab initio machine learning CSP methods, while remaining orders of magnitude cheaper than traditional quantum-chemical approaches. Specifically, OXtal recovers experimental structures with conformer $\text{RMSD}_1<0.5$ Å and attains over 80\% packing similarity rate, demonstrating its ability to model both thermodynamic and kinetic regularities of molecular crystallization.

</details>


### [174] [Flash Multi-Head Feed-Forward Network](https://arxiv.org/abs/2512.06989)
*Minshen Zhang,Xiang Hu,Jianguo Li,Wei Wu,Kewei Tu*

Main category: cs.LG

TL;DR: FlashMHF提出用多头FFN替代传统FFN，通过融合内核和动态加权并行子网络设计，在提升性能的同时大幅降低内存使用和加速推理。


<details>
  <summary>Details</summary>
Motivation: 受多头注意力机制启发，探索用多头FFN替代传统FFN。但直接应用面临两个挑战：内存消耗随头数线性增长，以及模型扩展时中间维度与头维度比例失衡，影响可扩展性和表达能力。

Method: 提出Flash Multi-Head FFN (FlashMHF)：1) 类似FlashAttention的I/O感知融合内核，在SRAM中在线计算输出；2) 使用动态加权并行子网络设计，保持中间维度与头维度的平衡比例。

Result: 在128M到1.3B参数规模的模型上验证，FlashMHF相比SwiGLU FFNs持续改进困惑度和下游任务准确率，同时降低峰值内存使用3-5倍，推理加速最高达1.08倍。

Conclusion: 多头设计是FFN的优越架构原则，FlashMHF作为Transformer中FFN的强大、高效且可扩展的替代方案。

Abstract: We explore Multi-Head FFN (MH-FFN) as a replacement of FFN in the Transformer architecture, motivated by the structural similarity between single-head attention and FFN. While multi-head mechanisms enhance expressivity in attention, naively applying them to FFNs faces two challenges: memory consumption scaling with the head count, and an imbalanced ratio between the growing intermediate size and the fixed head dimension as models scale, which degrades scalability and expressive power. To address these challenges, we propose Flash Multi-Head FFN (FlashMHF), with two key innovations: an I/O-aware fused kernel computing outputs online in SRAM akin to FlashAttention, and a design using dynamically weighted parallel sub-networks to maintain a balanced ratio between intermediate and head dimensions. Validated on models from 128M to 1.3B parameters, FlashMHF consistently improves perplexity and downstream task accuracy over SwiGLU FFNs, while reducing peak memory usage by 3-5x and accelerating inference by up to 1.08x. Our work establishes the multi-head design as a superior architectural principle for FFNs, presenting FlashMHF as a powerful, efficient, and scalable alternative to FFNs in Transformers.

</details>


### [175] [Toward Reliable Machine Unlearning: Theory, Algorithms, and Evaluation](https://arxiv.org/abs/2512.06993)
*Ali Ebrahimpour-Boroojeny*

Main category: cs.LG

TL;DR: 本文提出两种新的机器学习遗忘方法：AMUN用于样本遗忘，TRW用于类别遗忘，均优于现有方法。AMUN通过对抗样本微调降低模型对遗忘样本的置信度，TRW通过估计类间相似性调整目标分布。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习遗忘方法在实现模型对特定样本或类别的遗忘时效果有限，无法完全模拟从头训练模型的行为，存在隐私泄露风险。需要开发更有效的遗忘方法来保护隐私并满足法规要求。

Method: 1. AMUN方法：通过生成对抗样本来微调模型，降低对遗忘样本的置信度，同时保持对保留样本的性能。2. FastClip方法：通过层谱范数裁剪控制模型平滑度。3. TRW方法：针对类别遗忘，估计类间相似性，调整目标分布以模拟从头训练模型的行为。

Result: AMUN在图像分类任务中超越了现有SOTA方法，基于MIA得分评估。TRW在多个基准测试中匹配或超越了现有遗忘方法。理论分析表明模型平滑度是影响AMUN性能的关键因素。

Conclusion: 本文提出的AMUN和TRW方法为机器学习的样本遗忘和类别遗忘提供了有效的解决方案，能够更好地保护隐私并满足实际应用需求。模型平滑度和对抗样本迁移性是影响遗忘效果的重要因素。

Abstract: We propose new methodologies for both unlearning random set of samples and class unlearning and show that they outperform existing methods. The main driver of our unlearning methods is the similarity of predictions to a retrained model on both the forget and remain samples. We introduce Adversarial Machine UNlearning (AMUN), which surpasses prior state-of-the-art methods for image classification based on SOTA MIA scores. AMUN lowers the model's confidence on forget samples by fine-tuning on their corresponding adversarial examples. Through theoretical analysis, we identify factors governing AMUN's performance, including smoothness. To facilitate training of smooth models with a controlled Lipschitz constant, we propose FastClip, a scalable method that performs layer-wise spectral-norm clipping of affine layers. In a separate study, we show that increased smoothness naturally improves adversarial example transfer, thereby supporting the second factor above.
  Following the same principles for class unlearning, we show that existing methods fail in replicating a retrained model's behavior by introducing a nearest-neighbor membership inference attack (MIA-NN) that uses the probabilities assigned to neighboring classes to detect unlearned samples and demonstrate the vulnerability of such methods. We then propose a fine-tuning objective that mitigates this leakage by approximating, for forget-class inputs, the distribution over remaining classes that a model retrained from scratch would produce. To construct this approximation, we estimate inter-class similarity and tilt the target model's distribution accordingly. The resulting Tilted ReWeighting(TRW) distribution serves as the desired target during fine-tuning. Across multiple benchmarks, TRW matches or surpasses existing unlearning methods on prior metrics.

</details>


### [176] [Always Keep Your Promises: DynamicLRP, A Model-Agnostic Solution To Layer-Wise Relevance Propagation](https://arxiv.org/abs/2512.07010)
*Kevin Lee,Pablo Millan Arias*

Main category: cs.LG

TL;DR: DynamicLRP：首个模型无关的LRP框架，通过张量操作级分解和Promise系统实现架构无关性，无需修改模型即可应用于任意计算图


<details>
  <summary>Details</summary>
Motivation: 现有LRP实现基于模块级别，需要架构特定的传播规则和修改，限制了目标模型的通用性和实现的可持续性，无法适应不断演进的架构

Method: 提出DynamicLRP框架：1）在计算图内将归因分解到单个张量操作级别；2）引入Promise系统实现延迟激活解析；3）独立于反向传播机制，无需修改模型即可在任意计算图上运行

Result: 在31,465个计算图节点上实现99.92%的节点覆盖率，涵盖15种不同架构（包括Mamba、Whisper、DePlot等），仅需47个基础操作规则。性能匹配或超越专用实现，在VGG上ABPC为1.77 vs 1.69，在SQuADv2上RoBERTa-large和Flan-T5-large的top-1归因准确率分别为93.70%和95.06%

Conclusion: DynamicLRP通过操作级分解和Promise系统建立了可持续、可扩展的LRP基础，能够适应不断演进的架构，同时保持LRP的理论保证

Abstract: Layer-wise Relevance Propagation (LRP) provides principled attribution for neural networks through conservation properties and foundations in Deep Taylor Decomposition. However, existing implementations operate at the module level, requiring architecture-specific propagation rules and modifications. These limit the generality of target model and sustainability of implementations as architectures evolve. We introduce DynamicLRP, a model-agnostic LRP framework operating at the tensor operation level. By decomposing attribution to individual operations within computation graphs and introducing a novel mechanism for deferred activation resolution, named the Promise System, our approach achieves true architecture agnosticity while maintaining LRP's theoretical guarantees. This design operates independently of backpropagation machinery, enabling operation on arbitrary computation graphs without model modification and side-by-side execution with gradient backpropagation. Being based on computation graphs, this method is theoretically extensible to other deep learning libraries that support auto-differentiation. We demonstrate faithfulness matching or exceeding specialized implementations (1.77 vs 1.69 ABPC on VGG, equivalent performance on ViT, 93.70\% and 95.06\% top-1 attribution accuracy for explaining RoBERTa-large and Flan-T5-large answers on SQuADv2, respectively) while maintaining practical efficiency on models with hundreds of millions of parameters. We achieved 99.92\% node coverage across 31,465 computation graph nodes from 15 diverse architectures, including state-space models (Mamba), audio transformers (Whisper), and multimodal systems (DePlot) without any model-specific code with rules for 47 fundamental operations implemented. Our operation-level decomposition and Promise System establish a sustainable, extensible foundation for LRP across evolving architectures.

</details>


### [177] [Block Sparse Flash Attention](https://arxiv.org/abs/2512.07011)
*Daniel Ohayon,Itay Lamprecht,Itay Hubara,Israel Cohen,Daniel Soudry,Noam Elata*

Main category: cs.LG

TL;DR: BSFA是一种无需训练的长上下文注意力加速方法，通过计算精确的查询-键相似度选择最重要的值块，跳过约50%计算和内存传输，在保持99%以上基线准确率的同时实现1.10-1.24倍加速。


<details>
  <summary>Details</summary>
Motivation: 现代大语言模型需要处理长上下文，但注意力机制的二次复杂度造成严重计算瓶颈，需要高效的稀疏注意力方法来加速推理。

Method: BSFA通过计算精确的查询-键相似度，为每个查询选择top-k最重要的值块，通过比较每块最大分数与校准阈值来跳过约50%的计算和内存传输。只需在小数据集上进行一次性阈值校准来学习每层每头的注意力分数分布。

Result: 在Llama-3.1-8B上，BSFA在真实世界推理基准上实现最高1.10倍加速，在needle-in-a-haystack检索任务上实现最高1.24倍加速，同时保持99%以上基线准确率，某些配置甚至通过关注最相关内容提高了准确率。

Conclusion: BSFA是一种无需训练的高效稀疏注意力方法，可作为FlashAttention的即插即用替代，显著加速长上下文推理，在保持模型质量的同时超越现有稀疏注意力方法。

Abstract: Modern large language models increasingly require long contexts for reasoning and multi-document tasks, but attention's quadratic complexity creates a severe computational bottleneck. We present Block-Sparse FlashAttention (BSFA), a drop-in replacement that accelerates long-context inference while preserving model quality. Unlike methods that predict importance before computing scores, BSFA computes exact query-key similarities to select the top-k most important value blocks for each query. By comparing per-block maximum scores against calibrated thresholds, we skip approximately 50% of the computation and memory transfers for pruned blocks. Our training-free approach requires only a one-time threshold calibration on a small dataset to learn the per-layer and per-head attention score distributions. We provide a CUDA kernel implementation that can be used as a drop-in replacement for FlashAttention. On Llama-3.1-8B, BSFA achieves up to 1.10x speedup on real-world reasoning benchmarks and up to 1.24x for needle-in-a-haystack retrieval tasks while maintaining above 99% baseline accuracy, with certain configurations even improving accuracy by focusing on the most relevant content, substantially outperforming existing sparse attention methods. The implementation is available at https://github.com/Danielohayon/Block-Sparse-Flash-Attention

</details>


### [178] [Transferring Clinical Knowledge into ECGs Representation](https://arxiv.org/abs/2512.07021)
*Jose Geraldo Fernandes,Luiz Facury de Souza,Pedro Robles Dutenhefner,Gisele L. Pappa,Wagner Meira*

Main category: cs.LG

TL;DR: 提出三阶段训练范式，将多模态临床数据知识迁移到单模态ECG编码器，提升ECG分类准确性和可解释性


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在ECG分类中准确性高，但黑盒特性缺乏可解释性，阻碍临床采用。需要建立更可信、可解释的ECG分类模型

Method: 三阶段训练范式：1）自监督联合嵌入预训练，创建富含临床上下文信息的ECG表示；2）仅需ECG信号进行推理；3）训练模型从ECG嵌入预测相关实验室异常，作为间接解释机制

Result: 在MIMIC-IV-ECG数据集上，模型在多标签诊断分类中优于标准信号基线，显著缩小了与需要所有数据推理的全多模态模型的性能差距

Conclusion: 该方法为创建更准确、可信的ECG分类模型提供了实用有效的方法，通过将抽象预测转化为基于生理学的解释，为AI安全集成到临床工作流程提供了有前景的路径

Abstract: Deep learning models have shown high accuracy in classifying electrocardiograms (ECGs), but their black box nature hinders clinical adoption due to a lack of trust and interpretability. To address this, we propose a novel three-stage training paradigm that transfers knowledge from multimodal clinical data (laboratory exams, vitals, biometrics) into a powerful, yet unimodal, ECG encoder. We employ a self-supervised, joint-embedding pre-training stage to create an ECG representation that is enriched with contextual clinical information, while only requiring the ECG signal at inference time. Furthermore, as an indirect way to explain the model's output we train it to also predict associated laboratory abnormalities directly from the ECG embedding. Evaluated on the MIMIC-IV-ECG dataset, our model outperforms a standard signal-only baseline in multi-label diagnosis classification and successfully bridges a substantial portion of the performance gap to a fully multimodal model that requires all data at inference. Our work demonstrates a practical and effective method for creating more accurate and trustworthy ECG classification models. By converting abstract predictions into physiologically grounded \emph{explanations}, our approach offers a promising path toward the safer integration of AI into clinical workflows.

</details>


### [179] [Transformation of Biological Networks into Images via Semantic Cartography for Visual Interpretation and Scalable Deep Analysis](https://arxiv.org/abs/2512.07040)
*Sakib Mostafa,Lei Xing,Md. Tauhidul Islam*

Main category: cs.LG

TL;DR: Graph2Image将大型生物网络转换为二维图像，利用CNN进行高效分析，解决了传统方法在可扩展性、长程依赖和多模态集成方面的限制。


<details>
  <summary>Details</summary>
Motivation: 生物网络对生物医学研究至关重要，但现有分析方法（包括深度学习方法）面临可扩展性有限、长程依赖捕捉困难、多模态集成挑战、表达能力受限和可解释性差等问题。

Method: Graph2Image框架将大型生物网络转换为二维图像集，通过在2D网格上空间排列代表性网络节点，将节点解耦为图像，从而能够利用具有全局感受野和多尺度金字塔的卷积神经网络。

Result: 在多个大规模生物网络数据集上，Graph2Image相比现有方法将分类准确率提高了高达67.2%，提供了可解释的可视化，揭示了生物学上一致的规律，并能在个人计算机上分析超过10亿节点的超大规模网络。

Conclusion: Graph2Image为生物网络分析提供了一个可扩展、可解释且支持多模态的方法，为疾病诊断和复杂生物系统研究提供了新的机会。

Abstract: Complex biological networks are fundamental to biomedical science, capturing interactions among molecules, cells, genes, and tissues. Deciphering these networks is critical for understanding health and disease, yet their scale and complexity represent a daunting challenge for current computational methods. Traditional biological network analysis methods, including deep learning approaches, while powerful, face inherent challenges such as limited scalability, oversmoothing long-range dependencies, difficulty in multimodal integration, expressivity bounds, and poor interpretability. We present Graph2Image, a framework that transforms large biological networks into sets of two-dimensional images by spatially arranging representative network nodes on a 2D grid. This transformation decouples the nodes as images, enabling the use of convolutional neural networks (CNNs) with global receptive fields and multi-scale pyramids, thus overcoming limitations of existing biological network analysis methods in scalability, memory efficiency, and long-range context capture. Graph2Image also facilitates seamless integration with other imaging and omics modalities and enhances interpretability through direct visualization of node-associated images. When applied to several large-scale biological network datasets, Graph2Image improved classification accuracy by up to 67.2% over existing methods and provided interpretable visualizations that revealed biologically coherent patterns. It also allows analysis of very large biological networks (nodes > 1 billion) on a personal computer. Graph2Image thus provides a scalable, interpretable, and multimodal-ready approach for biological network analysis, offering new opportunities for disease diagnosis and the study of complex biological systems.

</details>


### [180] [Self-Supervised Learning on Molecular Graphs: A Systematic Investigation of Masking Design](https://arxiv.org/abs/2512.07064)
*Jiannan Yang,Veronika Thost,Tengfei Ma*

Main category: cs.LG

TL;DR: 该研究通过概率框架系统评估分子图自监督学习中的掩码策略，发现对于常见节点级预测任务，复杂掩码分布相比均匀采样并无优势，而预测目标和编码器架构的协同更为关键。


<details>
  <summary>Details</summary>
Motivation: 当前分子表示学习中，许多基于掩码的预训练方法都是启发式设计，缺乏系统评估，难以确定哪些设计选择真正有效。需要建立统一框架来透明比较和理解掩码策略。

Method: 将预训练-微调流程统一到概率框架中，在严格控制的设置下系统研究三个核心设计维度：掩码分布、预测目标和编码器架构，并使用信息论指标评估预训练信号的信息量。

Result: 研究发现：1) 对于常见节点级预测任务，复杂掩码分布相比均匀采样没有一致优势；2) 预测目标的选择及其与编码器架构的协同更为关键；3) 使用语义更丰富的预测目标能带来显著下游性能提升，特别是与表达能力强的图Transformer编码器结合时。

Conclusion: 该研究为分子图自监督学习提供了实用指导：应更关注预测目标和编码器架构的协同设计，而非过度优化掩码分布策略，这有助于开发更有效的分子表示学习方法。

Abstract: Self-supervised learning (SSL) plays a central role in molecular representation learning. Yet, many recent innovations in masking-based pretraining are introduced as heuristics and lack principled evaluation, obscuring which design choices are genuinely effective. This work cast the entire pretrain-finetune workflow into a unified probabilistic framework, enabling a transparent comparison and deeper understanding of masking strategies. Building on this formalism, we conduct a controlled study of three core design dimensions: masking distribution, prediction target, and encoder architecture, under rigorously controlled settings. We further employ information-theoretic measures to assess the informativeness of pretraining signals and connect them to empirically benchmarked downstream performance. Our findings reveal a surprising insight: sophisticated masking distributions offer no consistent benefit over uniform sampling for common node-level prediction tasks. Instead, the choice of prediction target and its synergy with the encoder architecture are far more critical. Specifically, shifting to semantically richer targets yields substantial downstream improvements, particularly when paired with expressive Graph Transformer encoders. These insights offer practical guidance for developing more effective SSL methods for molecular graphs.

</details>


### [181] [Procrustean Bed for AI-Driven Retrosynthesis: A Unified Framework for Reproducible Evaluation](https://arxiv.org/abs/2512.07079)
*Anton Morgunov,Victor S. Batista*

Main category: cs.LG

TL;DR: RetroCast是一个统一的评估套件，用于标准化计算机辅助合成规划（CASP）模型的评估，揭示高"可解性"分数常掩盖化学无效性，且搜索方法在重建长程合成计划时存在"复杂性悬崖"。


<details>
  <summary>Details</summary>
Motivation: 计算机辅助合成规划领域缺乏标准化评估基础设施，现有指标过于关注拓扑完成度而忽视化学有效性，阻碍了该领域的透明和可重复发展。

Method: 开发RetroCast评估套件，包括：1）统一模式标准化异构模型输出；2）可重复基准测试流程（分层抽样和自举置信区间）；3）SynthArena交互式平台用于定性路线检查；4）在新标准化基准上评估领先的搜索式和序列式算法。

Result: 发现"可解性"（库存终止率）与路线质量存在分歧：高可解性分数常掩盖化学无效性，且与实验真实情况再现不相关。识别出"复杂性悬崖"现象：搜索方法尽管可解性高，但在重建长程合成计划时性能急剧下降，而序列方法表现更好。

Conclusion: RetroCast框架为CASP领域提供了透明、可重复的评估基础设施，揭示了当前评估指标的局限性，并发布了完整框架、基准定义和标准化模型预测数据库以支持该领域发展。

Abstract: Progress in computer-aided synthesis planning (CASP) is obscured by the lack of standardized evaluation infrastructure and the reliance on metrics that prioritize topological completion over chemical validity. We introduce RetroCast, a unified evaluation suite that standardizes heterogeneous model outputs into a common schema to enable statistically rigorous, apples-to-apples comparison. The framework includes a reproducible benchmarking pipeline with stratified sampling and bootstrapped confidence intervals, accompanied by SynthArena, an interactive platform for qualitative route inspection. We utilize this infrastructure to evaluate leading search-based and sequence-based algorithms on a new suite of standardized benchmarks. Our analysis reveals a divergence between "solvability" (stock-termination rate) and route quality; high solvability scores often mask chemical invalidity or fail to correlate with the reproduction of experimental ground truths. Furthermore, we identify a "complexity cliff" in which search-based methods, despite high solvability rates, exhibit a sharp performance decay in reconstructing long-range synthetic plans compared to sequence-based approaches. We release the full framework, benchmark definitions, and a standardized database of model predictions to support transparent and reproducible development in the field.

</details>


### [182] [TRACE: A Generalizable Drift Detector for Streaming Data-Driven Optimization](https://arxiv.org/abs/2512.07082)
*Yuan-Ting Zhong,Ting Huang,Xiaolin Xiao,Yue-Jiao Gong*

Main category: cs.LG

TL;DR: 提出了TRACE方法，一种可迁移的概念漂移估计器，用于检测流数据中的分布变化，并将其集成到流优化器中实现自适应优化。


<details>
  <summary>Details</summary>
Motivation: 流数据驱动优化面临未知概念漂移的挑战，现有方法通常基于固定漂移间隔和完全环境可观测性等限制性假设，难以适应多样化的动态环境。

Method: TRACE采用原则性标记化策略从数据流中提取统计特征，利用基于注意力的序列学习建模漂移模式，实现未见数据集上的准确检测，展示学习漂移模式的可迁移性。

Result: 在多样化基准测试中，TRACE表现出优越的泛化能力、鲁棒性和有效性，能够准确检测不同时间尺度的分布变化。

Conclusion: TRACE作为一种可插拔的概念漂移检测器，能够有效处理流数据中的未知概念漂移，提升流数据驱动优化的适应性和性能。

Abstract: Many optimization tasks involve streaming data with unknown concept drifts, posing a significant challenge as Streaming Data-Driven Optimization (SDDO). Existing methods, while leveraging surrogate model approximation and historical knowledge transfer, are often under restrictive assumptions such as fixed drift intervals and fully environmental observability, limiting their adaptability to diverse dynamic environments. We propose TRACE, a TRAnsferable C}oncept-drift Estimator that effectively detects distributional changes in streaming data with varying time scales. TRACE leverages a principled tokenization strategy to extract statistical features from data streams and models drift patterns using attention-based sequence learning, enabling accurate detection on unseen datasets and highlighting the transferability of learned drift patterns. Further, we showcase TRACE's plug-and-play nature by integrating it into a streaming optimizer, facilitating adaptive optimization under unknown drifts. Comprehensive experimental results on diverse benchmarks demonstrate the superior generalization, robustness, and effectiveness of our approach in SDDO scenarios.

</details>


### [183] [The Geometry of Persona: Disentangling Personality from Reasoning in Large Language Models](https://arxiv.org/abs/2512.07092)
*Zhixiang Wang*

Main category: cs.LG

TL;DR: 提出Soul Engine框架，基于线性表示假设，通过提取解耦的人格向量实现个性化LLM，无需微调主干权重，避免对齐税。


<details>
  <summary>Details</summary>
Motivation: 当前个性化LLM部署受稳定性-可塑性困境约束，传统对齐方法（如SFT）依赖随机权重更新，常导致"对齐税"——降低通用推理能力。

Method: 基于线性表示假设（人格特征存在于正交线性子空间），提出Soul Engine框架，使用SoulBench数据集（动态上下文采样构建），在冻结的Qwen-2.5基础上采用双头架构提取解耦人格向量，不修改主干权重。

Result: 三个突破：1) 高精度画像：MSE为0.011；2) 几何正交性：T-SNE可视化确认人格流形离散连续，实现"零样本人格注入"保持原始智能；3) 确定性引导：通过向量算术实现行为鲁棒控制。

Conclusion: 挑战了微调对个性化的必要性，从概率提示转向确定性潜在干预，为安全可控的AI个性化提供了数学严谨的基础。

Abstract: Background: The deployment of personalized Large Language Models (LLMs) is currently constrained by the stability-plasticity dilemma. Prevailing alignment methods, such as Supervised Fine-Tuning (SFT), rely on stochastic weight updates that often incur an "alignment tax" -- degrading general reasoning capabilities.
  Methods: We propose the Soul Engine, a framework based on the Linear Representation Hypothesis, which posits that personality traits exist as orthogonal linear subspaces. We introduce SoulBench, a dataset constructed via dynamic contextual sampling. Using a dual-head architecture on a frozen Qwen-2.5 base, we extract disentangled personality vectors without modifying the backbone weights.
  Results: Our experiments demonstrate three breakthroughs. First, High-Precision Profiling: The model achieves a Mean Squared Error (MSE) of 0.011 against psychological ground truth. Second, Geometric Orthogonality: T-SNE visualization confirms that personality manifolds are distinct and continuous, allowing for "Zero-Shot Personality Injection" that maintains original model intelligence. Third, Deterministic Steering: We achieve robust control over behavior via vector arithmetic, validated through extensive ablation studies.
  Conclusion: This work challenges the necessity of fine-tuning for personalization. By transitioning from probabilistic prompting to deterministic latent intervention, we provide a mathematically rigorous foundation for safe, controllable AI personalization.

</details>


### [184] [Dual Refinement Cycle Learning: Unsupervised Text Classification of Mamba and Community Detection on Text Attributed Graph](https://arxiv.org/abs/2512.07100)
*Hong Wang,Yinglong Zhang,Hanhan Guo,Xuewen Xia,Xing Xu*

Main category: cs.LG

TL;DR: DRCL是一个完全无监督的框架，通过双向精炼循环整合图结构和文本语义信息，用于文本属性网络中的社区发现，无需标签或类别定义。


<details>
  <summary>Details</summary>
Motivation: 预训练语言模型依赖大量标注数据难以部署到真实文本属性网络中，而传统社区检测方法忽略文本语义信息，限制了在下游应用中的实用性。

Method: 提出双精炼循环学习框架，包含GCN社区检测模块和文本语义建模模块，通过热启动初始化和双向伪标签交换，实现结构和语义信息的相互增强。

Result: 在多个文本属性图数据集上，DRCL持续提升发现社区的结构和语义质量；基于DRCL社区信号训练的Mamba分类器达到与监督模型相当的准确率。

Conclusion: DRCL展示了在标注数据稀缺或昂贵的大规模系统中部署的潜力，通过无监督方式有效整合结构和语义信息，为实际应用提供了可行解决方案。

Abstract: Pretrained language models offer strong text understanding capabilities but remain difficult to deploy in real-world text-attributed networks due to their heavy dependence on labeled data. Meanwhile, community detection methods typically ignore textual semantics, limiting their usefulness in downstream applications such as content organization, recommendation, and risk monitoring. To overcome these limitations, we present Dual Refinement Cycle Learning (DRCL), a fully unsupervised framework designed for practical scenarios where no labels or category definitions are available.
  DRCL integrates structural and semantic information through a warm-start initialization and a bidirectional refinement cycle between a GCN-based Community Detection Module (GCN-CDM) and a Text Semantic Modeling Module (TSMM). The two modules iteratively exchange pseudo-labels, allowing semantic cues to enhance structural clustering and structural patterns to guide text representation learning without manual supervision.
  Across several text-attributed graph datasets, DRCL consistently improves the structural and semantic quality of discovered communities. Moreover, a Mamba-based classifier trained solely from DRCL's community signals achieves accuracy comparable to supervised models, demonstrating its potential for deployment in large-scale systems where labeled data are scarce or costly.

</details>


### [185] [FOAM: Blocked State Folding for Memory-Efficient LLM Training](https://arxiv.org/abs/2512.07112)
*Ziqing Wen,Jiahuan Wang,Ping Luo,Dongsheng Li,Tao Sun*

Main category: cs.LG

TL;DR: FOAM是一种内存高效的优化器，通过块级梯度均值和残差校正压缩优化器状态，减少50%训练内存，消除90%优化器状态内存开销，同时保持与Adam相当的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型训练时面临严重的内存瓶颈，特别是使用Adam等内存密集型优化器时。现有内存高效方法存在计算开销大、需要额外内存或性能下降等问题。

Method: 提出FOAM方法：1) 通过计算块级梯度均值压缩优化器状态；2) 引入残差校正恢复丢失的信息；3) 保持与vanilla Adam的理论收敛等价性。

Result: FOAM减少约50%总训练内存，消除高达90%的优化器状态内存开销，加速收敛，且与其他内存高效优化器兼容，性能匹配或超越现有基准。

Conclusion: FOAM提供了一种有效解决LLM训练内存瓶颈的方法，在保持性能的同时显著减少内存需求，具有实际应用价值。

Abstract: Large language models (LLMs) have demonstrated remarkable performance due to their large parameter counts and extensive training data. However, their scale leads to significant memory bottlenecks during training, especially when using memory-intensive optimizers like Adam. Existing memory-efficient approaches often rely on techniques such as singular value decomposition (SVD), projections, or weight freezing, which can introduce substantial computational overhead, require additional memory for projections, or degrade model performance. In this paper, we propose Folded Optimizer with Approximate Moment (FOAM), a method that compresses optimizer states by computing block-wise gradient means and incorporates a residual correction to recover lost information. Theoretically, FOAM achieves convergence rates equivalent to vanilla Adam under standard non-convex optimization settings. Empirically, FOAM reduces total training memory by approximately 50\%, eliminates up to 90\% of optimizer state memory overhead, and accelerates convergence. Furthermore, FOAM is compatible with other memory-efficient optimizers, delivering performance and throughput that match or surpass both full-rank and existing memory-efficient baselines.

</details>


### [186] [PlantBiMoE: A Bidirectional Foundation Model with SparseMoE for Plant Genomes](https://arxiv.org/abs/2512.07113)
*Kepeng Lin,Qizhe Zhang,Rui Wang,Xuehai Hu,Wei Xu*

Main category: cs.LG

TL;DR: PlantBiMoE是一个轻量级植物基因组语言模型，结合双向Mamba和稀疏专家混合框架，在MPGB基准测试中优于现有方法，在31个数据集的20个上取得最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有植物基因组模型如AgroNT和PDLLMs存在参数过大或无法有效建模DNA双链双向性的问题，需要更高效且能捕捉DNA双向结构依赖的模型。

Method: 提出PlantBiMoE模型，整合双向Mamba来捕捉DNA正反链的结构依赖，采用稀疏专家混合框架减少活跃参数数量，提升计算效率而不牺牲建模能力。

Result: 在MPGB基准测试（包含31个数据集、11个代表性任务）中，PlantBiMoE在20个数据集上取得最佳性能，平均性能也优于现有模型。

Conclusion: PlantBiMoE能有效表示植物基因组序列，为植物基因组学、基因编辑和合成生物学提供强大的计算工具，代码已开源。

Abstract: Understanding the underlying linguistic rules of plant genomes remains a fundamental challenge in computational biology. Recent advances including AgroNT and PDLLMs have made notable progress although, they suffer from excessive parameter size and limited ability to model the bidirectional nature of DNA strands respectively. To address these limitations, we propose PlantBiMoE, a lightweight and expressive plant genome language model that integrates bidirectional Mamba and a Sparse Mixture-of-Experts (SparseMoE) framework. The bidirectional Mamba enables the model to effectively capture structural dependencies across both the forward and reverse DNA strands, while SparseMoE significantly reduces the number of active parameters, improving computational efficiency without sacrificing modeling capacity. We evaluated and tested our model on the Modified Plants Genome Benchmark (MPGB), an enhanced genomic benchmark, which consolidates 31 datasets across 11 representative tasks, with input sequence lengths ranging from 50 to 6,000 bp. Experimental results demonstrate that PlantBiMoE achieves the best performance on 20 out of 31 datasets and the average best when comparing with existing models. In summary, all above results demonstrate that our model can effectively represent plant genomic sequences, serving as a robust computational tool for diverse genomic tasks, while making substantive contributions to plant genomics, gene editing, and synthetic biology. The code is available at: https://github.com/HUST-Keep-Lin/PlantBiMoE

</details>


### [187] [Winning the Lottery by Preserving Network Training Dynamics with Concrete Ticket Search](https://arxiv.org/abs/2512.07142)
*Tanay Arora,Christof Teuscher*

Main category: cs.LG

TL;DR: CTS算法通过组合优化和梯度平衡，在初始化阶段高效找到高性能稀疏子网络，性能超越传统剪枝方法，计算成本远低于彩票票证重绕方法。


<details>
  <summary>Details</summary>
Motivation: 现有彩票票证发现方法存在计算成本高（如LTR）或精度-稀疏度权衡差（如PaI）的问题，PaI方法依赖一阶显著性指标忽略了权重间依赖关系，尤其在稀疏区域表现不佳。

Method: 提出Concrete Ticket Search (CTS)算法，将子网络发现建模为组合优化问题，使用Concrete松弛离散搜索空间，采用GRADBALANCE梯度平衡方案控制稀疏度，并提出基于知识蒸馏的剪枝目标（特别是最小化稀疏与密集网络输出的反向KL散度CTS-KL）。

Result: CTS产生的子网络能稳健通过合理性检查，在精度上达到或超过LTR，同时计算成本显著降低。例如在ResNet-20/CIFAR10上，达到99.3%稀疏度时精度74.0%（LTR为68.3%），计算时间仅7.9分钟（LTR需95.2分钟）。

Conclusion: CTS通过整体组合优化方法有效解决了初始化剪枝方法的局限性，在高度稀疏区域表现尤为突出，为高效发现高性能彩票票证提供了新途径。

Abstract: The Lottery Ticket Hypothesis asserts the existence of highly sparse, trainable subnetworks ('winning tickets') within dense, randomly initialized neural networks. However, state-of-the-art methods of drawing these tickets, like Lottery Ticket Rewinding (LTR), are computationally prohibitive, while more efficient saliency-based Pruning-at-Initialization (PaI) techniques suffer from a significant accuracy-sparsity trade-off and fail basic sanity checks. In this work, we argue that PaI's reliance on first-order saliency metrics, which ignore inter-weight dependencies, contributes substantially to this performance gap, especially in the sparse regime. To address this, we introduce Concrete Ticket Search (CTS), an algorithm that frames subnetwork discovery as a holistic combinatorial optimization problem. By leveraging a Concrete relaxation of the discrete search space and a novel gradient balancing scheme (GRADBALANCE) to control sparsity, CTS efficiently identifies high-performing subnetworks near initialization without requiring sensitive hyperparameter tuning. Motivated by recent works on lottery ticket training dynamics, we further propose a knowledge distillation-inspired family of pruning objectives, finding that minimizing the reverse Kullback-Leibler divergence between sparse and dense network outputs (CTS-KL) is particularly effective. Experiments on varying image classification tasks show that CTS produces subnetworks that robustly pass sanity checks and achieve accuracy comparable to or exceeding LTR, while requiring only a small fraction of the computation. For example, on ResNet-20 on CIFAR10, it reaches 99.3% sparsity with 74.0% accuracy in 7.9 minutes, while LTR attains the same sparsity with 68.3% accuracy in 95.2 minutes. CTS's subnetworks outperform saliency-based methods across all sparsities, but its advantage over LTR is most pronounced in the highly sparse regime.

</details>


### [188] [FlowLPS: Langevin-Proximal Sampling for Flow-based Inverse Problem Solvers](https://arxiv.org/abs/2512.07150)
*Jonghyun Park,Jong Chul Ye*

Main category: cs.LG

TL;DR: FlowLPS：基于预训练流模型解决逆问题的新框架，通过朗之万近端采样策略，在FFHQ和DIV2K数据集上超越现有方法


<details>
  <summary>Details</summary>
Motivation: 现有基于深度生成模型的训练免费方法在应用于流模型时存在两个主要问题：1) 难以收敛到后验模式；2) 在潜在空间中存在流形偏差。需要一种新框架来解决这些问题。

Method: FlowLPS框架结合朗之万动力学进行流形一致探索和近端优化进行精确模式搜索。朗之万动力学确保在潜在空间中的一致探索，而近端优化则专注于寻找精确的后验模式。

Result: 在FFHQ和DIV2K数据集上的多个逆问题任务中，FlowLPS在重建保真度和感知质量之间取得了优越的平衡，超越了现有的最先进逆问题求解器。

Conclusion: FlowLPS通过朗之万近端采样策略有效解决了流模型在逆问题应用中的收敛和流形偏差问题，为基于预训练流模型的逆问题求解提供了有效的训练免费框架。

Abstract: Deep generative models have become powerful priors for solving inverse problems, and various training-free methods have been developed. However, when applied to latent flow models, existing methods often fail to converge to the posterior mode or suffer from manifold deviation within latent spaces. To mitigate this, here we introduce a novel training-free framework, FlowLPS, that solves inverse problems with pretrained flow models via a Langevin Proximal Sampling (LPS) strategy. Our method integrates Langevin dynamics for manifold-consistent exploration with proximal optimization for precise mode seeking, achieving a superior balance between reconstruction fidelity and perceptual quality across multiple inverse tasks on FFHQ and DIV2K, outperforming state of the art inverse solvers.

</details>


### [189] [Improving the Throughput of Diffusion-based Large Language Models via a Training-Free Confidence-Aware Calibration](https://arxiv.org/abs/2512.07173)
*Jucheng Shen,Gaurav Sarkar,Yeonju Ro,Sharath Nittur Sridhar,Zhangyang Wang,Aditya Akella,Souvik Kundu*

Main category: cs.LG

TL;DR: CadLLM是一种无需训练的方法，通过自适应控制生成块大小、步长和阈值来加速基于扩散的大语言模型推理，实现最高2.28倍吞吐量提升


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散的大语言模型推理效率较低，需要加速推理吞吐量。作者观察到token unmasking置信度在不同块和步骤中具有动态特性，这为优化提供了机会

Method: 1. 分析token unmasking置信度在不同块和步骤中的动态特性；2. 提出轻量级自适应方法，根据未mask token的平均置信度控制生成块大小、步长和阈值；3. 通过动态利用词汇表子集来减少softmax开销，调节采样广度

Result: 在四个流行任务上的实验表明，CadLLM相比最先进的基线方法实现了最高2.28倍的吞吐量提升，同时保持了有竞争力的准确性

Conclusion: CadLLM是一种即插即用、模型无关的方法，兼容基于KV缓存的扩散大语言模型，能显著提升推理效率而不损失准确性

Abstract: We present CadLLM, a training-free method to accelerate the inference throughput of diffusion-based LLMs (dLLMs). We first investigate the dynamic nature of token unmasking confidence across blocks and steps. Based on this observation, we present a lightweight adaptive approach that controls the generation block size, step size, and threshold based on the average confidence of unmasked tokens. We further reduce softmax overhead by dynamically leveraging a subset of the vocabulary to regulate sampling breadth. CadLLM is a plug-and-play, model-agnostic method compatible with KV-cache-based dLLMs. Extensive experiments on four popular tasks demonstrate that CadLLM yields up to 2.28x throughput improvement over the state-of-the-art baseline with competitive accuracy.

</details>


### [190] [SPACE: Noise Contrastive Estimation Stabilizes Self-Play Fine-Tuning for Large Language Models](https://arxiv.org/abs/2512.07175)
*Yibo Wang,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang,Lijun Zhang*

Main category: cs.LG

TL;DR: SPACE是一种基于噪声对比估计的自对弈微调方法，通过将合成样本作为辅助成分，以二分类方式区分真实数据，避免传统基于奖励差距方法的不稳定问题，实现稳定收敛到真实数据分布。


<details>
  <summary>Details</summary>
Motivation: 现有自对弈微调方法主要关注真实数据和合成数据之间的奖励差距，忽略了绝对奖励值，导致目标函数可能退化，造成不稳定演化。需要一种能稳定收敛到真实数据分布的方法。

Method: 提出SPACE方法，使用噪声对比估计捕捉真实世界数据分布。将合成样本作为辅助成分，通过二分类方式区分真实样本和合成样本，独立优化每种数据的绝对奖励值，确保目标函数始终有意义。

Result: 理论证明SPACE的最优解与真实世界数据的基础分布一致，并能保证稳定收敛到最优分布。实证表明SPACE在各种任务上显著提升LLM性能，优于使用更多真实样本的监督微调，相比基于差距的自对弈方法表现出显著优势和稳定演化。

Conclusion: SPACE通过噪声对比估计解决了传统自对弈微调的不稳定问题，能够稳定地学习真实数据分布，在有限真实数据情况下有效提升模型性能，为LLM微调提供了更可靠的方法。

Abstract: Self-play fine-tuning has demonstrated promising abilities in adapting large language models (LLMs) to downstream tasks with limited real-world data. The basic principle is to iteratively refine the model with real samples and synthetic ones generated from itself. However, the existing methods primarily focus on the relative gaps between the rewards for two types of data, neglecting their absolute values. Through theoretical analysis, we identify that the gap-based methods suffer from unstable evolution, due to the potentially degenerated objectives. To address this limitation, we introduce a novel self-play fine-tuning method, namely Self-PlAy via Noise Contrastive Estimation (SPACE), which leverages noise contrastive estimation to capture the real-world data distribution. Specifically, SPACE treats synthetic samples as auxiliary components, and discriminates them from the real ones in a binary classification manner. As a result, SPACE independently optimizes the absolute reward values for each type of data, ensuring a consistently meaningful objective and thereby avoiding the instability issue. Theoretically, we show that the optimal solution of the objective in SPACE aligns with the underlying distribution of real-world data, and SPACE guarantees a provably stable convergence to the optimal distribution. Empirically, we show that SPACE significantly improves the performance of LLMs over various tasks, and outperforms supervised fine-tuning that employs much more real-world samples. Compared to gap-based self-play fine-tuning methods, SPACE exhibits remarkable superiority and stable evolution.

</details>


### [191] [UniDiff: A Unified Diffusion Framework for Multimodal Time Series Forecasting](https://arxiv.org/abs/2512.07184)
*Da Zhang,Bingyu Li,Zhuyuan Zhao,Junyu Gao,Feiping Nie,Xuelong Li*

Main category: cs.LG

TL;DR: UniDiff是一个用于多模态时间序列预测的统一扩散框架，通过并行融合模块整合文本和时间戳信息，在多领域基准数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 随着多模态数据在现实应用中的激增，利用文本和时间戳等异构信息进行准确的时间序列预测成为一个关键挑战。现有的扩散模型主要局限于单模态数值序列建模，忽略了复杂异构数据中丰富的跨模态信号。

Method: 提出UniDiff统一扩散框架：1) 将时间序列分块并映射到嵌入空间；2) 核心是统一的并行融合模块，使用单一交叉注意力机制一步整合时间戳的结构信息和文本的语义上下文；3) 引入针对多源条件的新型无分类器引导机制，可在推理时分别控制文本和时间信息的引导强度。

Result: 在八个领域的真实世界基准数据集上进行广泛实验，证明UniDiff模型达到了最先进的性能。

Conclusion: UniDiff成功解决了多模态时间序列预测的挑战，通过统一的扩散框架有效整合异构信息，显著提升了预测性能。

Abstract: As multimodal data proliferates across diverse real-world applications, leveraging heterogeneous information such as texts and timestamps for accurate time series forecasting (TSF) has become a critical challenge. While diffusion models demonstrate exceptional performance in generation tasks, their application to TSF remains largely confined to modeling single-modality numerical sequences, overlooking the abundant cross-modal signals inherent in complex heterogeneous data. To address this gap, we propose UniDiff, a unified diffusion framework for multimodal time series forecasting. To process the numerical sequence, our framework first tokenizes the time series into patches, preserving local temporal dynamics by mapping each patch to an embedding space via a lightweight MLP. At its core lies a unified and parallel fusion module, where a single cross-attention mechanism adaptively weighs and integrates structural information from timestamps and semantic context from texts in one step, enabling a flexible and efficient interplay between modalities. Furthermore, we introduce a novel classifier-free guidance mechanism designed for multi-source conditioning, allowing for decoupled control over the guidance strength of textual and temporal information during inference, which significantly enhances model robustness. Extensive experiments on real-world benchmark datasets across eight domains demonstrate that the proposed UniDiff model achieves state-of-the-art performance.

</details>


### [192] [Less is More: Non-uniform Road Segments are Efficient for Bus Arrival Prediction](https://arxiv.org/abs/2512.07200)
*Zhen Huang,Jiaxin Deng,Jiayu Xu,Junbiao Pang,Haitao Yu*

Main category: cs.LG

TL;DR: 提出基于强化学习的非均匀道路分段方法，用于公交车到达时间预测，相比传统均匀分段策略在效率和性能上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统公交车到达时间预测系统采用均匀道路分段策略，无法考虑道路条件、交叉口、兴趣点等物理约束的差异，限制了预测效率。需要一种能自适应学习非均匀道路分段的方法。

Method: 采用两阶段方法：1) 基于强化学习框架，根据影响分数提取非均匀道路分段；2) 在线性预测模型中对选定分段进行预测。该方法在保证计算效率的同时实现最优分段选择。

Result: 实验结果表明，该方法在大规模基准测试中不仅提高了效率，还改善了学习性能。线性方法甚至能比更复杂的方法获得更好的性能。

Conclusion: 提出的基于强化学习的非均匀道路分段方法在公交车到达时间预测中优于传统均匀分段策略，实现了效率与性能的双重提升。数据集和代码已开源。

Abstract: In bus arrival time prediction, the process of organizing road infrastructure network data into homogeneous entities is known as segmentation. Segmenting a road network is widely recognized as the first and most critical step in developing an arrival time prediction system, particularly for auto-regressive-based approaches. Traditional methods typically employ a uniform segmentation strategy, which fails to account for varying physical constraints along roads, such as road conditions, intersections, and points of interest, thereby limiting prediction efficiency. In this paper, we propose a Reinforcement Learning (RL)-based approach to efficiently and adaptively learn non-uniform road segments for arrival time prediction. Our method decouples the prediction process into two stages: 1) Non-uniform road segments are extracted based on their impact scores using the proposed RL framework; and 2) A linear prediction model is applied to the selected segments to make predictions. This method ensures optimal segment selection while maintaining computational efficiency, offering a significant improvement over traditional uniform approaches. Furthermore, our experimental results suggest that the linear approach can even achieve better performance than more complex methods. Extensive experiments demonstrate the superiority of the proposed method, which not only enhances efficiency but also improves learning performance on large-scale benchmarks. The dataset and the code are publicly accessible at: https://github.com/pangjunbiao/Less-is-More.

</details>


### [193] [Geometric Prior-Guided Federated Prompt Calibration](https://arxiv.org/abs/2512.07208)
*Fei Luo,Ziwei Zhao,Mingxuan Wang,Duoyang Li,Zhe Qian,Jiayi Tuo,Chenyue Zhou,Yanbiao Ma*

Main category: cs.LG

TL;DR: GGTPC提出几何引导的文本提示校准框架，通过全局几何先验校正联邦提示学习中数据异构导致的本地训练偏差，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 联邦提示学习(FPL)在数据异构场景下性能严重受限，本地训练的提示会变得有偏差。现有方法聚焦于聚合或正则化，未能解决本地训练偏差的根本原因。

Method: 提出几何引导的文本提示校准(GGTPC)框架：1) 服务器端通过协方差矩阵重构全局数据分布的几何形状作为全局几何先验；2) 客户端使用几何先验校准层(GPCL)在训练时将本地特征分布与全局先验对齐。

Result: 在标签倾斜的CIFAR-100数据集上(β=0.1)，比SOTA提升2.15%；在极端倾斜(β=0.01)时比基线提升9.17%；在领域倾斜的Office-Home数据集上作为即插即用模块，将FedAvg性能提升4.60%。

Conclusion: GGTPC通过校正本地训练偏差有效缓解数据异构问题，可作为通用模块增强各种联邦学习算法，证明了全局几何先验在联邦提示学习中的有效性。

Abstract: Federated Prompt Learning (FPL) offers a parameter-efficient solution for collaboratively training large models, but its performance is severely hindered by data heterogeneity, which causes locally trained prompts to become biased. Existing methods, focusing on aggregation or regularization, fail to address this root cause of local training bias. To this end, we propose Geometry-Guided Text Prompt Calibration (GGTPC), a novel framework that directly corrects this bias by providing clients with a global geometric prior. This prior, representing the shape of the global data distribution derived from the covariance matrix, is reconstructed on the server in a privacy-preserving manner. Clients then use a novel Geometry-Prior Calibration Layer (GPCL) to align their local feature distributions with this global prior during training. Extensive experiments show GGTPC's effectiveness. On the label-skewed CIFAR-100 dataset ($β$=0.1), it outperforms the state-of-the-art by 2.15\%. Under extreme skew ($β$=0.01), it improves upon the baseline by 9.17\%. Furthermore, as a plug-and-play module on the domain-skewed Office-Home dataset, it boosts FedAvg's performance by 4.60\%. These results demonstrate that GGTPC effectively mitigates data heterogeneity by correcting the fundamental local training bias, serving as a versatile module to enhance various FL algorithms.

</details>


### [194] [Pay Less Attention to Function Words for Free Robustness of Vision-Language Models](https://arxiv.org/abs/2512.07222)
*Qiwei Tian,Chenhao Lin,Zhengyu Zhao,Chao Shen*

Main category: cs.LG

TL;DR: 提出Function-word De-Attention (FDA)方法，通过减少功能词在跨模态注意力中的影响，提升视觉语言模型的鲁棒性，在对抗攻击下显著降低攻击成功率，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有鲁棒视觉语言模型在鲁棒性和性能之间存在权衡问题。研究发现功能词是模型在跨模态对抗攻击下的脆弱点，需要专门的方法来减轻功能词的影响。

Method: 提出Function-word De-Attention (FDA)方法，类似于差分放大器，计算原始跨模态注意力和功能词跨模态注意力，然后将后者从前者中差分减去，从而获得更对齐和鲁棒的视觉语言模型。

Result: 在6种不同攻击、2个下游任务、3个数据集和3个模型上的综合实验显示：在检索任务上，FDA使3个测试模型的攻击成功率平均下降18%/13%/53%，性能仅下降0.2%/0.3%/0.6%；在视觉定位任务上，攻击成功率下降90%，性能反而提升0.3%。

Conclusion: FDA方法有效提升了视觉语言模型在对抗攻击下的鲁棒性，同时保持了模型性能，具有良好的可扩展性、泛化能力和零样本性能。

Abstract: To address the trade-off between robustness and performance for robust VLM, we observe that function words could incur vulnerability of VLMs against cross-modal adversarial attacks, and propose Function-word De-Attention (FDA) accordingly to mitigate the impact of function words. Similar to differential amplifiers, our FDA calculates the original and the function-word cross-attention within attention heads, and differentially subtracts the latter from the former for more aligned and robust VLMs. Comprehensive experiments include 2 SOTA baselines under 6 different attacks on 2 downstream tasks, 3 datasets, and 3 models. Overall, our FDA yields an average 18/13/53% ASR drop with only 0.2/0.3/0.6% performance drops on the 3 tested models on retrieval, and a 90% ASR drop with a 0.3% performance gain on visual grounding. We demonstrate the scalability, generalization, and zero-shot performance of FDA experimentally, as well as in-depth ablation studies and analysis. Code will be made publicly at https://github.com/michaeltian108/FDA.

</details>


### [195] [PINE: Pipeline for Important Node Exploration in Attributed Networks](https://arxiv.org/abs/2512.07244)
*Elizaveta Kovtun,Maksim Makarenko,Natalia Semenova,Alexey Zaytsev,Semen Budennyy*

Main category: cs.LG

TL;DR: PINE是一个用于无监督识别属性图中重要节点的管道框架，结合节点语义特征和网络结构，利用注意力机制计算节点重要性分数。


<details>
  <summary>Details</summary>
Motivation: 传统方法（如度中心性、PageRank）仅考虑网络结构而忽略节点属性，而现有神经网络方法需要监督学习。缺乏既无监督又能利用节点属性的方法。

Method: 提出PINE管道框架，核心是基于注意力的图模型，在学习图结构特性的过程中融入节点语义特征，通过注意力分布计算节点重要性分数。

Result: 在多种同质和异质属性网络上展示了优越性能，作为工业实现系统，成功应用于大规模企业图中关键实体的无监督识别。

Conclusion: PINE填补了无监督且属性感知的重要节点识别方法的空白，有效结合节点语义特征和网络结构，具有实际工业应用价值。

Abstract: A graph with semantically attributed nodes are a common data structure in a wide range of domains. It could be interlinked web data or citation networks of scientific publications. The essential problem for such a data type is to determine nodes that carry greater importance than all the others, a task that markedly enhances system monitoring and management. Traditional methods to identify important nodes in networks introduce centrality measures, such as node degree or more complex PageRank. However, they consider only the network structure, neglecting the rich node attributes. Recent methods adopt neural networks capable of handling node features, but they require supervision. This work addresses the identified gap--the absence of approaches that are both unsupervised and attribute-aware--by introducing a Pipeline for Important Node Exploration (PINE). At the core of the proposed framework is an attention-based graph model that incorporates node semantic features in the learning process of identifying the structural graph properties. The PINE's node importance scores leverage the obtained attention distribution. We demonstrate the superior performance of the proposed PINE method on various homogeneous and heterogeneous attributed networks. As an industry-implemented system, PINE tackles the real-world challenge of unsupervised identification of key entities within large-scale enterprise graphs.

</details>


### [196] [IFFair: Influence Function-driven Sample Reweighting for Fair Classification](https://arxiv.org/abs/2512.07249)
*Jingran Yang,Min Zhang,Lingfeng Zhang,Zhaohui Wang,Yonggang Zhang*

Main category: cs.LG

TL;DR: 提出基于影响函数的预处理方法IFFair，通过动态调整训练样本权重来减轻机器学习模型中的偏见，无需修改网络结构或数据特征。


<details>
  <summary>Details</summary>
Motivation: 机器学习在决策中广泛应用，但基于数据的模式会学习甚至加剧样本中的偏见，导致对弱势群体的歧视性决策，损害社会福祉并阻碍应用发展。

Method: 基于影响函数的预处理方法IFFair，利用不同群体训练样本的影响差异作为指导，在训练过程中动态调整样本权重，不修改网络结构、数据特征和决策边界。

Result: 在多个真实数据集和指标上的实验表明，IFFair能减轻分类任务中的多种偏见指标（人口统计均等、机会均等、错误率均等），且比现有预处理方法在效用与公平性之间取得更好的平衡。

Conclusion: IFFair是一种有效的公平性优化方法，通过动态调整样本权重来减轻机器学习模型中的偏见，在保持模型效用的同时提升公平性。

Abstract: Because machine learning has significantly improved efficiency and convenience in the society, it's increasingly used to assist or replace human decision-making. However, the data-based pattern makes related algorithms learn and even exacerbate potential bias in samples, resulting in discriminatory decisions against certain unprivileged groups, depriving them of the rights to equal treatment, thus damaging the social well-being and hindering the development of related applications. Therefore, we propose a pre-processing method IFFair based on the influence function. Compared with other fairness optimization approaches, IFFair only uses the influence disparity of training samples on different groups as a guidance to dynamically adjust the sample weights during training without modifying the network structure, data features and decision boundaries. To evaluate the validity of IFFair, we conduct experiments on multiple real-world datasets and metrics. The experimental results show that our approach mitigates bias of multiple accepted metrics in the classification setting, including demographic parity, equalized odds, equality of opportunity and error rate parity without conflicts. It also demonstrates that IFFair achieves better trade-off between multiple utility and fairness metrics compared with previous pre-processing methods.

</details>


### [197] [SIT-Graph: State Integrated Tool Graph for Multi-Turn Agents](https://arxiv.org/abs/2512.07287)
*Sijia Li,Yuchen Huang,Zifan Liu,Zijian Li,Jingjing fu,Lei Song,Jiang Bian,Jun Zhang,Rui Wang*

Main category: cs.LG

TL;DR: SIT-Graph：一种增强多轮工具使用的状态集成工具图方法，通过利用部分重叠经验，结合情景记忆和程序记忆，在需要时召回上下文，在常规步骤中遵循工具依赖关系。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代理在多轮工具使用场景中面临挑战，因为意图是逐步澄清的，环境随着每次工具调用而演变。现有方法要么将整个轨迹或预定义子任务视为不可分割单元，要么仅利用工具间依赖关系，难以适应状态和信息随轮次变化的情况。

Method: 提出状态集成工具图(SIT-Graph)，从历史轨迹中构建工具图，并在每条边上添加对话和工具历史的紧凑状态摘要。推理时，当需要回忆先前上下文时检索状态摘要指导行动，当步骤常规时则遵循高置信度的工具依赖关系。

Result: 在多个有状态多轮工具使用基准测试中，SIT-Graph始终优于基于记忆和图的基础方法，提供更稳健的工具选择和更有效的经验转移。

Conclusion: SIT-Graph通过结合情景记忆和程序记忆的类人决策机制，有效解决了多轮工具使用中的适应性问题，为LLM代理提供了更强大的经验复用能力。

Abstract: Despite impressive advances in agent systems, multi-turn tool-use scenarios remain challenging. It is mainly because intent is clarified progressively and the environment evolves with each tool call. While reusing past experience is natural, current LLM agents either treat entire trajectories or pre-defined subtasks as indivisible units, or solely exploit tool-to-tool dependencies, hindering adaptation as states and information evolve across turns. In this paper, we propose a State Integrated Tool Graph (SIT-Graph), which enhances multi-turn tool use by exploiting partially overlapping experience. Inspired by human decision-making that integrates episodic and procedural memory, SIT-Graph captures both compact state representations (episodic-like fragments) and tool-to-tool dependencies (procedural-like routines) from historical trajectories. Specifically, we first build a tool graph from accumulated tool-use sequences, and then augment each edge with a compact state summary of the dialog and tool history that may shape the next action. At inference time, SIT-Graph enables a human-like balance between episodic recall and procedural execution: when the next decision requires recalling prior context, the agent retrieves the state summaries stored on relevant edges and uses them to guide its next action; when the step is routine, it follows high-confidence tool dependencies without explicit recall. Experiments across multiple stateful multi-turn tool-use benchmarks show that SIT-Graph consistently outperforms strong memory- and graph-based baselines, delivering more robust tool selection and more effective experience transfer.

</details>


### [198] [Towards a Relationship-Aware Transformer for Tabular Data](https://arxiv.org/abs/2512.07310)
*Andrei V. Konstantinov,Valerii A. Zuev,Lev V. Utkin*

Main category: cs.LG

TL;DR: 提出基于改进注意力机制的模型，用于处理表格数据中的样本间依赖关系，在回归和因果效应估计任务中表现优于梯度提升决策树。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型无法处理表格数据中的样本间依赖关系图，而图神经网络只考虑相邻节点，难以应用于稀疏图。需要一种能有效利用外部依赖关系的方法，特别是在因果效应估计等任务中。

Method: 提出基于改进注意力机制的解决方案，通过在注意力矩阵中添加额外项来考虑数据点之间的可能关系。设计了多种模型变体，并在合成和真实数据集上进行回归任务评估，以及在IHDP数据集上进行因果效应估计任务评估。

Result: 提出的模型在回归任务中相互比较并与梯度提升决策树对比，在因果效应估计任务中在IHDP数据集上表现出色，证明了改进注意力机制在处理样本间依赖关系方面的有效性。

Conclusion: 基于改进注意力机制的模型能够有效处理表格数据中的样本间依赖关系，为需要考虑数据点相关性的任务（如因果效应估计）提供了有效的解决方案。

Abstract: Deep learning models for tabular data typically do not allow for imposing a graph of external dependencies between samples, which can be useful for accounting for relatedness in tasks such as treatment effect estimation. Graph neural networks only consider adjacent nodes, making them difficult to apply to sparse graphs. This paper proposes several solutions based on a modified attention mechanism, which accounts for possible relationships between data points by adding a term to the attention matrix. Our models are compared with each other and the gradient boosting decision trees in a regression task on synthetic and real-world datasets, as well as in a treatment effect estimation task on the IHDP dataset.

</details>


### [199] [Learning-Augmented Ski Rental with Discrete Distributions: A Bayesian Approach](https://arxiv.org/abs/2512.07313)
*Bosun Kang,Hyejun Park,Chenglin Fan*

Main category: cs.LG

TL;DR: 提出基于贝叶斯决策和机器学习的滑雪租赁问题新框架，通过维护精确后验分布实现不确定性量化，在准确先验下接近最优，同时保持鲁棒性保证


<details>
  <summary>Details</summary>
Motivation: 传统算法只考虑最坏情况成本，而近期学习增强方法利用噪声预测但缺乏不确定性量化。本文旨在统一这两种视角，为带有不完美预测的在线决策问题提供贝叶斯推理框架

Method: 提出离散贝叶斯框架，维护时间范围的精确后验分布，允许纳入专家先验知识。算法实现先验依赖的竞争性保证，平滑插值于最坏情况和完全知情设置之间

Result: 算法在不同场景下表现出优越的实证性能，在准确先验下达到接近最优结果，同时保持鲁棒的最坏情况保证。框架可扩展至多预测、非均匀先验和上下文信息

Conclusion: 贝叶斯推理为带有不完美预测的在线决策问题提供了实用优势，统一了传统最坏情况分析和学习增强方法，实现了性能与鲁棒性的平衡

Abstract: We revisit the classic ski rental problem through the lens of Bayesian decision-making and machine-learned predictions. While traditional algorithms minimize worst-case cost without assumptions, and recent learning-augmented approaches leverage noisy forecasts with robustness guarantees, our work unifies these perspectives. We propose a discrete Bayesian framework that maintains exact posterior distributions over the time horizon, enabling principled uncertainty quantification and seamless incorporation of expert priors. Our algorithm achieves prior-dependent competitive guarantees and gracefully interpolates between worst-case and fully-informed settings. Our extensive experimental evaluation demonstrates superior empirical performance across diverse scenarios, achieving near-optimal results under accurate priors while maintaining robust worst-case guarantees. This framework naturally extends to incorporate multiple predictions, non-uniform priors, and contextual information, highlighting the practical advantages of Bayesian reasoning in online decision problems with imperfect predictions.

</details>


### [200] [Local-Curvature-Aware Knowledge Graph Embedding: An Extended Ricci Flow Approach](https://arxiv.org/abs/2512.07332)
*Zhengquan Luo,Guy Tadmor,Or Amar,David Zeevi,Zhiqiang Xu*

Main category: cs.LG

TL;DR: RicciKGE提出了一种动态几何适应方法，通过将知识图谱嵌入损失梯度与局部曲率耦合在扩展的Ricci流中，使实体嵌入与底层流形几何共同演化，以解决预定义齐次流形无法适应真实图谱局部曲率变化的问题。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱嵌入方法将所有实体放置在一个齐次流形上（欧几里得、球面、双曲或其乘积/多曲率变体），但预定义的齐次流形无法适应真实世界图谱在不同局部区域表现出的急剧变化的曲率。这种几何不匹配会扭曲实体间的距离，损害嵌入的表达能力。

Method: 提出RicciKGE方法，将KGE损失梯度与局部曲率耦合在扩展的Ricci流中，使实体嵌入与底层流形几何动态共同演化，实现相互适应。理论上证明了当耦合系数有界且适当选择时，所有边曲率呈指数衰减（流形趋向欧几里得平坦），且KGE距离严格收敛到全局最优。

Result: 在链接预测和节点分类基准测试中取得了实验改进，证明了RicciKGE在适应异构知识图谱结构方面的有效性。

Conclusion: RicciKGE通过动态几何适应机制，解决了传统KGE方法中预定义齐次流形与真实图谱局部曲率不匹配的问题，实现了流形几何与嵌入优化的相互促进，提升了知识图谱嵌入的表达能力。

Abstract: Knowledge graph embedding (KGE) relies on the geometry of the embedding space to encode semantic and structural relations. Existing methods place all entities on one homogeneous manifold, Euclidean, spherical, hyperbolic, or their product/multi-curvature variants, to model linear, symmetric, or hierarchical patterns. Yet a predefined, homogeneous manifold cannot accommodate the sharply varying curvature that real-world graphs exhibit across local regions. Since this geometry is imposed a priori, any mismatch with the knowledge graph's local curvatures will distort distances between entities and hurt the expressiveness of the resulting KGE. To rectify this, we propose RicciKGE to have the KGE loss gradient coupled with local curvatures in an extended Ricci flow such that entity embeddings co-evolve dynamically with the underlying manifold geometry towards mutual adaptation. Theoretically, when the coupling coefficient is bounded and properly selected, we rigorously prove that i) all the edge-wise curvatures decay exponentially, meaning that the manifold is driven toward the Euclidean flatness; and ii) the KGE distances strictly converge to a global optimum, which indicates that geometric flattening and embedding optimization are promoting each other. Experimental improvements on link prediction and node classification benchmarks demonstrate RicciKGE's effectiveness in adapting to heterogeneous knowledge graph structures.

</details>


### [201] [Recover-to-Forget: Gradient Reconstruction from LoRA for Efficient LLM Unlearning](https://arxiv.org/abs/2512.07374)
*Yezi Liu,Hanning Chen,Wenjun Huang,Yang Ni,Mohsen Imani*

Main category: cs.LG

TL;DR: R2F提出了一种基于LoRA适配器重建完整模型梯度方向的高效大语言模型遗忘方法，无需完整模型微调或原始训练数据。


<details>
  <summary>Details</summary>
Motivation: 大型基础模型（如LLMs）的遗忘对于动态知识更新、数据删除权利执行和模型行为修正至关重要。现有遗忘方法通常需要完整模型微调或访问原始训练数据，限制了可扩展性和实用性。

Method: R2F框架通过从低秩LoRA适配器更新重建完整模型梯度方向。使用多个改写提示计算LoRA参数的梯度，训练梯度解码器来近似相应的完整模型梯度。解码器在代理模型上训练后迁移到目标模型。

Result: 方法实现了有效的遗忘同时保持模型的一般性能。实验结果表明R2F为预训练LLMs提供了可扩展且轻量级的遗忘替代方案，无需完整重新训练或访问内部参数。

Conclusion: R2F提供了一种高效、可扩展的大语言模型遗忘框架，通过梯度重建技术解决了现有方法在可扩展性和实用性方面的限制。

Abstract: Unlearning in large foundation models (e.g., LLMs) is essential for enabling dynamic knowledge updates, enforcing data deletion rights, and correcting model behavior. However, existing unlearning methods often require full-model fine-tuning or access to the original training data, which limits their scalability and practicality. In this work, we introduce Recover-to-Forget (R2F), a novel framework for efficient unlearning in LLMs based on reconstructing full-model gradient directions from low-rank LoRA adapter updates. Rather than performing backpropagation through the full model, we compute gradients with respect to LoRA parameters using multiple paraphrased prompts and train a gradient decoder to approximate the corresponding full-model gradients. To ensure applicability to larger or black-box models, the decoder is trained on a proxy model and transferred to target models. We provide a theoretical analysis of cross-model generalization and demonstrate that our method achieves effective unlearning while preserving general model performance. Experimental results demonstrate that R2F offers a scalable and lightweight alternative for unlearning in pretrained LLMs without requiring full retraining or access to internal parameters.

</details>


### [202] [LUNE: Efficient LLM Unlearning via LoRA Fine-Tuning with Negative Examples](https://arxiv.org/abs/2512.07375)
*Yezi Liu,Hanning Chen,Wenjun Huang,Yang Ni,Mohsen Imani*

Main category: cs.LG

TL;DR: LUNE：基于LoRA的轻量级大语言模型遗忘框架，通过仅更新低秩适配器实现高效知识遗忘，计算成本降低约一个数量级


<details>
  <summary>Details</summary>
Motivation: 大语言模型难以移除特定信息，在处理隐私、偏见缓解和知识修正时存在困难。传统遗忘方法需要昂贵的微调或权重编辑，不适用于实际部署

Method: 提出LoRA-based Unlearning with Negative Examples (LUNE)框架，仅更新低秩适配器并冻结主干网络，通过负例训练定位中间表示来抑制或替换目标知识

Result: 在多个事实遗忘任务上的实验表明：1）LUNE效果与全微调和内存编辑方法相当；2）计算成本降低约一个数量级

Conclusion: LUNE提供了一种轻量级、高效的模型遗忘解决方案，通过局部化编辑避免全局破坏性变化，为实际部署提供了可行方案

Abstract: Large language models (LLMs) possess vast knowledge acquired from extensive training corpora, but they often cannot remove specific pieces of information when needed, which makes it hard to handle privacy, bias mitigation, and knowledge correction. Traditional model unlearning approaches require computationally expensive fine-tuning or direct weight editing, making them impractical for real-world deployment. In this work, we introduce LoRA-based Unlearning with Negative Examples (LUNE), a lightweight framework that performs negative-only unlearning by updating only low-rank adapters while freezing the backbone, thereby localizing edits and avoiding disruptive global changes. Leveraging Low-Rank Adaptation (LoRA), LUNE targets intermediate representations to suppress (or replace) requested knowledge with an order-of-magnitude lower compute and memory than full fine-tuning or direct weight editing. Extensive experiments on multiple factual unlearning tasks show that LUNE: (I) achieves effectiveness comparable to full fine-tuning and memory-editing methods, and (II) reduces computational cost by about an order of magnitude.

</details>


### [203] [Towards Reliable Test-Time Adaptation: Style Invariance as a Correctness Likelihood](https://arxiv.org/abs/2512.07390)
*Gilhyun Nam,Taewon Kim,Joonhyun Jeong,Eunho Yang*

Main category: cs.LG

TL;DR: SICL框架利用风格不变性进行鲁棒的不确定性估计，通过测量风格变化变体间的预测一致性来估计实例级正确性概率，无需反向传播，可与任何TTA方法兼容。


<details>
  <summary>Details</summary>
Motivation: 测试时适应（TTA）方法虽然能高效适应部署模型，但往往导致预测不确定性校准不佳，这在自动驾驶、金融和医疗等高风险领域是严重问题。现有校准方法通常假设固定模型或静态分布，在现实动态测试条件下性能会下降。

Method: 提出SICL框架，利用风格不变性进行鲁棒的不确定性估计。通过测量预测在风格变化变体间的一致性来估计实例级正确性概率，仅需模型前向传播，无需反向传播，可作为即插即用的校准模块与任何TTA方法兼容。

Result: 在4个基线、5种TTA方法和2个现实场景、3种模型架构的综合评估中，SICL相比传统校准方法平均减少了13个百分点的校准误差。

Conclusion: SICL提供了一种简单有效的解决方案，通过风格不变性原理改善TTA方法中的不确定性校准问题，在高风险应用中具有重要价值。

Abstract: Test-time adaptation (TTA) enables efficient adaptation of deployed models, yet it often leads to poorly calibrated predictive uncertainty - a critical issue in high-stakes domains such as autonomous driving, finance, and healthcare. Existing calibration methods typically assume fixed models or static distributions, resulting in degraded performance under real-world, dynamic test conditions. To address these challenges, we introduce Style Invariance as a Correctness Likelihood (SICL), a framework that leverages style-invariance for robust uncertainty estimation. SICL estimates instance-wise correctness likelihood by measuring prediction consistency across style-altered variants, requiring only the model's forward pass. This makes it a plug-and-play, backpropagation-free calibration module compatible with any TTA method. Comprehensive evaluations across four baselines, five TTA methods, and two realistic scenarios with three model architecture demonstrate that SICL reduces calibration error by an average of 13 percentage points compared to conventional calibration approaches.

</details>


### [204] [Empirical Results for Adjusting Truncated Backpropagation Through Time while Training Neural Audio Effects](https://arxiv.org/abs/2512.07393)
*Yann Bourdin,Pierrick Legrand,Fanny Roche*

Main category: cs.LG

TL;DR: 该研究优化了TBPTT在音频效果建模中的训练参数，通过调整序列数、批次大小和序列长度，提升了动态范围压缩模型的性能和训练效率。


<details>
  <summary>Details</summary>
Motivation: 在数字音频效果建模中，特别是动态范围压缩方面，需要优化TBPTT训练方法以提高模型性能、训练稳定性并降低计算需求。

Method: 使用卷积-循环架构，通过大量实验评估TBPTT的关键超参数（序列数、批次大小、序列长度）对模型性能的影响，并在有无用户控制条件的数据集上进行测试。

Result: 精心调整TBPTT参数显著提高了模型精度和训练稳定性，同时减少了计算需求。客观评估显示性能改进，主观听力测试表明优化配置保持了高感知质量。

Conclusion: TBPTT超参数的优化对于数字音频效果建模至关重要，能够平衡性能、稳定性和计算效率，为音频处理任务提供了有效的训练策略。

Abstract: This paper investigates the optimization of Truncated Backpropagation Through Time (TBPTT) for training neural networks in digital audio effect modeling, with a focus on dynamic range compression. The study evaluates key TBPTT hyperparameters -- sequence number, batch size, and sequence length -- and their influence on model performance. Using a convolutional-recurrent architecture, we conduct extensive experiments across datasets with and without conditionning by user controls. Results demonstrate that carefully tuning these parameters enhances model accuracy and training stability, while also reducing computational demands. Objective evaluations confirm improved performance with optimized settings, while subjective listening tests indicate that the revised TBPTT configuration maintains high perceptual quality.

</details>


### [205] [Asymptotic analysis of shallow and deep forgetting in replay with Neural Collapse](https://arxiv.org/abs/2512.07400)
*Giulia Lanzillotta,Damiano Meier,Thomas Hofmann*

Main category: cs.LG

TL;DR: 论文揭示了持续学习中深度特征遗忘与浅层分类器遗忘的区别，发现小缓冲区能防止特征遗忘但需要大缓冲区缓解分类器遗忘，并提出通过修正统计伪影可在小缓冲区下获得鲁棒性能。


<details>
  <summary>Details</summary>
Motivation: 持续学习中的一个持久悖论是：神经网络即使在输出预测失败时，也经常保留过去任务的线性可分表示。本文旨在形式化这种深度特征空间与浅层分类器级别遗忘的区别，并解释为什么经验回放中需要不同大小的缓冲区来应对这两种遗忘。

Method: 将神经坍缩框架扩展到顺序设置，将深度遗忘形式化为向分布外子空间的几何漂移，证明任何非零回放分数都能保证线性可分性的保留。同时识别小缓冲区导致的"强坍缩"会产生秩不足协方差和膨胀的类均值，使分类器无法识别真实总体边界。

Result: 揭示了经验回放中的关键不对称性：最小缓冲区能成功锚定特征几何并防止深度遗忘，但缓解浅层遗忘通常需要更大的缓冲区容量。通过将持续学习与分布外检测统一，挑战了对大缓冲区的依赖。

Conclusion: 通过显式修正统计伪影（秩不足协方差和膨胀的类均值），可以在最小回放下实现鲁棒性能，这为持续学习提供了新的方向，减少了对大缓冲区的依赖。

Abstract: A persistent paradox in continual learning (CL) is that neural networks often retain linearly separable representations of past tasks even when their output predictions fail. We formalize this distinction as the gap between deep feature-space and shallow classifier-level forgetting. We reveal a critical asymmetry in Experience Replay: while minimal buffers successfully anchor feature geometry and prevent deep forgetting, mitigating shallow forgetting typically requires substantially larger buffer capacities. To explain this, we extend the Neural Collapse framework to the sequential setting. We characterize deep forgetting as a geometric drift toward out-of-distribution subspaces and prove that any non-zero replay fraction asymptotically guarantees the retention of linear separability. Conversely, we identify that the "strong collapse" induced by small buffers leads to rank-deficient covariances and inflated class means, effectively blinding the classifier to true population boundaries. By unifying CL with out-of-distribution detection, our work challenges the prevailing reliance on large buffers, suggesting that explicitly correcting these statistical artifacts could unlock robust performance with minimal replay.

</details>


### [206] [Adaptive Tuning of Parameterized Traffic Controllers via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2512.07417)
*Giray Önür,Azita Dabiri,Bart De Schutter*

Main category: cs.LG

TL;DR: 提出多智能体强化学习框架，通过自适应调整状态反馈交通控制器参数，结合状态反馈控制器的反应性和强化学习的适应性，提高训练效率和系统鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统交通管理策略（如路径引导、匝道控制和交通信号控制）通常依赖状态反馈控制器，虽然简单反应快，但缺乏应对复杂时变交通动态的适应性。需要结合状态反馈控制的反应性和强化学习的适应性。

Method: 提出多智能体强化学习框架，每个智能体自适应调整状态反馈交通控制器的参数（而非直接高频控制动作）。采用较低频率的参数调整，提高训练效率。多智能体结构增强系统鲁棒性，局部控制器在部分故障时可独立运行。

Result: 在模拟的多类别交通网络中进行评估，结果显示：提出的多智能体框架优于无控制和固定参数状态反馈控制，与单智能体RL自适应状态反馈控制性能相当，但对部分故障具有更好的恢复能力。

Conclusion: 多智能体强化学习框架成功结合了状态反馈控制的反应性和强化学习的适应性，通过参数调整而非直接动作控制提高训练效率，多智能体结构增强了系统鲁棒性和对部分故障的恢复能力。

Abstract: Effective traffic control is essential for mitigating congestion in transportation networks. Conventional traffic management strategies, including route guidance, ramp metering, and traffic signal control, often rely on state feedback controllers, used for their simplicity and reactivity; however, they lack the adaptability required to cope with complex and time-varying traffic dynamics. This paper proposes a multi-agent reinforcement learning framework in which each agent adaptively tunes the parameters of a state feedback traffic controller, combining the reactivity of state feedback controllers with the adaptability of reinforcement learning. By tuning parameters at a lower frequency rather than directly determining control actions at a high frequency, the reinforcement learning agents achieve improved training efficiency while maintaining adaptability to varying traffic conditions. The multi-agent structure further enhances system robustness, as local controllers can operate independently in the event of partial failures. The proposed framework is evaluated on a simulated multi-class transportation network under varying traffic conditions. Results show that the proposed multi-agent framework outperforms the no control and fixed-parameter state feedback control cases, while performing on par with the single-agent RL-based adaptive state feedback control, with a much better resilience to partial failures.

</details>


### [207] [Revolutionizing Mixed Precision Quantization: Towards Training-free Automatic Proxy Discovery via Large Language Models](https://arxiv.org/abs/2512.07419)
*Haidong Kang,Jun Du,Lihong Lin*

Main category: cs.LG

TL;DR: 提出TAP框架，利用大语言模型自动发现混合精度量化的训练免费代理，无需人工专家参与或训练过程。


<details>
  <summary>Details</summary>
Motivation: 传统混合精度量化方法要么依赖昂贵的可微分优化搜索（效率低且不灵活），要么需要人工专家设计代理（劳动密集且需要专业知识）。能否设计一个无需人工专家参与和训练的代理？

Method: 提出LLM驱动的训练免费自动代理发现框架TAP，利用大语言模型为MPQ寻找定制化代理。采用基于直接策略优化的强化学习来优化提示，在LLM和MPQ任务间建立正反馈循环。

Result: 在主流基准测试上的广泛实验表明，TAP实现了最先进的性能。

Conclusion: TAP为MPQ社区提供了LLM驱动设计算法的新视角，将显著推动该领域发展。

Abstract: Mixed-Precision Quantization (MPQ) liberates the Deep Neural Networks (DNNs) from the Out-Of-Memory (OOM) bottleneck, which garnered increasing research attention. However, conventional methods either searched from costly differentiable optimization, which is neither efficient nor flexible, or learned a quantized DNN from the proxy (i.e., HAWQ) manually designed by human experts, which is labor-intensive and requires huge expert knowledge. Can we design a proxy without involving any human experts and training? In this paper, we provide an affirmative answer by proposing a novel Large Language Models (LLMs)-driven Training-free Automatic Proxy (dubbed TAP) discovery framework, which reforms the design paradigm of MPQ by utilizing LLMs to find superior TAP tailored for MPQ, automatically. In addition, to bridge the gap between black-box LLMs and the tough MPQ task, we ingeniously propose simple Direct Policy Optimization (DPO) based reinforcement learning to enhance LLMs' reasoning by optimizing prompts, which can construct a positive feedback loop between the LLM and the MPQ task, enabling LLMs to generate better TAP in the next evolution. Extensive experiments on mainstream benchmarks demonstrate that TAP achieves state-of-the-art performance. Finally, we truly believe that our TAP will significantly contribute to the MPQ community by providing a new perspective on LLM-driven design algorithms.

</details>


### [208] [MIDG: Mixture of Invariant Experts with knowledge injection for Domain Generalization in Multimodal Sentiment Analysis](https://arxiv.org/abs/2512.07430)
*Yangle Li,Danli Luo,Haifeng Hu*

Main category: cs.LG

TL;DR: 提出MIDG框架，通过混合不变专家模型提取领域不变特征，结合跨模态适配器注入知识，提升多模态情感分析的领域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有多模态情感分析领域泛化方法在提取不变特征时忽略了模态间的协同作用，且知识注入技术存在跨模态知识碎片化问题，无法充分利用模态间的特定表示。

Method: 1. 混合不变专家模型提取领域不变特征，增强模态间协同关系学习；2. 跨模态适配器通过跨模态知识注入增强多模态表示的语义丰富性。

Result: 在三个数据集上的广泛领域实验表明，MIDG框架取得了优越的性能表现。

Conclusion: 提出的MIDG框架通过有效提取领域不变特征和跨模态知识注入，显著提升了多模态情感分析的领域泛化能力。

Abstract: Existing methods in domain generalization for Multimodal Sentiment Analysis (MSA) often overlook inter-modal synergies during invariant features extraction, which prevents the accurate capture of the rich semantic information within multimodal data. Additionally, while knowledge injection techniques have been explored in MSA, they often suffer from fragmented cross-modal knowledge, overlooking specific representations that exist beyond the confines of unimodal. To address these limitations, we propose a novel MSA framework designed for domain generalization. Firstly, the framework incorporates a Mixture of Invariant Experts model to extract domain-invariant features, thereby enhancing the model's capacity to learn synergistic relationships between modalities. Secondly, we design a Cross-Modal Adapter to augment the semantic richness of multimodal representations through cross-modal knowledge injection. Extensive domain experiments conducted on three datasets demonstrate that the proposed MIDG achieves superior performance.

</details>


### [209] [Mitigating Bias in Graph Hyperdimensional Computing](https://arxiv.org/abs/2512.07433)
*Yezi Liu,William Youngwoo Chung,Yang Ni,Hanning Chen,Mohsen Imani*

Main category: cs.LG

TL;DR: 本文提出FairGHDC框架，用于解决图超维计算中的公平性问题，通过引入偏差校正项来减少群体间的不公平，同时保持计算效率优势。


<details>
  <summary>Details</summary>
Motivation: 图超维计算（HDC）作为认知任务的脑启发计算范式，虽然具有鲁棒性和效率优势，但其公平性影响尚未被充分研究。现有方法在数据表示和决策规则中可能存在偏见，导致对不同群体的不平等对待。

Method: 提出FairGHDC框架，引入基于差距的人口统计奇偶正则化器的偏差校正项，将其转换为标量公平因子，用于缩放真实标签类超向量的更新。该方法直接在超向量空间中进行去偏，无需修改图编码器或反向传播。

Result: 在六个基准数据集上的实验表明，FairGHDC显著减少了人口统计奇偶和机会均等差距，同时保持了与标准GNN和公平感知GNN相当的准确性。在GPU训练时间上实现了约10倍的加速。

Conclusion: FairGHDC有效解决了图HDC中的公平性问题，在保持计算效率优势的同时实现了公平性改进，为脑启发计算的实际应用提供了公平性保障。

Abstract: Graph hyperdimensional computing (HDC) has emerged as a promising paradigm for cognitive tasks, emulating brain-like computation with high-dimensional vectors known as hypervectors. While HDC offers robustness and efficiency on graph-structured data, its fairness implications remain largely unexplored. In this paper, we study fairness in graph HDC, where biases in data representation and decision rules can lead to unequal treatment of different groups. We show how hypervector encoding and similarity-based classification can propagate or even amplify such biases, and we propose a fairness-aware training framework, FairGHDC, to mitigate them. FairGHDC introduces a bias correction term, derived from a gap-based demographic-parity regularizer, and converts it into a scalar fairness factor that scales the update of the class hypervector for the ground-truth label. This enables debiasing directly in the hypervector space without modifying the graph encoder or requiring backpropagation. Experimental results on six benchmark datasets demonstrate that FairGHDC substantially reduces demographic-parity and equal-opportunity gaps while maintaining accuracy comparable to standard GNNs and fairness-aware GNNs. At the same time, FairGHDC preserves the computational advantages of HDC, achieving up to about one order of magnitude ($\approx 10\times$) speedup in training time on GPU compared to GNN and fairness-aware GNN baselines.

</details>


### [210] [KAN-Dreamer: Benchmarking Kolmogorov-Arnold Networks as Function Approximators in World Models](https://arxiv.org/abs/2512.07437)
*Chenwei Shi,Xueyu Luan*

Main category: cs.LG

TL;DR: KAN-Dreamer：将KAN架构集成到DreamerV3中，用KAN/FastKAN替换部分MLP和卷积组件，在DeepMind Control Suite上实现与原始MLP相当的性能。


<details>
  <summary>Details</summary>
Motivation: KANs作为MLPs的替代方案，具有更好的参数效率和可解释性，但计算开销较大。本研究旨在探索将KAN架构集成到DreamerV3这一先进的MBRL算法中，以结合两者的优势。

Method: 开发KAN-Dreamer，将DreamerV3中的特定MLP和卷积组件替换为KAN和FastKAN层。在JAX-based World Model中实现完全向量化版本，简化网格管理。研究分为三个子系统：视觉感知、潜在预测和行为学习。

Result: 在DeepMind Control Suite (walker_walk)上的实验表明，使用适配的FastKAN作为奖励和继续预测器的替代方案，在样本效率、训练速度和渐进性能方面与原始MLP架构相当。

Conclusion: KAN架构可以作为DreamerV3中MLP组件的有效替代，保持性能的同时可能带来参数效率和可解释性的优势。本研究为未来基于KAN的世界模型开发提供了初步探索。

Abstract: DreamerV3 is a state-of-the-art online model-based reinforcement learning (MBRL) algorithm known for remarkable sample efficiency. Concurrently, Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to Multi-Layer Perceptrons (MLPs), offering superior parameter efficiency and interpretability. To mitigate KANs' computational overhead, variants like FastKAN leverage Radial Basis Functions (RBFs) to accelerate inference. In this work, we investigate integrating KAN architectures into the DreamerV3 framework. We introduce KAN-Dreamer, replacing specific MLP and convolutional components of DreamerV3 with KAN and FastKAN layers. To ensure efficiency within the JAX-based World Model, we implement a tailored, fully vectorized version with simplified grid management. We structure our investigation into three subsystems: Visual Perception, Latent Prediction, and Behavior Learning. Empirical evaluations on the DeepMind Control Suite (walker_walk) analyze sample efficiency, training time, and asymptotic performance. Experimental results demonstrate that utilizing our adapted FastKAN as a drop-in replacement for the Reward and Continue predictors yields performance on par with the original MLP-based architecture, maintaining parity in both sample efficiency and training speed. This report serves as a preliminary study for future developments in KAN-based world models.

</details>


### [211] [Forget and Explain: Transparent Verification of GNN Unlearning](https://arxiv.org/abs/2512.07450)
*Imran Ahsan,Hyunwook Yu,Jinsung Kim,Mucheol Kim*

Main category: cs.LG

TL;DR: 提出一个基于可解释性的GNN遗忘验证器，通过对比删除前后的模型快照，使用归因偏移和局部结构变化作为透明证据来验证遗忘是否真正发生。


<details>
  <summary>Details</summary>
Motivation: 现有GNN遗忘方法主要关注效率和可扩展性，但缺乏透明度，且GNN的黑盒特性使得难以验证遗忘是否真正发生，特别是在GDPR等隐私法规要求下。

Method: 提出可解释性驱动的验证器，在删除前后对模型进行快照，使用五种可解释性指标：残差归因、热图偏移、可解释性分数偏差、图编辑距离和诊断图规则偏移。

Result: 评估了两种骨干网络（GCN、GAT）和四种遗忘策略（Retrain、GraphEditor、GNNDelete、IDEA）在五个基准数据集上的表现。结果显示Retrain和GNNDelete实现近乎完全的遗忘，GraphEditor提供部分擦除，IDEA留下残差信号。

Conclusion: 解释性差异提供了主要的人类可读遗忘证据，同时成员推断ROC-AUC作为补充的图范围隐私信号，为GNN遗忘提供了透明验证方法。

Abstract: Graph neural networks (GNNs) are increasingly used to model complex patterns in graph-structured data. However, enabling them to "forget" designated information remains challenging, especially under privacy regulations such as the GDPR. Existing unlearning methods largely optimize for efficiency and scalability, yet they offer little transparency, and the black-box nature of GNNs makes it difficult to verify whether forgetting has truly occurred. We propose an explainability-driven verifier for GNN unlearning that snapshots the model before and after deletion, using attribution shifts and localized structural changes (for example, graph edit distance) as transparent evidence. The verifier uses five explainability metrics: residual attribution, heatmap shift, explainability score deviation, graph edit distance, and a diagnostic graph rule shift. We evaluate two backbones (GCN, GAT) and four unlearning strategies (Retrain, GraphEditor, GNNDelete, IDEA) across five benchmarks (Cora, Citeseer, Pubmed, Coauthor-CS, Coauthor-Physics). Results show that Retrain and GNNDelete achieve near-complete forgetting, GraphEditor provides partial erasure, and IDEA leaves residual signals. These explanation deltas provide the primary, human-readable evidence of forgetting; we also report membership-inference ROC-AUC as a complementary, graph-wide privacy signal.

</details>


### [212] [Parallel Algorithms for Combined Regularized Support Vector Machines: Application in Music Genre Classification](https://arxiv.org/abs/2512.07463)
*Rongmei Liang,Zizheng Liu,Xiaofei Wu,Jingwen Tu*

Main category: cs.LG

TL;DR: 提出基于共识结构的统一优化框架，开发分布式并行ADMM算法处理分布式存储大数据中的组合正则化支持向量机，引入高斯回代法确保收敛，并在音乐信息检索中应用稀疏组套索SVM。


<details>
  <summary>Details</summary>
Motivation: 在人工智能快速发展的时代，组合正则化支持向量机（CR-SVMs）能有效处理数据特征间的结构信息，但在分布式存储的大数据场景中缺乏高效算法。

Method: 提出基于共识结构的统一优化框架，适用于多种损失函数和组合正则化项，可扩展到非凸正则化。基于该框架开发分布式并行ADMM算法，引入高斯回代法确保收敛，并提出稀疏组套索支持向量机（SGL-SVM）模型。

Result: 理论分析表明算法计算复杂度不受不同正则化项和损失函数影响，具有普适性。在合成和免费音乐档案数据集上的实验验证了算法的可靠性、稳定性和效率。

Conclusion: 提出的统一优化框架和分布式并行ADMM算法有效解决了分布式存储大数据中CR-SVMs的计算问题，在音乐信息检索等应用中表现出良好性能，具有强可扩展性。

Abstract: In the era of rapid development of artificial intelligence, its applications span across diverse fields, relying heavily on effective data processing and model optimization. Combined Regularized Support Vector Machines (CR-SVMs) can effectively handle the structural information among data features, but there is a lack of efficient algorithms in distributed-stored big data. To address this issue, we propose a unified optimization framework based on consensus structure. This framework is not only applicable to various loss functions and combined regularization terms but can also be effectively extended to non-convex regularization terms, showing strong scalability. Based on this framework, we develop a distributed parallel alternating direction method of multipliers (ADMM) algorithm to efficiently compute CR-SVMs when data is stored in a distributed manner. To ensure the convergence of the algorithm, we also introduce the Gaussian back-substitution method. Meanwhile, for the integrity of the paper, we introduce a new model, the sparse group lasso support vector machine (SGL-SVM), and apply it to music information retrieval. Theoretical analysis confirms that the computational complexity of the proposed algorithm is not affected by different regularization terms and loss functions, highlighting the universality of the parallel algorithm. Experiments on synthetic and free music archiv datasets demonstrate the reliability, stability, and efficiency of the algorithm.

</details>


### [213] [Materium: An Autoregressive Approach for Material Generation](https://arxiv.org/abs/2512.07486)
*Niklas Dobberstein,Jan Hamaekers*

Main category: cs.LG

TL;DR: Materium是一个用于生成晶体结构的自回归Transformer模型，通过将3D材料表示转换为包含元素、氧化态、分数坐标和晶格参数的token序列，实现快速、可扩展的晶体结构生成。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散方法需要多次去噪步骤迭代细化原子位置，生成速度慢。需要开发一种能够快速生成精确晶体结构的方法，同时能够基于多种材料属性进行条件生成。

Method: 采用自回归Transformer架构，将3D晶体结构转换为包含元素（带氧化态）、分数坐标和晶格参数的token序列。模型通过条件生成支持多种材料属性作为输入条件，包括基本属性（密度、空间群）和实用目标（带隙、磁密度）。

Result: 模型在单个GPU上仅需几小时即可完成训练，在GPU和CPU上生成速度远超扩散方法。在单一条件和组合条件下均表现一致良好，生成的候选结构能够准确匹配请求的输入条件。

Conclusion: Materium提供了一种高效、快速的晶体结构生成方法，克服了扩散方法的计算瓶颈，同时支持多种材料属性的条件生成，为材料发现和设计提供了实用的工具。

Abstract: We present Materium: an autoregressive transformer for generating crystal structures that converts 3D material representations into token sequences. These sequences include elements with oxidation states, fractional coordinates and lattice parameters. Unlike diffusion approaches, which refine atomic positions iteratively through many denoising steps, Materium places atoms at precise fractional coordinates, enabling fast, scalable generation. With this design, the model can be trained in a few hours on a single GPU and generate samples much faster on GPUs and CPUs than diffusion-based approaches. The model was trained and evaluated using multiple properties as conditions, including fundamental properties, such as density and space group, as well as more practical targets, such as band gap and magnetic density. In both single and combined conditions, the model performs consistently well, producing candidates that align with the requested inputs.

</details>


### [214] [Efficient Low-Tubal-Rank Tensor Estimation via Alternating Preconditioned Gradient Descent](https://arxiv.org/abs/2512.07490)
*Zhiyu Liu,Zhi Han,Yandong Tang,Jun Fan,Yao Wang*

Main category: cs.LG

TL;DR: 提出交替预条件梯度下降（APGD）算法，解决低管秩张量估计中过参数化导致的收敛缓慢问题，即使在高估秩的情况下也能实现线性收敛。


<details>
  <summary>Details</summary>
Motivation: 低管秩张量估计是信号处理、机器学习和图像科学中的基础问题。传统方法使用张量奇异值分解计算量大，不适用于大规模张量。现有基于梯度下降的因子分解方法需要准确估计张量秩，当秩被高估时收敛显著变慢甚至发散。

Method: 提出交替预条件梯度下降（APGD）算法：1）在原始梯度上添加预条件项；2）交替更新两个因子张量；3）基于目标函数的几何假设建立线性收敛保证；4）分析低管秩张量分解和恢复的具体情况。

Result: 理论分析表明APGD即使在过参数化情况下也能实现线性收敛，且收敛率与张量条件数无关。在合成数据上的大量仿真验证了理论断言。

Conclusion: APGD算法有效解决了低管秩张量估计中过参数化导致的收敛问题，为大规模张量处理提供了高效解决方案，具有理论保证和实际验证。

Abstract: The problem of low-tubal-rank tensor estimation is a fundamental task with wide applications across high-dimensional signal processing, machine learning, and image science. Traditional approaches tackle such a problem by performing tensor singular value decomposition, which is computationally expensive and becomes infeasible for large-scale tensors. Recent approaches address this issue by factorizing the tensor into two smaller factor tensors and solving the resulting problem using gradient descent. However, this kind of approach requires an accurate estimate of the tensor rank, and when the rank is overestimated, the convergence of gradient descent and its variants slows down significantly or even diverges. To address this problem, we propose an Alternating Preconditioned Gradient Descent (APGD) algorithm, which accelerates convergence in the over-parameterized setting by adding a preconditioning term to the original gradient and updating these two factors alternately. Based on certain geometric assumptions on the objective function, we establish linear convergence guarantees for more general low-tubal-rank tensor estimation problems. Then we further analyze the specific cases of low-tubal-rank tensor factorization and low-tubal-rank tensor recovery. Our theoretical results show that APGD achieves linear convergence even under over-parameterization, and the convergence rate is independent of the tensor condition number. Extensive simulations on synthetic data are carried out to validate our theoretical assertions.

</details>


### [215] [Exploring possible vector systems for faster training of neural networks with preconfigured latent spaces](https://arxiv.org/abs/2512.07509)
*Nikita Gabdullin*

Main category: cs.LG

TL;DR: 该论文提出使用预定义向量系统（如An根系统）作为潜在空间配置目标，以优化神经网络嵌入分布，从而加速大规模分类任务的训练，并减少向量数据库的存储需求。


<details>
  <summary>Details</summary>
Motivation: 神经网络性能与其潜在空间中的嵌入分布特性密切相关。传统方法在处理极多类别数据集时面临分类层训练困难，需要更高效的潜在空间配置方法来加速训练并优化存储。

Method: 提出使用预定义向量系统（特别是An根系统）作为潜在空间配置目标，构建系统化的向量系统用于编码器和视觉变换器的训练，探索最小潜在空间维度配置以加速收敛。

Result: 该方法显著加速了ImageNet-1K和50k-600k类别数据集的训练，使用最小潜在空间维度能实现更快收敛，并有望减少存储神经网络嵌入的向量数据库大小。

Conclusion: 预定义向量系统为神经网络潜在空间配置提供了有效框架，特别适用于大规模分类任务，既能加速训练又能优化存储效率，具有重要的实际应用价值。

Abstract: The overall neural network (NN) performance is closely related to the properties of its embedding distribution in latent space (LS). It has recently been shown that predefined vector systems, specifically An root system vectors, can be used as targets for latent space configurations (LSC) to ensure the desired LS structure. One of the main LSC advantage is the possibility of training classifier NNs without classification layers, which facilitates training NNs on datasets with extremely large numbers of classes. This paper provides a more general overview of possible vector systems for NN training along with their properties and methods for vector system construction. These systems are used to configure LS of encoders and visual transformers to significantly speed up ImageNet-1K and 50k-600k classes LSC training. It is also shown that using the minimum number of LS dimensions for a specific number of classes results in faster convergence. The latter has potential advantages for reducing the size of vector databases used to store NN embeddings.

</details>


### [216] [Machine Learning: Progress and Prospects](https://arxiv.org/abs/2512.07519)
*Alexander Gammerman*

Main category: cs.LG

TL;DR: 这篇1996年的就职讲座回顾了机器学习的历史起源，从14世纪的奥卡姆剃刀到20世纪中叶的算法发展，并讨论了机器学习作为多学科交叉领域的现状。


<details>
  <summary>Details</summary>
Motivation: 讲座旨在探讨机器学习的起源和发展历程，展示这一领域深厚的历史根基和多元的学科背景，帮助听众理解机器学习并非新兴技术，而是有着悠久的思想渊源。

Method: 采用历史回顾和思想溯源的方法，从哲学、统计学、计算机科学等多个角度追溯机器学习思想的起源，包括奥卡姆剃刀、归纳法、判别分析等核心概念的发展脉络。

Result: 明确了机器学习的思想根源可以追溯到古代哲学（亚里士多德）、中世纪逻辑（奥卡姆）、近代统计学（费舍尔）和现代计算机科学（香农），展示了该领域作为多学科融合的特点。

Conclusion: 机器学习是一个历史悠久、思想渊源深厚的领域，它融合了哲学、统计学、计算机科学等多个学科，包含归纳学习、神经网络、聚类等多个研究方向，构成了一个丰富而多元的学术领域。

Abstract: This Inaugural Lecture was given at Royal Holloway University of London in 1996. It covers an introduction to machine learning and describes various theoretical advances and practical projects in the field. The Lecture here is presented in its original format, but a few remarks have been added in 2025 to reflect recent developments, and the list of references has been updated to enhance the convenience and accuracy for readers.
  When did machine learning start? Maybe a good starting point is 1949, when Claude Shannon proposed a learning algorithm for chess-playing programs. Or maybe we should go back to the 1930s when Ronald Fisher developed discriminant analysis - a type of learning where the problem is to construct a decision rule that separates two types of vectors. Or could it be the 18th century when David Hume discussed the idea of induction? Or the 14th century, when William of Ockham formulated the principle of "simplicity" known as "Ockham's razor" (Ockham, by the way, is a small village not far from Royal Holloway). Or it may be that, like almost everything else in Western civilisation and culture, the origin of these ideas lies in the Mediterranean. After all, it was Aristotle who said that "we learn some things only by doing things".
  The field of machine learning has been greatly influenced by other disciplines and the subject is in itself not a very homogeneous discipline, but includes separate, overlapping subfields. There are many parallel lines of research in ML: inductive learning, neural networks, clustering, and theories of learning. They are all part of the more general field of machine learning.

</details>


### [217] [Model-Based Reinforcement Learning Under Confounding](https://arxiv.org/abs/2512.07528)
*Nishanth Venkatesh,Andreas A. Malikopoulos*

Main category: cs.LG

TL;DR: 提出一种在上下文未观测的混淆环境中进行模型强化学习的方法，通过代理变量识别奖励期望，结合行为平均转移模型构建替代MDP，实现一致的政策评估


<details>
  <summary>Details</summary>
Motivation: 在上下文未观测的C-MDPs中，传统模型学习方法存在根本不一致性，因为行为政策下的转移和奖励机制与评估状态政策所需的干预量不对应，需要解决混淆环境下的模型学习和规划问题

Method: 采用近端离政策评估方法，利用代理变量的温和可逆性条件识别混淆奖励期望；结合行为平均转移模型构建替代MDP，其贝尔曼算子对状态政策定义良好且一致；与最大因果熵模型学习框架无缝集成

Result: 提出的公式能够在上下文信息未观测、不可用或收集不切实际的混淆环境中实现原则性模型学习和规划，解决了传统方法的不一致性问题

Conclusion: 该方法为混淆环境中的强化学习提供了理论基础和实践框架，通过代理变量识别和替代MDP构建，实现了在上下文信息缺失情况下的有效模型学习和政策评估

Abstract: We investigate model-based reinforcement learning in contextual Markov decision processes (C-MDPs) in which the context is unobserved and induces confounding in the offline dataset. In such settings, conventional model-learning methods are fundamentally inconsistent, as the transition and reward mechanisms generated under a behavioral policy do not correspond to the interventional quantities required for evaluating a state-based policy. To address this issue, we adapt a proximal off-policy evaluation approach that identifies the confounded reward expectation using only observable state-action-reward trajectories under mild invertibility conditions on proxy variables. When combined with a behavior-averaged transition model, this construction yields a surrogate MDP whose Bellman operator is well defined and consistent for state-based policies, and which integrates seamlessly with the maximum causal entropy (MaxCausalEnt) model-learning framework. The proposed formulation enables principled model learning and planning in confounded environments where contextual information is unobserved, unavailable, or impractical to collect.

</details>


### [218] [FRWKV:Frequency-Domain Linear Attention for Long-Term Time Series Forecasting](https://arxiv.org/abs/2512.07539)
*Qingyuan Yang,Shizhuo,Dongyue Chen,Da Teng,Zehua Gan*

Main category: cs.LG

TL;DR: FRWKV：结合线性注意力与频域分析的时序预测框架，实现O(T)复杂度并在8个真实数据集上取得最佳平均排名


<details>
  <summary>Details</summary>
Motivation: 传统Transformer在长序列时序预测中存在两大瓶颈：1）二次复杂度O(T²)导致计算效率低；2）对频域信息利用不足。需要开发既能降低计算复杂度又能有效利用频域信息的新方法。

Method: 提出FRWKV框架，结合RWKV的线性注意力机制（O(T)复杂度）与频域分析，通过频域编码器增强时序特征表示，实现可扩展的长序列建模。

Result: 在8个真实世界数据集上，FRWKV取得了第一的平均排名。消融研究证实了线性注意力和频域编码器两个组件的关键作用。

Conclusion: 线性注意力与频域分析的结合为可扩展时序建模建立了新范式，展示了这两种技术的强大协同效应。代码已开源。

Abstract: Traditional Transformers face a major bottleneck in long-sequence time series forecasting due to their quadratic complexity $(\mathcal{O}(T^2))$ and their limited ability to effectively exploit frequency-domain information. Inspired by RWKV's $\mathcal{O}(T)$ linear attention and frequency-domain modeling, we propose FRWKV, a frequency-domain linear-attention framework that overcomes these limitations. Our model integrates linear attention mechanisms with frequency-domain analysis, achieving $\mathcal{O}(T)$ computational complexity in the attention path while exploiting spectral information to enhance temporal feature representations for scalable long-sequence modeling. Across eight real-world datasets, FRWKV achieves a first-place average rank. Our ablation studies confirm the critical roles of both the linear attention and frequency-encoder components. This work demonstrates the powerful synergy between linear attention and frequency analysis, establishing a new paradigm for scalable time series modeling. Code is available at this repository: https://github.com/yangqingyuan-byte/FRWKV.

</details>


### [219] [RRAEDy: Adaptive Latent Linearization of Nonlinear Dynamical Systems](https://arxiv.org/abs/2512.07542)
*Jad Mounayer,Sebastian Rodriguez,Jerome Tomezyk,Chady Ghnatios,Francisco Chinesta*

Main category: cs.LG

TL;DR: RRAEDy是一种自动发现合适潜在维度、同时强制潜在空间正则化和线性化的动力学模型，无需手动调整或辅助损失函数


<details>
  <summary>Details</summary>
Motivation: 现有潜在空间模型需要预先固定潜在维度，依赖复杂的损失平衡来近似线性动力学，且不对潜在变量进行正则化

Method: 基于秩约减自编码器(RRAE)，通过奇异值自动排序和剪枝潜在变量，同时学习控制时间演化的潜在动态模态分解(DMD)算子

Result: 在Van der Pol振荡器、Burgers方程、2D Navier-Stokes和旋转高斯等基准测试中实现了准确和鲁棒的预测

Conclusion: RRAEDy通过无结构但线性约束的公式，能够学习稳定且低维的动力学，无需辅助损失或手动调参

Abstract: Most existing latent-space models for dynamical systems require fixing the latent dimension in advance, they rely on complex loss balancing to approximate linear dynamics, and they don't regularize the latent variables. We introduce RRAEDy, a model that removes these limitations by discovering the appropriate latent dimension, while enforcing both regularized and linearized dynamics in the latent space. Built upon Rank-Reduction Autoencoders (RRAEs), RRAEDy automatically rank and prune latent variables through their singular values while learning a latent Dynamic Mode Decomposition (DMD) operator that governs their temporal progression. This structure-free yet linearly constrained formulation enables the model to learn stable and low-dimensional dynamics without auxiliary losses or manual tuning. We provide theoretical analysis demonstrating the stability of the learned operator and showcase the generality of our model by proposing an extension that handles parametric ODEs. Experiments on canonical benchmarks, including the Van der Pol oscillator, Burgers' equation, 2D Navier-Stokes, and Rotating Gaussians, show that RRAEDy achieves accurate and robust predictions. Our code is open-source and available at https://github.com/JadM133/RRAEDy. We also provide a video summarizing the main results at https://youtu.be/ox70mSSMGrM.

</details>


### [220] [ReLaX: Reasoning with Latent Exploration for Large Reasoning Models](https://arxiv.org/abs/2512.07558)
*Shimin Zhang,Xianwei Chen,Yufan Shen,Ziyuan Ye,Jibin Wu*

Main category: cs.LG

TL;DR: 本文提出ReLaX方法，通过分析大语言模型的潜在动态来调控探索与利用平衡，解决强化学习验证奖励中的熵崩溃问题，显著提升推理性能。


<details>
  <summary>Details</summary>
Motivation: 强化学习验证奖励（RLVR）虽然能提升大推理模型的推理能力，但常导致熵崩溃，造成策略过早收敛和性能饱和。现有方法主要操纵token级熵来促进探索，但作者认为潜在动态编码了更丰富的计算结构，能更好地指导探索-利用权衡。

Method: 提出ReLaX（Reasoning with Latent eXploration）范式：1）利用Koopman算子理论获得隐藏状态动态的线性化表示；2）引入动态谱分散（DSD）指标量化潜在动态的异质性，作为策略探索的直接指标；3）在策略优化中显式纳入潜在动态来调控探索与利用。

Result: 在广泛的多模态和纯文本推理基准测试中，ReLaX显著缓解了过早收敛问题，并持续实现了最先进的性能。

Conclusion: 通过分析大语言模型的潜在动态来调控探索-利用平衡是有效的，ReLaX方法为解决RLVR中的熵崩溃问题提供了新思路，在多个推理任务上取得了优异表现。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has recently demonstrated remarkable potential in enhancing the reasoning capability of Large Reasoning Models (LRMs). However, RLVR often leads to entropy collapse, resulting in premature policy convergence and performance saturation. While manipulating token-level entropy has proven effective for promoting policy exploration, we argue that the latent dynamics underlying token generation encode a far richer computational structure for steering policy optimization toward a more effective exploration-exploitation tradeoff. To enable tractable analysis and intervention of the latent dynamics of LRMs, we leverage Koopman operator theory to obtain a linearized representation of their hidden-state dynamics. This enables us to introduce Dynamic Spectral Dispersion (DSD), a new metric to quantify the heterogeneity of the model's latent dynamics, serving as a direct indicator of policy exploration. Building upon these foundations, we propose Reasoning with Latent eXploration (ReLaX), a paradigm that explicitly incorporates latent dynamics to regulate exploration and exploitation during policy optimization. Comprehensive experiments across a wide range of multimodal and text-only reasoning benchmarks show that ReLaX significantly mitigates premature convergence and consistently achieves state-of-the-art performance.

</details>


### [221] [Weighted Contrastive Learning for Anomaly-Aware Time-Series Forecasting](https://arxiv.org/abs/2512.07569)
*Joel Ekstrand,Tor Mattsson,Zahra Taghiyarrenani,Slawomir Nowaczyk,Jens Lundström,Mikael Lindén*

Main category: cs.LG

TL;DR: WECA方法通过加权对比适应提升多元时间序列在异常条件下的预测可靠性，在ATM现金物流等应用中显著改善异常数据预测性能


<details>
  <summary>Details</summary>
Motivation: 现代深度预测模型在正常数据上表现良好，但在分布偏移（如异常条件）下往往失效。在ATM现金物流等应用中，突发需求变化会严重干扰运营，因此需要可靠的异常条件下预测方法。

Method: 提出加权对比适应（WECA），使用加权对比目标对齐正常和异常增强的表示，在保持异常相关信息的同时，确保在良性变化下的一致性。

Result: 在全国ATM交易数据集上评估，使用领域知识注入异常，WECA将异常影响数据的SMAPE提高了6.1个百分点，而对正常数据的性能下降可忽略不计。

Conclusion: WECA能够在保持正常操作性能的同时，显著增强异常条件下的预测可靠性，为实际应用中的分布偏移问题提供了有效解决方案。

Abstract: Reliable forecasting of multivariate time series under anomalous conditions is crucial in applications such as ATM cash logistics, where sudden demand shifts can disrupt operations. Modern deep forecasters achieve high accuracy on normal data but often fail when distribution shifts occur. We propose Weighted Contrastive Adaptation (WECA), a Weighted contrastive objective that aligns normal and anomaly-augmented representations, preserving anomaly-relevant information while maintaining consistency under benign variations. Evaluations on a nationwide ATM transaction dataset with domain-informed anomaly injection show that WECA improves SMAPE on anomaly-affected data by 6.1 percentage points compared to a normally trained baseline, with negligible degradation on normal data. These results demonstrate that WECA enhances forecasting reliability under anomalies without sacrificing performance during regular operations.

</details>


### [222] [Time Series Foundation Models for Process Model Forecasting](https://arxiv.org/abs/2512.07624)
*Yongbo Yu,Jari Peeperkorn,Johannes De Smedt,Jochen De Weerdt*

Main category: cs.LG

TL;DR: 本文研究了时间序列基础模型在过程模型预测中的应用，发现预训练的时间序列基础模型在零样本和微调设置下均优于传统方法，展示了跨领域时间结构迁移的有效性。


<details>
  <summary>Details</summary>
Motivation: 过程模型预测旨在预测过程控制流结构随时间的变化，但现有机器学习方法由于直接跟随关系时间序列的稀疏性和异质性，性能提升有限。本文探索时间序列基础模型作为替代方案，利用其预训练知识来改进预测性能。

Method: 使用真实事件日志生成的直接跟随关系时间序列，比较时间序列基础模型的零样本使用（无额外训练）与在PMF特定数据上微调的变体。与传统和专门模型进行对比，评估MAE和RMSE等预测误差指标。

Result: 时间序列基础模型通常比传统方法和专门模型获得更低的预测误差，表明从非过程领域有效迁移了时间结构知识。微调虽然能进一步提高准确性，但增益通常较小，在较小或更复杂的数据集上可能消失，因此零样本使用仍是强大的默认选择。

Conclusion: 时间序列基础模型在过程相关时间序列预测中展现出良好的泛化能力和数据效率，为过程模型预测提供了有效的解决方案。这是首次系统评估时间基础模型在PMF中的应用。

Abstract: Process Model Forecasting (PMF) aims to predict how the control-flow structure of a process evolves over time by modeling the temporal dynamics of directly-follows (DF) relations, complementing predictive process monitoring that focuses on single-case prefixes. Prior benchmarks show that machine learning and deep learning models provide only modest gains over statistical baselines, mainly due to the sparsity and heterogeneity of the DF time series. We investigate Time Series Foundation Models (TSFMs), large pre-trained models for generic time series, as an alternative for PMF. Using DF time series derived from real-life event logs, we compare zero-shot use of TSFMs, without additional training, with fine-tuned variants adapted on PMF-specific data. TSFMs generally achieve lower forecasting errors (MAE and RMSE) than traditional and specialized models trained from scratch on the same logs, indicating effective transfer of temporal structure from non-process domains. While fine-tuning can further improve accuracy, the gains are often small and may disappear on smaller or more complex datasets, so zero-shot use remains a strong default. Our study highlights the generalization capability and data efficiency of TSFMs for process-related time series and, to the best of our knowledge, provides the first systematic evaluation of temporal foundation models for PMF.

</details>


### [223] [A Mathematical Theory of Top-$k$ Sparse Attention via Total Variation Distance](https://arxiv.org/abs/2512.07647)
*Georgios Tzachristas,Lei Deng,Ioannis Tzachristas,Gong Zhang,Renhai Chen*

Main category: cs.LG

TL;DR: 提出了一种用于认证Top-k注意力截断的统一数学框架，量化了分布和输出层面的近似误差，推导出非渐近确定性边界，并在高斯评分模型下得到闭式解。


<details>
  <summary>Details</summary>
Motivation: 注意力机制中的Top-k截断虽然广泛使用，但缺乏严格的误差量化理论框架。现有方法通常依赖启发式或经验规则，无法提供可证明的误差保证。

Method: 建立统一的数学框架，分析注意力分布P与其Top-k截断P̂之间的总变差距离，推导出与KL散度的精确关系。提出边界间隙、多间隙和分块变体等非渐近确定性边界，并通过头尾分解分析输出误差。

Result: 证明了总变差距离等于丢弃的softmax尾部质量，输出误差可分解为τ∥μ_tail-μ_head∥₂。在高斯评分模型下得到闭式尾部质量和最小k_ε的渐近规则，实验验证了理论预测。

Conclusion: 该框架为Top-k注意力截断提供了严格的误差认证，能够在满足总变差预算的同时平均减少2-4倍的评分键数量，为高效注意力计算提供了理论保证。

Abstract: We develop a unified mathematical framework for certified Top-$k$ attention truncation that quantifies approximation error at both the distribution and output levels. For a single attention distribution $P$ and its Top-$k$ truncation $\hat P$, we show that the total-variation distance coincides with the discarded softmax tail mass and satisfies $\mathrm{TV}(P,\hat P)=1-e^{-\mathrm{KL}(\hat P\Vert P)}$, yielding sharp Top-$k$-specific bounds in place of generic inequalities. From this we derive non-asymptotic deterministic bounds -- from a single boundary gap through multi-gap and blockwise variants -- that control $\mathrm{TV}(P,\hat P)$ using only the ordered logits. Using an exact head-tail decomposition, we prove that the output error factorizes as $\|\mathrm{Attn}(q,K,V)-\mathrm{Attn}_k(q,K,V)\|_2=τ\|μ_{\mathrm{tail}}-μ_{\mathrm{head}}\|_2$ with $τ=\mathrm{TV}(P,\hat P)$, yielding a new head-tail diameter bound $\|\mathrm{Attn}(q,K,V)-\mathrm{Attn}_k(q,K,V)\|_2\leτ\,\mathrm{diam}_{H,T}$ and refinements linking the error to $\mathrm{Var}_P(V)$. Under an i.i.d. Gaussian score model $s_i\sim\mathcal N(μ,σ^2)$ we derive closed-form tail masses and an asymptotic rule for the minimal $k_\varepsilon$ ensuring $\mathrm{TV}(P,\hat P)\le\varepsilon$, namely $k_\varepsilon/n\approxΦ_c(σ+Φ^{-1}(\varepsilon))$. Experiments on bert-base-uncased and synthetic logits confirm the predicted scaling of $k_\varepsilon/n$ and show that certified Top-$k$ can reduce scored keys by 2-4$\times$ on average while meeting the prescribed total-variation budget.

</details>


### [224] [Depth-Wise Activation Steering for Honest Language Models](https://arxiv.org/abs/2512.07667)
*Gracjan Góral,Marysia Winkels,Steven Basart*

Main category: cs.LG

TL;DR: 提出一种无需训练的高斯调度激活引导方法，通过在不同网络深度分配引导强度来提高语言模型的诚实性，而非准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型有时会陈述错误信息，尽管内部知道正确答案，这是诚实性而非准确性的失败，会削弱可审计性和安全性。现有方法主要优化事实正确性或依赖重新训练和脆弱的单层编辑，对真实报告的控制有限。

Method: 提出一种无需训练的激活引导方法，使用高斯调度在多个网络深度上加权引导强度。该方法简单、模型无关、无需微调，为从模型现有能力中引出真实报告提供了低成本控制手段。

Result: 在MASK基准测试中（分离诚实性与知识），评估了LLaMA、Qwen和Mistral家族的七个模型，发现高斯调度在六个模型中比无引导和单层基线提高了诚实性。在LLaMA-3.1-8B-Instruct和Qwen-2.5-7B-Instruct上的等预算消融实验显示，高斯调度优于随机、均匀和盒滤波器深度分配。

Conclusion: 高斯调度激活引导方法表明，如何在深度上分配干预对结果有实质性影响，超越了总强度的影响。该方法为从语言模型中引出真实报告提供了一种简单有效的控制手段。

Abstract: Large language models sometimes assert falsehoods despite internally representing the correct answer, failures of honesty rather than accuracy, which undermines auditability and safety. Existing approaches largely optimize factual correctness or depend on retraining and brittle single-layer edits, offering limited leverage over truthful reporting. We present a training-free activation steering method that weights steering strength across network depth using a Gaussian schedule. On the MASK benchmark, which separates honesty from knowledge, we evaluate seven models spanning the LLaMA, Qwen, and Mistral families and find that Gaussian scheduling improves honesty over no-steering and single-layer baselines in six of seven models. Equal-budget ablations on LLaMA-3.1-8B-Instruct and Qwen-2.5-7B-Instruct show the Gaussian schedule outperforms random, uniform, and box-filter depth allocations, indicating that how intervention is distributed across depth materially affects outcomes beyond total strength. The method is simple, model-agnostic, requires no finetuning, and provides a low-cost control knob for eliciting truthful reporting from models' existing capabilities.

</details>


### [225] [A Bootstrap Perspective on Stochastic Gradient Descent](https://arxiv.org/abs/2512.07676)
*Hongjian Lan,Yucong Liu,Florian Schäfer*

Main category: cs.LG

TL;DR: SGD通过梯度协方差矩阵的迹正则化控制算法变异性，利用批次采样的梯度变异性作为数据收集过程随机性的代理，从而避免虚假解并提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 研究SGD相比确定性梯度下降（GD）具有更好泛化能力的原因。作者认为SGD的泛化优势源于其通过批次采样的梯度变异性来近似数据收集过程的随机性，类似于统计bootstrap方法。

Method: 1. 在经验风险最小化的理想化实验中验证SGD倾向于选择对重采样鲁棒的解；2. 理论证明SGD通过隐式正则化梯度协方差矩阵的迹来控制算法变异性；3. 在神经网络训练中，将算法变异性估计作为显式正则器来验证其效果。

Result: 1. SGD能够避免训练损失中更宽更深的虚假解；2. 理论分析表明SGD通过控制算法变异性使解对采样噪声不敏感；3. 神经网络实验中，显式加入算法变异性正则器能够提升测试性能。

Conclusion: SGD的泛化优势源于其bootstrap估计机制：通过批次采样的梯度变异性作为数据收集过程随机性的代理，隐式正则化梯度协方差矩阵的迹，从而控制算法变异性并提升泛化能力。

Abstract: Machine learning models trained with \emph{stochastic} gradient descent (SGD) can generalize better than those trained with deterministic gradient descent (GD). In this work, we study SGD's impact on generalization through the lens of the statistical bootstrap: SGD uses gradient variability under batch sampling as a proxy for solution variability under the randomness of the data collection process. We use empirical results and theoretical analysis to substantiate this claim. In idealized experiments on empirical risk minimization, we show that SGD is drawn to parameter choices that are robust under resampling and thus avoids spurious solutions even if they lie in wider and deeper minima of the training loss. We prove rigorously that by implicitly regularizing the trace of the gradient covariance matrix, SGD controls the algorithmic variability. This regularization leads to solutions that are less sensitive to sampling noise, thereby improving generalization. Numerical experiments on neural network training show that explicitly incorporating the estimate of the algorithmic variability as a regularizer improves test performance. This fact supports our claim that bootstrap estimation underpins SGD's generalization advantages.

</details>


### [226] [In-Context and Few-Shots Learning for Forecasting Time Series Data based on Large Language Models](https://arxiv.org/abs/2512.07705)
*Saroj Gopali,Bipin Chhetri,Deepika Giri,Sima Siami-Namini,Akbar Siami Namin*

Main category: cs.LG

TL;DR: 比较了时间序列预测中传统方法（ARIMA、LSTM、TCN）与预训练基础模型（TimesFM、LLMs）的性能，发现TimesFM在RMSE和推理时间上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 随着预训练基础模型（如LLMs和TimesFM）的发展，需要研究这些模型是否能在时间序列预测中超越传统方法（ARIMA、LSTM、TCN等），特别是在实时预测场景中。

Method: 研究了LLMs在时间序列预测中的性能，探索了上下文学习、零样本学习和少样本学习方法。使用了OpenAI o4-mini、Gemini 2.5 Flash Lite、Google的TimesFM，以及TCN和LSTM网络进行对比实验。

Result: TimesFM表现最佳，具有最低的RMSE值（0.3023）和竞争力的推理时间（266秒）。OpenAI的o4-mini在零样本学习中也表现出良好性能。

Conclusion: 预训练时间序列基础模型是实时预测的有前景方向，能够以最小的模型适应实现准确且可扩展的部署。

Abstract: Existing data-driven approaches in modeling and predicting time series data include ARIMA (Autoregressive Integrated Moving Average), Transformer-based models, LSTM (Long Short-Term Memory) and TCN (Temporal Convolutional Network). These approaches, and in particular deep learning-based models such as LSTM and TCN, have shown great results in predicting time series data. With the advancement of leveraging pre-trained foundation models such as Large Language Models (LLMs) and more notably Google's recent foundation model for time series data, {\it TimesFM} (Time Series Foundation Model), it is of interest to investigate whether these foundation models have the capability of outperforming existing modeling approaches in analyzing and predicting time series data.
  This paper investigates the performance of using LLM models for time series data prediction. We investigate the in-context learning methodology in the training of LLM models that are specific to the underlying application domain. More specifically, the paper explores training LLMs through in-context, zero-shot and few-shot learning and forecasting time series data with OpenAI {\tt o4-mini} and Gemini 2.5 Flash Lite, as well as the recent Google's Transformer-based TimesFM, a time series-specific foundation model, along with two deep learning models, namely TCN and LSTM networks. The findings indicate that TimesFM has the best overall performance with the lowest RMSE value (0.3023) and the competitive inference time (266 seconds). Furthermore, OpenAI's o4-mini also exhibits a good performance based on Zero Shot learning.
  These findings highlight pre-trained time series foundation models as a promising direction for real-time forecasting, enabling accurate and scalable deployment with minimal model adaptation.

</details>


### [227] [Enabling Delayed-Full Charging Through Transformer-Based Real-Time-to-Departure Modeling for EV Battery Longevity](https://arxiv.org/abs/2512.07723)
*Yonggeon Lee,Jibin Hwang,Alfred Malengo Kondoro,Juhyun Song,Youngtae Noh*

Main category: cs.LG

TL;DR: 提出基于Transformer的时间到事件模型，用于准确预测电动汽车用户的出发时间，以优化充电策略延长电池寿命


<details>
  <summary>Details</summary>
Motivation: 电动汽车锂离子电池在长时间高电量状态下会加速退化，可以通过延迟充满电直到出发前缓解，这需要准确预测用户出发时间

Method: 使用Transformer架构的实时到事件模型，将每天表示为TTE序列，通过时间离散化为基于网格的token，利用流式上下文信息而非仅依赖历史模式

Result: 在93名用户的真实世界研究中，使用被动智能手机数据验证，该方法能有效捕捉个人日常中的不规则出发模式，性能优于基线模型

Conclusion: 该方法展示了实际部署的潜力，有助于可持续交通系统的发展，通过优化充电策略延长电池寿命

Abstract: Electric vehicles (EVs) are key to sustainable mobility, yet their lithium-ion batteries (LIBs) degrade more rapidly under prolonged high states of charge (SOC). This can be mitigated by delaying full charging \ours until just before departure, which requires accurate prediction of user departure times. In this work, we propose Transformer-based real-time-to-event (TTE) model for accurate EV departure prediction. Our approach represents each day as a TTE sequence by discretizing time into grid-based tokens. Unlike previous methods primarily dependent on temporal dependency from historical patterns, our method leverages streaming contextual information to predict departures. Evaluation on a real-world study involving 93 users and passive smartphone data demonstrates that our method effectively captures irregular departure patterns within individual routines, outperforming baseline models. These results highlight the potential for practical deployment of the \ours algorithm and its contribution to sustainable transportation systems.

</details>


### [228] [A multimodal Bayesian Network for symptom-level depression and anxiety prediction from voice and speech data](https://arxiv.org/abs/2512.07741)
*Agnes Norbury,George Fairs,Alexandra L. Georgescu,Matthew M. Nour,Emilia Molimpakis,Stefano Goria*

Main category: cs.LG

TL;DR: 使用贝叶斯网络模型从语音特征预测抑郁和焦虑症状，在大型数据集上评估性能、公平性和临床实用性


<details>
  <summary>Details</summary>
Motivation: 临床评估中需要整合语言和非语言信息，但现有智能工具尚未实现临床应用。贝叶斯网络可以解决采用障碍，提供透明可解释的评估支持

Method: 使用贝叶斯网络模型，基于30,135名独特说话者的语音特征预测抑郁和焦虑症状，评估性能、人口统计学公平性、多模态整合和冗余性

Result: 模型表现良好：抑郁和焦虑的ROC-AUC分别为0.842和0.831，ECE分别为0.018和0.015；核心症状ROC-AUC>0.74；评估了公平性和临床实用性

Conclusion: 基于丰富大规模多模态数据，在症状层面而非疾病层面构建的贝叶斯网络模型，是构建稳健评估支持工具的合理方法，提供透明可解释的输出，适合临床专家监督

Abstract: During psychiatric assessment, clinicians observe not only what patients report, but important nonverbal signs such as tone, speech rate, fluency, responsiveness, and body language. Weighing and integrating these different information sources is a challenging task and a good candidate for support by intelligence-driven tools - however this is yet to be realized in the clinic. Here, we argue that several important barriers to adoption can be addressed using Bayesian network modelling. To demonstrate this, we evaluate a model for depression and anxiety symptom prediction from voice and speech features in large-scale datasets (30,135 unique speakers). Alongside performance for conditions and symptoms (for depression, anxiety ROC-AUC=0.842,0.831 ECE=0.018,0.015; core individual symptom ROC-AUC>0.74), we assess demographic fairness and investigate integration across and redundancy between different input modality types. Clinical usefulness metrics and acceptability to mental health service users are explored. When provided with sufficiently rich and large-scale multimodal data streams and specified to represent common mental conditions at the symptom rather than disorder level, such models are a principled approach for building robust assessment support tools: providing clinically-relevant outputs in a transparent and explainable format that is directly amenable to expert clinical supervision.

</details>


### [229] [Formalized Hopfield Networks and Boltzmann Machines](https://arxiv.org/abs/2512.07766)
*Matteo Cipollina,Michail Karatarakis,Freek Wiedijk*

Main category: cs.LG

TL;DR: 该论文在Lean 4中形式化神经网络，包括确定性和随机模型，证明了Hopfield网络的收敛性和Hebbian学习的正确性，以及Boltzmann机器的遍历性。


<details>
  <summary>Details</summary>
Motivation: 神经网络被广泛应用，但其分析和验证仍然具有挑战性。为了提供严格的数学保证，需要在定理证明器中形式化神经网络及其性质。

Method: 使用Lean 4定理证明器形式化神经网络。首先形式化Hopfield网络（确定性递归网络），证明其收敛性和Hebbian学习的正确性（限于两两正交模式）。然后形式化随机网络，以Boltzmann机器为例，使用Perron-Frobenius定理的新形式化证明其遍历性和收敛到唯一平稳分布。

Result: 成功在Lean 4中形式化了确定性和随机神经网络模型。证明了Hopfield网络的收敛性和Hebbian学习的正确性。对于Boltzmann机器，证明了其遍历性并展示了收敛到唯一平稳分布。

Conclusion: 该工作展示了在定理证明器中形式化神经网络及其性质的可行性，为神经网络的严格分析和验证提供了基础。形式化的Perron-Frobenius定理也可用于其他随机系统的分析。

Abstract: Neural networks are widely used, yet their analysis and verification remain challenging. In this work, we present a Lean 4 formalization of neural networks, covering both deterministic and stochastic models. We first formalize Hopfield networks, recurrent networks that store patterns as stable states. We prove convergence and the correctness of Hebbian learning, a training rule that updates network parameters to encode patterns, here limited to the case of pairwise-orthogonal patterns. We then consider stochastic networks, where updates are probabilistic and convergence is to a stationary distribution. As a canonical example, we formalize the dynamics of Boltzmann machines and prove their ergodicity, showing convergence to a unique stationary distribution using a new formalization of the Perron-Frobenius theorem.

</details>


### [230] [GatedFWA: Linear Flash Windowed Attention with Gated Associative Memory](https://arxiv.org/abs/2512.07782)
*Jiaxu Liu,Yuhe Bai,Christos-Savvas Bouganis*

Main category: cs.LG

TL;DR: 提出GatedFWA：一种内存门控的滑动窗口注意力机制，在保持SWA效率的同时稳定内存更新并控制梯度流，通过可学习的衰减偏置实现内存递归中的可控收缩。


<details>
  <summary>Details</summary>
Motivation: 传统Softmax全注意力计算复杂度为序列长度的平方，而滑动窗口注意力(SWA)虽然实现线性时间编码/解码，但在关联内存解释下，其差分式更新导致训练目标无界。Softmax注意力则存在内存收缩和梯度消失问题。

Method: GatedFWA通过在每个token/head上累积门控值作为衰减偏置添加到注意力logits中，实现内存递归中的可学习收缩。采用融合的单通道门预处理和与FlashAttention兼容的内核，在滑动掩码下注入门控，确保I/O效率和数值稳定性。

Result: 在语言建模基准测试中，GatedFWA以可忽略的开销提供有竞争力的吞吐量，更好地利用全局上下文，并能与NSA等token压缩/选择方法无缝集成，泛化到各种自回归领域。

Conclusion: GatedFWA成功解决了SWA的内存更新不稳定和Softmax注意力的梯度消失问题，在保持高效计算的同时实现了可控的内存更新和梯度流，为自回归模型提供了更稳定高效的注意力机制。

Abstract: Modern autoregressive models rely on attention, yet the Softmax full attention in Transformers scales quadratically with sequence length. Sliding Window Attention (SWA) achieves linear-time encoding/decoding by constraining the attention pattern, but under an \textit{Associative Memory} interpretation, its difference-style update renders the training objective effectively \emph{unbounded}. In contrast, Softmax attention normalizes updates, leading to \emph{memory shrinkage and gradient vanishing}. We propose GatedFWA: a Memory-\underline{Gated} (\underline{F}lash) \underline{W}indowed \underline{A}ttention mechanism that preserves SWAs efficiency while stabilizing memory updates and making gradient flow controllable. In essence, GatedFWA accumulate a per-token/head gate into a decay bias added to the attention logits, acting as a learnable contraction in the memory recurrence. We implement a fused one-pass gate preprocessing and a FlashAttention-compatible kernel that injects the gate under a sliding mask, ensuring I/O efficiency and numerical stability. On language modelling benchmarks, GatedFWA delivers competitive throughput with negligible overhead and better use of global context, and it integrates cleanly with token compression/selection methods such as NSA and generalizes to various autoregressive domains.

</details>


### [231] [Group Representational Position Encoding](https://arxiv.org/abs/2512.07805)
*Yifan Zhang,Zixiang Chen,Yifeng Liu,Zhen Qin,Huizhuo Yuan,Kangping Xu,Yang Yuan,Quanquan Gu,Andrew Chi-Chih Yao*

Main category: cs.LG

TL;DR: GRAPE是一个基于群作用的统一位置编码框架，包含乘法旋转（SO(d)）和加法logit偏置（GL）两种机制，统一了RoPE和ALiBi等现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有位置编码方法如RoPE和ALiBi等各自独立，缺乏统一的理论框架。GRAPE旨在提供一个基于群作用的统一理论框架，将不同的位置编码机制整合到一个统一的数学框架下。

Method: 基于群作用理论，提出了两种位置编码机制：1）乘法GRAPE：在SO(d)群中使用乘法旋转，位置n作用为G(n)=exp(nωL)，其中L是秩2斜对称生成元；2）加法GRAPE：在GL群中使用单能作用产生加法logit偏置。两种机制分别统一了RoPE和ALiBi等现有方法。

Result: GRAPE框架能够精确恢复RoPE（当d/2平面为规范坐标对且具有对数均匀谱时）和ALiBi、Forgetting Transformer等现有方法。通过学习的交换子空间和紧凑非交换混合，可以扩展几何结构以捕捉跨子空间特征耦合。

Conclusion: GRAPE为长上下文模型中的位置几何提供了一个原则性的设计空间，将RoPE和ALiBi等现有位置编码方法统一为特例，为位置编码的设计提供了更丰富的理论框架和扩展可能性。

Abstract: We present GRAPE (Group RepresentAtional Position Encoding), a unified framework for positional encoding based on group actions. GRAPE brings together two families of mechanisms: (i) multiplicative rotations (Multiplicative GRAPE) in $\mathrm{SO}(d)$ and (ii) additive logit biases (Additive GRAPE) arising from unipotent actions in the general linear group $\mathrm{GL}$. In Multiplicative GRAPE, a position $n \in \mathbb{Z}$ (or $t \in \mathbb{R}$) acts as $\mathbf{G}(n)=\exp(n\,ω\,\mathbf{L})$ with a rank-2 skew generator $\mathbf{L} \in \mathbb{R}^{d \times d}$, yielding a relative, compositional, norm-preserving map with a closed-form matrix exponential. RoPE is recovered exactly when the $d/2$ planes are the canonical coordinate pairs with log-uniform spectrum. Learned commuting subspaces and compact non-commuting mixtures strictly extend this geometry to capture cross-subspace feature coupling at $O(d)$ and $O(r d)$ cost per head, respectively. In Additive GRAPE, additive logits arise as rank-1 (or low-rank) unipotent actions, recovering ALiBi and the Forgetting Transformer (FoX) as exact special cases while preserving an exact relative law and streaming cacheability. Altogether, GRAPE supplies a principled design space for positional geometry in long-context models, subsuming RoPE and ALiBi as special cases. Project Page: https://github.com/model-architectures/GRAPE.

</details>


### [232] [Provable Long-Range Benefits of Next-Token Prediction](https://arxiv.org/abs/2512.07818)
*Xinyuan Cao,Santosh S. Vempala*

Main category: cs.LG

TL;DR: 论文证明：通过优化RNN的下一词预测，可以学习到训练分布的近似，使得在任意k个连续词上，学习到的语言模型与真实分布无法区分。


<details>
  <summary>Details</summary>
Motivation: 解释为什么现代语言模型（训练用于下一词预测）能够生成连贯文档并捕获长程结构，从理论上证明下一词预测对于学习长程结构的能力。

Method: 使用循环神经网络（RNN）优化下一词预测，证明学习到的模型能够近似训练分布。理论分析表明，对于从训练分布采样的文档，任何有界描述长度的算法都无法区分真实文档的k个连续词和模型生成的k个词。

Result: 提供了实现k词不可区分性所需模型大小的多项式边界（与文档长度无关），为实践中观察到的长程连贯性提供了复杂性理论解释。

Conclusion: 下一词预测在理论上具有学习长程结构的能力，这解释了为什么基于下一词预测训练的语言模型能够生成连贯文档并捕获长程依赖关系。

Abstract: Why do modern language models, trained to do well on next-word prediction, appear to generate coherent documents and capture long-range structure? Here we show that next-token prediction is provably powerful for learning longer-range structure, even with common neural network architectures. Specifically, we prove that optimizing next-token prediction over a Recurrent Neural Network (RNN) yields a model that closely approximates the training distribution: for held-out documents sampled from the training distribution, no algorithm of bounded description length limited to examining the next $k$ tokens, for any $k$, can distinguish between $k$ consecutive tokens of such documents and $k$ tokens generated by the learned language model following the same prefix. We provide polynomial bounds (in $k$, independent of the document length) on the model size needed to achieve such $k$-token indistinguishability, offering a complexity-theoretic explanation for the long-range coherence observed in practice.

</details>


### [233] [The Adoption and Usage of AI Agents: Early Evidence from Perplexity](https://arxiv.org/abs/2512.07828)
*Jeremy Yang,Noah Yonack,Kate Zyskowski,Denis Yarats,Johnny Ho,Jerry Ma*

Main category: cs.LG

TL;DR: 首个大规模AI智能体在开放网络环境中的实地研究，分析了Perplexity的Comet浏览器及其AI助手的使用情况，揭示了用户群体、使用强度和用例的异质性。


<details>
  <summary>Details</summary>
Motivation: 了解通用AI智能体在开放网络环境中的实际采用情况、使用强度和具体用例，填补大规模实地研究的空白，为研究者、企业、政策制定者和教育工作者提供实证依据。

Method: 基于Perplexity的Comet浏览器及其Comet Assistant智能体，分析数亿条匿名用户交互数据，引入分层智能体分类法（主题、子主题、任务三个层次）系统化表征使用情况。

Result: 早期采用者、高GDP国家用户、高教育水平人群以及数字/知识密集型行业从业者更可能采用AI智能体；生产力与工作流、学习与研究两大主题占57%查询；个人使用占55%，专业和教学使用分别占30%和16%；短期使用具有粘性，长期用户转向认知导向主题。

Conclusion: AI智能体的扩散对研究者、企业、政策制定者和教育工作者具有重要影响，需要进一步研究这一新兴AI能力类别，特别是用户使用模式的演变和不同群体的采用差异。

Abstract: This paper presents the first large-scale field study of the adoption, usage intensity, and use cases of general-purpose AI agents operating in open-world web environments. Our analysis centers on Comet, an AI-powered browser developed by Perplexity, and its integrated agent, Comet Assistant. Drawing on hundreds of millions of anonymized user interactions, we address three fundamental questions: Who is using AI agents? How intensively are they using them? And what are they using them for? Our findings reveal substantial heterogeneity in adoption and usage across user segments. Earlier adopters, users in countries with higher GDP per capita and educational attainment, and individuals working in digital or knowledge-intensive sectors -- such as digital technology, academia, finance, marketing, and entrepreneurship -- are more likely to adopt or actively use the agent. To systematically characterize the substance of agent usage, we introduce a hierarchical agentic taxonomy that organizes use cases across three levels: topic, subtopic, and task. The two largest topics, Productivity & Workflow and Learning & Research, account for 57% of all agentic queries, while the two largest subtopics, Courses and Shopping for Goods, make up 22%. The top 10 out of 90 tasks represent 55% of queries. Personal use constitutes 55% of queries, while professional and educational contexts comprise 30% and 16%, respectively. In the short term, use cases exhibit strong stickiness, but over time users tend to shift toward more cognitively oriented topics. The diffusion of increasingly capable AI agents carries important implications for researchers, businesses, policymakers, and educators, inviting new lines of inquiry into this rapidly emerging class of AI capabilities.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [234] [Investigating the interplay of the braneworld gravity and the plasma environment on the black hole shadow](https://arxiv.org/abs/2512.06051)
*Siddharth Kumar Sahoo,Indrani Banerjee*

Main category: gr-qc

TL;DR: 研究旋转膜世界黑洞在色散等离子体环境中的阴影，利用EHT观测数据约束膜世界引力参数


<details>
  <summary>Details</summary>
Motivation: 探索膜世界引力理论在黑洞阴影观测中的可检验性，研究等离子体环境对黑洞阴影的影响，利用EHT对M87*和Sgr A*的观测数据约束膜世界引力参数

Method: 采用Kerr-Newman-like度规描述旋转膜世界黑洞，考虑潮汐电荷q参数化膜世界引力效应；研究非均匀和均匀等离子体环境对光线传播的影响；利用EHT观测数据约束(q,α_i)参数空间

Result: 等离子体密度增加时，非均匀等离子体减小阴影尺寸，均匀等离子体增大阴影尺寸；负潮汐电荷(q<0)增大阴影直径，正潮汐电荷(q>0)减小阴影直径；EHT数据约束潮汐电荷范围：M87*为-1.15≲q≲0.45，Sgr A*为-0.65≲q≲0.8（低密度等离子体极限）

Conclusion: 在M87*和Sgr A*等低密度等离子体环境中，阴影尺寸主要由背景几何决定；但在高密度等离子体环境中，阴影尺寸同时受背景度规和等离子体环境共同影响；EHT观测数据可用于约束膜世界引力参数

Abstract: We investigate the shadow of a rotating braneworld black hole in dispersive plasma environments and assess the potential of the Event Horizon Telescope (EHT) observations to constrain braneworld gravity. The spacetime around a rotating braneworld black hole is modelled by a Kerr-Newman-like metric determined by its mass $M$, spin $a$, and tidal charge $q$, which encodes the gravitational effects of the bulk spacetime. We consider both inhomogeneous and homogeneous plasma environments characterized by plasma parameters $α_i$ ($i=1,2\text{ and }3$) to study light propagation and the interplay of the background spacetime and the plasma environment in influencing the shadow size and shape. We find that as the plasma density increases, inhomogeneous plasma environments decrease the shadow size, however homogeneous plasma enlarges it. On studying the effect due to background spacetime we find that $q<0$ (negative tidal charge) increases the shadow diameter, while $q>0$ decreases it. Using the EHT measurements of M87* and Sgr A*, we constrain the $(q,α_i)$ parameter space. The EHT data constrains the tidal charge in the range $-1.15 \lesssim q \lesssim 0.45$ for M87* and $-0.65 \lesssim q \lesssim 0.8$ for Sgr A* in the low density plasma limit. As the plasma density increases, the data exhibits a preference towards negative tidal charge for inhomogeneous plasma environments and positive tidal charge for homogeneous plasma environments. Our study reveals that the size of the shadow is primarily governed by the background geometry in presence of low density plasma environments such as that observed in M87* and Sgr A*. However, if supermassive blackholes are surrounded by high density plasma then the shadow size is dictated by both the background metric and the plasma environment.

</details>


### [235] [Investigating all-sky Frequency Hough performances for neutron stars](https://arxiv.org/abs/2512.06055)
*Martina Di Cesare,Pia Astone,Rosario De Rosa,David Keitel,Cristiano Palomba,Marco Serra*

Main category: gr-qc

TL;DR: 该论文提出了一种机器学习策略，用于改进频率霍夫变换全天连续引力波搜索管道，替代传统的后续跟踪方法，在真实干涉仪数据上取得了优于传统阈值分类的灵敏度。


<details>
  <summary>Details</summary>
Motivation: 中子星估计数量（10^8-9）与已观测数量（10^3）存在巨大差距，全天连续引力波搜索可能帮助缩小这一差距。频率霍夫变换管道虽然有效，但其传统后续跟踪方法在低信噪比下灵敏度有限。

Method: 提出了一种机器学习策略，替代频率霍夫变换管道的标准后续跟踪程序。该方法在真实干涉仪数据上进行性能测试，能够检测到低于传统后续跟踪阈值（CR_thr=5）的信号。

Result: 机器学习方法在真实数据上表现出令人鼓舞的分类结果，能够检测到低于传统后续跟踪阈值的信号，提高了全天连续引力波搜索的灵敏度。

Conclusion: 机器学习策略为全天连续引力波搜索提供了有前景的替代方案，能够提高中子星探测效率，有助于缩小中子星估计数量与实际观测数量之间的巨大差距。

Abstract: Between the estimated population of Neutron Stars (NSs) and the actual number present in the catalogs, there is a huge gap: O(10$^{8-9}$) vs O(10$^3$). Among the different search techniques for Continuous gravitational waves (CWs), the all-sky could help to reduce the discrepancy. We focus on the all-sky CW pipeline Frequency Hough (FH), which operates without prior knowledge of the source parameters ($f,\dot{f}, λ, β$). Here, we present a Machine Learning strategy, diverging from the standard follow-up(FU) of the FH pipeline. We study the performance with real interferometer data, until reaching $h$ value subthreshold for the standard FU procedure ($CR_{thr}=5$), with encouraging classification results.

</details>


### [236] [Hidden symmetries for tidal Love numbers: generalities and applications to analogue black holes](https://arxiv.org/abs/2512.06082)
*Valerio De Luca,Brandon Khek,Justin Khoury,Mark Trodden*

Main category: gr-qc

TL;DR: 本文探讨了黑洞与声学黑洞中潮汐Love数的消失现象，揭示了这两种系统中隐藏的对称性联系。


<details>
  <summary>Details</summary>
Motivation: 研究黑洞潮汐Love数在四维广义相对论中消失的现象，以及类似现象在超音速声学流中的出现，旨在探索这两种看似不同物理系统背后的共同对称性原理。

Method: 通过分析声学黑洞中的阶梯对称性，并将其与广义相对论黑洞时空中的结构特性进行比较，建立基于对称性的理论框架连接。

Result: 证明了声学黑洞中观察到的阶梯对称性可以追溯到基础波动方程的结构特性，这些特性与广义相对论黑洞时空中的特性相似。

Conclusion: 黑洞和声学黑洞中潮汐Love数的消失现象共享共同的对称性起源，这为理解不同物理系统中的隐藏对称性提供了新的视角。

Abstract: Tidal Love numbers characterize the conservative, static response of compact objects to external tidal fields. Remarkably, these quantities vanish identically for asymptotically flat black holes in four-dimensional General Relativity. This behavior has been attributed to hidden symmetries -- both geometric and algebraic -- governing perturbations in these space-times. Interestingly, a similar vanishing of selected multipolar Love numbers arises in the context of supersonic acoustic flows. These systems share several key features with black holes in General Relativity, such as the presence of an effective acoustic horizon and a wave equation describing linear excitations. In this work, we explore a symmetry-based connection between the two frameworks and demonstrate that the ladder symmetries observed in acoustic black holes can be traced to structural properties of the underlying wave equation, mirroring those found in general relativistic black hole space-times.

</details>


### [237] [Apparent Phantom Crossing in Gauss-Bonnet Gravity](https://arxiv.org/abs/2512.06279)
*Shin'ichi Nojiri,Sergei D. Odintsov,V. K Oikonomou*

Main category: gr-qc

TL;DR: DESI观测暗示暗能量状态参数w可能从w<-1变为w>-1（逆幻影穿越），本文在标量-爱因斯坦-高斯-博内引力框架下构建实现该穿越的模型，并研究表观幻影穿越场景，其中暗物质能量密度下降更慢，可能解释DESI观测。


<details>
  <summary>Details</summary>
Motivation: DESI观测数据显示暗能量状态参数w可能在红移z~0.5时从w<-1变为w>-1，这种现象被称为逆幻影穿越。本文旨在探索这种穿越的可能性，并构建能够实现该现象的物理模型。

Method: 在标量-爱因斯坦-高斯-博内引力和无鬼f(𝒢)引力框架下构建实现幻影穿越的现实模型。同时研究表观幻影穿越场景，其中暗物质能量密度下降比通常预期更慢。还提出新场景：标量场对应粒子作为暗物质，其质量因与高斯-博内不变量耦合而增加。

Result: 成功构建了实现幻影穿越的模型，在表观幻影穿越场景中，宇宙流体的任何分量都不违反能量条件。新提出的场景中，标量场粒子作为暗物质，其质量增加使暗物质能量密度下降变慢，这可能将逆幻影穿越与宇宙从减速膨胀到加速膨胀的转变联系起来。

Conclusion: DESI观测到的逆幻影穿越现象可以在标量-爱因斯坦-高斯-博内引力框架下实现。表观幻影穿越场景提供了解释DESI数据的可能机制，其中暗物质能量密度下降变慢是关键。新提出的暗物质-标量场统一模型将幻影穿越与宇宙膨胀相变联系起来，为理解暗能量和暗物质提供了新视角。

Abstract: The recent observations of the Dark Energy Spectroscopic Instrument (DESI) indicated the possibility that the dark energy equation of state parameter $w$ might change from $w<-1$ to $w>-1$ when the redshift $z\sim 0.5$, which is called the inverse phantom crossing. In this paper, we investigate the possibility of the phantom crossing, and we construct realistic models realizing the crossing in the framework of the scalar--Einstein--Gauss-Bonnet gravity and ghost-free $f(\mathcal{G})$ gravity. We also investigate the scenario of the apparent phantom crossing, where dark matter energy density decreases more slowly than usually expected, which might explain the DESI observations. In the scenarios developed, the energy conditions are not violated by any component of the cosmic fluid. In the framework of the apparent phantom crossing, we also propose a new scenario, where the particle corresponding to the scalar field in the scalar--Einstein--Gauss-Bonnet gravity is dark matter. The mass of the particle might increase due to the coupling with the Gauss-Bonnet invariant, which makes the decrease of the dark matter energy density slower. This last scenario may suggest that the inverse phantom crossing might be related to the transition from the decelerating expansion of the Universe to the accelerating expansion.

</details>


### [238] [A Brief Review of Quantum Tunneling: Computational Approaches and Experimental Evidence](https://arxiv.org/abs/2512.06361)
*Sareh Eslamzadeh,Saheb Soroushfar*

Main category: gr-qc

TL;DR: 本文综述了霍金辐射的量子隧穿方法，包括理论基础、扩展到动态黑洞以及实验研究进展。


<details>
  <summary>Details</summary>
Motivation: 霍金辐射是黑洞理论的核心概念，量子隧穿方法为理解黑洞蒸发提供了半经典框架。本文旨在系统回顾该方法的理论基础、扩展到动态黑洞的挑战，以及当前实验验证的进展。

Method: 采用Hamilton-Jacobi和Parikh-Wilczek方法作为半经典框架，推导静态黑洞的霍金辐射。扩展到动态黑洞时，引入捕获视界、Kodama矢量和动态表面引力等概念，分析粒子穿越动态视界的可能隧穿路径，强调作用量虚部在确定霍金温度中的关键作用。

Result: 建立了从静态到动态黑洞的霍金辐射隧穿理论框架，阐明了动态黑洞中隧穿过程的特殊性。实验方面，虽然尚未直接探测到霍金辐射，但通过玻色-爱因斯坦凝聚体、光学模拟和超导量子比特等类比实验获得了间接支持证据。

Conclusion: 量子隧穿方法为霍金辐射提供了有力的半经典解释框架，特别是在动态黑洞情况下需要修正处理。实验研究虽未实现直接探测，但类比实验和量子模拟为隧穿解释提供了间接验证，未来实验技术发展有望带来突破。

Abstract: This paper presents a concise review of the quantum tunneling approach to Hawking radiation, covering its theoretical foundations, extensions, and experimental efforts. We begin by outlining the Hamilton-Jacobi and Parikh-Wilczek methods, which provide a semi-classical framework for deriving Hawking radiation from stationary black holes. The discussion is then extended to dynamical black holes, where evolving horizons require modified treatments incorporating trapping horizons, Kodama vectors, and dynamical surface gravity. We explored the possible tunneling paths for particles crossing the horizon in dynamical black holes and emphasized the crucial role of the imaginary part of the action in determining the Hawking temperature. In the second part, we review experimental investigations of Hawking radiation, including analogue black hole experiments, quantum simulations, and astrophysical searches for primordial black hole evaporation. While no direct detection of Hawking radiation has been achieved, recent advances in Bose-Einstein condensates, optical analogues, and superconducting qubits offer indirect support for the tunneling interpretation of black hole evaporation.

</details>


### [239] [On Spavieri's conundrum or the shadow of the twin paradox -- A submission to the One-Way Linear Effect (OWLE) Award](https://arxiv.org/abs/2512.06382)
*Marco Mamone-Capria*

Main category: gr-qc

TL;DR: 论文分析线性萨尼亚克效应中的所谓不一致性，指出其根源在于对双生子悖论标准解法的理解困难，而非同时性约定的问题。


<details>
  <summary>Details</summary>
Motivation: 解决特殊相对论中线性萨尼亚克效应处理中感知到的不一致性问题，澄清一些作者对此效应的困惑根源。

Method: 通过分析线性萨尼亚克效应的绝对性本质，指出问题根源在于对双生子悖论标准解法的不适应，而非同时性约定的选择问题。

Result: 证明线性萨尼亚克效应是绝对效应，任何保持特殊相对论物理内容的同时性约定调整都无法解决感知到的问题，真正困难在于理解双生子悖论的标准解法。

Conclusion: 线性萨尼亚克效应中的所谓不一致性实际上反映了对双生子悖论标准解法的理解困难，而非特殊相对论本身的问题，同时性约定的调整无法解决这一根本困难。

Abstract: We deal with a problem concerning a supposed inconsistency in the special relativistic treatment of the so-called linear Sagnac effect. It is shown that, under modern clothes, the root of the difficulty perceived by some authors lies in their uneasiness with the standard solution of the twin paradox. In particular, since the linear Sagnac effect is an absolute effect, no tinkering with conventionality of simultaneity, so far as it preserves the physical content of special relativity, would get us out of the supposed trouble.

</details>


### [240] [Adiabatic tides in compact binaries on quasi-elliptic orbits: Dynamics at the second-and-a-half relative post-Newtonian order](https://arxiv.org/abs/2512.06489)
*Quentin Henry,Anna Heffernan*

Main category: gr-qc

TL;DR: 该论文针对GW200105这一具有偏心特征的中子星-黑洞双星系统，在2.5阶后牛顿近似下推导了包含潮汐效应的准椭圆轨道波形，提供了至14阶偏心率的展开结果。


<details>
  <summary>Details</summary>
Motivation: GW200105是首个显示偏心特征且为中子星-黑洞双星的引力波探测事件，这需要开发能够处理准椭圆轨道上潮汐效应的波形模型。

Method: 在后牛顿框架下，采用绝热近似包含质量型四极矩和八极矩以及流型四极矩形变，在2.5阶相对后牛顿阶数下进行计算。推导了保守运动的准开普勒参数化，将径向分离和相位及其时间导数表示为轨道频率、时间偏心率和偏近点角的函数。

Result: 提供了至14阶偏心率的展开结果，通过求解广义开普勒方程获得时间函数，并利用已知的辐射反冲加速度项推导了轨道元素的长期和振荡演化。

Conclusion: 该研究为偏心中子星-黑洞双星系统提供了包含潮汐效应的波形计算方法，相关结果在补充文件中提供，辐射通量和应变振幅模式的推导在配套论文中给出。

Abstract: GW200105 is the first gravitational wave detection to show signs of eccentricity, it also is a neutron star - blackhole binary. This raises the need for waveforms that incorporate tidal effects on quasi-elliptic orbits. We tackle the problem of finite size effects within the post-Newtonian framework, including the mass-type quadrupole and octupole, as well as the current-type quadrupole deformations in the adiabatic approximation. The computations are performed at the second-and-a-half relative post-Newtonian order. We first derive the quasi-Keplerian parametrization of the conservative motion; we then express the radial separation and phase with their time derivatives in terms of the orbital frequency, the time eccentricity and the eccentric anomaly. To obtain these as functions of time, we invert the generalized Kepler equation while also discussing the convergence of eccentricity expanded results. We provide those results to the fourteenth order in eccentricity. Finally, we exploit the already known radiation reaction term of the acceleration in order to derive the secular and oscillatory evolutions of the orbital elements. The companion paper contains the derivation of the radiated fluxes and the amplitude modes of the strain. All relevant results are provided in an ancillary file.

</details>


### [241] [Emergent Universe Scenario in the Modified Chaplygin gas : Towards an Exact Solution and Observational Constraints](https://arxiv.org/abs/2512.06498)
*D. Panigrahi,S. Chatterjee,B. C. Paul*

Main category: gr-qc

TL;DR: 重新审视修正Chaplygin气体模型，通过一阶近似得到尺度因子的精确解析解，提出一个从有限最小尺寸开始、平滑演化到类de Sitter膨胀的非奇异宇宙学场景，并用观测数据约束参数。


<details>
  <summary>Details</summary>
Motivation: 修正Chaplygin气体模型能够描述完整宇宙演化，但场方程高度非线性，无法得到尺度因子关于宇宙时间的封闭解析解。需要克服这一限制，确定翻转时间和其他物理特征。

Method: 引入替代的一阶近似方法，得到尺度因子的精确解析表达式。使用哈勃观测数据约束状态方程参数，并通过Raychaudhuri方程进行补充分析验证模型稳健性。

Result: 获得了一个涌现的非奇异宇宙学场景：宇宙从有限最小尺寸开始，从准静态相平滑演化到晚期类de Sitter膨胀，自然趋近于ΛCDM极限。参数约束范围为0 < α < 1和0 < A < 1/3，有效状态方程参数从早期物质主导时期的正值演化到晚期约-1的值。

Conclusion: 修正Chaplygin气体模型通过一阶近似方法能够成功描述完整宇宙演化，提供解析解并得到观测支持，是一个有前景的宇宙学框架。

Abstract: The Modified Chaplygin Gas (MCG) model is revisited to examine its ability to describe the full cosmic evolution within a single framework. Because the field equations are highly nonlinear, no closed analytical solution for the scale factor in terms of cosmic time exists. To address this limitation and determine the flip time along with other physical characteristics, we introduce an alternative first order approximation that yields an exact analytical expression for the scale factor. This approach gives rise to an emergent, non singular cosmological scenario in which the universe begins with a finite minimum size and evolves smoothly from a quasi static phase to a de Sitter like expansion at late times, naturally approaching the LambdaCDM limit. Using Hubble observational data, we constrain the equation of state parameters and obtain the viable ranges 0 < alpha < 1 and 0 < A < 1/3. The effective equation of state parameter evolves from a positive value in the early matter dominated era to approximately minus one at late times, consistent with observations. A complementary analysis based on the Raychaudhuri equation further supports the robustness of the model.

</details>


### [242] [The Two-Sheeted Topology of Extended Kerr-Type Spacetimes and a Parity-of-Crossings Property for Ring-Traversing Geodesics](https://arxiv.org/abs/2512.06549)
*Sabbir A. Rahman*

Main category: gr-qc

TL;DR: 论文研究了具有环奇点的Kerr型时空的全局拓扑结构，证明了移除环奇点后时空可表示为外部Kerr区域的双叶分支覆盖，并建立了奇点穿越的奇偶性定理。


<details>
  <summary>Details</summary>
Motivation: 重新审视扩展Kerr时空和具有环奇点的Kerr型时空的全局结构，理解环奇点如何影响时空的拓扑性质以及测地线穿越奇点的行为。

Method: 通过基本解析延拓（内外区域在盘面上粘合），移除环奇点，将时空构造为外部Kerr区域的分支双覆盖。使用覆盖空间理论描述双叶结构，分析测地线穿越奇点的行为，并推广到多环奇点情况。

Result: 证明移除环奇点后时空是外部Kerr区域的双叶分支覆盖，分支轨迹是环本身。建立了奇点穿越的奇偶性定理：偶数次穿越返回原叶，奇数次穿越到达对侧叶。多环情况下基本群是自由群F_N，并推广到最大解析延拓。

Conclusion: Kerr型时空具有丰富的拓扑结构，环奇点诱导了非平凡的Z_2作用。应用Novikov自洽原理表明，全局一致性要求将可容许历史限制在由环穿越奇偶性标记的离散扇区中。

Abstract: We revisit the global structure of the extended Kerr spacetime and of a broader class of Kerr-type spacetimes possessing ring singularities. By working with the elementary analytic extension (the union of the interior and exterior regions glued across the disk), we show that excising the ring singularity yields a domain that can be realised as a branched double cover of an exterior Kerr region. The branch locus is the ring itself, and the associated deck transformation defines a non-trivial $\mathbb{Z}_2$-action that exchanges the two sheets ($r>0$ and $r<0$) of the spacetime.
  We give a covering-space characterisation of this double-sheeted structure and show that admissible geodesics which cross the ring singularity implement the non-trivial deck transformation. In particular, we prove a parity-of-crossings property: any admissible geodesic that traverses an even number of ring singularities returns to its original sheet, while an odd number of traversals terminates on the opposite sheet.
  Generalising to $N$ disjoint ring singularities, we prove that the fundamental group of the excised manifold is the free group $F_N$ generated by simple loops around each ring, and we classify the associated double covers. Identifying the physically distinguished cover where every ring induces a sheet exchange, we extend the parity-of-crossings theorem to the multi-ring setting. We then formally extend these results to the maximal analytic extension (the infinite Carter--Penrose chain), proving that the sheet-exchange mechanism applies globally to this infinite structure.
  Finally, applying the Novikov self-consistency principle to this topological framework, we demonstrate that the requirement of global consistency restricts admissible histories to discrete sectors labelled by ring-crossing parities.

</details>


### [243] [Quantum Treatment of Black Hole Superradiance](https://arxiv.org/abs/2512.06790)
*Lingyun Fu,Hidetoshi Omiya,Takahiro Tanaka,Xi Tong,Yi Wang,Hui-Yu Zhu*

Main category: gr-qc

TL;DR: 该论文对克尔黑洞周围的标量场进行正则量子化，提供了黑洞超辐射的完整量子描述，证明了粒子云的演化与初始态无关，并探讨了相关量子现象。


<details>
  <summary>Details</summary>
Motivation: 先前关于黑洞超辐射的研究多将玻色场视为经典场，未能解释粒子如何产生以及云如何随时间增长。需要从量子场论角度提供完整的量子描述。

Method: 对克尔黑洞周围的有质量标量场进行正则量子化，在弯曲时空量子场论框架下分析粒子数、能量和角动量的演化。

Result: 证明了粒子云的增长与初始态选择无关，能够一致地解释标量场的演化，并探讨了霍金辐射、绝热反冲和自相互作用下的能级跃迁方向等现象。

Conclusion: 该工作为黑洞超辐射提供了自洽的量子力学视角，统一了包括霍金辐射在内的多种相关现象，建立了完整的量子描述框架。

Abstract: Rotating black holes can form dense boson clouds through superradiant instability, making Kerr black holes a powerful probe of ultralight massive bosons. Previous studies of black hole superradiance have often treated bosonic fields classically, leaving open questions about how particles are produced and how the clouds grow over time. In this work, we canonically quantize a massive scalar field around a Kerr black hole, providing a fully quantum description of black hole superradiance. We show that the evolution of the particle number in the cloud, as well as the energy and angular momentum of the scalar field, can be consistently explained within the standard framework of quantum field theory in curved spacetime. Furthermore, we prove that the growth of the cloud occurs independently of the choice of initial state. We also explore several phenomena related to a massive scalar field in a rotating black hole spacetime, including Hawking radiation, adiabatic backreaction on the black hole spin, and the direction of level transitions in the presence of self-interactions of the field. Our analysis provides a consistent quantum-mechanical perspective that includes all these phenomena.

</details>


### [244] [Extreme mass ratio inspirals in the cold vector dark matter environment](https://arxiv.org/abs/2512.06807)
*Rajesh Karmakar,Kaustubh Mukund Vispute,Debaprasad Maity*

Main category: gr-qc

TL;DR: 研究探讨矢量暗物质（Proca场）对引力波观测的影响，分析其在粒子态和波动态下的密度分布，并通过LISA观测预测探测可能性。


<details>
  <summary>Details</summary>
Motivation: 先前研究已探讨标量暗物质通过引力波观测的可探测性，本研究扩展至矢量暗物质（Proca场），旨在分析其在黑洞附近的密度分布及其对引力波相位的影响。

Method: 构建矢量暗物质在黑洞附近的密度分布（质量范围10^{-10}-10^{-15} eV），数值计算波动态分布，假设外围暗物质遵循带中心尖峰的NFW分布。建立恒星质量黑洞（1M⊙）向史瓦西黑洞（10^4M⊙）旋进的模型，分析引力波应变中的相位偏移，并进行LISA观测的Fisher预测。

Result: 计算了矢量暗物质在粒子态和波动态下的密度分布，分析了其对引力波相位的去相位效应，通过Fisher预测评估了LISA观测的可探测性，并与标量暗物质案例进行了比较。

Conclusion: 矢量暗物质在引力波谱中具有可探测特征，特别是在粒子态和波动态下表现出不同特性，LISA观测有望探测此类信号，为暗物质性质研究提供新途径。

Abstract: With regard to the observed dark matter density profile in galaxies and clusters, the scalar dark matter scenario has been previously studied for potential detectability through gravitational wave observations at measurable signal-to-noise ratios. In the present study, we consider the case of dark matter described by a massive vector field, also referred to as the Proca field. The density profile in the vicinity of the black hole is explicitly constructed for a broad range of dark matter mass, $μ\sim 10^{-10}-10^{-15}{\mathrm eV}$, which allows it to exhibit both particle and wave-like characteristics. While in the particle regime, the computation of the DM density distribution is analytically tractable, we find it convenient to compute the same numerically in the wave regime. Nevertheless, in the outer region, the surrounding dark matter is assumed to follow a broken power-law distribution, represented by a Navarro-Frenk-White (NFW) profile with a central spike. For the purpose of investigating the detectability of the vector dark matter in the gravitational wave spectrum, we have modelled a stellar-mass black hole ($1M_{\odot}$) inspiralling into a Schwarzschild black hole of mass $10^4M_{\odot}$ within such a vector dark matter environment. With this setup, we analyzed the dephasing in the gravitational wave strain induced by vector dark matter and performed a Fisher forecast for upcoming LISA observations, with particular emphasis on the distinctive features in both the particle and wave regimes of the dark matter. Additionally, most of the important results have been compared with the scalar dark matter case.

</details>


### [245] [Quasinormal modes of Schwarzschild-de Sitter black holes in semi-open systems](https://arxiv.org/abs/2512.06903)
*Libo Xie,Li-Ming Cao,Ming-Fei Ji,Yu-Sen Zhou,Liang-Bi Wu*

Main category: gr-qc

TL;DR: 使用Heun函数研究半开放系统中Schwarzschild-de Sitter黑洞的扰动，分析准正规模谱、灰体因子和异常点三个方面的行为特征。


<details>
  <summary>Details</summary>
Motivation: 研究在事件视界附近添加部分反射壁的半开放系统中黑洞扰动的物理特性，探索反射边界条件对黑洞动力学行为的影响。

Method: 采用Heun函数分析Schwarzschild-de Sitter黑洞在半开放系统中的扰动，通过引入频率无关反射率参数𝒦，研究准正规模谱、灰体因子和异常点的行为。

Result: 发现三种不同类型的准正规模行为：第一类模式趋近实轴形成长寿命准束缚态；第二类模式趋近但不接触实轴保持有限衰减率；第三类模式最终位于虚轴成为纯衰减模式。灰体因子表现出由势垒与反射壁距离控制的强振荡，而Boltzmann型反射率仅产生小修正。通过将𝒦推广为复参数，观察到二阶异常点附近的模式交换现象。

Conclusion: 半开放系统中反射边界条件显著影响黑洞扰动特性，产生丰富的物理现象，包括准正规模谱的多样化行为、灰体因子的振荡特性以及异常点附近的模式交换，这些发现为黑洞物理研究提供了新视角。

Abstract: We study perturbations of Schwarzschild-de Sitter black holes in semi-open systems by using the Heun functions. For the semi-open system, a partially reflective wall is added around the event horizon. Three aspects of this model are investigated, namely the quasinormal mode (QNM) spectra, the greybody factor (GF), and the exceptional point (EP). For the QNM aspect, we identify three distinct behaviors as the frequency-independent reflectivity $\mathcal{K}$ increasing. The first-type modes approach the real axis and form long-lived quasi-bound states. The second-type modes move toward but do not reach the real axis and retain a finite decay rate. The third-type modes eventually lie on the imaginary axis becoming purely decaying modes. For the GF aspect, GFs exhibit strong oscillations controlled by the distance between the potential and the reflective wall with a real constant reflectivity. In contrast, a Boltzmann-type reflectivity produces only small corrections. Finally, by promoting $\mathcal{K}$ to a complex parameter, the modified boundary conditions give rise to a second-order EP. Parameterizing the vicinity of such EP, we observe the mode exchange phenomenon, and the deviation of spectra scale with the square root of the deviation of the parameter, as predicted by a Puiseux series expansion.

</details>


### [246] [A first-order formulation of f(R) gravity in spherical symmetry](https://arxiv.org/abs/2512.06908)
*Philippe G. LeFloch,Filipe C. Mena*

Main category: gr-qc

TL;DR: 本文建立了f(R)引力中球对称标量场演化的首阶形式，提出了特征初值问题，并证明了霍金质量的单调性。


<details>
  <summary>Details</summary>
Motivation: 研究f(R)修正引力理论中球对称标量场的全局演化，建立适合几何分析和数值模拟的数学框架。

Method: 在广义Bondi-Sachs坐标系中，将f(R)场方程重铸为两个耦合的一阶非局部非线性双曲方程系统，处理特征初值问题。

Result: 建立了f(R)引力中球对称标量场演化的首阶形式，证明了霍金质量的单调性，分析了f(R)→R的奇异极限。

Conclusion: 该形式化方法分离了演化方程和约束方程，为修正引力中球对称塌缩的几何分析和数值模拟提供了基础框架。

Abstract: We develop a first-order formulation of the field equations in f(R) gravity governing the global evolution of a (possibly massive) scalar field under spherical symmetry. Our formulation allows us to pose the characteristic initial value problem and to establish several properties of solutions. More precisely, we work in generalized Bondi-Sachs coordinates and prescribe initial data on an asymptotically Euclidean, future light cone with vertex at the center of symmetry, and we identify the precise regularity conditions required at the center. Following and extending Christodoulou's approach to the Einstein-massless scalar-field system, we recast the f(R) field equations as an integro-differential system of two coupled, first-order, nonlocal, nonlinear hyperbolic equations, whose principal unknowns are the scalar field and the spacetime scalar curvature. In deriving this reduced two-equation system, we identify the regularity conditions at the center of symmetry and impose natural assumptions on the scalar-field potential and on the function f(R) governing the gravitational Lagrangian density. As an application, we prove the monotonicity of the Hawking mass in this setting and formally analyze the singular limit in which the integrand f(R) of the action approaches R, corresponding to the Einstein-Hilbert action. Hence, the formulation isolates the essential evolution and constraint content on the future domain of dependence of two null hypersurfaces and is designed to facilitate subsequent advances in geometric analysis and robust numerical simulations of spherical collapse in modified gravity.

</details>


### [247] [Angular Momentum Penrose Inequality](https://arxiv.org/abs/2512.06918)
*Da Xu*

Main category: gr-qc

TL;DR: 证明了满足主导能量条件的轴对称真空初始数据的角动量彭罗斯不等式，建立了ADM质量关于黑洞视界面积和科马角动量的尖锐下界，等号仅由克尔解实现。


<details>
  <summary>Details</summary>
Motivation: 建立第一个同时包含视界面积和角动量的几何不等式，对宇宙审查假设、黑洞热力学和引力波观测有重要意义。

Method: 结合四个主要要素：求解轴对称Jang方程（其中扭转作为低阶扰动）、通过散度恒等式建立共形因子界、使用de Rham上同调证明沿水平集的角动量守恒、应用已证明的Dain-Reiris亚极值面积-角动量不等式。

Result: 证明了角动量彭罗斯不等式，建立了ADM质量关于视界面积和角动量的尖锐下界，等号仅由克尔解实现。

Conclusion: 通过Agostiniani-Mazzieri-Oronzio流中组合面积-角动量泛函的单调性得到结果，这是第一个同时包含视界面积和角动量的几何不等式，对多个物理领域有重要应用。

Abstract: We prove the Angular Momentum Penrose Inequality for axisymmetric vacuum initial data satisfying the dominant energy condition. This inequality establishes a sharp lower bound on the ADM mass in terms of both the horizon area and the Komar angular momentum of a black hole, with equality achieved precisely by the Kerr solution. The proof combines four main ingredients: solving an axisymmetric Jang equation where twist enters as a lower-order perturbation, establishing conformal factor bounds via a divergence identity, proving angular momentum conservation along level sets using de Rham cohomology, and applying the proven Dain-Reiris area-angular momentum inequality for sub-extremality. The monotonicity of a combined area-angular momentum functional along the Agostiniani-Mazzieri-Oronzio flow yields the result. This provides the first geometric inequality incorporating both horizon area and angular momentum, with implications for cosmic censorship, black hole thermodynamics, and gravitational wave observations of spinning black holes.

</details>


### [248] [Revisiting black holes in dark-matter halos: on consistent solutions to the Einstein equations](https://arxiv.org/abs/2512.06930)
*S. V. Bolokhov*

Main category: gr-qc

TL;DR: 该论文指出近期许多声称构建暗物质晕环绕黑洞的爱因斯坦方程解的研究方法存在根本错误，这些方法错误地将牛顿关系直接应用于相对论框架，导致得到的解并非真正的暗物质分布，而是各向异性流体配置。


<details>
  <summary>Details</summary>
Motivation: 近期多篇论文声称构建了具有经验密度分布（如NFW、Burkert、Einasto等）的暗物质晕环绕黑洞的爱因斯坦方程解。本文旨在揭示这些方法中的系统性错误，澄清这些解并非真正的暗物质分布，而是各向异性流体配置。

Method: 通过分析文献中代表性例子（包括基于NFW、Burkert、Einasto、孤子、伪等温、Dehnen-(1,4,5/2)分布以及NGC 4649晕的度量），展示这些方法如何错误地将牛顿关系（切向速度与包围质量的关系）直接应用于相对论框架，并随意假设度量函数g(r)=f(r)。

Result: 该方法导致各向异性流体，其径向压力P_r=-ρ，切向压力P_t=-rρ'/2-ρ，密度与声称的晕分布不同，且在视界附近常变得非物理，违反弱能量条件。因此得到的时空并非描述已知星系晕中的黑洞，而是与预期物质分布无关的独特各向异性配置。

Conclusion: 本文澄清了牛顿近似在致密天体附近的适用范围，并为在广义相对论中构建暗物质启发的黑洞几何建立了自洽框架。对于每个案例，提供了正确的爱因斯坦一致形式的度量和相关物理解释。

Abstract: A number of recent papers have claimed to construct solutions of Einstein's equations describing black holes surrounded by dark-matter halos with empirically motivated density profiles such as the Navarro-Frenk-White, Burkert, Einasto, pseudo-isothermal, and solitonic distributions. We show that the approach used to obtain many of these metrics generically does not lead to the correct solutions to the Einstein equations for the matter sources they purport to represent. This issue originates from applying the Newtonian relation between the tangential velocity and the enclosed mass directly within a relativistic framework, followed by the ad hoc assumption $g(r)=f(r)$ for the metric functions. This procedure leads to an anisotropic fluid with $P_r=-ρ$ and $P_t=-rρ'/2-ρ$, whose density differs from the claimed halo profile and often becomes non-physical near the horizon, violating the weak energy condition. As a result, the obtained spacetimes do not describe black holes embedded in known galactic halos but rather distinct anisotropic configurations unrelated to the intended matter distribution. We demonstrate this problem on several representative examples from the literature, including metrics based on the NFW, Burkert, Einasto, solitonic, pseudo-isothermal, and Dehnen-(1,4,5/2) profiles, as well as the case of the NGC~4649 halo. For each case, the correct Einstein-consistent form of the metric and the associated physical interpretation are provided. Our analysis clarifies the limits of validity of the Newtonian approximation near compact objects and establishes a consistent framework for constructing dark-matter-inspired black-hole geometries within General Relativity.

</details>


### [249] [Optimal Control Theory of the (2+1)-Dimensional BTZ Black Hole](https://arxiv.org/abs/2512.06931)
*M. Radomirov,R. C. Rashkov,G. S. Stoilov,T. Vetsov*

Main category: gr-qc

TL;DR: 将有限时间几何优化框架应用于(2+1)维BTZ黑洞的热涨落和(非)平衡最优过程研究


<details>
  <summary>Details</summary>
Motivation: 首次为BTZ黑洞构建几何最优控制理论，研究黑洞热力学中的最优过程

Method: 使用Hessian热力学信息度量构造测地线轨迹，定义连接不同热力学构型的最优协议

Result: 建立了BTZ黑洞的几何最优控制理论框架，描述了有限时间状态转移的最优路径

Conclusion: 成功将有限时间几何优化应用于黑洞热力学，为研究黑洞热力学过程的最优控制提供了新方法

Abstract: We apply a finite-time geometric optimization framework to investigate thermal fluctuations and (non)equilibrium optimal processes in the $(2+1)$-dimensional BTZ black hole. Employing Hessian thermodynamic information metrics, we construct geodesic trajectories that define optimal protocols connecting distinct thermodynamic configurations. Finite-time state transitions are described by paths that extremize entropy production or energy dissipation, depending on the chosen thermodynamic representation. This work presents the first formulation of a geometric optimal control theory for the BTZ black hole.

</details>


### [250] [Exact solution of the Einstein-scalar-Gauss-Bonnet model with Noether symmetry constraints](https://arxiv.org/abs/2512.07187)
*Olga Razina,Dauren Rakhatov,Pyotr Tsyba,Emilio Elizalde*

Main category: gr-qc

TL;DR: 应用Noether对称方法，在广义爱因斯坦-标量-高斯-博内模型中获得了解析解，该模型包含ξ(φ)f(G)项。通过宇宙学观测数据验证，该模型在信息准则上略优于ΛCDM模型，且能解释从减速到加速膨胀的转变。


<details>
  <summary>Details</summary>
Motivation: 研究广义爱因斯坦-标量-高斯-博内模型，探索包含标量场与高斯-博内不变量非最小耦合的暗能量模型，以解释宇宙加速膨胀现象并评估其相对于标准ΛCDM模型的优越性。

Method: 应用Noether对称方法获得解析解；通过变分原理和微扰理论推导运动方程和张量扰动传播速度；使用宇宙计时器、重子声学振荡和Ia型超新星数据进行模型验证；基于信息准则进行模型选择；分析慢滚参数、谱指数和张量-标量比来研究早期宇宙动力学。

Result: 哈勃参数包含来自刚体物质和暗能量的贡献；信息准则显示该新框架略优于ΛCDM模型；模型稳定（声速为正且无Ostrogradsky鬼态）；总状态参数表明在z≈0.66处存在从减速到加速膨胀的转变；早期宇宙动力学与Planck 2018和ACT观测完全一致。

Conclusion: 该广义爱因斯坦-标量-高斯-博内模型在观测上可行，略优于标准ΛCDM模型，能解释宇宙加速膨胀的转变，且早期宇宙预测与当前观测一致，为暗能量研究提供了有前景的理论框架。

Abstract: By applying Noether symmetry methods, analytic solutions are obtained for a generalized Einstein-scalar-Gauss-Bonnet model with a $ξ(φ)f(G)$ component. Variation with respect to the metric, supplemented by small perturbations, produces the equations of motion and the terms that determine the propagation speed of tensor perturbations. The resulting Hubble parameter incorporates contributions from stiff matter and dark energy, the last originating from a scalar field non-minimally coupled to the Gauss-Bonnet invariant. The viability of the model is assessed by using Cosmic Chronometers, Baryon Acoustic Oscillations, and type Ia supernovae data. Best model selection based on information criteria indicates a slight preference for this new framework over the $Λ$ Cold Dark Matter model. Stability of the model follows from the positive speed of sound and absence of ``Ostrogradsky ghosts''. The total equation of state parameter hints towards the presence of a transition from decelerated to accelerated expansion at $z\approx 0.66$, corresponding to the transition from matter to dark energy dominance. Early Universe dynamics, derived from the slow-roll parameters, spectral indices, and the tensor-to-scalar ratio, are found to be perfectly consistent with observations from Planck 2018 and the Atacama Cosmology Telescope.

</details>


### [251] [Systematic bias due to eccentricity in parameter estimation for merging binary neutron stars : spinning case](https://arxiv.org/abs/2512.07205)
*Eunjung Lee,Hee-Suk Cho,Chang-Hwan Lee*

Main category: gr-qc

TL;DR: 该研究扩展了先前关于偏心双中子星引力波参数估计的工作，通过加入自旋参数，使用Fisher-Cutler-Vallisneri方法分析使用非偏心波形导致的系统偏差，并验证了方法的可靠性。


<details>
  <summary>Details</summary>
Motivation: 先前研究已探讨了偏心对无自旋双中子星系统引力波参数估计的影响，但实际双中子星系统通常具有自旋。因此需要将研究扩展到包含自旋的更现实情况，以全面评估偏心对参数估计的影响。

Method: 采用解析的Fisher-Cutler-Vallisneri方法计算使用非偏心波形进行参数估计时产生的系统偏差，并通过与数值贝叶斯参数估计结果比较验证方法可靠性。随机生成10^4个双中子星源，参数空间包括质量(m1,m2)、有效自旋(χ_eff)和偏心(e0)，假设APR4状态方程的潮汐形变参数作为真值。

Result: 对于M_c、η和χ_eff的偏差分布呈现窄带，随e0增加呈二次函数增减，表明偏差对这三个参数的依赖性较弱。而~λ的偏差分布广泛，在给定e0下强烈依赖于质量和自旋参数。通过贝叶斯参数估计验证了偏差对中子星性质推断的影响。

Conclusion: 偏心对双中子星引力波参数估计的影响在包含自旋的情况下依然显著，特别是对潮汐形变参数的估计偏差较大且依赖于系统参数。这强调了在引力波数据分析中考虑偏心效应的重要性，特别是对中子星状态方程的约束研究。

Abstract: In our previous work [Phys. Rev. D {\bf 105}. 124022 (2022)], we studied the impact of eccentricity on gravitational-wave parameter estimation for a nonspinning binary neutron star (BNS) system. We here extend the work to a more realistic case by including the spin parameter in the system. As in the previous work, we employ the analytic Fisher-Cutler-Vallisneri method to calculate the systematic bias that can be produced by using noneccentric waveforms in parameter estimation, and we verify the reliability of the method by comparing it with numerical Bayesian parameter estimation results. We generate $10^4$ BNS sources randomly distributed in the parameter space $m_1$-$m_2$-$χ_{\rm eff}$-$e_0$, where the nuetron star mass is in the range of $1 M_\odot \leq m_{1,2}\leq 2M_\odot (m_2 \leq m_1)$, the effective spin is $-0.2 \leq χ_{\rm eff} \leq0 .2$, and the eccentricity (at the reference frequency 10 Hz) is $0 \leq e_0 \leq 0.024$. For the true value of the tidal deformability ($λ$) of neutron stars, we assume the equation of state model APR4. For all gravitational-wave signals emitted from the sources, we calculate the systematic biases ($Δθ$) for the chirp mass ($M_c$), symmetric mass ratio ($η$), effective spin ($χ_{\rm eff}$), and effective tidal deformability ($\tildeλ$), and obtain generalized distributions of the biases. The distribution of biases in $M_c, η$, and $χ_{\rm eff}$ shows narrow bands that increase or decrease quadratically with increasing $e_0$, indicating a weak dependence of biases on the three parameters. On the other hand, the biases of $\tildeλ$ are widely distributed depending on the values of the mass and spin parameters at a given $e_0$. We investigate the implications of biased parameters for the inference of neutron star properties by performing Bayesian parameter estimation for specific cases.

</details>


### [252] [Orbital dynamics and spin-precession around a circular chiral vorton](https://arxiv.org/abs/2512.07364)
*S. M. Holme,H. S. Ramadhan,I. Nurul Huda,Leonardus B. Putra*

Main category: gr-qc

TL;DR: 研究手征涡旋环（vorton）的弱场度规下测试粒子的动力学，包括类时和零测地线，发现多种轨道类型和混沌运动，并计算陀螺仪进动频率，这些特征可能为探测涡旋环提供观测途径。


<details>
  <summary>Details</summary>
Motivation: 涡旋环在高能物理中作为可能的暗物质候选者和大统一理论的探针具有重要意义。研究其动力学特征有助于寻找观测这些理论实体的方法。

Method: 使用最近推导的手征涡旋环弱场度规，分析测试粒子的类时和零测地线动力学，通过庞加莱截面研究规则与混沌运动的转变，并计算沿Killing轨迹的陀螺仪的Lense-Thirring和自旋进动频率。

Result: 识别出多种轨道类型：束缚进动轨道、圆形轨道、环面和冠状振荡，以及非束缚散射路径。庞加莱截面显示规则与混沌运动之间的转变对涡旋环张力Gμ和初始条件敏感。进动剖面显示出克尔黑洞中不存在但类似克尔裸奇点的特征：环核附近的发散和多极小值结构。

Conclusion: 这些动力学和进动特征可能为探测涡旋环提供潜在的观测途径，涡旋环的独特特征与克尔黑洞不同，更类似于克尔裸奇点。

Abstract: Vortons are of interest in high-energy physics as possible dark matter candidates and as probes of Grand Unified Theories. Using the recently derived weak-field metric for a chiral vorton, we study the dynamics of test particles by analyzing both timelike and null geodesics. We identify several classes of trajectories, including bound precessing orbits, circular orbits, toroidal, and crown-type oscillations, as well as unbound scattering paths. Poincare surfaces of section reveal transitions between regular and chaotic motions that depend sensitively on the vorton tension $Gμ$ and initial conditions. We further compute the Lense-Thirring and general spin-precession frequencies for gyroscopes along Killing trajectories. The resulting precession profiles exhibit several distinct features not present in Kerr black holes but reminiscent of Kerr naked singularities, such as: divergences near the ring core, and multi-minima structures. These dynamical and precessional signatures may offer potential observational pathways for detecting vortons.

</details>


### [253] [The equation of Binet in classical and relativistic orbital mechanics](https://arxiv.org/abs/2512.07485)
*Jose Luis Alvarez-Perez*

Main category: gr-qc

TL;DR: 本文从自由落体和惯性运动的无穷小位移推导出比奈方程，并首次推导出史瓦西-(反-)德西特度规的相对论版比奈方程，澄清了宇宙常数在光子轨迹中的作用争议。


<details>
  <summary>Details</summary>
Motivation: 本文旨在从基础物理角度重新推导比奈方程，并扩展到广义相对论框架。传统推导通常使用势能或Killing矢量，而本文寻求更直接的几何推导方法，同时澄清宇宙常数在黑洞时空光子轨迹中的争议性作用。

Method: 1. 使用无穷小微积分的基本概念，从自由落体和惯性运动的水平和垂直无穷小位移推导经典比奈方程；2. 首次直接推导史瓦西-(反-)德西特度规的相对论版比奈方程，无需引入势能或使用Killing矢量；3. 分析史瓦西-(反-)德西特和Reissner-Nordström-(反-)德西特时空中宇宙常数对光子轨迹的影响。

Result: 1. 成功从基本物理原理推导出经典比奈方程；2. 首次获得史瓦西-(反-)德西特度规的相对论比奈方程的直接推导；3. 澄清了宇宙常数在黑洞时空光子轨迹中的作用，解决了相关争议。

Conclusion: 本文提供了比奈方程的新推导方法，既包括经典框架的基础推导，也包括广义相对论框架的扩展。新的相对论推导方法更加直接，避免了传统方法的复杂性，同时澄清了宇宙常数在黑洞时空动力学中的确切作用。

Abstract: Binet's equation provides a direct way to obtain the geometric shape of orbits in a central force field. It is well known that in Newtonian gravitation Binet's equation leads to all the conic curves as solutions for an inverse-square force. In this work, we show how Binet's equation arises from the horizontal and vertical infinitesimal displacements of a body in free fall and in inertial motion. This derivation uses elementary concepts of infinitesimal calculus. Second, we derive the relativistic version of Binet's equation for the Schwarzschild-(anti-)de Sitter metric. This derivation, which is novel, directly relates the coordinates involved in Binet's equation without the need to introduce potentials or the use of Killing vectors. Finally, we tackle some controversies related to the role of the cosmological constant in the trajectory of photons in a Schwarzschild-(anti-)de Sitter or even in Reissner-Nordström-(anti-)de Sitter spacetimes.

</details>


### [254] [Asymptotic evolution of bulk-viscous, spherically symmetric spacetimes](https://arxiv.org/abs/2512.07545)
*Balázs Endre Szigeti,Imre Ferenc Barna,Gergely Gábor Barnaföldi*

Main category: gr-qc

TL;DR: 对广义球对称时空中的运动学自相似解进行系统分类，考虑体粘性流的影响


<details>
  <summary>Details</summary>
Motivation: 引力相互作用的无标度性质导致自相似性，但存在仅部分实现自相似的情况，需要研究运动学自相似解

Method: 系统分类最一般球对称时空中的运动学自相似解，考虑体粘性流的存在

Result: 提供了运动学自相似解的分类框架，这些解作为吸引子描述更一般解的渐近动力学

Conclusion: 运动学自相似解在引力理论中具有重要意义，特别是在体粘性流存在的情况下，为理解引力系统的渐近行为提供了重要工具

Abstract: The scale-free nature of gravitational interaction in both Newtonian gravity and the general theory of relativity gives rise to the concept of self-similarity, where solutions are scale invariant. As a result of this property, the governing partial differential equations are greatly simplified and can be transformed into ordinary ones. These solutions function as attractors, characterizing the asymptotic dynamics of more general solutions. There exist situations in which self-similarity is only partially realized, giving rise to kinematic self-similar solutions. Our study provides a systematic classification of kinematic self-similar solutions corresponding to the most general spherically symmetric spacetime in the presence of bulk viscous flows.

</details>


### [255] [Long-wavelength UV-LEDs and charge management in the detection of gravitational waves in space](https://arxiv.org/abs/2512.07546)
*Yuandong Jia,Yinbowen Zhang,Suwen Wang,Guozhi Chai,Zemin Zhang,Yi Zhang,Hongxin Li,Shuanglin Huang,Hongqing Huo,Zongfeng Li,Yun Kau Lau*

Main category: gr-qc

TL;DR: 该研究针对引力波探测任务中的电荷管理系统，采用275nm UV-LED实现最佳性能，能在保持测试质量块电位接近零的同时支持快速放电和连续放电策略。


<details>
  <summary>Details</summary>
Motivation: 引力波探测任务中的电荷管理系统需要平衡充电和放电速率，同时避免频繁激活电荷测量。传统使用255nm波长直接照射测试质量块的方法存在局限性，需要探索更长波长的替代方案。

Method: 采用更复杂的惯性传感器模型，模拟立方体测试质量块的表面特性和功函数（类似LISA Pathfinder）。研究使用269nm、275nm、280nm和295nm四种长于标准255nm波长的UV-LED，研究双极电荷管理系统性能。

Result: 实验结果表明，275nm UV-LED实现最佳性能，能保持测试质量块电位更接近零，同时支持快速放电和连续放电两种策略。

Conclusion: 该研究为未来电荷管理系统的设计和优化提供了有用参考，特别是275nm UV-LED在平衡性能和策略灵活性方面的优势。

Abstract: For the charge management system in gravitational wave detection missions, a continuous discharge strategy is considered by continuously illuminating a test mass (TM) with weak light in such a way to strike a balance between the charging and discharging rates and at the same time avoids the requirement for frequent activation of charge measurements. Built on experiments by one of us based on a simple parallel plate model for inertial sensor, in the present work a more sophisticated inertial sensor model that mimics the surface properties and work function of a cubical TM of an inertial sensor in space (like that of the LISA Pathfinder) is employed to study bipolar charge management system that utilizes UV-LEDs with peak wavelengths of 269 nm, 275 nm, 280 nm, and 295 nm that are longer than the standard 255 nm commonly employed for direct TM illumination. Experimental results indicate that the 275 nm UV-LED achieves optimal performance, maintaining the TM potential closer to zero and at the same time accommodates both rapid discharge and continuous discharge strategies. The present work provides useful input in the future study of system design and optimization for the charge management system.

</details>


### [256] [Chains of rotating boson stars with quartic or sextic self-interaction](https://arxiv.org/abs/2512.07610)
*Hao-Ran Sun,Jing-Kang Bin,Li Zhao*

Main category: gr-qc

TL;DR: 研究爱因斯坦引力中复标量场自相互作用对旋转玻色星链的影响，发现奇偶链数在质量-频率和角动量-频率关系上呈现不同模式，且四阶与六阶相互作用对稳定性的限制不同。


<details>
  <summary>Details</summary>
Motivation: 探索爱因斯坦引力中复标量场自相互作用对旋转玻色星链系统的影响，特别是自相互作用如何改变系统的全局性质和形态特征。

Method: 在爱因斯坦引力耦合复标量场模型中引入四阶或六阶自相互作用，数值构造多组分系统，分析自相互作用对ADM质量、角动量和能层形态的影响。

Result: 发现链的奇偶性导致不同模式：偶数链呈现螺旋曲线，奇数链呈现环状结构；能层随频率增加而合并；四阶相互作用对奇数链存在更严格限制，六阶相互作用允许更强耦合下的稳定解。

Conclusion: 自相互作用类型对旋转玻色星链的稳定性有显著影响，四阶相互作用限制更多，而六阶相互作用允许更广泛的稳定参数空间，奇偶链数在系统行为上表现出根本性差异。

Abstract: This paper investigates chains of rotating boson stars (BSs) within Einstein gravity coupled to a complex scalar field. The model incorporates quartic or sextic self-interactions in the scalar Lagrangian, which support the existence of stationary, solitonic, gravitationally bound solutions. We numerically construct these multi-component systems and investigate how the self-interactions alter their global properties -- specifically the Arnowitt-Deser-Misner (ADM) mass $M$, the angular momentum $J$ and the morphology of their ergospheres. A central result is the distinct dependence of the $(ω, M)$ and $(ω, J)$ relations on the parity of the chains. Specifically, systems with an even number of constituents display spiraling curves, while those with an odd number exhibit loop structures. Moreover, we observe that two initially distinct ergospheres merge into a single one as the frequency $ω$ increases. Our analysis also indicates that the quartic interaction imposes more restrictive existence bounds, particularly for odd-numbered chains, thereby restricting stable configurations to the weak-coupling regime. In contrast, the sextic interaction has a weaker effect and enables stable solutions at substantially stronger couplings.

</details>


### [257] [Black Hole Scattering and Integrability: A Hyperboloidal Approach](https://arxiv.org/abs/2512.07641)
*Corentin Vitel*

Main category: gr-qc

TL;DR: 该论文探讨了Schwarzschild引力背景下散射问题的可积结构，在双曲叶层化方案中通过Lax对构建等谱流，揭示了体-边界结构的半直积作用


<details>
  <summary>Details</summary>
Motivation: 研究Schwarzschild引力背景下散射问题的可积结构，特别是在双曲叶层化方案中，探索非自伴时间生成算子的性质及其与体-边界结构的关系

Method: 采用双曲叶层化方案，构建弱Lax对（在零无穷远条件下有效），推导相关的无限等谱流序列，分析非自伴时间算子的体-边界分解结构

Result: 提出了在特定条件下有效的弱Lax对，构造了相应的无限等谱流序列，揭示了时间算子可分解为体结构和边界结构两部分，为引力动力学提供了半直积作用描述框架

Conclusion: Schwarzschild引力散射问题在双曲叶层化方案中展现出丰富的可积结构，Lax对和等谱流的构建为理解黑洞强引力动力学中的"波-平均流"方法提供了理论基础

Abstract: Integrability structures are known to play a key role in one-dimensional scattering. In the Schwarzschild gravitational context, the analysis emphasizing the role of the so-called Darboux covariance and its intimate connection with KdV conserved quantities was recently introduced by Lenzi & Sopuerta. In a second stage, together with Jaramillo, this led in particular to the identification of the structural role of the "KdV-Virasoro-Schwarzian derivative" triangle in this problem. Such a gravitational scattering description dwells naturally on a Cauchy foliation of the spacetime. In the following, we first review--for the Schwarzschild background--this problem in a hyperboloidal foliation scheme, where the infinitesimal time generator of the dynamics is a non-selfadjoint operator. Then, we explore the underlying integrability features through a Lax-pair formulation. Specifically, the main results presented here are i) the explicit proposal of a weak Lax-pair, valid under suitable conditions involving fields at null infinity, with ii) the construction of the associated infinite sequence of isospectral flows. From a broader perspective, the very form of the non-selfadjoint infinitesimal time operator, which neatly separates into two components corresponding to bulk and boundary structures, paves the way for the description of the gravitational dynamics in terms of a "semi-direct action" of bulk degrees of freedom onto boundary degrees of freedom. This is akin to the "wave-mean flow" approach for black hole strong-gravity dynamics recently proposed in this line of research.

</details>


### [258] [Density contrast in the scalar-tensor extension of non-metricity gravity](https://arxiv.org/abs/2512.07643)
*Ganesh Subramaniam,Avik De,Jackson Levi Said*

Main category: gr-qc

TL;DR: 本文在标量-张量扩展的非度量性引力理论中，首次完整推导了标量宇宙学扰动，获得了有效泊松方程和修正引力常数，并通过数值分析表明该理论与ΛCDM模型有一定可比性。


<details>
  <summary>Details</summary>
Motivation: 先前对对称远平行引力的研究主要关注背景演化或特殊规范选择，而在非最小耦合框架下对标量扰动的完整处理尚未探索。本文旨在填补这一空白，为测试标量非度量性理论提供基础。

Method: 在标量-张量扩展的非度量性引力理论中，推导完整的扰动场方程，施加准静态近似，获得有效泊松方程和修正引力常数G_eff，构建密度对比演化方程，分析物质增长率与增长指数。

Result: 通过数值分析表明，标量非度量性理论在某种程度上与ΛCDM模型可比。研究结果为利用大尺度结构观测测试标量非度量性理论奠定了基础。

Conclusion: 本文首次在非最小耦合的非度量性宇宙学中完成了标量扰动的完整处理，为约束这类理论开辟了新途径，并建立了与观测数据对比的框架。

Abstract: We present a novel derivation of scalar cosmological perturbations in the scalar-tensor extension of non-metricity gravity, where the non-metricity scalar $Q$ is non-minimally coupled to a dynamical scalar field. While previous investigations of symmetric teleparallel gravity focused primarily on background evolution or specialised gauge choices, a complete treatment of scalar perturbations in this non-minimally coupled framework has remained unexplored. In this work, we derive the full set of perturbed field equations, impose the quasi-static approximation, and obtain the effective Poisson equation together with the corresponding modified gravitational constant $G_{\rm eff}$. These ingredients allow us to construct the density contrast evolution equation and analyse the matter growth rate and growth index. Through numerical analysis, we showed that the scalar non-metricity theory is comparable to the well-known $ΛCDM$ model to some extent. The results provide a foundation for testing scalar non-metricity theories against large-scale structure observations and open new avenues for constraining non-minimally coupled non-metricity cosmologies.

</details>


### [259] [Conserved quantities and integrability for massless spinning particles in general relativity](https://arxiv.org/abs/2512.07677)
*Lars Andersson,Finnian Gray,Marius A. Oancea*

Main category: gr-qc

TL;DR: 论文研究了广义相对论中无质量自旋粒子的动力学，推导了与共形Killing-Yano张量相关的广义守恒定律，证明了在D型时空中的可积性。


<details>
  <summary>Details</summary>
Motivation: 研究广义相对论中无质量自旋粒子的动力学，特别是Mathisson-Papapetrou-Dixon方程在无质量情况下的应用，以及这些方程在具有隐藏对称性的时空中的行为。

Method: 使用Mathisson-Papapetrou-Dixon方程框架，考虑具有隐藏对称性的时空，推导与共形Killing-Yano张量相关的广义守恒定律，并分析自旋Hall方程在D型时空中的可积性。

Result: 证明了无质量自旋粒子的自旋Hall方程在一大类D型时空中是完全可积的，并且对于有质量自旋粒子，与Killing-Yano张量相关的广义Carter常数独立于自旋补充条件的选择而守恒。

Conclusion: 在具有隐藏对称性的时空中，无质量自旋粒子的动力学可以通过共形Killing-Yano张量获得广义守恒定律，自旋Hall方程在D型时空中可积，这为理解高能物理中的粒子运动提供了重要理论框架。

Abstract: In general relativity, the dynamics of spinning particles is governed by the Mathisson-Papapetrou-Dixon equations, which are most commonly applied to massive bodies, but the framework also works in the massless case. Such massless versions naturally arise, for example, in the description of energy centroids of high-frequency wave packets. In this work, we consider massless spinning particles in spacetimes with hidden symmetries and we derive the generalized conservation laws associated with conformal Killing-Yano tensors. We then show that the spin Hall equations, a particular case of the Mathisson-Papapetrou-Dixon equations restricted to massless particles with longitudinal angular momentum, are completely integrable in a large class of type D spacetimes. Additionally, we also show that for massive spinning particles, the generalized Carter constant associated with Killing-Yano tensors is conserved independently of the choice of spin supplementary condition.

</details>


### [260] [Bianchi Cosmologies in a Thurston-Based Theory of Gravity](https://arxiv.org/abs/2512.07708)
*Quentin Vigneron,Hamed Barzegar*

Main category: gr-qc

TL;DR: 该论文研究了依赖于Thurston几何的引力理论中的Bianchi-Kantowski-Sachs时空解，证明了在正宇宙常数下所有BKS度量都会各向同性化，且弱能量条件满足时不会发生再坍缩，这与广义相对论形成对比。


<details>
  <summary>Details</summary>
Motivation: 探索拓扑结构在理解引力中的作用，特别是Bianchi-Kantowski-Sachs时空与Thurston几何之间的强相互作用，研究依赖于Thurston几何的引力理论中的非倾斜BKS解。

Method: 研究依赖于Thurston几何的引力理论中的非倾斜Bianchi-Kantowski-Sachs解，分析剪切自由完美流体解和静态真空解的存在性，并证明在正宇宙常数下的各向同性化性质。

Result: 1. 所有拓扑结构都存在剪切自由完美流体解和静态真空解；2. 除非旋转对称Bianchi II模型外，所有BKS度量在正宇宙常数下都会各向同性化；3. 弱能量条件满足时不会发生再坍缩；4. 这些结果不需要比广义相对论更多的参数。

Conclusion: 该框架为在任何拓扑结构中构建简单的暴胀模型提供了可能，与广义相对论相比，在正宇宙常数下表现出更好的各向同性化行为，且避免了再坍缩问题。

Abstract: The strong interplay between Bianchi--Kantowski--Sachs (BKS) spacetimes and Thurston geometries motivates the exploration of the role of topology in our understanding of gravity. As such, we study non-tilted BKS solutions of a theory of gravity that explicitly depends on Thurston geometries. We show that shear-free solutions with perfect fluid, as well as static vacuum solutions, exist for all topologies. Moreover, we prove that, aside from non-rotationally-symmetric Bianchi II models, all BKS metrics isotropize in the presence of a positive cosmological constant, and that recollapse is never possible when the weak energy condition is satisfied. This contrasts with General Relativity (GR), where these two properties fail for Bianchi IX and KS metrics. No additional parameters compared to GR are required for these results. We discuss, in particular, how this framework might allow for simple inflationary models in any topology.

</details>


### [261] [Thermodynamic Phase Transitions and Quantum Entropy Corrections in the Simpson-Visser Regular Black Hole](https://arxiv.org/abs/2512.07786)
*Vinayak Joshi,Ashok B. Joshi*

Main category: gr-qc

TL;DR: 论文研究了正则黑洞的热力学行为，发现其存在临界不稳定性相变，并推导了熵的量子修正，揭示了奇点消除不仅是几何修正，更是深刻的热力学事件。


<details>
  <summary>Details</summary>
Motivation: 正则黑洞为解决标准黑洞中心奇点问题提供了一个有吸引力的框架。研究者希望探索这类非奇异时空的热力学行为，特别是奇点消除如何影响黑洞的稳定性和最终命运。

Method: 使用Simpson-Visser的"black-bounce"几何作为分析可处理的框架，研究正则时空的热力学行为。通过热容量分析识别相变，并利用Hamilton-Jacobi隧穿形式推导熵的量子修正。

Result: 发现正则时空存在临界不稳定性，表现为热容量不连续的相变，标志着黑洞蒸发状态的根本变化。推导了熵的量子修正，为非奇异时空的熵提供了更精细的统计基础。

Conclusion: 奇点消除不仅是几何修正，更是深刻的热力学事件，直接影响蒸发黑洞的稳定性和最终命运。研究结果为理解黑洞末态提供了定量分析。

Abstract: Regular black holes offer a compelling framework to explore the consequences of resolving the central singularity of standard black holes. Using the Simpson-Visser "black-bounce" geometry as an elegant, analytically tractable framework, we explore the intricate thermodynamic behavior in such models. We demonstrate that this regular spacetime exhibits a critical instability, marked by a phase transition where the heat capacity is discontinuous. This transition signals a fundamental change in the black hole's evaporation state, which depends on the regularization parameter. Pushing beyond the semiclassical limit, we then derive the leading-order quantum corrections to the entropy via the Hamilton-Jacobi tunneling formalism. Our analysis provides a refined statistical basis for the entropy of non-singular spacetimes and offers a quantitative analysis of the nature of the black hole end-state. These results reveal that singularity resolution is not merely a geometric modification but a profound thermodynamic event, with direct implications for the stability and ultimate fate of evaporating black holes.

</details>


### [262] [The holographic origin of future singularities and the role of spatial curvature in cosmic expansion](https://arxiv.org/abs/2512.07791)
*Miguel Cruz,Samuel Lepe,Joel Saavedra*

Main category: gr-qc

TL;DR: 研究全息暗能量在Granda-Oliveros红外截断和Kaniadakis熵修正下的宇宙学影响，发现GO模型导致大撕裂奇点，而Kaniadakis修正将其软化为小撕裂奇点。


<details>
  <summary>Details</summary>
Motivation: 探索全息暗能量在不同红外截断模型和熵修正下的宇宙学行为，特别是研究空间曲率和熵修正如何影响宇宙的最终命运和奇点类型。

Method: 采用Granda-Oliveros模型定义红外截断，并引入Kaniadakis统计中的广义熵-面积关系，分析平直和弯曲宇宙中的全息暗能量演化。

Result: GO模型下平直宇宙必然演化至大撕裂奇点；正曲率加速奇点形成，负曲率引起状态转变。Kaniadakis修正后出现稳定de Sitter临界点并演化至小撕裂奇点，空间曲率仅定量影响而不改变奇点类型。

Conclusion: 全息宇宙学的渐近命运对熵-面积关系高度敏感：GO模型预测大撕裂奇点，而Kaniadakis修正将其软化为小撕裂奇点，即使在弯曲宇宙中也是如此。

Abstract: In this work, we investigate the cosmological implications of holographic dark energy (HDE) when the infrared cutoff is defined through the Granda-Oliveros (GO) model and the entropy-area is generalized in the context of Kaniadakis statistics. For the GO model, we showed that a spatially flat universe inevitably evolves toward a big rip singularity. At the same time, the inclusion of spatial curvature modifies the expansion rate without removing the finite-time divergence: positive curvature speeds up the formation of the singularity, whereas negative curvature induces transitions between quintessence, de Sitter, and phantom-like regimes. When Kaniadakis entropy corrections are incorporated, the qualitative behavior changes substantially. The modified HDE density admits a stable de Sitter critical point and evolves toward a little rip singularity, in which the Hubble rate diverges only at infinite cosmic time. We further demonstrate that spatial curvature acts solely as a quantitative deformation in this scenario. Although it alters the detailed expansion history, it does not alter the little-rip character of the future singularity. Our results reveal that the asymptotic fate of holographic cosmologies is highly sensitive to the underlying entropy-area relation: the GO model robustly predicts a big rip. At the same time, its Kaniadakis deformation consistently softens the singularity into a little rip, even in curved universes.

</details>


### [263] [Caustics in the spherically symmetric Einstein-dust system](https://arxiv.org/abs/2512.07812)
*David Bick*

Main category: gr-qc

TL;DR: 本文研究了爱因斯坦-尘埃系统中壳交叉奇点附近的动力学，建立了包含焦散线的局部存在性结果，构造了球对称时空，其中焦散线作为2-尘埃区域与真空区域的奇异边界。


<details>
  <summary>Details</summary>
Motivation: 研究爱因斯坦-尘埃系统中壳交叉奇点（焦散线）附近的动力学行为，这些焦散线在流体粒子轨迹中形成，是理解广义相对论中奇异结构的重要问题。

Method: 通过求解具有类空演化方向的PDE问题，构造包含焦散线的球对称时空，证明度规具有有限正则性（C^{1,1/2}），并满足弱形式的爱因斯坦方程。

Result: 建立了焦散线附近的局部存在性定理，构造了球对称时空，其中焦散线是2-尘埃区域与真空区域的奇异边界；曲率不变量和能量密度在接近焦散线时发散；度规满足弱爱因斯坦方程；识别了新的静态球对称时空族。

Conclusion: 成功描述了爱因斯坦-尘埃系统中焦散线附近的动力学，建立了局部存在性结果，构造了具有有限正则性的度规解，并发现了新的静态时空族，为理解壳交叉奇点提供了数学框架。

Abstract: Caustics-envelopes formed by the trajectories of fluid particles-arise in proposed dynamical extensions for shell-crossing singularities occurring in the Einstein-dust system. In this study, a local existence result is established, describing the dynamics in a neighbourhood of such caustics. Specifically, we obtain spherically symmetric spacetimes $(M,g_{μν})$ containing a caustic $\mathcal{C}$, which, in the quotient $M/SO(3)$, is a timelike curve forming a singular boundary between a 2-dust region and a vacuum region. The spacetimes are constructed from solutions to a PDE problem posed with a spacelike direction of evolution. Curvature invariants and energy densities diverge as the caustic is approached. Consequently the metric has limited regularity $g\in C^{1,1/2}$ and is shown to satisfy Einstein's equation weakly. On the complement of the caustic, the metric is smooth and satisfies Einstein's equation classically. A (degenerate) coordinate system is identified in which the dynamical variables are smooth with extension to the caustic. Finally, a novel family of static, spherically symmetric spacetimes is identified, complementing the local construction above. Each spacetime contains an eternal annular 2-dust region bounded by a pair of caustics.

</details>


### [264] [Novel thermodynamic inequality for charged and rotating AdS black holes](https://arxiv.org/abs/2512.07825)
*Hamid R. Bakhtiarizadeh*

Main category: gr-qc

TL;DR: 提出了一个新的热力学不等式 $4πJ^2/(3MV)<1$，适用于稳态渐近AdS带电旋转黑洞，通过分析热力学变量关系避免裸奇点，验证了传统形式($\mathcal{R}\geq 1$)的反等周不等式在旋转情况下的有效性。


<details>
  <summary>Details</summary>
Motivation: 研究稳态渐近AdS带电旋转黑洞的热力学性质，建立避免裸奇点的热力学约束条件，验证反等周不等式在旋转黑洞情况下的有效性。

Method: 通过分析热力学变量之间的恒等式根来推导不等式，检验Kerr-AdS黑洞和渐近AdS不带电旋转黑洞弦，研究不同视界拓扑结构，并利用中间精化反等周不等式将结果推广到高维时空。

Result: 提出了新的热力学不等式 $4πJ^2/(3MV)<1$，验证了该不等式在多种黑洞解中的有效性，确认了传统形式反等周不等式($\mathcal{R}\geq 1$)在旋转情况下的正确性，并将结果扩展到高维时空。

Conclusion: 成功建立了适用于稳态渐近AdS带电旋转黑洞的新热力学不等式，为黑洞热力学提供了新的约束条件，支持了反等周不等式在更广泛情况下的有效性，并将结果推广到高维情况。

Abstract: We propose a new thermodynamic inequality for stationary and asymptotically Anti-de Sitter charged and rotating black holes, $ 4πJ^2/(3MV)<1 $. This inequality is derived through an analysis of the roots of the identity which holds among the thermodynamic variables to avoid a naked singularity. We have analyzed the Kerr-AdS black hole and the asymptotically AdS uncharged and rotating black strings and find strong supporting evidence for different horizon topologies. Using this inequality we verify the validity of reverse isoperimetric inequality in its conventional form ($ {\cal R}\geq 1 $) in the presence of rotation. By examining a wide range of black hole solutions, we confirm the validity of the proposed inequality. Assuming that reverse isoperimetric inequality continues to hold in higher dimensions, and employing the intermediate refined reverse isoperimetric inequalities introduced in [\href{https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.131.241401}{Phys. Rev. Lett. {\bf 131}, 241401}] as guiding principles, we extend the inequality to higher-dimensional spacetimes.

</details>
