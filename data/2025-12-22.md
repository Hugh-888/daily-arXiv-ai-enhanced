<div id=toc></div>

# Table of Contents

- [quant-ph](#quant-ph) [Total: 48]
- [gr-qc](#gr-qc) [Total: 22]
- [cs.LG](#cs.LG) [Total: 67]
- [physics.comp-ph](#physics.comp-ph) [Total: 3]


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [1] [Bundling of bipartite entanglement](https://arxiv.org/abs/2512.16979)
*Maike Drieb-Schoen,Florian Dreier,Wolfgang Lechner*

Main category: quant-ph

TL;DR: 论文研究了约束能量子空间中的二分纠缠，证明了多个二分划分的纠缠谱在整个子空间中相同，并展示了纠缠熵在幺正演化下形成"束"结构。


<details>
  <summary>Details</summary>
Motivation: 研究量子多体系统中约束能量子空间内的纠缠特性，探索不同二分划分下纠缠谱的普遍性关系，为理解复杂量子系统中的纠缠结构提供新视角。

Method: 利用约束能量子空间的结构特性，提出验证两个二分划分纠缠谱是否在整个子空间中相同的方法；针对宇称嵌入定义的子空间，进一步提供多项式时间算法来确定这种关系。

Result: 证明了在约束能量子空间中，多个二分划分的纠缠谱在整个子空间中相同；展示了量子多体系统中二分纠缠熵在幺正时间演化下形成"束"结构；开发了验证纠缠谱相同性的方法和多项式时间算法。

Conclusion: 约束能量子空间中的二分纠缠具有特殊的普遍性结构，不同二分划分的纠缠谱在整个子空间中保持一致，这为量子纠缠的理论研究和实际应用提供了新的理论基础和计算工具。

Abstract: We investigate bipartite entanglement and prove that in constrained energy subspaces, the entanglement spectra of multiple bipartitions are the same across the whole subspace. We show that in quantum many-body systems the bipartite entanglement entropy is affected in such a way that it forms "bundles" under unitary time evolution. Leveraging the structure of the subspace, we present methods to verify whether the entanglement spectrum of two bipartitions is identical throughout the entire subspace. For the subspace defined by the parity embedding, we further provide an algorithm that can determine this in polynomial time.

</details>


### [2] [Subsystems (in)dependence in GIE proposals](https://arxiv.org/abs/2512.17024)
*Nicolas Boulle,Guilherme Franzmann*

Main category: quant-ph

TL;DR: 该论文分析了引力诱导纠缠实验中子系统独立性的理论问题，指出在规范约束和引力修饰下，子系统独立性并非平凡，这会影响量子引力实验的解释和设计。


<details>
  <summary>Details</summary>
Motivation: 最近提出的引力诱导纠缠实验被认为是验证引力量子性质的关键，但这些实验依赖于子系统独立性的假设。论文旨在通过代数量子场论框架，澄清这些理论基础问题。

Method: 使用代数量子场论分析子系统独立性，区分操作性和代数独立性概念。研究引力修饰场如何影响类空间隔可观测量之间的对易关系，并探讨当子系统代数不对易时对纠缠见证的影响。

Result: 发现即使在线性化协变量子引力中，微观因果性的违反也会影响量子引力实验的解释和建模。引力修饰会导致微观因果性违反，这本身可以作为探测引力量子性质的新途径。

Conclusion: 引力诱导纠缠实验中的子系统独立性问题是低能（微扰）量子引力中的普遍问题。论文建议将束缚修饰诱导的微观因果性违反作为探测引力量子性质的补充途径。

Abstract: Recent proposals suggest that detecting entanglement between two spatially superposed masses would establish the quantum nature of gravity. However, these gravitationally induced entanglement (GIE) experiments rely on assumptions about subsystem independence. We sharpen the theoretical underpinnings of such proposals by examining them through the lens of algebraic quantum field theory (AQFT), distinguishing distinct operational and algebraic notions of independence. We argue that state and measurement independence of subsystems, essential to the experimental logic, is nontrivial in the presence of gauge constraints and gravitational dressing. Using gravitationally dressed fields, we recall that commutation relations between spacelike separated observables are nontrivial, undermining strict Hilbert space factorization. We further explore the implications for entanglement witnesses, investigating the Tsirelson bound when subsystem algebras fail to commute, and showing that the Tsirelson bound persists for a suitably symmetrized CHSH observable even though the operational status of such "joint" observables becomes delicate when commensurability fails. Our analysis highlights how even within linearized covariant quantum gravity, violations of microcausality may affect both the interpretation, modelling, and design of proposed laboratory tests of quantum gravity, despite remaining negligible for current experimental regimes. Although we consider GIE-style protocols as a concrete case study, the subsystem-independence issues we highlight are generic to low-energy (perturbative) quantum gravity. Finally, we derive estimates for dressing-induced microcausality violations, which suggest a complementary avenue to current proposals: in principle, bounding dressing-induced microcausality violations themselves as a probe of the quantum nature of gravity.

</details>


### [3] [Comparing Homodyne and Heterodyne Tomography of Quantum States of Light](https://arxiv.org/abs/2512.17031)
*Rhea P. Fernandes,Andrew J. Pizzimenti,Christos N. Gagatsos,Joseph M. Lukens*

Main category: quant-ph

TL;DR: 本文比较了零差与外差测量在重构非高斯量子态时的相对效率，发现零差层析在所有测试的非高斯态中都优于外差测量，但两者差距比渐近Cramer-Rao下界预测的要小。


<details>
  <summary>Details</summary>
Motivation: 非高斯量子态是光子量子信息处理的关键资源，其生成和表征在量子光学中日益重要。零差与外差测量在连续变量层析中哪个更高效重构非高斯态是一个重要但尚未解决的问题。

Method: 结合基于Fisher信息的形式化方法与模拟实验，理论分析和数值比较了零差与外差测量在重构非高斯量子态时的效率。

Result: 研究发现零差层析在所有测试的非高斯态中都优于外差测量，但两种测量方式之间的差距显著小于渐近Cramer-Rao下界所预测的程度。

Conclusion: 研究结果对于优化实际连续变量量子系统中的测量策略具有实用价值，为零差测量在非高斯态重构中的优势提供了理论支持。

Abstract: Non-Gaussian quantum states are critical resources in photonic quantum information processing, rendering their generation and characterization of increasing importance in quantum optics. In this work, we theoretically and numerically analyze the relative efficiency of homodyne versus heterodyne measurements for reconstructing non-Gaussian states, a major outstanding question in continuous-variable tomography. Combining a Fisher information-based formalism with simulated experiments, we find homodyne tomography to outperform heterodyne measurements for all non-Gaussian states tested, although the separation between the two modalities proves significantly narrower than suggested by the asymptotic Cramer-Rao lower bound. Our results should find use for optimizing measurement strategies in practical continuous-variable quantum systems.

</details>


### [4] [Attosecond Control of Squeezed Light](https://arxiv.org/abs/2512.17046)
*Russell Zimmerman,Shashank Kumar,Shiva Kant Tiwari,Eric Liu,Francis Walz,Siddhant Pandey,George J. Economou,Hadiseh Alaeian,Chen-Ting Liao,Valentin Walther,Niranjan Shivaram*

Main category: quant-ph

TL;DR: 研究人员通过强超快激光场调制电介质的三阶非线性响应，实现了在阿秒时间尺度上控制压缩光的类型（振幅压缩到相位压缩），并利用频率分辨平衡零差探测测量了量子噪声压缩。


<details>
  <summary>Details</summary>
Motivation: 压缩光在量子计量学和量子信息科学中具有重要应用，但传统方法主要通过材料工程调节非线性来产生压缩光，缺乏对压缩类型的快速动态控制。本研究旨在实现阿秒时间尺度上对压缩光类型的主动控制。

Method: 使用强超快激光场调制电介质的三阶非线性响应，通过控制输入飞秒激光脉冲之间的亚周期相位延迟来调节压缩类型。采用频率分辨平衡零差探测方案同时提取不同频率模式下的场正交分量，获得完整的相干矩阵。

Result: 成功实现了从振幅压缩到相位压缩的转换控制，测量了飞秒压缩光脉冲中不同频率模式间场正交分量的量子相关性，获得了包含跨频率量子关联的完整相干矩阵。

Conclusion: 该方法为开发具有前所未有的正交压缩控制能力的量子光源开辟了新途径，对多模量子信息处理和通过超快光-物质相互作用测量瞬态量子物质相关性具有重要意义。

Abstract: Squeezed light has revolutionized quantum metrology by enhancing interferometry for sensitive applications such as the detection of gravitational waves. Squeezed light has also played a pivotal role in quantum information science with numerous applications in quantum computing and communication. Previously, squeezed light has been primarily generated using nonlinear optical interactions, where control of the degree of squeezing was possible by tuning the nonlinearity of the generating medium using suitable material engineering. Here, we modulate the third-order nonlinear response in dielectrics with strong ultrafast laser fields to control the degree of squeezing on attosecond time scales. We demonstrate the ability to change the ultrafast squeezed light generated in the nonlinear process from amplitude-squeezed to phase-squeezed by controlling the strong-field-driven nonlinear response of the material through a sub-cycle phase delay between the input femtosecond laser pulses. The squeezing of quantum noise is measured using a frequency-resolved balanced homodyne detection scheme capable of extracting the field quadratures in different frequency modes simultaneously. Using this frequency-resolved measurement we extract the complete coherency matrix containing the quantum correlations between field quadratures across different frequency modes of the femtosecond squeezed light pulse. These results have major implications for the development of quantum light sources with unprecedented levels of control over quadrature squeezing, for applications in multimode quantum information processing, and for measuring transient quantum matter correlations via transduction to quantum field correlations in an ultrafast light-matter interaction.

</details>


### [5] [Molecular Quantum Computations on a Protein](https://arxiv.org/abs/2512.17130)
*Akhil Shajan,Danil Kaliakin,Fangchun Liang,Thaddeus Pellegrini,Hakan Doga,Subhamoy Bhowmik,Susanta Das,Antonio Mezzacapo,Mario Motta,Kenneth M. Merz*

Main category: quant-ph

TL;DR: 该研究实现了一种基于片段、量子中心的高性能计算工作流，用于使用量子硬件计算分子电子结构，并将其应用于预测300原子Trp-cage小蛋白两种构象的相对能量。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够处理大型蛋白质系统（包含数百甚至数千个原子）电子结构计算的工作流，通过结合量子计算和经典计算资源，实现大规模电子构型相互作用（CI）模拟。

Method: 采用基于波函数的嵌入（EWF）作为基础碎片化框架，所有原子都明确包含在CI处理中。对单个碎片使用样本基量子对角化（SQD）处理挑战性碎片，使用完全构型相互作用（FCI）处理简单碎片。

Result: 通过将EWF-(FCI,SQD)结果与EWF-MP2和EWF-CCSD基准进行比较，评估了SQD在碎片CI计算中的准确性，证明了该方法能够有效预测蛋白质系统的相对能量。

Conclusion: 研究表明，通过量子计算和经典计算资源的结合使用，可以实现包含数百甚至数千个原子的大型蛋白质系统的大规模电子构型相互作用模拟。

Abstract: This work presents the implementation of a fragment-based, quantum-centric supercomputing workflow for computing molecular electronic structure using quantum hardware. The workflow is applied to predict the relative energies of two conformers of the 300-atom Trp-cage miniprotein. The methodology employs wave function-based embedding (EWF) as the underlying fragmentation framework, in which all atoms in the system are explicitly included in the CI treatment. CI calculations for individual fragments are performed using either sample-based quantum diagonalization (SQD) for challenging fragments or full configuration interaction (FCI) for trivial fragments. To assess the accuracy of SQD for fragment CI calculations, EWF-(FCI,SQD) results are compared against EWF-MP2 and EWF-CCSD benchmarks. Overall, the results demonstrate that large-scale electronic configuration interaction (CI) simulations of protein systems containing hundreds or even thousands of atoms can be realized through the combined use of quantum and classical computing resources.

</details>


### [6] [Evaluating Sample-Based Krylov Quantum Diagonalization for Heisenberg Models with Applications to Materials Science](https://arxiv.org/abs/2512.17141)
*Roman Firt,Neel Misciasci,Jonathan E. Mueller,Triet Friedhoff,Chinonso Onah,Aaron Schulze,Sarah Mostame*

Main category: quant-ph

TL;DR: SKQD算法在Heisenberg模型上表现良好，能准确计算基态能量和磁化曲线，在量子硬件上成功实现18和30量子比特系统


<details>
  <summary>Details</summary>
Motivation: 评估SKQD算法在强关联Heisenberg模型上的性能，特别是在基态密集的困难区域，并验证其在量子硬件上的可行性

Method: 使用基于样本的Krylov量子对角化算法，结合问题相关的初始态和磁化扇区扫描，在一维和二维Heisenberg模型上进行测试

Result: SKQD能准确重现基态能量和场依赖的磁化曲线，与DMRG和精确对角化结果定性一致，在更各向异性区域精度系统性提高；在量子硬件上成功实现18和30量子比特链

Conclusion: SKQD算法在Heisenberg模型上表现有效，适用于一维和二维几何结构，在量子硬件上具有实现潜力

Abstract: We evaluate the Sample-based Krylov Quantum Diagonalization (SKQD) algorithm on one- and two-dimensional Heisenberg models, including strongly correlated regimes in which the ground state is dense. Using problem-informed initial states and magnetization-sector sweeps, SKQD accurately reproduces ground-state energies and field-dependent magnetization across a range of anisotropies. Benchmarks against DMRG and exact diagonalization show consistent qualitative agreement, with accuracy improving systematically in more anisotropic regimes. We further demonstrate SKQD on quantum hardware by implementing 18- and 30-qubit Heisenberg chains, obtaining magnetization curves that match theoretical expectations. Simulations on small 2D square-lattice systems further demonstrate that the method applies effectively beyond 1D geometries.

</details>


### [7] [fractional-time deformation of quantum coherence in open systems: a non-markovian framework beyond lindblad dynamics](https://arxiv.org/abs/2512.17144)
*Taylan Demir*

Main category: quant-ph

TL;DR: 提出量子主方程的时间分数阶扩展，引入Caputo型分数阶导数，将分数阶导数融入Lindblad框架，自然产生长记忆相干衰减，为非马尔可夫性提供可解释的灵活模型。


<details>
  <summary>Details</summary>
Motivation: 传统Lindblad框架中的指数衰减无法描述长记忆相干衰减等非马尔可夫现象，需要扩展量子主方程以更好地建模非马尔可夫动力学。

Method: 提出量子主方程的时间分数阶扩展，引入Caputo型分数阶导数，将分数阶导数融入Lindblad框架，建立分数阶量子主方程模型。

Result: 分析和数值结果表明，分数阶动力学自然产生长记忆相干衰减，为非马尔可夫性提供了可解释且灵活的模型。

Conclusion: 分数阶量子主方程扩展了传统Lindblad框架，能够自然描述非马尔可夫动力学中的长记忆效应，为量子开放系统提供了更强大的建模工具。

Abstract: In this paper, we propose a fractional time extension of the Quan tum Master Equation. We introduce a Caputo-type fractional derivative in time as an extension of the exponential decay of the Lindblad framework through the incorporation of fractional derivatives into the Lindblad framework. We show that the analytical and numerical results of our analytical and numerical models, demonstrate that fractional dynamics produces long-memory coherence decay naturally and provides an interpretable and flexible model of non-Markovianity.

</details>


### [8] [Zero-added-loss entanglement multiplexing using time-bin spectral shearing](https://arxiv.org/abs/2512.17148)
*Joseph C. Chapman,Muneer Alshowkan,Jack Postlewaite,Saikat Guha,Nageswara Rao*

Main category: quant-ph

TL;DR: 提出一种基于时间纠缠和频谱剪切技术的零附加损耗复用光源设计，优化频谱复用参数，实验验证时间脉冲与频谱剪切的兼容性


<details>
  <summary>Details</summary>
Motivation: 为实现量子中继器所需的高质量量子通信，需要高保真度的纠缠源。Chen等人提出的零附加损耗复用方案能产生准确定性纠缠光子对，本文旨在将该方案扩展到时间纠缠应用场景

Method: 设计基于时间纠缠和频谱剪切的ZALM光源；分析实验相关的频谱剪切参数以优化频谱复用；实验验证时间脉冲与频谱剪切的兼容性

Result: 成功验证了时间脉冲与频谱剪切的兼容性，观察到对两个时间仓施加相同剪切时无相位偏移；为时间纠缠应用扩展了ZALM光源的优势

Conclusion: 时间纠缠与频谱剪切的兼容性验证为频谱剪切的广泛应用铺平了道路，该技术能提供高实用性的确定性频率偏移，有望促进量子中继器的发展

Abstract: High-quality quantum communications that enable important capabilities, such as distributed quantum computing and sensing, will require quantum repeaters for providing high-quality entanglement. To realize high-rate heralded entanglement for quantum repeaters, Chen et al. [Phys. Rev. Appl. 19, 054209 (2023)] proposed a scheme for heralded-multiplexed generation of quasi-deterministic entangled photon pairs, called zero-added-loss multiplexing (ZALM). Here, we propose a design of ZALM source using time-bin entanglement and spectral shearing. Additionally, we provide an analysis of experimentally relevant spectral-shearing parameters to optimize the spectral multiplexing. Moreover, we experimentally verify the compatibility of time-bin pulses and spectral shearing, as supported by observation of no phase shift when the same shearing is applied to both time bins. These results expand the benefits of applying a ZALM source to time-bin entanglement use cases. Moreover, more fully demonstrating time-bin and spectral shearing compatibility clears a path towards a broader use of spectral shearing that provides a deterministic frequency shift of high utility.

</details>


### [9] [Witnessing Entanglement in Mixed-Particle Quantum Systems](https://arxiv.org/abs/2512.17860)
*Irma Avdic,David A. Mazziotti*

Main category: quant-ph

TL;DR: 该论文提出了一种纠缠见证方法，用于检测混合粒子系统中费米子和玻色子的非对角长程序，量化各粒子类型的纠缠贡献，并揭示跨粒子类型的集体纠缠形成。


<details>
  <summary>Details</summary>
Motivation: 在同时包含费米子和玻色子的混合粒子系统中，需要一种能够检测和量化两种粒子类型纠缠的方法。现有方法难以独立分析费米子和玻色子子系统中的非对角长程序，也无法揭示它们如何共同形成系统的总纠缠。

Method: 通过分析每个子系统的粒子-空穴约化密度矩阵，提出一种纠缠见证方法。该方法能够独立检测费米子和玻色子子系统中的非对角长程序，并识别整个混合粒子系统中长程序的发展。同时量化各粒子类型中非对角长程序的幅度。

Result: 该方法成功检测到混合粒子系统中的非对角长程序，揭示了费米子和玻色子关联如何结合形成系统总纠缠。特别发现了由多体关联而非粒子统计驱动的粒子-空穴对玻色凝聚现象。使用Lipkin-Meshkov-Glick自旋模型展示了从单一粒子类型局域化非对角长程序到两种粒子类型共享非对角长程序的转变。

Conclusion: 该纠缠见证方法为分析混合粒子系统中的纠缠提供了新工具，能够独立量化费米子和玻色子贡献，揭示集体纠缠的形成机制。为费米子和玻色子关联共存的系统提供了新的理论洞察。

Abstract: We introduce an entanglement witness that identifies off-diagonal long-range order (ODLRO) -- a distinctive form of entanglement -- in systems containing both fermionic and bosonic particles. By analyzing the particle-hole reduced density matrices of each subsystem, the approach detects ODLRO independently in both fermionic and bosonic sectors and identifies when long-range order develops across the entire mixed-particle system. The witness also quantifies the magnitude of ODLRO within each particle type, revealing how fermionic and bosonic correlations combine to form the total entanglement of the system, including a bosonic condensation of particle-hole pairs driven by many-body correlations rather than particle statistics. Using the Lipkin-Meshkov-Glick spin model, we show how the transition from ODLRO localized to one particle type to ODLRO shared by both particle types captures the onset of collective entanglement in a mixed-particle environment, providing new insight into systems where fermionic and bosonic correlations coexist.

</details>


### [10] [On-Demand Millisecond Storage of Spectro-Temporal Multimode Telecom Photons](https://arxiv.org/abs/2512.17181)
*Anuj Sethia,Nasser Gohari Kamel,Daniel Oblak*

Main category: quant-ph

TL;DR: 实验演示了基于Er³⁺:Y₂SiO₅晶体的电信波长量子存储器，实现了1ms存储时间、10.36%效率和20个时域+3个频域模式的多模容量


<details>
  <summary>Details</summary>
Motivation: 构建可扩展的量子网络需要量子中继器来克服光纤中的指数传输损耗，而量子中继器需要具有长存储时间和大多模容量的高效量子存储器

Method: 使用Er³⁺:Y₂SiO₅晶体构建电信波长量子存储器，采用单光子探测器测量弱相干脉冲的按需存储和读取性能

Result: 实现了1ms的存储时间（超过以往Er³⁺基存储器），300μs时效率达10.36%，信噪比10.9，同时存储20个时域和3个频域模式

Conclusion: 该存储器具有长存储时间、高效率和大多模容量，为可扩展量子中继器架构提供了关键组件

Abstract: The realization of scalable quantum networks for distribution of entanglement over long distances hinges on quantum repeaters. To outperform the exponential transmission loss in optical fibers, quantum repeaters must employ multiplexing schemes in the temporal, spectral, or spatial domain. The performance of such a multiplexed scheme is contingent on efficient quantum memories offering both extended storage times and large multimode capacities. In this work, we experimentally demonstrate such a memory operating at telecom wavelength using an Er$^{3+}$:Y$_{2}$SiO$_{5}$ crystal. Using single-photon detectors, we record on-demand storage and recall of weak coherent pulses for up to $1$ ms, exceeding that of previously reported quantum memories based on Er$^{3+}$. The memory exhibits an efficiency of 10.36\% at 300 $μ$s storage time with a signal-to-noise ratio of $10.9$. We further showcase its multimode capacity by storing 20 temporal and 3 spectral modes simultaneously with on-demand and selective recall capabilities, essential for a scalable quantum repeater architecture.

</details>


### [11] [Quantum-enhanced Information Retrieval from Reflective Intelligent Surfaces](https://arxiv.org/abs/2512.17199)
*Shiqian Guo,Tingxiang Ji,Jianqing Liu*

Main category: quant-ph

TL;DR: 提出一种结合时间分辨量子接收器和多模探测信号的新方法，用于从被动可重构智能表面提取大字母信息，在无需复杂量子资源的情况下实现超越经典极限的性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统被动反向散射系统受经典无线接收器基本限制，无法在不牺牲能效或通信距离的情况下提高数据速率，这阻碍了该技术的广泛应用。

Method: 采用时间分辨量子接收器结合多模探测信号，通过自适应接收机制从被动可重构智能表面提取大字母调制信息，无需依赖纠缠等复杂量子资源。

Result: 仿真结果显示，该方法在调制尺寸高达M=2^8时超越了经典标准量子极限，同时将探测能量减半或将通信距离提高1.41倍。

Conclusion: 提出的量子接收器技术为被动反向散射系统提供了显著的量子优势，有望推动该技术在能量受限应用中的更广泛采用。

Abstract: Information retrieval from passive backscatter systems is widely used in digital applications with tight energy budgets, short communication distances, and low data rates. Due to the fundamental limits of classical wireless receivers, the achievable data rate cannot be increased without compromising either energy efficiency or communication range, thereby hindering the broader adoption of this technology. In this work, we present a novel time-resolving quantum receiver combined with a multi-mode probing signal to extract large-alphabet information modulated by a passive reconfigurable intelligent surface (RIS). The adaptive nature of the proposed receiver yields significant quantum advantages over classical receivers without relying on complex or fragile quantum resources such as entanglement. Simulation results show that the proposed technique surpasses the classical standard quantum limit (SQL) for modulation sizes up to M = 2^8, meanwhile halving the probing energy or increasing the communication distance by a factor of 1.41.

</details>


### [12] [Bound states and decay dynamics in $N$-level Friedrichs model with factorizable interactions](https://arxiv.org/abs/2512.17207)
*Jia-Ming Zhang,Yu Xin,Bing Chen*

Main category: quant-ph

TL;DR: 本文通过投影算符形式推导了单激发Friedrichs模型中N能级系统与连续谱相互作用的解析表达式，建立了确定束缚态数量的明确判据，并推导了开放系统的耗散动力学。


<details>
  <summary>Details</summary>
Motivation: 研究N能级系统与连续谱的因子化相互作用，旨在理解束缚态对系统自发衰变的抑制效应，并为开放系统的耗散动力学提供解析描述。

Method: 使用投影算符形式推导单激发Friedrichs模型的解析表达式，建立束缚态数量的明确判据，推导开放系统的耗散动力学，并将框架应用于光子晶体波导中的原子链。

Result: 建立了束缚态存在的明确判据，发现束缚态抑制系统的完全自发衰变；在马尔可夫极限下，系统动力学由能量无关的非厄米哈密顿量描述；在原子链-光子晶体波导系统中发现了丰富的衰变动力学并实现了反PT对称哈密顿量。

Conclusion: 该研究为单激发Friedrichs模型提供了完整的解析框架，揭示了束缚态对衰变动力学的关键影响，并在具体系统中实现了反PT对称哈密顿量，为开放量子系统的研究提供了新工具。

Abstract: Considering an $N$-level system interacting factorizably with a continuous spectrum, we derive analytical expressions for the bound states and the dynamical evolution within this single-excitation Friedrichs model by using the projection operator formalism. First, we establish explicit criteria to determine the number of bound states, whose existence suppresses the complete spontaneous decay of the system. Second, we derive the open system's dissipative dynamics, which is naturally described by an energy-independent non-Hermitian Hamiltonian in the Markovian limit. As an example, we apply our framework to an atomic chain embedded in a photonic crystal waveguide, uncovering a rich variety of decay dynamics and realizing an anti-$\mathcal{PT}$-symmetric Hamiltonian in the system's evolution.

</details>


### [13] [Emergent Universality Class in Dissipative Quantum Systems with Dipole Moment Conservation](https://arxiv.org/abs/2512.17210)
*Wenbo Zhou,Yuke Zhang,Pengfei Zhang*

Main category: quant-ph

TL;DR: 该论文研究具有偶极矩守恒的耗散量子系统的普适动力学，发现了一个新的强相互作用非平衡不动点，并揭示了偶极对称性强弱对电荷输运的不同影响。


<details>
  <summary>Details</summary>
Motivation: 理解量子多体系统的非平衡动力学是现代物理学的重要挑战。特别是，研究那些没有对应平衡态的非平衡普适类变得越来越重要。受最近实验进展的启发，本文研究具有偶极矩守恒的耗散量子系统的普适动力学。

Method: 开发了有效的场论描述，并辅以一个具体的量子自旋模型来捕捉由此产生的普适行为。通过分析揭示了控制相涨落的新非平衡不动点。

Result: 发现了一个新的强相互作用非平衡不动点，该不动点控制着具有强或弱偶极对称性系统的等时相涨落。在强偶极对称性下，电荷输运变为亚扩散，而在弱对称性情况下仍保持扩散性。

Conclusion: 研究结果揭示了量子多体系统中动力学约束与耗散之间复杂的相互作用，为理解非平衡普适类提供了新的见解。

Abstract: Understanding the non-equilibrium dynamics of quantum many-body systems remains one of the grand challenges of modern physics. In particular, increasing attention has been devoted to the emergence of non-equilibrium universality classes that have no equilibrium counterparts. A prominent example is the Kardar-Parisi-Zhang universality class realized in dissipative Bose-Einstein condensates. In this Letter, motivated by recent experimental advances, we investigate the universal dynamics of dissipative quantum systems with dipole moment conservation. We develop an effective field theory description, supported by a concrete quantum spin model, to capture the resulting universal behaviors. Our analysis unveils a novel strongly interacting non-equilibrium fixed point that governs the equal-time phase fluctuations in systems with either strong or weak dipole symmetries. Moreover, charge transport becomes subdiffusive in the presence of strong dipole symmetry, while it remains diffusive in the weakly symmetric case. Our results reveal the intricate interplay between kinetic constraints and dissipation in quantum many-body systems.

</details>


### [14] [An edge-based and subspace reduction encoding scheme to solve the traveling salesman problem in quantum computers](https://arxiv.org/abs/2512.17291)
*Anandu Kalleri Madhu,Chi-Kwong Li,Jami Rönkkö,Mikio Nakahara,Ray-Kuang Lee*

Main category: quant-ph

TL;DR: 本文提出了一种用于量子计算机求解旅行商问题的新型基于边的编码技术，减少了所需量子比特数，并在IQM量子计算机上成功求解了4城市TSP实例。


<details>
  <summary>Details</summary>
Motivation: 现有量子计算中TSP问题的编码方法（如基于节点的编码）需要较多量子资源，限制了在真实量子设备上的应用。需要开发更高效的编码方案来减少量子比特需求，使TSP问题能在当前量子硬件上求解。

Method: 提出基于边的编码技术，结合子空间缩减编码进一步降低TSP解空间的维度。在模拟器和真实量子计算机上测试了4、5、6城市TSP实例，并与文献中的基于节点编码方法进行对比分析。

Result: 在最新的IQM量子计算机上成功获得了4城市TSP实例的最优解。实验表明，提出的编码方案在统计指标、量子资源利用和计算效率方面优于传统方法，特别是在较小TSP实例上表现更佳。

Conclusion: 基于边的编码技术为量子计算机求解TSP问题提供了更高效的方案，显著减少了量子资源需求，使在现有量子硬件上解决实际问题成为可能，为量子优化算法的发展提供了新方向。

Abstract: This paper introduces a novel edge-based encoding technique for solving the Traveling Salesman Problem (TSP) on a quantum computer, reducing the required number of qubits. For implementation in real quantum devices, we applied the subspace reduction encoding to further reduce the dimension of the TSP solution space. We attack the TSP for 4-, 5-, and 6-city instances in both simulators and real quantum computers across different encoding frameworks. Optimal solutions of the 4-city TSP instance are obtained on state-of-the art IQM quantum computer. Our study presents a comparative analysis between edge-based encoding scheme and the node-based encoding methodology in the literature. Our findings indicate that the proposed encoding scheme outperforms conventional methods in terms of statistical measures, quantum resource utilization, and computational efficiency when applied to smaller TSP instances.

</details>


### [15] [Towards Quantum Advantage in Sparsified Bosonic SYK Models](https://arxiv.org/abs/2512.17294)
*Vaibhav Gautam,Atsushi Matsuo,Masahito Yamazaki*

Main category: quant-ph

TL;DR: 该论文提出稀疏化玻色子SYK模型作为探索量子优势的有前景平台，并研究了该模型的量子模拟，包括经典模拟器和超导量子比特实现的量子设备，同时指出了高混沌系统量子模拟中的微妙问题。


<details>
  <summary>Details</summary>
Motivation: 探索量子优势的实现途径，通过研究玻色子SYK模型的稀疏化作为量子模拟的测试平台，为未来量子优势的寻找提供理论基础。

Method: 采用稀疏化玻色子SYK模型，在经典模拟器和超导量子比特实现的量子设备上进行量子模拟研究。

Result: 发现了高混沌系统量子模拟中的微妙问题，这些问题需要在未来寻找量子优势时加以解决。

Conclusion: 稀疏化玻色子SYK模型是探索量子优势的有前景平台，但高混沌系统的量子模拟存在需要解决的微妙问题，为未来量子优势研究提供了重要方向。

Abstract: We advocate the sparsification of bosonic SYK models as a promising arena for the exploration of quantum advantage. We initiate the study of quantum simulations of the models, both in classical simulators and on quantum devices implemented using superconducting qubits. We point out subtleties in the quantum simulations of highly chaotic systems, which should be addressed in the future search for quantum advantage.

</details>


### [16] [Spin minimum uncertainty states for refined uncertainty relations](https://arxiv.org/abs/2512.17307)
*Hao Dai,Yue Zhang*

Main category: quant-ph

TL;DR: 研究自旋系统中信息论精化的海森堡不确定关系的最小不确定态，发现自旋相干态确实达到最小不确定，但也存在超越相干态族的最小不确定态。


<details>
  <summary>Details</summary>
Motivation: 传统海森堡不确定关系的最小不确定态已被广泛研究，通常被视为从不确定性角度最经典的量子态。本研究旨在探索自旋系统中信息论精化的海森堡不确定关系的最小不确定态，以深入了解量子性本质及其潜在应用。

Method: 采用两种不同方法：矩阵表述和Wick符号表示，推导出饱和不确定界限的态的显式表达式。

Result: 自旋相干态确实达到最小不确定，这与它们作为自旋系统经典态的传统认定一致。此外，还发现了超越相干态族的额外最小不确定态类别。通过与先前研究的玻色子情况比较，阐明了两种设置之间差异的起源。

Conclusion: 自旋系统中信息论精化的不确定关系的最小不确定态不仅包括自旋相干态，还包含其他类别，这为理解自旋系统的量子经典边界提供了新视角，并与玻色子情况形成对比。

Abstract: Minimum uncertainty states of the conventional Heisenberg uncertainty relation have been extensively studied and are often regarded as the most classical quantum states from the perspective of uncertainty, providing valuable insight into the nature of quantumness and its potential applications. In this work, we investigate the minimum uncertainty states associated with an information-theoretic refinement of the Heisenberg uncertainty relation in general spin systems. Using two different approaches, the matrix formulation and the Wick symbol representation, we derive explicit expressions for the states that saturate the uncertainty bound. We show that spin coherent states indeed achieve minimum uncertainty, consistent with their conventional identification as the classical states of spin systems. Moreover, we also identify additional classes of minimum uncertainty states beyond the coherent family. Finally, we compare the spin-system results with the previously studied bosonic case and elucidate the origin of the differences between the two settings.

</details>


### [17] [Microcomb-driven large-scale fully connected quantum network](https://arxiv.org/abs/2512.17318)
*Fang-Xiang Wang,Sheng-Teng Zheng,Long Huang,Guo-We Zhang,Guang-Shu Wang,Wen-Jing Ding,Ze-Hao Wang,Shuang Wang,Zhen-Qiang Yin,Chang-Ling Zou,Brent E. Little,Guochao Wang,Lingxiao Zhu,Guang-Can Guo,Weiqiang Wang,Wenfu Zhang,Wei Chen,Zheng-Fu Han*

Main category: quant-ph

TL;DR: 基于双光子HOM干涉的大规模全连接量子网络，通过集成孤子微梳和光子编码芯片，实现了200用户、200公里的全连接量子网络，具有信息论安全性。


<details>
  <summary>Details</summary>
Motivation: 全连接量子网络虽然能同时连接所有用户，是最通用和鲁棒的网络架构，但其可扩展性在实际应用中仍然面临巨大挑战。

Method: 基于双光子Hong-Ou-Mandel干涉构建网络架构，使用集成孤子微梳和光子编码芯片实现精确的大规模并行频率生成和锁定、高可见度的HOM干涉以及测量设备无关量子密钥分发。

Result: 实现了200用户、200公里的全连接量子网络，即使在不可信网络提供商的情况下也能保证用户间安全性，具有严格的信息论安全性。

Conclusion: 该网络架构为实现跨大都市和城际区域的大规模全连接MDI量子网络铺平了道路。

Abstract: Fully connected quantum networks enable simultaneously connecting every user to every other user and are the most versatile and robust networking architecture. However, the scalability of such networks remains great challenge for practical applications. Here we construct a large-scale fully connected quantum network founded on two-photon Hong-Ou-Mandel (HOM) interference, where user-to-user security is guaranteed even with untrusted network provider. Using integrated soliton microcomb (SMC) and photonic encoding chips, we realize precise massive parallel frequency generation and locking, high-visibility HOM interferences and measurement-device-independent (MDI) quantum key distribution. The proposed architecture enables a 200-user fully connected quantum network over 200 kilometers with strict information-theoretic security via untrusted network provider. The implemented networking architecture paves the way for realizing large-scale fully connected MDI quantum networks across metropolitan and intercity regions.

</details>


### [18] [The Standard Model Symmetry and Qubit Entanglement](https://arxiv.org/abs/2512.17328)
*Jochen Szangolies*

Main category: quant-ph

TL;DR: 该研究将量子纠缠与高维时空维度联系起来，通过降维从纠缠量子比特系统中推导出标准模型规范群，提出了一种新的时空和规范场涌现机制。


<details>
  <summary>Details</summary>
Motivation: 整合量子引力与量子信息理论，探索如何从量子纠缠中同时涌现出时空结构和规范对称性，特别是标准模型的规范群。

Method: 将两比特和三比特纠缠系统分别关联到5+1维和9+1维时空，通过选择优先复方向降维到3+1维，分析降维后的残余对称性。

Result: 三比特纠缠系统降维后具有SU(3)×SU(2)×U(1)/ℤ₆对称性，这正是标准模型的规范群。时空从纠缠熵的面积律贡献中涌现，而规范场和物质场来自面积律破坏项。

Conclusion: 该研究为从量子纠缠中统一涌现时空和规范场提供了新框架，解释了弱力手征性的可能起源，并展示了在量子模拟标准模型场论中的应用前景。

Abstract: Research at the intersection of quantum gravity and quantum information theory has seen significant success in describing the emergence of spacetime and gravity from quantum states whose entanglement entropy approximately obeys an area law. In a different direction, the Kaluza-Klein proposal aims to recover gauge symmetries by means of dimensional reduction of higher-dimensional gravitational theories. Integrating both, gravitational and gauge degrees of freedom in $3+1$ dimensions may be obtained upon dimensional reduction of higher-dimensional emergent gravity. To this end, we show that entangled systems of two and three qubits can be associated with $5+1$ and $9+1$ dimensional spacetimes respectively, which are reduced to $3+1$ dimensions upon singling out a preferred complex direction. In the latter case, this reduction is invariant under a residual $SU(3) \times SU(2) \times U(1) /\mathbb{Z}_6$ symmetry, the Standard Model gauge group. This motivates a picture in which spacetime emerges from the area law-contribution to the entanglement entropy, while gauge and matter degrees of freedom are due to area law-violating terms. We remark on a possible natural origin of the chirality of the weak force in the given construction. Furthermore, we highlight the possibility of using this construction in quantum simulations of Standard Model fields.

</details>


### [19] [Validating the calibrated creation of heralded single photons](https://arxiv.org/abs/2512.17336)
*Daniel Borrero Landazabal,Kaisa Laiho*

Main category: quant-ph

TL;DR: 基于PP-KTP波导的参量下转换实现电信波段单光子源，通过光子关联测量准确表征单光子态的平均光子数和光子数宇称


<details>
  <summary>Details</summary>
Motivation: 现有光子对过程和预示单光子的表征方法中，符合计数判别已变得非常实用。需要开发更全面的工具箱来表征预示单光子态的特性，特别是对损耗具有容忍度的表征方法。

Method: 在PP-KTP波导中实现电信波段的参量下转换（PDC）单光子源，涉及少量光学模式。将传统品质因数相结合，通过简单的光子关联测量来获取预示态的平均光子数和光子数宇称。

Result: 实验证明仅通过简单的光子关联测量就能准确确定这些特性。该方法对损耗具有容忍度，能够实现预示单光子态的精确表征。

Conclusion: 该方法可用于校准创建预示单光子，并确定表征单量子态所需的关键可观测量期望值。研究结果在单光子源表征方面具有实用价值。

Abstract: Coincidence-count discrimination have turned utterly practical in the characterization of photon-pair processes and heralded single photons. Here, we implement a heralded single photon source based on parametric down-conversion (PDC) in a PP-KTP waveguide in the telecom wavelength range involving a low number of optical modes. We extend the toolbox for the loss-tolerant state characterization by combining conventional figures-of-merit in order to access the heralded state's mean photon number and its photon-number parity. Our experiment demonstrates that an accurate determination of these characteristics is possible just through simple photon-correlation measurements. We believe that our results can find usage in the calibrated creation of heralded single photons and in determining the expectation values of observables that are crucial for denoting a single quantum.

</details>


### [20] [Rydberg Atomic RF Sensor-based Quantum Radar](https://arxiv.org/abs/2512.17421)
*Sourav Banerjee,Neel Kanth Kundu*

Main category: quant-ph

TL;DR: 基于里德堡原子的量子雷达通过光学读取实现电场检测，相比传统雷达具有更高信噪比和更低速度估计误差


<details>
  <summary>Details</summary>
Motivation: 里德堡原子RF传感器相比传统偶极天线在电场检测方面具有独特优势，需要探索其在量子雷达中的应用潜力

Method: 提出基于里德堡原子的量子雷达系统模型，采用激光和光子探测器进行光学读取，推导信噪比公式，并与经典雷达对比，使用不变函数方法估计多普勒频率

Result: 仿真显示量子雷达相比传统雷达获得更高信噪比，在速度估计中具有更低的均方根误差

Conclusion: 基于里德堡原子的量子雷达系统在性能上优于传统雷达，展示了量子传感技术在雷达应用中的潜力

Abstract: Rydberg atom-based RF sensors offer distinct advantages over conventional dipole antennas for electric field detection. This paper presents a system model and performance analysis of a Rydberg atom-based quantum radar, which employs optical readout via lasers and photon detectors instead of circuit-based receivers. We derive the signal-to-noise ratio (SNR), compare it with classical radar, and estimate Doppler frequency using an invariant function-based method. Simulations show that the quantum radar achieves higher SNR and lower RMSE in velocity estimation than conventional radar.

</details>


### [21] [Single-Photon Scattering in a Waveguide Coupled to a Lossy or Gain Giant Atom](https://arxiv.org/abs/2512.17456)
*Yu Xin,Jia-Ming Zhang,Bing Chen*

Main category: quant-ph

TL;DR: 研究一维耦合谐振器波导与具有复本征能的巨原子耦合系统中的单光子散射，发现增益型巨原子会导致散射发散和谱奇点，并揭示时间相关散射理论在非厄米系统中的必要性。


<details>
  <summary>Details</summary>
Motivation: 研究非厄米系统中单光子散射的独特现象，特别是当巨原子具有增益或损耗特性时，探索传统时间无关散射理论在非厄米系统中的局限性。

Method: 采用广义投影算符形式理论，推导散射系数的解析表达式，通过高斯波包散射的数值模拟验证时间相关理论预测。

Result: 损耗型巨原子吸收入射波，增益型巨原子放大入射波并在特定能量处导致散射发散（谱奇点）；系统存在连续谱中的束缚态，导致持续波发射；增益系统至少有一个时间增长的束缚态主导长时间动力学。

Conclusion: 非厄米系统中的散射现象复杂，传统时间无关散射理论不适用，增益型巨原子导致谱奇点和时间增长的束缚态，需要发展时间相关散射理论来描述此类系统的动力学行为。

Abstract: This work investigates single-photon scattering in a one-dimensional coupled-resonator waveguide coupled to a giant atom with a complex on-site energy. Within the generalized projection operator formalism, we derive analytical expressions for the scattering coefficients. We find that a lossy giant atom absorbs the incident wave, whereas a gain giant atom not only amplifies the incident wave but also leads to scattering divergence at certain energies, corresponding to spectral singularities. We explore the critical scattering dynamics associated with these singularities, and attribute the persistent wave emission to the existence of a stationary bound state in the continuum. Due to the presence of this bound state, the conventional time-independent scattering theory proves inadequate for such a non-Hermitian system. Furthermore, we show that the system with gain always features at least one time-growing bound state, which dominates the long-time dynamics, and we verify our time-dependent theoretical predictions via numerical simulations of Gaussian wave packet scattering.

</details>


### [22] [Probing an electron spin ensemble with squeezed microwave signals](https://arxiv.org/abs/2512.17490)
*P. Oehrl,F. Fesquet,K. E. Honasoge,M. Handschuh,A. Marx,R. Gross,K. G. Fedorov,H. Huebl*

Main category: quant-ph

TL;DR: 实验研究了压缩微波与电子自旋共振的相互作用，评估自旋系综作为GHz量子存储器的潜力，实现了61%的转移效率。


<details>
  <summary>Details</summary>
Motivation: 量子态高效转移到长寿命存储单元（如固态自旋系综）是量子通信、传感和计算领域的关键挑战，需要评估自旋系综作为GHz信号量子存储器的可行性。

Method: 生成高达5dB的连续变量压缩微波信号，让其与电子自旋共振跃迁相互作用；自旋系综通过电感耦合到集总元件超导微波谐振器（协同性C=0.3）；使用Wigner层析成像分析信号，并用量子输入-输出形式主义的稳态模型进行建模。

Result: 观察到压缩微波与自旋激发之间的转移效率约为61%，实验数据与量子输入-输出模型吻合良好，为自旋基量子存储器的设计参数提供了指导。

Conclusion: 自旋系综作为GHz量子存储器具有潜力，61%的转移效率证明了可行性，通过优化设计参数（如提高协同性）可进一步提升性能。

Abstract: The efficient transfer of quantum states into a long-lived storage unit such as solid-state spin ensembles is widely recognized as a critical challenge with significant implications for quantum communication, sensing and computing applications. Here, we experimentally investigate the interaction of propagating squeezed microwaves with an electron spin resonance transition in order to evaluate the use of spin ensembles as quantum memories for GHz signals. We generate continuous variable microwave states with a squeezing of up to 5dB below the vacuum level and let this signal interrogate a spin ensemble, which is inductively coupled to a lumped element superconducting microwave resonator with a cooperativity of C=0.3. Analyzing this signal using Wigner tomography, we observe a transfer efficiency of around 61% between the squeezed microwaves and the spin excitation. We successfully model our experimental results with a dedicated steady-state model based on the quantum input-output formalism and provide guidance for design parameters required to enable spin-based quantum memories.

</details>


### [23] [Bias-Class Discrimination of Universal QRAM Boolean Memories](https://arxiv.org/abs/2512.17503)
*Leonardo Bohac*

Main category: quant-ph

TL;DR: 研究通过固定通用QRAM接口区分布尔内存配置，分析布尔函数偏置类别（相对于1/2的不平衡度）的量子查询推断能力


<details>
  <summary>Details</summary>
Motivation: 探索在量子内存中存储未知布尔函数时，通过相干可寻址查询能推断出关于函数偏置类别（考虑补对称性）的什么信息，超越Deutsch-Jozsa的完美区分情况

Method: 使用固定通用QRAM接口，分析单查询集成状态在地址寄存器上的两特征空间结构，推导单副本Helstrom最优测量和成功概率的闭式表达式

Result: 发现补函数仅改变全局相位，假设p和1-p在信息论上相同，自然判别量是相位偏置幅度|μ|（等价于μ²），超越了Deutsch-Jozsa的完美区分

Conclusion: 该研究为布尔函数偏置类别的量子查询推断提供了理论框架，补充了Bernstein-Vazirani等精确识别设置，揭示了量子查询在偏置分析中的能力

Abstract: We study the discrimination of Boolean memory configurations via a fixed Universal QRAM (U-QRAM) interface. Given query access to a quantum memory storing an unknown Boolean function $f:[N]\to\{0,1\}$, we ask: what can be inferred about the bias class of $f$ (its imbalance from $1/2$, up to complement symmetry) using coherent, addressable queries? We show that for exact-weight bias classes, the induced single-query ensemble state on the address register has a two-eigenspace structure that yields closed-form expressions for the single-copy Helstrom-optimal measurement and success probability. Because complementing $f$ changes the state $|ψ\rangle$ only by a global phase, hypotheses $p$ and $1-p$ are information-theoretically identical in this model; thus the natural discriminand is the phase-bias magnitude $|μ|$ (equivalently $μ^2$). This goes beyond the perfect-discrimination case of Deutsch-Jozsa and complements exact-identification settings such as Bernstein-Vazirani.

</details>


### [24] [Autonomous Picosecond-Precision Synchronization in Measurement-Device-Independent Quantum Key Distribution](https://arxiv.org/abs/2512.17510)
*A. P. Pljonkin*

Main category: quant-ph

TL;DR: 提出一种用于光纤MDI-QKD网络的自主同步算法，无需辅助光通道或共享时钟参考，可实现10ps精度同步


<details>
  <summary>Details</summary>
Motivation: MDI-QKD需要皮秒级时间同步，但传统方法依赖辅助光通道或共享时钟，限制了实际部署的可扩展性和鲁棒性

Method: 利用往返光脉冲传播和存在高斯噪声时的统计信号检测，推导误报概率解析表达式，量化检测可靠性

Result: 数值模拟显示，在100公里信道长度和实际光功率水平下，可实现优于10ps的同步精度

Conclusion: 该方法提高了MDI-QKD架构的可扩展性和鲁棒性，可直接应用于城域和骨干量子网络

Abstract: Measurement-device-independent quantum key distribution (MDI-QKD) eliminates detector side-channel attacks by relocating all measurements to an untrusted intermediate node. However, its practical implementation critically relies on picosecond-level temporal synchronization between spatially separated users. In this work, we present a physically motivated autonomous synchronization algorithm for fiber-based MDI-QKD networks that does not require auxiliary optical channels or shared clock references. The method exploits round-trip optical pulse propagation and statistical signal detection in the presence of Gaussian noise. We derive analytical expressions for false-alarm probabilities, quantify detection reliability, and demonstrate through numerical modeling that synchronization accuracy better than 10~ps is achievable for channel lengths up to 100~km with realistic optical power levels. The proposed approach improves the scalability and robustness of MDI-QKD architectures and is directly applicable to metropolitan and backbone quantum networks.

</details>


### [25] [Refrigeration of a 1D gas of microwave photons](https://arxiv.org/abs/2512.17530)
*Lukas Schamriß,Louis Garbe,Peter Rabl*

Main category: quant-ph

TL;DR: 提出一种利用约瑟夫森元件冷却微波光子的新方案，可将一维光子气体冷却至亚毫开尔文温度


<details>
  <summary>Details</summary>
Motivation: 开发一种简单有效的方案来冷却微波光子气体，使其温度低于稀释制冷机的典型基温，为量子模拟应用创造条件

Method: 在超导传输线一端并联非线性约瑟夫森元件，设计一种将光子从高频模式转移到低频模式的冷却机制，同时保持光子总数不变

Result: 预测该机制可将光子气体冷却至亚毫开尔文温度，并发现系统会出现一种在平衡情况下不会发生的新型凝聚相变

Conclusion: 该冷却方案为微波光子相互作用的量子模拟提供了有前景的应用前景，能够实现极低温度的光子气体制备

Abstract: We discuss a conceptually simple scheme for cooling a one dimensional gas of microwave photons in a superconducting transmission line. By shunting one end of the transmission line by a nonlinear Josephson element, we show how a cooling mechanism can be engineered that transfers photons from high- into low-frequency modes, while preserving their total number. We evaluate the resulting nonequilibrium steady state of the photon gas, which arises from a competition between this engineered cooling process and the natural, number non-conserving thermalization with the surrounding bath. Our analysis predicts that for realistic experimental parameters, this mechanism can be used to prepare photonic gases at sub-millikelvin temperatures, considerably below the typical base temperature of a dilution refrigerator. In addition, the system exhibits a new type of condensation transition that does not occur in the corresponding equilibrium scenario. As an outlook, we discuss potential applications of this cooling approach for quantum simulation schemes with interacting microwave photons.

</details>


### [26] [Coherent phase control of orbital-angular-momentum light-induced torque in a double-tripod atom-light coupling scheme](https://arxiv.org/abs/2512.17537)
*Hamid R. Hamedi,Viačeslav Kudriašov,Mažena Mackoit-Sinkevičienė,Julius Ruseckas*

Main category: quant-ph

TL;DR: 五能级双三脚架原子系统中，利用携带轨道角动量的涡旋光束和相位控制，实现光学扭矩的精确调控和原子旋转流动


<details>
  <summary>Details</summary>
Motivation: 研究如何通过相位可控机制在原子系统中产生光学扭矩，实现对原子旋转运动的精确控制，为量子控制、精密测量和量子信息处理提供新方法

Method: 采用五能级双三脚架原子-光耦合方案，使用四束强相干控制场和两束携带轨道角动量的弱涡旋探测光束，通过解析求解稳态条件下的光学布洛赫方程

Result: OAM涡旋光束的空间相位梯度诱导出量子化扭矩，使原子旋转并在环形几何中产生定向原子流；系统可相干重构为Λ或双Λ构型，扭矩特性对相位变化高度敏感

Conclusion: 该相位可控光学扭矩机制能够精确调控原子电流流动，在量子控制、精密测量和量子信息处理领域具有潜在应用价值

Abstract: We investigate a phase-controllable mechanism for generating optical torque in a five-level double-tripod (DT) atom-light coupling scheme interacting with four strong coherent control fields as well as two weak optical vortex probe beams carrying orbital angular momentum (OAM). The spatial phase gradients of the OAM-carrying probes induce a quantized torque that is transferred to the atoms, rotating them and generating a directed atomic flow within an annular geometry. Analytical solutions of the optical Bloch equations under steady-state conditions show that the induced torque and resulting rotational motion exhibit high sensitivity to phase variations. We show that the DT system coherently reconfigures into either coupled Λ or double-Λ schemes depending on the relative phases, with each configuration exhibiting distinct quantized torque characteristics. This enables precise phase control of the atomic current flow, with potential applications in quantum control, precision measurement, and quantum information processing.

</details>


### [27] [Bloch Motions and Spinning Tops](https://arxiv.org/abs/2512.17549)
*Albert Huber,Paul Schreivogl*

Main category: quant-ph

TL;DR: 该研究将封闭量子系统的布洛赫矢量动力学与刚体动力学、可积系统理论联系起来，证明了量子动力学的刘维尔可积性，并推导出量子纠缠振荡的特定解。


<details>
  <summary>Details</summary>
Motivation: 探索量子系统动力学与经典力学系统之间的数学等价性，建立量子动力学与刚体动力学、可积系统理论的联系，从而利用经典力学方法研究量子系统的稳定性和特殊解。

Method: 从冯·诺依曼方程推导布洛赫分量的运动方程，证明其与经典点质量分布运动方程的数学等价性；利用海森堡方程推导形成欧拉-泊松系统的布洛赫矢量方程；应用刘维尔可积性理论、能量-卡西米尔方法等经典力学工具分析量子动力学。

Result: 证明了量子动力学方程的刘维尔可积性，建立了与诺依曼模型和哈密顿欧拉-泊松模型的联系；推导了量子动力学的稳定性判据；构造了编码复合量子系统复杂动力学的特定解，包括纠缠振荡态；推导了中间轴定理的量子类比。

Conclusion: 该形式体系为量子动力学提供了新的分析框架，揭示了量子系统与经典力学系统之间的深刻数学联系，能够产生具体的物理预测，如纠缠振荡现象和稳定性判据，为研究复合量子系统的复杂动力学提供了有力工具。

Abstract: This work investigates the dynamics of closed quantum systems in the Bloch vector representation using methods from rigid body dynamics and the theory of integrable systems. To this end, equations of motion for Bloch components are derived from the von Neumann equation, which are mathematically equivalent to equations of motion for a distribution of point masses from classical mechanics. Furthermore, using the Heisenberg equation, another system of Bloch vector equations is derived, which forms an Euler-Poinsot system, as is commonly encountered in the theory of torque-free spinning tops. This is used to prove the Liouville integrability of the corresponding Hamilton equations of motion, whereby formal connections to the Neumann model of classical Hamiltonian dynamics and the Hamiltonian Euler-Poinsot model are drawn to identify the first integrals of motion. Within the same framework, stability criteria for quantum dynamics are then derived which correspond to the Routh-Hurwitz criterion resp. other criteria following from the Energy-Casimir method of classical Newtonian mechanics. Following that, specific solutions to the equations of motion are constructed that encode the complex dynamics of composite quantum systems. Eventually, to show that this formalism provides concrete physical predictions, an analogue of the intermediate axis theorem is derived and the effect of oscillating entanglement is discussed. As a basis for this, special types of solutions to the equations of motion are derived that constitute oscillating entangled states, i.e., dynamical quantum states that change their entanglement structure from maximally entangled to separable and vice versa.

</details>


### [28] [Group-theoretical analysis of quantum complexity: the oscillator group case](https://arxiv.org/abs/2512.17552)
*K. Andrzejewski,K. Bolonek-Lasoń,P. Kosiński*

Main category: quant-ph

TL;DR: 本文基于群论方法推导了振荡子群表示中酉算符的Nielsen复杂度，通过求解右不变度量下的测地线方程，为计算该群表示中任意酉算符的复杂度提供了理论框架。


<details>
  <summary>Details</summary>
Motivation: 受量子力学过程中复杂性理论快速发展的启发，本文旨在推导振荡子群表示中酉算符的Nielsen复杂度。动机在于将复杂性分析建立在底层群结构的基础上，为量子计算和量子信息中的复杂性研究提供新的理论工具。

Method: 方法基于群论框架：1) 将复杂性分析问题归结为底层群结构问题；2) 通过考虑相关酉表示将抽象结构提升到算子层面；3) 对满足自然不变条件的右不变度量类求解振荡子群上的测地线方程；4) 解用初等函数显式给出，通过边界条件得到超越方程，测地线长度由该方程的解给出。

Result: 成功求解了振荡子群上右不变度量下的测地线方程，得到了用初等函数表示的显式解。建立了边界条件与超越方程的联系，测地线长度可由该超越方程的解计算。由于振荡子群的酉不可约表示已完全分类，理论上可以计算该群表示中任意酉算符的复杂度。

Conclusion: 本文建立了基于群论框架的Nielsen复杂度计算方法，为振荡子群表示中酉算符的复杂性分析提供了完整的理论推导。该方法原则上可应用于该群表示中的任意酉算符，为量子复杂性理论的发展提供了新的数学工具。

Abstract: Motivated by the recent rapid development of complexity theory applied to quantum mechanical processes we present the complete derivation of Nielsen's complexity of unitaries belonging to the representations of oscillator group. Our approach is based on the observation that the whole problem refers to the structure of the underlying group. The questions concerning the complexity of particular unitaries are solved by lifting the abstract structure to the operator level by considering the relevant unitary representation. For the class of right-invariant metrics obeying natural invariance condition we solve the geodesic equations on oscillator group. The solution is given explicitly in terms of elementary functions. Imposing the boundary conditions yield a transcendental equation and the length of the geodesic is given in terms of the solutions to the latter. Since the unitary irreducible representations of oscillator group are classified this allows us to compute, at least in principle, the complexity of any unitary operator belonging to the representation.

</details>


### [29] [Quantum Mechanics in a Spherical Wedge: Complete Solution and Implications for Angular Momentum Theory](https://arxiv.org/abs/2512.17558)
*Mustafa Bakr,Smain Amari*

Main category: quant-ph

TL;DR: 该论文研究了三维球面楔形区域中粒子的定态薛定谔方程，揭示了对称性破缺边界条件下谱重组现象，为角动量量子化提供了算子域视角。


<details>
  <summary>Details</summary>
Motivation: 研究受约束域模型中对称性破缺边界条件对量子系统的影响，探索角动量量子化的算子域视角，理解单值性和极向正则性在标准角动量量子化中的不同作用。

Method: 求解三维球面楔形区域（Dirichlet边界条件）的定态薛定谔方程，分析方位角坐标中的驻波解，研究有效方位角量子数的非整数特性，并应用于库仑势场。

Result: 1. 定态不是L_z的本征态，角动量投影成为具有真正量子不确定性的可观测量；2. 有效方位角量子数通常为非整数，极向波函数的平方可积性要求角本征值参数满足特定条件；3. 氢原子整数角动量谱源于全球面希尔伯特空间域的周期性识别，修改边界条件会产生具有非整数有效角动量的重组谱。

Conclusion: 该模型阐明了标准角动量量子化中单值性（通过方位角拓扑选择整数m）和极向正则性（通过解析约束选择整数ℓ≥|m|）的不同作用，为对称性破缺边界条件下的谱重组提供了精确可解的理论框架。

Abstract: We solve the stationary Schrödinger equation for a particle confined to a 3D spherical wedge -- the region $\{(r,θ,φ): 0 \leq r \leq R,\, 0 \leq θ\leq π,\, 0 \leq φ\leq Φ\}$ with Dirichlet BCs on all surfaces. This exactly solvable constrained-domain model exhibits spectral reorganisation under symmetry-breaking BCs and provides an operator-domain viewpoint on angular momentum quantisation. We obtain three main results. First, the stationary states are standing waves in the azimuthal coordinate and consequently are \emph{not} eigenstates of $\hat{L}_z$; we prove $\langle L_z \rangle = 0$ with $ΔL_z = \hbar n_φπ/Φ\neq 0$, demonstrating that angular momentum projection becomes an observable with genuine quantum uncertainty rather than a good quantum number. Second, the effective azimuthal quantum number $μ= n_φπ/Φ$ is generically non-integer, and square-integrability of the polar wavefunctions at both poles requires the angular eigenvalue parameter $ν$ to satisfy $ν- μ\in \mathbb{Z}_{\geq 0}$. This regularity constraint yields a hierarchy: sectoral solutions ($ν= μ$, satisfying the first-order highest-weight condition) exist for any real $μ> 0$, while tesseral and zonal solutions require integer steps, appearing only when $μ$ itself is integer. Third, application to a Coulomb potential shows that the familiar integer angular momentum spectrum of hydrogen arises from the periodic identification $φ\sim φ+ 2π$ that defines the full-sphere Hilbert space domain; modified boundary conditions yield a reorganised spectrum with non-integer effective angular momentum. The model clarifies the distinct roles of single-valuedness (selecting integer $m$ via azimuthal topology) and polar regularity (selecting integer $\ell \geq |m|$ via analytic constraints) in the standard quantisation of orbital angular momentum.

</details>


### [30] [Investigating methods to solve large windfarm optimization problems with a minimum number of qubits using circuit-based quantum computers](https://arxiv.org/abs/2512.17582)
*James Hancock,Matthew Craven,Craig McNeile*

Main category: quant-ph

TL;DR: 研究探索量子计算解决风电场布局优化问题，提出两种高效编码方法（PCE和新型SQOE），在9×9网格上仅需最多20个量子比特，在模拟器上验证了竞争性性能和良好扩展性。


<details>
  <summary>Details</summary>
Motivation: 风电场布局优化（WFLO）是一个复杂的组合优化问题，传统方法计算成本高。量子计算为解决此类二次无约束二进制优化（QUBO）问题提供了新途径，但需要高效的量子比特编码方法以减少资源需求。

Method: 将WFLO问题建模为QUBO问题，研究两种高效编码方法：已有的Pauli相关编码（PCE）和新型单量子比特算子编码（SQOE）。这两种方法都实现了少于每个网格点一个量子比特的高效编码。在三个风电场配置（两个来自先前研究，一个基于威尔士真实风电场）上进行测试。

Result: 改进的编码方法使得在9×9网格上解决WFLO问题仅需最多20个量子比特（在量子计算机模拟器上）。两种编码方法都表现出竞争性性能，并在测试系统中展示了良好的扩展特性。

Conclusion: PCE和SQOE编码方法为量子计算解决风电场布局优化问题提供了高效的资源利用方案，展示了量子计算在复杂优化问题中的潜力，特别是在减少量子比特需求方面取得了重要进展。

Abstract: This study investigates quantum computing approaches for solving the windfarm layout optimization (WFLO) problems formulated as a quadratic unconstrained binary optimization (QUBO) problem. We investigate two encoding methods that require fewer than one qubit per grid point: the previously developed Pauli correlation encoding (PCE) and a novel single-qubit operator encoding (SQOE). These methods are tested on three windfarm configurations - two from prior WFLO scaling studies and a new real-world model based on an existing windfarm in Wales. The improved encoding methods allow us to solve WFLO problems on $9\times 9$ grids using up to 20 qubits on a quantum computer simulator. The results show that both encoding methods perform competitively and demonstrate favorable scaling characteristics across the tested systems.

</details>


### [31] [Frequency-Multiplexed Millimeter-Wave Fault-Tolerant Superconducting Qubits Enabled by an On-Chip Nonreciprocal Control Bus](https://arxiv.org/abs/2512.17588)
*Sajjad Taravati*

Main category: quant-ph

TL;DR: 提出频率复用毫米波超导量子比特概念，通过片上低温非互易时空周期超导频率倍增器作为通用控制总线，用单个低频输入替代多个高频驱动线，同时抑制Purcell衰减和串扰，实现超过25量子比特的可扩展量子处理。


<details>
  <summary>Details</summary>
Motivation: 超导量子处理器扩展受限于低温布线复杂性、微波串扰和Purcell衰减。现有架构需要大量高频驱动线，导致I/O复杂性和噪声问题。

Method: 设计集成片上低温非互易时空周期超导频率倍增器作为频率复用量子比特阵列的通用控制总线。单个低频输入通过倍增器转换为高阶谐波梳，每个谐波共振寻址不同量子比特。动态非互易特性提供信号增益和固有隔离。

Result: 总线同时抑制Purcell衰减，提高所有不同频率量子比特的T1时间，将相干串扰降低两个数量级以上。时空调制实现参数频率倍增，产生类似宇宙膨胀的波传播动力学。非马尔可夫主方程理论模型确认工程化内存核延长相干时间。完整误差预算分析显示架构在超过25量子比特阵列中保持低于容错阈值的门误差。

Conclusion: 集成、频率复用、非互易控制总线为前所未有的I/O简化、噪声弹性和可扩展高相干量子处理提供了路径，将串扰主导的误差预算转换为受限于固有材料相干性的误差预算。

Abstract: Scaling superconducting quantum processors is fundamentally limited by the escalating complexity of cryogenic wiring and the debilitating effects of microwave crosstalk and Purcell decay. This paper proposes the concept of frequency-multiplexed millimeter-wave superconducting qubits and demonstrates a novel architecture that integrates an on-chip cryogenic nonreciprocal space-time-periodic superconducting frequency multiplier as a universal control bus for a frequency-multiplexed qubit array. The bus replaces multiple high-frequency XY drive lines with a single low-frequency input tone, which the multiplier converts into a comb of high-order harmonics, each resonantly addressing a distinct qubit. Crucially, the dynamic and nonreciprocal nature of the bus provides signal gain and intrinsic isolation that simultaneously suppresses Purcell decay, enhancing T1 times across all distinct-frequency qubits, and reduces coherent crosstalk by more than two orders of magnitude. The spatiotemporal modulation enables parametric frequency multiplication and creates wave-propagation dynamics analogous to cosmological expansion, with observed redshift-like broadening and deceleration of magnetic-field wavepackets. Theoretical modeling based on a non-Markovian master equation confirms that the engineered memory kernel extends coherence while reshaping the noise spectrum. Full error-budget analysis shows that the architecture maintains gate errors below the fault-tolerance threshold for arrays exceeding 25 qubits, converting a crosstalk-dominated error budget into one limited by intrinsic material coherence. This integrated, frequency-multiplexed, and nonreciprocal control bus therefore offers a path toward unprecedented I/O simplification, noise resilience, and scalable high-coherence quantum processin

</details>


### [32] [The threshold for quantum-classical correspondence is $D \sim \hbar^{\frac43}$](https://arxiv.org/abs/2512.17623)
*Felipe Hernández,Daniel Ranard,C. Jess Riedel*

Main category: quant-ph

TL;DR: 该论文证明在混沌量子系统中，量子-经典对应性的阈值是D∼ℏ^{4/3}，而不是之前认为的D≫ℏ^2。当环境扩散强度D小于ℏ^{4/3}时，即使对于宏观可观测量，量子与经典演化在Ehrenfest时间后也会出现显著差异。


<details>
  <summary>Details</summary>
Motivation: 在混沌量子系统中，量子态在Ehrenfest时间后会显著偏离经典相空间分布。虽然通常用环境退相干来解释量子-经典对应性在更长时间尺度上的保持，但关于所需扩散强度的精确阈值存在争议：严格结果要求D≫ℏ^{4/3}，而一些启发式论证认为D≫ℏ^2就足够了。

Method: 构建了一个显式的Lindblad动力学模型，使用光滑时间依赖的哈密顿量和线性Lindblad算子，生成均匀各向同性扩散。通过这个具体例子来研究量子-经典对应性的阈值行为。

Result: 证明了D∼ℏ^{4/3}确实是量子-经典对应性超越Ehrenfest时间的阈值。当D≪ℏ^{4/3}时，即使在Ehrenfest时间，量子与经典演化也会出现与ℏ无关的差异，即使对于宏观光滑可观测量也是如此。

Conclusion: 该研究解决了关于量子-经典对应性所需扩散强度阈值的争议，确认了D∼ℏ^{4/3}是临界标度，而不是更弱的D≫ℏ^2条件。这为理解混沌量子系统中环境退相干的作用提供了精确的理论基础。

Abstract: In chaotic quantum systems, an initially localized quantum state can deviate strongly from the corresponding classical phase-space distribution after the Ehrenfest time $t_{\mathrm{E}} \sim \log(\hbar^{-1})$, even in the limit $\hbar \to 0$. Decoherence by the environment is often invoked to explain the persistence of the quantum-classical correspondence at longer timescales. Recent rigorous results for Lindblad dynamics with phase-space diffusion strength $D$ show that quantum and classical evolutions remain close for times that are exponentially longer than the Ehrenfest time whenever $D \gg \hbar^{\frac43}$, in units set by the classical Hamiltonian. At the same time, some heuristic arguments have suggested the weaker condition $D \gg \hbar^{2}$ always suffices. Here we construct an explicit Lindbladian that demonstrates that the scaling $D \sim \hbar^{\frac43}$ is indeed the threshold for quantum-classical correspondence beyond the Ehrenfest time. Our example uses a smooth time-dependent Hamiltonian and linear Lindblad operators generating homogeneous isotropic diffusion. It exhibits an $\hbar$-independent quantum-classical discrepancy at the Ehrenfest time whenever $D \ll \hbar^{\frac43}$, even for $\hbar$-independent "macroscopic" smooth observables.

</details>


### [33] [Fraud detection in credit card transactions using Quantum-Assisted Restricted Boltzmann Machines](https://arxiv.org/abs/2512.17660)
*João Marcos Cavalcanti de Albuquerque Neto,Gustavo Castro do Amaral,Guilherme Penello Temporão*

Main category: quant-ph

TL;DR: 量子辅助受限玻尔兹曼机在信用卡欺诈检测中表现优于经典方法，即使在当前含噪量子退火器上也能实现


<details>
  <summary>Details</summary>
Motivation: 随着量子计算处理效率和可用性的提升，新兴量子计算平台的应用案例变得经济相关。研究旨在评估量子辅助RBM在真实金融欺诈检测中的性能

Method: 使用量子辅助受限玻尔兹曼机（RBM），在真实量子硬件和模拟器上运行，测试数据集包含巴西金融科技公司Stone提供的1.45亿笔交易记录，用于信用卡欺诈检测

Result: 量子辅助RBM方法在大多数性能指标上能够实现优于经典方法的性能，即使使用当前含噪的量子退火器也能取得良好结果

Conclusion: 该研究为在金融系统中实施量子辅助RBM进行一般故障检测铺平了道路，展示了量子计算在金融欺诈检测中的实际应用潜力

Abstract: Use cases for emerging quantum computing platforms become economically relevant as the efficiency of processing and availability of quantum computers increase. We assess the performance of Restricted Boltzmann Machines (RBM) assisted by quantum computing, running on real quantum hardware and simulators, using a real dataset containing 145 million transactions provided by Stone, a leading Brazilian fintech, for credit card fraud detection. The results suggest that the quantum-assisted RBM method is able to achieve superior performance in most figures of merit in comparison to classical approaches, even using current noisy quantum annealers. Our study paves the way for implementing quantum-assisted RBMs for general fault detection in financial systems.

</details>


### [34] [Quantum heat current in Terahertz-driven phonon systems](https://arxiv.org/abs/2512.17669)
*Yulong Qiao,Richard. Matthias Geilhufe*

Main category: quant-ph

TL;DR: 研究太赫兹脉冲驱动光学声子模式的超快量子热力学，揭示非马尔可夫耗散效应


<details>
  <summary>Details</summary>
Motivation: 高强度超快激光脉冲为量子材料控制提供了新机遇，太赫兹脉冲可共振驱动光学声子模式，但传统马尔可夫近似在超快驱动下可能失效，需要研究非马尔可夫耗散效应

Method: 采用Caldeira-Leggett型框架，将声子视为与热环境耦合的开放量子系统，推导声子与热浴之间的量子热流，分析实际脉冲协议下的行为

Result: 超快激光驱动可揭示并诱导显著偏离马尔可夫近似的现象，为探测和控制固态系统中的非马尔可夫耗散提供了途径

Conclusion: 太赫兹脉冲驱动的光学声子模式展现出丰富的非马尔可夫热力学行为，为量子材料控制和热管理提供了新视角

Abstract: The advent of high-intensity ultrafast laser pulses has opened new opportunities for controlling and designing quantum materials. In particular, terahertz (THz) pulses can resonantly drive optical phonon modes, enabling dynamic manipulation of lattice degrees of freedom. In this work, we investigate the ultrafast quantum thermodynamics of optical phonon mode driven by a THz pulse by treating the phonon as an open quantum system coupled to a thermal environment within a Caldeira-Leggett-type framework. We derive the quantum heat current between the phonon and the bath and analyze its behavior under realistic pulse protocols. Our results demonstrate that ultrafast laser driving can reveal and even induce significant deviations from the commonly adopted Markovian approximation, thereby providing a pathway to probe and control non-Markovian dissipation in driven solid-state systems.

</details>


### [35] [Detecting non-Gaussian entanglement beyond Gaussian criteria](https://arxiv.org/abs/2512.17681)
*Abhinav Verma,Olga Solodovnikova,Jonas S. Neergaard-Nielsen,Ulrik L. Andersen*

Main category: quant-ph

TL;DR: 提出了一种新的不可分性判据，能够检测高斯统计方法无法识别的非高斯纠缠，适用于连续变量量子系统


<details>
  <summary>Details</summary>
Motivation: 量子纠缠是量子理论的核心，但在非高斯系统中可靠检测纠缠一直是个挑战。基于高斯统计的不可分性测试（如Duan和Simon判据）在量子相关性编码在场正交分量的高阶矩时会失效

Method: 引入了一种新的不可分性判据，通过结合高阶正交分量累积量来揭示非高斯纠缠，扩展了高斯理论，无需完整态层析，可直接从零差和外差数据评估

Result: 该判据能够检测基于协方差的判据无法识别的非高斯纠缠，适用于两模Fock态任意叠加，为连续变量平台提供了实验可行的非高斯资源识别方法

Conclusion: 提出的判据为检测连续变量系统中的非高斯纠缠提供了有效工具，填补了高斯统计方法在非高斯系统检测中的空白，具有重要的实验应用价值

Abstract: Entanglement is central to quantum theory, yet detecting it reliably in non-Gaussian systems remains a long-standing challenge. In continuous-variable platforms, inseparability tests based on Gaussian statistics - such as those of Duan and Simon - fail when quantum correlations are encoded in higher moments of the field quadratures. Here we introduce an inseparability criterion that exposes non-Gaussian entanglement that escapes covariance-based criteria by incorporating higher-order quadrature cumulants. The criterion extends Gaussian theory without requiring full state tomography and can be evaluated directly from homodyne and heterodyne data and is possible to extend to arbitrary superpositions of Fock states in two modes. This provides an experimentally viable approach for identifying non-Gaussian resources in continuous-variable platforms.

</details>


### [36] [Digital-Analog Quantum Computing with Qudits](https://arxiv.org/abs/2512.17697)
*Alatz Alvarez-Ahedo,Mikel Garcia de Andoin,Mikel Sanz*

Main category: quant-ph

TL;DR: 将数字-模拟量子计算框架从两能级系统扩展到d能级系统，利用Weyl-Heisenberg基的单量子dit门与模拟哈密顿量块结合实现通用计算


<details>
  <summary>Details</summary>
Motivation: 现有的数字-模拟量子计算框架主要针对两能级系统（量子比特），但许多量子系统天然具有多能级结构。为了充分利用这些系统的计算潜力，需要将框架扩展到d能级系统（量子dit）

Method: 通过将模拟哈密顿量块与从Weyl-Heisenberg基中提取的单量子dit门结合，提出了一种协议，最多使用O(d^4 n^2)个模拟块来模拟任意两体哈密顿量

Result: 成功将数字-模拟量子计算框架扩展到d能级系统，能够高效模拟包含磁四极矩项的多体量子dit自旋哈密顿量

Conclusion: 该工作为量子dit架构提供了一种通用的数字-模拟计算框架，展示了其在模拟复杂多体量子dit系统方面的潜力

Abstract: Digital-analog quantum computing with two-level systems is a computational paradigm that combines an analog Hamiltonian with single-qubit gates to achieve universality. We extend this framework to $d$-level systems by conjugating an analog Hamiltonian block with single-qudit gates drawn from the Weyl-Heisenberg basis, which provides a natural set of operations for qudit architectures. More specifically, we propose a protocol to simulate arbitrary two-body Hamiltonians with at most $O(d^4 n^2)$ analog blocks. The power of this approach is illustrated by the simulation of many-body qudit spin Hamiltonians including magnetic quadrupolar terms.

</details>


### [37] [Inclusion constants for free spectrahedra with applications to quantum incompatibility](https://arxiv.org/abs/2512.17706)
*Andreas Bluhm,Eric Evert,Igor Klep,Victor Magron,Ion Nechita*

Main category: quant-ph

TL;DR: 本文提出了一种计算自由谱面体包含常数的新方法，特别针对笛卡尔积自由单纯形的情况，并应用于量子信息理论中的测量兼容性分析。


<details>
  <summary>Details</summary>
Motivation: 自由谱面体包含问题在硬谱面体包含问题的松弛中具有重要作用，但除了高度对称情况外，缺乏计算包含常数的通用方法。本文旨在填补这一空白。

Method: 结合非交换多项式优化方法，并对相关自由谱面体的极值点进行详细分析，从而计算笛卡尔积自由单纯形的包含常数。

Result: 获得了包含常数的新闭式解析表达式，并将该方法应用于量子信息理论，证明了不相容测量在变得相容之前所能容忍的白噪声量的新界限。

Conclusion: 本文为计算自由谱面体包含常数提供了一种通用方法，特别针对笛卡尔积自由单纯形，并在量子测量兼容性问题上取得了新的理论进展。

Abstract: Building on the matrix cube problem, inclusions of free spectrahedra have been used successfully to obtain relaxations of hard spectrahedral inclusion problems. The quality of such a relaxation is quantified by the inclusion constant associated with each free spectrahedron. While optimal values of inclusion constants were known in certain highly symmetric cases, no general method for computing them was available. In this work, we show that inclusion constants for Cartesian products of free simplices can be computed using methods from non-commutative polynomial optimization, together with a detailed analysis of the extreme points of the associated free spectrahedra. This analysis also yields new closed-form analytic expressions for these constants. As an application to quantum information theory, we prove new bounds on the amount of white noise that incompatible measurements can tolerate before they become compatible. In particular, we study the case of one dichotomic and one $k$-outcome measurement, as well as the case of four dichotomic qubit measurements.

</details>


### [38] [Certified bounds on optimization problems in quantum theory](https://arxiv.org/abs/2512.17713)
*Younes Naceur,Jie Wang,Victor Magron,Antonio Acín*

Main category: quant-ph

TL;DR: 提出一种从数值数据中提取非交换优化问题精确有理界限的严格框架，用于量子信息理论中的可靠认证


<details>
  <summary>Details</summary>
Motivation: 多项式优化的半定松弛已成为解决量子信息理论中非交换算子非凸优化问题的核心工具，但由于依赖浮点方法，半定求解器给出的界限可能超过全局最优解，削弱了其可认证性

Method: 引入一个严格框架，从数值数据中提取非交换优化问题的精确有理界限，并扩展到稀疏性和对称性适应的半定松弛方法

Result: 将该方法应用于量子信息理论中的几个典型问题，建立了有理后处理作为可靠认证的实用途径

Conclusion: 有理后处理将半定优化推向量子信息科学的可认证标准

Abstract: Semidefinite relaxations of polynomial optimization have become a central tool for addressing the non-convex optimization problems over non-commutative operators that are ubiquitous in quantum information theory and, more in general, quantum physics. Yet, as these global relaxation methods rely on floating-point methods, the bounds issued by the semidefinite solver can - and often do - exceed the global optimum, undermining their certifiability. To counter this issue, we introduce a rigorous framework for extracting exact rational bounds on non-commutative optimization problems from numerical data, and apply it to several paradigmatic problems in quantum information theory. An extension to sparsity and symmetry-adapted semidefinite relaxations is also provided and compared to the general dense scheme. Our results establish rational post-processing as a practical route to reliable certification, pushing semidefinite optimization toward a certifiable standard for quantum information science.

</details>


### [39] [Continuum Limits of Lazy Open Quantum Walks](https://arxiv.org/abs/2512.17755)
*Lara Janiurek,Viv Kendon*

Main category: quant-ph

TL;DR: 本文推导了一维惰性离散时间量子行走的连续时空极限，得到了含退相干的三态模型的显式宏观演化方程，超越了传统的两态模型。


<details>
  <summary>Details</summary>
Motivation: 虽然两态量子行走的连续极限已有研究，但惰性三态行走（特别是包含噪声的情况）的显式连续时空公式尚未建立。本文旨在填补这一空白，为理解内部对称性、静止态耦合和不同退相干通道如何影响大规模输运提供理论框架。

Method: 使用SU(3)表示的Grover型硬币，结合作用于硬币或空间子空间的Lindblad退相干公式，系统地展开离散动力学，在空间和时间上获得控制粗粒度演化的连续主方程。

Result: 得到的生成元产生了真正的偏微分方程描述。在幺正极限下，系统由Dirac型SU(3)哈密顿量控制，描述左右移动模式的弹道平流，通过局部对称混合耦合，静止态作为额外的内部自由度。硬币退相干选择性地阻尼内部相干性，而空间退相干抑制长程空间干涉并迅速驱动动力学趋向经典行为。

Conclusion: 该连续框架阐明了内部对称性、静止态耦合和不同退相干通道如何塑造惰性开放量子行走中的大规模输运，为未来扩展到多通道量子输运模型和量子启发算法奠定了基础。

Abstract: We derive the continuous spacetime limit of the one dimensional lazy discrete time quantum walk, obtaining explicit macroscopic evolution equations for a three state model in the presence of decoherence. While continuum limits of two state quantum walks are well established, an explicit continuous spacetime formulation for the lazy three state walk, particularly including noise, has not previously been constructed. Using an SU(3) representation of a Grover type coin together with a Lindblad formulation of decoherence acting either on the coin or the spatial subspace, we systematically expand the discrete dynamics in both space and time to obtain continuum master equations governing the coarse grained evolution. The resulting generators yield a genuine partial differential equation description of the walk, going beyond purely probabilistic or spectral correspondences. We show that the unitary limit is governed by a Dirac-type SU(3) Hamiltonian describing ballistic advection of left and right moving modes coupled by local symmetric mixing, with the rest state acting as an additional internal degree of freedom. Coin dephasing selectively damps internal coherences while preserving coherent spatial transport, whereas spatial dephasing suppresses long range spatial interference and rapidly drives the dynamics toward classical behaviour. This continuum framework clarifies how internal symmetry, rest state coupling, and distinct decoherence channels shape large scale transport in lazy open quantum walks, and provides a foundation for future extensions toward multichannel quantum transport models and quantum-inspired algorithms.

</details>


### [40] [Demonstration of a quantum comparator on an ion-trap quantum device](https://arxiv.org/abs/2512.17779)
*Tatsuhiko N. Ikeda,Riku Nakama,Shunsuke Saeki,Hiroki Kuwata,Shuhei M. Yoshida,Akira Shimizu,Sho Sugiura*

Main category: quant-ph

TL;DR: 在RIKEN的Reimei量子计算机上成功演示了量子整数比较器，在n=9比特宽度下获得95%的成功率（传统标准）和69%成功率（更严格标准）


<details>
  <summary>Details</summary>
Motivation: 量子计算机被认为能比经典计算机更快解决基于模运算的计算问题，而整数比较是算术运算的基本构建块，需要在实际量子硬件上验证其性能

Method: 使用RIKEN的Reimei量子计算机，该计算机采用囚禁离子架构，提供全连接量子比特和高保真度门操作，实现了量子整数比较器电路

Result: 在比特宽度n=3,5,7,9下观察到高成功率：n=9时传统输出标准下成功率95%，更严格标准（要求辅助比特也正确）下成功率69%，远超先前实验规模

Conclusion: 该实验证明了量子比较器在远超先前实验规模的可靠性，不仅适用于比较器，也适用于更广泛的量子算术电路领域

Abstract: Quantum computers are believed to solve a class of computational problems that are based on modular arithmetic faster than classical computers. Among the arithmetic building blocks, comparison of integer pairs is a primitive. Here we report its demonstration in the Reimei quantum computer at RIKEN, whose trapped-ion architecture provides all-to-all qubit connectivity together with high gate fidelities. We observe high success probabilities for bit widths n = 3, 5, 7, and 9: Under a conventional output-only success criterion we obtain 95% at n=9; under a stricter criterion additionally requiring the ancilla to be correct, the success is 69% at n=9. These results demonstrate reliable quantum comparison at scales far beyond those previously achieved experimentally, not only for comparators but also in the broader context of quantum arithmetic circuits.

</details>


### [41] [Adiabatic preparation of many-body quantum states: getting the beginning and ending right](https://arxiv.org/abs/2512.17780)
*Emil T. M. Pedersen,Freek Witteveen,Klaus Mølmer,Matthias Christandl*

Main category: quant-ph

TL;DR: 通过优化哈密顿量调度的平滑性，在量子相变附近实现更高效的绝热演化，将保真度误差从1/T²提升到1/Tⁿ⁺¹


<details>
  <summary>Details</summary>
Motivation: 在量子模拟中，绝热演化是制备目标量子态的关键技术。传统方法在量子相变附近演化时，由于能隙关闭，保真度误差通常以1/T²缩放，需要长时间演化才能达到高保真度。本文旨在探索如何通过优化调度函数来显著提高演化效率。

Method: 采用平滑的初始和最终调度函数来控制哈密顿量的时间演化。理论分析表明，如果时间依赖的哈密顿量在开始和结束时具有n阶可导且前n阶导数为零，则保真度误差可以按1/Tⁿ⁺¹缩放。通过一维混合场伊辛模型和里德堡原子链进行数值计算和实验验证，比较不同调度函数的端到端转移误差。

Result: 数值计算和实验结果表明，采用平滑调度函数可以显著抑制端到端转移误差。具体而言，当哈密顿量在开始和结束时具有n阶平滑性时，相对于最终绝热本征态的保真度误差按1/Tⁿ⁺¹缩放，相比传统的1/T²缩放有显著改进。

Conclusion: 通过优化哈密顿量调度函数的平滑性，可以在量子相变附近实现更高效的绝热演化。这种方法为量子模拟和量子计算中的态制备提供了重要的优化策略，特别是在存在耗散损失的情况下，能够以更短的演化时间达到更高的保真度。

Abstract: We present numerical calculations, and simulations performed on a Rydberg atom quantum simulator, of the adiabatic evolution of many-body quantum systems around a quantum phase transition. We demonstrate that the end-to-end transfer error, for a given process duration and dissipative losses, can be suppressed by adopting smooth initial and final scheduling functions for the Hamiltonian. We consider a one-dimensional mixed-field Ising model, as well as a chain of Rydberg atoms, and compare numerical calculations and experimental results for the end-to-end transfer error with different schedule functions. We show, in particular, that if the time dependent Hamiltonian is $n$ times differentiable with vanishing $1^{st}$ to $n^{th}$ order derivatives in the beginning and in the end, the infidelity with respect to the final adiabatic eigenstate scales as $1/T^{n+1}$ when evolving for time $T$.

</details>


### [42] [Kerr-induced non-Gaussianity of ultrafast bright squeezed vacuum](https://arxiv.org/abs/2512.17797)
*Andrei Rasputnyi,Ilya Karuseichyk,Gerd Leuchs,Denis Seletskiy,Maria Chekhova*

Main category: quant-ph

TL;DR: 利用Kerr非线性将明亮压缩真空转化为确定性产生的明亮非高斯态，通过单次f-2f干涉仪表征其Husimi函数，观察到从高斯分布到S形非高斯分布的转变。


<details>
  <summary>Details</summary>
Motivation: 非高斯态是容错量子计算和增强计量学的关键资源，但通常微弱且需要通过后选择获得。本研究旨在确定性生成明亮的非高斯态。

Method: 在明亮压缩真空（BSV）中引入Kerr非线性，使用单次f-2f干涉仪采样其Husimi函数来表征生成的状态。

Result: 观察到Husimi函数从2D高斯分布转变为S形非高斯分布，这是强度依赖非线性相位的直接统计证据。虽然BSV作为混合态无法观测到Wigner函数的负性，但分析表明BSV可视为纯压缩相干态的混合，其中一些对损耗具有较好的容忍度。

Conclusion: 这项工作在量子光学和超快非线性光学之间架起了桥梁，为需要高光子通量的量子应用开辟了道路。

Abstract: Non-Gaussian states of light are a critical resource for fault-tolerant quantum computing and enhanced metrology, but are typically faint and often obtained via post-selection. Here, we demonstrate the deterministic generation of a bright non-Gaussian state by introducing a Kerr nonlinearity to a macroscopic state of light called bright squeezed vacuum (BSV). To characterize the resulting state, we use a single-shot f-2f interferometer to sample its Husimi function. We observe a clear transformation from a 2D Gaussian distribution to an 'S'-shaped non-Gaussian profile, which is the direct statistical evidence of the intensity-dependent nonlinear phase. The negativity of the Wigner function, which is an intrinsic property of any pure non-Gaussian state, cannot be observed because BSV is a mixed state even under minute optical loss. However, we show that BSV can be considered as a mixture of pure squeezed coherent states, for some of which Kerr-induced Wigner-function negativity is quite tolerant to loss. This work bridges the gap between quantum optics and ultrafast nonlinear optics, opening a path to quantum applications that require high photon flux.

</details>


### [43] [Domain-Aware Quantum Circuit for QML](https://arxiv.org/abs/2512.17800)
*Gurinder Singh,Thaddeus Pellegrini,Kenneth M. Merz,*

Main category: quant-ph

TL;DR: 提出了一种领域感知量子电路（DAQC），利用图像先验通过非重叠DCT式之字形窗口引导局部保持编码和纠缠，在NISQ设备上实现高性能量子机器学习图像分类。


<details>
  <summary>Details</summary>
Motivation: 在噪声中等规模量子（NISQ）设备上设计既具有表达力、可训练性，又能抵抗硬件噪声的参数化量子电路（PQCs）是量子机器学习的核心挑战。现有方法在深度和全局纠缠方面容易遇到贫瘠高原效应。

Method: 提出领域感知量子电路（DAQC），利用图像先验通过非重叠DCT式之字形窗口引导局部保持编码和纠缠。采用交错编码-纠缠-训练循环，纠缠操作在承载相邻像素的量子比特之间进行，与设备连接性对齐。这种分阶段、局部保持的信息流扩展了有效感受野，无需深度全局混合。

Result: 在MNIST、FashionMNIST和PneumoniaMNIST数据集上评估。在量子硬件上，DAQC性能与强大的经典基线（ResNet-18/50、DenseNet-121、EfficientNet-B0）相当，并大幅优于量子电路搜索（QCS）基线。仅使用量子特征提取器和线性经典读出层就实现了目前量子硬件上QML图像分类任务的最佳报告性能。

Conclusion: DAQC通过利用图像先验引导局部保持编码和纠缠，有效缓解了深度诱导和全局纠缠的贫瘠高原效应，在有限深度和量子比特条件下实现了高性能量子机器学习图像分类，为NISQ设备上的QML应用提供了有前景的解决方案。

Abstract: Designing parameterized quantum circuits (PQCs) that are expressive, trainable, and robust to hardware noise is a central challenge for quantum machine learning (QML) on noisy intermediate-scale quantum (NISQ) devices. We present a Domain-Aware Quantum Circuit (DAQC) that leverages image priors to guide locality-preserving encoding and entanglement via non-overlapping DCT-style zigzag windows. The design employs interleaved encode-entangle-train cycles, where entanglement is applied among qubits hosting neighboring pixels, aligned to device connectivity. This staged, locality-preserving information flow expands the effective receptive field without deep global mixing, enabling efficient use of limited depth and qubits. The design concentrates representational capacity on short-range correlations, reduces long-range two-qubit operations, and encourages stable optimization, thereby mitigating depth-induced and globally entangled barren-plateau effects. We evaluate DAQC on MNIST, FashionMNIST, and PneumoniaMNIST datasets. On quantum hardware, DAQC achieves performance competitive with strong classical baselines (e.g., ResNet-18/50, DenseNet-121, EfficientNet-B0) and substantially outperforming Quantum Circuit Search (QCS) baselines. To the best of our knowledge, DAQC, which uses a quantum feature extractor with only a linear classical readout (no deep classical backbone), currently achieves the best reported performance on real quantum hardware for QML-based image classification tasks. Code and pretrained models are available at: https://github.com/gurinder-hub/DAQC.

</details>


### [44] [Quantum Wasserstein distance for Gaussian states](https://arxiv.org/abs/2512.17809)
*Anaelle Hertz,Mohammad Ahmadpoor,Oleksandr Dzhenzherov,Augusto Gerolin,Khabat Heshami*

Main category: quant-ph

TL;DR: 本文给出了任意两个单模高斯态之间的二阶Wasserstein距离的一般公式，并讨论了如何从该公式恢复经典高斯分布和热态的量子Wasserstein距离。


<details>
  <summary>Details</summary>
Motivation: 量子最优传输和量子Wasserstein距离在量子态区分和量子计量学中具有重要意义。本文旨在建立单模高斯态之间的Wasserstein距离的通用计算方法。

Method: 基于De Palma和Trevisan提出的量子最优传输形式化方法，推导出任意两个单模高斯态之间的二阶Wasserstein距离的一般公式。

Result: 得到了单模高斯态之间Wasserstein距离的封闭形式解，能够恢复经典高斯分布和热态的量子Wasserstein距离作为特例。

Conclusion: 该工作为直接比较各种已知距离度量与Wasserstein距离提供了路径，通过封闭形式解促进了量子最优传输理论的发展。

Abstract: Optimal transport between classical probability distributions has been proven useful in areas such as machine learning and random combinatorial optimization. Quantum optimal transport, and the quantum Wasserstein distance as the minimal cost associated with transforming one quantum state to another, is expected to have implications in quantum state discrimination and quantum metrology. In this work, following the formalism introduced in [De Palma, G. and Trevisan, D. Ann. Henri Poincaré, {\bf 22} (2021), 3199-3234] to compute the optimal transport plan between two quantum states, we give a general formula for the Wasserstein distance of order 2 between any two one-mode Gaussian states. We discuss how the Wasserstein distance between classical Gaussian distributions and the quantum Wasserstein distance by De Palma and Trevisan for thermal states can be recovered from our general formula for Gaussian states. This opens the path to directly compare various known distance measures with the Wasserstein distance through their closed-form solutions.

</details>


### [45] [Low-loss frequency-tunable Josephson junction array cavities on Ge/SiGe heterostructures with a tapered etching approach](https://arxiv.org/abs/2512.17812)
*Franco De Palma,Elena Acinapura,Wonjin Jang,Fabian Oppliger,Radha Krishnan,Arianna Nigro,Ilaria Zardo,Pasquale Scarlino*

Main category: quant-ph

TL;DR: 通过刻蚀Ge/SiGe异质结构至高阻Si衬底，并在其上直接图案化超导腔，实现了高质量因子的微波谐振器，为Ge基量子器件与超导电路的集成提供了可行方案。


<details>
  <summary>Details</summary>
Motivation: Ge/SiGe异质结构是量子器件的理想平台，但由于材料堆栈中的缺陷，与高质量微波超导腔的兼容性一直是个挑战。需要找到一种方法将超导腔与Ge量子器件有效集成。

Method: 采用反向梯度Ge/SiGe异质结构，将约1.6μm厚的Ge/SiGe堆栈完全刻蚀至高阻Si衬底，直接在衬底上图案化超导腔。设计了锥形台面结构，使超导腔能够轻松跨越台面到达Ge量子阱中的量子器件。

Result: 实现了高质量因子的谐振器：可调频率约瑟夫森结阵列谐振器的内部品质因子Qi≈10000-20000（受限于结的制备），50Ω共面波导Nb剥离谐振器的Qi≈100000。这些Qi值在跨越台面区域时仍能保持，与高阻Si晶圆参考样品相当。

Conclusion: 该工作为超导-半导体混合器件提供了实用的实现路径，可直接应用于平面Ge新兴技术，解决了Ge基量子器件与超导电路集成的关键挑战。

Abstract: Ge/SiGe heterostructures represent a promising platform for hosting various quantum devices such as hole spin qubits and Andreev spin qubits. However, the compatibility of such heterostructures with high-quality-factor microwave superconducting cavities remains a challenge due to defects in the material stack. In this work, we present an approach to enhance the coherence of cavity modes on a reverse-graded Ge/SiGe heterostructure, which consists of etching the full $\sim 1.6~\mathrm{μm}$-thick Ge/SiGe stack down to its starting high-resistivity Si substrate, in order to pattern superconducting cavities directly on it. We engineer the mesa step to be tapered, so that it can be easily climbed by the superconducting cavities to reach the quantum devices potentially hosted in the Ge quantum well. Using this approach, we observe internal quality factors of $Q_\mathrm{i} \approx 10000-20000$ for high-impedance frequency-tunable Josephson junction array resonators, limited by the junctions' fabrication, and $Q_\mathrm{i} \approx 100000$ for $50~\mathrmΩ$ coplanar waveguide Nb lift-off resonators. These $Q_\mathrm{i}$ are preserved despite the overlap with the mesa structure in the climbing region, and are comparable to the ones obtained for identical resonators fabricated on a high-resistivity Si wafer reference. Thereby, this work paves a practical path toward superconductor-semiconductor hybrid devices, immediately applicable to emerging technologies on planar Ge.

</details>


### [46] [Simulation of topological superconductors and their competing orders using photon-mediated interactions](https://arxiv.org/abs/2512.17889)
*Anjun Chu,Joyce Kwan,Eric Yilun Song,Seth Hew Peng Chew,James K. Thompson,Ana Maria Rey*

Main category: quant-ph

TL;DR: 提出一种腔QED量子模拟器，通过调控腔介导的耦合来工程化竞争的手性p波和d波超导序，实现拓扑超导相的可控模拟和测量。


<details>
  <summary>Details</summary>
Motivation: 拓扑超导体中非常规配对的实际实现和控制仍然是一个核心挑战。固态系统和超冷原子系统中难以实现和观察竞争性拓扑超导相。

Method: 引入腔QED量子模拟器，通过设计腔介导的原子赝自旋耦合来模拟动量依赖的配对通道。利用腔QED系统中自然存在的不等腔-晶格波长来工程化空间非均匀的腔介导耦合。

Result: 该平台能够实现受控态制备和超导序参数的连续测量，揭示了平衡态和猝灭设置下的单一主导配对通道相，以及竞争配对通道的共存区域。可以直接观察平衡和非平衡下的拓扑转变。

Conclusion: 该腔QED量子模拟器为模拟在固态和超冷原子系统中难以实现的竞争性拓扑超导相提供了一条强大途径，实现了拓扑超导相的可控工程化和直接观测。

Abstract: Realizing and controlling the unconventional pairing featured by topological superconductors remains a central challenge. We introduce a cavity QED quantum simulator that engineers competing chiral $p_x+ip_y$ and $d_{x^2-y^2}+id_{xy}$ orders by tailoring cavity-mediated couplings between atomic pseudospins that emulate momentum-dependent pairing channels. The desired spatially inhomogeneous cavity-mediated couplings can be engineered in a 2D optical lattice using incommensurate cavity-lattice wavelengths naturally occurring in cavity QED systems. This minimal and fully tunable platform enables controlled state preparation and continuous measurement of superconducting order parameters, revealing phases in both equilibrium and sudden-quench settings with a single dominant pairing channel, as well as coexistence regimes with competing pairing channels. Crucially, our implementation allows direct observation of topological transitions in and out of equilibrium, providing a powerful route to the quantum simulation of competing topological superconducting phases that remain elusive in solid-state and ultracold-atom systems.

</details>


### [47] [Exploring the Effect of Basis Rotation on NQS Performance](https://arxiv.org/abs/2512.17893)
*Sven Benjamin Kožić,Vinko Zlatić,Fabio Franchini,Salvatore Marco Giampaolo*

Main category: quant-ph

TL;DR: 通过可解析求解的一维Ising模型，研究局部基旋转如何改变目标波函数在参数空间中的位置，揭示浅层神经量子态优化中的信息几何障碍（鞍点和高曲率区域）。


<details>
  <summary>Details</summary>
Motivation: 神经量子态的性能依赖于基的选择，但其底层机制尚不清楚。需要理解基旋转如何影响优化过程，特别是浅层架构（如受限玻尔兹曼机）在变分训练中的表现。

Method: 使用完全可解的一维Ising模型，通过局部基旋转改变波函数在参数空间中的位置，计算量子Fisher信息和Fubini-Study距离，分析旋转角度对损失函数景观的影响。研究浅层架构（特别是RBM）使用量子自然梯度训练时的优化行为。

Result: 局部基旋转不改变损失函数景观，但将精确波函数重新定位在参数空间中，增加了其与典型初始化的几何距离。浅层架构（RBM）训练时容易陷入鞍点区域，在铁磁情况下，近简并本征态产生高曲率障碍，导致优化停滞在中等保真度。

Conclusion: 基旋转暴露了损失函数景观中的信息几何障碍（鞍点和高曲率区域），这些障碍阻碍浅层神经量子态的优化。研究强调了在变分训练中需要基于景观感知的模型设计。

Abstract: Neural Quantum States (NQS) use neural networks to represent wavefunctions of quantum many-body systems, but their performance depends on the choice of basis, yet the underlying mechanism remains poorly understood. We use a fully solvable one-dimensional Ising model to show that local basis rotations leave the loss landscape unchanged while relocating the exact wavefunction in parameter space, effectively increasing its geometric distance from typical initializations. By sweeping a rotation angle, we compute quantum Fisher information and Fubini-Study distances to quantify how the rotated wavefunction moves within the loss landscape. Shallow architectures (with focus on Restricted Boltzmann Machines (RBMs)) trained with quantum natural gradient are more likely to fall into saddle-point regions depending on the rotation angle: they achieve low energy error but fail to reproduce correct coefficient distributions. In the ferromagnetic case, near-degenerate eigenstates create high-curvature barriers that trap optimization at intermediate fidelities. We introduce a framework based on an analytically solvable rotated Ising model to investigate how relocating the target wavefunction within a fixed loss landscape exposes information-geometric barriers,such as saddle points and high-curvature regions,that hinder shallow NQS optimization, underscoring the need for landscape-aware model design in variational training.

</details>


### [48] [Visualizing Detection Efficiency in Optomechanical Scattering](https://arxiv.org/abs/2512.17894)
*Youssef Tawfik,Shan Hao,Thomas P. Purdy*

Main category: quant-ph

TL;DR: 提出一种可视化光学测量效率的新方法，通过映射探测器表面的局部贡献来优化信息提取，实验证明遮挡部分光电探测器能提高运动检测灵敏度


<details>
  <summary>Details</summary>
Motivation: 许多光学测量技术（如波长尺度粒子的光散射或光学杠杆检测表面运动）将信息编码在复杂的辐射模式中。提取所有可用信息对量子增强传感协议至关重要，但通常不切实际，因为需要多个通道来空间分辨散射信号。

Method: 提出一种新方法来可视化实际测量方案如何高效捕获散射光中的可用信息，通过映射探测器表面的局部贡献来检测效率。使用该工具实验优化了用象限光电二极管对光机械谐振器运动幅度的自由空间测量。

Result: 实验证明遮挡部分光电探测器能增强灵敏度，反直觉地显著提高了系统中高阶机械模式的检测能力。该方法也可应用于小粒子的光散射测量。

Conclusion: 该方法提供了一种优化光学测量效率的有效工具，通过可视化探测器表面的信息分布，能够指导实验设计并提高测量灵敏度，特别是在量子增强传感和精密测量领域具有应用价值。

Abstract: Many optical measurement techniques, such as light scattering from wavelength-scale particles or detecting motion from a surface with an optical lever, encode information in a complex radiation pattern. Extracting all available information is essential for many quantum-enhanced sensing protocols but is often impractical, as it requires many channels to spatially resolve the scattered signal. We present a new method to visualize how efficiently a practical measurement scheme captures the information available in the scattered light by mapping out the local contribution to the detection efficiency on the detector surface. We use this tool to experimentally optimize the free space measurement of the amplitude of motion of an optomechanical resonator with a quadrant photodiode. We show that blocking sections of the photodetector enhances sensitivity, counterintuitively yielding a significant improvement in detecting higher-order mechanical modes in the system. We also show how our method can be applied to light scattering measurements of small particles.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [49] [Double-trace instability of BTZ black holes](https://arxiv.org/abs/2512.16982)
*Oscar J. C. Dias,David Sola Gil,Jorge E. Santos*

Main category: gr-qc

TL;DR: 旋转BTZ黑洞在双迹边界条件下对质量标量场扰动不稳定，包括轴对称和非轴对称模式，其中轴对称不稳定占主导。这种不稳定源于边界能量角动量流入，而非超辐射效应。


<details>
  <summary>Details</summary>
Motivation: 研究旋转BTZ黑洞在双迹边界条件下的线性稳定性，探索不同于标准边界条件（狄利克雷和诺伊曼）下的稳定性行为，理解双迹变形如何影响黑洞稳定性。

Method: 对旋转BTZ黑洞进行质量标量场扰动的全面线性稳定性分析，采用双迹边界条件，研究轴对称和非轴对称模式的稳定性，绘制参数空间中的稳定性边界曲线。

Result: 发现BTZ黑洞在双迹边界条件下会出现不稳定：1）不仅非轴对称模式不稳定，轴对称模式也不稳定；2）轴对称不稳定是主导和最基本的；3）确定了BTZ不稳定而全局AdS₃稳定的参数区域，绘制了完整的稳定性边界曲线。

Conclusion: 双迹边界条件会导致BTZ黑洞不稳定，这种不稳定源于边界能量角动量流入而非超辐射效应，为理解高维旋转AdS黑洞的双迹不稳定提供了原型，并暗示存在带标量凝聚的旋转毛状黑洞解。

Abstract: We perform a comprehensive study of the linear stability of rotating BTZ black holes under massive scalar field perturbations with double-trace boundary conditions. While BTZ black holes are stable under standard Dirichlet and Neumann boundary conditions, we demonstrate that they can develop instabilities when subjected to double-trace boundary conditions. Our key findings are threefold. First, we show that BTZ black holes exhibit instabilities not only for non-axisymmetric modes $\unicode{x2013}$ previously the only known unstable sector $\unicode{x2013}$ but crucially also for axisymmetric modes. Second, we prove that the axisymmetric instability is the dominant and most fundamental: configurations unstable to any non-axisymmetric mode are already unstable to the axisymmetric one. Third, we identify regions in the BTZ parameter space where these black holes are unstable while global AdS$_3$ remains stable, and we map the complete onset curves that determine the corresponding stability boundaries. Unlike conventional superradiant instabilities, the BTZ double-trace instability occurs for angular velocities always satisfying the Hawking-Reall bound. We trace the physical origin of these instabilities to the influx of energy and angular momentum through the asymptotic boundary permitted by double-trace deformations for a particular sign of the coupling, rather than to near-horizon effects. Our results provide a prototype for understanding double-trace instabilities in higher-dimensional rotating AdS black holes and suggest the existence of rotating hairy black hole solutions with scalar condensates, which we construct in a companion paper.

</details>


### [50] [A novel violation of the equivalence principle](https://arxiv.org/abs/2512.17020)
*Saurya Das,Mitja Fridman,Sourav Sur*

Main category: gr-qc

TL;DR: 论文提出惯性质量与引力质量的差异可能取决于物体与引力体的距离，而非仅由其内部成分决定，并提出了检验方法和协变框架。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为惯性质量与引力质量的差异（等效原理违反）仅由物体内部成分和相互作用决定。本文挑战这一假设，探索这种差异是否可能随物体与引力体的距离而变化。

Method: 提出协变框架来分析惯性质量与引力质量差异的距离依赖性，并设计具体的实验检验方法来验证这一假设。

Result: 理论上证明了惯性质量与引力质量的差异可以成为物体与引力体距离的函数，而非仅由内部性质决定。

Conclusion: 等效原理违反可能具有距离依赖性，这为检验基本物理原理提供了新方向，并需要重新思考质量差异的起源。

Abstract: It is generally assumed that any discrepancy between an object's inertial and gravitational masses, leading to a violation of the equivalence principle, arises from the nature of its internal constituents and their interactions. We show here that the difference can instead be a function of the distance of the object from a gravitating body, and suggest ways of testing this, illustrating side-by-side a covariant framework for the same.

</details>


### [51] [Deviations from Gaussian White Noise in Stochastic Inflation](https://arxiv.org/abs/2512.17070)
*Zahra Ahmadi,Mahdiyar Noorbala*

Main category: gr-qc

TL;DR: 随机通胀框架中噪声特性的研究：偏离de Sitter背景、尖锐截断函数和Bunch-Davies初态假设如何影响噪声的颜色、平稳性和高斯性。


<details>
  <summary>Details</summary>
Motivation: 随机通胀框架广泛用于研究通胀时空中的标量场扰动，但传统方法基于多个假设（de Sitter背景、Heaviside窗函数、Bunch-Davies初态）导致白噪声驱动。研究这些假设放松后噪声特性的变化对于理解随机通胀框架的鲁棒性和适用范围具有重要意义。

Method: 通过理论分析研究三种假设放松对噪声特性的影响：1）偏离de Sitter背景；2）使用非Heaviside窗函数（以分段线性窗函数为例）；3）偏离Bunch-Davies初态。计算噪声的功率谱和记忆特性，分析噪声的颜色、平稳性和高斯性变化。

Result: 1）偏离de Sitter背景仅改变噪声振幅的时间依赖性，仍保持白噪声特性；2）偏离尖锐截断窗函数或Bunch-Davies初态会产生有色噪声；3）分段线性窗函数模型显示有色噪声特性；4）偏离Bunch-Davies初态需要两粒子态叠加才能产生有色噪声，且噪声非平稳；5）偏离de Sitter背景和尖锐截断不影响高斯性，但改变初态会导致非高斯噪声。

Conclusion: 随机通胀框架中的噪声特性对基本假设敏感：背景几何变化仅影响振幅，窗函数和初态变化会显著改变噪声的颜色、平稳性和高斯性。这为理解随机通胀框架的适用范围和潜在修正提供了理论基础。

Abstract: Stochastic inflation is widely used as a framework to study scalar field perturbations on an inflationary spacetime in a classical manner. In Starobinsky's seminal work and most of the subsequent literature, stochastic inflation is driven by a white noise. This is a consequence of a number of assumptions about the background metric, the window function, and the initial state. Given that noise is the central object in this approach, it is worthwhile to investigate how the noise is modified upon relaxing some of these assumptions. We show that while deviation from an exact de Sitter background maintains the white character of the noise (only with a time-dependent amplitude), deviation from the Heaviside window function or the Bunch-Davies initial state can produce colored noise. We calculate the power spectrum and the memory of the noise for a toy model with a piecewise linear window function. We also show that, in order to produce a colored noise, the deviation from the Bunch-Davies vacuum should essentially be a sum of two-particle states. The resulting noise is non-stationary and we find its instantaneous power spectrum in a concrete example. Furthermore, while deviations from de Sitter background and sharp cutoff do not affect Gaussianity, changing the initial state yields a non-Gaussian noise.

</details>


### [52] [A Search for Binary Black Hole Mergers in LIGO O1-O3 Data with Convolutional Neural Networks](https://arxiv.org/abs/2512.17204)
*Ethan Silver,Plamen Krastev,Edo Berger*

Main category: gr-qc

TL;DR: 使用神经网络检测引力波事件的机器学习流程，在LIGO前三个观测期中成功检测到57个已编目黑洞合并事件


<details>
  <summary>Details</summary>
Motivation: 引力波天文学快速发展，但传统检测方法计算量大、速度慢。神经网络有望显著加速引力波事件的检测、分类和参数估计，这对电磁对应体的及时观测至关重要。

Method: 开发机器学习流程，使用真实LIGO数据生成训练数据，训练和优化神经网络来检测双黑洞合并事件。将该模型应用于搜索LIGO的前三个观测期数据。

Result: 在O1、O2、O3观测期的75个已编目双黑洞事件中，成功检测到57个事件，同时产生57个误报（可通过参数推断和人工检查排除）。通过时间偏移数据广泛测试了假警报率。

Conclusion: 该研究是开发基于机器学习的引力波搜索的重要一步，为实现低延迟检测和多信使天文学奠定了基础。

Abstract: Since the first detection of gravitational waves in 2015 by LIGO from the binary black hole merger GW150914, gravitational wave astronomy has developed significantly, with over 200 compact binary merger events cataloged. The use of neural networks has the potential to significantly speed up the detection, classification, and especially parameter estimation for gravitational wave events, compared to current techniques, quite important for electromagnetic follow-up of events. In this work, we present a machine learning pipeline using neural networks to detect gravitational wave events. We generate training data using real LIGO data to train and refine neural networks that can detect binary black hole (BBH) mergers, and apply these models to search through LIGO's first three observing runs. We detect 57 out of the 75 total cataloged BBH events with two detectors of data in O1, O2, and O3, with 57 false positives that can mostly be ruled out with parameter inference and human inspection. Finally, we extensively test this pipeline on time-shifted data to characterize its False Alarm Rate (FAR). These results are an important step in developing machine learning-based GW searches, enabling low-latency detection and multi-messenger astronomy.

</details>


### [53] [Quasinormal modes of thick branes in $f(R)$ gravity](https://arxiv.org/abs/2512.17208)
*Yu-Peng E,Chun-Chun Zhu,Yu-Xiao Liu*

Main category: gr-qc

TL;DR: 在f(R)引力理论中，通过三种数值方法系统研究了厚膜模型的准正规模，发现势垒结构对频谱有重要影响，准局域态可理解为势垒间的共振。


<details>
  <summary>Details</summary>
Motivation: 研究f(R)引力理论中厚膜模型的引力扰动准正规模，理解势垒结构如何影响准正规模频谱，探索准局域态的物理本质。

Method: 采用三种互补数值方法：渐近迭代法、波动方程直接积分法、时域数值演化法，求解引力扰动的薛定谔型方程，分析模型参数对有效势的影响。

Result: 三种方法结果高度一致，势垒结构对准正规模频谱有显著影响，准正规模实部近似呈等差数列，表明准局域态可理解为势垒间的共振。

Conclusion: f(R)引力厚膜模型的准正规模可通过势垒结构理解，准局域态表现为势垒间共振，数值结果可靠，为相关引力理论研究提供参考。

Abstract: We systematically investigate the quasinormal modes of thick branes in $f(R)$ gravity by numerically solving the Schrödinger-like perturbation equation of gravitational perturbations. To ensure the reliability of the results, we employ three complementary methods: the asymptotic iteration method, the direct integration of the wave equation, and the time-domain numerical evolution. We analyze how the model parameters influence the shape of the effective potential of gravitational perturbations and find that the structure of the potential barrier plays a significant role in shaping the quasinormal frequency spectrum. The results obtained from the three methods exhibit strong consistency, thereby ensuring the reliability of the calculations. In particular, the real parts of the quasinormal frequencies exhibit an approximately arithmetic progression, suggesting that the quasi-localized states can be understood as resonances between the barriers.

</details>


### [54] [Interplay of Lyapunov exponents, phase transitions and chaos bound in nonlinear electrodynamics black hole](https://arxiv.org/abs/2512.17242)
*Chuanhong Gao,Chuang Yang,Tetvui Chong,Deyou Chen*

Main category: gr-qc

TL;DR: 研究非线性电动力学黑洞周围无质量和带电粒子的李雅普诺夫指数，发现这些指数能有效揭示相变，且在相变期间混沌界限的违反仅发生在小黑洞的稳定分支中


<details>
  <summary>Details</summary>
Motivation: 探索非线性电动力学黑洞的混沌特性（李雅普诺夫指数）与相变之间的关系，以及混沌界限的违反情况

Method: 研究无质量和带电粒子在非线性电动力学黑洞周围的李雅普诺夫指数，分析这些指数与黑洞相变及混沌界限的关系

Result: 李雅普诺夫指数能有效揭示相变；相变期间混沌界限的违反仅发生在小黑洞的稳定分支中；无论是否发生相变，都能观察到混沌界限的违反

Conclusion: 李雅普诺夫指数是探测非线性电动力学黑洞相变的有效工具，混沌界限的违反现象在特定条件下出现，为理解黑洞热力学与混沌动力学的关系提供了新见解

Abstract: In this paper, we investigate Lyapunov exponents of chaos for both massless and charged particles around a non-linear electrodynamics black hole, and explore their relationships with a phase transition and a chaos bound of this black hole. Our results indicate that these exponents can effectively reveal the phase transition. Specifically, during the phase transition, the violation of the chaos bound occurs solely within a stable branch of a small black hole. Moreover, regardless of whether the phase transition takes place, the violations are observed.

</details>


### [55] [Between two descriptions of dark matter around a black hole: photon sphere, shadow, and lensing](https://arxiv.org/abs/2512.17304)
*M. F. Fauzi,H. S. Ramadhan,A. Sulaksono*

Main category: gr-qc

TL;DR: 比较两种各向异性暗物质分布模型（真空模型和爱因斯坦星团模型）在黑洞周围的观测差异，重点关注光子球、阴影半径和透镜效应


<details>
  <summary>Details</summary>
Motivation: 研究两种广泛使用的各向异性暗物质分布模型在黑洞周围的观测差异，以了解不同径向压力特性（负压和零压）如何影响黑洞的观测特征

Method: 分析真空模型（负径向压力）和爱因斯坦星团暗物质模型（零径向压力）的光子球、阴影半径和透镜观测量的理论计算与比较

Result: 两种模型显示出不同的光子球行为，爱因斯坦星团模型相对于标准史瓦西黑洞在阴影半径上表现出更显著的偏差，两种模型中都发现了与物质晕相关的独特透镜现象

Conclusion: 不同暗物质分布模型对黑洞观测特征有显著影响，特别是爱因斯坦星团模型在阴影半径上表现出更强的偏离，这为通过观测区分不同暗物质模型提供了可能性

Abstract: We examine observational discrepancies of two widely used models describing anisotropic (dark) matter distributions around a black hole, focusing on their photon spheres, shadow radii, and lensing observables. The models considered are the vacuum and Einstein cluster dark matter model, characterized by negative and zero radial pressure, respectively. The analysis reveals that these models display contrasting photon sphere behavior. In particular, the Einstein cluster results in a more pronounced deviation in the shadow radius relative to the standard Schwarzschild black hole. Additionally, a distinctive lensing phenomenon associated with the matter halo is identified in both models.

</details>


### [56] [A Monte Carlo approach to stationary kinetic disks in the Kerr spacetime](https://arxiv.org/abs/2512.17346)
*Ghafran Khan,Patryk Mach*

Main category: gr-qc

TL;DR: 将广义相对论Vlasov方程的蒙特卡洛求解方案扩展到Kerr时空，研究赤道平面上无限延伸的薄盘气体配置


<details>
  <summary>Details</summary>
Motivation: 扩展现有的广义相对论Vlasov方程求解方法到更一般的Kerr时空，研究黑洞周围气体薄盘的动力学行为

Method: 采用蒙特卡洛方法计算Kerr时空中Vlasov方程的稳态解，研究赤道平面上的薄盘配置，包括单能模型和无穷远处平面Maxwell-Jüttner分布

Result: 成功恢复了粒子电流面密度的分量，并分析了薄盘动力学模型的角动量和角速度等特性

Conclusion: 蒙特卡洛框架能够有效处理Kerr时空中的Vlasov方程，为研究黑洞周围气体薄盘的动力学提供了新工具

Abstract: We extend a recently proposed Monte Carlo scheme for computing stationary solutions of the general-relativistic Vlasov equation to the Kerr spacetime. As an example, we focus on razor-thin configurations of a gas confined to the equatorial plane and extending to spatial infinity. We consider monoenergetic models as well as solutions corresponding to planar Maxwell-Jüttner distributions at infinity. In both cases, the components of the particle current surface density are recovered within the proposed Monte Carlo framework. Some aspects of razor-thin kinetic disk models, including an analysis of the bulk angular momentum and angular velocity, are briefly covered.

</details>


### [57] [Ghost-free 2-form fields in cosmology: implications for gravitational parity violation](https://arxiv.org/abs/2512.17348)
*Yuki Horii,Tomoaki Murata,Tsutomu Kobayashi*

Main category: gr-qc

TL;DR: 该论文研究了保持与有质量2-形式场相同动力学自由度的宇称破坏、非最小耦合2-形式场理论，发现宇称破坏项可通过场重定义吸收，仅势能项可包含宇称破坏效应，并在宇宙学模型中展示了手性引力波的产生。


<details>
  <summary>Details</summary>
Motivation: 探索宇称破坏的非最小耦合2-形式场理论，同时保持理论无鬼场（ghost-free），研究此类理论在宇宙学中产生手性引力波的可能性。

Method: 从最一般的动能项和维度四耦合项出发，寻找保持动力学自由度不变的2-参数理论族；通过场重定义分析宇称破坏项；在均匀各向同性宇宙学模型中，研究三重2-形式场配置下的张量扰动。

Result: 发现宇称破坏项可通过场重定义吸收到势能项中；在宇宙学模型中识别出三种张量扰动类型（两种是动力学的）；证明在势能项包含宇称破坏项时，可以产生手性引力波。

Conclusion: 宇称破坏的2-形式场理论可通过场重定义简化为与Heisenberg和Trenkler类似的结构，宇称破坏效应仅出现在势能项中，且此类理论能够在宇宙学中产生手性引力波。

Abstract: We explore the possibility of parity-violating, nonminimally coupled 2-form field theories that retain the same dynamical degrees of freedom as a massive 2-form and thus are ghost-free. Starting from the most general kinetic terms and dimension four couplings between the 2-form field and the curvature tensors, we find a two-parameter family of such theories. However, we also find that parity-violating terms involving the dual 2-form field can be absorbed into a field redefinition, leaving a theory with essentially the same structure as that obtained by Heisenberg and Trenkler (i.e., the parity-preserving coupling to the double dual Riemann tensor). After the field redefinition, the only place where parity-violating terms can appear is in the potential. We then consider a homogeneous and isotropic cosmological model with an isotropic configuration of a triplet of 2-form fields, and study tensor perturbations in this setup. There are three types of tensor perturbations, two of which are dynamical. We show that chiral gravitational waves can be generated in the presence of parity-violating terms in the potential.

</details>


### [58] [Origin of Quasi-Periodic Oscillations and Accretion Process in X-Ray Binaries around Quantum Lee-Wick Black Hole](https://arxiv.org/abs/2512.17358)
*Orhan Donmez,G. Mustafa,M. Yousaf,Faisal Javed,Ikhtiyor Saidov,Farruh Atamurotov*

Main category: gr-qc

TL;DR: 研究Lee-Wick黑洞的吸积动力学和测试粒子运动，分析模型参数如何影响轨道稳定性和X射线双星系统中的准周期振荡，通过解析分析和数值模拟揭示Lee-Wick参数对吸积流形态和频率比的影响。


<details>
  <summary>Details</summary>
Motivation: 研究Lee-Wick黑洞的吸积动力学，探索高阶导数引力理论的可观测特征，特别是模型参数如何影响轨道稳定性、准周期振荡和吸积流形态，为通过多波段观测测试高阶导数引力理论提供途径。

Method: 1. 使用有效势方法推导测试粒子的比能量、角动量、本轮频率和最内稳定圆轨道位置；2. 进行广义相对论流体动力学模拟，分析Bondi-Hoyle-Lyttleton吸积产生的激波锥形态；3. 比较弱Lee-Wick参数（Block-1）和强Lee-Wick参数（Block-2）两种典型状态。

Result: 1. Block-1解与史瓦西黑洞情况相似；2. Block-2模型产生更密集、不对称的激波锥，伴随更强的准周期振荡活动，从低频向高频准周期振荡转变；3. Lee-Wick参数S1和S2显著改变吸积流形态和黑洞附近的频率比。

Conclusion: Lee-Wick参数对吸积动力学产生可观测的影响，特别是在强参数状态下产生独特的吸积流形态和频率特征，这些特征可能在高分辨率X射线时序数据中被探测到，为通过多波段观测测试高阶导数引力理论提供了重要途径。

Abstract: In this study, we investigate the accretion dynamics and test particle motion around a non-rotating, spherically symmetric Lee-Wick black hole (BH) to reveal how the model parameters affect orbital stability and the quasi-periodic oscillations (QPOs) observed in X-ray binary systems. The spacetime geometry, characterized by the BH mass and the coupling parameters $S_1$ and $S_2$, includes exponential and oscillatory corrections arising from the Lee-Wick terms. Using the effective potential approach, we derive specific energy, angular momentum, epicyclic frequencies, and the locations of the innermost stable circular orbits (ISCOs) of test particles. In addition to the analytical analysis, we explore the effects of the Lee-Wick spacetime parameters on the shock-cone morphology produced by Bondi-Hoyle-Lyttleton (BHL) accretion. To this end, we perform general relativistic hydrodynamic simulations in two characteristic regimes: Block-1 (weak Lee-Wick regime) and Block-2 (strong Lee-Wick regime). The results show that Block-1 solutions closely resemble the Schwarzschild case, while Block-2 models develop denser and asymmetric shock cones accompanied by stronger QPOs activity, shifting from low-frequency to high-frequency QPOs. These variations yield distinct observational signatures that may be detectable in high-resolution X-ray timing data. Our analytical and numerical findings demonstrate that the Lee-Wick parameters $S_1$ and $S_2$ cause measurable changes in the morphology of the accretion flow and in the frequency ratios near the BH. This suggests that future multi-wavelength observations could provide an important avenue to test higher-derivative gravity theories.

</details>


### [59] [Generalized Kerr-Schild gauge](https://arxiv.org/abs/2512.17369)
*Enrique Alvarez,Jesus Anero*

Main category: gr-qc

TL;DR: 将Kerr-Schild规范推广到变形向量非零的情况，证明变形向量必须是背景时空的测地线才能保证变形后的度规是Ricci平坦的


<details>
  <summary>Details</summary>
Motivation: 传统的Kerr-Schild规范要求变形向量是零向量，本文旨在推广这一规范，允许变形向量非零，探索更一般的度规变形理论

Method: 将Kerr-Schild规范推广到变形向量非零的情况，分析曲率张量的有限展开，证明关于变形度规Ricci平坦条件的定理

Result: 发现即使变形向量非零，曲率张量仍能保持有限展开，并证明变形度规为Ricci平坦的充要条件是变形向量必须是背景时空的测地线

Conclusion: 成功推广了Kerr-Schild规范，建立了非零变形向量下度规变形的理论框架，为广义相对论中的度规构造提供了新的数学工具

Abstract: The Kerr-Schild gauge is generalized to the case that the vector generating the deformation is not null. Contrary to naive expectations, this vector generates a finite expansion for the curvature tensor. We prove a theorem
  on the conditions for the deformed metric being Ricci flat, namely that the deformation vector must be geodesic of the background spacetime.

</details>


### [60] [Hydrodynamical Misner-Sharp Formulation for Gravitational Collapse in Scalar-Tensor Theories](https://arxiv.org/abs/2512.17526)
*Jose A. R. Cembranos,Luis Diaz-Gimenez*

Main category: gr-qc

TL;DR: 研究标量-张量引力理论中的引力坍缩问题，引入爱因斯坦框架下的新流体力学公式，获得平衡的TOV条件用于寻找有效初始状态，并展示坍缩初始阶段的最小版本及连接条件分析


<details>
  <summary>Details</summary>
Motivation: 在标量-张量引力理论框架下研究引力坍缩问题，传统方法在爱因斯坦框架下需要新的流体力学表述来处理这类理论中的引力坍缩现象

Method: 引入爱因斯坦框架下的新流体力学公式（受Misner和Sharp启发），推导平衡的Tolman-Oppenheimer-Volkoff条件，用于寻找有效初始状态，并分析相应的连接条件

Result: 获得了标量-张量引力理论中引力坍缩问题的平衡TOV条件，建立了寻找有效初始状态的框架，并展示了坍缩初始阶段的最小版本及其连接条件分析

Conclusion: 成功在标量-张量引力理论中建立了引力坍析的流体力学框架，为研究这类理论中的引力坍缩现象提供了新的工具和方法基础

Abstract: We study the problem of gravitational collapse in the context of scalar-tensor theories of Gravity. We introduce a new hydrodynamical formulation in the Einstein frame, inspired by that of Misner and Sharp. We obtain the equilibrium Tolman-Oppenheimer-Volkoff condition that we use to find valid initial states of the problem within this framework. For illustration purposes, we present the minimal version of the initial phases of the collapse together with an analysis of the corresponding junction conditions.

</details>


### [61] [Advantages and disadvantages of maximally entangled states in dilaton black hole background](https://arxiv.org/abs/2512.17535)
*Zhen Yang,He Cheng,Si-Han Li*

Main category: gr-qc

TL;DR: 在GHS膨胀子黑洞视界附近，非最大纠缠态可能比最大纠缠态提供更好的纠缠资源，而量子相干性则呈现单调行为：初始相干性越大，抵抗膨胀子诱导退化的鲁棒性越强。


<details>
  <summary>Details</summary>
Motivation: 研究在弯曲时空背景下，特别是GHS膨胀子黑洞附近，量子纠缠和相干性的行为，以了解引力效应对量子信息处理资源的影响。

Method: 分析四类类贝尔费米子态在GHS膨胀子黑洞事件视界附近的量子纠缠和相干性，比较最大纠缠态与非最大纠缠态的表现。

Result: 1. 最大纠缠态的纠缠度可能低于适当选择的非最大纠缠态；2. 量子相干性呈现单调行为：初始相干性越大，抵抗膨胀子诱导退化的能力越强。

Conclusion: 在膨胀子黑洞附近的量子信息处理中，最优初始量子态的选择敏感依赖于所需的量子资源类型（纠缠或相干性），非最大纠缠态在某些情况下可能提供操作优势。

Abstract: We investigate quantum entanglement and coherence for four classes of Bell-like fermionic states in the vicinity of the event horizon of a Garfinkle-Horowitz-Strominger (GHS) dilaton black hole. Contrary to the common expectation that maximally entangled states always provide superior quantum resources, our results show that their entanglement can be lower than that of suitably chosen non-maximally entangled states in this curved spacetime background. This reveals that non-maximally entangled states may offer operational advantages for entanglement-based tasks under gravitational effects. In contrast, quantum coherence exhibits monotonic behavior: larger initial coherence leads to systematically enhanced robustness against the dilaton induced degradation. These results indicate that the optimal choice of initial quantum states depends sensitively on the specific quantum resource, either quantum entanglement or quantum coherence, required for quantum information processing near a dilaton black hole.

</details>


### [62] [GW231123: Overlapping Gravitational Wave Signals?](https://arxiv.org/abs/2512.17550)
*Qian Hu,Harsh Narola,Jef Heynen,Mick Wright,John Veitch,Justin Janquart,Chris Van Den Broeck*

Main category: gr-qc

TL;DR: GW231123可能包含两个重叠的引力波信号，而非单一黑洞合并事件，这解释了不同波形模型间的测量差异。


<details>
  <summary>Details</summary>
Motivation: GW231123作为迄今探测到的最重黑洞合并事件，不同波形模型对其源属性的测量存在显著差异，这些差异无法通过模拟可靠复现，暗示可能存在未考虑的重叠信号或其他物理效应。

Method: 使用允许两个重叠信号的灵活模型分析GW231123数据，并与孤立信号模型比较贝叶斯因子，同时检验类似的高质量事件GW190521作为对照。

Result: 重叠信号模型显著优于孤立信号模型（贝叶斯因子~10^2-10^4），位于背景分布的前几个百分点；该模型基本消除了不同波形模型间的测量差异，且两个恢复的信号显示相似属性；在GW190521中未观察到类似效应。

Conclusion: GW231123很可能包含两个重叠的引力波信号，而非单一黑洞合并事件；忽略重叠信号会导致源属性估计出现与GW231123报道相似的差异，这对未来引力波数据分析具有重要意义。

Abstract: The recently discovered gravitational wave event GW231123 was interpreted as the merger of two black holes with a total mass of 190-265 $M_\odot$, making it the heaviest such merger detected to date. Whilst much of the post-discovery literature has focused on its astrophysical origins, primary analyses have exhibited considerable discrepancies in the measurement of source properties between waveform models, which cannot reliably be reproduced by simulations. Such discrepancies may arise when an unaccounted overlapping signal is present in the data, or from phenomena that produce similar effects, such as gravitational lensing or overlapping noise artifacts. In this work, we analyse GW231123 using a flexible model that allows for two overlapping signals, and find that it is favoured over the isolated signal model with Bayes factors of $\sim 10^2 - 10^{4}$, depending on the waveform model. These values lie within the top few per cent of the background distribution. Similar effects are not observed in GW190521, another high-mass event. Under the overlapping signals model, discrepancies in the measurement of source properties between waveform models are largely mitigated, and the two recovered sources show similar properties. Additionally, we find that neglecting an additional signal in overlapping-signal data can lead to discrepancies in the estimated source properties resembling those reported in GW231123.

</details>


### [63] [Entanglement, equivalence principle, and HBAR entropy, in a new bumblebee black hole](https://arxiv.org/abs/2512.17567)
*A. A. Araújo Filho,Wentao Liu*

Main category: gr-qc

TL;DR: 研究新型大黄蜂黑洞在洛伦兹对称性自发破缺下的量子信息和热力学性质，通过量子探针分析近视界物理，包括量子纠缠退化和原子响应。


<details>
  <summary>Details</summary>
Motivation: 研究洛伦兹对称性自发破缺产生的新型大黄蜂黑洞的量子信息和热力学性质，探索近视界物理中量子纠缠、原子响应和熵产生等基本物理现象。

Method: 使用近视界Rindler对应关系，分析惯性观测者和加速观测者共享场模的量子纠缠退化；研究自由下落二能级原子与量子场的耦合；计算加速度辐射跃迁概率；将HBAR熵概念扩展到大黄蜂黑洞。

Result: 尽管共享相同度规，两种洛伦兹破缺真空在视界附近（特别是低频）变得可区分；原子响应在局部与平坦时空无法区分，证实等效原理在洛伦兹破缺修正下仍然有效；推导出大黄蜂黑洞的HBAR熵产生率。

Conclusion: 大黄蜂黑洞的量子信息特性在洛伦兹对称性破缺背景下展现出独特性质，但局部物理仍遵循等效原理，为研究量子引力效应和黑洞热力学提供了新视角。

Abstract: We investigate quantum information and thermodynamic properties of a new bumblebee black hole arising from spontaneous Lorentz symmetry breaking by analyzing near-horizon physics through complementary quantum probes. We study the degradation of quantum entanglement for field modes shared by inertial and accelerated observers in spacelike and lightlike Lorentz-violating vacua that generate identical spacetime metrics. Using the near-horizon Rindler correspondence, we derive analytic expressions for the logarithmic negativity and mutual information and examine their dependence on detector position, frequency, and Lorentz-violation parameters. Despite sharing the same metric, the two Lorentz-violating vacua become distinguishable near the horizon, particularly at low frequencies. We analyze the excitation of a freely falling two-level atom coupled to quantum fields near the horizon. The associated acceleration-radiation transition probabilities are computed explicitly. The resulting atomic response is locally indistinguishable from that in flat spacetime, confirming the validity of the equivalence principle even in the presence of Lorentz-violating corrections. Finally, we extend the notion of horizon-brightened acceleration radiation (HBAR) entropy to the bumblebee black hole and derive the corresponding entropy production rate induced by infalling atoms.

</details>


### [64] [Slowly rotating Black Holes in DHOST Theories](https://arxiv.org/abs/2512.17614)
*Hugo Candan,Karim Noui,David Langlois*

Main category: gr-qc

TL;DR: 在DHOST理论中研究缓慢旋转黑洞解，推导出框架拖曳函数的可积微分方程，并应用于带主毛发的黑洞解，分析旋转对ISCO和光轨迹的影响。


<details>
  <summary>Details</summary>
Motivation: 研究DHOST理论中缓慢旋转黑洞的性质，特别是框架拖曳函数的行为，以及旋转对黑洞周围轨道动力学的影响。

Method: 从DHOST理论的静态球对称度规解出发，采用Hartle-Thorne ansatz建模缓慢旋转时空，推导框架拖曳函数的微分方程并证明其可积性。

Result: 证明了框架拖曳函数的微分方程对于任何DHOST理论都是可积的，获得了其显式形式；发现角向依赖在视界和无穷远处被禁止；应用于带主毛发的黑洞解，分析了旋转对ISCO和光轨迹的影响。

Conclusion: DHOST理论中的缓慢旋转黑洞具有可积的框架拖曳函数，其性质与广义相对论类似，旋转显著影响ISCO和光轨迹，为测试修改引力理论提供了新途径。

Abstract: We study slowly rotating black hole solutions within Degenerate Higher Order Scalar Tensor (DHOST) theories. Starting from a static, spherically symmetric metric solution of a DHOST theory, we employ the Hartle-Thorne ansatz to model a slowly rotating spacetime. We show that the differential equation governing the frame-dragging function $ω$ (which is supposed to depend on the radial coordinate only) is integrable for any DHOST theory allowing us to obtain its explicit form. We also consider angular dependence in $ω$ and show that regularity at the horizon and at infinity forbids it, as in General Relativity. As an illustration of the formalism introduced here, we study the slowly-rotating version of black hole solutions with primary hair obtained recently, examining the influence of the rotation on the Innermost Stable Circular Orbit (ISCO) and on the circular light trajectories in the equatorial plane.

</details>


### [65] [Revisiting particle circular orbits as probes of black hole thermodynamics](https://arxiv.org/abs/2512.17642)
*Lei You,Jinsong Yang*

Main category: gr-qc

TL;DR: 该论文挑战了黑洞相变观测中粒子圆轨道半径rc随视界半径rh单调增加的普遍共识，揭示了rc(rh)在等压和等温条件下的不同单调性行为，并证明了相变区域内单调性仍然保持。


<details>
  <summary>Details</summary>
Motivation: 近年来，粒子圆轨道半径rc的跳跃被认为是黑洞相变的观测特征，基于rc随视界半径rh单调增加的普遍共识。然而，本文旨在检验这种单调性是否普遍成立。

Method: 推导了一个与系综无关的通用判据drc/drh，并将其应用于d维Reissner-Nordström-Anti-de Sitter黑洞，分析了等压和等温条件下rc(rh)的单调性行为。

Result: 发现rc(rh)在等压线上严格单调，但在等温线上通常非单调（Schwarzschild-Anti-de Sitter黑洞的光子球除外）。然而，在相变区域内单调性仍然保持。从rc提取的临界指数与从rh获得的匹配，且这些现象都与热力学第一定律密切相关。

Conclusion: rc(rh)的单调性并非普遍成立，但相变区域内单调性保持。非单调性本身可作为区分等压与等温演化的新观测探针，为黑洞热力学提供了补充工具。

Abstract: In recent years, jumps in the particle circular-orbit radius $r_{\rm c}$ have been proposed as observational signatures of black hole phase transitions, supported by the general consensus that $r_{\rm c}$ increases monotonically with the horizon radius $r_h$. However, in this paper, we will show that this monotonicity is not universally valid. By deriving a universal, ensemble-independent criterion for $\mathrm{d}r_{\rm c}/\mathrm{d}r_h$ and applying it to the $d$-dimensional Reissner-Nordström-Anti-de Sitter black hole, we reveal a sharp dichotomy: while $r_{\rm c}(r_h)$ exhibits strictly monotonicity along isobars, it typically becomes non-monotonic along isotherms (except for the photon sphere of Schwarzschild-Anti-de Sitter black hole)--a behavior that has been overlooked in previous studies. Nevertheless, we rigorously prove that within the phase-transition region itself, the monotonicity of $r_{\rm c}(r_h)$ is preserved. However, the generalizability of this result to other spacetimes requires case-by-case verification, and its validity could have notable implications for the observability of the jump in $r_{\rm c}$. Interestingly, non-monotonicity itself acts as a new observational probe: the monotonicity contrast in $r_{\rm c}(r_h)$ distinguishes isobaric from isothermal evolution, providing a complementary thermodynamic probe. Furthermore, we show that the critical exponents extracted from $r_{\rm c}$ match those obtained from $r_h$, independent of ensemble. Remarkably, all these phenomena are closely tied to the thermodynamic first law.

</details>


### [66] [Networks as the fundamental constituents of the universe](https://arxiv.org/abs/2512.17676)
*Carlo A. Trugenberger*

Main category: gr-qc

TL;DR: 该论文提出了一种基于二元关系作为宇宙基本构成要素的模型，通过随机网络上的统计模型来统一描述空间和物质，其中几何相和随机相分别对应空间和物质，在弱耦合和大尺度下涌现出全息表面和爱因斯坦方程。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是建立一个统一的理论框架，将空间、物质、引力和量子力学都视为由更基本的二元关系网络所涌现的宏观统计效应，从而解决量子引力、宇宙学常数问题等基础物理难题。

Method: 使用二元关系作为基本构建块，通过随机网络上的统计模型，以组合Ollivier-Ricci曲率作为网络版的爱因斯坦-希尔伯特作用量，定义了紫外连续固定点模型，该模型包含几何相和随机相两个相。

Result: 在弱耦合和大尺度下，网络组织成全息表面，其集体状态编码了涌现的3D空间和其中的物质分布；爱因斯坦方程作为本构关系出现；黑洞的全息性质自然产生；宇宙学常数问题和暗物质有自然解释机制。

Conclusion: 该模型表明引力和量子力学都是基本二元自由度自由能最小化的宏观统计效应，在普朗克尺度上时空的流形性质失效，网络的最小尺度随机性显现，为量子引力提供了新的理论框架。

Abstract: We review an approach that uses binary relations as the fundamental constituents of the universe, utilizing them as building blocks for both space and matter. The model is defined by an ultraviolet continuous fixed point of a statistical model on random networks, governed by the combinatorial Ollivier-Ricci curvature, which acts as a network analogue of the Einstein-Hilbert action. The model exhibits two distinct phases separated by this fixed point, a geometric and a random phase, representing space and matter, respectively. At weak coupling and on large scales, the network organizes into a holographic surface whose collective state encodes both an emergent 3D space and the matter distributed in it. The Einstein equations emerge as constitutive relations expressing matter in terms of fundamental network degrees of freedom while dynamics in a comoving frame is governed by relativistic quantum mechanics. Quantum mechanics, however is an effective theory breaking down at the scale of the radius of curvature of the holographic network. On smaller scales, not only relativistic invariance is lost but also the Lorentzian signature of space-time. Finally, the manifold nature of space-time breaks down on the Planck length, where the random character of the fundamental network on the smallest scales becomes apparent. The network model seems to naturally encode several of the large-distance features of cosmology, albeit still at a qualitative level. The holographic property of black holes arises intrinsically from the expander nature of random regular graphs. There is a natural mechanism to resolve the cosmological constant problem and dark matter appears naturally as a metastable allotrope in the network fabric of space-time. In this model, both gravity and quantum mechanics are macroscopic statistical effects reflecting the free energy minimization of fundamental binary degrees of freedom.

</details>


### [67] [Quasinormal modes of rotating black holes beyond general relativity in the WKB approximation](https://arxiv.org/abs/2512.17786)
*Ruijing Tang,Nicola Franchini,Sebastian H. Völkel,Emanuele Berti*

Main category: gr-qc

TL;DR: 本文扩展了高阶WKB方法用于计算旋转黑洞的准正则模谱，评估其在广义相对论之外的修正引力理论中的准确性，发现其精度足以匹配当前引力波观测需求。


<details>
  <summary>Details</summary>
Motivation: 研究超越广义相对论的引力理论需要准确计算黑洞准正则模谱的方法。高阶WKB方法虽然已用于非旋转黑洞，但在旋转黑洞和修正引力理论中的应用仍有不足，需要评估其准确性。

Method: 扩展高阶WKB方法用于计算Kerr黑洞准正则模谱，评估其与连分数法计算结果的准确性。然后将WKB近似应用于超越广义相对论的理论，包括参数化超越Teukolsky形式和更高阶导数引力理论，与线性化和连分数计算进行比较。

Result: WKB方法在超越广义相对论的理论中计算得到的频率具有足够高的精度，其误差小于迄今为止观测到的最高信噪比环降信号GW250114的测量误差。

Conclusion: 高阶WKB方法不仅适用于广义相对论中的旋转黑洞，在修正引力理论中也具有足够的准确性，能够满足当前引力波观测的需求，为黑洞光谱学研究提供了灵活可靠的计算工具。

Abstract: Exploring gravitational theories beyond general relativity (GR) with black hole (BH) spectroscopy requires accurate and flexible methods for computing their quasinormal mode (QNM) spectrum. A popular method of choice is the higher-order Wentzel-Kramers-Brillouin (WKB) approximation, mostly applied to nonrotating BHs. While previous studies demonstrated that the higher-order WKB method can also be used for Kerr BHs in GR, there has been little work on rotating BHs in modified theories of gravity. In this work, we revive the idea by extending WKB calculations of the Kerr QNM spectrum to higher order and assessing its accuracy against continued-fraction tabulated data. We then apply the WKB approximation beyond GR, comparing it against both linearized and continued fraction calculations in the parametrized beyond-Teukolsky formalism and in higher-derivative gravity (HDG) theories. We find that the frequencies computed by the WKB method in theories beyond GR have better accuracy than the measurement errors for GW250114, the event with the highest ringdown signal-to-noise ratio observed to date.

</details>


### [68] [Renormalization of the Quantum Stress Tensor Fluctuations and the Limits of Semiclassical Gravity](https://arxiv.org/abs/2512.17789)
*Alejandro Perez,Daniel Sudarsky*

Main category: gr-qc

TL;DR: 研究量子场论在弯曲时空中的能动量张量期望值及其涨落，分析半经典引力中能动量张量涨落相对于期望值的大小对理论自洽性的影响


<details>
  <summary>Details</summary>
Motivation: 在半经典引力理论中，能动量张量的期望值⟨T_{ab}⟩作为爱因斯坦方程的源项。为确保理论概念上的自洽性，能动量张量的涨落必须远小于其期望值。本文旨在检验这一条件是否成立

Method: 使用算子乘积展开方法，在固定弯曲背景上研究自由标量场的能动量张量期望值⟨T_{ab}(x)⟩_{ren}和涨落张量⟨T_{ab}(x)T_{cd}(x)⟩_{ren}的重整化，针对合适的Hadamard态进行分析

Result: 研究发现，在黑洞蒸发和暴胀宇宙学中自然出现的压缩真空态（squeezed vacua）无法满足半经典性判据，即其能动量张量的涨落相对于期望值并不小

Conclusion: 压缩真空态在半经典引力框架下存在概念上的不一致性，这对黑洞蒸发和暴胀宇宙学等物理过程的半经典描述提出了挑战

Abstract: We analyze the expectation value of the energy-momentum tensor and its fluctuations in quantum field theory on curved spacetimes $\langle T_{ab} \rangle$. A necessary condition for the conceptual consistency of semiclassical gravity, where $\langle T_{ab} \rangle$ represent the sources of the Einstein equations, is that the fluctuations of the energy momentum tensor remain small compared to its expectation value. We study the renormalization of both the energy-momentum tensor $\langle T_{ab}(x)\rangle_{\rm ren}$ and the fluctuation tensor $\langle T_{ab}(x) T_{cd}(x) \rangle_{\rm ren}$ for suitable Hadamard states, using the operator product expansion for a free scalar field on a fixed curved background. We show that squeezed vacua -- arising naturally in black hole evaporation and in inflationary cosmology -- fail to satisfy the semiclassicality criterion.

</details>


### [69] [Revisited apparent horizon entropy and GSL in modified gravity](https://arxiv.org/abs/2512.17861)
*Soma Heydari,Parastoo Askari,Kayoomars Karami*

Main category: gr-qc

TL;DR: 本文提出了一种改进的视界熵形式，用于在修正引力理论中研究广义热力学第二定律的有效性，并通过f(T)和f(R)引力模型验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 研究修正引力理论中广义热力学第二定律的有效性，建立适用于非平坦FRW宇宙的普适视界熵形式，探索热力学与引力之间的深刻联系。

Method: 从修正的Friedmann方程直接构建视界熵，包含标准Bekenstein-Hawking项和额外积分项（编码偏离广义相对论的有效能量密度和压强），推导GSL的紧凑表达式，并应用于f(T)和f(R)引力模型。

Result: 提出的普适熵公式能相对改善某些模型的晚期GSL有效性，而对其他模型保持不变，强化了热力学与引力之间的深刻联系。

Conclusion: 重新审视的视界熵形式为研究修正引力中的热力学定律提供了有效框架，积分项的纳入能改善某些模型的GSL有效性，证实了热力学与引力理论之间的内在关联。

Abstract: This work presents a universal and revisited formalism for the entropy of the apparent horizon in modified gravity to investigate the validity of the Generalized Second Law (GSL) of thermodynamics. This revisited horizon entropy is constructed directly from the modified Friedmann equations in a non-flat Friedmann-Robertson-Walker (FRW) universe. The resulting entropy relation contains, beside the standard Bekenstein-Hawking term, an additional integral contribution that encodes the effective energy density and pressure generated by deviations from general relativity. Using this universal entropy formula, a compact expression for the GSL is derived. This formalism is then applied to some viable $f(T)$ and $f(R)$ gravity models, in order to re-evaluate the validity of the GSL as a function of redshift. The analysis demonstrates that including the integral term in the revisited entropy can relatively improve the late-time validity of the GSL for some of these models while living others unchanged, thereby reinforcing the profound connection between thermodynamics and gravity.

</details>


### [70] [Trails of clouds in binary black holes](https://arxiv.org/abs/2512.17887)
*Mateja Bošković,Rafael A. Porto,Matthias Koschnitzke*

Main category: gr-qc

TL;DR: 旋转黑洞的超辐射不稳定性产生长寿命玻色子云，伴星通过共振和非共振跃迁影响云演化和轨道动力学，产生可观测的引力波特征。


<details>
  <summary>Details</summary>
Motivation: 研究双黑洞系统中玻色子云与轨道动力学的相互作用，为探测超轻粒子提供理论框架，并预测未来引力波探测器可观测的特征。

Method: 采用世界线有效场论方法，建立适用于偏心轨道和倾斜轨道的系统框架，捕捉共振和非共振跃迁，不依赖平衡定律。

Result: 发现同向旋转的"漂浮轨道"可在进入探测器频段前耗尽玻色子云，触发偏心率增长；反向旋转轨道也能耗尽云并驱动偏心率无限增长；揭示了轨道倾角相关的新特征，包括赤道轨道不稳定性和中间倾角固定点。

Conclusion: 该研究完善了双黑洞系统中超轻粒子印记的描述，为LISA、Cosmic Explorer和爱因斯坦望远镜等未来探测器提供了可探测的特征，能揭示系统中玻色子云的存在历史。

Abstract: Superradiant instabilities of rotating black holes can give rise to long-lived bosonic clouds, offering natural laboratories to probe ultralight particles across a wide range of parameter space. The presence of a companion can dramatically impact both the cloud's evolution and the binary's orbital dynamics, generating a trail of feedback effects that require detailed modelling. Using a worldline effective field theory approach, we develop a systematic framework for binaries on generic (eccentric and inclined) orbits, capturing both resonant and non-resonant transitions without relying solely on balance laws. We demonstrate the existence of ``co-rotating'' floating orbits that can deplete the cloud prior to entering the detector's band, triggering eccentricity growth towards a sequence of fixed points. Likewise, we show that ``counter-rotating'' orbits can also deplete the cloud, driving (unbounded) growth of eccentricity. Furthermore, we uncover novel features tied to orbital inclination. Depending on the mass ratio, equatorial orbits can become unstable, and fixed points may arise not only for aligned or anti-aligned configurations but, strikingly, also at intermediate inclinations. We derive flow equations governing spin-orbit misalignment and eccentricity and identify distinctive signatures that can reveal the presence of boson clouds in the binary's history, as well as key features of possible in-band transitions. These results refine and extend earlier work, yielding a more faithful description of the imprints of ultralight particles in gravitational-wave signals from binary black holes, signatures that are within reach of future detectors such as LISA, Cosmic Explorer, and the Einstein~Telescope.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [71] [Dion2: A Simple Method to Shrink Matrix in Muon](https://arxiv.org/abs/2512.16928)
*Kwangjun Ahn,Noah Amsel,John Langford*

Main category: cs.LG

TL;DR: Dion2是一种简化Muon优化器的方法，通过采样部分行或列进行正交化，降低计算和通信成本，提高可扩展性。


<details>
  <summary>Details</summary>
Motivation: Muon优化器虽然性能优秀，但其正交化步骤的超线性成本随规模增加而带来显著开销。现有方法尝试减小正交化矩阵的规模，但仍有改进空间。

Method: Dion2在每次迭代中采样部分行或列，仅对这些采样部分进行正交化。这种采样过程使更新变得稀疏，从而降低计算和通信成本。

Result: 该方法简化了Muon的计算过程，相比先前方法更加简单，同时减少了计算和通信开销，提高了Muon优化器的可扩展性。

Conclusion: Dion2提供了一种简单有效的方法来降低Muon优化器的计算成本，通过稀疏采样策略改善了其在大规模应用中的可扩展性。

Abstract: The Muon optimizer enjoys strong empirical performance and theoretical grounding. However, the super-linear cost of its orthonormalization step introduces increasing overhead with scale. To alleviate this cost, several works have attempted to reduce the size of the matrix entering the orthonormalization step. We introduce Dion2, a much simpler method for shrinking the matrix involved in Muon's computation compared to prior approaches. At a high level, Dion2 selects a fraction of rows or columns at each iteration and orthonormalizes only those. This sampling procedure makes the update sparse, reducing both computation and communication costs which in turn improves the scalability of Muon.

</details>


### [72] [BIONIX: A Wireless, Low-Cost Prosthetic Arm with Dual-Signal EEG and EMG Control](https://arxiv.org/abs/2512.16929)
*Pranesh Sathish Kumar*

Main category: cs.LG

TL;DR: 开发低成本双模式神经肌肉控制系统，结合EEG和EMG实现假肢多自由度实时控制


<details>
  <summary>Details</summary>
Motivation: 解决低收入地区截肢者使用假肢时缺乏直观控制系统的问题，提高功能性和可及性

Method: 使用NeuroSky MindWave Mobile 2采集EEG信号，通过ThinkGear蓝牙传输到ESP32微控制器运行轻量级分类模型；使用MyoWare 2.0传感器采集EMG信号，通过阈值检测实现肘部控制；EEG控制手指伺服，EMG控制肘部伺服

Result: 构建了功能原型（总成本约240美元），EEG检测眨眼事件切换手部开合状态，EMG通过三个激活带实现直观肘部控制，系统稳定可靠

Conclusion: 该系统展示了低成本、生物直观假肢控制的可行途径，适合资源匮乏地区和全球健康应用，未来可改进3D打印外壳、降低EMG延迟、提升伺服扭矩

Abstract: Affordable upper-limb prostheses often lack intuitive control systems, limiting functionality and accessibility for amputees in low-resource settings. This project presents a low-cost, dual-mode neuro-muscular control system integrating electroencephalography (EEG) and electromyography (EMG) to enable real-time, multi-degree-of-freedom control of a prosthetic arm. EEG signals are acquired using the NeuroSky MindWave Mobile 2 and transmitted via ThinkGear Bluetooth packets to an ESP32 microcontroller running a lightweight classification model. The model was trained on 1500 seconds of recorded EEG data using a 6-frame sliding window with low-pass filtering, excluding poor-signal samples and using a 70/20/10 training--validation--test split. The classifier detects strong blink events, which toggle the hand between open and closed states. EMG signals are acquired using a MyoWare 2.0 sensor and SparkFun wireless shield and transmitted to a second ESP32, which performs threshold-based detection. Three activation bands (rest: 0--T1; extension: T1--T2; contraction: greater than T2) enable intuitive elbow control, with movement triggered only after eight consecutive frames in a movement class to improve stability. The EEG-controlled ESP32 actuates four finger servos, while the EMG-controlled ESP32 drives two elbow servos. A functional prototype was constructed using low-cost materials (total cost approximately 240 dollars), with most expense attributed to the commercial EEG headset. Future work includes transitioning to a 3D-printed chassis, integrating auto-regressive models to reduce EMG latency, and upgrading servo torque for improved load capacity and grip strength. This system demonstrates a feasible pathway to low-cost, biologically intuitive prosthetic control suitable for underserved and global health applications.

</details>


### [73] [QSMOTE-PGM/kPGM: QSMOTE Based PGM and kPGM for Imbalanced Dataset Classification](https://arxiv.org/abs/2512.16960)
*Bikash K. Behera,Giuseppe Sergioli,Robert Giuntini*

Main category: cs.LG

TL;DR: 量子启发机器学习方法中，基于核技巧和量子态判别PGM的分类器在合成过采样场景中优于经典随机森林，PGM在特定编码下表现最佳，KPGM则在不同采样策略下更稳健。


<details>
  <summary>Details</summary>
Motivation: 量子启发机器学习利用量子理论数学框架增强经典算法，但核技巧与量子态判别PGM方法缺乏统一比较。本研究旨在理论结合实验对比这些范式，探索它们在合成过采样场景下的性能差异。

Method: 提出统一理论框架对比核技巧与PGM方法，包括核化PGM和直接PGM分类器。使用量子SMOTE变体进行合成过采样实验，评估不同编码方式（立体、幅度）和量子副本数量对性能的影响。

Result: PGM和KPGM分类器均优于经典随机森林基线，特别是使用多个量子副本时。PGM在立体编码和n_copies=2时获得最高准确率（0.8512）和F1分数（0.8234）。KPGM在不同QSMOTE变体下表现更稳定，在立体编码和幅度编码下分别达到0.8511和0.8483。

Conclusion: 量子启发分类器在召回率和平衡性能方面具有实际优势，PGM受益于编码特定增强，KPGM在不同采样策略下更稳健。研究为理解核基和测量基QiML方法提供了实用指导，帮助根据数据特征和计算约束选择合适方法。

Abstract: Quantum-inspired machine learning (QiML) leverages mathematical frameworks from quantum theory to enhance classical algorithms, with particular emphasis on inner product structures in high-dimensional feature spaces. Among the prominent approaches, the Kernel Trick, widely used in support vector machines, provides efficient similarity computation, while the Pretty Good Measurement (PGM), originating from quantum state discrimination, enables classification grounded in Hilbert space geometry. Building on recent developments in kernelized PGM (KPGM) and direct PGM-based classifiers, this work presents a unified theoretical and empirical comparison of these paradigms. We analyze their performance across synthetic oversampling scenarios using Quantum SMOTE (QSMOTE) variants. Experimental results show that both PGM and KPGM classifiers consistently outperform a classical random forest baseline, particularly when multiple quantum copies are employed. Notably, PGM with stereo encoding and n_copies=2 achieves the highest overall accuracy (0.8512) and F1-score (0.8234), while KPGM demonstrates competitive and more stable behavior across QSMOTE variants, with top scores of 0.8511 (stereo) and 0.8483 (amplitude). These findings highlight that quantum-inspired classifiers not only provide tangible gains in recall and balanced performance but also offer complementary strengths: PGM benefits from encoding-specific enhancements, whereas KPGM ensures robustness across sampling strategies. Our results advance the understanding of kernel-based and measurement-based QiML methods, offering practical guidance on their applicability under varying data characteristics and computational constraints.

</details>


### [74] [Estimating Spatially Resolved Radiation Fields Using Neural Networks](https://arxiv.org/abs/2512.17654)
*Felix Lehner,Pasquale Lombardo,Susana Castillo,Oliver Hupe,Marcus Magnor*

Main category: cs.LG

TL;DR: 使用神经网络重建医疗辐射场中散射辐射空间分布的研究，通过蒙特卡洛模拟生成数据集，评估不同网络架构在剂量学应用中的效果。


<details>
  <summary>Details</summary>
Motivation: 医疗辐射场（如介入放射学和心脏病学）中的辐射防护剂量学需要准确估计散射辐射的空间分布，传统方法计算复杂且耗时，需要更高效的解决方案。

Method: 使用基于Geant4的蒙特卡洛模拟生成三个复杂度递增的合成数据集，评估卷积神经网络和全连接神经网络架构，比较它们在重建辐射场通量和能谱空间分布方面的表现。

Result: 研究确定了在重建医疗辐射场空间分布方面表现良好的神经网络设计决策，所有数据集和训练流程均已开源发布。

Conclusion: 神经网络可以有效估计医疗辐射场中的散射辐射分布，为辐射防护剂量学提供了新的计算工具，开源数据集和代码有助于该领域的进一步研究。

Abstract: We present an in-depth analysis on how to build and train neural networks to estimate the spatial distribution of scattered radiation fields for radiation protection dosimetry in medical radiation fields, such as those found in Interventional Radiology and Cardiology. Therefore, we present three different synthetically generated datasets with increasing complexity for training, using a Monte-Carlo Simulation application based on Geant4. On those datasets, we evaluate convolutional and fully connected architectures of neural networks to demonstrate which design decisions work well for reconstructing the fluence and spectra distributions over the spatial domain of such radiation fields. All used datasets as well as our training pipeline are published as open source in separate repositories.

</details>


### [75] [Compression is Routing: Reconstruction Error as an Intrinsic Signal for Modular Language Models](https://arxiv.org/abs/2512.16963)
*Zhongpan Tang*

Main category: cs.LG

TL;DR: 论文提出"压缩即路由"新架构理念，通过Transformer自编码器实现64倍序列压缩，利用重建误差作为内在分布指纹来自动调度专家模块，无需显式门控网络。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型面临三大挑战：上下文长度限制、高推理成本、持续学习中的灾难性遗忘。虽然MoE架构缓解了部分冲突，但其路由机制依赖显式训练的辅助分类器，增加了系统复杂性且在处理混合域输入时缺乏可解释性。

Method: 提出"压缩即路由"架构理念，训练了一个8700万参数的端到端Transformer自编码器，实现512个token压缩为8个潜在向量的64倍序列长度压缩。利用重建误差作为内在分布指纹，专家模块可根据重建残差自动调度，无需显式门控网络。

Result: 压缩器表现出极端的领域判别能力：在域内（代码）验证集上重建准确率达99.47%；在半分布外领域（Wiki文本）上骤降至47.76%；在全分布外领域（随机序列）上暴跌至仅0.57%。这种系统性性能差异验证了重建误差作为内在分布指纹的有效性。

Conclusion: 重建误差可作为内在分布指纹，专家模块可通过重建残差自动调度，无需显式门控网络。该架构为可扩展模块化神经网络提供了新视角，并为处理超长上下文提供了"VRAM压缩"新思路。

Abstract: Current Large Language Models (LLMs) face three major challenges: context length limitations, high inference costs, and catastrophic forgetting during continual learning. While Mixture-of-Experts (MoE) architectures mitigate some of these conflicts, their routing mechanisms typically rely on explicitly trained auxiliary classifiers. This not only increases system complexity but also often lacks interpretability when handling mixed-domain inputs.
  Building upon the premise that ``Compression is Intelligence,'' this paper proposes a novel architectural philosophy: \textbf{``Compression is Routing.''} We trained an 87M-parameter end-to-end Transformer Autoencoder, achieving a \textbf{64x sequence length compression} (compressing 512 tokens into 8 latent vectors). Experimental results demonstrate that this compressor possesses extreme domain discriminative capability: it achieves a reconstruction accuracy of \textbf{99.47\%} on the in-domain (code) validation set; accuracy drops sharply to \textbf{47.76\%} on a semi-out-of-distribution domain (Wiki text); and further plummets to just \textbf{0.57\%} on a fully out-of-distribution domain (random sequences).
  This extreme and systematic performance discrepancy establishes the validity of reconstruction error as an \textbf{Intrinsic Distribution Fingerprint}. Based on this, we propose that expert modules can be automatically scheduled using reconstruction residuals directly, without the need for explicit gating networks. This mechanism offers excellent scalability. Furthermore, this architecture provides a new perspective on ``VRAM compression'' for handling ultra-long contexts. This report aims to verify the physical validity of this foundational architecture, offering a new research perspective for the next generation of scalable modular neural networks.

</details>


### [76] [Physics-Informed Lightweight Machine Learning for Aviation Visibility Nowcasting Across Multiple Climatic Regimes](https://arxiv.org/abs/2512.16967)
*Marcelo Cerda Castillo*

Main category: cs.LG

TL;DR: 基于XGBoost的轻量级梯度提升框架，利用METAR地面观测数据和物理引导特征工程，实现低能见度和降水事件的短期预测，在11个国际机场的盲测中显著优于传统TAF预报。


<details>
  <summary>Details</summary>
Motivation: 当前航空气象业务依赖计算密集的数值天气预报和人工发布的TAF产品，存在保守偏差和时间分辨率有限的问题，需要更高效、准确的短期预测方法保障航空安全和运行效率。

Method: 采用XGBoost梯度提升框架，仅使用METAR地面观测数据，通过基于热力学原理的物理引导特征工程增强特征，在11个代表不同气候区域的国际机场（2000-2024年数据）进行训练和评估。

Result: 模型成功捕捉了局地物理过程，在3小时战术预报盲测中，相比业务TAF预报，检测率显著提高，召回率提升2.5-4.0倍，同时减少了误报。SHAP分析显示模型能隐式重建局地物理驱动因子。

Conclusion: 该轻量级物理引导机器学习框架为航空气象短期预测提供了高效、可解释的解决方案，具有业务部署潜力，特别适合边缘计算环境。

Abstract: Short-term prediction (nowcasting) of low-visibility and precipitation events is critical for aviation safety and operational efficiency. Current operational approaches rely on computationally intensive numerical weather prediction guidance and human-issued TAF products, which often exhibit conservative biases and limited temporal resolution. This study presents a lightweight gradient boosting framework (XGBoost) trained exclusively on surface observation data (METAR) and enhanced through physics-guided feature engineering based on thermodynamic principles. The framework is evaluated across 11 international airports representing distinct climatic regimes (including SCEL, KJFK, KORD, KDEN, SBGR, and VIDP) using historical data from 2000 to 2024. Results suggest that the model successfully captures underlying local physical processes without manual configuration. In a blind comparative evaluation against operational TAF forecasts, the automated model achieved substantially higher detection rates at tactical horizons (3 hours), with a 2.5 to 4.0 times improvement in recall while reducing false alarms. Furthermore, SHAP analysis reveals that the model performs an implicit reconstruction of local physical drivers (advection, radiation, and subsidence), providing actionable explainability for operational situational awareness.
  Keywords: aviation meteorology; physics-guided machine learning; explainable artificial intelligence; lightweight machine learning; nowcasting; METAR; TAF verification; edge computing

</details>


### [77] [Turn-PPO: Turn-Level Advantage Estimation with PPO for Improved Multi-Turn RL in Agentic LLMs](https://arxiv.org/abs/2512.17008)
*Junbo Li,Peng Zhou,Rui Meng,Meet P. Vadera,Lihong Li,Yang Li*

Main category: cs.LG

TL;DR: 本文提出turn-PPO方法，通过将MDP从token级扩展到turn级，解决了GRPO在多轮任务中长期推理的稳定性问题，在WebShop和Sokoban数据集上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 强化学习在训练交互式LLM智能体方面具有优势，但传统GRPO算法在多轮任务中长期推理场景中存在显著局限性，需要更稳定有效的优势估计策略。

Method: 首先探索PPO作为GRPO的替代方案，发现其更稳健；然后提出turn-PPO变体，将MDP从token级重新表述为turn级，专门针对多轮场景优化。

Result: 在WebShop和Sokoban数据集上的实验结果表明，turn-PPO无论是否包含长期推理组件都表现出有效性，优于传统GRPO方法。

Conclusion: turn-PPO通过turn级MDP表述解决了多轮任务中强化学习的稳定性问题，为交互式LLM智能体的训练提供了更有效的优化方法。

Abstract: Reinforcement learning (RL) has re-emerged as a natural approach for training interactive LLM agents in real-world environments. However, directly applying the widely used Group Relative Policy Optimization (GRPO) algorithm to multi-turn tasks exposes notable limitations, particularly in scenarios requiring long-horizon reasoning. To address these challenges, we investigate more stable and effective advantage estimation strategies, especially for multi-turn settings. We first explore Proximal Policy Optimization (PPO) as an alternative and find it to be more robust than GRPO. To further enhance PPO in multi-turn scenarios, we introduce turn-PPO, a variant that operates on a turn-level MDP formulation, as opposed to the commonly used token-level MDP. Our results on the WebShop and Sokoban datasets demonstrate the effectiveness of turn-PPO, both with and without long reasoning components.

</details>


### [78] [GB-DQN: Gradient Boosted DQN Models for Non-stationary Reinforcement Learning](https://arxiv.org/abs/2512.17034)
*Chang-Hwan Lee,Chanseung Lee*

Main category: cs.LG

TL;DR: GB-DQN使用梯度提升集成方法解决深度强化学习中的非平稳环境问题，通过增量残差学习适应动态变化，相比DQN和基线方法具有更快的恢复速度和更好的稳定性。


<details>
  <summary>Details</summary>
Motivation: 非平稳环境对深度强化学习构成根本性挑战，因为动态或奖励的变化会使已学习的价值函数失效，导致灾难性遗忘。现有方法在应对模型漂移时存在效率低下和稳定性不足的问题。

Method: 提出梯度提升深度Q网络（GB-DQN），这是一种自适应集成方法。不重新训练单个Q网络，而是构建一个加法集成，其中每个新学习器被训练来近似当前集成在漂移后的贝尔曼残差。该方法通过增量残差学习来适应模型漂移。

Result: 理论分析表明每个提升步骤都能减少经验贝尔曼残差，在标准假设下集成收敛到漂移后的最优价值函数。在具有受控动态变化的各种控制任务实验中，相比DQN和常见非平稳基线方法，GB-DQN表现出更快的恢复速度、更好的稳定性和更强的鲁棒性。

Conclusion: GB-DQN通过梯度提升集成和增量残差学习有效解决了深度强化学习中的非平稳环境问题，为应对模型漂移提供了一种理论保证且实际有效的解决方案。

Abstract: Non-stationary environments pose a fundamental challenge for deep reinforcement learning, as changes in dynamics or rewards invalidate learned value functions and cause catastrophic forgetting. We propose \emph{Gradient-Boosted Deep Q-Networks (GB-DQN)}, an adaptive ensemble method that addresses model drift through incremental residual learning. Instead of retraining a single Q-network, GB-DQN constructs an additive ensemble in which each new learner is trained to approximate the Bellman residual of the current ensemble after drift. We provide theoretical results showing that each boosting step reduces the empirical Bellman residual and that the ensemble converges to the post-drift optimal value function under standard assumptions. Experiments across a diverse set of control tasks with controlled dynamics changes demonstrate faster recovery, improved stability, and greater robustness compared to DQN and common non-stationary baselines.

</details>


### [79] [SFBD-OMNI: Bridge models for lossy measurement restoration with limited clean samples](https://arxiv.org/abs/2512.17051)
*Haoye Lu,Yaoliang Yu,Darren Ho*

Main category: cs.LG

TL;DR: 提出SFBD-OMNI框架，通过单边熵最优传输解决含噪声样本的分布恢复问题，利用少量干净样本实现不可恢复情况下的分布重建


<details>
  <summary>Details</summary>
Motivation: 现实场景中获取完全观测样本成本高昂，而部分噪声观测相对容易收集。需要开发方法从大量噪声样本中恢复真实分布

Method: 将任务建模为单边熵最优传输问题，采用EM类算法求解。提出可恢复性测试准则，引入SFBD-OMNI框架，将随机前向-后向解卷积推广到任意测量模型

Result: 在基准数据集和多样化测量设置中，方法在定性和定量性能上均有显著提升，证明少量干净样本可使原本不可恢复的分布变得可恢复

Conclusion: SFBD-OMNI框架能有效处理任意测量模型下的分布恢复问题，为实际应用中从噪声观测重建真实分布提供了实用解决方案

Abstract: In many real-world scenarios, obtaining fully observed samples is prohibitively expensive or even infeasible, while partial and noisy observations are comparatively easy to collect. In this work, we study distribution restoration with abundant noisy samples, assuming the corruption process is available as a black-box generator. We show that this task can be framed as a one-sided entropic optimal transport problem and solved via an EM-like algorithm. We further provide a test criterion to determine whether the true underlying distribution is recoverable under per-sample information loss, and show that in otherwise unrecoverable cases, a small number of clean samples can render the distribution largely recoverable. Building on these insights, we introduce SFBD-OMNI, a bridge model-based framework that maps corrupted sample distributions to the ground-truth distribution. Our method generalizes Stochastic Forward-Backward Deconvolution (SFBD; Lu et al., 2025) to handle arbitrary measurement models beyond Gaussian corruption. Experiments across benchmark datasets and diverse measurement settings demonstrate significant improvements in both qualitative and quantitative performance.

</details>


### [80] [Dynamic Tool Dependency Retrieval for Efficient Function Calling](https://arxiv.org/abs/2512.17052)
*Bhrij Patel,Davide Belli,Amir Jalalirad,Maximilian Arnold,Aleksandr Ermovol,Bence Major*

Main category: cs.LG

TL;DR: 提出DTDR方法，通过动态建模工具依赖关系，结合初始查询和演化执行上下文，提升函数调用代理的检索精度和任务成功率


<details>
  <summary>Details</summary>
Motivation: 现有检索方法依赖静态有限输入，无法捕捉多步工具依赖和演化任务上下文，导致引入无关工具误导代理，降低效率和准确性

Method: 提出动态工具依赖检索(DTDR)，轻量级检索方法，基于函数调用演示建模工具依赖关系，结合初始查询和演化执行上下文进行自适应检索

Result: 在多个数据集和LLM骨干网络上评估，DTDR相比最先进的静态检索方法，将函数调用成功率提升23%到104%

Conclusion: 动态工具检索能显著提升函数调用代理的性能，通过建模工具依赖关系和适应任务上下文演化，提高检索精度和下游任务准确性

Abstract: Function calling agents powered by Large Language Models (LLMs) select external tools to automate complex tasks. On-device agents typically use a retrieval module to select relevant tools, improving performance and reducing context length. However, existing retrieval methods rely on static and limited inputs, failing to capture multi-step tool dependencies and evolving task context. This limitation often introduces irrelevant tools that mislead the agent, degrading efficiency and accuracy. We propose Dynamic Tool Dependency Retrieval (DTDR), a lightweight retrieval method that conditions on both the initial query and the evolving execution context. DTDR models tool dependencies from function calling demonstrations, enabling adaptive retrieval as plans unfold. We benchmark DTDR against state-of-the-art retrieval methods across multiple datasets and LLM backbones, evaluating retrieval precision, downstream task accuracy, and computational efficiency. Additionally, we explore strategies to integrate retrieved tools into prompts. Our results show that dynamic tool retrieval improves function calling success rates between $23\%$ and $104\%$ compared to state-of-the-art static retrievers.

</details>


### [81] [Universal consistency of the $k$-NN rule in metric spaces and Nagata dimension. III](https://arxiv.org/abs/2512.17058)
*Vladimir G. Pestov*

Main category: cs.LG

TL;DR: 本文证明了k-最近邻分类器在可分度量空间中的弱普适一致性等价于空间的sigma-有限维性，完成了该等价关系的最后一块证明。


<details>
  <summary>Details</summary>
Motivation: 动机是完成k-最近邻分类器在可分度量空间中弱普适一致性条件的完整等价证明。此前已有部分结果：Preiss (1983) 宣布了(2)⇔(3)的等价性，Assouad和Quentin de Gromard (2006) 详细证明了(3)⇒(2)，Cérou和Guyader (2006) 证明了(2)⇒(1)。本文需要证明最后缺失的(1)⇒(3)部分，并修正系列文章中第二篇文章的错误声明。

Method: 方法是通过数学证明建立k-最近邻分类器的弱普适一致性(1)蕴含度量空间的sigma-有限维性(3)。这涉及到度量空间理论、测度论和统计学习理论的交叉研究，特别是Lebesgue-Besicovitch微分性质和Nagata维度的关系。

Result: 主要结果是证明了(1)⇒(3)的蕴含关系，从而完成了三个条件之间的完整等价链：(1) k-最近邻分类器弱普适一致 ⇔ (2) 强Lebesgue-Besicovitch微分性质 ⇔ (3) 空间具有sigma-有限维性。同时修正了Kumari和Pestov (2024)中的错误声明。

Conclusion: 结论是建立了k-最近邻分类器在可分度量空间中弱普适一致性的完整特征化：当且仅当度量空间具有sigma-有限维性时，k-最近邻分类器是弱普适一致的。这为理解非参数分类器在一般度量空间中的行为提供了理论基础。

Abstract: We prove the last remaining implication allowing to claim the equivalence of the following conditions for a complete separable metric space $X$:
  (1) The $k$-nearest neighbour classifier is (weakly) universally consistent in $X$, (2) The strong Lebesgue--Besicovitch differentiation property holds in $X$ for every locally finite Borel measure, (3) $X$ is sigma-finite dimensional in the sense of Nagata.
  The equivalence (2)$\iff$(3) was announced by Preiss (1983), while a detailed proof of the implication (3)$\Rightarrow$(2) has appeared in Assouad and Quentin de Gromard (2006). The implication (2)$\Rightarrow$(1) was established by Cérou and Guyader (2006). We prove the implication (1)$\Rightarrow$(3). The result was conjectured in the first article in the series (Collins, Kumari, Pestov 2020), and here we also correct a wrong claim made in the second article (Kumari and Pestov 2024).

</details>


### [82] [Bandwidth-Efficient Adaptive Mixture-of-Experts via Low-Rank Compensation](https://arxiv.org/abs/2512.17073)
*Zhenyu Liu,Yunzhen Liu,Zehao Fan,Garrett Gagnon,Yayue Hou,Nan Wu,Yangwook Kang,Liu Liu*

Main category: cs.LG

TL;DR: 提出BEAM-LRC方法，通过低秩补偿实现带宽高效的MoE推理，在保持精度的同时减少传输数据量


<details>
  <summary>Details</summary>
Motivation: MoE模型通过稀疏激活扩展容量，但给内存和带宽带来压力。现有的卸载方案因令牌级路由导致不规则传输，使推理受限于I/O。静态均匀量化会降低精度，且忽略了专家异质性

Method: 提出带宽高效的自适应混合专家低秩补偿方法：1）使用路由器引导的精度恢复，通过预计算低秩补偿器；2）推理时传输紧凑的低秩因子给Top-n专家，应用补偿恢复精度，其他专家保持低比特；3）与GPU和GPU-NDP系统的卸载集成

Result: 该方法在带宽-精度权衡方面表现优越，提高了推理吞吐量

Conclusion: BEAM-LRC方法通过低秩补偿有效解决了MoE推理中的带宽瓶颈问题，在保持模型精度的同时显著减少了数据传输需求

Abstract: Mixture-of-Experts (MoE) models scale capacity via sparse activation but stress memory and bandwidth. Offloading alleviates GPU memory by fetching experts on demand, yet token-level routing causes irregular transfers that make inference I/O-bound. Static uniform quantization reduces traffic but degrades accuracy under aggressive compression by ignoring expert heterogeneity. We present Bandwidth-Efficient Adaptive Mixture-of-Experts via Low-Rank Compensation, which performs router-guided precision restoration using precomputed low-rank compensators. At inference time, our method transfers compact low-rank factors with Top-n (n<k) experts per token and applies compensation to them, keeping others low-bit. Integrated with offloading on GPU and GPU-NDP systems, our method delivers a superior bandwidth-accuracy trade-off and improved throughput.

</details>


### [83] [Can Large Reasoning Models Improve Accuracy on Mathematical Tasks Using Flawed Thinking?](https://arxiv.org/abs/2512.17079)
*Saraswathy Amjith,Mihika Dusad,Neha Muramalla,Shweta Shah*

Main category: cs.LG

TL;DR: 训练模型在包含故意错误的推理轨迹上，可以提高其检测和恢复错误的能力，而不损害标准问题解决能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在数学推理中，一旦出现早期错误（如算术错误或不合理推理），错误会传播到最终答案而无法纠正。需要研究如何让模型具备错误检测和恢复能力。

Method: 使用MATH-lighteval竞赛级问题，生成包含单一控制错误（计算错误或推理错误）的CoT前缀，用GRPO和二元最终答案奖励对Qwen3-4B进行微调。

Result: Mixed-CoT-RL模型在干净问题上与标准RL表现相当（41% vs 41%），但在包含错误推理的问题上显著优于标准RL（24% vs 19%）。仅使用干净数据训练会降低鲁棒性。

Conclusion: 在训练中暴露错误轨迹可以提高模型的错误恢复能力而不牺牲准确性，为构建更鲁棒的数学推理LLMs提供了路径。

Abstract: Chain-of-thought (CoT) prompting has become central to mathematical reasoning in large language models, yet models remain brittle to early errors: a single arithmetic slip or unjustified inference typically propagates uncorrected to an incorrect final answer. We investigate whether training on intentionally flawed reasoning traces can teach models to detect and recover from such errors without degrading standard problem-solving ability. Using competition-level problems from MATH-lighteval, we generate CoT prefixes containing exactly one controlled error, either a calculation error (sign flips, dropped terms) or a reasoning error (misapplied rules, unjustified logical steps), and fine-tune Qwen3-4B with GRPO using a binary final-answer reward. Our Mixed-CoT-RL model matches standard RL on clean problems (41% vs 41%) while substantially outperforming it on problems prefilled with flawed reasoning (24% vs 19%). Notably, clean-only RL fine-tuning degrades robustness below the untuned baseline 19% vs. 20%), indicating that conventional training increases susceptibility to misleading prefills. Among error types, training on reasoning errors yields greater robustness gains than calculation errors alone, with mixed training performing best. These findings demonstrate that exposure to flawed traces during training can improve error-recovery behavior without sacrificing accuracy, suggesting a path toward more robust mathematical reasoning in LLMs.

</details>


### [84] [How to Square Tensor Networks and Circuits Without Squaring Them](https://arxiv.org/abs/2512.17090)
*Lorenzo Loconte,Adrián Javaloy,Antonio Vergari*

Main category: cs.LG

TL;DR: 提出平方电路的参数化方法，通过正交性条件简化边缘化计算，在保持表达能力的同时提升学习效率


<details>
  <summary>Details</summary>
Motivation: 平方张量网络及其扩展形式平方电路作为分布估计器具有表达能力且支持闭式边缘化，但平方操作在计算配分函数或边缘化变量时引入额外复杂度，限制了在机器学习中的应用

Method: 受张量网络规范形式中的正交性和电路中确定性可实现可处理最大化的启发，提出平方电路的参数化方法，通过正交性条件简化边缘化计算，即使对于不直接映射到已知张量网络的因子分解也能高效边缘化

Result: 实验表明提出的平方电路条件在分布估计任务中不会损失表达能力，同时实现更高效的学习

Conclusion: 通过参数化平方电路克服边缘化计算开销，为不同因子分解提供高效边缘化方法，扩展了平方电路在机器学习中的应用

Abstract: Squared tensor networks (TNs) and their extension as computational graphs--squared circuits--have been used as expressive distribution estimators, yet supporting closed-form marginalization. However, the squaring operation introduces additional complexity when computing the partition function or marginalizing variables, which hinders their applicability in ML. To solve this issue, canonical forms of TNs are parameterized via unitary matrices to simplify the computation of marginals. However, these canonical forms do not apply to circuits, as they can represent factorizations that do not directly map to a known TN. Inspired by the ideas of orthogonality in canonical forms and determinism in circuits enabling tractable maximization, we show how to parameterize squared circuits to overcome their marginalization overhead. Our parameterizations unlock efficient marginalization even in factorizations different from TNs, but encoded as circuits, whose structure would otherwise make marginalization computationally hard. Finally, our experiments on distribution estimation show how our proposed conditions in squared circuits come with no expressiveness loss, while enabling more efficient learning.

</details>


### [85] [Learning to Plan, Planning to Learn: Adaptive Hierarchical RL-MPC for Sample-Efficient Decision Making](https://arxiv.org/abs/2512.17091)
*Toshiaki Hori,Jonathan DeCastro,Deepak Gopinath,Avinash Balachandran,Guy Rosman*

Main category: cs.LG

TL;DR: 提出融合强化学习与MPC规划的新方法，通过自适应采样机制提升规划性能和数据效率


<details>
  <summary>Details</summary>
Motivation: 解决具有层次结构的规划问题，将强化学习与MPC规划紧密结合，提升复杂规划任务的适应性和鲁棒性

Method: 提出融合强化学习与MPPI采样的自适应规划框架：RL动作指导MPPI采样，MPPI样本自适应聚合用于价值估计，在价值估计不确定区域加强MPPI探索

Result: 在赛车驾驶、改进Acrobot和带障碍的Lunar Lander等多个领域验证，相比现有方法提升72%成功率，收敛速度提升2.1倍，数据效率和整体性能更优

Conclusion: 该方法实现了强化学习与MPC规划的优雅融合，形成鲁棒的规划框架，能处理复杂规划问题并适应不同应用场景

Abstract: We propose a new approach for solving planning problems with a hierarchical structure, fusing reinforcement learning and MPC planning. Our formulation tightly and elegantly couples the two planning paradigms. It leverages reinforcement learning actions to inform the MPPI sampler, and adaptively aggregates MPPI samples to inform the value estimation. The resulting adaptive process leverages further MPPI exploration where value estimates are uncertain, and improves training robustness and the overall resulting policies. This results in a robust planning approach that can handle complex planning problems and easily adapts to different applications, as demonstrated over several domains, including race driving, modified Acrobot, and Lunar Lander with added obstacles. Our results in these domains show better data efficiency and overall performance in terms of both rewards and task success, with up to a 72% increase in success rate compared to existing approaches, as well as accelerated convergence (x2.1) compared to non-adaptive sampling.

</details>


### [86] [UniCoMTE: A Universal Counterfactual Framework for Explaining Time-Series Classifiers on ECG Data](https://arxiv.org/abs/2512.17100)
*Justin Li,Efe Sencan,Jasper Zheng Duan,Vitus J. Leung,Stephan Tsaur,Ayse K. Coskun*

Main category: cs.LG

TL;DR: UniCoMTE是一个模型无关的框架，用于为多元时间序列分类器生成反事实解释，提高深度学习模型的可解释性，特别是在医疗等高风险领域。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在复杂时间序列分类中表现出色，但其黑盒特性限制了在高风险领域（如医疗）的信任和采用。需要提高模型的可解释性以增强用户信任。

Method: 提出UniCoMTE框架，通过修改输入样本并评估对模型预测的影响，识别对预测影响最大的时间特征。该框架与多种模型架构兼容，可直接处理原始时间序列输入。

Result: 在ECG时间序列分类器上评估显示，UniCoMTE生成的解释比现有方法（LIME和SHAP）更简洁、稳定且符合人类认知。医学专家问卷评估证实了其临床实用性。

Conclusion: UniCoMTE通过将模型预测与有意义的信号模式联系起来，提高了深度学习模型在现实世界时间序列应用中的可解释性，为高风险领域的模型部署提供了可信的解释框架。

Abstract: Machine learning models, particularly deep neural networks, have demonstrated strong performance in classifying complex time series data. However, their black-box nature limits trust and adoption, especially in high-stakes domains such as healthcare. To address this challenge, we introduce UniCoMTE, a model-agnostic framework for generating counterfactual explanations for multivariate time series classifiers. The framework identifies temporal features that most heavily influence a model's prediction by modifying the input sample and assessing its impact on the model's prediction. UniCoMTE is compatible with a wide range of model architectures and operates directly on raw time series inputs. In this study, we evaluate UniCoMTE's explanations on a time series ECG classifier. We quantify explanation quality by comparing our explanations' comprehensibility to comprehensibility of established techniques (LIME and SHAP) and assessing their generalizability to similar samples. Furthermore, clinical utility is assessed through a questionnaire completed by medical experts who review counterfactual explanations presented alongside original ECG samples. Results show that our approach produces concise, stable, and human-aligned explanations that outperform existing methods in both clarity and applicability. By linking model predictions to meaningful signal patterns, the framework advances the interpretability of deep learning models for real-world time series applications.

</details>


### [87] [Fault Diagnosis and Quantification for Photovoltaic Arrays based on Differentiable Physical Models](https://arxiv.org/abs/2512.17107)
*Zenan Yang,Yuanliang Li,Jingwei Zhang,Yongjie Liu,Kun Ding*

Main category: cs.LG

TL;DR: 提出基于可微分快速故障仿真模型(DFFSM)的光伏串故障量化方法，使用Adahessian优化器进行梯度故障参数识别(GFPI)，实现高精度故障诊断


<details>
  <summary>Details</summary>
Motivation: 现有光伏阵列故障量化方法存在效率有限和可解释性不足的问题，需要更准确可靠的故障诊断方法以支持光伏系统的可靠运行和智能维护

Method: 提出可微分快速故障仿真模型(DFFSM)准确建模多故障下的I-V特性，并提供故障参数的解析梯度；基于此开发使用Adahessian优化器的梯度故障参数识别(GFPI)方法

Result: 在模拟和实测I-V曲线上的实验结果表明，GFPI方法对不同故障均实现高量化精度，I-V重构误差低于3%，验证了可微分物理仿真器在光伏系统故障诊断中的可行性

Conclusion: 提出的基于DFFSM的GFPI方法有效解决了光伏串故障量化问题，展示了可微分物理仿真器在光伏系统故障诊断中的应用潜力和有效性

Abstract: Accurate fault diagnosis and quantification are essential for the reliable operation and intelligent maintenance of photovoltaic (PV) arrays. However, existing fault quantification methods often suffer from limited efficiency and interpretability. To address these challenges, this paper proposes a novel fault quantification approach for PV strings based on a differentiable fast fault simulation model (DFFSM). The proposed DFFSM accurately models I-V characteristics under multiple faults and provides analytical gradients with respect to fault parameters. Leveraging this property, a gradient-based fault parameters identification (GFPI) method using the Adahessian optimizer is developed to efficiently quantify partial shading, short-circuit, and series-resistance degradation. Experimental results on both simulated and measured I-V curves demonstrate that the proposed GFPI achieves high quantification accuracy across different faults, with the I-V reconstruction error below 3%, confirming the feasibility and effectiveness of the application of differentiable physical simulators for PV system fault diagnosis.

</details>


### [88] [Atom: Efficient On-Device Video-Language Pipelines Through Modular Reuse](https://arxiv.org/abs/2512.17108)
*Kunjal Panchal,Saayan Mitra,Somdeb Sarkhel,Haoliang Wang,Ishita Dasgupta,Gang Wu,Hui Guan*

Main category: cs.LG

TL;DR: Atom是一个在移动设备上高效执行视频-语言多阶段流水线的系统，通过分解大模型为可复用模块并跨子任务重用，减少模型重复加载，实现并行执行，在保持性能的同时显著降低延迟。


<details>
  <summary>Details</summary>
Motivation: 当前视频-语言模型在移动设备上执行多阶段流水线（如检索、字幕生成、组装）时存在效率问题，主要表现为重复的模型加载和碎片化执行，导致延迟较高。

Method: 将十亿参数模型分解为可复用模块（如视觉编码器和语言解码器），在不同子任务间重用这些模块，消除重复模型加载，支持并行执行。

Result: 在商用智能手机上，相比非重用基线，Atom实现了27-33%的执行速度提升，性能下降极小（检索任务Recall@1下降≤2.3，字幕生成CIDEr下降≤1.5）。

Conclusion: Atom为边缘设备上的高效视频-语言理解提供了一个实用、可扩展的方法，通过重用设计显著提升了执行效率。

Abstract: Recent advances in video-language models have enabled powerful applications like video retrieval, captioning, and assembly. However, executing such multi-stage pipelines efficiently on mobile devices remains challenging due to redundant model loads and fragmented execution. We introduce Atom, an on-device system that restructures video-language pipelines for fast and efficient execution. Atom decomposes a billion-parameter model into reusable modules, such as the visual encoder and language decoder, and reuses them across subtasks like captioning, reasoning, and indexing. This reuse-centric design eliminates repeated model loading and enables parallel execution, reducing end-to-end latency without sacrificing performance. On commodity smartphones, Atom achieves 27--33% faster execution compared to non-reuse baselines, with only marginal performance drop ($\leq$ 2.3 Recall@1 in retrieval, $\leq$ 1.5 CIDEr in captioning). These results position Atom as a practical, scalable approach for efficient video-language understanding on edge devices.

</details>


### [89] [Bridging Training and Merging Through Momentum-Aware Optimization](https://arxiv.org/abs/2512.17109)
*Alireza Moayedikia,Alicia Troncoso*

Main category: cs.LG

TL;DR: 提出统一框架，在训练时维护因子化动量和曲率统计信息，然后重用这些信息进行几何感知的模型组合，避免重复计算并实现更优的模型合并。


<details>
  <summary>Details</summary>
Motivation: 当前工作流在训练时计算曲率信息，丢弃后又在模型合并时重新计算类似信息，造成计算浪费并丢失有价值的轨迹数据。训练大型神经网络和合并任务特定模型都需要参数重要性估计，但这两个挑战一直被孤立处理。

Method: 引入统一框架，在训练过程中维护因子化的动量和曲率统计信息，然后重用这些信息进行几何感知的模型组合。该方法在内存效率上与最先进方法相当，同时积累任务显著性分数，实现无需后验Fisher计算的曲率感知合并。

Result: 在自然语言理解基准测试中，曲率感知参数选择在所有稀疏度水平上都优于仅基于幅度的基线方法，多任务合并也优于强基线。该框架表现出秩不变收敛性，并且与现有低秩优化器相比具有更好的超参数鲁棒性。

Conclusion: 通过将优化轨迹视为可重用资产而非丢弃，该方法消除了冗余计算，同时实现了更原则性的模型组合。建立了非凸目标的收敛保证，近似误差受梯度奇异值衰减的约束。

Abstract: Training large neural networks and merging task-specific models both exploit low-rank structure and require parameter importance estimation, yet these challenges have been pursued in isolation. Current workflows compute curvature information during training, discard it, then recompute similar information for merging -- wasting computation and discarding valuable trajectory data. We introduce a unified framework that maintains factorized momentum and curvature statistics during training, then reuses this information for geometry-aware model composition. The proposed method achieves memory efficiency comparable to state-of-the-art approaches while accumulating task saliency scores that enable curvature-aware merging without post-hoc Fisher computation. We establish convergence guarantees for non-convex objectives with approximation error bounded by gradient singular value decay. On natural language understanding benchmarks, curvature-aware parameter selection outperforms magnitude-only baselines across all sparsity levels, with multi-task merging improving over strong baselines. The proposed framework exhibits rank-invariant convergence and superior hyperparameter robustness compared to existing low-rank optimizers. By treating the optimization trajectory as a reusable asset rather than discarding it, our approach eliminates redundant computation while enabling more principled model composition.

</details>


### [90] [Digitizing Nepal's Written Heritage: A Comprehensive HTR Pipeline for Old Nepali Manuscripts](https://arxiv.org/abs/2512.17111)
*Anjali Sarawgi,Esteban Garces Arias,Christof Zotter*

Main category: cs.LG

TL;DR: 首个针对古尼泊尔语的端到端手写文本识别系统，采用编码器-解码器架构和数据增强技术，在字符错误率上达到4.9%，并开源代码支持低资源历史文字研究。


<details>
  <summary>Details</summary>
Motivation: 古尼泊尔语作为具有历史意义但资源匮乏的语言，缺乏有效的手写文本识别系统。本文旨在为这种低资源历史文字开发首个端到端的识别管道。

Method: 采用行级转录方法，系统探索编码器-解码器架构，结合数据增强技术，实施解码策略分析，并进行标记级混淆分析以理解模型行为。

Result: 最佳模型达到4.9%的字符错误率，实现了对古尼泊尔语手写文本的有效识别。虽然评估数据集保密，但开源了训练代码、模型配置和评估脚本。

Conclusion: 成功开发了首个古尼泊尔语手写文本识别系统，为低资源历史文字的识别研究提供了可行方案和技术基础，通过开源代码促进该领域进一步发展。

Abstract: This paper presents the first end-to-end pipeline for Handwritten Text Recognition (HTR) for Old Nepali, a historically significant but low-resource language. We adopt a line-level transcription approach and systematically explore encoder-decoder architectures and data-centric techniques to improve recognition accuracy. Our best model achieves a Character Error Rate (CER) of 4.9\%. In addition, we implement and evaluate decoding strategies and analyze token-level confusions to better understand model behaviour and error patterns. While the dataset we used for evaluation is confidential, we release our training code, model configurations, and evaluation scripts to support further research in HTR for low-resource historical scripts.

</details>


### [91] [The Effect of Negation on CLIP in Medical Imaging: Limitations of Contrastive Language-Image Pretraining](https://arxiv.org/abs/2512.17121)
*Jasmine Vu,Shivanand Sheshappanavar*

Main category: cs.LG

TL;DR: 该研究评估了CheXagent模型在胸部X光图像检索中处理否定短语的能力，通过微调方法改进CLIP模型对否定句的理解，同时分析了模型内部行为变化。


<details>
  <summary>Details</summary>
Motivation: CLIP等视觉语言模型在医学影像任务中广泛应用，但存在处理否定短语能力不足的问题，这在医学诊断场景中尤为关键，需要改进模型对否定临床语言的理解能力。

Method: 评估Stanford AIMI CheXagent模型在使用含否定和不含否定提示时的胸部X光图像检索能力，基于先前工作提出的微调方法改进模型，并通过token归因、t-SNE投影和注意力头消融分析模型内部行为。

Result: 微调后CLIP模型处理否定短语的能力得到改善，但正提示评估准确率略有下降；通过内部行为分析揭示了不同微调方法如何重塑文本编码器对否定临床语言的表示。

Conclusion: 该研究有助于更好地理解CLIP模型的内部行为，通过改进其对临床相关否定语言的处理能力，提升其在医学AI设备中的可靠性。

Abstract: Large vision-language models like CLIP are increasingly used in medical imaging tasks due to their ability to align images and text without the need for extensive labeled data. This makes them particularly useful for applications like image retrieval, report generation, and classification in clinical settings. A potential issue to this approach is that CLIP-based models often under perform when interpreting negated phrases, which is especially problematic in the context of medical diagnosing. In this study, we evaluate the Stanford AIMI CheXagent model on its ability to correctly retrieve chest X-ray images using prompts with and without negation. The goal of this project is to understand where this model fails and then use it as a base model to improve its retrieval accuracy by fine tuning methods outlined in previous work. Results from this study show improvement in handling of negation in the CLIP model with a slight decrease in accuracy of positive prompt evaluation. Alongside retrieval accuracy, we examined internal model behavior through token attribution, t-SNE projection, and attention-head ablation to better characterize how each fine tuning approach reshaped the text encoders representation of negated clinical language. Through this work, we hope to better understand the internal behavior of CLIP and improve its handling of negation using clinically relevant language for improving its reliability in medical AI devices.

</details>


### [92] [DiffeoMorph: Learning to Morph 3D Shapes Using Differentiable Agent-Based Simulations](https://arxiv.org/abs/2512.17129)
*Seong Ho Pahng,Guoye Guan,Benjamin Fefferman,Sahand Hormoz*

Main category: cs.LG

TL;DR: DiffeoMorph：一个端到端可微分框架，通过学习形态发生协议指导智能体群形成目标3D形状，使用注意力SE(3)等变图神经网络和基于3D Zernike多项式的形状匹配损失。


<details>
  <summary>Details</summary>
Motivation: 生物系统通过相同智能体的集体行为形成复杂三维结构，这种分布式控制如何产生精确全局模式是发育生物学、分布式机器人、可编程物质和多智能体学习的核心问题。

Method: 提出DiffeoMorph框架，智能体使用基于注意力的SE(3)等变图神经网络更新位置和内部状态；引入基于3D Zernike多项式的形状匹配损失，通过双层优化（内层优化对齐四元数，外层更新模型）实现完全SO(3)不变性。

Result: 通过系统基准测试验证了形状匹配损失优于其他标准距离度量；演示了DiffeoMorph能够仅使用最小空间线索形成从简单椭球体到复杂形态的各种形状。

Conclusion: DiffeoMorph为学习分布式形态发生协议提供了一个有效的可微分框架，能够指导智能体群自组织形成复杂三维结构，在生物发育模拟和分布式机器人领域具有应用潜力。

Abstract: Biological systems can form complex three-dimensional structures through the collective behavior of identical agents -- cells that follow the same internal rules and communicate without central control. How such distributed control gives rise to precise global patterns remains a central question not only in developmental biology but also in distributed robotics, programmable matter, and multi-agent learning. Here, we introduce DiffeoMorph, an end-to-end differentiable framework for learning a morphogenesis protocol that guides a population of agents to morph into a target 3D shape. Each agent updates its position and internal state using an attention-based SE(3)-equivariant graph neural network, based on its own internal state and signals received from other agents. To train this system, we introduce a new shape-matching loss based on the 3D Zernike polynomials, which compares the predicted and target shapes as continuous spatial distributions, not as discrete point clouds, and is invariant to agent ordering, number of agents, and rigid-body transformations. To enforce full SO(3) invariance -- invariant to rotations yet sensitive to reflections, we include an alignment step that optimally rotates the predicted Zernike spectrum to match the target before computing the loss. This results in a bilevel problem, with the inner loop optimizing a unit quaternion for the best alignment and the outer loop updating the agent model. We compute gradients through the alignment step using implicit differentiation. We perform systematic benchmarking to establish the advantages of our shape-matching loss over other standard distance metrics for shape comparison tasks. We then demonstrate that DiffeoMorph can form a range of shapes -- from simple ellipsoids to complex morphologies -- using only minimal spatial cues.

</details>


### [93] [Smoothing DiLoCo with Primal Averaging for Faster Training of LLMs](https://arxiv.org/abs/2512.17131)
*Aaron Defazio,Konstantin Mishchenko,Parameswaran Raman,Hao-Jun Michael Shi,Lin Xiao*

Main category: cs.LG

TL;DR: GPA是一种改进的优化算法，通过解耦Nesterov方法中的插值常数，实现平滑的迭代平均，解决了DiLoCo和Schedule-Free等方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 针对现有平均化优化器（如单工作器DiLoCo和Schedule-Free）的局限性：DiLoCo的周期性平均引入双循环结构，增加内存需求和超参数数量；Schedule-Free虽然维护均匀平均但仍有改进空间。

Method: 扩展Nesterov方法的原始平均化形式，解耦插值常数，使算法能在每一步平滑地平均迭代，消除双循环结构，减少内存开销到单个额外缓冲区。

Result: 在Llama-160M模型上，GPA相比基线（AdamW）达到相同验证损失的速度提升24.22%；在ImageNet ViT任务中，小批量和大批量设置下分别获得12%和27%的速度提升；理论证明GPA能匹配或超越原始优化器的收敛保证。

Conclusion: GPA通过解耦插值常数实现了更有效的迭代平均，在性能和效率上优于现有平均化优化器，同时简化了超参数调整并减少了内存需求。

Abstract: We propose Generalized Primal Averaging (GPA), an extension of Nesterov's method in its primal averaging formulation that addresses key limitations of recent averaging-based optimizers such as single-worker DiLoCo and Schedule-Free (SF) in the non-distributed setting. These two recent algorithmic approaches improve the performance of base optimizers, such as AdamW, through different iterate averaging strategies. Schedule-Free explicitly maintains a uniform average of past weights, while single-worker DiLoCo performs implicit averaging by periodically aggregating trajectories, called pseudo-gradients, to update the model parameters. However, single-worker DiLoCo's periodic averaging introduces a two-loop structure, increasing its memory requirements and number of hyperparameters. GPA overcomes these limitations by decoupling the interpolation constant in the primal averaging formulation of Nesterov. This decoupling enables GPA to smoothly average iterates at every step, generalizing and improving upon single-worker DiLoCo. Empirically, GPA consistently outperforms single-worker DiLoCo while removing the two-loop structure, simplifying hyperparameter tuning, and reducing its memory overhead to a single additional buffer. On the Llama-160M model, GPA provides a 24.22% speedup in terms of steps to reach the baseline (AdamW's) validation loss. Likewise, GPA achieves speedups of 12% and 27% on small and large batch setups, respectively, to attain AdamW's validation accuracy on the ImageNet ViT workload. Furthermore, we prove that for any base optimizer with regret bounded by $O(\sqrt{T})$, where $T$ is the number of iterations, GPA can match or exceed the convergence guarantee of the original optimizer, depending on the choice of interpolation constants.

</details>


### [94] [Distributed Learning in Markovian Restless Bandits over Interference Graphs for Stable Spectrum Sharing](https://arxiv.org/abs/2512.17161)
*Liad Lea Didi,Kobi Cohen*

Main category: cs.LG

TL;DR: SMILE算法：分布式频谱共享中实现全局稳定、干扰感知的信道分配，结合多对一匹配与未知马尔可夫信道学习


<details>
  <summary>Details</summary>
Motivation: 在通信受限的无线网络中，多个认知通信实体（如小区、子网络或认知无线电用户）需要共享频谱资源。现有方法难以在未知的、时变环境中实现全局稳定的干扰感知信道分配。

Method: 提出SMILE（Stable Multi-matching with Interference-aware LEarning）算法，将不安定多臂老虎机学习与图约束协调相结合，实现分布式探索未知信道和利用学习信息的平衡。

Result: 理论证明SMILE收敛到最优稳定分配，并实现相对于完全了解期望效用的基准的对数遗憾。仿真验证了算法的鲁棒性、可扩展性和效率。

Conclusion: SMILE首次在随机时变不安定环境中实现了全局Gale-Shapley稳定的信道分配，为通信受限网络中的分布式频谱共享提供了有效解决方案。

Abstract: We study distributed learning for spectrum access and sharing among multiple cognitive communication entities, such as cells, subnetworks, or cognitive radio users (collectively referred to as cells), in communication-constrained wireless networks modeled by interference graphs. Our goal is to achieve a globally stable and interference-aware channel allocation. Stability is defined through a generalized Gale-Shapley multi-to-one matching, a well-established solution concept in wireless resource allocation. We consider wireless networks where L cells share S orthogonal channels and cannot simultaneously use the same channel as their neighbors. Each channel evolves as an unknown restless Markov process with cell-dependent rewards, making this the first work to establish global Gale-Shapley stability for channel allocation in a stochastic, temporally varying restless environment. To address this challenge, we develop SMILE (Stable Multi-matching with Interference-aware LEarning), a communication-efficient distributed learning algorithm that integrates restless bandit learning with graph-constrained coordination. SMILE enables cells to distributedly balance exploration of unknown channels with exploitation of learned information. We prove that SMILE converges to the optimal stable allocation and achieves logarithmic regret relative to a genie with full knowledge of expected utilities. Simulations validate the theoretical guarantees and demonstrate SMILE's robustness, scalability, and efficiency across diverse spectrum-sharing scenarios.

</details>


### [95] [BumpNet: A Sparse Neural Network Framework for Learning PDE Solutions](https://arxiv.org/abs/2512.17198)
*Shao-Ting Chiu,Ioannis G. Kevrekidis,Ulisses Braga-Neto*

Main category: cs.LG

TL;DR: BumpNet是一种基于无网格基函数展开的稀疏神经网络框架，用于PDE数值解和算子学习。它使用可训练的sigmoid基函数，结合动态剪枝实现模型简约和h-自适应，并与PINNs、EDNNs、DeepONet等现有架构结合。


<details>
  <summary>Details</summary>
Motivation: 现有径向基函数(RBF)网络虽然可用于PDE求解，但难以充分利用现代神经网络训练技术。需要一种既能保持基函数展开优势，又能利用现代深度学习优化方法的框架。

Method: BumpNet使用sigmoid激活函数构造基函数，所有参数（形状、位置、幅度）完全可训练。通过动态剪枝实现模型简约和h-自适应。提出三种变体：Bump-PINNs（结合PINNs求解一般PDE）、Bump-EDNN（空间用BumpNet，时间用EDNNs）、Bump-DeepONet（作为DeepONet的trunk网络）。

Result: 大量数值实验表明，所提架构在效率和精度方面表现优异，能够有效求解PDE和进行算子学习。

Conclusion: BumpNet是一个通用的稀疏神经网络框架，通过结合现代训练技术和基函数展开方法，为PDE数值解和算子学习提供了高效准确的解决方案。

Abstract: We introduce BumpNet, a sparse neural network framework for PDE numerical solution and operator learning. BumpNet is based on meshless basis function expansion, in a similar fashion to radial-basis function (RBF) networks. Unlike RBF networks, the basis functions in BumpNet are constructed from ordinary sigmoid activation functions. This enables the efficient use of modern training techniques optimized for such networks. All parameters of the basis functions, including shape, location, and amplitude, are fully trainable. Model parsimony and h-adaptivity are effectively achieved through dynamically pruning basis functions during training. BumpNet is a general framework that can be combined with existing neural architectures for learning PDE solutions: here, we propose Bump-PINNs (BumpNet with physics-informed neural networks) for solving general PDEs; Bump-EDNN (BumpNet with evolutionary deep neural networks) to solve time-evolution PDEs; and Bump-DeepONet (BumpNet with deep operator networks) for PDE operator learning. Bump-PINNs are trained using the same collocation-based approach used by PINNs, Bump-EDNN uses a BumpNet only in the spatial domain and uses EDNNs to advance the solution in time, while Bump-DeepONets employ a BumpNet regression network as the trunk network of a DeepONet. Extensive numerical experiments demonstrate the efficiency and accuracy of the proposed architecture.

</details>


### [96] [Learning solution operator of dynamical systems with diffusion maps kernel ridge regression](https://arxiv.org/abs/2512.17203)
*Jiwoo Song,Daning Huang,John Harlim*

Main category: cs.LG

TL;DR: 提出DM-KRR方法，通过扩散映射核结合动态感知验证策略，实现复杂动力系统的长期预测，在精度和数据效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 许多科学和工程系统具有复杂的非线性动力学特性，难以进行长期准确预测。现有数据驱动模型在几何结构未知或表示不佳时性能会下降，需要一种能适应系统内在几何结构的方法。

Method: 提出扩散映射核岭回归（DM-KRR）方法：1）使用从扩散映射导出的数据驱动核，隐式适应系统不变集的内在几何；2）结合动态感知验证策略进行模型选择；3）无需显式流形重构或吸引子建模。

Result: 在包括光滑流形、混沌吸引子和高维时空流等多种系统中，DM-KRR在精度和数据效率上一致优于最先进的随机特征、神经网络和算子学习方法。

Conclusion: 长期预测能力不仅取决于模型表达能力，更关键的是通过动态一致的模型选择尊重数据中编码的几何约束。该方法为复杂动力系统的可靠高效学习提供了有前景的路径。

Abstract: Many scientific and engineering systems exhibit complex nonlinear dynamics that are difficult to predict accurately over long time horizons. Although data-driven models have shown promise, their performance often deteriorates when the geometric structures governing long-term behavior are unknown or poorly represented. We demonstrate that a simple kernel ridge regression (KRR) framework, when combined with a dynamics-aware validation strategy, provides a strong baseline for long-term prediction of complex dynamical systems. By employing a data-driven kernel derived from diffusion maps, the proposed Diffusion Maps Kernel Ridge Regression (DM-KRR) method implicitly adapts to the intrinsic geometry of the system's invariant set, without requiring explicit manifold reconstruction or attractor modeling, procedures that often limit predictive performance. Across a broad range of systems, including smooth manifolds, chaotic attractors, and high-dimensional spatiotemporal flows, DM-KRR consistently outperforms state-of-the-art random feature, neural-network and operator-learning methods in both accuracy and data efficiency. These findings underscore that long-term predictive skill depends not only on model expressiveness, but critically on respecting the geometric constraints encoded in the data through dynamically consistent model selection. Together, simplicity, geometry awareness, and strong empirical performance point to a promising path for reliable and efficient learning of complex dynamical systems.

</details>


### [97] [Electric Vehicle Charging Load Forecasting: An Experimental Comparison of Machine Learning Methods](https://arxiv.org/abs/2512.17257)
*Iason Kyriakopoulos,Yannis Theodoridis*

Main category: cs.LG

TL;DR: 该研究系统比较了五种时间序列预测模型在电动汽车充电需求预测中的表现，涵盖分钟、小时、天三个时间尺度以及从单个充电站到城市级别的空间聚合水平。


<details>
  <summary>Details</summary>
Motivation: 随着电动汽车普及带来的电网管理挑战，准确预测充电需求变得日益重要。现有研究缺乏对不同时间尺度和空间聚合水平下多种预测方法的系统性比较。

Method: 使用五种时间序列预测模型（传统统计方法、机器学习和深度学习方法），在四个公开真实数据集上，评估短期（分钟级）、中期（小时级）和长期（天级）预测性能，以及从单个充电站到区域和城市级别的空间聚合效果。

Result: 研究首次系统评估了电动汽车充电需求预测在广泛时间尺度和空间聚合水平上的表现，为不同应用场景提供了方法选择依据。

Conclusion: 该工作填补了电动汽车充电需求预测研究中系统性比较的空白，为电网管理和充电基础设施规划提供了重要参考。

Abstract: With the growing popularity of electric vehicles as a means of addressing climate change, concerns have emerged regarding their impact on electric grid management. As a result, predicting EV charging demand has become a timely and important research problem. While substantial research has addressed energy load forecasting in transportation, relatively few studies systematically compare multiple forecasting methods across different temporal horizons and spatial aggregation levels in diverse urban settings. This work investigates the effectiveness of five time series forecasting models, ranging from traditional statistical approaches to machine learning and deep learning methods. Forecasting performance is evaluated for short-, mid-, and long-term horizons (on the order of minutes, hours, and days, respectively), and across spatial scales ranging from individual charging stations to regional and city-level aggregations. The analysis is conducted on four publicly available real-world datasets, with results reported independently for each dataset. To the best of our knowledge, this is the first work to systematically evaluate EV charging demand forecasting across such a wide range of temporal horizons and spatial aggregation levels using multiple real-world datasets.

</details>


### [98] [SHARP-QoS: Sparsely-gated Hierarchical Adaptive Routing for joint Prediction of QoS](https://arxiv.org/abs/2512.17262)
*Suraj Kumar,Arvind Kumar,Soumi Chattopadhyay*

Main category: cs.LG

TL;DR: SHARP-QoS是一个用于联合QoS预测的统一框架，通过双机制提取分层特征、自适应特征共享和EMA损失平衡来解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的QoS数据稀疏、噪声大且具有分层依赖性，现有方法要么单独预测每个QoS参数（计算成本高、泛化差），要么联合预测但存在负迁移和表示学习不足的问题。

Method: 1. 双机制在庞加莱球中使用双曲卷积提取QoS和上下文结构的分层特征；2. 自适应特征共享机制允许信息丰富的QoS和上下文信号之间交换特征，使用门控特征融合模块进行动态特征选择；3. EMA损失平衡策略实现稳定的联合优化。

Result: 在包含2、3、4个QoS参数的三个数据集上评估，SHARP-QoS优于单任务和多任务基线模型。模型有效解决了稀疏性、异常值鲁棒性和冷启动等主要挑战，同时保持适度的计算开销。

Conclusion: SHARP-QoS通过分层特征提取、自适应特征共享和损失平衡，实现了可靠的联合QoS预测，解决了现有方法的局限性，为面向服务的计算提供了有效的解决方案。

Abstract: Dependable service-oriented computing relies on multiple Quality of Service (QoS) parameters that are essential to assess service optimality. However, real-world QoS data are extremely sparse, noisy, and shaped by hierarchical dependencies arising from QoS interactions, and geographical and network-level factors, making accurate QoS prediction challenging. Existing methods often predict each QoS parameter separately, requiring multiple similar models, which increases computational cost and leads to poor generalization. Although recent joint QoS prediction studies have explored shared architectures, they suffer from negative transfer due to loss-scaling caused by inconsistent numerical ranges across QoS parameters and further struggle with inadequate representation learning, resulting in degraded accuracy. This paper presents an unified strategy for joint QoS prediction, called SHARP-QoS, that addresses these issues using three components. First, we introduce a dual mechanism to extract the hierarchical features from both QoS and contextual structures via hyperbolic convolution formulated in the Poincaré ball. Second, we propose an adaptive feature-sharing mechanism that allows feature exchange across informative QoS and contextual signals. A gated feature fusion module is employed to support dynamic feature selection among structural and shared representations. Third, we design an EMA-based loss balancing strategy that allows stable joint optimization, thereby mitigating the negative transfer. Evaluations on three datasets with two, three, and four QoS parameters demonstrate that SHARP-QoS outperforms both single- and multi-task baselines. Extensive study shows that our model effectively addresses major challenges, including sparsity, robustness to outliers, and cold-start, while maintaining moderate computational overhead, underscoring its capability for reliable joint QoS prediction.

</details>


### [99] [A Theoretical Analysis of State Similarity Between Markov Decision Processes](https://arxiv.org/abs/2512.17265)
*Zhenyu Tao,Wei Xu,Xiaohu You*

Main category: cs.LG

TL;DR: 本文提出了广义双模拟度量（GBSM），用于测量任意马尔可夫决策过程对之间的状态相似性，相比传统双模拟度量在多MDP场景中具有更严格的理论边界和更好的性能。


<details>
  <summary>Details</summary>
Motivation: 双模拟度量（BSM）在分析单个MDP内的状态相似性方面很有效，但扩展到多个MDP之间时面临挑战。现有方法缺乏完善的数学性质，限制了MDP间的理论分析。

Method: 建立了广义双模拟度量（GBSM），严格证明了其三个基本度量性质：GBSM对称性、MDP间三角不等式和相同空间上的距离界限。利用这些性质分析了MDP间的策略迁移、状态聚合和基于采样的估计。

Result: GBSM获得了比标准BSM更严格的理论边界，提供了闭式样本复杂度估计，改进了基于BSM的渐近结果。数值实验验证了理论发现，展示了GBSM在多MDP场景中的有效性。

Conclusion: GBSM为测量任意MDP对之间的状态相似性提供了坚实的理论基础，具有更好的理论性质和实际性能，推动了多MDP场景下的强化学习分析。

Abstract: The bisimulation metric (BSM) is a powerful tool for analyzing state similarities within a Markov decision process (MDP), revealing that states closer in BSM have more similar optimal value functions. While BSM has been successfully utilized in reinforcement learning (RL) for tasks like state representation learning and policy exploration, its application to state similarity between multiple MDPs remains challenging. Prior work has attempted to extend BSM to pairs of MDPs, but a lack of well-established mathematical properties has limited further theoretical analysis between MDPs. In this work, we formally establish a generalized bisimulation metric (GBSM) for measuring state similarity between arbitrary pairs of MDPs, which is rigorously proven with three fundamental metric properties, i.e., GBSM symmetry, inter-MDP triangle inequality, and a distance bound on identical spaces. Leveraging these properties, we theoretically analyze policy transfer, state aggregation, and sampling-based estimation across MDPs, obtaining explicit bounds that are strictly tighter than existing ones derived from the standard BSM. Additionally, GBSM provides a closed-form sample complexity for estimation, improving upon existing asymptotic results based on BSM. Numerical results validate our theoretical findings and demonstrate the effectiveness of GBSM in multi-MDP scenarios.

</details>


### [100] [Understanding Generalization in Role-Playing Models via Information Theory](https://arxiv.org/abs/2512.17270)
*Yongqi Li,Hao Lang,Fei Huang,Tieyun Qian,Yongbin Li*

Main category: cs.LG

TL;DR: 论文提出R-EMID信息论指标来量化角色扮演模型在分布偏移下的性能退化，并开发强化学习框架提升对话响应概率估计，发现用户偏移风险最高且强化学习最有效。


<details>
  <summary>Details</summary>
Motivation: 角色扮演模型在实际应用中表现不佳，主要由于用户、角色和对话组合的分布偏移。现有方法如LLM-as-a-judge无法提供细粒度诊断，缺乏形式化框架来表征RPM的泛化行为。

Method: 1. 提出R-EMID信息论指标，以可解释方式测量RPM性能退化；2. 推导R-EMID上界预测最坏情况泛化性能；3. 提出协同演化强化学习框架，自适应建模用户、角色和对话上下文连接，提升对话响应生成概率估计。

Result: 评估显示用户偏移在所有偏移中风险最高，强化学习是增强RPM泛化最有效的方法。R-EMID能够有效量化RPM在不同分布偏移下的性能退化。

Conclusion: R-EMID为角色扮演模型的泛化性能提供了可解释的量化框架，协同演化强化学习能有效提升对话响应概率估计，为RPM的鲁棒部署提供了理论和方法支持。

Abstract: Role-playing models (RPMs) are widely used in real-world applications but underperform when deployed in the wild. This degradation can be attributed to distribution shifts, including user, character, and dialogue compositional shifts. Existing methods like LLM-as-a-judge fall short in providing a fine-grained diagnosis of how these shifts affect RPM generalization, and thus there lack formal frameworks to characterize RPM generalization behaviors. To bridge these gaps, we introduce an information-theoretic metric, named reasoning-based effective mutual information difference (R-EMID), to measure RPM performance degradation in an interpretable way. We also derive an upper bound on R-EMID to predict the worst-case generalization performance of RPMs and theoretically reveal how various shifts contribute to the RPM performance degradation. Moreover, we propose a co-evolving reinforcement learning framework to adaptively model the connection among user, character, and dialogue context and thus enhance the estimation of dialogue response generation probability, which is critical for calculating R-EMID. Finally, we evaluate the generalization performance of various RPMs using R-EMID, finding that user shift poses the highest risk among all shifts and reinforcement learning is the most effective approach for enhancing RPM generalization.

</details>


### [101] [MINPO: Memory-Informed Neural Pseudo-Operator to Resolve Nonlocal Spatiotemporal Dynamics](https://arxiv.org/abs/2512.17273)
*Farinaz Mostajeran,Aruzhan Tleubek,Salah A Faroughi*

Main category: cs.LG

TL;DR: MINPO是一个统一的神经网络框架，用于建模由长程空间相互作用和/或长期时间记忆引起的非局部动力学，通过学习非局部算子及其逆来直接求解积分微分方程。


<details>
  <summary>Details</summary>
Motivation: 许多物理系统表现出由积分微分方程描述的非局部时空行为。传统方法需要重复计算卷积积分，成本随核复杂度和维度快速增加。现有神经求解器只能加速特定实例，无法泛化到不同的非局部结构。

Method: MINPO使用KANs或MLPs作为编码器，学习非局部算子及其逆的神经表示，然后显式重建未知解场。通过轻量级非局部一致性损失项来保证学习算子与重建解之间的一致性。

Result: 与经典方法和最先进的基于MLPs的神经策略（A-PINN、fPINN）及其KAN变体（A-PIKAN、fPIKAN）相比，MINPO在准确性方面表现出色，并展示了在处理不同核类型、不同核维度和重复核积分计算需求方面的鲁棒性。

Conclusion: MINPO超越了特定问题公式，为受非局部算子支配的系统提供了一个统一框架，能够自然捕获并高效解决由广泛IDE谱及其子集（包括分数PDE）支配的非局部时空依赖关系。

Abstract: Many physical systems exhibit nonlocal spatiotemporal behaviors described by integro-differential equations (IDEs). Classical methods for solving IDEs require repeatedly evaluating convolution integrals, whose cost increases quickly with kernel complexity and dimensionality. Existing neural solvers can accelerate selected instances of these computations, yet they do not generalize across diverse nonlocal structures. In this work, we introduce the Memory-Informed Neural Pseudo-Operator (MINPO), a unified framework for modeling nonlocal dynamics arising from long-range spatial interactions and/or long-term temporal memory. MINPO, employing either Kolmogorov-Arnold Networks (KANs) or multilayer perceptron networks (MLPs) as encoders, learns the nonlocal operator and its inverse directly through neural representations, and then explicitly reconstruct the unknown solution fields. The learning is guarded by a lightweight nonlocal consistency loss term to enforce coherence between the learned operator and reconstructed solution. The MINPO formulation allows to naturally capture and efficiently resolve nonlocal spatiotemporal dependencies governed by a wide spectrum of IDEs and their subsets, including fractional PDEs. We evaluate the efficacy of MINPO in comparison with classical techniques and state-of-the-art neural-based strategies based on MLPs, such as A-PINN and fPINN, along with their newly-developed KAN variants, A-PIKAN and fPIKAN, designed to facilitate a fair comparison. Our study offers compelling evidence of the accuracy of MINPO and demonstrates its robustness in handling (i) diverse kernel types, (ii) different kernel dimensionalities, and (iii) the substantial computational demands arising from repeated evaluations of kernel integrals. MINPO, thus, generalizes beyond problem-specific formulations, providing a unified framework for systems governed by nonlocal operators.

</details>


### [102] [Alzheimer's Disease Brain Network Mining](https://arxiv.org/abs/2512.17276)
*Alireza Moayedikia,Sara Fin*

Main category: cs.LG

TL;DR: MATCH-AD是一个半监督学习框架，通过结合深度表示学习、图标签传播和最优传输理论，在仅有三分之一标注数据的情况下实现近乎完美的阿尔茨海默病诊断准确率。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病诊断面临标注数据稀缺的挑战，临床评估昂贵且侵入性强，导致大多数神经影像数据集缺乏真实标签。需要开发能够利用有限标注数据挖掘大规模未标注数据潜力的方法。

Method: 提出MATCH-AD框架，整合三个核心组件：1)深度表示学习提取特征；2)基于图的标签传播利用数据流形结构将诊断信息从少量标注样本传播到大量未标注样本；3)最优传输理论（Wasserstein距离）量化认知状态间的疾病进展。

Result: 在NACC近5000名受试者数据集上评估，包含结构MRI、脑脊液生物标志物和临床变量。尽管只有不到三分之一的样本有真实标签，但实现了近乎完美的诊断准确率，Kappa系数表明几乎完全一致，显著优于所有基线方法。

Conclusion: 该研究表明，有原则的半监督学习能够释放全球积累的部分标注神经影像数据的诊断潜力，大幅减少标注负担，同时保持适合临床部署的准确性，为阿尔茨海默病诊断提供了实用解决方案。

Abstract: Machine learning approaches for Alzheimer's disease (AD) diagnosis face a fundamental challenges. Clinical assessments are expensive and invasive, leaving ground truth labels available for only a fraction of neuroimaging datasets. We introduce Multi view Adaptive Transport Clustering for Heterogeneous Alzheimer's Disease (MATCH-AD), a semi supervised framework that integrates deep representation learning, graph-based label propagation, and optimal transport theory to address this limitation. The framework leverages manifold structure in neuroimaging data to propagate diagnostic information from limited labeled samples to larger unlabeled populations, while using Wasserstein distances to quantify disease progression between cognitive states. Evaluated on nearly five thousand subjects from the National Alzheimer's Coordinating Center, encompassing structural MRI measurements from hundreds of brain regions, cerebrospinal fluid biomarkers, and clinical variables MATCHAD achieves near-perfect diagnostic accuracy despite ground truth labels for less than one-third of subjects. The framework substantially outperforms all baseline methods, achieving kappa indicating almost perfect agreement compared to weak agreement for the best baseline, a qualitative transformation in diagnostic reliability. Performance remains clinically useful even under severe label scarcity, and we provide theoretical convergence guarantees with proven bounds on label propagation error and transport stability. These results demonstrate that principled semi-supervised learning can unlock the diagnostic potential of the vast repositories of partially annotated neuroimaging data accumulating worldwide, substantially reducing annotation burden while maintaining accuracy suitable for clinical deployment.

</details>


### [103] [M2RU: Memristive Minion Recurrent Unit for Continual Learning at the Edge](https://arxiv.org/abs/2512.17299)
*Abdullah M. Zyarah,Dhireesha Kudithipudi*

Main category: cs.LG

TL;DR: M2RU是一种混合信号架构，实现了minion循环单元，用于边缘平台上的高效时序处理和片上持续学习，相比CMOS数字设计能效提升29倍。


<details>
  <summary>Details</summary>
Motivation: 边缘平台上的持续学习面临挑战，因为循环网络需要能耗高的训练过程和频繁的数据移动，这在嵌入式部署中不切实际。

Method: 提出M2RU混合信号架构，集成加权位流技术（使多比特数字输入无需高分辨率转换即可在交叉阵列中处理）和经验回放机制（在域转移下稳定学习）。

Result: M2RU在48.62mW功耗下实现15GOPS，对应312GOPS/W，在顺序MNIST和CIFAR-10任务上保持与软件基线5%以内的精度差距，相比CMOS数字设计能效提升29倍，预期操作寿命12.2年。

Conclusion: M2RU为边缘级时序智能中的实时适应提供了一个可扩展且高能效的平台。

Abstract: Continual learning on edge platforms remains challenging because recurrent networks depend on energy-intensive training procedures and frequent data movement that are impractical for embedded deployments. This work introduces M2RU, a mixed-signal architecture that implements the minion recurrent unit for efficient temporal processing with on-chip continual learning. The architecture integrates weighted-bit streaming, which enables multi-bit digital inputs to be processed in crossbars without high-resolution conversion, and an experience replay mechanism that stabilizes learning under domain shifts. M2RU achieves 15 GOPS at 48.62 mW, corresponding to 312 GOPS per watt, and maintains accuracy within 5 percent of software baselines on sequential MNIST and CIFAR-10 tasks. Compared with a CMOS digital design, the accelerator provides 29X improvement in energy efficiency. Device-aware analysis shows an expected operational lifetime of 12.2 years under continual learning workloads. These results establish M2RU as a scalable and energy-efficient platform for real-time adaptation in edge-level temporal intelligence.

</details>


### [104] [Explanation Beyond Intuition: A Testable Criterion for Inherent Explainability](https://arxiv.org/abs/2512.17316)
*Michael Merry,Pat Riddle,Jim Warren*

Main category: cs.LG

TL;DR: 该论文提出了一个基于图论的固有可解释性标准，用于区分可解释模型与已解释模型，并以临床使用的PREDICT心血管风险模型为例进行了验证。


<details>
  <summary>Details</summary>
Motivation: 当前可解释人工智能领域缺乏一致的固有可解释性定义和测试标准，现有工作要么依赖度量指标，要么诉诸直觉判断，需要建立严谨的评估框架。

Method: 使用图论表示和分解模型结构，形成结构局部解释作为可验证的假设-证据注释，然后重新组合成全局解释，建立固有可解释性标准。

Result: 提出的标准与现有固有可解释性直觉相符，能解释为什么大型回归模型可能不可解释而稀疏神经网络可能可解释，并成功为临床使用的PREDICT心血管风险模型提供了完整解释。

Conclusion: 该工作为可解释性研究提供了结构化框架，为监管机构提供了灵活而严谨的合规测试标准，并证明了PREDICT模型具有固有可解释性。

Abstract: Inherent explainability is the gold standard in Explainable Artificial Intelligence (XAI). However, there is not a consistent definition or test to demonstrate inherent explainability. Work to date either characterises explainability through metrics, or appeals to intuition - "we know it when we see it". We propose a globally applicable criterion for inherent explainability. The criterion uses graph theory for representing and decomposing models for structure-local explanation, and recomposing them into global explanations. We form the structure-local explanations as annotations, a verifiable hypothesis-evidence structure that allows for a range of explanatory methods to be used. This criterion matches existing intuitions on inherent explainability, and provides justifications why a large regression model may not be explainable but a sparse neural network could be. We differentiate explainable -- a model that allows for explanation -- and \textit{explained} -- one that has a verified explanation. Finally, we provide a full explanation of PREDICT -- a Cox proportional hazards model of cardiovascular disease risk, which is in active clinical use in New Zealand. It follows that PREDICT is inherently explainable. This work provides structure to formalise other work on explainability, and allows regulators a flexible but rigorous test that can be used in compliance frameworks.

</details>


### [105] [Task Schema and Binding: A Double Dissociation Study of In-Context Learning](https://arxiv.org/abs/2512.17325)
*Chaeha Kim*

Main category: cs.LG

TL;DR: ICL分解为任务模式识别和绑定两个可分离机制，通过激活修补实验验证，具有架构通用性，对提示工程有实际意义


<details>
  <summary>Details</summary>
Motivation: 解决ICL机制不明确的问题，挑战将ICL视为单一机制的传统观点，为双过程理论提供因果证据

Method: 在9个模型（7个Transformer家族和Mamba，370M-13B参数）上进行激活修补实验，分析任务模式和绑定机制的分离性

Result: 1. 双分离：任务模式通过后期MLP修补100%转移，绑定通过残差流修补62%转移；2. 先验-模式权衡：模式依赖与先验知识负相关；3. 架构通用性：机制在所有测试架构中都存在

Conclusion: ICL由可分离的任务模式和绑定机制组成，先验知识通过注意力误路由而非直接输出竞争干扰，这对提示工程和ICL系统可靠性有重要实践意义

Abstract: We provide causal mechanistic validation that in-context learning (ICL) decomposes into two separable mechanisms: Task Schema (abstract task type recognition) and Binding (specific input-output associations). Through activation patching experiments across 9 models from 7 Transformer families plus Mamba (370M-13B parameters), we establish three key findings:
  1. Double dissociation: Task Schema transfers at 100% via late MLP patching; Binding transfers at 62% via residual stream patching -- proving separable mechanisms
  2. Prior-Schema trade-off: Schema reliance inversely correlates with prior knowledge (Spearman rho = -0.596, p < 0.001, N=28 task-model pairs)
  3. Architecture generality: The mechanism operates across all tested architectures including the non-Transformer Mamba
  These findings offer a mechanistic account of the ICL puzzle that contrasts with prior views treating ICL as a monolithic mechanism (whether retrieval-based, gradient descent-like, or purely Bayesian). By establishing that Schema and Binding are neurally dissociable -- not merely behavioral modes -- we provide causal evidence for dual-process theories of ICL. Models rely on Task Schema when prior knowledge is absent, but prior knowledge interferes through attentional mis-routing (72.7% recency bias) rather than direct output competition (0%). This explains why arbitrary mappings succeed (zero prior leads to full Schema reliance) while factual overrides fail -- and reveals that the true bottleneck is attentional, not output-level. Practical implications: Understanding these dual mechanisms enables more efficient prompt engineering -- reliable schema transfer reduces required demonstrations for novel tasks, while prior-aware design can mitigate the 38% binding failure rate in high-prior scenarios, improving ICL system reliability in production deployments.

</details>


### [106] [Adaptive Graph Pruning with Sudden-Events Evaluation for Traffic Prediction using Online Semi-Decentralized ST-GNNs](https://arxiv.org/abs/2512.17352)
*Ivan Kralj,Lodovico Giaretta,Gordan Ježić,Ivana Podnar Žarko,Šarūnas Girdzijauskas*

Main category: cs.LG

TL;DR: 提出自适应剪枝算法减少ST-GNN在边缘计算中的通信开销，同时引入SEPA新指标评估交通事件预测能力


<details>
  <summary>Details</summary>
Motivation: ST-GNN在智能交通系统中处理分布式传感器数据时，相邻边缘节点间重复传输重叠节点特征导致通信开销过大

Method: 提出自适应剪枝算法动态过滤冗余邻居特征，基于近期模型性能调整剪枝率；引入SEPA指标专门评估交通减速和恢复事件的预测能力

Result: 在PeMS-BAY和PeMSD7-M数据集上，自适应剪枝算法在保持预测精度的同时显著降低通信成本，SEPA指标揭示了空间连接性对动态交通预测的真正价值

Conclusion: 通信开销可以在不损害对关键交通事件响应能力的情况下显著降低，自适应剪枝算法在在线半去中心化设置中有效平衡了通信效率和预测性能

Abstract: Spatio-Temporal Graph Neural Networks (ST-GNNs) are well-suited for processing high-frequency data streams from geographically distributed sensors in smart mobility systems. However, their deployment at the edge across distributed compute nodes (cloudlets) createssubstantial communication overhead due to repeated transmission of overlapping node features between neighbouring cloudlets. To address this, we propose an adaptive pruning algorithm that dynamically filters redundant neighbour features while preserving the most informative spatial context for prediction. The algorithm adjusts pruning rates based on recent model performance, allowing each cloudlet to focus on regions experiencing traffic changes without compromising accuracy. Additionally, we introduce the Sudden Event Prediction Accuracy (SEPA), a novel event-focused metric designed to measure responsiveness to traffic slowdowns and recoveries, which are often missed by standard error metrics. We evaluate our approach in an online semi-decentralized setting with traditional FL, server-free FL, and Gossip Learning on two large-scale traffic datasets, PeMS-BAY and PeMSD7-M, across short-, mid-, and long-term prediction horizons. Experiments show that, in contrast to standard metrics, SEPA exposes the true value of spatial connectivity in predicting dynamic and irregular traffic. Our adaptive pruning algorithm maintains prediction accuracy while significantly lowering communication cost in all online semi-decentralized settings, demonstrating that communication can be reduced without compromising responsiveness to critical traffic events.

</details>


### [107] [Adversarially Robust Detection of Harmful Online Content: A Computational Design Science Approach](https://arxiv.org/abs/2512.17367)
*Yidong Chai,Yi Liu,Mohammadreza Ebrahimi,Weifeng Li,Balaji Padmanabhan*

Main category: cs.LG

TL;DR: 提出LLM-SGA框架和ARHOCD检测器，通过集成学习、动态权重分配和对抗训练，提升有害内容检测的对抗鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 社交媒体有害内容检测模型易受对抗攻击，现有方法难以同时保证对抗鲁棒性和检测准确性，需要新的解决方案。

Method: 1) 提出LLM-SGA框架，利用文本对抗攻击的关键不变性；2) 实例化ARHOCD检测器，包含集成检测器、基于贝叶斯推理的动态权重分配方法、迭代优化的对抗训练策略。

Result: 在仇恨言论、谣言和极端主义内容三个数据集上评估，ARHOCD在对抗条件下表现出强泛化能力和更高的检测准确率。

Conclusion: ARHOCD通过创新的框架设计和组件，有效提升了有害内容检测的对抗鲁棒性，解决了现有研究的局限性。

Abstract: Social media platforms are plagued by harmful content such as hate speech, misinformation, and extremist rhetoric. Machine learning (ML) models are widely adopted to detect such content; however, they remain highly vulnerable to adversarial attacks, wherein malicious users subtly modify text to evade detection. Enhancing adversarial robustness is therefore essential, requiring detectors that can defend against diverse attacks (generalizability) while maintaining high overall accuracy. However, simultaneously achieving both optimal generalizability and accuracy is challenging. Following the computational design science paradigm, this study takes a sequential approach that first proposes a novel framework (Large Language Model-based Sample Generation and Aggregation, LLM-SGA) by identifying the key invariances of textual adversarial attacks and leveraging them to ensure that a detector instantiated within the framework has strong generalizability. Second, we instantiate our detector (Adversarially Robust Harmful Online Content Detector, ARHOCD) with three novel design components to improve detection accuracy: (1) an ensemble of multiple base detectors that exploits their complementary strengths; (2) a novel weight assignment method that dynamically adjusts weights based on each sample's predictability and each base detector's capability, with weights initialized using domain knowledge and updated via Bayesian inference; and (3) a novel adversarial training strategy that iteratively optimizes both the base detectors and the weight assignor. We addressed several limitations of existing adversarial robustness enhancement research and empirically evaluated ARHOCD across three datasets spanning hate speech, rumor, and extremist content. Results show that ARHOCD offers strong generalizability and improves detection accuracy under adversarial conditions.

</details>


### [108] [AdvJudge-Zero: Binary Decision Flips in LLM-as-a-Judge via Adversarial Control Tokens](https://arxiv.org/abs/2512.17375)
*Tung-Ling Li,Yuhao Wu,Hongliang Liu*

Main category: cs.LG

TL;DR: 论文揭示了奖励模型和LLM-as-a-Judge系统存在安全漏洞：低困惑度的控制令牌序列可以翻转二元评估结果，导致高误判率，并提出AdvJudge-Zero方法和对抗训练解决方案。


<details>
  <summary>Details</summary>
Motivation: 奖励模型和LLM-as-a-Judge系统是现代后训练流程（如RLHF、DPO、RLAIF）的核心组件，负责提供标量反馈和二元决策来指导模型选择和强化学习微调。然而这些评判系统存在安全漏洞，可能被恶意利用进行奖励攻击。

Method: 提出AdvJudge-Zero方法，利用模型的下一令牌分布和束搜索探索从头发现多样化的控制令牌序列。分析显示这些控制令牌在隐藏状态空间引发低秩"软模式"扰动，与评判系统的拒绝方向反对齐。

Result: 实验表明，这些控制令牌在数学和推理基准测试中导致大型开源权重和专业评判模型对错误答案产生极高的误判率（假阳性）。对抗训练可以显著减少假阳性同时保持评估质量。

Conclusion: 评判系统存在现实的安全风险，低困惑度控制令牌可导致奖励攻击。AdvJudge-Zero方法能有效发现这些漏洞，而基于LoRA的对抗训练是可行的防御方案，需要在后训练流程中加强安全防护。

Abstract: Reward models and LLM-as-a-Judge systems are central to modern post-training pipelines such as RLHF, DPO, and RLAIF, where they provide scalar feedback and binary decisions that guide model selection and RL-based fine-tuning. We show that these judge systems exhibit a recurring vulnerability: short sequences of low-perplexity control tokens can flip many binary evaluations from correct ``No'' judgments to incorrect ``Yes'' judgments by steering the last-layer logit gap. These control tokens are patterns that a policy model could plausibly generate during post-training, and thus represent realistic reward-hacking risks rather than worst-case adversarial strings. Our method, AdvJudge-Zero, uses the model's next-token distribution and beam-search exploration to discover diverse control-token sequences from scratch, and our analysis shows that the induced hidden-state perturbations concentrate in a low-rank ``soft mode'' that is anti-aligned with the judge's refusal direction. Empirically, these tokens cause very high false positive rates when large open-weight and specialized judge models score incorrect answers on math and reasoning benchmarks. Finally, we show that LoRA-based adversarial training on small sets of control-token-augmented examples can markedly reduce these false positives while preserving evaluation quality.

</details>


### [109] [DeepShare: Sharing ReLU Across Channels and Layers for Efficient Private Inference](https://arxiv.org/abs/2512.17398)
*Yonathan Bornfeld,Shai Avidan*

Main category: cs.LG

TL;DR: 提出一种新的隐私推理激活模块，通过原型通道复用DReLU操作，大幅减少隐私推理中的非线性计算开销


<details>
  <summary>Details</summary>
Motivation: 隐私推理中的主要计算瓶颈是ReLU门计算，现有方法致力于减少网络中的ReLU数量。作者发现DReLU（ReLU的非线性阶跃函数）可以被多个ReLU操作复用

Method: 提出新的激活模块：仅对原型通道子集执行DReLU操作，其余复制通道从对应的原型通道神经元复制DReLU结果。将此思想扩展到不同层之间

Result: 在ResNet类型网络中大幅减少DReLU操作数量；理论分析显示新方法能用1个非线性和2个神经元解决扩展XOR问题；在多个分类任务上达到SOTA，在图像分割任务上达到SOTA

Conclusion: 通过DReLU复用机制有效减少隐私推理中的计算开销，在保持隐私保护的同时提升效率，为隐私推理提供了新的优化方向

Abstract: Private Inference (PI) uses cryptographic primitives to perform privacy preserving machine learning. In this setting, the owner of the network runs inference on the data of the client without learning anything about the data and without revealing any information about the model. It has been observed that a major computational bottleneck of PI is the calculation of the gate (i.e., ReLU), so a considerable amount of effort have been devoted to reducing the number of ReLUs in a given network.
  We focus on the DReLU, which is the non-linear step function of the ReLU and show that one DReLU can serve many ReLU operations. We suggest a new activation module where the DReLU operation is only performed on a subset of the channels (Prototype channels), while the rest of the channels (replicate channels) replicates the DReLU of each of their neurons from the corresponding neurons in one of the prototype channels. We then extend this idea to work across different layers.
  We show that this formulation can drastically reduce the number of DReLU operations in resnet type network. Furthermore, our theoretical analysis shows that this new formulation can solve an extended version of the XOR problem, using just one non-linearity and two neurons, something that traditional formulations and some PI specific methods cannot achieve. We achieve new SOTA results on several classification setups, and achieve SOTA results on image segmentation.

</details>


### [110] [meval: A Statistical Toolbox for Fine-Grained Model Performance Analysis](https://arxiv.org/abs/2512.17409)
*Dishantkumar Sutariya,Eike Petersen*

Main category: cs.LG

TL;DR: 提出一个统计工具箱，用于在医学影像应用中系统分析机器学习模型在不同患者亚组中的性能差异，解决样本量差异、多重比较校正等统计挑战。


<details>
  <summary>Details</summary>
Motivation: 当前分析机器学习模型在不同患者亚组中的性能已成为标准做法，但进行严格的统计分析存在挑战：需要选择合适的性能指标处理不同样本量和基础率，确定指标不确定性，校正多重比较，以及在交叉分析中从组合众多的亚组中找到"最有趣"的亚组。

Method: 开发一个统计工具箱，专门针对医学影像应用设计，提供系统的方法来评估模型在不同亚组中的性能差异。该工具箱处理统计挑战，包括指标选择、不确定性估计、多重比较校正，以及交叉分析中的亚组发现机制。

Result: 在ISIC2020皮肤病变恶性分类和MIMIC-CXR胸部X光疾病分类两个案例研究中展示了工具箱的应用，验证了其在实际医学影像任务中的实用性。

Conclusion: 该统计工具箱使从业者能够轻松而严格地评估模型在不同亚组中的潜在性能差异，特别适用于医学影像应用，有助于发现重要的模型失败模式。

Abstract: Analyzing machine learning model performance stratified by patient and recording properties is becoming the accepted norm and often yields crucial insights about important model failure modes. Performing such analyses in a statistically rigorous manner is non-trivial, however. Appropriate performance metrics must be selected that allow for valid comparisons between groups of different sample sizes and base rates; metric uncertainty must be determined and multiple comparisons be corrected for, in order to assess whether any observed differences may be purely due to chance; and in the case of intersectional analyses, mechanisms must be implemented to find the most `interesting' subgroups within combinatorially many subgroup combinations. We here present a statistical toolbox that addresses these challenges and enables practitioners to easily yet rigorously assess their models for potential subgroup performance disparities. While broadly applicable, the toolbox is specifically designed for medical imaging applications. The analyses provided by the toolbox are illustrated in two case studies, one in skin lesion malignancy classification on the ISIC2020 dataset and one in chest X-ray-based disease classification on the MIMIC-CXR dataset.

</details>


### [111] [Assessing Long-Term Electricity Market Design for Ambitious Decarbonization Targets using Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2512.17444)
*Javier Gonzalez-Ruiz,Carlos Rodriguez-Pardo,Iacopo Savelli,Alice Di Bella,Massimo Tavoni*

Main category: cs.LG

TL;DR: 提出一个基于多智能体强化学习的模型，用于模拟电力市场长期投资决策，支持政策制定者设计和评估市场机制，应用于意大利电力系统案例研究。


<details>
  <summary>Details</summary>
Motivation: 电力系统对实现碳中和至关重要，但现有工具不足以支持政策制定者设计和评估长期电力市场机制，需要更先进的建模工具来应对复杂的市场动态和政策交互。

Method: 采用多智能体强化学习框架，发电公司作为利润最大化智能体在批发电力市场中进行投资决策，使用独立近端策略优化算法，并通过超参数搜索确保分散训练符合竞争行为。

Result: 应用于意大利电力系统的案例研究表明，市场设计对电力部门脱碳和避免价格波动具有关键作用，框架能够评估多种政策和市场机制同时交互的复杂场景。

Conclusion: 提出的多智能体强化学习框架为政策制定者提供了评估长期电力市场的有效工具，能够捕捉脱碳能源系统的关键特征，支持市场设计和政策制定。

Abstract: Electricity systems are key to transforming today's society into a carbon-free economy. Long-term electricity market mechanisms, including auctions, support schemes, and other policy instruments, are critical in shaping the electricity generation mix. In light of the need for more advanced tools to support policymakers and other stakeholders in designing, testing, and evaluating long-term markets, this work presents a multi-agent reinforcement learning model capable of capturing the key features of decarbonizing energy systems. Profit-maximizing generation companies make investment decisions in the wholesale electricity market, responding to system needs, competitive dynamics, and policy signals. The model employs independent proximal policy optimization, which was selected for suitability to the decentralized and competitive environment. Nevertheless, given the inherent challenges of independent learning in multi-agent settings, an extensive hyperparameter search ensures that decentralized training yields market outcomes consistent with competitive behavior. The model is applied to a stylized version of the Italian electricity system and tested under varying levels of competition, market designs, and policy scenarios. Results highlight the critical role of market design for decarbonizing the electricity sector and avoiding price volatility. The proposed framework allows assessing long-term electricity markets in which multiple policy and market mechanisms interact simultaneously, with market participants responding and adapting to decarbonization pathways.

</details>


### [112] [Learning What to Write: Write-Gated KV for Efficient Long-Context Inference](https://arxiv.org/abs/2512.17452)
*Yen-Chieh Huang,Rui Fang,Ming-Syan Chen,Pi-Cheng Hsiu*

Main category: cs.LG

TL;DR: WG-KV通过写入门控机制预测token效用，选择性写入KV缓存，减少46-57%内存使用，提升推理速度3倍以上


<details>
  <summary>Details</summary>
Motivation: 长上下文LLM推理面临二次注意力复杂度和线性KV缓存增长的瓶颈，现有方法通过后处理选择或淘汰忽略了根本低效性：无差别写入持久内存

Method: 将KV缓存管理形式化为因果系统三要素：KV准入、选择和淘汰，通过Write-Gated KV机制学习预测token进入缓存前的效用，过滤低效用状态，维护紧凑全局缓存和滑动本地缓存

Result: 在Llama模型上减少46-57%内存使用，预填充速度提升3.03-3.45倍，解码速度提升1.89-2.56倍，精度损失可忽略，兼容FlashAttention和分页KV系统

Conclusion: 学习"写什么"是高效长上下文推理的原则性和实用方法，写入门控KV缓存管理是有效解决方案

Abstract: Long-context LLM inference is bottlenecked by the quadratic attention complexity and linear KV cache growth. Prior approaches mitigate this via post-hoc selection or eviction but overlook the root inefficiency: indiscriminate writing to persistent memory. In this paper, we formalize KV cache management as a causal system of three primitives: KV Admission, Selection, and Eviction. We instantiate KV Admission via Write-Gated KV, a lightweight mechanism that learns to predict token utility before it enters the cache. By filtering out low-utility states early to maintain a compact global cache alongside a sliding local cache, Write-Gated KV reduces memory usage by 46-57% and delivers 3.03-3.45$\times$ prefill and 1.89-2.56$\times$ decode speedups on Llama model with negligible accuracy loss, all while remaining compatible with FlashAttention and paged-KV systems. These results demonstrate that learning what to write, is a principled and practical recipe for efficient long-context inference. Code is available at https://github.com/EMCLab-Sinica/WG-KV .

</details>


### [113] [A lightweight Spatial-Temporal Graph Neural Network for Long-term Time Series Forecasting](https://arxiv.org/abs/2512.17453)
*Henok Tenaw Moges,Deshendran Moodley*

Main category: cs.LG

TL;DR: Lite-STGNN是一个轻量级时空图神经网络，用于长期多元预测，结合了分解式时间建模和可学习的稀疏图结构，在保持参数效率的同时实现了最先进的准确性。


<details>
  <summary>Details</summary>
Motivation: 需要开发一个轻量级、高效且可解释的框架来处理长期多元时间序列预测问题，同时克服传统基于Transformer方法的计算复杂性和参数过多的问题。

Method: 1. 时间模块：采用趋势-季节性分解进行时间建模；2. 空间模块：使用低秩Top-K邻接学习和保守的逐层门控进行消息传递，增强线性基线的空间校正能力。

Result: 在四个基准数据集上达到最先进的准确性（预测步长可达720步），参数效率高，训练速度显著快于基于Transformer的方法。消融研究表明空间模块比时间基线提升4.6%，Top-K增强局部性3.3%，学习到的邻接矩阵揭示了领域特定的交互动态。

Conclusion: Lite-STGNN提供了一个紧凑、可解释且高效的长期多元时间序列预测框架，在准确性、效率和可解释性之间取得了良好平衡。

Abstract: We propose Lite-STGNN, a lightweight spatial-temporal graph neural network for long-term multivariate forecasting that integrates decomposition-based temporal modeling with learnable sparse graph structure. The temporal module applies trend-seasonal decomposition, while the spatial module performs message passing with low-rank Top-$K$ adjacency learning and conservative horizon-wise gating, enabling spatial corrections that enhance a strong linear baseline. Lite-STGNN achieves state-of-the-art accuracy on four benchmark datasets for horizons up to 720 steps, while being parameter-efficient and substantially faster to train than transformer-based methods. Ablation studies show that the spatial module yields 4.6% improvement over the temporal baseline, Top-$K$ enhances locality by 3.3%, and learned adjacency matrices reveal domain-specific interaction dynamics. Lite-STGNN thus offers a compact, interpretable, and efficient framework for long-term multivariate time series forecasting.

</details>


### [114] [Deep Learning-Based Surrogate Creep Modelling in Inconel 625: A High-Temperature Alloy Study](https://arxiv.org/abs/2512.17477)
*Shubham Das,Kaushal Singhania,Amit Sadhu,Suprabhat Das,Arghya Nandi*

Main category: cs.LG

TL;DR: 使用深度学习替代模型（BiLSTM-VAE和BiLSTM-Transformer）快速预测Inconel 625高温合金的蠕变应变，相比传统ANSYS仿真实现秒级预测，大幅提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 高温合金如Inconel 625的蠕变行为对航空航天和能源系统的长期可靠性至关重要。传统有限元仿真（如ANSYS）计算成本高，单次10,000小时模拟需要30-40分钟，限制了设计优化和结构健康监测的效率。

Method: 使用ANSYS基于Norton定律生成单轴应力（50-150 MPa）和温度（700-1000°C）下的蠕变应变数据。训练两种深度学习架构：1）BiLSTM变分自编码器（BiLSTM-VAE），提供不确定性感知和生成式预测；2）BiLSTM-Transformer混合模型，利用自注意力机制捕捉长期时间依赖关系。

Result: 两种替代模型均表现出色：BiLSTM-VAE提供稳定可靠的蠕变应变预测，BiLSTM-Transformer在整个时间范围内实现高确定性精度。计算效率大幅提升：ANSYS仿真需要30-40分钟，而替代模型仅需几秒钟即可完成预测。

Conclusion: 深度学习替代模型为高温合金蠕变评估提供了快速、准确的解决方案，显著加速设计优化和结构健康监测流程，为高温合金应用提供了可扩展的预测框架。

Abstract: Time-dependent deformation, particularly creep, in high-temperature alloys such as Inconel 625 is a key factor in the long-term reliability of components used in aerospace and energy systems. Although Inconel 625 shows excellent creep resistance, finite-element creep simulations in tools such as ANSYS remain computationally expensive, often requiring tens of minutes for a single 10,000-hour run. This work proposes deep learning based surrogate models to provide fast and accurate replacements for such simulations. Creep strain data was generated in ANSYS using the Norton law under uniaxial stresses of 50 to 150 MPa and temperatures of 700 to 1000 $^\circ$C, and this temporal dataset was used to train two architectures: a BiLSTM Variational Autoencoder for uncertainty-aware and generative predictions, and a BiLSTM Transformer hybrid that employs self-attention to capture long-range temporal behavior. Both models act as surrogate predictors, with the BiLSTM-VAE offering probabilistic output and the BiLSTM-Transformer delivering high deterministic accuracy. Performance is evaluated using RMSE, MAE, and $R^2$. Results show that the BiLSTM-VAE provides stable and reliable creep strain forecasts, while the BiLSTM-Transformer achieves strong accuracy across the full time range. Latency tests indicate substantial speedup: while each ANSYS simulation requires 30 to 40 minutes for a given stress-temperature condition, the surrogate models produce predictions within seconds. The proposed framework enables rapid creep assessment for design optimization and structural health monitoring, and provides a scalable solution for high-temperature alloy applications.

</details>


### [115] [SafeBench-Seq: A Homology-Clustered, CPU-Only Baseline for Protein Hazard Screening with Physicochemical/Composition Features and Cluster-Aware Confidence Intervals](https://arxiv.org/abs/2512.17527)
*Muhammad Haris Khan*

Main category: cs.LG

TL;DR: SafeBench-Seq：一个基于公开数据的蛋白质序列危害筛查基准测试，采用同源性聚类和集群级保留评估，提供可解释特征和校准概率，用于CPU上的生物安全风险评估。


<details>
  <summary>Details</summary>
Motivation: 蛋白质设计基础模型存在生物安全风险，但社区缺乏简单、可重复的序列级危害筛查基准，需要能在普通CPU上运行且在同源性控制下明确评估的方法。

Method: 从公开数据构建基准（SafeProtein危害数据和UniProt良性数据），使用可解释特征（全局物理化学描述符和氨基酸组成），通过≤40%同源性聚类进行集群级保留评估，提供校准概率和多种评估指标。

Result: 同源性聚类评估相比随机分割显著高估鲁棒性；校准线性模型表现出较好的校准性能，而树集成模型保留稍高的Brier/ECE分数；基准仅发布元数据（不包含危害序列），确保可重复性。

Conclusion: SafeBench-Seq提供了一个CPU专用、可重复的蛋白质序列危害筛查基准，通过同源性控制评估和校准概率，为生物安全风险评估提供了严格的基础设施。

Abstract: Foundation models for protein design raise concrete biosecurity risks, yet the community lacks a simple, reproducible baseline for sequence-level hazard screening that is explicitly evaluated under homology control and runs on commodity CPUs. We introduce SafeBench-Seq, a metadata-only, reproducible benchmark and baseline classifier built entirely from public data (SafeProtein hazards and UniProt benigns) and interpretable features (global physicochemical descriptors and amino-acid composition). To approximate "never-before-seen" threats, we homology-cluster the combined dataset at <=40% identity and perform cluster-level holdouts (no cluster overlap between train/test). We report discrimination (AUROC/AUPRC) and screening-operating points (TPR@1% FPR; FPR@95% TPR) with 95% bootstrap confidence intervals (n=200), and we provide calibrated probabilities via CalibratedClassifierCV (isotonic for Logistic Regression / Random Forest; Platt sigmoid for Linear SVM). We quantify probability quality using Brier score, Expected Calibration Error (ECE; 15 bins), and reliability diagrams. Shortcut susceptibility is probed via composition-preserving residue shuffles and length-/composition-only ablations. Empirically, random splits substantially overestimate robustness relative to homology-clustered evaluation; calibrated linear models exhibit comparatively good calibration, while tree ensembles retain slightly higher Brier/ECE. SafeBench-Seq is CPU-only, reproducible, and releases metadata only (accessions, cluster IDs, split labels), enabling rigorous evaluation without distributing hazardous sequences.

</details>


### [116] [NetworkFF: Unified Layer Optimization in Forward-Only Neural Networks](https://arxiv.org/abs/2512.17531)
*Salar Beigzad*

Main category: cs.LG

TL;DR: 提出协作前向-前向算法，通过层间协作机制改进原始前向-前向算法，解决层间隔离问题，提升深层架构收敛效率


<details>
  <summary>Details</summary>
Motivation: 传统前向-前向算法存在层间隔离问题，各层独立优化"优良度"函数，缺乏集体学习动态，限制了表示协调和深层架构的收敛效率

Method: 提出协作前向-前向学习框架，包含两种协作范式：固定协作CFF（恒定层间耦合）和自适应协作CFF（可学习协作参数）。协作优良度函数整合所有层的加权贡献，实现协调特征学习

Result: 在MNIST和Fashion-MNIST数据集上评估显示，相比基线前向-前向实现有显著性能提升

Conclusion: 层间协作是前向-前向学习的基本增强机制，具有立即应用于神经形态计算架构和能源受限AI系统的潜力

Abstract: The Forward-Forward algorithm eliminates backpropagation's memory constraints and biological implausibility through dual forward passes with positive and negative data. However, conventional implementations suffer from critical inter-layer isolation, where layers optimize goodness functions independently without leveraging collective learning dynamics. This isolation constrains representational coordination and limits convergence efficiency in deeper architectures. This paper introduces Collaborative Forward-Forward (CFF) learning, extending the original algorithm through inter-layer cooperation mechanisms that preserve forward-only computation while enabling global context integration. Our framework implements two collaborative paradigms: Fixed CFF (F-CFF) with constant inter-layer coupling and Adaptive CFF (A-CFF) with learnable collaboration parameters that evolve during training. The collaborative goodness function incorporates weighted contributions from all layers, enabling coordinated feature learning while maintaining memory efficiency and biological plausibility. Comprehensive evaluation on MNIST and Fashion-MNIST demonstrates significant performance improvements over baseline Forward-Forward implementations. These findings establish inter-layer collaboration as a fundamental enhancement to Forward-Forward learning, with immediate applicability to neuromorphic computing architectures and energy-constrained AI systems.

</details>


### [117] [Bayesian Optimisation: Which Constraints Matter?](https://arxiv.org/abs/2512.17569)
*Xietao Wang Lin,Juan Ungredda,Max Butler,James Town,Alma Rahat,Hemant Singh,Juergen Branke*

Main category: cs.LG

TL;DR: 提出新的贝叶斯优化变体，针对具有解耦黑盒约束的问题，通过知识梯度采集函数，仅评估相关约束以提高优化效率。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯优化在处理昂贵的全局黑盒优化问题时表现出色，但现有方法在处理解耦约束问题时效率不高。当只有少数约束在最优解处起约束作用时，评估所有约束会浪费计算资源。

Method: 提出基于知识梯度采集函数的贝叶斯优化变体，针对解耦黑盒约束问题设计。方法能够识别并仅评估在最优解处可能起约束作用的相关约束，而不是评估所有约束函数。

Result: 通过实证基准测试，证明所提方法优于现有最先进方法，在处理具有解耦约束的优化问题时表现出更好的性能。

Conclusion: 提出的贝叶斯优化变体能够有效处理解耦黑盒约束问题，通过选择性评估相关约束来提高优化效率，为这类问题提供了更优的解决方案。

Abstract: Bayesian optimisation has proven to be a powerful tool for expensive global black-box optimisation problems. In this paper, we propose new Bayesian optimisation variants of the popular Knowledge Gradient acquisition functions for problems with \emph{decoupled} black-box constraints, in which subsets of the objective and constraint functions may be evaluated independently. In particular, our methods aim to take into account that often only a handful of the constraints may be binding at the optimum, and hence we should evaluate only relevant constraints when trying to optimise a function. We empirically benchmark these methods against existing methods and demonstrate their superiority over the state-of-the-art.

</details>


### [118] [GreedySnake: Accelerating SSD-Offloaded LLM Training with Efficient Scheduling and Optimizer Step Overlapping](https://arxiv.org/abs/2512.17570)
*Yikang Yue,Yishu Yin,Xuehai Qian*

Main category: cs.LG

TL;DR: GreedySnake是一种新的SSD卸载训练系统，采用垂直调度策略，相比水平调度能获得更高的训练吞吐量，特别是在小批量情况下，更接近理论性能极限。


<details>
  <summary>Details</summary>
Motivation: SSD卸载训练是降低大语言模型训练成本的有效方法，但现有系统存在I/O瓶颈和调度效率问题，需要更高效的调度策略来提升训练性能。

Method: 提出GreedySnake系统，采用垂直调度策略（逐层处理所有微批次），并优化I/O瓶颈，将部分优化步骤与下一轮前向传播重叠执行。

Result: 在A100 GPU上测试，GreedySnake相比ZeRO-Infinity获得显著提升：GPT-65B在1GPU上提升1.96倍，4GPU上提升1.93倍；GPT-175B在1GPU上提升2.53倍。

Conclusion: GreedySnake通过垂直调度和I/O优化，有效提升了SSD卸载训练的效率，使系统更接近理论性能极限，为大规模语言模型训练提供了更经济的解决方案。

Abstract: SSD-offloaded training offers a practical and promising approach to making LLM training cost-effective. Building on gradient accumulation with micro-batches, this paper introduces GreedySnake, a new SSD-offloaded training system that employs vertical scheduling, which executes all microbatches of a layer before proceeding to the next. Compared to existing systems that use horizontal scheduling (i.e., executing micro-batches sequentially), GreedySnake achieves higher training throughput with smaller batch sizes, bringing the system much closer to the ideal scenario predicted by the roofline model. To further mitigate the I/O bottleneck, GreedySnake overlaps part of the optimization step with the forward pass of the next iteration. Experimental results on A100 GPUs show that GreedySnake achieves saturated training throughput improvements over ZeRO-Infinity: 1.96x on 1 GPU and 1.93x on 4 GPUs for GPT-65B, and 2.53x on 1 GPU for GPT-175B. The code is open-sourced at https://github.com/npz7yyk/GreedySnake

</details>


### [119] [Machine Learning for Static and Single-Event Dynamic Complex Network Analysis](https://arxiv.org/abs/2512.17577)
*Nikolaos Nakis*

Main category: cs.LG

TL;DR: 开发用于静态和单事件动态网络的图表示学习新算法，基于潜在空间模型，创建结构感知的网络表示，实现统一学习过程


<details>
  <summary>Details</summary>
Motivation: 现有图表示学习方法通常需要启发式方法和多阶段处理，缺乏统一的学习框架。需要开发能够同时捕捉网络结构特征（如同质性、传递性、平衡理论）并处理多种图分析任务的综合方法

Method: 基于潜在空间模型家族，特别是潜在距离模型，开发结构感知的网络表示学习方法。该方法能够自然传达网络特征，创建层次化的网络结构表达，并设计统一的学习过程，避免启发式方法和后处理步骤

Result: 开发了能够实现网络结构层次表达、社区特征识别、极端轮廓识别和时间网络影响动态量化的方法。创建了统一的学习框架，能够处理多种图分析任务

Conclusion: 提出的方法为图表示学习提供了统一框架，能够全面捕捉网络结构特征，处理多样化的图分析任务，为静态和动态网络分析提供了强大工具

Abstract: The primary objective of this thesis is to develop novel algorithmic approaches for Graph Representation Learning of static and single-event dynamic networks. In such a direction, we focus on the family of Latent Space Models, and more specifically on the Latent Distance Model which naturally conveys important network characteristics such as homophily, transitivity, and the balance theory. Furthermore, this thesis aims to create structural-aware network representations, which lead to hierarchical expressions of network structure, community characterization, the identification of extreme profiles in networks, and impact dynamics quantification in temporal networks. Crucially, the methods presented are designed to define unified learning processes, eliminating the need for heuristics and multi-stage processes like post-processing steps. Our aim is to delve into a journey towards unified network embeddings that are both comprehensive and powerful, capable of characterizing network structures and adeptly handling the diverse tasks that graph analysis offers.

</details>


### [120] [Learning Safe Autonomous Driving Policies Using Predictive Safety Representations](https://arxiv.org/abs/2512.17586)
*Mahesh Keswani,Raunak Bhattacharyya*

Main category: cs.LG

TL;DR: SRPL框架在真实自动驾驶场景中验证有效，能改善奖励-安全权衡，提升成功率并降低成本，但对策略优化器和数据分布敏感，且能增强对观测噪声的鲁棒性和跨数据集泛化能力。


<details>
  <summary>Details</summary>
Motivation: 安全强化学习在自动驾驶中面临性能优化与安全要求之间的根本矛盾：过于保守的策略限制驾驶效率，而激进探索则带来安全风险。SRPL框架通过预测未来约束违规模型来解决这一挑战，但此前主要在受控环境中验证，需要研究其在真实自动驾驶场景中的有效性。

Method: 在真实自动驾驶场景中系统评估SRPL框架，使用Waymo Open Motion Dataset和NuPlan数据集进行实验，分析其对奖励-安全权衡的影响，考察对策略优化器和数据分布的依赖性，测试对观测噪声的鲁棒性，并进行零样本跨数据集评估。

Result: SRPL能显著改善奖励-安全权衡，成功率提升效果量r=0.65-0.86，成本降低效果量r=0.70-0.83，所有改进p<0.05。但其有效性依赖于底层策略优化器和数据集分布。预测安全表示对提升观测噪声鲁棒性起关键作用，在跨数据集评估中SRPL增强的智能体表现出更好的泛化能力。

Conclusion: 预测安全表示有潜力增强自动驾驶中的安全强化学习，SRPL框架在真实场景中能有效改善安全-性能权衡，但需要考虑策略优化器和数据分布的影响。研究结果为预测安全表示在自动驾驶安全强化学习中的应用提供了实证支持。

Abstract: Safe reinforcement learning (SafeRL) is a prominent paradigm for autonomous driving, where agents are required to optimize performance under strict safety requirements. This dual objective creates a fundamental tension, as overly conservative policies limit driving efficiency while aggressive exploration risks safety violations. The Safety Representations for Safer Policy Learning (SRPL) framework addresses this challenge by equipping agents with a predictive model of future constraint violations and has shown promise in controlled environments. This paper investigates whether SRPL extends to real-world autonomous driving scenarios. Systematic experiments on the Waymo Open Motion Dataset (WOMD) and NuPlan demonstrate that SRPL can improve the reward-safety tradeoff, achieving statistically significant improvements in success rate (effect sizes r = 0.65-0.86) and cost reduction (effect sizes r = 0.70-0.83), with p < 0.05 for observed improvements. However, its effectiveness depends on the underlying policy optimizer and the dataset distribution. The results further show that predictive safety representations play a critical role in improving robustness to observation noise. Additionally, in zero-shot cross-dataset evaluation, SRPL-augmented agents demonstrate improved generalization compared to non-SRPL methods. These findings collectively demonstrate the potential of predictive safety representations to strengthen SafeRL for autonomous driving.

</details>


### [121] [Sharing Knowledge without Sharing Data: Stitches can improve ensembles of disjointly trained models](https://arxiv.org/abs/2512.17592)
*Arthur Guijt,Dirk Thierens,Ellen Kerkhof,Jan Wiersma,Tanja Alderliesten,Peter A. N. Bosman*

Main category: cs.LG

TL;DR: 该论文研究了在数据分散且无法共享的医疗领域，如何通过异步协作（共享已训练模型）而非同步联邦学习来提升性能。研究发现，通过"缝合层"技术结合不同模型，可以在保持各自数据性能的同时提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在医疗等数据分散且隐私敏感的领域，数据无法集中共享。联邦学习需要同步训练，但实际应用中往往只能异步共享已训练好的模型。需要研究如何通过异步协作有效结合不同方训练的模型。

Method: 提出使用"缝合"（stitching）方法结合异步共享的已训练模型。具体是在个体训练模型的中间表示层之间插入一对缝合层，通过多目标视角评估各方数据的性能表现。

Result: 1) 仅用单方数据训练的模型在与另一方数据合并时，在该方数据上性能相似，但在其他方数据上表现较差；2) 集成个体训练的网络能提升泛化，但会损害各方在自己数据上的性能；3) 通过缝合层结合中间表示，能在保持泛化提升的同时恢复各方数据性能至竞争水平。

Conclusion: 异步协作通过缝合层技术可以有效结合分散训练的模型，在保持各方数据性能的同时提升泛化能力，为数据无法共享的场景提供了可行的解决方案。

Abstract: Deep learning has been shown to be very capable at performing many real-world tasks. However, this performance is often dependent on the presence of large and varied datasets. In some settings, like in the medical domain, data is often fragmented across parties, and cannot be readily shared. While federated learning addresses this situation, it is a solution that requires synchronicity of parties training a single model together, exchanging information about model weights. We investigate how asynchronous collaboration, where only already trained models are shared (e.g. as part of a publication), affects performance, and propose to use stitching as a method for combining models.
  Through taking a multi-objective perspective, where performance on each parties' data is viewed independently, we find that training solely on a single parties' data results in similar performance when merging with another parties' data, when considering performance on that single parties' data, while performance on other parties' data is notably worse. Moreover, while an ensemble of such individually trained networks generalizes better, performance on each parties' own dataset suffers. We find that combining intermediate representations in individually trained models with a well placed pair of stitching layers allows this performance to recover to a competitive degree while maintaining improved generalization, showing that asynchronous collaboration can yield competitive results.

</details>


### [122] [A Unified Representation of Neural Networks Architectures](https://arxiv.org/abs/2512.17593)
*Christophe Prieur,Mircea Lazar,Bogdan Robu*

Main category: cs.LG

TL;DR: 该论文提出了一种分布式参数神经网络（DiPaNet）的统一框架，将有限和无限维神经网络架构通过均匀化/离散化联系起来，并推导了神经元数量和隐藏层数趋于无穷时的近似误差。


<details>
  <summary>Details</summary>
Motivation: 研究神经网络架构在隐藏层神经元数量和层数趋于无穷时的极限情况，建立有限维和无限维神经网络之间的统一理论框架，并量化近似误差。

Method: 首先推导单隐藏层神经网络的积分无限宽度表示，扩展到具有有限积分隐藏层的深度残差CNN；然后通过离散化技术形式化神经ODE与深度残差NN的关系；最后将两种方法合并为统一的DiPaNet表示。

Result: 提出了DiPaNet作为神经网络的一般化表示，证明大多数现有有限和无限维神经网络架构可以通过均匀化/离散化与DiPaNet表示相关联，并推导了近似误差作为神经元数量和隐藏层数的函数。

Conclusion: DiPaNet提供了一个统一的确定性框架，适用于一般的均匀连续矩阵权重函数，能够连接各种神经网络架构，为理论分析和实际应用提供了新的视角。

Abstract: In this paper we consider the limiting case of neural networks (NNs) architectures when the number of neurons in each hidden layer and the number of hidden layers tend to infinity thus forming a continuum, and we derive approximation errors as a function of the number of neurons and/or hidden layers. Firstly, we consider the case of neural networks with a single hidden layer and we derive an integral infinite width neural representation that generalizes existing continuous neural networks (CNNs) representations. Then we extend this to deep residual CNNs that have a finite number of integral hidden layers and residual connections. Secondly, we revisit the relation between neural ODEs and deep residual NNs and we formalize approximation errors via discretization techniques. Then, we merge these two approaches into a unified homogeneous representation of NNs as a Distributed Parameter neural Network (DiPaNet) and we show that most of the existing finite and infinite-dimensional NNs architectures are related via homogeneization/discretization with the DiPaNet representation. Our approach is purely deterministic and applies to general, uniformly continuous matrix weight functions. Differences and similarities with neural fields are discussed along with further possible generalizations and applications of the DiPaNet framework.

</details>


### [123] [A Systems-Theoretic View on the Convergence of Algorithms under Disturbances](https://arxiv.org/abs/2512.17598)
*Guner Dilsad Er,Sebastian Trimpe,Michael Muehlebach*

Main category: cs.LG

TL;DR: 该论文提出了一种系统分析算法在噪声、扰动和与其他动态系统互连情况下收敛性的统一框架，通过Lyapunov理论量化扰动影响，并应用于分布式学习、机器学习泛化和隐私保护等多个场景。


<details>
  <summary>Details</summary>
Motivation: 现代算法在复杂物理、社会和工程系统中运行时，会暴露于扰动、噪声以及与其他动态系统的互连中，而现有的收敛性分析通常假设算法在孤立环境中运行。需要一种系统方法来量化这些外部因素对算法性能的影响。

Method: 利用逆Lyapunov定理，推导出量化扰动影响的关键不等式，将已知的孤立算法收敛性保证扩展到存在扰动的情况，系统推导稳定性边界和收敛速率。

Result: 建立了统一的算法分析工具，能够评估扰动对算法性能的影响，具体应用于：1) 分布式学习中的通信约束；2) 机器学习泛化的敏感性；3) 隐私保护中的有意噪声注入。

Conclusion: 该研究提供了一个统一的框架，用于分析算法在噪声、扰动和系统互连情况下的性能，为算法在复杂现实环境中的鲁棒性分析提供了理论基础。

Abstract: Algorithms increasingly operate within complex physical, social, and engineering systems where they are exposed to disturbances, noise, and interconnections with other dynamical systems. This article extends known convergence guarantees of an algorithm operating in isolation (i.e., without disturbances) and systematically derives stability bounds and convergence rates in the presence of such disturbances. By leveraging converse Lyapunov theorems, we derive key inequalities that quantify the impact of disturbances. We further demonstrate how our result can be utilized to assess the effects of disturbances on algorithmic performance in a wide variety of applications, including communication constraints in distributed learning, sensitivity in machine learning generalization, and intentional noise injection for privacy. This underpins the role of our result as a unifying tool for algorithm analysis in the presence of noise, disturbances, and interconnections with other dynamical systems.

</details>


### [124] [More Consistent Accuracy PINN via Alternating Easy-Hard Training](https://arxiv.org/abs/2512.17607)
*Zhaoqian Gao,Min Yanga*

Main category: cs.LG

TL;DR: 本文提出了一种结合硬优先级和易优先级的混合训练策略，通过交替训练算法解决PINNs在不同PDE类型上性能不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 虽然物理信息神经网络（PINNs）已成为求解偏微分方程的重要范式，但其训练策略研究不足。现有的硬优先级和易优先级方法在不同PDE类型上存在性能不一致和权衡问题，需要更稳健的训练方法。

Method: 开发了一种混合策略，结合硬优先级和易优先级的优势，采用交替训练算法。该方法在具有陡峭梯度、非线性和高维度的PDE上特别有效。

Result: 在具有陡峭梯度、非线性和高维度的PDE上，该方法实现了相对L2误差主要在O(10^-5)到O(10^-6)范围内的高精度，显著优于基线方法，并在不同问题上表现出更好的可靠性。

Conclusion: 该研究为设计混合训练策略提供了新见解，能够增强PINNs的性能和鲁棒性，解决了现有方法在不同PDE类型上性能不一致的问题。

Abstract: Physics-informed neural networks (PINNs) have recently emerged as a prominent paradigm for solving partial differential equations (PDEs), yet their training strategies remain underexplored. While hard prioritization methods inspired by finite element methods are widely adopted, recent research suggests that easy prioritization can also be effective. Nevertheless, we find that both approaches exhibit notable trade-offs and inconsistent performance across PDE types. To address this issue, we develop a hybrid strategy that combines the strengths of hard and easy prioritization through an alternating training algorithm. On PDEs with steep gradients, nonlinearity, and high dimensionality, the proposed method achieves consistently high accuracy, with relative L2 errors mostly in the range of O(10^-5) to O(10^-6), significantly surpassing baseline methods. Moreover, it offers greater reliability across diverse problems, whereas compared approaches often suffer from variable accuracy depending on the PDE. This work provides new insights into designing hybrid training strategies to enhance the performance and robustness of PINNs.

</details>


### [125] [SCOPE: Sequential Causal Optimization of Process Interventions](https://arxiv.org/abs/2512.17629)
*Jakob De Moor,Hans Weytjens,Johannes De Smedt,Jochen De Weerdt*

Main category: cs.LG

TL;DR: SCOPE是一种新的规范性过程监控方法，通过反向归纳学习对齐的序列干预推荐，直接利用观测数据优化关键绩效指标，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有规范性过程监控方法在处理序列干预时存在局限：要么只关注单次干预，要么将多次干预视为独立事件，要么依赖模拟或数据增强来训练强化学习代理，这会造成现实差距和偏差。实际业务过程中，组织需要对齐序列干预来共同引导案例结果。

Method: SCOPE采用反向归纳方法估计每个候选干预行动的效果，将其影响从最终决策点向后传播到第一个决策点。利用因果学习器直接使用观测数据，无需构建过程近似来进行强化学习。

Result: 在现有合成数据集和新半合成数据集上的实验表明，SCOPE在优化关键绩效指标方面始终优于最先进的规范性过程监控技术。新的半合成设置基于真实事件日志，为未来序列规范性过程监控研究提供了可重复的基准。

Conclusion: SCOPE通过反向归纳和因果学习解决了序列干预对齐问题，能够直接利用观测数据，避免了现有方法中的现实差距和偏差问题，为规范性过程监控提供了更有效的序列干预推荐方法。

Abstract: Prescriptive Process Monitoring (PresPM) recommends interventions during business processes to optimize key performance indicators (KPIs). In realistic settings, interventions are rarely isolated: organizations need to align sequences of interventions to jointly steer the outcome of a case. Existing PresPM approaches fall short in this respect. Many focus on a single intervention decision, while others treat multiple interventions independently, ignoring how they interact over time. Methods that do address these dependencies depend either on simulation or data augmentation to approximate the process to train a Reinforcement Learning (RL) agent, which can create a reality gap and introduce bias. We introduce SCOPE, a PresPM approach that learns aligned sequential intervention recommendations. SCOPE employs backward induction to estimate the effect of each candidate intervention action, propagating its impact from the final decision point back to the first. By leveraging causal learners, our method can utilize observational data directly, unlike methods that require constructing process approximations for reinforcement learning. Experiments on both an existing synthetic dataset and a new semi-synthetic dataset show that SCOPE consistently outperforms state-of-the-art PresPM techniques in optimizing the KPI. The novel semi-synthetic setup, based on a real-life event log, is provided as a reusable benchmark for future work on sequential PresPM.

</details>


### [126] [Trust-Region Adaptive Policy Optimization](https://arxiv.org/abs/2512.17636)
*Mingyu Su,Jian Guan,Yuxian Gu,Minlie Huang,Hongning Wang*

Main category: cs.LG

TL;DR: TRAPO是一种混合训练框架，通过交错使用监督微调（SFT）和强化学习（RL）来解决传统两阶段训练（SFT然后RL）的不一致性，在数学推理任务上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统两阶段训练管道（SFT然后RL）存在关键不一致性：SFT强制刚性模仿，抑制探索并导致遗忘，限制了RL的改进潜力。需要一种更高效的训练框架来统一外部监督和自我探索。

Method: TRAPO框架在每个训练实例中交错使用SFT和RL：在专家前缀上优化SFT损失，在模型自身补全上优化RL损失。引入信任区域SFT（TrSFT）来稳定训练，最小化信任区域内的前向KL散度，在区域外衰减优化。还包含自适应前缀选择机制，根据测量效用分配专家指导。

Result: 在五个数学推理基准测试中，TRAPO始终超越标准SFT、RL、SFT-then-RL管道以及最近的最先进方法，为推理增强的LLMs建立了强大的新范式。

Conclusion: TRAPO通过统一监督学习和强化学习，解决了传统两阶段训练的不一致性，提供了一种更高效、稳定的训练框架，显著提升了大型语言模型的复杂推理能力。

Abstract: Post-training methods, especially Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL), play an important role in improving large language models' (LLMs) complex reasoning abilities. However, the dominant two-stage pipeline (SFT then RL) suffers from a key inconsistency: SFT enforces rigid imitation that suppresses exploration and induces forgetting, limiting RL's potential for improvements. We address this inefficiency with TRAPO (\textbf{T}rust-\textbf{R}egion \textbf{A}daptive \textbf{P}olicy \textbf{O}ptimization), a hybrid framework that interleaves SFT and RL within each training instance by optimizing SFT loss on expert prefixes and RL loss on the model's own completions, unifying external supervision and self-exploration. To stabilize training, we introduce Trust-Region SFT (TrSFT), which minimizes forward KL divergence inside a trust region but attenuates optimization outside, effectively shifting toward reverse KL and yielding stable, mode-seeking updates favorable for RL. An adaptive prefix-selection mechanism further allocates expert guidance based on measured utility. Experiments on five mathematical reasoning benchmarks show that TRAPO consistently surpasses standard SFT, RL, and SFT-then-RL pipelines, as well as recent state-of-the-art approaches, establishing a strong new paradigm for reasoning-enhanced LLMs.

</details>


### [127] [Polyharmonic Cascade](https://arxiv.org/abs/2512.17671)
*Yuriy N. Bakhvalov*

Main category: cs.LG

TL;DR: 提出"多谐级联"深度学习架构，通过多谐样条包序列实现任意复杂非线性函数逼近，保持全局光滑性和概率解释，采用非梯度下降的线性系统训练方法


<details>
  <summary>Details</summary>
Motivation: 传统深度学习架构缺乏严格的数学理论基础和概率解释，梯度下降训练方法存在收敛慢、容易过拟合等问题，需要一种既能保持理论一致性又能高效训练的新架构

Method: 提出多谐级联架构：由多谐样条包序列组成，每层基于随机函数理论和无差别原理严格推导；训练方法采用全局线性系统求解而非梯度下降，在每批次上对固定"星座"节点处的函数值求解线性系统

Result: 实现了所有层的同步更新，保持各层概率解释和与原模型的理论一致性；计算简化为可在GPU上高效执行的2D矩阵运算；在MNIST数据集上展示了快速学习且不过拟合

Conclusion: 多谐级联架构提供了一种具有严格数学基础和概率解释的深度学习新范式，其线性系统训练方法避免了梯度下降的缺点，在保持理论一致性的同时实现了高效计算

Abstract: This paper presents a deep machine learning architecture, the "polyharmonic cascade" -- a sequence of packages of polyharmonic splines, where each layer is rigorously derived from the theory of random functions and the principles of indifference. This makes it possible to approximate nonlinear functions of arbitrary complexity while preserving global smoothness and a probabilistic interpretation. For the polyharmonic cascade, a training method alternative to gradient descent is proposed: instead of directly optimizing the coefficients, one solves a single global linear system on each batch with respect to the function values at fixed "constellations" of nodes. This yields synchronized updates of all layers, preserves the probabilistic interpretation of individual layers and theoretical consistency with the original model, and scales well: all computations reduce to 2D matrix operations efficiently executed on a GPU. Fast learning without overfitting on MNIST is demonstrated.

</details>


### [128] [You Only Train Once: Differentiable Subset Selection for Omics Data](https://arxiv.org/abs/2512.17678)
*Daphné Chopard,Jorge da Silva Gonçalves,Irene Cannistraci,Thomas M. Sutter,Julia E. Vogt*

Main category: cs.LG

TL;DR: YOTO是一个端到端的单细胞转录组特征选择框架，通过可微分架构联合识别离散基因子集并进行预测，实现选择与预测的强耦合。


<details>
  <summary>Details</summary>
Motivation: 现有单细胞转录组特征选择方法多为多阶段流程或依赖事后特征归因，导致特征选择与预测任务弱耦合，无法实现端到端优化。

Method: YOTO采用端到端可微分架构，通过稀疏性约束确保只有选中的基因参与推理，无需额外训练下游分类器。采用多任务学习设计，使相关任务共享表示，部分标记数据集可相互增强。

Result: 在两个代表性单细胞RNA-seq数据集上评估，YOTO始终优于最先进的基线方法，证明稀疏、端到端、多任务基因子集选择能提升预测性能并获得紧凑有意义的基因子集。

Conclusion: YOTO框架通过端到端联合优化特征选择与预测，提高了单细胞分析的预测性能，发现了紧凑且有生物学意义的基因子集，推动了生物标志物发现和单细胞分析的发展。

Abstract: Selecting compact and informative gene subsets from single-cell transcriptomic data is essential for biomarker discovery, improving interpretability, and cost-effective profiling. However, most existing feature selection approaches either operate as multi-stage pipelines or rely on post hoc feature attribution, making selection and prediction weakly coupled. In this work, we present YOTO (you only train once), an end-to-end framework that jointly identifies discrete gene subsets and performs prediction within a single differentiable architecture. In our model, the prediction task directly guides which genes are selected, while the learned subsets, in turn, shape the predictive representation. This closed feedback loop enables the model to iteratively refine both what it selects and how it predicts during training. Unlike existing approaches, YOTO enforces sparsity so that only the selected genes contribute to inference, eliminating the need to train additional downstream classifiers. Through a multi-task learning design, the model learns shared representations across related objectives, allowing partially labeled datasets to inform one another, and discovering gene subsets that generalize across tasks without additional training steps. We evaluate YOTO on two representative single-cell RNA-seq datasets, showing that it consistently outperforms state-of-the-art baselines. These results demonstrate that sparse, end-to-end, multi-task gene subset selection improves predictive performance and yields compact and meaningful gene subsets, advancing biomarker discovery and single-cell analysis.

</details>


### [129] [Convergence Guarantees for Federated SARSA with Local Training and Heterogeneous Agents](https://arxiv.org/abs/2512.17688)
*Paul Mangold,Eloïse Berthier,Eric Moulines*

Main category: cs.LG

TL;DR: 本文首次为具有线性函数逼近和本地训练的联邦SARSA（FedSARSA）提供了收敛性保证，量化了异构性影响，并证明了多智能体线性加速效果。


<details>
  <summary>Details</summary>
Motivation: 联邦强化学习中的异构性（本地转移和奖励的差异）对算法收敛性的影响尚未得到充分理论分析，需要为FedSARSA建立收敛保证和复杂度边界。

Method: 提出新的理论分析框架，包括单智能体SARSA的多步误差精确展开，分析FedSARSA在异构环境中的收敛性，量化异构性影响，并证明多本地更新下的收敛。

Result: 首次建立了FedSARSA在异构环境中的样本和通信复杂度边界，证明了算法在存在异构性时的收敛性，并展示了相对于智能体数量的线性加速效果（除马尔可夫采样的高阶项外）。

Conclusion: FedSARSA在异构联邦强化学习环境中具有理论收敛保证，能够实现多智能体线性加速，数值实验支持理论发现，为联邦SARSA算法提供了首个完整的理论分析框架。

Abstract: We present a novel theoretical analysis of Federated SARSA (FedSARSA) with linear function approximation and local training. We establish convergence guarantees for FedSARSA in the presence of heterogeneity, both in local transitions and rewards, providing the first sample and communication complexity bounds in this setting. At the core of our analysis is a new, exact multi-step error expansion for single-agent SARSA, which is of independent interest. Our analysis precisely quantifies the impact of heterogeneity, demonstrating the convergence of FedSARSA with multiple local updates. Crucially, we show that FedSARSA achieves linear speed-up with respect to the number of agents, up to higher-order terms due to Markovian sampling. Numerical experiments support our theoretical findings.

</details>


### [130] [Spatially-informed transformers: Injecting geostatistical covariance biases into self-attention for spatio-temporal forecasting](https://arxiv.org/abs/2512.17696)
*Yuri Calleo*

Main category: cs.LG

TL;DR: 提出空间感知Transformer，通过可学习协方差核将地统计归纳偏置注入自注意力机制，结合物理先验与数据驱动残差，实现高维时空过程建模。


<details>
  <summary>Details</summary>
Motivation: 传统高斯过程计算复杂度高，难以处理大规模传感器网络；而Transformer缺乏几何归纳偏置，将空间传感器视为排列不变的token，无法理解距离关系。需要结合地统计学的概率严谨性与深度学习的灵活表达能力。

Method: 提出空间感知Transformer，在自注意力机制中通过可学习协方差核注入地统计归纳偏置。将注意力结构分解为平稳物理先验和非平稳数据驱动残差，施加软拓扑约束，优先考虑空间邻近交互，同时保留建模复杂动态的能力。

Result: 在合成高斯随机场和真实世界交通基准测试中，该方法优于最先进的图神经网络。网络通过反向传播成功恢复底层过程的真实空间衰减参数（"深度变异函数"现象）。统计验证表明，该方法不仅提供更优的预测精度，还能产生良好校准的概率预测。

Conclusion: 该方法有效弥合了物理感知建模与数据驱动学习之间的差距，为高维时空过程建模提供了兼具概率严谨性和深度学习灵活性的解决方案。

Abstract: The modeling of high-dimensional spatio-temporal processes presents a fundamental dichotomy between the probabilistic rigor of classical geostatistics and the flexible, high-capacity representations of deep learning. While Gaussian processes offer theoretical consistency and exact uncertainty quantification, their prohibitive computational scaling renders them impractical for massive sensor networks. Conversely, modern transformer architectures excel at sequence modeling but inherently lack a geometric inductive bias, treating spatial sensors as permutation-invariant tokens without a native understanding of distance. In this work, we propose a spatially-informed transformer, a hybrid architecture that injects a geostatistical inductive bias directly into the self-attention mechanism via a learnable covariance kernel. By formally decomposing the attention structure into a stationary physical prior and a non-stationary data-driven residual, we impose a soft topological constraint that favors spatially proximal interactions while retaining the capacity to model complex dynamics. We demonstrate the phenomenon of ``Deep Variography'', where the network successfully recovers the true spatial decay parameters of the underlying process end-to-end via backpropagation. Extensive experiments on synthetic Gaussian random fields and real-world traffic benchmarks confirm that our method outperforms state-of-the-art graph neural networks. Furthermore, rigorous statistical validation confirms that the proposed method delivers not only superior predictive accuracy but also well-calibrated probabilistic forecasts, effectively bridging the gap between physics-aware modeling and data-driven learning.

</details>


### [131] [Mitigating Forgetting in Low Rank Adaptation](https://arxiv.org/abs/2512.17720)
*Joanna Sliwa,Frank Schneider,Philipp Hennig,Jose Miguel Hernandez-Lobato*

Main category: cs.LG

TL;DR: LaLoRA：基于拉普拉斯近化的LoRA权重正则化方法，通过约束高曲率方向的参数更新来缓解灾难性遗忘，在保持轻量级的同时改善学习-遗忘权衡。


<details>
  <summary>Details</summary>
Motivation: 参数高效微调方法（如LoRA）虽然能快速适应下游任务，但常导致模型遗忘先前学到的领域知识（灾难性遗忘）。需要一种方法在保持高效微调的同时保护已有知识。

Method: LaLoRA将拉普拉斯近似应用于LoRA权重，估计模型对每个参数的置信度，约束高曲率方向的更新。仅对LoRA权重应用拉普拉斯近似，保持方法轻量级。探索不同损失景观曲率近似来估计参数置信度。

Result: 在Llama模型数学推理微调中，LaLoRA改善了学习-遗忘权衡，可通过正则化强度直接控制该权衡。分析了用于拉普拉斯近化的数据影响，并验证了超参数鲁棒性。

Conclusion: LaLoRA通过权重空间正则化有效缓解了参数高效微调中的灾难性遗忘问题，在保持轻量级的同时实现了更好的知识保留与目标领域学习平衡。

Abstract: Parameter-efficient fine-tuning methods, such as Low-Rank Adaptation (LoRA), enable fast specialization of large pre-trained models to different downstream applications. However, this process often leads to catastrophic forgetting of the model's prior domain knowledge. We address this issue with LaLoRA, a weight-space regularization technique that applies a Laplace approximation to Low-Rank Adaptation. Our approach estimates the model's confidence in each parameter and constrains updates in high-curvature directions, preserving prior knowledge while enabling efficient target-domain learning. By applying the Laplace approximation only to the LoRA weights, the method remains lightweight. We evaluate LaLoRA by fine-tuning a Llama model for mathematical reasoning and demonstrate an improved learning-forgetting trade-off, which can be directly controlled via the method's regularization strength. We further explore different loss landscape curvature approximations for estimating parameter confidence, analyze the effect of the data used for the Laplace approximation, and study robustness across hyperparameters.

</details>


### [132] [Can You Hear Me Now? A Benchmark for Long-Range Graph Propagation](https://arxiv.org/abs/2512.17762)
*Luca Miglior,Matteo Tolloso,Alessio Gravina,Davide Bacciu*

Main category: cs.LG

TL;DR: 论文提出了ECHO基准测试，用于系统评估图神经网络在长距离信息传播上的能力，包含合成图任务和真实化学数据集，揭示了现有GNN在长程交互上的性能差距。


<details>
  <summary>Details</summary>
Motivation: 有效捕捉长程交互是图神经网络研究中的基本但未解决的挑战，对科学应用至关重要。当前缺乏专门评估GNN长距离传播能力的系统基准。

Method: 提出ECHO基准测试，包含三个合成图任务（单源最短路径、节点离心率、图直径）和两个真实化学数据集（ECHO-Charge和ECHO-Energy），这些任务设计在具有信息瓶颈的复杂拓扑结构上，需要长程传播能力。

Result: 对流行GNN架构的广泛基准测试揭示了明显的性能差距，强调了真正长程传播的困难，并识别了能够克服固有局限性的设计选择。

Conclusion: ECHO为评估长程信息传播设立了新标准，为科学AI领域提供了长程传播需求的强有力示例，推动了GNN在长程交互能力上的研究。

Abstract: Effectively capturing long-range interactions remains a fundamental yet unresolved challenge in graph neural network (GNN) research, critical for applications across diverse fields of science. To systematically address this, we introduce ECHO (Evaluating Communication over long HOps), a novel benchmark specifically designed to rigorously assess the capabilities of GNNs in handling very long-range graph propagation. ECHO includes three synthetic graph tasks, namely single-source shortest paths, node eccentricity, and graph diameter, each constructed over diverse and structurally challenging topologies intentionally designed to introduce significant information bottlenecks. ECHO also includes two real-world datasets, ECHO-Charge and ECHO-Energy, which define chemically grounded benchmarks for predicting atomic partial charges and molecular total energies, respectively, with reference computations obtained at the density functional theory (DFT) level. Both tasks inherently depend on capturing complex long-range molecular interactions. Our extensive benchmarking of popular GNN architectures reveals clear performance gaps, emphasizing the difficulty of true long-range propagation and highlighting design choices capable of overcoming inherent limitations. ECHO thereby sets a new standard for evaluating long-range information propagation, also providing a compelling example for its need in AI for science.

</details>


### [133] [Easy Adaptation: An Efficient Task-Specific Knowledge Injection Method for Large Models in Resource-Constrained Environments](https://arxiv.org/abs/2512.17771)
*Dong Chen,Zhengqing Hu,Shixing Zhao,Yibo Guo*

Main category: cs.LG

TL;DR: 提出Easy Adaptation方法，通过设计特定小模型来补充大语言模型在特定任务上的不足，无需访问大模型参数且资源消耗极低


<details>
  <summary>Details</summary>
Motivation: 现有参数高效微调方法面临两大挑战：1）资源成本高，仍需要大量时间和内存；2）参数依赖性强，需要访问大模型参数，而许多领先模型已采用闭源API访问策略，成本高昂且微调过程缓慢

Method: 提出Easy Adaptation方法，设计特定小模型来补充大语言模型在特定数据分布上的不足，无需访问大模型参数，仅需极少量资源

Result: 大量实验表明，EA方法在多样化任务上能够匹配参数高效微调的性能，且无需访问大模型参数，仅需极少量资源

Conclusion: EA方法为解决大模型适应性问题提供了新的有效途径，特别是在资源受限和模型闭源的环境下，通过特定小模型补充大模型在特定任务上的表现，实现了高效且低成本的适应

Abstract: While the enormous parameter scale endows Large Models (LMs) with unparalleled performance, it also limits their adaptability across specific tasks. Parameter-Efficient Fine-Tuning (PEFT) has emerged as a critical approach for effectively adapting LMs to a diverse range of downstream tasks. However, existing PEFT methods face two primary challenges: (1) High resource cost. Although PEFT methods significantly reduce resource demands compared to full fine-tuning, it still requires substantial time and memory, making it impractical in resource-constrained environments. (2) Parameter dependency. PEFT methods heavily rely on updating a subset of parameters associated with LMs to incorporate task-specific knowledge. Yet, due to increasing competition in the LMs landscape, many companies have adopted closed-source policies for their leading models, offering access only via Application Programming Interface (APIs). Whereas, the expense is often cost-prohibitive and difficult to sustain, as the fine-tuning process of LMs is extremely slow. Even if small models perform far worse than LMs in general, they can achieve superior results on particular distributions while requiring only minimal resources. Motivated by this insight, we propose Easy Adaptation (EA), which designs Specific Small Models (SSMs) to complement the underfitted data distribution for LMs. Extensive experiments show that EA matches the performance of PEFT on diverse tasks without accessing LM parameters, and requires only minimal resources.

</details>


### [134] [Calibratable Disambiguation Loss for Multi-Instance Partial-Label Learning](https://arxiv.org/abs/2512.17788)
*Wei Tang,Yin-Fang Yang,Weijia Zhang,Min-Ling Zhang*

Main category: cs.LG

TL;DR: 提出可校准消歧损失(CDL)解决多示例部分标签学习(MIPL)中的校准问题，提高分类准确性和校准性能


<details>
  <summary>Details</summary>
Motivation: 现有MIPL方法存在校准性能差的问题，影响分类器可靠性，需要同时提高分类准确性和校准性能

Method: 提出可插拔的可校准消歧损失(CDL)，包含两种实现：基于候选标签集概率校准，以及整合候选和非候选标签集概率

Result: CDL显著提升分类和校准性能，理论分析证明其优于传统消歧损失，实验验证在基准和真实数据集上有效

Conclusion: CDL是有效的可插拔校准解决方案，可无缝集成到现有MIPL和PLL框架中，同时提高分类准确性和校准可靠性

Abstract: Multi-instance partial-label learning (MIPL) is a weakly supervised framework that extends the principles of multi-instance learning (MIL) and partial-label learning (PLL) to address the challenges of inexact supervision in both instance and label spaces. However, existing MIPL approaches often suffer from poor calibration, undermining classifier reliability. In this work, we propose a plug-and-play calibratable disambiguation loss (CDL) that simultaneously improves classification accuracy and calibration performance. The loss has two instantiations: the first one calibrates predictions based on probabilities from the candidate label set, while the second one integrates probabilities from both candidate and non-candidate label sets. The proposed CDL can be seamlessly incorporated into existing MIPL and PLL frameworks. We provide a theoretical analysis that establishes the lower bound and regularization properties of CDL, demonstrating its superiority over conventional disambiguation losses. Experimental results on benchmark and real-world datasets confirm that our CDL significantly enhances both classification and calibration performance.

</details>


### [135] [Exploiting ID-Text Complementarity via Ensembling for Sequential Recommendation](https://arxiv.org/abs/2512.17820)
*Liam Collins,Bhuvesh Kumar,Clark Mingxuan Ju,Tong Zhao,Donald Loveland,Leonardo Neves,Neil Shah*

Main category: cs.LG

TL;DR: 该论文研究发现ID嵌入和文本嵌入在序列推荐中具有互补性，提出通过独立训练和简单集成策略来利用这种互补性，证明无需复杂融合架构即可达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前序列推荐模型对ID嵌入和模态嵌入的互补性缺乏理解。一些工作完全用模态嵌入替代ID嵌入，另一些则采用复杂的融合策略联合使用两者。本文旨在研究ID和文本特征的互补性，并探索更简单有效的利用方式。

Method: 提出新的序列推荐方法：1）通过独立训练ID模型和文本模型来保持两者的互补性；2）采用简单的集成策略来利用这种互补性。该方法避免了复杂的多阶段训练或对齐架构。

Result: 实验表明该方法优于多个竞争性序列推荐基线，证明ID和文本特征对于达到SOTA性能都是必要的，但不需要复杂的融合架构。简单的独立训练加集成就能有效利用两者的互补信号。

Conclusion: ID嵌入和文本嵌入在序列推荐中具有互补性，两者结合对于达到最佳性能是必要的。然而，不需要复杂的融合架构，简单的独立训练和集成策略就足以有效利用这种互补性。

Abstract: Modern Sequential Recommendation (SR) models commonly utilize modality features to represent items, motivated in large part by recent advancements in language and vision modeling. To do so, several works completely replace ID embeddings with modality embeddings, claiming that modality embeddings render ID embeddings unnecessary because they can match or even exceed ID embedding performance. On the other hand, many works jointly utilize ID and modality features, but posit that complex fusion strategies, such as multi-stage training and/or intricate alignment architectures, are necessary for this joint utilization. However, underlying both these lines of work is a lack of understanding of the complementarity of ID and modality features. In this work, we address this gap by studying the complementarity of ID- and text-based SR models. We show that these models do learn complementary signals, meaning that either should provide performance gain when used properly alongside the other. Motivated by this, we propose a new SR method that preserves ID-text complementarity through independent model training, then harnesses it through a simple ensembling strategy. Despite this method's simplicity, we show it outperforms several competitive SR baselines, implying that both ID and text features are necessary to achieve state-of-the-art SR performance but complex fusion architectures are not.

</details>


### [136] [Weighted Stochastic Differential Equation to Implement Wasserstein-Fisher-Rao Gradient Flow](https://arxiv.org/abs/2512.17878)
*Herlock Rahimi*

Main category: cs.LG

TL;DR: 本文提出了一种基于Wasserstein-Fisher-Rao几何的扩散采样方法，通过引入显式修正项和加权随机微分方程，改善非凸/多模态分布下的采样效率。


<details>
  <summary>Details</summary>
Motivation: 传统基于分数的扩散模型在强对数凹分布上表现良好，但在非凸或多模态分布（如双井势）中混合率会指数级恶化。许多实际生成建模任务涉及高度非对数凹的目标分布，需要开发能改善探索能力的采样方案。

Method: 利用信息几何工具，通过Wasserstein-Fisher-Rao几何增强扩散采样器，引入显式修正项，并使用Feynman-Kac表示通过加权随机微分方程实现质量重加权机制。

Result: 提出了WFR-based采样动力学框架，为未来理论和算法发展提供了几何和算子理论结构的基础。

Conclusion: Wasserstein-Fisher-Rao几何为改善非凸/多模态分布下的采样提供了有前景的方向，本文的初步研究为后续理论算法开发奠定了基础。

Abstract: Score-based diffusion models currently constitute the state of the art in continuous generative modeling. These methods are typically formulated via overdamped or underdamped Ornstein--Uhlenbeck-type stochastic differential equations, in which sampling is driven by a combination of deterministic drift and Brownian diffusion, resulting in continuous particle trajectories in the ambient space. While such dynamics enjoy exponential convergence guarantees for strongly log-concave target distributions, it is well known that their mixing rates deteriorate exponentially in the presence of nonconvex or multimodal landscapes, such as double-well potentials. Since many practical generative modeling tasks involve highly non-log-concave target distributions, considerable recent effort has been devoted to developing sampling schemes that improve exploration beyond classical diffusion dynamics.
  A promising line of work leverages tools from information geometry to augment diffusion-based samplers with controlled mass reweighting mechanisms. This perspective leads naturally to Wasserstein--Fisher--Rao (WFR) geometries, which couple transport in the sample space with vertical (reaction) dynamics on the space of probability measures. In this work, we formulate such reweighting mechanisms through the introduction of explicit correction terms and show how they can be implemented via weighted stochastic differential equations using the Feynman--Kac representation. Our study provides a preliminary but rigorous investigation of WFR-based sampling dynamics, and aims to clarify their geometric and operator-theoretic structure as a foundation for future theoretical and algorithmic developments.

</details>


### [137] [Regularized Random Fourier Features and Finite Element Reconstruction for Operator Learning in Sobolev Space](https://arxiv.org/abs/2512.17884)
*Xinyue Yu,Hayden Schaeffer*

Main category: cs.LG

TL;DR: 提出了一种基于正则化随机傅里叶特征(RRFF)和有限元重构映射(RRFF-FEM)的算子学习方法，用于从噪声数据中学习偏微分方程的解算子，该方法具有噪声鲁棒性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统的核基算子学习方法虽然能提供准确的理论保证，但在大规模训练集上计算代价高昂，且对噪声敏感。需要开发一种既能保持理论保证，又能处理噪声数据且计算高效的方法。

Method: 1. 使用多元学生t分布生成随机傅里叶特征；2. 引入频率加权的Tikhonov正则化来抑制高频噪声；3. 结合有限元重构映射(RRFF-FEM)进行算子学习；4. 当特征数N按m log m缩放时，系统保持良好条件。

Result: 1. 建立了随机特征矩阵极端奇异值的高概率界限；2. 在多个基准PDE问题(对流、Burgers、达西流、Helmholtz、Navier-Stokes、结构力学)上验证了方法的有效性；3. 相比无正则化随机特征模型，RRFF和RRFF-FEM对噪声更鲁棒，训练时间减少，性能提升；4. 与核方法和神经算子相比保持了竞争性的精度。

Conclusion: RRFF和RRFF-FEM方法为从噪声数据中学习算子提供了一种计算高效、理论保证且噪声鲁棒的解决方案，在保持精度的同时显著减少了训练时间，适用于各种PDE问题的解算子近似。

Abstract: Operator learning is a data-driven approximation of mappings between infinite-dimensional function spaces, such as the solution operators of partial differential equations. Kernel-based operator learning can offer accurate, theoretically justified approximations that require less training than standard methods. However, they can become computationally prohibitive for large training sets and can be sensitive to noise. We propose a regularized random Fourier feature (RRFF) approach, coupled with a finite element reconstruction map (RRFF-FEM), for learning operators from noisy data. The method uses random features drawn from multivariate Student's $t$ distributions, together with frequency-weighted Tikhonov regularization that suppresses high-frequency noise. We establish high-probability bounds on the extreme singular values of the associated random feature matrix and show that when the number of features $N$ scales like $m \log m$ with the number of training samples $m$, the system is well-conditioned, which yields estimation and generalization guarantees. Detailed numerical experiments on benchmark PDE problems, including advection, Burgers', Darcy flow, Helmholtz, Navier-Stokes, and structural mechanics, demonstrate that RRFF and RRFF-FEM are robust to noise and achieve improved performance with reduced training time compared to the unregularized random feature model, while maintaining competitive accuracy relative to kernel and neural operator tests.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [138] [On Energy-Dependent Neutron Diffusion](https://arxiv.org/abs/2512.16931)
*Gabriele Burgio,Christian Reiter,Stefano Lorenzi*

Main category: physics.comp-ph

TL;DR: 本文通过渐近推导解决了多群扩散方程理论中的分歧，提出了精确反演P1近似中通量与电流关系的矩阵表达式，并计算了氢无限介质的2群扩散系数。


<details>
  <summary>Details</summary>
Motivation: 虽然能量相关的中子扩散方程在核工程中广泛应用，但其作为输运方程近似的理论基础尚未完全理解，不同研究中使用的扩散系数近似方法存在显著差异和矛盾。

Method: 采用形式渐近推导多群扩散方程，提出精确反演P1近似中通量与电流关系的矩阵表达式，该表达式基于晶格计算已有的截面数据可任意精度计算，并使用蒙特卡洛方法计算氢无限介质的2群扩散系数。

Result: 得到了形式精确、物理意义明确的多群扩散系数矩阵表达式，计算了氢无限介质的2群扩散系数，并与累积迁移方法和出散射近似的结果进行了比较。

Conclusion: 本文解决了多群扩散方程理论中的分歧，提供了精确的扩散系数计算方法，为核工程中的扩散近似提供了更坚实的理论基础。

Abstract: While the energy-dependent neutron diffusion equation is widely employed in nuclear engineering, its status as an approximation to the transport equation is not yet completely understood, and several different approximations are in use to determine the diffusion coefficients. Past work on the theory underlying the diffusion approximation has often made use of asymptotic arguments; in the energy-dependent case, however, papers have appeared that differ substantially in their findings. Here we present a formal asymptotic derivation of the multigroup diffusion equation which addresses these differences, along with the varying and sometimes physically stringent assumptions employed in these works.
  Further, we show a way to exactly invert the relationship between flux and current in the P1 approximation, giving a matricial expression for the multigroup diffusion coefficient which is formally exact, has clear physical meaning, and which can be easily computed to arbitrary precision on the basis of cross-section data already produced by lattice calculations. The resulting 2-group diffusion coefficient for an infinite medium of hydrogen is calculated with Monte Carlo, and compared to the those deriving from the Cumulative Migration Method and from the out-scatter approximation.

</details>


### [139] [Quantitative phase nano-imaging with a laboratory source](https://arxiv.org/abs/2512.17357)
*Luca Fardin,Chris Armstrong,Alberto Astolfo,Sebastian Ignacio Allen Binet,Matthieu N. Boone,Rebecca Fitzgarrald,Yong Ma,Alexander Thomas,Darren J. Batey,Alessandro Olivo,Silvia Cipiccia*

Main category: physics.comp-ph

TL;DR: 实验室X射线ptychography在保持定量性的同时，成功应用于脑组织模型成像，为实验室X射线源定量纳米成像奠定了基础。


<details>
  <summary>Details</summary>
Motivation: X射线ptychography作为强大的纳米成像方法，目前主要局限于大型同步辐射设施。为了将该技术推广到广泛的实验室X射线源用户群体，需要验证在实验室环境下（X射线通量比同步辐射低几个数量级）是否仍能保持定量信息的准确性。

Method: 在实验室设置中实施X射线ptychography技术，并将其应用于脑组织模型的成像，同时评估该技术在实验室环境下的定量性能。

Result: 研究证明X射线ptychography在实验室环境中能够保持定量性，成功实现了脑组织模型的成像，并识别了当前的技术挑战和限制。

Conclusion: 实验室X射线ptychography具有可行性，为实验室X射线源的定量纳米成像技术发展奠定了基础，并指出了未来的发展方向。

Abstract: Investigating the structure of matter at the nanoscale non destructively is a key capability enabled by X-ray imaging. One of the most powerful nano-imaging methods is X-ray ptychography, a coherent diffraction imaging technique that has become the go-to method at synchrotron facilities for applications ranging from brain imaging to battery materials. However, the requirements in terms of X-ray beam quality have limited its use to large synchrotron facilities and, to date, only one attempt has been made to translate the technique to a small-scale laboratory. To unleash the power of this technique to the broad user community of laboratory X-ray sources, there are outstanding questions to answer including whether the quantitativeness of the information is preserved in a laboratory despite the drastic decrease in X-ray flux of several orders of magnitude, with respect to synchrotron instruments. In this study not only we demonstrate that the quantitativeness of X-ray ptychography is preserved in a laboratory setting, but we also apply the method to the imaging of a brain tissue phantom. Finally, we describe the current challenges and limitations, and we set the basis for further development and future directions of quantitative nano-imaging with laboratory X-ray sources.

</details>


### [140] [Spectral finite-element formulation of the optimized effective potential method for atomic structure in the random phase approximation](https://arxiv.org/abs/2512.17757)
*Shubhang Krishnakant Trivedi,Phanish Suryanarayana*

Main category: physics.comp-ph

TL;DR: 提出了用于原子结构计算的随机相位近似优化有效势方法的光谱有限元公式，开发了基于Chebyshev-Gauss-Lobatto网格、高阶连续拉格朗日基函数和Gauss-Legendre积分的有限元框架，并构建了基于核方法和线性回归的机器学习模型。


<details>
  <summary>Details</summary>
Motivation: 开发一个高精度的光谱有限元框架，用于原子结构计算中的随机相位近似优化有效势方法，以验证双杂化泛函的准确性并构建机器学习模型来预测交换关联势。

Method: 采用Chebyshev-Gauss-Lobatto网格配置的光谱有限元方法，使用高阶C0连续拉格朗日多项式基函数，对轨道、Hartree势和RPA-OEP交换关联势使用不同的多项式阶数，空间积分采用Gauss-Legendre求积法。

Result: 验证了所开发框架的准确性，评估了基于RPA关联构建的单参数双杂化泛函的保真度，并成功开发了基于核方法和线性回归的广义梯度近似水平上的RPA-OEP交换关联势机器学习模型。

Conclusion: 成功开发了一个高精度的光谱有限元框架用于RPA-OEP原子结构计算，该框架能够准确验证双杂化泛函并构建有效的机器学习模型来预测交换关联势，为原子结构计算提供了新的工具。

Abstract: We present a spectral finite-element formulation of the optimized effective potential (OEP) method for atomic structure calculations in the random phase approximation (RPA). In particular, we develop a finite-element framework that employs a polynomial mesh with element nodes placed according to the Chebyshev-Gauss-Lobatto scheme, high-order $\mathcal{C}^0$-continuous Lagrange polynomial basis functions, and Gauss-Legendre quadrature for spatial integration. We employ distinct polynomial degrees for the orbitals, Hartree potential, and RPA-OEP exchange-correlation potential. Through representative examples, we verify the accuracy of the developed framework, assess the fidelity of one-parameter double-hybrid functionals constructed with RPA correlation, and develop a machine-learned model for the RPA-OEP exchange-correlation potential at the level of the generalized gradient approximation, based on the kernel method and linear regression.

</details>
