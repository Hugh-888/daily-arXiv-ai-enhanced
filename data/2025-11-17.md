<div id=toc></div>

# Table of Contents

- [physics.comp-ph](#physics.comp-ph) [Total: 3]
- [cs.LG](#cs.LG) [Total: 77]
- [gr-qc](#gr-qc) [Total: 11]
- [quant-ph](#quant-ph) [Total: 38]


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [1] [BOA Constrictor: A Mamba-based lossless compressor for High Energy Physics data](https://arxiv.org/abs/2511.11337)
*Akshat Gupta,Caterina Doglioni,Thomas Joseph Elliott*

Main category: physics.comp-ph

TL;DR: 提出基于Mamba架构的BOA压缩器，在高能物理数据压缩中实现最先进的压缩比，但吞吐量较低


<details>
  <summary>Details</summary>
Motivation: 解决高能物理实验产生的PB级数据存储挑战，传统压缩算法无法充分利用科学数据的深层结构

Method: 基于Mamba架构构建BOA压缩器，结合自回归Mamba模型进行下一字节预测和并行流式范围编码

Result: 在所有数据集上超越LZMA-9，压缩比从2.21倍到44.14倍，模型大小仅约4.5MB，但吞吐量较低

Conclusion: 基于Mamba的方法是有前景的原理验证，但需要性能优化和硬件移植才能成为生产就绪工具

Abstract: The petabyte-scale data generated annually by High Energy Physics (HEP) experiments like those at the Large Hadron Collider present a significant data storage challenge. Whilst traditional algorithms like LZMA and ZLIB are widely used, they often fail to exploit the deep structure inherent in scientific data. We investigate the application of modern state space models (SSMs) to this problem, which have shown promise for capturing long-range dependencies in sequences. We present the Bytewise Online Autoregressive (BOA) Constrictor, a novel, streaming-capable lossless compressor built upon the Mamba architecture. BOA combines an autoregressive Mamba model for next-byte prediction with a parallelised streaming range coder. We evaluate our method on three distinct structured datasets in HEP, demonstrating state-of-the-art compression ratios, improving upon LZMA-9 across all datasets. These improvements range from 2.21$\times$ (vs. 1.69$\times$) on the ATLAS dataset to a substantial 44.14$\times$ (vs. 27.14$\times$) on the highly-structured CMS dataset, with a modest $\sim 4.5$MB model size. However, this gain in compression ratio comes with a trade-off in throughput; the Storage-Saving Rate ($σ_{SSR}$) of our prototype currently lags behind highly-optimised CPU-based algorithms like ZLIB. We conclude that while this Mamba-based approach is a highly promising proof-of-principle, significant future work on performance optimisation and hardware portability is required to develop it into a production-ready tool for the HEP community.

</details>


### [2] [Beyond quantum mean-field approximation: Phase-space formulation of many-body time-dependent density functional theory and efficient spectral approximations](https://arxiv.org/abs/2511.11354)
*Jiong-Hang Liang,Yunfeng Xiong*

Main category: physics.comp-ph

TL;DR: 本文提出了一种基于Wigner相空间表述的高效数值方法来解决2-RDM动力学模拟中的高维计算挑战，通过谱近似和并行计算实现了首次真实的2-RDM动力学模拟。


<details>
  <summary>Details</summary>
Motivation: 传统TDDFT方法在描述依赖双体演化行为的关键观测量（如双激发概率和双体动态关联）方面存在不足，而直接使用2-RDM又面临高维计算挑战。

Method: 采用等效的Wigner相空间表述，对非局域量子势进行高效谱近似：周期性空间使用伪差分算子方法，非周期性空间使用Chebyshev谱元方法，并结合分布式特征线法构建大规模并行数值方案。

Result: 数值实验展示了双体相互作用对量子动力学理论的修正，以及双体相互作用引起的系统熵增加。

Conclusion: 该方法为准确描述2-RDM动力学铺平了道路，推进了多体TDDFT的实际应用。

Abstract: As a universal quantum mechanical approach to the dynamical many-body problem, the time-dependent density functional theory (TDDFT) might be inadequate to describe crucial observables that rely on two-body evolution behavior, like the double-excitation probability and two-body dynamic correlation. One promising remedy is to utilize the time-dependent 2-reduced density matrix (2-RDM) that directly represents two-body observables in an N-particle system, and resort to the extended TDDFT for multibody densities to break the confines of spatial local on one-body density [Phys. Rev. Lett. 26(6) (2024) 263001]. However, the usage of 2-RDM is prohibitive due to the augmented dimensionality, e.g., 4-D space for unidimensional 2-RDM. This work addresses the high-dimensional numerical challenges by using an equivalent Wigner phase-space formulation of 2-RDM and seeking efficient spectral approximations to nonlocal quantum potentials. For spatial periodic case, a pseudo-difference operator approach is derived for both the Hartree-exchange-correlation term and two-body collision operator, while the discretization via the Chebyshev spectral element method is provided for non-periodic case. A massively parallel numerical scheme, which integrates these spectral approximations with a distributed characteristics method, allows us to make the first attempt for real simulations of 2-RDM dynamics. Numerical experiments demonstrate the two-body correction to the quantum kinetic theory, and show the increase in the system's entropy induced by the two-bdoy interaction. Thus it may pave the way for an accurate description of 2-RDM dynamics and advance to a practical application of many-body TDDFT.

</details>


### [3] [Power law attention biases for molecular transformers](https://arxiv.org/abs/2511.11489)
*Jay Shen,Yifeng Tang,Andrew Ferguson*

Main category: physics.comp-ph

TL;DR: 提出了一种基于物理幂律的低复杂度注意力偏置方法，通过原子间距离的对数函数来加权注意力概率，在分子属性预测中表现优于位置编码和图注意力。


<details>
  <summary>Details</summary>
Motivation: Transformer在大多数数据模态中占据主导地位，但在分子属性预测领域并未如此，原因可能是缺乏有效捕捉原子间关系的结构偏置。

Method: 提出基于物理幂律的注意力偏置家族b_ij = p log||r_i - r_j||，根据原子间距离加权注意力概率，是一种低复杂度的方法。

Result: 在QM9和SPICE数据集上，该方法优于位置编码和图注意力，与更复杂的高斯核偏置保持竞争力，且能补偿完全消除缩放点积注意力。

Conclusion: 良好的注意力偏置可以为实现可解释的分子Transformer提供低成本路径。

Abstract: Transformers are the go-to architecture for most data modalities due to their scalability. While they have been applied extensively to molecular property prediction, they do not dominate the field as they do elsewhere. One cause may be the lack of structural biases that effectively capture the relationships between atoms. Here, we investigate attention biases as a simple and natural way to encode structure. Motivated by physical power laws, we propose a family of low-complexity attention biases $b_{ij} = p \log|| \mathbf{r}_i - \mathbf{r}_j||$ which weigh attention probabilities according to interatomic distances. On the QM9 and SPICE datasets, this approach outperforms positional encodings and graph attention while remaining competitive with more complex Gaussian kernel biases. We also show that good attention biases can compensate for a complete ablation of scaled dot-product attention, suggesting a low-cost path toward interpretable molecular transformers.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [LAD-BNet: Lag-Aware Dual-Branch Networks for Real-Time Energy Forecasting on Edge Devices](https://arxiv.org/abs/2511.10680)
*Jean-Philippe Lignier*

Main category: cs.LG

TL;DR: LAD-BNet是一种专为边缘设备优化的实时能耗预测神经网络，结合时间滞后显式处理和扩张卷积TCN，在Google Coral TPU上实现14.49% MAPE精度和18ms推理时间。


<details>
  <summary>Details</summary>
Motivation: 解决智能电网和智能建筑中边缘设备实时能耗预测的挑战，满足嵌入式设备的内存和计算约束。

Method: 提出LAD-BNet混合架构：一个分支显式处理时间滞后，另一个分支使用扩张卷积的TCN，同时捕获短期和长期时间依赖关系。

Result: 在10分钟分辨率能耗数据上，1小时预测达到14.49% MAPE，Edge TPU推理时间18ms（比CPU快8-12倍），内存占用180MB，比LSTM基线提升2.39%，比纯TCN提升3.04%。

Conclusion: 该模型为实时能源优化、需求管理和运营规划等工业应用提供了可行的边缘计算解决方案。

Abstract: Real-time energy forecasting on edge devices represents a major challenge for smart grid optimization and intelligent buildings. We present LAD-BNet (Lag-Aware Dual-Branch Network), an innovative neural architecture optimized for edge inference with Google Coral TPU. Our hybrid approach combines a branch dedicated to explicit exploitation of temporal lags with a Temporal Convolutional Network (TCN) featuring dilated convolutions, enabling simultaneous capture of short and long-term dependencies. Tested on real energy consumption data with 10-minute temporal resolution, LAD-BNet achieves 14.49% MAPE at 1-hour horizon with only 18ms inference time on Edge TPU, representing an 8-12 x acceleration compared to CPU. The multi-scale architecture enables predictions up to 12 hours with controlled performance degradation. Our model demonstrates a 2.39% improvement over LSTM baselines and 3.04% over pure TCN architectures, while maintaining a 180MB memory footprint suitable for embedded device constraints. These results pave the way for industrial applications in real-time energy optimization, demand management, and operational planning.

</details>


### [5] [LT-Soups: Bridging Head and Tail Classes via Subsampled Model Soups](https://arxiv.org/abs/2511.10683)
*Masih Aminbeidokhti,Subhankar Roy,Eric Granger,Elisa Ricci,Marco Pedersoli*

Main category: cs.LG

TL;DR: 提出LT-Soups框架解决长尾数据集中参数高效微调方法在头尾类性能权衡的问题，通过两阶段模型融合实现更好的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据集通常呈现长尾分布，现有参数高效微调方法如LoRA和AdaptFormer虽然能保持尾类性能，但会牺牲头类准确率。头尾比例是影响这种权衡的关键但被忽视的因素。

Method: 提出LT-Soups两阶段框架：第一阶段在平衡子集上微调模型并取平均以减少头类偏差；第二阶段仅在全数据集上微调分类器以恢复头类准确率。

Result: 在六个基准数据集上的实验表明，LT-Soups在广泛的不平衡范围内相比PEFT和传统模型融合方法实现了更优的性能权衡。

Conclusion: LT-Soups框架能够有效解决长尾数据集中参数高效微调方法的性能权衡问题，在不同不平衡机制下都表现出优越的泛化能力。

Abstract: Real-world datasets typically exhibit long-tailed (LT) distributions, where a few head classes dominate and many tail classes are severely underrepresented. While recent work shows that parameter-efficient fine-tuning (PEFT) methods like LoRA and AdaptFormer preserve tail-class performance on foundation models such as CLIP, we find that they do so at the cost of head-class accuracy. We identify the head-tail ratio, the proportion of head to tail classes, as a crucial but overlooked factor influencing this trade-off. Through controlled experiments on CIFAR100 with varying imbalance ratio ($ρ$) and head-tail ratio ($η$), we show that PEFT excels in tail-heavy scenarios but degrades in more balanced and head-heavy distributions. To overcome these limitations, we propose LT-Soups, a two-stage model soups framework designed to generalize across diverse LT regimes. In the first stage, LT-Soups averages models fine-tuned on balanced subsets to reduce head-class bias; in the second, it fine-tunes only the classifier on the full dataset to restore head-class accuracy. Experiments across six benchmark datasets show that LT-Soups achieves superior trade-offs compared to both PEFT and traditional model soups across a wide range of imbalance regimes.

</details>


### [6] [Differentiable Sparse Identification of Lagrangian Dynamics](https://arxiv.org/abs/2511.10706)
*Zitong Zhang,Hao Sun*

Main category: cs.LG

TL;DR: 提出了一种新的可微分稀疏识别框架，通过三次B样条近似、鲁棒方程发现机制和递归导数计算方案，解决了拉格朗日系统识别中的噪声敏感性和数据限制问题。


<details>
  <summary>Details</summary>
Motivation: 现有拉格朗日识别方法受测量噪声和数据可用性的显著影响，稀疏回归技术在复杂机械系统中对有理函数和噪声敏感。

Method: 集成三次B样条近似到拉格朗日系统识别中，开发鲁棒方程发现机制，并基于B样条基函数实现递归导数计算方案。

Result: 在复杂机械系统中表现出优越性能，相比基线方法能够从噪声数据中更准确可靠地提取物理规律。

Conclusion: 该方法为非线性动力学中从数据发现控制方程提供了有效的解决方案，特别是在复杂机械系统中具有显著优势。

Abstract: Data-driven discovery of governing equations from data remains a fundamental challenge in nonlinear dynamics. Although sparse regression techniques have advanced system identification, they struggle with rational functions and noise sensitivity in complex mechanical systems. The Lagrangian formalism offers a promising alternative, as it typically avoids rational expressions and provides a more concise representation of system dynamics. However, existing Lagrangian identification methods are significantly affected by measurement noise and limited data availability. This paper presents a novel differentiable sparse identification framework that addresses these limitations through three key contributions: (1) the first integration of cubic B-Spline approximation into Lagrangian system identification, enabling accurate representation of complex nonlinearities, (2) a robust equation discovery mechanism that effectively utilizes measurements while incorporating known physical constraints, (3) a recursive derivative computation scheme based on B-spline basis functions, effectively constraining higher-order derivatives and reducing noise sensitivity on second-order dynamical systems. The proposed method demonstrates superior performance and enables more accurate and reliable extraction of physical laws from noisy data, particularly in complex mechanical systems compared to baseline methods.

</details>


### [7] [Bias-Restrained Prefix Representation Finetuning for Mathematical Reasoning](https://arxiv.org/abs/2511.10707)
*Sirui Liang,Pengfei Cao,Jian Zhao,Cong Huang,Jun Zhao,Kang Liu*

Main category: cs.LG

TL;DR: 提出了BREP ReFT方法，通过优化推理前缀生成、早期干预和约束干预向量幅度，解决了ReFT在数学推理任务上性能下降的问题，显著提升了数学推理能力。


<details>
  <summary>Details</summary>
Motivation: ReFT方法在数学推理任务上表现不佳，主要原因是难以生成有效的推理前缀，以及在CoT阶段干扰数值编码导致错误累积。

Method: BREP ReFT方法：1）截断训练数据优化初始推理前缀生成；2）在早期推理阶段进行干预防止错误累积；3）约束干预向量幅度避免干扰数值编码。

Result: 在多种模型架构上的实验表明，BREP在数学推理任务上优于标准ReFT和基于权重的PEFT方法，具有更好的效果、效率和泛化能力。

Conclusion: BREP ReFT通过针对性的优化策略，有效解决了ReFT在数学推理任务中的局限性，为参数高效微调提供了新的解决方案。

Abstract: Parameter-Efficient finetuning (PEFT) enhances model performance on downstream tasks by updating a minimal subset of parameters. Representation finetuning (ReFT) methods further improve efficiency by freezing model weights and optimizing internal representations with fewer parameters than PEFT, outperforming PEFT on several tasks. However, ReFT exhibits a significant performance decline on mathematical reasoning tasks. To address this problem, the paper demonstrates that ReFT's poor performance on mathematical tasks primarily stems from its struggle to generate effective reasoning prefixes during the early inference phase. Moreover, ReFT disturbs the numerical encoding and the error accumulats during the CoT stage. Based on these observations, this paper proposes Bias-REstrained Prefix Representation FineTuning (BREP ReFT), which enhances ReFT's mathematical reasoning capability by truncating training data to optimize the generation of initial reasoning prefixes, intervening on the early inference stage to prevent error accumulation, and constraining the intervention vectors' magnitude to avoid disturbing numerical encoding. Extensive experiments across diverse model architectures demonstrate BREP's superior effectiveness, efficiency, and robust generalization capability, outperforming both standard ReFT and weight-based PEFT methods on the task of mathematical reasoning. The source code is available at https://github.com/LiangThree/BREP.

</details>


### [8] [Differentiation Strategies for Acoustic Inverse Problems: Admittance Estimation and Shape Optimization](https://arxiv.org/abs/2511.11415)
*Nikolas Borrel-Jensen,Josiah Bjorgaard*

Main category: cs.LG

TL;DR: 本文展示了使用可微分编程解决声学逆问题的实用方法，包括边界导纳估计和形状优化，通过JAX-FEM自动微分实现高效梯度计算，无需手动推导伴随方程。


<details>
  <summary>Details</summary>
Motivation: 传统声学逆问题求解需要手动推导伴随方程，过程复杂且容易出错。现代可微分软件栈为这类问题提供了更高效的解决方案。

Method: 使用JAX-FEM进行自动微分实现边界导纳估计，结合PyTorch3D进行网格操作，采用随机有限差分法进行声学形状优化，将物理驱动的边界优化与几何驱动的内部网格适配分离。

Result: 边界导纳估计达到3位精度，形状优化在目标频率实现48.1%的能量减少，相比标准有限差分法减少30倍FEM求解次数。

Conclusion: 现代可微分软件栈能够快速原型化基于物理的逆问题优化工作流，自动微分适用于参数估计，有限差分与自动微分结合适用于几何设计。

Abstract: We demonstrate a practical differentiable programming approach for acoustic inverse problems through two applications: admittance estimation and shape optimization for resonance damping. First, we show that JAX-FEM's automatic differentiation (AD) enables direct gradient-based estimation of complex boundary admittance from sparse pressure measurements, achieving 3-digit precision without requiring manual derivation of adjoint equations. Second, we apply randomized finite differences to acoustic shape optimization, combining JAX-FEM for forward simulation with PyTorch3D for mesh manipulation through AD. By separating physics-driven boundary optimization from geometry-driven interior mesh adaptation, we achieve 48.1% energy reduction at target frequencies with 30-fold fewer FEM solutions compared to standard finite difference on the full mesh. This work showcases how modern differentiable software stacks enable rapid prototyping of optimization workflows for physics-based inverse problems, with automatic differentiation for parameter estimation and a combination of finite differences and AD for geometric design.

</details>


### [9] [Towards Uncertainty Quantification in Generative Model Learning](https://arxiv.org/abs/2511.10710)
*Giorgio Morales,Frederic Jurie,Jalal Fadili*

Main category: cs.LG

TL;DR: 本文提出生成模型不确定性量化问题，探讨了使用集成精度召回曲线等研究方向，并在合成数据集上验证了聚合精度召回曲线在捕捉模型近似不确定性方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前生成模型评估方法主要关注学习分布与目标分布的接近程度，但忽略了这些测量中的固有不确定性，这是生成模型可靠性方面的一个关键但研究不足的问题。

Method: 提出使用集成精度召回曲线进行不确定性量化，通过聚合多个模型的精度召回曲线来捕捉模型近似的不确定性。

Result: 在合成数据集上的初步实验表明，聚合精度召回曲线能够有效捕捉模型近似不确定性，并支持基于不确定性特征对不同模型架构进行系统比较。

Conclusion: 不确定性量化是生成模型学习中的重要问题，集成精度召回曲线为系统评估和比较不同模型的不确定性特征提供了有效方法。

Abstract: While generative models have become increasingly prevalent across various domains, fundamental concerns regarding their reliability persist. A crucial yet understudied aspect of these models is the uncertainty quantification surrounding their distribution approximation capabilities. Current evaluation methodologies focus predominantly on measuring the closeness between the learned and the target distributions, neglecting the inherent uncertainty in these measurements. In this position paper, we formalize the problem of uncertainty quantification in generative model learning. We discuss potential research directions, including the use of ensemble-based precision-recall curves. Our preliminary experiments on synthetic datasets demonstrate the effectiveness of aggregated precision-recall curves in capturing model approximation uncertainty, enabling systematic comparison among different model architectures based on their uncertainty characteristics.

</details>


### [10] [Movement-Specific Analysis for FIM Score Classification Using Spatio-Temporal Deep Learning](https://arxiv.org/abs/2511.10713)
*Jun Masaki,Ariaki Higashi,Naoko Shinagawa,Kazuhiko Hirata,Yuichi Kurita,Akira Furui*

Main category: cs.LG

TL;DR: 提出了一种自动评估FIM（功能独立性测量）分数的方法，使用不同于标准FIM评估动作的简单练习，通过深度学习模型来估计FIM运动项目分数。


<details>
  <summary>Details</summary>
Motivation: 传统的FIM评估对患者和医疗专业人员都造成很大负担，需要一种自动化的评估方法来减轻这种负担。

Method: 采用深度神经网络架构，整合了时空图卷积网络（ST-GCN）、双向长短期记忆网络（BiLSTM）和注意力机制，能够捕捉长期时间依赖关系并识别关键身体关节的贡献。

Result: 在277名康复患者的研究中，该方法成功区分了完全独立患者和需要协助的患者，在不同FIM项目上达到了70.09-78.79%的平衡准确率。

Conclusion: 该方法能够有效自动化FIM评估，并揭示了特定运动模式可作为特定FIM评估项目的可靠预测因子。

Abstract: The functional independence measure (FIM) is widely used to evaluate patients' physical independence in activities of daily living. However, traditional FIM assessment imposes a significant burden on both patients and healthcare professionals. To address this challenge, we propose an automated FIM score estimation method that utilizes simple exercises different from the designated FIM assessment actions. Our approach employs a deep neural network architecture integrating a spatial-temporal graph convolutional network (ST-GCN), bidirectional long short-term memory (BiLSTM), and an attention mechanism to estimate FIM motor item scores. The model effectively captures long-term temporal dependencies and identifies key body-joint contributions through learned attention weights. We evaluated our method in a study of 277 rehabilitation patients, focusing on FIM transfer and locomotion items. Our approach successfully distinguishes between completely independent patients and those requiring assistance, achieving balanced accuracies of 70.09-78.79 % across different FIM items. Additionally, our analysis reveals specific movement patterns that serve as reliable predictors for particular FIM evaluation items.

</details>


### [11] [Fast Neural Tangent Kernel Alignment, Norm and Effective Rank via Trace Estimation](https://arxiv.org/abs/2511.10796)
*James Hazelden*

Main category: cs.LG

TL;DR: 提出了基于迹估计的矩阵无关方法，用于快速计算神经正切核(NTK)的迹、Frobenius范数、有效秩和对齐度，相比传统方法可获得多个数量级的加速。


<details>
  <summary>Details</summary>
Motivation: 传统方法计算完整NTK矩阵在计算上不可行，特别是对于循环架构。需要一种快速分析有限宽度经验NTK的方法。

Method: 使用Hutch++迹估计器进行矩阵无关分析，并提出了仅需前向或反向自动微分的单边估计器，特别适用于模型状态与参数数量差距大的情况。

Result: 矩阵无关随机化方法可提供多个数量级的加速，单边估计器在低样本情况下优于Hutch++。

Conclusion: 矩阵无关随机化方法能够显著加速NTK的分析和应用，为研究神经网络训练动态提供了高效工具。

Abstract: The Neural Tangent Kernel (NTK) characterizes how a model's state evolves over Gradient Descent. Computing the full NTK matrix is often infeasible, especially for recurrent architectures. Here, we introduce a matrix-free perspective, using trace estimation to rapidly analyze the empirical, finite-width NTK. This enables fast computation of the NTK's trace, Frobenius norm, effective rank, and alignment. We provide numerical recipes based on the Hutch++ trace estimator with provably fast convergence guarantees. In addition, we show that, due to the structure of the NTK, one can compute the trace using only forward- or reverse-mode automatic differentiation, not requiring both modes. We show these so-called one-sided estimators can outperform Hutch++ in the low-sample regime, especially when the gap between the model state and parameter count is large. In total, our results demonstrate that matrix-free randomized approaches can yield speedups of many orders of magnitude, leading to faster analysis and applications of the NTK.

</details>


### [12] [Near-optimal Linear Predictive Clustering in Non-separable Spaces via Mixed Integer Programming and Quadratic Pseudo-Boolean Reductions](https://arxiv.org/abs/2511.10809)
*Jiazhou Liang,Hassan Khurram,Scott Sanner*

Main category: cs.LG

TL;DR: 提出了两种新的线性预测聚类全局优化方法，通过利用可分性理论特性推导出具有可证明误差界的近似最优解，显著提高了混合整数规划的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的贪婪优化方法缺乏全局最优性，在非可分聚类设置中表现不佳；而混合整数规划方法虽然能保证全局最优但可扩展性差。

Method: 基于约束优化范式，利用可分性理论特性推导出具有可证明误差界的近似最优解，将问题简化为二次伪布尔优化问题。

Result: 在合成和真实数据集上的比较分析表明，该方法始终获得近似最优解，回归误差显著低于贪婪优化，同时比现有MIP方法具有更好的可扩展性。

Conclusion: 提出的方法在保持近似最优性的同时，显著提高了线性预测聚类的计算效率，解决了现有方法在最优性和可扩展性之间的权衡问题。

Abstract: Linear Predictive Clustering (LPC) partitions samples based on shared linear relationships between feature and target variables, with numerous applications including marketing, medicine, and education. Greedy optimization methods, commonly used for LPC, alternate between clustering and linear regression but lack global optimality. While effective for separable clusters, they struggle in non-separable settings where clusters overlap in feature space. In an alternative constrained optimization paradigm, Bertsimas and Shioda (2007) formulated LPC as a Mixed-Integer Program (MIP), ensuring global optimality regardless of separability but suffering from poor scalability. This work builds on the constrained optimization paradigm to introduce two novel approaches that improve the efficiency of global optimization for LPC. By leveraging key theoretical properties of separability, we derive near-optimal approximations with provable error bounds, significantly reducing the MIP formulation's complexity and improving scalability. Additionally, we can further approximate LPC as a Quadratic Pseudo-Boolean Optimization (QPBO) problem, achieving substantial computational improvements in some settings. Comparative analyses on synthetic and real-world datasets demonstrate that our methods consistently achieve near-optimal solutions with substantially lower regression errors than greedy optimization while exhibiting superior scalability over existing MIP formulations.

</details>


### [13] [Transformers know more than they can tell -- Learning the Collatz sequence](https://arxiv.org/abs/2511.10811)
*François Charton,Ashvni Narayanan*

Main category: cs.LG

TL;DR: 本文研究Transformer模型预测Collatz序列长步长的能力，发现模型准确率随编码基数变化，最高达99.7%（基数24和32），最低仅25-37%（基数3和11）。所有模型都学习相同的模式：按输入模2^p的余数分类学习，准确率接近完美，反映了Collatz序列的数学特性。


<details>
  <summary>Details</summary>
Motivation: 研究Transformer模型如何学习复杂的算术函数——Collatz序列的长步长预测，以理解模型学习复杂计算的控制结构（循环长度）的能力。

Method: 使用不同基数编码输入和输出，训练Transformer模型预测Collatz序列的长步长，分析模型学习模式和错误类型。

Result: 模型准确率随编码基数变化显著，所有模型都按输入模2^p的余数分类学习。错误主要源于循环长度估计错误而非计算错误，幻觉现象几乎不存在。

Conclusion: 学习复杂算术函数的难点在于理解计算的控制结构（循环长度）。使用数学问题作为工具可以更好地理解、解释和改进语言模型。

Abstract: We investigate transformer prediction of long Collatz steps, a complex arithmetic function that maps odd integers to their distant successors in the Collatz sequence ( $u_{n+1}=u_n/2$ if $u_n$ is even, $u_{n+1}=(3u_n+1)/2$ if $u_n$ is odd). Model accuracy varies with the base used to encode input and output. It can be as high as $99.7\%$ for bases $24$ and $32$, and as low as $37$ and $25\%$ for bases $11$ and $3$. Yet, all models, no matter the base, follow a common learning pattern. As training proceeds, they learn a sequence of classes of inputs that share the same residual modulo $2^p$. Models achieve near-perfect accuracy on these classes, and less than $1\%$ for all other inputs. This maps to a mathematical property of Collatz sequences: the length of the loops involved in the computation of a long Collatz step can be deduced from the binary representation of its input. The learning pattern reflects the model learning to predict inputs associated with increasing loop lengths. An analysis of failure cases reveals that almost all model errors follow predictable patterns. Hallucination, a common feature of large language models, almost never happens. In over $90\%$ of failures, the model performs the correct calculation, but wrongly estimates loop lengths. Our observations give a full account of the algorithms learned by the models. They suggest that the difficulty of learning such complex arithmetic function lies in figuring the control structure of the computation -- the length of the loops. We believe that the approach outlined here, using mathematical problems as tools for understanding, explaining, and perhaps improving language models, can be applied to a broad range of problems and bear fruitful results.

</details>


### [14] [Towards Universal Neural Operators through Multiphysics Pretraining](https://arxiv.org/abs/2511.10829)
*Mikhail Masliaev,Dmitry Gusarov,Ilya Markov,Alexander Hvatov*

Main category: cs.LG

TL;DR: 研究了基于transformer的神经算子在迁移学习中的表现，评估了其在多种PDE问题上的性能，包括参数外推、新变量引入和多方程数据集迁移。


<details>
  <summary>Details</summary>
Motivation: 神经算子在数据驱动的物理模拟中训练成本高昂，下游学习通过预训练简化模型再微调复杂问题来解决此问题。

Method: 在通用迁移学习设置中评估基于transformer的神经算子，涵盖参数外推、新变量引入和多方程数据集迁移等场景。

Result: 先进的神经算子架构能够有效在PDE问题间迁移知识。

Conclusion: 基于transformer的神经算子在迁移学习环境中表现良好，能够跨PDE问题有效传递知识。

Abstract: Although neural operators are widely used in data-driven physical simulations, their training remains computationally expensive. Recent advances address this issue via downstream learning, where a model pretrained on simpler problems is fine-tuned on more complex ones. In this research, we investigate transformer-based neural operators, which have previously been applied only to specific problems, in a more general transfer learning setting. We evaluate their performance across diverse PDE problems, including extrapolation to unseen parameters, incorporation of new variables, and transfer from multi-equation datasets. Our results demonstrate that advanced neural operator architectures can effectively transfer knowledge across PDE problems.

</details>


### [15] [Benchmarking Quantum Kernels Across Diverse and Complex Data](https://arxiv.org/abs/2511.10831)
*Yuhan Jiang,Matthew Otten*

Main category: cs.LG

TL;DR: 提出了一个变分量子核框架，在8个高维真实数据集上验证了量子核方法相对于经典RBF核的性能优势，证明了量子核作为高性能机器学习工具的潜力。


<details>
  <summary>Details</summary>
Motivation: 当前量子核方法研究主要局限于低维或合成数据集，无法充分评估其在真实高维数据上的实际优势，需要填补这一研究空白。

Method: 开发了变分量子核框架，使用资源高效的ansatz处理复杂分类任务，并引入参数缩放技术加速收敛，在8个高维真实数据集上进行全面基准测试。

Result: 经典模拟结果显示，所提出的量子核在性能上明显优于标准的经典核（如RBF核），在表格、图像、时间序列和图数据等多样化任务中表现出色。

Conclusion: 适当设计的量子核可以作为多功能、高性能的工具，为真实世界机器学习中的量子增强应用奠定基础，但需要进一步研究来全面评估实际量子优势。

Abstract: Quantum kernel methods are a promising branch of quantum machine learning, yet their practical advantage on diverse, high-dimensional, real-world data remains unverified. Current research has largely been limited to low-dimensional or synthetic datasets, preventing a thorough evaluation of their potential. To address this gap, we developed a variational quantum kernel framework utilizing resource-efficient ansätze for complex classification tasks and introduced a parameter scaling technique to accelerate convergence. We conducted a comprehensive benchmark of this framework on eight challenging, real world and high-dimensional datasets covering tabular, image, time series, and graph data. Our classically simulated results show that the proposed quantum kernel demonstrated a clear performance advantage over standard classical kernels, such as the radial basis function (RBF) kernel. This work demonstrates that properly designed quantum kernels can function as versatile, high-performance tools, laying a foundation for quantum-enhanced applications in real-world machine learning. Further research is needed to fully assess the practical quantum advantage.

</details>


### [16] [SURFACEBENCH: Can Self-Evolving LLMs Find the Equations of 3D Scientific Surfaces?](https://arxiv.org/abs/2511.10833)
*Sanchit Kabra,Shobhnik Kriplani,Parshin Shojaee,Chandan K. Reddy*

Main category: cs.LG

TL;DR: SurfaceBench是一个用于符号曲面发现的综合基准，包含183个任务，涵盖15种符号复杂度类别，支持显式、隐式和参数化方程表示形式，并采用几何感知指标评估方程发现质量。


<details>
  <summary>Details</summary>
Motivation: 现有的符号回归基准存在局限性：主要关注标量函数、忽略领域基础、依赖脆弱的字符串匹配指标，无法捕捉科学等价性。需要建立一个能够反映曲面级结构、抵抗LLM记忆化、并基于科学领域的基准。

Method: 构建包含183个任务的综合基准，涵盖15种符号复杂度类别，包含显式、隐式和参数化方程表示。每个任务包含真实方程、变量语义和合成的三维数据。采用几何感知指标（如Chamfer和Hausdorff距离）结合符号检查来评估方程发现质量。

Result: 实验表明，最先进的框架虽然在特定函数族上偶尔成功，但难以在不同表示类型和曲面复杂度之间泛化。SurfaceBench建立了一个具有挑战性和诊断性的测试平台。

Conclusion: SurfaceBench连接了符号推理与几何重建，为组合泛化、数据驱动的科学归纳和几何感知推理提供了原则性基准测试平台。

Abstract: Equation discovery from data is a core challenge in machine learning for science, requiring the recovery of concise symbolic expressions that govern complex physical and geometric phenomena. Recent approaches with large language models (LLMs) show promise in symbolic regression, but their success often hinges on memorized formulas or overly simplified functional forms. Existing benchmarks exacerbate this limitation: they focus on scalar functions, ignore domain grounding, and rely on brittle string-matching based metrics that fail to capture scientific equivalence. We introduce SurfaceBench, first comprehensive benchmark for symbolic surface discovery. SurfaceBench comprises 183 tasks across 15 categories of symbolic complexity, spanning explicit, implicit, and parametric equation representation forms. Each task includes ground-truth equations, variable semantics, and synthetically sampled three dimensional data. Unlike prior SR datasets, our tasks reflect surface-level structure, resist LLM memorization through novel symbolic compositions, and are grounded in scientific domains such as fluid dynamics, robotics, electromagnetics, and geometry. To evaluate equation discovery quality, we pair symbolic checks with geometry-aware metrics such as Chamfer and Hausdorff distances, capturing both algebraic fidelity and spatial reconstruction accuracy. Our experiments reveal that state-of-the-art frameworks, while occasionally successful on specific families, struggle to generalize across representation types and surface complexities. SurfaceBench thus establishes a challenging and diagnostic testbed that bridges symbolic reasoning with geometric reconstruction, enabling principled benchmarking of progress in compositional generalization, data-driven scientific induction, and geometry-aware reasoning with LLMs. We release the code here: https://github.com/Sanchit-404/surfacebench

</details>


### [17] [EarthSight: A Distributed Framework for Low-Latency Satellite Intelligence](https://arxiv.org/abs/2511.10834)
*Ansel Kaplan Erol,Seungjun Lee,Divya Mahajan*

Main category: cs.LG

TL;DR: EarthSight是一个分布式卫星图像智能框架，通过多任务推理、地面站查询调度和动态过滤器排序，显著降低卫星图像分析的计算时间和端到端延迟。


<details>
  <summary>Details</summary>
Motivation: 传统卫星图像传输管道需要将所有图像下传后再分析，导致数小时到数天的延迟。现有解决方案将每颗卫星视为独立计算节点，存在冗余推理和资源浪费问题。

Method: 1) 在卫星上使用共享骨干网络进行多任务推理；2) 地面站查询调度器聚合用户请求、预测优先级并分配计算预算；3) 动态过滤器排序整合模型选择性、准确性和执行成本，早期拒绝低价值图像。

Result: 评估显示，EarthSight将每张图像的平均计算时间减少1.9倍，90百分位端到端延迟从51分钟降至21分钟。

Conclusion: EarthSight通过轨道和地面之间的分布式决策，使卫星星座能够在严格的带宽和功耗预算内实现可扩展、低延迟的图像分析。

Abstract: Low-latency delivery of satellite imagery is essential for time-critical applications such as disaster response, intelligence, and infrastructure monitoring. However, traditional pipelines rely on downlinking all captured images before analysis, introducing delays of hours to days due to restricted communication bandwidth. To address these bottlenecks, emerging systems perform onboard machine learning to prioritize which images to transmit. However, these solutions typically treat each satellite as an isolated compute node, limiting scalability and efficiency. Redundant inference across satellites and tasks further strains onboard power and compute costs, constraining mission scope and responsiveness. We present EarthSight, a distributed runtime framework that redefines satellite image intelligence as a distributed decision problem between orbit and ground. EarthSight introduces three core innovations: (1) multi-task inference on satellites using shared backbones to amortize computation across multiple vision tasks; (2) a ground-station query scheduler that aggregates user requests, predicts priorities, and assigns compute budgets to incoming imagery; and (3) dynamic filter ordering, which integrates model selectivity, accuracy, and execution cost to reject low-value images early and conserve resources. EarthSight leverages global context from ground stations and resource-aware adaptive decisions in orbit to enable constellations to perform scalable, low-latency image analysis within strict downlink bandwidth and onboard power budgets. Evaluations using a prior established satellite simulator show that EarthSight reduces average compute time per image by 1.9x and lowers 90th percentile end-to-end latency from first contact to delivery from 51 to 21 minutes compared to the state-of-the-art baseline.

</details>


### [18] [The Map of Misbelief: Tracing Intrinsic and Extrinsic Hallucinations Through Attention Patterns](https://arxiv.org/abs/2511.10837)
*Elyes Hajji,Aymen Bouguerra,Fabio Arnez*

Main category: cs.LG

TL;DR: 本文提出了一个区分外在和内在幻觉的评估框架，并利用注意力机制改进幻觉检测方法，发现基于采样的方法适合检测外在幻觉，而注意力聚合方法更适合内在幻觉。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在安全关键领域部署时容易产生幻觉，现有检测方法计算成本高且未区分幻觉类型，需要更有效的检测策略。

Method: 提出区分外在和内在幻觉的评估框架，利用注意力不确定性量化算法，开发新的注意力聚合策略来提高可解释性和检测性能。

Result: 实验发现基于采样的方法（如语义熵）能有效检测外在幻觉但无法检测内在幻觉，而基于输入令牌注意力聚合的方法更适合内在幻觉检测。

Conclusion: 注意力机制是量化模型不确定性的丰富信号，为根据幻觉性质调整检测策略提供了新方向。

Abstract: Large Language Models (LLMs) are increasingly deployed in safety-critical domains, yet remain susceptible to hallucinations. While prior works have proposed confidence representation methods for hallucination detection, most of these approaches rely on computationally expensive sampling strategies and often disregard the distinction between hallucination types. In this work, we introduce a principled evaluation framework that differentiates between extrinsic and intrinsic hallucination categories and evaluates detection performance across a suite of curated benchmarks. In addition, we leverage a recent attention-based uncertainty quantification algorithm and propose novel attention aggregation strategies that improve both interpretability and hallucination detection performance. Our experimental findings reveal that sampling-based methods like Semantic Entropy are effective for detecting extrinsic hallucinations but generally fail on intrinsic ones. In contrast, our method, which aggregates attention over input tokens, is better suited for intrinsic hallucinations. These insights provide new directions for aligning detection strategies with the nature of hallucination and highlight attention as a rich signal for quantifying model uncertainty.

</details>


### [19] [FlowPath: Learning Data-Driven Manifolds with Invertible Flows for Robust Irregularly-sampled Time Series Classification](https://arxiv.org/abs/2511.10841)
*YongKyung Oh,Dong-Young Lim,Sungil Kim*

Main category: cs.LG

TL;DR: FlowPath提出了一种通过可逆神经流学习控制路径几何形状的新方法，用于处理稀疏和不规则采样的时间序列数据，相比固定插值方法在分类准确率上有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有神经控制微分方程方法对控制路径的选择高度敏感，固定插值方案强加了过于简化的几何假设，在高缺失率下往往无法准确表示底层数据流形。

Method: FlowPath通过可逆神经流学习控制路径的几何形状，构建连续且数据自适应的流形，利用可逆性约束确保信息保持和良好行为的变换。

Result: 在18个基准数据集和真实案例研究中，FlowPath相比使用固定插值或不可逆架构的基线方法，在分类准确率上实现了统计显著的改进。

Conclusion: 研究结果表明，不仅需要建模沿路径的动力学，还需要建模路径本身的几何形状，这为从不规则时间序列中学习提供了鲁棒且可泛化的解决方案。

Abstract: Modeling continuous-time dynamics from sparse and irregularly-sampled time series remains a fundamental challenge. Neural controlled differential equations provide a principled framework for such tasks, yet their performance is highly sensitive to the choice of control path constructed from discrete observations. Existing methods commonly employ fixed interpolation schemes, which impose simplistic geometric assumptions that often misrepresent the underlying data manifold, particularly under high missingness. We propose FlowPath, a novel approach that learns the geometry of the control path via an invertible neural flow. Rather than merely connecting observations, FlowPath constructs a continuous and data-adaptive manifold, guided by invertibility constraints that enforce information-preserving and well-behaved transformations. This inductive bias distinguishes FlowPath from prior unconstrained learnable path models. Empirical evaluations on 18 benchmark datasets and a real-world case study demonstrate that FlowPath consistently achieves statistically significant improvements in classification accuracy over baselines using fixed interpolants or non-invertible architectures. These results highlight the importance of modeling not only the dynamics along the path but also the geometry of the path itself, offering a robust and generalizable solution for learning from irregular time series.

</details>


### [20] [Behaviour Policy Optimization: Provably Lower Variance Return Estimates for Off-Policy Reinforcement Learning](https://arxiv.org/abs/2511.10843)
*Alexander W. Goodall,Edwin Hamel-De le Court,Francesco Belardinelli*

Main category: cs.LG

TL;DR: 该论文提出利用行为策略收集离线数据来降低回报估计方差的方法，并将其扩展到在线强化学习设置中，通过改进两种策略梯度方法，在多种环境中实现了更好的样本效率和性能。


<details>
  <summary>Details</summary>
Motivation: 许多强化学习算法依赖回报估计进行策略改进，但由于高方差回报估计会导致样本效率低和训练不稳定。最近离线评估研究表明，精心设计的行为策略可以收集离线数据来获得方差更低的回报估计。

Method: 将离线评估的关键见解扩展到在线强化学习设置，使用单一行为策略收集数据用于策略改进，通过重要性加权样本进行去偏和方差管理，改进了两种策略梯度方法。

Result: 实验表明，在多种环境中，该方法相比传统方法具有更好的样本效率和性能表现。

Conclusion: 收集离线数据的行为策略可以产生方差更低的回报估计，这一发现挑战了传统认为在线策略收集数据方差最优的观点，为强化学习算法提供了新的改进方向。

Abstract: Many reinforcement learning algorithms, particularly those that rely on return estimates for policy improvement, can suffer from poor sample efficiency and training instability due to high-variance return estimates. In this paper we leverage new results from off-policy evaluation; it has recently been shown that well-designed behaviour policies can be used to collect off-policy data for provably lower variance return estimates. This result is surprising as it means collecting data on-policy is not variance optimal. We extend this key insight to the online reinforcement learning setting, where both policy evaluation and improvement are interleaved to learn optimal policies. Off-policy RL has been well studied (e.g., IMPALA), with correct and truncated importance weighted samples for de-biasing and managing variance appropriately. Generally these approaches are concerned with reconciling data collected from multiple workers in parallel, while the policy is updated asynchronously, mismatch between the workers and policy is corrected in a mathematically sound way. Here we consider only one worker - the behaviour policy, which is used to collect data for policy improvement, with provably lower variance return estimates. In our experiments we extend two policy-gradient methods with this regime, demonstrating better sample efficiency and performance over a diverse set of environments.

</details>


### [21] [STAMP: Spatial-Temporal Adapter with Multi-Head Pooling](https://arxiv.org/abs/2511.10848)
*Brad Shook,Abby Turner,Jieshi Chen,Michał Wiliński,Mononito Goswami,Jonathan Elmer,Artur Dubrawski*

Main category: cs.LG

TL;DR: 提出了一个轻量级的时空适配器STAMP，利用通用时间序列基础模型的单变量嵌入来建模EEG数据的时空特征，在8个临床任务数据集上达到与专用EEG基础模型相当的性能。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏对EEG专用基础模型与通用时间序列基础模型在EEG任务上的对比分析，需要探索如何有效利用通用TSFM处理EEG数据。

Method: 设计STAMP适配器，通过多头池化机制从通用TSFM的单变量嵌入中隐式建模EEG的时空特征，支持灵活输入且参数轻量。

Result: 在8个EEG分类基准数据集上，STAMP达到与最先进EEG专用基础模型相当的性能，并通过消融研究验证了有效性。

Conclusion: 通用TSFM结合轻量适配器可以高效处理EEG数据，为利用通用基础模型处理特定领域时间序列数据提供了可行方案。

Abstract: Time series foundation models (TSFMs) pretrained on data from multiple domains have shown strong performance on diverse modeling tasks. Various efforts have been made to develop foundation models specific to electroencephalography (EEG) data, which records brain electrical activity as time series. However, no comparative analysis of EEG-specific foundation models (EEGFMs) versus general TSFMs has been performed on EEG-specific tasks. We introduce a novel Spatial-Temporal Adapter with Multi-Head Pooling (STAMP), which leverages univariate embeddings produced by a general TSFM, implicitly models spatial-temporal characteristics of EEG data, and achieves performance comparable to state-of-the-art EEGFMs. A comprehensive analysis is performed on 8 benchmark datasets of clinical tasks using EEG for classification, along with ablation studies. Our proposed adapter is lightweight in trainable parameters and flexible in the inputs it can accommodate, supporting easy modeling of EEG data using TSFMs.

</details>


### [22] [ExPairT-LLM: Exact Learning for LLM Code Selection by Pairwise Queries](https://arxiv.org/abs/2511.10855)
*Tom Yuviler,Dana Drachsler-Cohen*

Main category: cs.LG

TL;DR: ExPairT-LLM是一种用于代码选择的精确学习算法，通过向LLM提出成对成员资格和成对等价性查询来识别正确程序，在四个代码数据集上平均比最先进算法提升13.0%的pass@1成功率。


<details>
  <summary>Details</summary>
Motivation: 现有代码选择算法可能无法识别正确程序，因为它们可能错误识别不等价程序，或者依赖LLM并假设它总能正确确定每个输入的输出。

Method: 提出ExPairT-LLM算法，通过向LLM提出两种新型查询（成对成员资格和成对等价性）来进行代码选择，这些查询对LLM更简单，并通过锦标赛机制识别正确程序，对某些LLM错误具有鲁棒性。

Result: 在四个流行代码数据集上评估，ExPairT-LLM的pass@1（成功率）平均比最先进的代码选择算法高出13.0%，最高达27.1%。还将执行复杂推理的LLM的pass@1提高了24.0%。

Conclusion: ExPairT-LLM通过更简单的查询类型和锦标赛机制有效提升了代码选择的准确性和鲁棒性，显著优于现有方法。

Abstract: Despite recent advances in LLMs, the task of code generation is still challenging. To cope, code selection algorithms select the best program from multiple programs generated by an LLM. However, existing algorithms can fail to identify the correct program, either because they can misidentify nonequivalent programs or because they rely on an LLM and assume it always correctly determines the output for every input. We present ExPairT-LLM, an exact learning algorithm for code selection that selects a program by posing to an LLM oracle two new types of queries: pairwise membership and pairwise equivalence. These queries are simpler for LLMs and enable ExPairT-LLM to identify the correct program through a tournament, which is robust to some LLM mistakes. We evaluate ExPairT-LLM on four popular code datasets. Its pass@1 (success rate) outperforms the state-of-the-art code selection algorithm on average by +13.0% and up to +27.1%. It also improves the pass@1 of LLMs performing complex reasoning by +24.0%.

</details>


### [23] [Private Zeroth-Order Optimization with Public Data](https://arxiv.org/abs/2511.10859)
*Xuchen Gong,Tian Li*

Main category: cs.LG

TL;DR: 提出了PAZO框架，利用公共数据指导私有零阶优化算法，在保持差分隐私的同时显著提升效用和运行效率


<details>
  <summary>Details</summary>
Motivation: 解决一阶差分隐私机器学习算法（如DP-SGD）的高计算和内存成本问题，同时提升零阶方法在隐私/效用权衡方面的表现

Method: 利用公共数据指导私有零阶梯度近似，开发了PAZO框架，包含多种公共数据辅助的零阶优化器

Result: 在视觉和文本任务中，PAZO在预训练和微调设置下均实现了优越的隐私/效用权衡，在高度隐私保护场景下优于最佳一阶基线方法，同时提供高达16倍的运行加速

Conclusion: PAZO框架成功地将公共数据与零阶优化相结合，为差分隐私机器学习提供了高效且实用的解决方案

Abstract: One of the major bottlenecks for deploying popular first-order differentially private (DP) machine learning algorithms (e.g., DP-SGD) lies in their high computation and memory cost, despite the existence of optimized implementations. Zeroth-order methods have promise in mitigating the overhead, as they leverage function evaluations to approximate the gradients, hence significantly easier to privatize. While recent works have explored zeroth-order approaches in both private and non-private settings, they still suffer from relatively low utilities compared with DP-SGD, and have only been evaluated in limited application domains. In this work, we propose to leverage public information to guide and improve gradient approximation of private zeroth-order algorithms. We explore a suite of public-data-assisted zeroth-order optimizers (PAZO) with minimal overhead. We provide theoretical analyses of the PAZO framework under an assumption of the similarity between public and private data. Empirically, we demonstrate that PAZO achieves superior privacy/utility tradeoffs across vision and text tasks in both pre-training and fine-tuning settings, outperforming the best first-order baselines (with public data) especially in highly private regimes, while offering up to $16\times$ runtime speedup.

</details>


### [24] [Go-UT-Bench: A Fine-Tuning Dataset for LLM-Based Unit Test Generation in Go](https://arxiv.org/abs/2511.10868)
*Yashshi Pipalani,Hritik Raj,Rajat Ghosh,Vaishnavi Bhargava,Debojyoti Dutta*

Main category: cs.LG

TL;DR: 为了解决代码LLM训练数据不平衡问题，作者创建了GO UT Bench基准数据集，包含5264对Go语言代码和单元测试，用于提升模型在单元测试生成等实际开发任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有训练数据严重偏向原始开源代码，缺乏对实际软件开发任务（特别是单元测试生成）的覆盖，尤其是在Go等低资源语言中。这导致模型擅长代码自动补全但无法满足真实开发工作流需求。

Method: 构建GO UT Bench基准数据集，包含5264对来自10个不同领域的Go语言代码和单元测试。在两个LLM家族（专家混合模型和密集解码器）上进行微调评估。

Result: 微调后的模型在超过75%的基准任务上表现优于基础模型。

Conclusion: GO UT Bench数据集能有效解决代码LLM训练数据不平衡问题，显著提升模型在单元测试生成等实际开发任务中的性能。

Abstract: Training data imbalance poses a major challenge for code LLMs. Most available data heavily over represents raw opensource code while underrepresenting broader software engineering tasks, especially in low resource languages like Golang. As a result, models excel at code autocompletion but struggle with real world developer workflows such as unit test generation. To address this gap, we introduce GO UT Bench, a benchmark dataset of 5264 pairs of code and unit tests, drawn from 10 permissively licensed Golang repositories spanning diverse domain. We evaluate its effectiveness as a fine tuning dataset across two LLM families i.e. mixture of experts and dense decoders. Our results show that finetuned models outperform their base counterparts on more than 75% of benchmark tasks.

</details>


### [25] [Incorporating Spatial Information into Goal-Conditioned Hierarchical Reinforcement Learning via Graph Representations](https://arxiv.org/abs/2511.10872)
*Shuyuan Zhang,Zihan Wang,Xiao-Wen Chang,Doina Precup*

Main category: cs.LG

TL;DR: 提出G4RL方法，通过图编码器-解码器评估未见状态，解决GCHRL中的样本效率低和子目标表示差的问题，提升现有GCHRL方法在对称可逆环境中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有图引导的分层强化学习方法依赖领域知识构建图或动态构建图但无法有效利用图信息，存在样本效率低和子目标表示差的问题。

Method: 开发图编码器-解码器来评估未见状态，该方法可集成到任何现有GCHRL方法中，在对称可逆环境中使用网络训练状态图。

Result: 实验结果表明，利用图编码器-解码器产生的高低层内在奖励能显著提升最先进GCHRL方法的性能，且计算成本很小。

Conclusion: G4RL方法有效解决了GCHRL中的关键挑战，在密集和稀疏奖励环境中都能显著提升性能。

Abstract: The integration of graphs with Goal-conditioned Hierarchical Reinforcement Learning (GCHRL) has recently gained attention, as intermediate goals (subgoals) can be effectively sampled from graphs that naturally represent the overall task structure in most RL tasks. However, existing approaches typically rely on domain-specific knowledge to construct these graphs, limiting their applicability to new tasks. Other graph-based approaches create graphs dynamically during exploration but struggle to fully utilize them, because they have problems passing the information in the graphs to newly visited states. Additionally, current GCHRL methods face challenges such as sample inefficiency and poor subgoal representation. This paper proposes a solution to these issues by developing a graph encoder-decoder to evaluate unseen states. Our proposed method, Graph-Guided sub-Goal representation Generation RL (G4RL), can be incorporated into any existing GCHRL method when operating in environments with primarily symmetric and reversible transitions to enhance performance across this class of problems. We show that the graph encoder-decoder can be effectively implemented using a network trained on the state graph generated during exploration. Empirical results indicate that leveraging high and low-level intrinsic rewards from the graph encoder-decoder significantly enhances the performance of state-of-the-art GCHRL approaches with an extra small computational cost in dense and sparse reward environments.

</details>


### [26] [Multi-Joint Physics-Informed Deep Learning Framework for Time-Efficient Inverse Dynamics](https://arxiv.org/abs/2511.10878)
*Shuhao Ma,Zeyi Huang,Yu Cao,Wesley Doorsamy,Chaoyang Shi,Jun Li,Zhi-Qiang Zhang*

Main category: cs.LG

TL;DR: 提出了一种物理信息深度学习框架PI-MJCA-BiGRU，用于从运动学数据直接估计多关节系统中的肌肉激活和力，无需标注数据即可实现生理一致的预测。


<details>
  <summary>Details</summary>
Motivation: 传统方法计算成本高且缺乏多关节应用的高质量标注数据集，需要开发时间效率高且不依赖标注数据的肌肉激活和力估计方法。

Method: 使用多关节交叉注意力模块和双向门控循环单元层来捕捉关节间协调，通过将多关节动力学、关节间耦合和外部力相互作用嵌入损失函数实现物理信息学习。

Result: 在两个数据集上的实验验证表明，该方法性能与有监督方法相当，无需真实标签，且MJCA模块显著增强了关节间协调建模能力。

Conclusion: PI-MJCA-BiGRU框架为多关节肌肉激活和力估计提供了一种时间高效、无需标注数据的解决方案，在临床评估和辅助设备控制中具有应用潜力。

Abstract: Time-efficient estimation of muscle activations and forces across multi-joint systems is critical for clinical assessment and assistive device control. However, conventional approaches are computationally expensive and lack a high-quality labeled dataset for multi-joint applications. To address these challenges, we propose a physics-informed deep learning framework that estimates muscle activations and forces directly from kinematics. The framework employs a novel Multi-Joint Cross-Attention (MJCA) module with Bidirectional Gated Recurrent Unit (BiGRU) layers to capture inter-joint coordination, enabling each joint to adaptively integrate motion information from others. By embedding multi-joint dynamics, inter-joint coupling, and external force interactions into the loss function, our Physics-Informed MJCA-BiGRU (PI-MJCA-BiGRU) delivers physiologically consistent predictions without labeled data while enabling time-efficient inference. Experimental validation on two datasets demonstrates that PI-MJCA-BiGRU achieves performance comparable to conventional supervised methods without requiring ground-truth labels, while the MJCA module significantly enhances inter-joint coordination modeling compared to other baseline architectures.

</details>


### [27] [Multi-View Polymer Representations for the Open Polymer Prediction](https://arxiv.org/abs/2511.10893)
*Wonjin Jung,Yongseok Choi*

Main category: cs.LG

TL;DR: 多视图聚合物性质预测系统，集成四种表征方法并通过均匀集成平均预测，在NeurIPS 2025挑战赛中排名第9位。


<details>
  <summary>Details</summary>
Motivation: 利用互补的表征方法来提高聚合物性质预测的准确性和鲁棒性。

Method: 集成四种表征家族：RDKit/Morgan描述符、图神经网络、3D信息表征和预训练SMILES语言模型，使用10折交叉验证训练和SMILES测试时增强。

Result: 在2241支队伍中排名第9，公开MAE为0.057，私有MAE为0.082。

Conclusion: 多视图集成方法在聚合物性质预测中表现出色，证明了不同表征方法的互补价值。

Abstract: We address polymer property prediction with a multi-view design that exploits complementary representations. Our system integrates four families: (i) tabular RDKit/Morgan descriptors, (ii) graph neural networks, (iii) 3D-informed representations, and (iv) pretrained SMILES language models, and averages per-property predictions via a uniform ensemble. Models are trained with 10-fold splits and evaluated with SMILES test-time augmentation. The approach ranks 9th of 2241 teams in the Open Polymer Prediction Challenge at NeurIPS 2025. The submitted ensemble achieves a public MAE of 0.057 and a private MAE of 0.082.

</details>


### [28] [Graph Attention Network for Predicting Duration of Large-Scale Power Outages Induced by Natural Disasters](https://arxiv.org/abs/2511.10898)
*Chenghao Duan,Chuanyi Ji*

Main category: cs.LG

TL;DR: 提出了一种基于图注意力网络（GAT）的新方法来预测恶劣天气导致的停电持续时间，通过无监督预训练和半监督学习，在四个飓风影响下的501个县数据上取得了93%以上的准确率。


<details>
  <summary>Details</summary>
Motivation: 自然灾害导致的大规模停电造成巨大经济和社会影响，准确预测停电恢复时间对电网韧性至关重要。现有方法面临空间依赖性、空间异质性和事件数据有限三大挑战。

Method: 使用图注意力网络（GAT），采用无监督预训练和半监督学习框架，利用地理空间和天气数据来估计停电持续时间。

Result: 模型在四个飓风影响下的501个县数据上表现出色，准确率超过93%，比XGBoost、随机森林、GCN和简单GAT等方法高出2%-15%。

Conclusion: 提出的GAT方法能有效解决停电持续时间预测中的空间依赖性和异质性挑战，为电网韧性管理提供了可靠工具。

Abstract: Natural disasters such as hurricanes, wildfires, and winter storms have induced large-scale power outages in the U.S., resulting in tremendous economic and societal impacts. Accurately predicting power outage recovery and impact is key to resilience of power grid. Recent advances in machine learning offer viable frameworks for estimating power outage duration from geospatial and weather data. However, three major challenges are inherent to the task in a real world setting: spatial dependency of the data, spatial heterogeneity of the impact, and moderate event data. We propose a novel approach to estimate the duration of severe weather-induced power outages through Graph Attention Networks (GAT). Our network uses a simple structure from unsupervised pre-training, followed by semi-supervised learning. We use field data from four major hurricanes affecting $501$ counties in eight Southeastern U.S. states. The model exhibits an excellent performance ($>93\%$ accuracy) and outperforms the existing methods XGBoost, Random Forest, GCN and simple GAT by $2\% - 15\%$ in both the overall performance and class-wise accuracy.

</details>


### [29] [Towards Federated Clustering: A Client-wise Private Graph Aggregation Framework](https://arxiv.org/abs/2511.10915)
*Guanxiong He,Jie Wang,Liaoyuan Tang,Zheng Wang,Rong Wang,Feiping Nie*

Main category: cs.LG

TL;DR: 提出了SPP-FGC框架，通过本地结构图作为隐私保护知识共享媒介，解决联邦聚类中性能与隐私的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有联邦聚类方法在性能和隐私之间存在妥协：传输嵌入表示会泄露敏感数据，而只共享聚类原型会导致模型准确性下降。

Method: 采用客户端-服务器架构，客户端构建私有结构图捕获数据关系，服务器安全聚合和对齐形成全局图，从中推导统一聚类结构。提供SPP-FGC（单轮通信）和SPP-FGC+（迭代优化）两种模式。

Result: 实验表明框架达到最先进性能，聚类准确率比联邦基线提高高达10%（NMI），同时保持可证明的隐私保证。

Conclusion: SPP-FGC框架成功解决了联邦聚类中的隐私-性能权衡问题，通过结构图共享机制实现了高性能和强隐私保护的平衡。

Abstract: Federated clustering addresses the critical challenge of extracting patterns from decentralized, unlabeled data. However, it is hampered by the flaw that current approaches are forced to accept a compromise between performance and privacy: \textit{transmitting embedding representations risks sensitive data leakage, while sharing only abstract cluster prototypes leads to diminished model accuracy}. To resolve this dilemma, we propose Structural Privacy-Preserving Federated Graph Clustering (SPP-FGC), a novel algorithm that innovatively leverages local structural graphs as the primary medium for privacy-preserving knowledge sharing, thus moving beyond the limitations of conventional techniques. Our framework operates on a clear client-server logic; on the client-side, each participant constructs a private structural graph that captures intrinsic data relationships, which the server then securely aggregates and aligns to form a comprehensive global graph from which a unified clustering structure is derived. The framework offers two distinct modes to suit different needs. SPP-FGC is designed as an efficient one-shot method that completes its task in a single communication round, ideal for rapid analysis. For more complex, unstructured data like images, SPP-FGC+ employs an iterative process where clients and the server collaboratively refine feature representations to achieve superior downstream performance. Extensive experiments demonstrate that our framework achieves state-of-the-art performance, improving clustering accuracy by up to 10\% (NMI) over federated baselines while maintaining provable privacy guarantees.

</details>


### [30] [GraphToxin: Reconstructing Full Unlearned Graphs from Graph Unlearning](https://arxiv.org/abs/2511.10936)
*Ying Song,Balaji Palanisamy*

Main category: cs.LG

TL;DR: 提出了GraphToxin，这是第一个针对图遗忘的图重构攻击方法，能够恢复被删除的节点信息、个人链接以及连接中的敏感内容，严重威胁图遗忘的隐私保护功能。


<details>
  <summary>Details</summary>
Motivation: 图遗忘虽然被设计为遵守"被遗忘权"的解决方案，但存在安全漏洞，攻击者可能利用残余痕迹恢复被删除的敏感信息，从而破坏图遗忘的核心功能。

Method: 引入创新的曲率匹配模块，为完整的遗忘图恢复提供细粒度指导，支持白盒和黑盒设置下的多节点移除攻击，并提出了包含随机和最坏情况节点移除的全面评估框架。

Result: GraphToxin能够成功恢复被删除个体的信息、个人链接和连接中的敏感内容，现有防御机制对其基本无效，甚至可能增强攻击效果。

Conclusion: GraphToxin暴露了图遗忘方法的严重隐私风险，强调了开发更有效和鲁棒防御策略的紧迫性。

Abstract: Graph unlearning has emerged as a promising solution for complying with "the right to be forgotten" regulations by enabling the removal of sensitive information upon request. However, this solution is not foolproof. The involvement of multiple parties creates new attack surfaces, and residual traces of deleted data can still remain in the unlearned graph neural networks. These vulnerabilities can be exploited by attackers to recover the supposedly erased samples, thereby undermining the inherent functionality of graph unlearning. In this work, we propose GraphToxin, the first graph reconstruction attack against graph unlearning. Specifically, we introduce a novel curvature matching module to provide a fine-grained guidance for full unlearned graph recovery. We demonstrate that GraphToxin can successfully subvert the regulatory guarantees expected from graph unlearning - it can recover not only a deleted individual's information and personal links but also sensitive content from their connections, thereby posing substantially more detrimental threats. Furthermore, we extend GraphToxin to multiple node removals under both white-box and black-box setting. We highlight the necessity of a worst-case analysis and propose a comprehensive evaluation framework to systematically assess the attack performance under both random and worst-case node removals. This provides a more robust and realistic measure of the vulnerability of graph unlearning methods to graph reconstruction attacks. Our extensive experiments demonstrate the effectiveness and flexibility of GraphToxin. Notably, we show that existing defense mechanisms are largely ineffective against this attack and, in some cases, can even amplify its performance. Given the severe privacy risks posed by GraphToxin, our work underscores the urgent need for the development of more effective and robust defense strategies against this attack.

</details>


### [31] [Cascading Bandits With Feedback](https://arxiv.org/abs/2511.10938)
*R Sri Prakash,Nikhil Karamchandani,Sharayu Moharir*

Main category: cs.LG

TL;DR: 分析了四种决策策略在边缘推理场景下的表现，发现LCB和Thompson Sampling因持续适应反馈而获得常数O(1)遗憾，优于Explore-then-Commit和Action Elimination策略。


<details>
  <summary>Details</summary>
Motivation: 受边缘推理挑战的驱动，研究每个臂对应一个具有相关准确度和错误概率的推理模型的级联赌博机变体。

Method: 分析四种决策策略：Explore-then-Commit、Action Elimination、Lower Confidence Bound (LCB)和Thompson Sampling，并提供每种策略的严格理论遗憾保证。

Result: 与经典赌博机设置不同，Explore-then-Commit和Action Elimination因在探索阶段后承诺固定排序而遭受次优遗憾。LCB和Thompson Sampling基于观察到的反馈持续更新决策，实现常数O(1)遗憾。

Conclusion: 仿真验证了理论发现，突显了在不确定性下适应性对高效边缘推理的关键作用。

Abstract: Motivated by the challenges of edge inference, we study a variant of the cascade bandit model in which each arm corresponds to an inference model with an associated accuracy and error probability. We analyse four decision-making policies-Explore-then-Commit, Action Elimination, Lower Confidence Bound (LCB), and Thompson Sampling-and provide sharp theoretical regret guarantees for each. Unlike in classical bandit settings, Explore-then-Commit and Action Elimination incur suboptimal regret because they commit to a fixed ordering after the exploration phase, limiting their ability to adapt. In contrast, LCB and Thompson Sampling continuously update their decisions based on observed feedback, achieving constant O(1) regret. Simulations corroborate these theoretical findings, highlighting the crucial role of adaptivity for efficient edge inference under uncertainty.

</details>


### [32] [Flow matching-based generative models for MIMO channel estimation](https://arxiv.org/abs/2511.10941)
*Wenkai Liu,Nan Ma,Jianqiao Chen,Xiaoxuan Qi,Yuhang Ma*

Main category: cs.LG

TL;DR: 提出了一种基于流匹配（FM）的生成模型用于MIMO信道估计，相比扩散模型显著提高了采样速度，同时保持了高精度的信道估计性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在信道估计中表现出高精度，但采样速度慢是主要挑战。为解决这个问题，需要开发更高效的生成模型。

Method: 将信道估计问题构建在流匹配框架内，构建从噪声信道分布到真实信道分布的条件概率路径，推导仅依赖噪声统计的速度场来指导生成模型训练，在采样阶段使用训练好的速度场作为先验信息通过ODE欧拉求解器进行快速噪声信道增强。

Result: 数值结果表明，相比其他流行的基于扩散模型的方案（如分数匹配方案），所提出的基于FM的信道估计方案能显著降低采样开销，同时在不同信道条件下实现优越的信道估计精度。

Conclusion: 基于流匹配的信道估计方案在保持高精度的同时，显著提高了采样效率，为MIMO系统提供了快速可靠的信道估计解决方案。

Abstract: Diffusion model (DM)-based channel estimation, which generates channel samples via a posteriori sampling stepwise with denoising process, has shown potential in high-precision channel state information (CSI) acquisition. However, slow sampling speed is an essential challenge for recent developed DM-based schemes. To alleviate this problem, we propose a novel flow matching (FM)-based generative model for multiple-input multiple-output (MIMO) channel estimation. We first formulate the channel estimation problem within FM framework, where the conditional probability path is constructed from the noisy channel distribution to the true channel distribution. In this case, the path evolves along the straight-line trajectory at a constant speed. Then, guided by this, we derive the velocity field that depends solely on the noise statistics to guide generative models training. Furthermore, during the sampling phase, we utilize the trained velocity field as prior information for channel estimation, which allows for quick and reliable noise channel enhancement via ordinary differential equation (ODE) Euler solver. Finally, numerical results demonstrate that the proposed FM-based channel estimation scheme can significantly reduce the sampling overhead compared to other popular DM-based schemes, such as the score matching (SM)-based scheme. Meanwhile, it achieves superior channel estimation accuracy under different channel conditions.

</details>


### [33] [From Parameter to Representation: A Closed-Form Approach for Controllable Model Merging](https://arxiv.org/abs/2511.10943)
*Jialin Wu,Jian Yang,Handing Wang,Jiajun Wen,Zhiyong Yu*

Main category: cs.LG

TL;DR: 提出了一种新的可控模型合并方法，通过直接修正模型最终表示的最优线性变换来替代昂贵的离线多目标优化，实现线性复杂度的高效Pareto最优模型生成。


<details>
  <summary>Details</summary>
Motivation: 传统模型合并方法面临参数干扰问题，现有可控合并方法采用编译-查询范式，离线优化复杂度随任务数指数增长，限制了实用性。

Method: 将视角从参数空间优化转向直接修正模型最终表示，将修正建模为最优线性变换问题，得到闭式解，用单步架构无关计算替代整个离线优化过程。

Result: 实验结果显示该方法生成的Pareto前沿更优，偏好对齐更精确，计算成本大幅降低。

Conclusion: 该方法通过表示空间的最优线性变换实现了高效可控的模型合并，显著降低了计算复杂度，为多任务模型合并提供了实用解决方案。

Abstract: Model merging combines expert models for multitask performance but faces challenges from parameter interference. This has sparked recent interest in controllable model merging, giving users the ability to explicitly balance performance trade-offs. Existing approaches employ a compile-then-query paradigm, performing a costly offline multi-objective optimization to enable fast, preference-aware model generation. This offline stage typically involves iterative search or dedicated training, with complexity that grows exponentially with the number of tasks. To overcome these limitations, we shift the perspective from parameter-space optimization to a direct correction of the model's final representation. Our approach models this correction as an optimal linear transformation, yielding a closed-form solution that replaces the entire offline optimization process with a single-step, architecture-agnostic computation. This solution directly incorporates user preferences, allowing a Pareto-optimal model to be generated on-the-fly with complexity that scales linearly with the number of tasks. Experimental results show our method generates a superior Pareto front with more precise preference alignment and drastically reduced computational cost.

</details>


### [34] [How Data Quality Affects Machine Learning Models for Credit Risk Assessment](https://arxiv.org/abs/2511.10964)
*Andrea Maurino*

Main category: cs.LG

TL;DR: 该研究探讨了数据质量问题（缺失值、噪声属性、异常值、标签错误）对信用风险评估机器学习模型预测准确性的影响，评估了10种常用模型的鲁棒性差异。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在信用风险评估中的应用日益广泛，但其有效性很大程度上依赖于输入数据的质量，需要研究数据质量问题对模型性能的影响。

Method: 使用开源数据集，通过Pucktrick库引入受控的数据损坏，评估包括随机森林、SVM、逻辑回归等10种常用模型的鲁棒性。

Result: 实验显示不同模型对数据退化的鲁棒性存在显著差异，具体取决于数据损坏的性质和严重程度。

Conclusion: 提出的方法和配套工具为从业者增强数据管道鲁棒性提供了实用支持，并为研究人员在数据为中心的AI环境中进一步实验提供了灵活框架。

Abstract: Machine Learning (ML) models are being increasingly employed for credit risk evaluation, with their effectiveness largely hinging on the quality of the input data. In this paper we investigate the impact of several data quality issues, including missing values, noisy attributes, outliers, and label errors, on the predictive accuracy of the machine learning model used in credit risk assessment. Utilizing an open-source dataset, we introduce controlled data corruption using the Pucktrick library to assess the robustness of 10 frequently used models like Random Forest, SVM, and Logistic Regression and so on. Our experiments show significant differences in model robustness based on the nature and severity of the data degradation. Moreover, the proposed methodology and accompanying tools offer practical support for practitioners seeking to enhance data pipeline robustness, and provide researchers with a flexible framework for further experimentation in data-centric AI contexts.

</details>


### [35] [Unsupervised Robust Domain Adaptation: Paradigm, Theory and Algorithm](https://arxiv.org/abs/2511.11009)
*Fuxiang Huang,Xiaowei Fu,Shiyu Ye,Lina Ma,Wen Li,Xinbo Gao,David Zhang,Lei Zhang*

Main category: cs.LG

TL;DR: 本文提出了无监督鲁棒域自适应（URDA）范式，解决了传统UDA方法在对抗攻击下缺乏鲁棒性的问题，并提出了解耦对抗鲁棒训练（DART）算法。


<details>
  <summary>Details</summary>
Motivation: 传统无监督域自适应方法强调迁移能力但忽视对抗攻击鲁棒性，而标准对抗训练在UDA中效果不佳。本文旨在解决UDA+VAT范式中的内在纠缠问题。

Method: 提出URDA范式并建立其泛化边界理论，设计DART算法：先预训练任意UDA模型，然后通过解耦蒸馏进行瞬时鲁棒化后训练。

Result: 在四个基准数据集上的实验表明，DART能有效增强鲁棒性同时保持域适应性，验证了URDA范式和理论。

Conclusion: 首次建立了URDA范式和理论，提出的DART算法简单有效，为UDA领域提供了兼具迁移能力和鲁棒性的解决方案。

Abstract: Unsupervised domain adaptation (UDA) aims to transfer knowledge from a label-rich source domain to an unlabeled target domain by addressing domain shifts. Most UDA approaches emphasize transfer ability, but often overlook robustness against adversarial attacks. Although vanilla adversarial training (VAT) improves the robustness of deep neural networks, it has little effect on UDA. This paper focuses on answering three key questions: 1) Why does VAT, known for its defensive effectiveness, fail in the UDA paradigm? 2) What is the generalization bound theory under attacks and how does it evolve from classical UDA theory? 3) How can we implement a robustification training procedure without complex modifications? Specifically, we explore and reveal the inherent entanglement challenge in general UDA+VAT paradigm, and propose an unsupervised robust domain adaptation (URDA) paradigm. We further derive the generalization bound theory of the URDA paradigm so that it can resist adversarial noise and domain shift. To the best of our knowledge, this is the first time to establish the URDA paradigm and theory. We further introduce a simple, novel yet effective URDA algorithm called Disentangled Adversarial Robustness Training (DART), a two-step training procedure that ensures both transferability and robustness. DART first pre-trains an arbitrary UDA model, and then applies an instantaneous robustification post-training step via disentangled distillation.Experiments on four benchmark datasets with/without attacks show that DART effectively enhances robustness while maintaining domain adaptability, and validate the URDA paradigm and theory.

</details>


### [36] [Enhancing Graph Representations with Neighborhood-Contextualized Message-Passing](https://arxiv.org/abs/2511.11046)
*Brian Godwin Lim*

Main category: cs.LG

TL;DR: 提出了邻域上下文消息传递(NCMP)框架，通过考虑更广泛的局部邻域信息来增强经典消息传递GNN的表达能力，并开发了SINC-GCN模型。


<details>
  <summary>Details</summary>
Motivation: 传统消息传递GNN只考虑中心节点和单个邻居节点的特征对，未能利用整个邻域集合中的丰富上下文信息，限制了学习复杂关系的能力。

Method: 首先形式化邻域上下文概念，基于此将消息传递泛化为NCMP框架，并提出简单实用的参数化方法，开发了SINC-GCN模型。

Result: 在合成二元节点分类问题上的初步分析验证了所提GNN架构的表达能力和效率。

Conclusion: NCMP框架为增强经典GNN的图表示能力提供了一条实用路径。

Abstract: Graph neural networks (GNNs) have become an indispensable tool for analyzing relational data. In the literature, classical GNNs may be classified into three variants: convolutional, attentional, and message-passing. While the standard message-passing variant is highly expressive, its typical pair-wise messages nevertheless only consider the features of the center node and each neighboring node individually. This design fails to incorporate the rich contextual information contained within the broader local neighborhood, potentially hindering its ability to learn complex relationships within the entire set of neighboring nodes. To address this limitation, this work first formalizes the concept of neighborhood-contextualization, rooted in a key property of the attentional variant. This then serves as the foundation for generalizing the message-passing variant to the proposed neighborhood-contextualized message-passing (NCMP) framework. To demonstrate its utility, a simple, practical, and efficient method to parametrize and operationalize NCMP is presented, leading to the development of the proposed Soft-Isomorphic Neighborhood-Contextualized Graph Convolution Network (SINC-GCN). A preliminary analysis on a synthetic binary node classification problem then underscores both the expressivity and efficiency of the proposed GNN architecture. Overall, the paper lays the foundation for the novel NCMP framework as a practical path toward further enhancing the graph representational power of classical GNNs.

</details>


### [37] [Echoless Label-Based Pre-computation for Memory-Efficient Heterogeneous Graph Learning](https://arxiv.org/abs/2511.11081)
*Jun Hu,Shangheng Chen,Yufei He,Yuan Li,Bryan Hooi,Bingsheng He*

Main category: cs.LG

TL;DR: 提出Echoless-LP方法解决异质图神经网络中标签预计算方法的训练标签泄露问题，通过分区聚焦无回声传播消除回声效应，保持内存效率并与任意消息传递方法兼容。


<details>
  <summary>Details</summary>
Motivation: 现有的基于标签预计算的HGNNs存在训练标签泄露问题（回声效应），即节点的自身标签信息在多跳消息传递中传播回自身。现有的缓解策略在大图上内存效率低或与先进消息传递方法存在兼容性问题。

Method: 提出Echoless-LP方法，采用分区聚焦无回声传播(PFEP)：将目标节点分区，每个分区中的节点只从其他分区的邻居收集标签信息，避免回声效应。还引入非对称分区方案(APS)和PostAdjust机制来解决分区造成的信息丢失和分布偏移问题。

Result: 在公共数据集上的实验表明，Echoless-LP相比基线方法实现了更优的性能，同时保持了内存效率。

Conclusion: Echoless-LP有效解决了异质图神经网络中标签预计算的训练标签泄露问题，提供了一种内存高效且与任意消息传递方法兼容的解决方案。

Abstract: Heterogeneous Graph Neural Networks (HGNNs) are widely used for deep learning on heterogeneous graphs. Typical end-to-end HGNNs require repetitive message passing during training, limiting efficiency for large-scale real-world graphs. Pre-computation-based HGNNs address this by performing message passing only once during preprocessing, collecting neighbor information into regular-shaped tensors, which enables efficient mini-batch training. Label-based pre-computation methods collect neighbors' label information but suffer from training label leakage, where a node's own label information propagates back to itself during multi-hop message passing - the echo effect. Existing mitigation strategies are memory-inefficient on large graphs or suffer from compatibility issues with advanced message passing methods. We propose Echoless Label-based Pre-computation (Echoless-LP), which eliminates training label leakage with Partition-Focused Echoless Propagation (PFEP). PFEP partitions target nodes and performs echoless propagation, where nodes in each partition collect label information only from neighbors in other partitions, avoiding echo while remaining memory-efficient and compatible with any message passing method. We also introduce an Asymmetric Partitioning Scheme (APS) and a PostAdjust mechanism to address information loss from partitioning and distributional shifts across partitions. Experiments on public datasets demonstrate that Echoless-LP achieves superior performance and maintains memory efficiency compared to baselines.

</details>


### [38] [Scalable Population Training for Zero-Shot Coordination](https://arxiv.org/abs/2511.11083)
*Bingyu Hui,Lebin Yu,Quanming Yao,Yunpeng Qu,Xudong Zhang,Jian Wang*

Main category: cs.LG

TL;DR: 提出了ScaPT框架，通过元代理和互信息正则化器实现高效的大规模群体训练，在Hanabi游戏中验证了其优于现有方法的零样本协调性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于群体的零样本协调方法受限于计算资源，主要优化小群体的多样性，而忽视了扩大群体规模带来的性能提升潜力。

Method: ScaPT框架包含两个关键组件：通过选择性共享参数实现群体的元代理，以及保证群体多样性的互信息正则化器。

Result: 在Hanabi游戏中的实验验证了ScaPT框架的有效性，确认了其相对于代表性框架的优越性。

Conclusion: ScaPT通过高效的大规模群体训练方法，成功解决了零样本协调中群体规模扩展的问题，提供了更好的协调性能。

Abstract: Zero-shot coordination(ZSC) has become a hot topic in reinforcement learning research recently. It focuses on the generalization ability of agents, requiring them to coordinate well with collaborators that are not seen before without any fine-tuning. Population-based training has been proven to provide good zero-shot coordination performance; nevertheless, existing methods are limited by computational resources, mainly focusing on optimizing diversity in small populations while neglecting the potential performance gains from scaling population size. To address this issue, this paper proposes the Scalable Population Training (ScaPT), an efficient training framework comprising two key components: a meta-agent that efficiently realizes a population by selectively sharing parameters across agents, and a mutual information regularizer that guarantees population diversity. To empirically validate the effectiveness of ScaPT, this paper evaluates it along with representational frameworks in Hanabi and confirms its superiority.

</details>


### [39] [Sheaf Cohomology of Linear Predictive Coding Networks](https://arxiv.org/abs/2511.11092)
*Jeffrey Seely*

Main category: cs.LG

TL;DR: 该论文将线性预测编码网络建模为胞腔层，揭示了PC推理是层拉普拉斯算子下的扩散过程，并分析了循环拓扑中内部矛盾导致的学习停滞问题。


<details>
  <summary>Details</summary>
Motivation: 预测编码用局部优化替代全局反向传播，但循环拓扑中的反馈回路会产生内部矛盾，导致与监督无关的预测误差，影响学习效果。

Method: 使用胞腔层理论建模PC网络：层上链映射将激活映射为边预测误差，PC推理是层拉普拉斯算子下的扩散过程，利用霍奇分解分析不可约误差模式。

Result: 发现循环拓扑中的内部矛盾会引入无法通过推理消除的预测误差，导致学习停滞；层形式主义提供了诊断问题网络配置的工具。

Conclusion: 胞腔层形式主义为识别有问题的网络配置提供了诊断工具，并为循环PC网络的有效权重初始化提供了设计原则。

Abstract: Predictive coding (PC) replaces global backpropagation with local optimization over weights and activations. We show that linear PC networks admit a natural formulation as cellular sheaves: the sheaf coboundary maps activations to edge-wise prediction errors, and PC inference is diffusion under the sheaf Laplacian. Sheaf cohomology then characterizes irreducible error patterns that inference cannot remove. We analyze recurrent topologies where feedback loops create internal contradictions, introducing prediction errors unrelated to supervision. Using a Hodge decomposition, we determine when these contradictions cause learning to stall. The sheaf formalism provides both diagnostic tools for identifying problematic network configurations and design principles for effective weight initialization for recurrent PC networks.

</details>


### [40] [SMART: A Surrogate Model for Predicting Application Runtime in Dragonfly Systems](https://arxiv.org/abs/2511.11111)
*Xin Wang,Pietro Lodi Rizzini,Sourav Medya,Zhiling Lan*

Main category: cs.LG

TL;DR: 提出了一种结合图神经网络和大型语言模型的替代模型，用于准确预测Dragonfly网络中应用运行时间，支持高效的混合仿真。


<details>
  <summary>Details</summary>
Motivation: Dragonfly网络在高性能计算中是领先的互连结构，但共享网络链路上的工作负载干扰是一个主要挑战。传统的高保真并行离散事件仿真计算成本高，不适用于大规模或实时场景。

Method: 开发了结合图神经网络和大型语言模型的替代模型，从端口级路由器数据中捕获空间和时间模式。

Result: 该模型在运行时间预测方面优于现有的统计和机器学习基线方法。

Conclusion: 该混合仿真方法能够准确预测运行时间，支持Dragonfly网络的高效仿真。

Abstract: The Dragonfly network, with its high-radix and low-diameter structure, is a leading interconnect in high-performance computing. A major challenge is workload interference on shared network links. Parallel discrete event simulation (PDES) is commonly used to analyze workload interference. However, high-fidelity PDES is computationally expensive, making it impractical for large-scale or real-time scenarios. Hybrid simulation that incorporates data-driven surrogate models offers a promising alternative, especially for forecasting application runtime, a task complicated by the dynamic behavior of network traffic. We present \ourmodel, a surrogate model that combines graph neural networks (GNNs) and large language models (LLMs) to capture both spatial and temporal patterns from port level router data. \ourmodel outperforms existing statistical and machine learning baselines, enabling accurate runtime prediction and supporting efficient hybrid simulation of Dragonfly networks.

</details>


### [41] [Improving Continual Learning of Knowledge Graph Embeddings via Informed Initialization](https://arxiv.org/abs/2511.11118)
*Gerard Pons,Besim Bilalli,Anna Queralt*

Main category: cs.LG

TL;DR: 提出了一种新的知识图谱嵌入初始化策略，利用图谱模式和已有嵌入为新实体生成初始表示，提升持续学习效果


<details>
  <summary>Details</summary>
Motivation: 知识图谱频繁更新需要嵌入模型持续适应，而新实体嵌入初始化对最终准确性和训练时间有重要影响，特别是对于小而频繁的更新

Method: 利用知识图谱模式和先前学习的嵌入，基于实体所属类别为新实体获取初始表示，可与现有持续学习方法无缝集成

Result: 实验分析显示该方法提高了预测性能，增强了知识保留，加速了知识获取，减少了训练轮次和时间

Conclusion: 该初始化策略能有效改善知识图谱嵌入的持续学习效果，在不同类型嵌入模型中均表现出优势

Abstract: Many Knowledege Graphs (KGs) are frequently updated, forcing their Knowledge Graph Embeddings (KGEs) to adapt to these changes. To address this problem, continual learning techniques for KGEs incorporate embeddings for new entities while updating the old ones. One necessary step in these methods is the initialization of the embeddings, as an input to the KGE learning process, which can have an important impact in the accuracy of the final embeddings, as well as in the time required to train them. This is especially relevant for relatively small and frequent updates. We propose a novel informed embedding initialization strategy, which can be seamlessly integrated into existing continual learning methods for KGE, that enhances the acquisition of new knowledge while reducing catastrophic forgetting. Specifically, the KG schema and the previously learned embeddings are utilized to obtain initial representations for the new entities, based on the classes the entities belong to. Our extensive experimental analysis shows that the proposed initialization strategy improves the predictive performance of the resulting KGEs, while also enhancing knowledge retention. Furthermore, our approach accelerates knowledge acquisition, reducing the number of epochs, and therefore time, required to incrementally learn new embeddings. Finally, its benefits across various types of KGE learning models are demonstrated.

</details>


### [42] [Anomaly Detection in High-Dimensional Bank Account Balances via Robust Methods](https://arxiv.org/abs/2511.11143)
*Federico Maddanu,Tommaso Proietti,Riccardo Crupi*

Main category: cs.LG

TL;DR: 提出并评估了在中等和高维数据集中计算高效的几种稳健方法，用于检测银行账户余额中的点异常，应用于260万条匿名用户银行账户余额的每日记录。


<details>
  <summary>Details</summary>
Motivation: 检测银行账户余额中的点异常对于金融机构至关重要，可以识别潜在的欺诈、操作问题或其他异常情况。稳健统计方法在标记异常值和提供不受污染观测影响的数据分布参数估计方面很有用，但在高维设置下通常效率较低且计算成本高。

Method: 提出并评估了几种稳健方法，这些方法在中等和高维数据集中具有高崩溃点和低计算时间，可能计算高效。

Result: 应用处理了约260万条匿名用户银行账户余额的每日记录。

Conclusion: 所提出的稳健方法在高维金融数据异常检测中具有实际应用价值，能够有效平衡计算效率和检测准确性。

Abstract: Detecting point anomalies in bank account balances is essential for financial institutions, as it enables the identification of potential fraud, operational issues, or other irregularities. Robust statistics is useful for flagging outliers and for providing estimates of the data distribution parameters that are not affected by contaminated observations. However, such a strategy is often less efficient and computationally expensive under high dimensional setting. In this paper, we propose and evaluate empirically several robust approaches that may be computationally efficient in medium and high dimensional datasets, with high breakdown points and low computational time. Our application deals with around 2.6 million daily records of anonymous users' bank account balances.

</details>


### [43] [Deep Learning for Short-Term Precipitation Prediction in Four Major Indian Cities: A ConvLSTM Approach with Explainable AI](https://arxiv.org/abs/2511.11152)
*Tanmay Ghosh,Shaurabh Anand,Rakesh Gomaji Nannewar,Nithin Nagaraj*

Main category: cs.LG

TL;DR: 开发了一个可解释的深度学习框架，用于印度四个主要城市的短期降水预测，结合CNN-ConvLSTM架构和多种可解释性分析技术，实现了准确且透明的降水预报。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习降水预报模型往往作为黑盒运行，限制了其在真实天气预报中的采用。为了在保持准确性的同时增强透明度，需要开发可解释的深度学习框架。

Method: 采用混合时间分布式CNN-ConvLSTM架构，在多年代ERA5再分析数据上训练。为每个城市优化了卷积滤波器数量：班加罗尔（32）、孟买和德里（64）、加尔各答（128）。使用排列重要性、Grad-CAM、时间遮挡和反事实扰动进行可解释性分析。

Result: 模型实现了不同的RMSE值：班加罗尔0.21毫米/天、孟买0.52毫米/天、德里0.48毫米/天、加尔各答1.80毫米/天。预测时间范围从班加罗尔的1天到加尔各答的5天不等。模型依赖城市特定的变量进行预测。

Conclusion: 研究表明可解释AI（xAI）能够为不同城市环境提供准确的降水预测和透明的模式洞察，展示了深度学习模型在天气预报中的透明化应用潜力。

Abstract: Deep learning models for precipitation forecasting often function as black boxes, limiting their adoption in real-world weather prediction. To enhance transparency while maintaining accuracy, we developed an interpretable deep learning framework for short-term precipitation prediction in four major Indian cities: Bengaluru, Mumbai, Delhi, and Kolkata, spanning diverse climate zones. We implemented a hybrid Time-Distributed CNN-ConvLSTM (Convolutional Neural Network-Long Short-Term Memory) architecture, trained on multi-decadal ERA5 reanalysis data. The architecture was optimized for each city with a different number of convolutional filters: Bengaluru (32), Mumbai and Delhi (64), and Kolkata (128). The models achieved root mean square error (RMSE) values of 0.21 mm/day (Bengaluru), 0.52 mm/day (Mumbai), 0.48 mm/day (Delhi), and 1.80 mm/day (Kolkata). Through interpretability analysis using permutation importance, Gradient-weighted Class Activation Mapping (Grad-CAM), temporal occlusion, and counterfactual perturbation, we identified distinct patterns in the model's behavior. The model relied on city-specific variables, with prediction horizons ranging from one day for Bengaluru to five days for Kolkata. This study demonstrates how explainable AI (xAI) can provide accurate forecasts and transparent insights into precipitation patterns in diverse urban environments.

</details>


### [44] [Adaptive Symmetrization of the KL Divergence](https://arxiv.org/abs/2511.11159)
*Omri Ben-Dov,Luiz F. O. Chamon*

Main category: cs.LG

TL;DR: 提出了一种新的方法来最小化Jeffreys散度，通过使用代理模型来辅助优化主模型的Jeffreys散度，将联合训练任务表述为约束优化问题。


<details>
  <summary>Details</summary>
Motivation: 传统的概率分布学习方法通常使用前向KL散度，但其不对称性可能无法捕捉目标分布的所有特性。对称替代方案如Jeffreys散度计算困难，需要开发新的优化方法。

Method: 使用代理模型来辅助优化主模型的Jeffreys散度，将联合训练任务表述为约束优化问题，并在训练过程中自适应调整模型优先级。

Result: 该方法能够结合归一化流(NFs)和能量基模型(EBMs)的优势，应用于密度估计、图像生成和基于模拟的推理等任务。

Conclusion: 提出的框架为最小化Jeffreys散度提供了一种实用的算法，能够有效结合不同概率模型的优势。

Abstract: Many tasks in machine learning can be described as or reduced to learning a probability distribution given a finite set of samples. A common approach is to minimize a statistical divergence between the (empirical) data distribution and a parameterized distribution, e.g., a normalizing flow (NF) or an energy-based model (EBM). In this context, the forward KL divergence is a ubiquitous due to its tractability, though its asymmetry may prevent capturing some properties of the target distribution. Symmetric alternatives involve brittle min-max formulations and adversarial training (e.g., generative adversarial networks) or evaluating the reverse KL divergence, as is the case for the symmetric Jeffreys divergence, which is challenging to compute from samples. This work sets out to develop a new approach to minimize the Jeffreys divergence. To do so, it uses a proxy model whose goal is not only to fit the data, but also to assist in optimizing the Jeffreys divergence of the main model. This joint training task is formulated as a constrained optimization problem to obtain a practical algorithm that adapts the models priorities throughout training. We illustrate how this framework can be used to combine the advantages of NFs and EBMs in tasks such as density estimation, image generation, and simulation-based inference.

</details>


### [45] [Training Neural Networks at Any Scale](https://arxiv.org/abs/2511.11163)
*Thomas Pethick,Kimon Antonakopoulos,Antonio Silveti-Falls,Leena Chennuru Vankadara,Volkan Cevher*

Main category: cs.LG

TL;DR: 本文综述了现代神经网络训练优化方法，重点关注效率和可扩展性，介绍了最先进的优化算法及其统一模板。


<details>
  <summary>Details</summary>
Motivation: 随着神经网络规模和复杂度的增长，需要高效的优化方法来应对大规模训练问题。

Method: 提出了统一的算法模板，强调适应问题结构的重要性，并使算法对问题规模具有不可知性。

Result: 系统整理了最先进的优化算法，为实践者和研究者提供了全面的介绍。

Conclusion: 本文为希望参与这一激动人心新发展的实践者和研究者提供了入门指南。

Abstract: This article reviews modern optimization methods for training neural networks with an emphasis on efficiency and scale. We present state-of-the-art optimization algorithms under a unified algorithmic template that highlights the importance of adapting to the structures in the problem. We then cover how to make these algorithms agnostic to the scale of the problem. Our exposition is intended as an introduction for both practitioners and researchers who wish to be involved in these exciting new developments.

</details>


### [46] [Power Ensemble Aggregation for Improved Extreme Event AI Prediction](https://arxiv.org/abs/2511.11170)
*Julien Collard,Pierre Gentine,Tian Zheng*

Main category: cs.LG

TL;DR: 使用幂均值聚合集成预测可显著提升热浪等气候极端事件的预测性能，相比传统均值预测方法在预测极端高温事件方面表现更好。


<details>
  <summary>Details</summary>
Motivation: 解决气候极端事件（特别是热浪）预测的关键挑战，通过机器学习方法改进预测准确性。

Method: 将问题构建为分类问题，预测地表气温是否会在指定时间范围内超过其局部q分位数；通过使基于机器学习的天气预报模型具有生成性，并应用幂均值这一非线性聚合方法来集成预测。

Result: 幂均值聚合方法显著提升了分类器的性能，在预测极端热事件方面比同一模型的典型均值预测具有更好的准确性；该方法的最优性能随所选分位数阈值而变化，在预测更高极端事件时表现出更强的有效性。

Conclusion: 幂聚合方法显示出良好的前景和适应性，其性能随极端程度而变化，在预测更高极端事件时效果更佳。

Abstract: This paper addresses the critical challenge of improving predictions of climate extreme events, specifically heat waves, using machine learning methods. Our work is framed as a classification problem in which we try to predict whether surface air temperature will exceed its q-th local quantile within a specified timeframe. Our key finding is that aggregating ensemble predictions using a power mean significantly enhances the classifier's performance. By making a machine-learning based weather forecasting model generative and applying this non-linear aggregation method, we achieve better accuracy in predicting extreme heat events than with the typical mean prediction from the same model. Our power aggregation method shows promise and adaptability, as its optimal performance varies with the quantile threshold chosen, demonstrating increased effectiveness for higher extremes prediction.

</details>


### [47] [On-line learning of dynamic systems: sparse regression meets Kalman filtering](https://arxiv.org/abs/2511.11178)
*Gianluigi Pillonetto,Akram Yazdani,Aleksandr Aravkin*

Main category: cs.LG

TL;DR: 本文提出了Sindy Kalman Filter (SKF)方法，将稀疏驱动方法与卡尔曼滤波结合，实现了对非线性动态系统的实时参数识别和模型学习。


<details>
  <summary>Details</summary>
Motivation: 从数据中学习控制方程对于理解物理系统行为至关重要。现有Sindy算法在识别非线性动态系统方面有效，但缺乏实时学习能力。本文旨在将稀疏驱动方法扩展到实时学习场景。

Method: 将Sindy算法与卡尔曼滤波结合，将未知系统参数作为状态变量处理，开发了SKF方法。该方法通过前瞻误差增强参数识别策略，简化了稀疏水平、方差参数和切换时刻的估计。

Result: 在具有漂移或切换参数的混沌Lorenz系统上验证了SKF的有效性，并在基于真实飞行数据构建的稀疏非线性飞机模型上展示了实时识别能力。

Conclusion: SKF统一了稀疏驱动和卡尔曼滤波框架，能够实时推断复杂时变非线性模型，这是单独使用任一方法都无法实现的。

Abstract: Learning governing equations from data is central to understanding the behavior of physical systems across diverse scientific disciplines, including physics, biology, and engineering. The Sindy algorithm has proven effective in leveraging sparsity to identify concise models of nonlinear dynamical systems. In this paper, we extend sparsity-driven approaches to real-time learning by integrating a cornerstone algorithm from control theory -- the Kalman filter (KF). The resulting Sindy Kalman Filter (SKF) unifies both frameworks by treating unknown system parameters as state variables, enabling real-time inference of complex, time-varying nonlinear models unattainable by either method alone. Furthermore, SKF enhances KF parameter identification strategies, particularly via look-ahead error, significantly simplifying the estimation of sparsity levels, variance parameters, and switching instants. We validate SKF on a chaotic Lorenz system with drifting or switching parameters and demonstrate its effectiveness in the real-time identification of a sparse nonlinear aircraft model built from real flight data.

</details>


### [48] [Dynamic Deep Graph Learning for Incomplete Multi-View Clustering with Masked Graph Reconstruction Loss](https://arxiv.org/abs/2511.11181)
*Zhenghao Zhang,Jun Xie,Xingchen Chen,Tao Yu,Hongzhu Yi,Kaixin Xu,Yuanxiang Wang,Tianyu Zong,Xinming Wang,Jiahuan Chen,Guoqing Chao,Feng Chen,Zhepeng Wang,Jungang Xu*

Main category: cs.LG

TL;DR: 提出了一种动态深度图学习方法DGIMVCM，用于不完全多视图聚类，通过动态图学习、掩码图重构损失和伪标签自监督训练来解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中多视图数据普遍存在不完全性，现有基于GNN的方法存在两个主要问题：使用KNN构建静态图引入噪声，以及直接使用MSE损失导致梯度噪声。

Method: 1) 从原始数据构建缺失鲁棒的全局图，使用图卷积嵌入层提取特征和动态视图特定图结构；2) 引入图自注意力编码器提取高层表示，使用掩码图重构损失优化；3) 构建聚类模块并通过伪标签自监督训练机制优化。

Result: 在多个数据集上的广泛实验验证了DGIMVCM的有效性和优越性。

Conclusion: DGIMVCM通过动态图学习、掩码图重构损失和伪标签自监督训练，有效解决了不完全多视图聚类中的关键挑战，取得了显著的性能提升。

Abstract: The prevalence of real-world multi-view data makes incomplete multi-view clustering (IMVC) a crucial research. The rapid development of Graph Neural Networks (GNNs) has established them as one of the mainstream approaches for multi-view clustering. Despite significant progress in GNNs-based IMVC, some challenges remain: (1) Most methods rely on the K-Nearest Neighbors (KNN) algorithm to construct static graphs from raw data, which introduces noise and diminishes the robustness of the graph topology. (2) Existing methods typically utilize the Mean Squared Error (MSE) loss between the reconstructed graph and the sparse adjacency graph directly as the graph reconstruction loss, leading to substantial gradient noise during optimization. To address these issues, we propose a novel \textbf{D}ynamic Deep \textbf{G}raph Learning for \textbf{I}ncomplete \textbf{M}ulti-\textbf{V}iew \textbf{C}lustering with \textbf{M}asked Graph Reconstruction Loss (DGIMVCM). Firstly, we construct a missing-robust global graph from the raw data. A graph convolutional embedding layer is then designed to extract primary features and refined dynamic view-specific graph structures, leveraging the global graph for imputation of missing views. This process is complemented by graph structure contrastive learning, which identifies consistency among view-specific graph structures. Secondly, a graph self-attention encoder is introduced to extract high-level representations based on the imputed primary features and view-specific graphs, and is optimized with a masked graph reconstruction loss to mitigate gradient noise during optimization. Finally, a clustering module is constructed and optimized through a pseudo-label self-supervised training mechanism. Extensive experiments on multiple datasets validate the effectiveness and superiority of DGIMVCM.

</details>


### [49] [LoRaCompass: Robust Reinforcement Learning to Efficiently Search for a LoRa Tag](https://arxiv.org/abs/2511.11190)
*Tianlang He,Zhongming Lin,Tianrui Jiang,S. -H. Gary Chan*

Main category: cs.LG

TL;DR: LoRaCompass是一个强化学习模型，用于在未知环境中高效定位LoRa标签，通过空间感知特征提取和策略蒸馏损失函数实现鲁棒搜索，在80km²的多样化环境中验证，定位成功率超过90%，搜索路径长度与初始距离呈线性关系。


<details>
  <summary>Details</summary>
Motivation: 现有的基于强化学习的LoRa标签定位方法容易受到领域偏移和信号波动的影响，导致级联决策错误和显著的定位不准确性。

Method: 提出LoRaCompass模型，包含：1）空间感知特征提取器和策略蒸馏损失函数，从RSSI学习鲁棒空间表示以最大化靠近标签的概率；2）受上置信界启发的探索函数，引导传感器以递增置信度向标签移动。

Result: 在超过80km²的多样化未见环境中验证，LoRaCompass在100米范围内定位标签的成功率超过90%（比现有方法提高40%），搜索路径长度（跳数）与初始距离呈线性关系。

Conclusion: LoRaCompass能够实现鲁棒且高效的LoRa标签搜索，在领域偏移和信号波动下表现出色，为心智障碍人士等易走失人群的定位提供了有效解决方案。

Abstract: The Long-Range (LoRa) protocol, known for its extensive range and low power, has increasingly been adopted in tags worn by mentally incapacitated persons (MIPs) and others at risk of going missing. We study the sequential decision-making process for a mobile sensor to locate a periodically broadcasting LoRa tag with the fewest moves (hops) in general, unknown environments, guided by the received signal strength indicator (RSSI). While existing methods leverage reinforcement learning for search, they remain vulnerable to domain shift and signal fluctuation, resulting in cascading decision errors that culminate in substantial localization inaccuracies. To bridge this gap, we propose LoRaCompass, a reinforcement learning model designed to achieve robust and efficient search for a LoRa tag. For exploitation under domain shift and signal fluctuation, LoRaCompass learns a robust spatial representation from RSSI to maximize the probability of moving closer to a tag, via a spatially-aware feature extractor and a policy distillation loss function. It further introduces an exploration function inspired by the upper confidence bound (UCB) that guides the sensor toward the tag with increasing confidence. We have validated LoRaCompass in ground-based and drone-assisted scenarios within diverse unseen environments covering an area of over 80km^2. It has demonstrated high success rate (>90%) in locating the tag within 100m proximity (a 40% improvement over existing methods) and high efficiency with a search path length (in hops) that scales linearly with the initial distance.

</details>


### [50] [When to Stop Federated Learning: Zero-Shot Generation of Synthetic Validation Data with Generative AI for Early Stopping](https://arxiv.org/abs/2511.11208)
*Youngjoon Lee,Hyukjoon Lee,Jinu Gong,Yang Cao,Joonhyuk Kang*

Main category: cs.LG

TL;DR: 提出了一种基于零样本合成验证的联邦学习早停框架，利用生成式AI监控模型性能，在达到最优性能时提前停止训练，节省计算资源。


<details>
  <summary>Details</summary>
Motivation: 联邦学习通常预设固定的训练轮数，导致在达到最优性能后仍继续不必要的计算，或在模型无法取得有意义性能时仍持续训练，造成资源浪费。

Method: 使用生成式AI构建零样本合成验证框架，监控模型性能并自适应确定早停点，在接近最优轮数时停止训练。

Result: 在多标签胸部X光分类任务上，该方法将训练轮数减少高达74%，同时保持准确率在最优值的1%以内。

Conclusion: 该框架能有效节省计算资源，支持快速超参数调整，为联邦学习提供了高效的训练终止策略。

Abstract: Federated Learning (FL) enables collaborative model training across decentralized devices while preserving data privacy. However, FL methods typically run for a predefined number of global rounds, often leading to unnecessary computation when optimal performance is reached earlier. In addition, training may continue even when the model fails to achieve meaningful performance. To address this inefficiency, we introduce a zero-shot synthetic validation framework that leverages generative AI to monitor model performance and determine early stopping points. Our approach adaptively stops training near the optimal round, thereby conserving computational resources and enabling rapid hyperparameter adjustments. Numerical results on multi-label chest X-ray classification demonstrate that our method reduces training rounds by up to 74% while maintaining accuracy within 1% of the optimal.

</details>


### [51] [A Best-of-Both-Worlds Proof for Tsallis-INF without Fenchel Conjugates](https://arxiv.org/abs/2511.11211)
*Wei-Cheng Lee,Francesco Orabona*

Main category: cs.LG

TL;DR: 本文为Tsallis-INF多臂老虎机算法提供了一个简化的最佳世界保证推导，避免了共轭函数的使用，采用在线凸优化工具。


<details>
  <summary>Details</summary>
Motivation: 简化Tsallis-INF算法的理论证明，避免复杂的数学工具，提供更简洁的推导过程。

Method: 使用现代在线凸优化工具，避免共轭函数，不优化边界常数以获得更简洁的证明。

Result: 成功推导出Tsallis-INF算法在随机和对抗性老虎机问题中的最佳世界保证。

Conclusion: 通过简化证明方法，为Tsallis-INF算法提供了更易理解的理论基础，同时保持了算法的性能保证。

Abstract: In this short note, we present a simple derivation of the best-of-both-world guarantee for the Tsallis-INF multi-armed bandit algorithm from J. Zimmert and Y. Seldin. Tsallis-INF: An optimal algorithm for stochastic and adversarial bandits. Journal of Machine Learning Research, 22(28):1-49, 2021. URL https://jmlr.csail.mit.edu/papers/volume22/19-753/19-753.pdf. In particular, the proof uses modern tools from online convex optimization and avoid the use of conjugate functions. Also, we do not optimize the constants in the bounds in favor of a slimmer proof.

</details>


### [52] [Sparse Methods for Vector Embeddings of TPC Data](https://arxiv.org/abs/2511.11221)
*Tyler Wheeler,Michelle P. Kuchera,Raghuram Ramanujan,Ryan Krupp,Chris Wrede,Saiprasad Ravishankar,Connor L. Cross,Hoi Yan Ian Heung,Andrew J. Jones,Benjamin Votaw*

Main category: cs.LG

TL;DR: 探索稀疏卷积网络在时间投影室数据上的表示学习，发现即使权重随机设置的稀疏ResNet也能提供有用的事件嵌入，预训练可进一步提升嵌入质量，展示了稀疏卷积技术作为TPC实验通用表示学习工具的潜力。


<details>
  <summary>Details</summary>
Motivation: 时间投影室是核物理实验中重要的探测器，需要有效的方法来处理其产生的复杂数据，探索稀疏卷积网络在TPC数据表示学习中的应用潜力。

Method: 使用稀疏张量表示原始pad级信号，训练Minkowski Engine ResNet模型，在GADGET II TPC和AT-TPC两个不同探测器上进行交叉测试。

Result: 即使未经训练的稀疏ResNet模型也能为AT-TPC数据提供有用的嵌入，在GADGET数据上训练后嵌入质量得到改善，嵌入揭示了丰富的事件结构。

Conclusion: 稀疏卷积技术有潜力成为多样化TPC实验中通用的表示学习工具，为核物理数据分析提供新的方法。

Abstract: Time Projection Chambers (TPCs) are versatile detectors that reconstruct charged-particle tracks in an ionizing medium, enabling sensitive measurements across a wide range of nuclear physics experiments. We explore sparse convolutional networks for representation learning on TPC data, finding that a sparse ResNet architecture, even with randomly set weights, provides useful structured vector embeddings of events. Pre-training this architecture on a simple physics-motivated binary classification task further improves the embedding quality. Using data from the GAseous Detector with GErmanium Tagging (GADGET) II TPC, a detector optimized for measuring low-energy $β$-delayed particle decays, we represent raw pad-level signals as sparse tensors, train Minkowski Engine ResNet models, and probe the resulting event-level embeddings which reveal rich event structure. As a cross-detector test, we embed data from the Active-Target TPC (AT-TPC) -- a detector designed for nuclear reaction studies in inverse kinematics -- using the same encoder. We find that even an untrained sparse ResNet model provides useful embeddings of AT-TPC data, and we observe improvements when the model is trained on GADGET data. Together, these results highlight the potential of sparse convolutional techniques as a general tool for representation learning in diverse TPC experiments.

</details>


### [53] [Neural Network-Powered Finger-Drawn Biometric Authentication](https://arxiv.org/abs/2511.11235)
*Maan Al Balkhi,Kordian Gontarska,Marko Harasic,Adrian Paschke*

Main category: cs.LG

TL;DR: 基于神经网络的手指绘制数字生物认证研究，在触摸屏设备上使用CNN和自编码器架构进行用户认证，取得了约89%的认证准确率。


<details>
  <summary>Details</summary>
Motivation: 探索在触摸屏设备上使用简单手指绘制数字（0-9）作为生物特征进行用户认证的可行性，提供一种安全且用户友好的认证解决方案。

Method: 使用20名参与者在个人触摸屏设备上绘制的2000个手指数字样本，比较了改进的Inception-V1网络、轻量级浅层CNN以及卷积和全连接自编码器架构。

Result: 两种CNN架构均达到约89%的认证准确率，浅层CNN参数更少；自编码器方法达到约75%的准确率。

Conclusion: 手指绘制符号认证为触摸屏设备提供了一种可行、安全且用户友好的生物认证解决方案，可与现有基于模式的认证方法集成构建多层安全系统。

Abstract: This paper investigates neural network-based biometric authentication using finger-drawn digits on touchscreen devices. We evaluated CNN and autoencoder architectures for user authentication through simple digit patterns (0-9) traced with finger input. Twenty participants contributed 2,000 finger-drawn digits each on personal touchscreen devices. We compared two CNN architectures: a modified Inception-V1 network and a lightweight shallow CNN for mobile environments. Additionally, we examined Convolutional and Fully Connected autoencoders for anomaly detection. Both CNN architectures achieved ~89% authentication accuracy, with the shallow CNN requiring fewer parameters. Autoencoder approaches achieved ~75% accuracy. The results demonstrate that finger-drawn symbol authentication provides a viable, secure, and user-friendly biometric solution for touchscreen devices. This approach can be integrated with existing pattern-based authentication methods to create multi-layered security systems for mobile applications.

</details>


### [54] [Virtual Width Networks](https://arxiv.org/abs/2511.11238)
*Seed,Baisheng Li,Banggu Wu,Bole Ma,Bowen Xiao,Chaoyi Zhang,Cheng Li,Chengyi Wang,Chenyin Xu,Chi Zhang,Chong Hu,Daoguang Zan,Defa Zhu,Dongyu Xu,Du Li,Faming Wu,Fan Xia,Ge Zhang,Guang Shi,Haobin Chen,Hongyu Zhu,Hongzhi Huang,Huan Zhou,Huanzhang Dou,Jianhui Duan,Jianqiao Lu,Jianyu Jiang,Jiayi Xu,Jiecao Chen,Jin Chen,Jin Ma,Jing Su,Jingji Chen,Jun Wang,Jun Yuan,Juncai Liu,Jundong Zhou,Kai Hua,Kai Shen,Kai Xiang,Kaiyuan Chen,Kang Liu,Ke Shen,Liang Xiang,Lin Yan,Lishu Luo,Mengyao Zhang,Ming Ding,Mofan Zhang,Nianning Liang,Peng Li,Penghao Huang,Pengpeng Mu,Qi Huang,Qianli Ma,Qiyang Min,Qiying Yu,Renming Pang,Ru Zhang,Shen Yan,Shen Yan,Shixiong Zhao,Shuaishuai Cao,Shuang Wu,Siyan Chen,Siyu Li,Siyuan Qiao,Tao Sun,Tian Xin,Tiantian Fan,Ting Huang,Ting-Han Fan,Wei Jia,Wenqiang Zhang,Wenxuan Liu,Xiangzhong Wu,Xiaochen Zuo,Xiaoying Jia,Ximing Yang,Xin Liu,Xin Yu,Xingyan Bin,Xintong Hao,Xiongcai Luo,Xujing Li,Xun Zhou,Yanghua Peng,Yangrui Chen,Yi Lin,Yichong Leng,Yinghao Li,Yingshuan Song,Yiyuan Ma,Yong Shan,Yongan Xiang,Yonghui Wu,Yongtao Zhang,Yongzhen Yao,Yu Bao,Yuehang Yang,Yufeng Yuan,Yunshui Li,Yuqiao Xian,Yutao Zeng,Yuxuan Wang,Zehua Hong,Zehua Wang,Zengzhi Wang,Zeyu Yang,Zhengqiang Yin,Zhenyi Lu,Zhexi Zhang,Zhi Chen,Zhi Zhang,Zhiqi Lin,Zihao Huang,Zilin Xu,Ziyun Wei,Zuo Wang*

Main category: cs.LG

TL;DR: Virtual Width Networks (VWN) 通过解耦表示宽度和主干网络宽度，在不增加计算成本的情况下扩展嵌入空间，显著加速优化过程。


<details>
  <summary>Details</summary>
Motivation: 传统方法通过增加隐藏层大小来获得更宽的表示，但这会导致二次计算成本增长。VWN旨在获得宽表示的好处而不承担高昂的计算代价。

Method: VWN框架将表示宽度与主干网络宽度解耦，在保持主干计算几乎不变的情况下扩展嵌入空间。

Result: 8倍扩展使下一个token预测优化加速超过2倍，下两个token预测加速3倍。随着训练进行，损失差距增大且收敛加速比增加，虚拟宽度与损失减少之间存在近似对数线性缩放关系。

Conclusion: VWN不仅token高效，而且随着规模增大效果更显著，虚拟宽度缩放可作为大模型效率的新维度进行探索。

Abstract: We introduce Virtual Width Networks (VWN), a framework that delivers the benefits of wider representations without incurring the quadratic cost of increasing the hidden size. VWN decouples representational width from backbone width, expanding the embedding space while keeping backbone compute nearly constant. In our large-scale experiment, an 8-times expansion accelerates optimization by over 2 times for next-token and 3 times for next-2-token prediction. The advantage amplifies over training as both the loss gap grows and the convergence-speedup ratio increases, showing that VWN is not only token-efficient but also increasingly effective with scale. Moreover, we identify an approximately log-linear scaling relation between virtual width and loss reduction, offering an initial empirical basis and motivation for exploring virtual-width scaling as a new dimension of large-model efficiency.

</details>


### [55] [HealSplit: Towards Self-Healing through Adversarial Distillation in Split Federated Learning](https://arxiv.org/abs/2511.11240)
*Yuhan Xie,Chen Lyu*

Main category: cs.LG

TL;DR: HealSplit是首个专为Split Federated Learning设计的统一防御框架，提供端到端的检测和恢复功能，能有效抵御五种复杂的投毒攻击。


<details>
  <summary>Details</summary>
Motivation: Split Federated Learning虽然是一种新兴的隐私保护分布式学习范式，但仍然容易受到针对本地特征、标签、粉碎数据和模型权重的复杂数据投毒攻击。现有的防御方法主要从传统联邦学习改编而来，在SFL中效果较差，因为无法完全访问模型更新。

Method: HealSplit包含三个关键组件：1）基于拓扑感知的检测模块，通过构建粉碎数据图并使用拓扑异常评分来识别投毒样本；2）生成式恢复管道，为检测到的异常合成语义一致的替代品，并通过一致性验证学生进行验证；3）对抗性多教师蒸馏框架，使用来自普通教师的语义监督和来自异常影响去偏教师的异常感知信号来训练学生，并通过拓扑和基于梯度的交互矩阵之间的对齐来指导。

Result: 在四个基准数据集上的广泛实验表明，HealSplit始终优于十种最先进的防御方法，在各种攻击场景下实现了卓越的鲁棒性和防御效果。

Conclusion: HealSplit是首个专门为Split Federated Learning设计的统一防御框架，能够有效检测和恢复多种复杂的投毒攻击，显著提升了SFL系统的安全性和鲁棒性。

Abstract: Split Federated Learning (SFL) is an emerging paradigm for privacy-preserving distributed learning. However, it remains vulnerable to sophisticated data poisoning attacks targeting local features, labels, smashed data, and model weights. Existing defenses, primarily adapted from traditional Federated Learning (FL), are less effective under SFL due to limited access to complete model updates. This paper presents HealSplit, the first unified defense framework tailored for SFL, offering end-to-end detection and recovery against five sophisticated types of poisoning attacks. HealSplit comprises three key components: (1) a topology-aware detection module that constructs graphs over smashed data to identify poisoned samples via topological anomaly scoring (TAS); (2) a generative recovery pipeline that synthesizes semantically consistent substitutes for detected anomalies, validated by a consistency validation student; and (3) an adversarial multi-teacher distillation framework trains the student using semantic supervision from a Vanilla Teacher and anomaly-aware signals from an Anomaly-Influence Debiasing (AD) Teacher, guided by the alignment between topological and gradient-based interaction matrices. Extensive experiments on four benchmark datasets demonstrate that HealSplit consistently outperforms ten state-of-the-art defenses, achieving superior robustness and defense effectiveness across diverse attack scenarios.

</details>


### [56] [Heterogeneous Attributed Graph Learning via Neighborhood-Aware Star Kernels](https://arxiv.org/abs/2511.11245)
*Hong Huang,Chengyu Yao,Haiming Chen,Hang Gao*

Main category: cs.LG

TL;DR: 提出了NASK（邻域感知星形核），一种用于属性图学习的新型图核方法，通过Gower相似度系数和Weisfeiler-Lehman迭代来同时捕获异构属性语义和多尺度邻域结构信息。


<details>
  <summary>Details</summary>
Motivation: 现有图核方法难以同时捕获属性图中的异构属性语义和邻域信息，而属性图在社交网络、生物信息学等领域广泛存在。

Method: 使用Gower相似度系数的指数变换来联合建模数值和分类特征，并通过Weisfeiler-Lehman迭代增强的星形子结构来整合多尺度邻域结构信息。

Result: 在11个属性图和4个大规模真实图基准上的实验表明，NASK在16个最先进基线（包括9个图核和7个图神经网络）中始终取得优越性能。

Conclusion: NASK是一种正定图核，能够有效处理属性图的异构特征和结构信息，在多种基准测试中表现优于现有方法。

Abstract: Attributed graphs, typically characterized by irregular topologies and a mix of numerical and categorical attributes, are ubiquitous in diverse domains such as social networks, bioinformatics, and cheminformatics. While graph kernels provide a principled framework for measuring graph similarity, existing kernel methods often struggle to simultaneously capture heterogeneous attribute semantics and neighborhood information in attributed graphs. In this work, we propose the Neighborhood-Aware Star Kernel (NASK), a novel graph kernel designed for attributed graph learning. NASK leverages an exponential transformation of the Gower similarity coefficient to jointly model numerical and categorical features efficiently, and employs star substructures enhanced by Weisfeiler-Lehman iterations to integrate multi-scale neighborhood structural information. We theoretically prove that NASK is positive definite, ensuring compatibility with kernel-based learning frameworks such as SVMs. Extensive experiments are conducted on eleven attributed and four large-scale real-world graph benchmarks. The results demonstrate that NASK consistently achieves superior performance over sixteen state-of-the-art baselines, including nine graph kernels and seven Graph Neural Networks.

</details>


### [57] [Toward Scalable Early Cancer Detection: Evaluating EHR-Based Predictive Models Against Traditional Screening Criteria](https://arxiv.org/abs/2511.11293)
*Jiheum Park,Chao Pang,Tristan Y. Lee,Jeong Yun Yang,Jacob Berkowitz,Alexander Z. Wei,Nicholas Tatonetti*

Main category: cs.LG

TL;DR: 基于电子健康记录的预测模型在识别癌症高风险人群方面比传统风险因素（如年龄、吸烟史、基因突变等）效果更好，能实现3-6倍的真实癌症病例富集率提升。


<details>
  <summary>Details</summary>
Motivation: 当前癌症筛查指南仅覆盖少数癌症类型，且依赖年龄、吸烟史等狭窄定义的标准来识别高风险人群。基于电子健康记录的预测模型可能通过捕捉细微的癌症前诊断信号，提供更有效的风险识别工具。

Method: 使用All of Us研究项目中超过865,000名参与者的电子健康记录、基因组和调查数据，系统评估基于EHR的预测模型与传统风险因素在识别八种主要癌症高风险人群方面的临床效用。

Result: 即使使用基线建模方法，基于EHR的模型在识别为高风险的人群中，真实癌症病例的富集率比单独使用传统风险因素高出3-6倍。EHR基础模型进一步提高了26种癌症类型的预测性能。

Conclusion: 基于EHR的预测建模具有临床潜力，可以支持更精确和可扩展的早期检测策略。

Abstract: Current cancer screening guidelines cover only a few cancer types and rely on narrowly defined criteria such as age or a single risk factor like smoking history, to identify high-risk individuals. Predictive models using electronic health records (EHRs), which capture large-scale longitudinal patient-level health information, may provide a more effective tool for identifying high-risk groups by detecting subtle prediagnostic signals of cancer. Recent advances in large language and foundation models have further expanded this potential, yet evidence remains limited on how useful HER-based models are compared with traditional risk factors currently used in screening guidelines. We systematically evaluated the clinical utility of EHR-based predictive models against traditional risk factors, including gene mutations and family history of cancer, for identifying high-risk individuals across eight major cancers (breast, lung, colorectal, prostate, ovarian, liver, pancreatic, and stomach), using data from the All of Us Research Program, which integrates EHR, genomic, and survey data from over 865,000 participants. Even with a baseline modeling approach, EHR-based models achieved a 3- to 6-fold higher enrichment of true cancer cases among individuals identified as high risk compared with traditional risk factors alone, whether used as a standalone or complementary tool. The EHR foundation model, a state-of-the-art approach trained on comprehensive patient trajectories, further improved predictive performance across 26 cancer types, demonstrating the clinical potential of EHR-based predictive modeling to support more precise and scalable early detection strategies.

</details>


### [58] [Fast and Expressive Multi-Token Prediction with Probabilistic Circuits](https://arxiv.org/abs/2511.11346)
*Andreas Grivas,Lorenzo Loconte,Emile van Krieken,Piotr Nawrot,Yu Zhao,Euan Wielewski,Pasquale Minervini,Edoardo Ponti,Antonio Vergari*

Main category: cs.LG

TL;DR: MTPC框架通过概率电路探索多令牌预测中表达能力与延迟的权衡，显著加速字节级LLM生成，同时保持原始验证器性能。


<details>
  <summary>Details</summary>
Motivation: 现有MTP方法在加速LLM生成时往往牺牲表达能力，假设未来令牌独立。本研究旨在探索表达能力与延迟之间的最佳权衡。

Method: 提出MTPC框架，使用概率电路编码未来令牌的联合分布，支持混合模型、隐马尔可夫模型和张量网络等架构，并与推测解码结合。

Result: 实验显示MTPC相比独立假设的MTP显著加速生成，同时保证原始验证器LLM性能不变，并系统研究了表达能力与延迟的权衡。

Conclusion: MTPC框架有效平衡了多令牌预测的表达能力与延迟，为字节级LLM的加速生成提供了灵活且性能保证的解决方案。

Abstract: Multi-token prediction (MTP) is a prominent strategy to significantly speed up generation in large language models (LLMs), including byte-level LLMs, which are tokeniser-free but prohibitively slow. However, existing MTP methods often sacrifice expressiveness by assuming independence between future tokens. In this work, we investigate the trade-off between expressiveness and latency in MTP within the framework of probabilistic circuits (PCs). Our framework, named MTPC, allows one to explore different ways to encode the joint distributions over future tokens by selecting different circuit architectures, generalising classical models such as (hierarchical) mixture models, hidden Markov models and tensor networks. We show the efficacy of MTPC by retrofitting existing byte-level LLMs, such as EvaByte. Our experiments show that, when combined with speculative decoding, MTPC significantly speeds up generation compared to MTP with independence assumptions, while guaranteeing to retain the performance of the original verifier LLM. We also rigorously study the optimal trade-off between expressiveness and latency when exploring the possible parameterisations of MTPC, such as PC architectures and partial layer sharing between the verifier and draft LLMs.

</details>


### [59] [Toward Multi-Fidelity Machine Learning Force Field for Cathode Materials](https://arxiv.org/abs/2511.11361)
*Guangyi Dong,Zhihui Wang*

Main category: cs.LG

TL;DR: 开发了一个多保真度机器学习力场框架，可同时利用阴极材料的低保真度非磁性和高保真度磁性计算数据集进行训练，在LMFP阴极材料系统中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 锂离子电池阴极材料的机器学习力场开发和应用相对有限，主要由于其复杂的电子结构特性和高质量计算数据集的稀缺。

Method: 开发了多保真度机器学习力场框架，能够同时利用低保真度非磁性和高保真度磁性计算数据集进行训练。

Result: 在锂锰铁磷酸盐(LMFP)阴极材料系统上的测试证明了这种多保真度方法的有效性。

Conclusion: 这项研究有助于以较低的训练数据集成本实现阴极材料的高精度机器学习力场训练，并为机器学习力场在阴极材料计算模拟中的应用提供了新视角。

Abstract: Machine learning force fields (MLFFs), which employ neural networks to map atomic structures to system energies, effectively combine the high accuracy of first-principles calculation with the computational efficiency of empirical force fields. They are widely used in computational materials simulations. However, the development and application of MLFFs for lithium-ion battery cathode materials remain relatively limited. This is primarily due to the complex electronic structure characteristics of cathode materials and the resulting scarcity of high-quality computational datasets available for force field training. In this work, we develop a multi-fidelity machine learning force field framework to enhance the data efficiency of computational results, which can simultaneously utilize both low-fidelity non-magnetic and high-fidelity magnetic computational datasets of cathode materials for training. Tests conducted on the lithium manganese iron phosphate (LMFP) cathode material system demonstrate the effectiveness of this multi-fidelity approach. This work helps to achieve high-accuracy MLFF training for cathode materials at a lower training dataset cost, and offers new perspectives for applying MLFFs to computational simulations of cathode materials.

</details>


### [60] [On-Device Fine-Tuning via Backprop-Free Zeroth-Order Optimization](https://arxiv.org/abs/2511.11362)
*Prabodh Katti,Sangwoo Park,Bipin Rajendran,Osvaldo Simeone*

Main category: cs.LG

TL;DR: MeZO（内存高效零阶优化）通过仅使用前向评估估计梯度，消除了存储中间激活和优化器状态的需求，使边缘设备能够在内存限制下微调更大的模型，但需要更长的训练时间。


<details>
  <summary>Details</summary>
Motivation: 边缘AI系统需要在严格内存约束下适应不同任务，传统基于反向传播的训练需要存储层激活和优化器状态，严重限制了可部署模型的最大规模。

Method: 使用MeZO（内存高效零阶优化）方法，仅通过前向评估估计梯度，无需存储中间激活或优化器状态。

Result: 理论分析和数值验证表明，在设备内存约束下，MeZO能够容纳更大的模型规模，并在提供足够训练时间时展现出精度优势。

Conclusion: MeZO为边缘设备上的模型微调提供了可行的解决方案，在内存受限环境下能够支持更大模型的部署，但需要权衡训练时间成本。

Abstract: On-device fine-tuning is a critical capability for edge AI systems, which must support adaptation to different agentic tasks under stringent memory constraints. Conventional backpropagation (BP)-based training requires storing layer activations and optimizer states, a demand that can be only partially alleviated through checkpointing. In edge deployments in which the model weights must reside entirely in device memory, this overhead severely limits the maximum model size that can be deployed. Memory-efficient zeroth-order optimization (MeZO) alleviates this bottleneck by estimating gradients using forward evaluations alone, eliminating the need for storing intermediate activations or optimizer states. This enables significantly larger models to fit within on-chip memory, albeit at the cost of potentially longer fine-tuning wall-clock time. This paper first provides a theoretical estimate of the relative model sizes that can be accommodated under BP and MeZO training. We then numerically validate the analysis, demonstrating that MeZO exhibits accuracy advantages under on-device memory constraints, provided sufficient wall-clock time is available for fine-tuning.

</details>


### [61] [When Genes Speak: A Semantic-Guided Framework for Spatially Resolved Transcriptomics Data Clustering](https://arxiv.org/abs/2511.11380)
*Jiangkai Long,Yanran Zhu,Chang Tang,Kun Sun,Yuanyuan Liu,Xuesong Yan*

Main category: cs.LG

TL;DR: SemST是一个语义引导的空间转录组学数据聚类框架，利用大语言模型将基因符号转化为生物语义嵌入，并与图神经网络捕获的空间关系融合，通过细粒度语义调制模块实现生物功能与空间结构的整合。


<details>
  <summary>Details</summary>
Motivation: 现有计算模型将基因视为孤立的数值特征，忽略了基因符号中编码的丰富生物语义，这阻碍了对关键生物学特征的深入理解。

Method: 使用大语言模型将每个组织位点的基因集转化为生物语义嵌入，与图神经网络捕获的空间邻域关系融合，并引入细粒度语义调制模块进行特征校准。

Result: 在公共空间转录组学数据集上的广泛实验表明，SemST实现了最先进的聚类性能，且细粒度语义调制模块具有即插即用的通用性。

Conclusion: SemST通过整合基因符号的生物语义和空间结构，显著提升了空间转录组学数据的聚类性能，为理解组织微环境提供了新的视角。

Abstract: Spatial transcriptomics enables gene expression profiling with spatial context, offering unprecedented insights into the tissue microenvironment. However, most computational models treat genes as isolated numerical features, ignoring the rich biological semantics encoded in their symbols. This prevents a truly deep understanding of critical biological characteristics. To overcome this limitation, we present SemST, a semantic-guided deep learning framework for spatial transcriptomics data clustering. SemST leverages Large Language Models (LLMs) to enable genes to "speak" through their symbolic meanings, transforming gene sets within each tissue spot into biologically informed embeddings. These embeddings are then fused with the spatial neighborhood relationships captured by Graph Neural Networks (GNNs), achieving a coherent integration of biological function and spatial structure. We further introduce the Fine-grained Semantic Modulation (FSM) module to optimally exploit these biological priors. The FSM module learns spot-specific affine transformations that empower the semantic embeddings to perform an element-wise calibration of the spatial features, thus dynamically injecting high-order biological knowledge into the spatial context. Extensive experiments on public spatial transcriptomics datasets show that SemST achieves state-of-the-art clustering performance. Crucially, the FSM module exhibits plug-and-play versatility, consistently improving the performance when integrated into other baseline methods.

</details>


### [62] [Robust inverse material design with physical guarantees using the Voigt-Reuss Net](https://arxiv.org/abs/2511.11388)
*Sanath Keshav,Felix Fritzen*

Main category: cs.LG

TL;DR: 提出了一种具有严格物理保证的谱归一化代理模型，用于机械均质化的正问题和反问题求解。该方法基于Voigt-Reuss界限，通过Cholesky类算子学习特征值在[0,1]范围内的对称半正定表示，确保预测结果在Löwner意义下位于界限之间。


<details>
  <summary>Details</summary>
Motivation: 解决机械均质化中物理约束的保持问题，确保预测结果满足物理定律和材料对称性要求，同时实现高精度的正反问题求解。

Method: 利用Voigt-Reuss界限的差异，通过Cholesky类算子分解，学习维度无关的对称半正定表示。结合谱归一化和可微分渲染器，使用CNN处理2D平面应变问题。

Result: 在3D线性弹性中，对随机双相微观结构实现了近乎完美的各向同性投影保真度（R²≥0.998），张量级相对Frobenius误差中位数约为1.7%。在2D平面应变中，所有分量的R²>0.99，能够准确跟踪渗流引起的特征值跳跃。

Conclusion: Voigt-Reuss网络统一了准确、物理可接受的正向预测与大规模、约束一致的逆向设计，适用于椭圆算子和耦合物理场景。

Abstract: We propose a spectrally normalized surrogate for forward and inverse mechanical homogenization with hard physical guarantees. Leveraging the Voigt-Reuss bounds, we factor their difference via a Cholesky-like operator and learn a dimensionless, symmetric positive semi-definite representation with eigenvalues in $[0,1]$; the inverse map returns symmetric positive-definite predictions that lie between the bounds in the Löwner sense. In 3D linear elasticity on an open dataset of stochastic biphasic microstructures, a fully connected Voigt-Reuss net trained on $>\!7.5\times 10^{5}$ FFT-based labels with 236 isotropy-invariant descriptors and three contrast parameters recovers the isotropic projection with near-perfect fidelity (isotropy-related entries: $R^2 \ge 0.998$), while anisotropy-revealing couplings are unidentifiable from $SO(3)$-invariant inputs. Tensor-level relative Frobenius errors have median $\approx 1.7\%$ and mean $\approx 3.4\%$ across splits. For 2D plane strain on thresholded trigonometric microstructures, coupling spectral normalization with a differentiable renderer and a CNN yields $R^2>0.99$ on all components, subpercent normalized losses, accurate tracking of percolation-induced eigenvalue jumps, and robust generalization to out-of-distribution images. Treating the parametric microstructure as design variables, batched first-order optimization with a single surrogate matches target tensors within a few percent and returns diverse near-optimal designs. Overall, the Voigt-Reuss net unifies accurate, physically admissible forward prediction with large-batch, constraint-consistent inverse design, and is generic to elliptic operators and coupled-physics settings.

</details>


### [63] [SPOT: Single-Shot Positioning via Trainable Near-Field Rainbow Beamforming](https://arxiv.org/abs/2511.11391)
*Yeyue Cai,Jianhua Mo,Meixia Tao*

Main category: cs.LG

TL;DR: 提出一种基于深度学习的端到端方案，同时设计彩虹波束并估计用户位置，通过将移相器和真时延系数作为可训练变量来优化定位精度，大幅降低开销并提升二维定位性能。


<details>
  <summary>Details</summary>
Motivation: 相位时间阵列结合移相器和真时延器是一种经济高效的架构，可用于宽带感知和定位中生成频率相关的彩虹波束，但现有方法在定位精度和开销方面存在局限。

Method: 将移相器和真时延系数作为可训练变量，设计任务导向的波束以最大化定位精度；使用轻量级全连接模块从用户反馈的最大量化接收功率及其对应子载波索引中恢复用户的角距坐标。

Result: 与现有解析和学习方案相比，该方法将开销降低一个数量级，并始终提供更低的二维定位误差。

Conclusion: 所提出的端到端深度学习方案能够有效设计彩虹波束并实现高精度用户定位，在降低开销的同时显著提升定位性能。

Abstract: Phase-time arrays, which integrate phase shifters (PSs) and true-time delays (TTDs), have emerged as a cost-effective architecture for generating frequency-dependent rainbow beams in wideband sensing and localization. This paper proposes an end-to-end deep learning-based scheme that simultaneously designs the rainbow beams and estimates user positions. Treating the PS and TTD coefficients as trainable variables allows the network to synthesize task-oriented beams that maximize localization accuracy. A lightweight fully connected module then recovers the user's angle-range coordinates from its feedback of the maximum quantized received power and its corresponding subcarrier index after a single downlink transmission. Compared with existing analytical and learning-based schemes, the proposed method reduces overhead by an order of magnitude and delivers consistently lower two-dimensional positioning error.

</details>


### [64] [Multi-Phase Spacecraft Trajectory Optimization via Transformer-Based Reinforcement Learning](https://arxiv.org/abs/2511.11402)
*Amit Jain,Victor Rodriguez-Fernandez,Richard Linares*

Main category: cs.LG

TL;DR: 本文提出了一个基于Transformer的强化学习框架，用于统一多阶段航天器轨迹优化，通过单一策略架构处理动态不同的任务阶段，消除了手动阶段转换的需求。


<details>
  <summary>Details</summary>
Motivation: 现有航天器控制方法通常需要为不同任务阶段（如发射、上升、级间分离、轨道插入）分别设计策略，这限制了适应性并增加了操作复杂性。需要能够跨动态不同阶段泛化的自适应策略。

Method: 基于近端策略优化(PPO)，用Transformer编码器-解码器结构替代传统循环网络，集成门控Transformer-XL(GTrXL)架构，使智能体能够在关键操作期间维持跨秒到分钟时间尺度的连贯记忆。

Result: 框架在单阶段基准测试（双积分器和Van der Pol振荡器）中表现出接近最优性能，在多阶段航点导航变体中有效扩展，并在复杂的多阶段火箭上升问题中成功学习连贯控制策略。

Conclusion: Transformer框架不仅能在简单情况下匹配解析解，还能在动态不同的机制中有效学习连贯控制策略，为可扩展的自主任务规划奠定了基础，同时保持与安全关键验证协议的兼容性。

Abstract: Autonomous spacecraft control for mission phases such as launch, ascent, stage separation, and orbit insertion remains a critical challenge due to the need for adaptive policies that generalize across dynamically distinct regimes. While reinforcement learning (RL) has shown promise in individual astrodynamics tasks, existing approaches often require separate policies for distinct mission phases, limiting adaptability and increasing operational complexity. This work introduces a transformer-based RL framework that unifies multi-phase trajectory optimization through a single policy architecture, leveraging the transformer's inherent capacity to model extended temporal contexts. Building on proximal policy optimization (PPO), our framework replaces conventional recurrent networks with a transformer encoder-decoder structure, enabling the agent to maintain coherent memory across mission phases spanning seconds to minutes during critical operations. By integrating a Gated Transformer-XL (GTrXL) architecture, the framework eliminates manual phase transitions while maintaining stability in control decisions. We validate our approach progressively: first demonstrating near-optimal performance on single-phase benchmarks (double integrator and Van der Pol oscillator), then extending to multiphase waypoint navigation variants, and finally tackling a complex multiphase rocket ascent problem that includes atmospheric flight, stage separation, and vacuum operations. Results demonstrate that the transformer-based framework not only matches analytical solutions in simple cases but also effectively learns coherent control policies across dynamically distinct regimes, establishing a foundation for scalable autonomous mission planning that reduces reliance on phase-specific controllers while maintaining compatibility with safety-critical verification protocols.

</details>


### [65] [Multicalibration yields better matchings](https://arxiv.org/abs/2511.11413)
*Riccardo Colini Baldeschi,Simone Di Gregorio,Simone Fioravanti,Federico Fusco,Ido Guy,Daniel Haimovich,Stefano Leonardi,Fridolin Linder,Lorenzo Perini,Matteo Russo,Niek Tax*

Main category: cs.LG

TL;DR: 该论文提出使用多校准方法来改进加权图中最佳匹配问题的决策，通过构建多校准预测器来补偿不完美预测器带来的误差，使其在特定算法类中具有竞争力。


<details>
  <summary>Details</summary>
Motivation: 在加权图中寻找最佳匹配时，通常只能获得基于上下文的权重预测。如果预测器是贝叶斯最优的，那么基于预测权重计算最佳匹配是最优的。但在实践中，预测器往往不完美，需要设计能够补偿预测误差的决策规则。

Method: 提出使用多校准方法，要求预测器在受保护上下文集合的每个元素上都是无偏的。给定匹配算法类C和任意边权重预测器γ，构建特定的多校准预测器γ̂，使得基于γ̂输出的最佳匹配与在原始预测器γ上应用C中最佳决策规则具有竞争力。

Result: 证明了基于多校准预测器γ̂的最佳匹配决策在算法类C中具有竞争力，并提供了样本复杂度界限。

Conclusion: 多校准方法能够有效解决不完美预测器带来的问题，通过构建多校准预测器可以提升决策质量，使其与在原始预测器上应用最佳决策规则相竞争。

Abstract: Consider the problem of finding the best matching in a weighted graph where we only have access to predictions of the actual stochastic weights, based on an underlying context. If the predictor is the Bayes optimal one, then computing the best matching based on the predicted weights is optimal. However, in practice, this perfect information scenario is not realistic. Given an imperfect predictor, a suboptimal decision rule may compensate for the induced error and thus outperform the standard optimal rule.
  In this paper, we propose multicalibration as a way to address this problem. This fairness notion requires a predictor to be unbiased on each element of a family of protected sets of contexts. Given a class of matching algorithms $\mathcal C$ and any predictor $γ$ of the edge-weights, we show how to construct a specific multicalibrated predictor $\hat γ$, with the following property. Picking the best matching based on the output of $\hat γ$ is competitive with the best decision rule in $\mathcal C$ applied onto the original predictor $γ$. We complement this result by providing sample complexity bounds.

</details>


### [66] [Low-Bit, High-Fidelity: Optimal Transport Quantization for Flow Matching](https://arxiv.org/abs/2511.11418)
*Dara Varam,Diaa A. Abuhani,Imran Zualkernan,Raghad AlDamani,Lujain Khalil*

Main category: cs.LG

TL;DR: 本文提出了一种基于最优传输(OT)的流匹配(FM)生成模型后训练量化方法，能够在2-3比特/参数下保持生成质量，优于传统量化方法。


<details>
  <summary>Details</summary>
Motivation: 流匹配生成模型虽然具有高效的无模拟训练和确定性采样优势，但其实际部署受到高精度参数需求的挑战，需要有效的压缩方法。

Method: 采用基于最优传输的后训练量化方法，最小化量化权重与原始权重之间的2-Wasserstein距离，并与均匀、分段和对数量化方案进行系统比较。

Result: 在五个不同复杂度的基准数据集上的实验表明，OT量化在2-3比特/参数下仍能保持视觉生成质量和潜在空间稳定性，而其他方法在此比特率下失效。

Conclusion: 基于OT的量化是一种有原则且有效的方法，可用于压缩FM生成模型以适用于边缘和嵌入式AI应用。

Abstract: Flow Matching (FM) generative models offer efficient simulation-free training and deterministic sampling, but their practical deployment is challenged by high-precision parameter requirements. We adapt optimal transport (OT)-based post-training quantization to FM models, minimizing the 2-Wasserstein distance between quantized and original weights, and systematically compare its effectiveness against uniform, piecewise, and logarithmic quantization schemes. Our theoretical analysis provides upper bounds on generative degradation under quantization, and empirical results across five benchmark datasets of varying complexity show that OT-based quantization preserves both visual generation quality and latent space stability down to 2-3 bits per parameter, where alternative methods fail. This establishes OT-based quantization as a principled, effective approach to compress FM generative models for edge and embedded AI applications.

</details>


### [67] [Retrofit: Continual Learning with Bounded Forgetting for Security Applications](https://arxiv.org/abs/2511.11439)
*Yiling He,Junchi Lei,Hongyu She,Shuo Shao,Xinran Zheng,Yiping Liu,Zhan Qin,Lorenzo Cavallaro*

Main category: cs.LG

TL;DR: RETROFIT是一种无需历史数据的持续学习方法，通过参数级模型合并和低秩稀疏更新来缓解灾难性遗忘，在恶意软件检测和二进制摘要任务中显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有持续学习方法依赖完整重训练或数据回放，在数据敏感的安全场景中不可行，且面临知识迁移的双重挑战：无需旧数据保留先验知识和最小干扰集成新知识。

Method: 通过合并先前训练和新微调模型作为新旧知识教师，采用参数级合并避免历史数据需求；使用低秩稀疏更新将参数变化限制在独立子空间；通过模型置信度指导的知识仲裁动态平衡教师贡献。

Result: 在时序漂移的恶意软件检测中，保留分数从基线20.2%提升至38.6%，超过新数据上的oracle上界；在二进制摘要任务中，BLEU分数达到先前工作中迁移学习的两倍，在跨表示泛化中超越所有基线。

Conclusion: RETROFIT在无需历史数据的情况下有效缓解遗忘并保持适应性，为安全分析中的持续学习提供了可行解决方案。

Abstract: Modern security analytics are increasingly powered by deep learning models, but their performance often degrades as threat landscapes evolve and data representations shift. While continual learning (CL) offers a promising paradigm to maintain model effectiveness, many approaches rely on full retraining or data replay, which are infeasible in data-sensitive environments. Moreover, existing methods remain inadequate for security-critical scenarios, facing two coupled challenges in knowledge transfer: preserving prior knowledge without old data and integrating new knowledge with minimal interference.
  We propose RETROFIT, a data retrospective-free continual learning method that achieves bounded forgetting for effective knowledge transfer. Our key idea is to consolidate previously trained and newly fine-tuned models, serving as teachers of old and new knowledge, through parameter-level merging that eliminates the need for historical data. To mitigate interference, we apply low-rank and sparse updates that confine parameter changes to independent subspaces, while a knowledge arbitration dynamically balances the teacher contributions guided by model confidence. Our evaluation on two representative applications demonstrates that RETROFIT consistently mitigates forgetting while maintaining adaptability. In malware detection under temporal drift, it substantially improves the retention score, from 20.2% to 38.6% over CL baselines, and exceeds the oracle upper bound on new data. In binary summarization across decompilation levels, where analyzing stripped binaries is especially challenging, RETROFIT achieves around twice the BLEU score of transfer learning used in prior work and surpasses all baselines in cross-representation generalization.

</details>


### [68] [DiffPro: Joint Timestep and Layer-Wise Precision Optimization for Efficient Diffusion Inference](https://arxiv.org/abs/2511.11446)
*Farhana Amin,Sabiha Afroz,Kanchon Gharami,Mona Moghadampanah,Dimitrios S. Nikolopoulos*

Main category: cs.LG

TL;DR: DiffPro是一个后训练框架，通过联合优化时间步长和逐层精度来加速扩散模型推理，无需重新训练即可实现6.25倍模型压缩、50%时间步减少和2.8倍推理加速。


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽然能生成高质量图像，但由于需要大量去噪步骤和繁重的矩阵运算，推理成本高昂。需要一种无需训练的方法来减少延迟和内存使用。

Method: 结合三个组件：基于流形感知的敏感度指标分配权重位数、动态激活量化稳定跨时间步的激活、基于师生漂移的预算化时间步选择器。

Result: 在标准基准测试中实现高达6.25倍模型压缩、50%时间步减少和2.8倍推理加速，Delta FID <= 10。

Conclusion: DiffPro将步骤减少和精度规划统一为单一预算化部署计划，为实时节能扩散推理提供了实用效率提升。

Abstract: Diffusion models produce high quality images but inference is costly due to many denoising steps and heavy matrix operations. We present DiffPro, a post-training, hardware-faithful framework that works with the exact integer kernels used in deployment and jointly tunes timesteps and per-layer precision in Diffusion Transformers (DiTs) to reduce latency and memory without any training. DiffPro combines three parts: a manifold-aware sensitivity metric to allocate weight bits, dynamic activation quantization to stabilize activations across timesteps, and a budgeted timestep selector guided by teacher-student drift. In experiments DiffPro achieves up to 6.25x model compression, fifty percent fewer timesteps, and 2.8x faster inference with Delta FID <= 10 on standard benchmarks, demonstrating practical efficiency gains. DiffPro unifies step reduction and precision planning into a single budgeted deployable plan for real-time energy-aware diffusion inference.

</details>


### [69] [FairReweighing: Density Estimation-Based Reweighing Framework for Improving Separation in Fair Regression](https://arxiv.org/abs/2511.11459)
*Xiaoyin Xi,Zhe Yu*

Main category: cs.LG

TL;DR: 提出FairReweighing预处理算法，基于密度估计确保回归模型满足分离准则，在保持高准确性的同时提高公平性


<details>
  <summary>Details</summary>
Motivation: AI软件在关键领域应用广泛，但缺乏透明度引发公平性担忧。现有研究主要关注二元分类任务，回归中的公平性研究相对不足

Method: 采用互信息度量评估分离违规，基于分类中的Reweighing算法提出FairReweighing预处理算法，通过密度估计确保模型满足分离准则

Result: 理论上证明在数据独立性假设下能保证训练数据的分离；实证显示在合成和真实数据上优于现有回归公平性解决方案

Conclusion: FairReweighing算法能有效提高回归模型的公平性，同时保持高准确性，为回归公平性提供了有效的预处理解决方案

Abstract: There has been a prevalence of applying AI software in both high-stakes public-sector and industrial contexts. However, the lack of transparency has raised concerns about whether these data-informed AI software decisions secure fairness against people of all racial, gender, or age groups. Despite extensive research on emerging fairness-aware AI software, up to now most efforts to solve this issue have been dedicated to binary classification tasks. Fairness in regression is relatively underexplored. In this work, we adopted a mutual information-based metric to assess separation violations. The metric is also extended so that it can be directly applied to both classification and regression problems with both binary and continuous sensitive attributes. Inspired by the Reweighing algorithm in fair classification, we proposed a FairReweighing pre-processing algorithm based on density estimation to ensure that the learned model satisfies the separation criterion. Theoretically, we show that the proposed FairReweighing algorithm can guarantee separation in the training data under a data independence assumption. Empirically, on both synthetic and real-world data, we show that FairReweighing outperforms existing state-of-the-art regression fairness solutions in terms of improving separation while maintaining high accuracy.

</details>


### [70] [Epistemic Error Decomposition for Multi-step Time Series Forecasting: Rethinking Bias-Variance in Recursive and Direct Strategies](https://arxiv.org/abs/2511.11461)
*Riku Green,Huw Day,Zahraa S. Abdallah,Telmo M. Silva Filho*

Main category: cs.LG

TL;DR: 重新审视多步预测中的递归和直接策略，通过误差分解分析发现：对于线性预测器，递归策略的结构性差距为零；对于非线性预测器，递归可以增加模型表达能力。递归策略的方差可表示为一步方差乘以基于雅可比矩阵的放大因子。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为递归策略具有高偏差低方差，直接策略具有低偏差高方差。本文旨在重新审视这一信念，通过数学分析揭示两种策略在不同条件下的真实表现。

Method: 将多步预测误差分解为不可约噪声、结构性近似差距和估计方差三部分。对于线性预测器进行理论分析，对于非线性预测器通过多层感知机在ETTm1数据集上进行实验验证。

Result: 实验证实：递归预测可能同时具有比直接预测更低的偏差和更高的方差。递归策略的方差放大取决于参数误差的敏感性。

Conclusion: 选择递归或直接策略应基于模型非线性和噪声特性，而非传统的偏差-方差直觉。非线性模型下递归可能提供更好的表达能力。

Abstract: Multi-step forecasting is often described through a simple rule of thumb: recursive strategies are said to have high bias and low variance, while direct strategies are said to have low bias and high variance. We revisit this belief by decomposing the expected multi-step forecast error into three parts: irreducible noise, a structural approximation gap, and an estimation-variance term. For linear predictors we show that the structural gap is identically zero for any dataset. For nonlinear predictors, however, the repeated composition used in recursion can increase model expressivity, making the structural gap depend on both the model and the data. We further show that the estimation variance of the recursive strategy at any horizon can be written as the one-step variance multiplied by a Jacobian-based amplification factor that measures how sensitive the composed predictor is to parameter error. This perspective explains when recursive forecasting may simultaneously have lower bias and higher variance than direct forecasting. Experiments with multilayer perceptrons on the ETTm1 dataset confirm these findings. The results offer practical guidance for choosing between recursive and direct strategies based on model nonlinearity and noise characteristics, rather than relying on traditional bias-variance intuition.

</details>


### [71] [MoCap2Radar: A Spatiotemporal Transformer for Synthesizing Micro-Doppler Radar Signatures from Motion Capture](https://arxiv.org/abs/2511.11462)
*Kevin Chen,Kenneth W. Parker,Anish Arora*

Main category: cs.LG

TL;DR: 提出了一种基于纯机器学习的方法，使用Transformer模型将运动捕捉数据合成雷达频谱图，实现了从MoCap到雷达频谱的序列到序列转换。


<details>
  <summary>Details</summary>
Motivation: 为了解决雷达数据稀缺问题，利用更丰富的运动捕捉数据来增强雷达数据集，同时减少基于物理方法生成雷达数据所需的计算量。

Method: 使用基于Transformer的模型，将MoCap到频谱图转换制定为窗口化序列到序列任务，联合捕捉MoCap标记之间的空间关系和跨帧的时间动态。

Result: 实验表明该方法能生成视觉和数量上合理的多普勒雷达频谱图，具有良好的泛化能力，模型能够将多部位运动转换为多普勒特征并理解人体不同部位的空间关系。

Conclusion: 这是使用Transformer进行时间序列信号处理的有趣示例，特别适用于边缘计算和物联网雷达，能够利用丰富的MoCap数据增强稀缺的雷达数据集，且计算量远小于基于物理的方法。

Abstract: We present a pure machine learning process for synthesizing radar spectrograms from Motion-Capture (MoCap) data. We formulate MoCap-to-spectrogram translation as a windowed sequence-to-sequence task using a transformer-based model that jointly captures spatial relations among MoCap markers and temporal dynamics across frames. Real-world experiments show that the proposed approach produces visually and quantitatively plausible doppler radar spectrograms and achieves good generalizability. Ablation experiments show that the learned model includes both the ability to convert multi-part motion into doppler signatures and an understanding of the spatial relations between different parts of the human body.
  The result is an interesting example of using transformers for time-series signal processing. It is especially applicable to edge computing and Internet of Things (IoT) radars. It also suggests the ability to augment scarce radar datasets using more abundant MoCap data for training higher-level applications. Finally, it requires far less computation than physics-based methods for generating radar data.

</details>


### [72] [Quantifying and Improving Adaptivity in Conformal Prediction through Input Transformations](https://arxiv.org/abs/2511.11472)
*Sooyong Jang,Insup Lee*

Main category: cs.LG

TL;DR: 提出了一种新的自适应预测集评估方法，通过输入变换排序示例难度并使用均匀质量分箱，解决了现有方法中分箱不平衡的问题。基于此提出了两个新指标来更准确评估自适应性能，并开发了新的自适应预测集算法。


<details>
  <summary>Details</summary>
Motivation: 现有自适应预测集评估方法存在分箱不平衡问题，导致覆盖率或集合大小估计不准确，需要更可靠的评估指标来准确衡量方法对示例难度的自适应能力。

Method: 1) 使用输入变换对示例按难度排序，然后进行均匀质量分箱；2) 基于平衡分箱提出两个新评估指标；3) 开发新的自适应预测集算法，按估计难度分组并应用组条件共形预测。

Result: 实验表明，新提出的指标与期望的自适应属性相关性更强。在ImageNet图像分类和医疗视觉敏锐度预测任务上，新方法在各项新指标上均优于现有方法。

Conclusion: 提出的分箱方法和评估指标能够更可靠地评估预测集的自适应性能，基于此开发的自适应预测集算法在实际任务中表现优异。

Abstract: Conformal prediction constructs a set of labels instead of a single point prediction, while providing a probabilistic coverage guarantee. Beyond the coverage guarantee, adaptiveness to example difficulty is an important property. It means that the method should produce larger prediction sets for more difficult examples, and smaller ones for easier examples. Existing evaluation methods for adaptiveness typically analyze coverage rate violation or average set size across bins of examples grouped by difficulty. However, these approaches often suffer from imbalanced binning, which can lead to inaccurate estimates of coverage or set size. To address this issue, we propose a binning method that leverages input transformations to sort examples by difficulty, followed by uniform-mass binning. Building on this binning, we introduce two metrics to better evaluate adaptiveness. These metrics provide more reliable estimates of coverage rate violation and average set size due to balanced binning, leading to more accurate adaptivity assessment. Through experiments, we demonstrate that our proposed metric correlates more strongly with the desired adaptiveness property compared to existing ones. Furthermore, motivated by our findings, we propose a new adaptive prediction set algorithm that groups examples by estimated difficulty and applies group-conditional conformal prediction. This allows us to determine appropriate thresholds for each group. Experimental results on both (a) an Image Classification (ImageNet) (b) a medical task (visual acuity prediction) show that our method outperforms existing approaches according to the new metrics.

</details>


### [73] [Data-efficient U-Net for Segmentation of Carbide Microstructures in SEM Images of Steel Alloys](https://arxiv.org/abs/2511.11485)
*Alinda Ezgi Gerçek,Till Korten,Paul Chekhonin,Maleeha Hassan,Peter Steinbach*

Main category: cs.LG

TL;DR: 提出了一种数据高效的分割流程，使用轻量级U-Net（30.7M参数）仅需10张标注的扫描电镜图像即可实现反应堆压力容器钢中碳化物的精确分割，Dice系数达0.98，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 反应堆压力容器钢的微观结构理解对预测机械性能至关重要，但扫描电镜图像中碳化物与基体的灰度重叠使得简单阈值分割无效，需要更有效的分割方法。

Method: 使用轻量级U-Net架构，仅需10张标注的扫描电镜图像进行训练，实现数据高效的分割。

Result: 模型在有限数据下达到Dice-Sørensen系数0.98，显著优于传统图像分析方法（0.85），同时将标注工作量减少一个数量级。

Conclusion: 该方法可实现快速自动化的碳化物量化，适用于合金设计，并能推广到其他钢种，展示了数据高效深度学习在反应堆压力容器钢分析中的潜力。

Abstract: Understanding reactor-pressure-vessel steel microstructure is crucial for predicting mechanical properties, as carbide precipitates both strengthen the alloy and can initiate cracks. In scanning electron microscopy images, gray-value overlap between carbides and matrix makes simple thresholding ineffective. We present a data-efficient segmentation pipeline using a lightweight U-Net (30.7~M parameters) trained on just \textbf{10 annotated scanning electron microscopy images}. Despite limited data, our model achieves a \textbf{Dice-Sørensen coefficient of 0.98}, significantly outperforming the state-of-the-art in the field of metallurgy (classical image analysis: 0.85), while reducing annotation effort by one order of magnitude compared to the state-of-the-art data efficient segmentation model. This approach enables rapid, automated carbide quantification for alloy design and generalizes to other steel types, demonstrating the potential of data-efficient deep learning in reactor-pressure-vessel steel analysis.

</details>


### [74] [Intrinsic Dimension Estimation for Radio Galaxy Zoo using Diffusion Models](https://arxiv.org/abs/2511.11490)
*Joan Font-Quer Roset,Devina Mohan,Anna Scaife*

Main category: cs.LG

TL;DR: 使用基于分数的扩散模型估计Radio Galaxy Zoo数据集的固有维度，发现分布外源具有更高的固有维度值，且RGZ的固有维度高于自然图像数据集。


<details>
  <summary>Details</summary>
Motivation: 研究RGZ数据集的固有维度特性，探索其与能量分数、形态类别和信噪比的关系，为自监督学习算法提供定量分析基础。

Method: 使用基于分数的扩散模型估计RGZ数据集的固有维度，分析其与BNN能量分数、FR形态类别和SNR的关系。

Result: 分布外源具有更高的固有维度值；RGZ整体固有维度高于自然图像数据集；FR I和FR II类之间无显著关系；信噪比与固有维度呈弱负相关。

Conclusion: 固有维度与能量分数的关系可用于定量研究和改进自监督学习算法的表示学习，为未来RGZ数据集研究提供新方向。

Abstract: In this work, we estimate the intrinsic dimension (iD) of the Radio Galaxy Zoo (RGZ) dataset using a score-based diffusion model. We examine how the iD estimates vary as a function of Bayesian neural network (BNN) energy scores, which measure how similar the radio sources are to the MiraBest subset of the RGZ dataset. We find that out-of-distribution sources exhibit higher iD values, and that the overall iD for RGZ exceeds those typically reported for natural image datasets. Furthermore, we analyse how iD varies across Fanaroff-Riley (FR) morphological classes and as a function of the signal-to-noise ratio (SNR). While no relationship is found between FR I and FR II classes, a weak trend toward higher SNR at lower iD. Future work using the RGZ dataset could make use of the relationship between iD and energy scores to quantitatively study and improve the representations learned by various self-supervised learning algorithms.

</details>


### [75] [Honesty over Accuracy: Trustworthy Language Models through Reinforced Hesitation](https://arxiv.org/abs/2511.11500)
*Mohamad Amin Mohamadi,Tianhao Wang,Zhiyuan Li*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Modern language models fail a fundamental requirement of trustworthy intelligence: knowing when not to answer. Despite achieving impressive accuracy on benchmarks, these models produce confident hallucinations, even when wrong answers carry catastrophic consequences. Our evaluations on GSM8K, MedQA and GPQA show frontier models almost never abstain despite explicit warnings of severe penalties, suggesting that prompts cannot override training that rewards any answer over no answer. As a remedy, we propose Reinforced Hesitation (RH): a modification to Reinforcement Learning from Verifiable Rewards (RLVR) to use ternary rewards (+1 correct, 0 abstention, -$λ$ error) instead of binary. Controlled experiments on logic puzzles reveal that varying $λ$ produces distinct models along a Pareto frontier, where each training penalty yields the optimal model for its corresponding risk regime: low penalties produce aggressive answerers, high penalties conservative abstainers. We then introduce two inference strategies that exploit trained abstention as a coordination signal: cascading routes queries through models with decreasing risk tolerance, while self-cascading re-queries the same model on abstention. Both outperform majority voting with lower computational cost. These results establish abstention as a first-class training objective that transforms ``I don't know'' from failure into a coordination signal, enabling models to earn trust through calibrated honesty about their limits.

</details>


### [76] [FarSkip-Collective: Unhobbling Blocking Communication in Mixture of Experts Models](https://arxiv.org/abs/2511.11505)
*Yonatan Dukler,Guihong Li,Deval Shah,Vikram Appia,Emad Barsoum*

Main category: cs.LG

TL;DR: FarSkip-Collective通过修改MoE模型架构，跳过连接以实现计算与通信的重叠，在16B到109B参数模型中保持准确性的同时提升训练和推理效率。


<details>
  <summary>Details</summary>
Motivation: 阻塞通信是分布式环境中高效运行MoE模型的主要障碍，需要解决计算与通信无法重叠的问题。

Method: 修改现代模型架构，跳过模型中的连接，通过自蒸馏等技术将大型模型转换为支持通信重叠的架构。

Result: 成功转换了16B到109B参数的最先进模型，Llama 4 Scout（109B）在广泛下游评估中平均准确率仅比原始版本低1%。

Conclusion: FarSkip-Collective方法能够在不牺牲模型能力的前提下实现通信与计算的重叠，显著加速训练和推理过程。

Abstract: Blocking communication presents a major hurdle in running MoEs efficiently in distributed settings. To address this, we present FarSkip-Collective which modifies the architecture of modern models to enable overlapping of their computation with communication. Our approach modifies the architecture to skip connections in the model and it is unclear a priori whether the modified model architecture can remain as capable, especially for large state-of-the-art models and while modifying all of the model layers. We answer this question in the affirmative and fully convert a series of state-of-the-art models varying from 16B to 109B parameters to enable overlapping of their communication while achieving accuracy on par with their original open-source releases. For example, we convert Llama 4 Scout (109B) via self-distillation and achieve average accuracy within 1% of its instruction tuned release averaged across a wide range of downstream evaluations. In addition to demonstrating retained accuracy of the large modified models, we realize the benefits of FarSkip-Collective through optimized implementations that explicitly overlap communication with computation, accelerating both training and inference in existing frameworks.

</details>


### [77] [Generalizing Fair Clustering to Multiple Groups: Algorithms and Applications](https://arxiv.org/abs/2511.11539)
*Diptarka Chakraborty,Kushagra Chatterjee,Debarati Das,Tien-Long Nguyen*

Main category: cs.LG

TL;DR: 本文研究了多组（超过两组）的最接近公平聚类问题，证明了该问题在NP难度，并提出了近似算法，同时改进了公平相关聚类和公平共识聚类的近似保证。


<details>
  <summary>Details</summary>
Motivation: 现有聚类方法经常无法为受保护属性定义的边缘化群体提供公平表示，这通常由训练数据中的偏见引起。虽然最近有研究开始探讨最接近公平聚类，但仅限于两组情况，而实际数据通常包含多个群体（如年龄、种族、性别等）。

Method: 将最接近公平聚类问题推广到任意数量组的情况，证明其NP难度，并提出近线性时间的近似算法来处理任意大小的多组情况。

Result: 提出了高效的多组最接近公平聚类近似算法，改进了公平相关聚类的近似保证，并为多组公平共识聚类问题提供了首个近似算法。

Conclusion: 本研究成功解决了多组最接近公平聚类问题，填补了现有研究的空白，并为相关公平聚类问题提供了改进的解决方案。

Abstract: Clustering is a fundamental task in machine learning and data analysis, but it frequently fails to provide fair representation for various marginalized communities defined by multiple protected attributes -- a shortcoming often caused by biases in the training data. As a result, there is a growing need to enhance the fairness of clustering outcomes, ideally by making minimal modifications, possibly as a post-processing step after conventional clustering. Recently, Chakraborty et al. [COLT'25] initiated the study of \emph{closest fair clustering}, though in a restricted scenario where data points belong to only two groups. In practice, however, data points are typically characterized by many groups, reflecting diverse protected attributes such as age, ethnicity, gender, etc.
  In this work, we generalize the study of the \emph{closest fair clustering} problem to settings with an arbitrary number (more than two) of groups. We begin by showing that the problem is NP-hard even when all groups are of equal size -- a stark contrast with the two-group case, for which an exact algorithm exists. Next, we propose near-linear time approximation algorithms that efficiently handle arbitrary-sized multiple groups, thereby answering an open question posed by Chakraborty et al. [COLT'25].
  Leveraging our closest fair clustering algorithms, we further achieve improved approximation guarantees for the \emph{fair correlation clustering} problem, advancing the state-of-the-art results established by Ahmadian et al. [AISTATS'20] and Ahmadi et al. [2020]. Additionally, we are the first to provide approximation algorithms for the \emph{fair consensus clustering} problem involving multiple (more than two) groups, thus addressing another open direction highlighted by Chakraborty et al. [COLT'25].

</details>


### [78] [Multistability of Self-Attention Dynamics in Transformers](https://arxiv.org/abs/2511.11553)
*Claudio Altafini*

Main category: cs.LG

TL;DR: 自注意力动力学与多智能体Oja流相关，将单头自注意力系统的平衡点分为四类：共识、二分共识、聚类和多边形平衡点，其中前三类常共存且前两类总是与价值矩阵的特征向量对齐。


<details>
  <summary>Details</summary>
Motivation: 研究自注意力动力学与多智能体Oja流的关系，分析自注意力机制中平衡点的分类和稳定性特性。

Method: 将自注意力动力学建模为连续时间多智能体系统，分析其与多智能体Oja流的关系，并对单头自注意力系统的平衡点进行分类研究。

Result: 发现自注意力动力学存在四类平衡点，前三类常共存且前两类总是与价值矩阵的特征向量对齐，通常但不总是与主特征向量对齐。

Conclusion: 自注意力动力学具有丰富的平衡点结构，其与价值矩阵特征向量的对齐特性揭示了注意力机制的内在数学结构。

Abstract: In machine learning, a self-attention dynamics is a continuous-time multiagent-like model of the attention mechanisms of transformers. In this paper we show that such dynamics is related to a multiagent version of the Oja flow, a dynamical system that computes the principal eigenvector of a matrix corresponding for transformers to the value matrix. We classify the equilibria of the ``single-head'' self-attention system into four classes: consensus, bipartite consensus, clustering and polygonal equilibria. Multiple asymptotically stable equilibria from the first three classes often coexist in the self-attention dynamics. Interestingly, equilibria from the first two classes are always aligned with the eigenvectors of the value matrix, often but not exclusively with the principal eigenvector.

</details>


### [79] [A Unified Convergence Analysis for Semi-Decentralized Learning: Sampled-to-Sampled vs. Sampled-to-All Communication](https://arxiv.org/abs/2511.11560)
*Angelo Rodio,Giovanni Neglia,Zheng Chen,Erik G. Larsson*

Main category: cs.LG

TL;DR: 本文比较了半去中心化联邦学习中的两种模型分发策略：采样到采样(S2S)和采样到全部(S2A)，分析了它们在数据异构性、采样率、服务器聚合频率和网络连接性等关键参数下的性能差异。


<details>
  <summary>Details</summary>
Motivation: 尽管S2S和S2A策略在实际应用中都很重要，但缺乏对这两种策略的严格理论和实证比较，需要填补这一研究空白。

Method: 建立了一个统一的收敛分析框架，考虑采样率、服务器聚合频率和网络连接性等关键系统参数，对S2S和S2A策略进行理论分析和实验验证。

Result: 分析和实验结果表明，根据设备间数据异构性的程度，存在不同的性能区域，其中一种策略会优于另一种策略。

Conclusion: 研究结果为实际半去中心化联邦学习部署提供了具体的设计指导原则。

Abstract: In semi-decentralized federated learning, devices primarily rely on device-to-device communication but occasionally interact with a central server. Periodically, a sampled subset of devices uploads their local models to the server, which computes an aggregate model. The server can then either (i) share this aggregate model only with the sampled clients (sampled-to-sampled, S2S) or (ii) broadcast it to all clients (sampled-to-all, S2A). Despite their practical significance, a rigorous theoretical and empirical comparison of these two strategies remains absent. We address this gap by analyzing S2S and S2A within a unified convergence framework that accounts for key system parameters: sampling rate, server aggregation frequency, and network connectivity. Our results, both analytical and experimental, reveal distinct regimes where one strategy outperforms the other, depending primarily on the degree of data heterogeneity across devices. These insights lead to concrete design guidelines for practical semi-decentralized FL deployments.

</details>


### [80] [Optimizing Mixture of Block Attention](https://arxiv.org/abs/2511.11571)
*Guangxuan Xiao,Junxian Guo,Kasra Mazaheri,Song Han*

Main category: cs.LG

TL;DR: MoBA是一种用于LLM长上下文处理的高效注意力机制，但缺乏理论理解和高效GPU实现。本文通过统计模型分析MoBA机制，发现性能取决于路由器准确区分相关块的能力，提出了改进方法（小分块大小和键的短卷积），并开发了FlashMoBA实现高效GPU执行。


<details>
  <summary>Details</summary>
Motivation: MoBA虽然能通过稀疏注意力机制大幅降低计算成本，但其设计原则缺乏理论理解，且没有高效的GPU实现，阻碍了实际应用。

Method: 1. 开发统计模型分析MoBA机制；2. 推导信噪比连接架构参数与检索精度；3. 提出小分块大小和键的短卷积改进方法；4. 开发FlashMoBA CUDA内核实现高效GPU执行。

Result: 改进后的MoBA模型在从头训练的LLM中达到密集注意力基线的性能，FlashMoBA在小分块情况下比FlashAttention-2快14.7倍。

Conclusion: 通过理论分析和硬件优化，成功提升了MoBA的性能和效率，使其成为实用的长上下文处理解决方案。

Abstract: Mixture of Block Attention (MoBA) (Lu et al., 2025) is a promising building block for efficiently processing long contexts in LLMs by enabling queries to sparsely attend to a small subset of key-value blocks, drastically reducing computational cost. However, the design principles governing MoBA's performance are poorly understood, and it lacks an efficient GPU implementation, hindering its practical adoption. In this paper, we first develop a statistical model to analyze MoBA's underlying mechanics. Our model reveals that performance critically depends on the router's ability to accurately distinguish relevant from irrelevant blocks based on query-key affinities. We derive a signal-to-noise ratio that formally connects architectural parameters to this retrieval accuracy. Guided by our analysis, we identify two key pathways for improvement: using smaller block sizes and applying a short convolution on keys to cluster relevant signals, which enhances routing accuracy. While theoretically better, small block sizes are inefficient on GPUs. To bridge this gap, we introduce FlashMoBA, a hardware-aware CUDA kernel that enables efficient MoBA execution even with the small block sizes our theory recommends. We validate our insights by training LLMs from scratch, showing that our improved MoBA models match the performance of dense attention baselines. FlashMoBA achieves up to 14.7x speedup over FlashAttention-2 for small blocks, making our theoretically-grounded improvements practical. Code is available at: https://github.com/mit-han-lab/flash-moba.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [81] [Constants of motion and fundamental frequencies for elliptic orbits at fourth post-Newtonian order](https://arxiv.org/abs/2511.10735)
*David Trestini*

Main category: gr-qc

TL;DR: 该论文研究了非旋转致密双星系统在准椭圆轨道上的保守映射，获得了能量和角动量与基本频率之间的关系，达到了四阶后牛顿精度，并包含了瞬时项和尾项贡献。


<details>
  <summary>Details</summary>
Motivation: 研究致密双星系统在椭圆轨道上的动力学行为，特别是建立常数运动与基本频率之间的精确映射关系，这对于理解引力波辐射和双星演化至关重要。

Method: 采用作用角变量表述局部动力学，将尾项作为微扰处理，首先进行时间局域化，然后进行Delaunay平均，通过接触变换控制相空间变量。

Result: 获得了四阶后牛顿精度的轨道平均红移不变量，与解析自洽力结果完美吻合，并将三阶后牛顿精度的能量和角动量通量用基本频率重新表达。

Conclusion: 成功建立了非旋转致密双星系统在准椭圆轨道上的保守映射，验证了尾项处理的正确性，为引力波天文学提供了重要的理论基础。

Abstract: In the case of nonspinning compact binary systems on quasi-elliptic orbits, I obtain the conservative map between the constants of motion (energy and angular momentum) and the fundamental (radial and azimuthal) frequencies at the fourth post-Newtonian order, including both instantaneous and tail contributions. This map is expressed in terms of an enhancement function of the eccentricity, which is appropriately resummed to ensure accuracy for any eccentricity; in particular, I recover known results for circular orbits. In order to obtain this map, the local dynamics are expressed using an action-angle formulation. The tail term is treated as a perturbation, which is first localized in time, then Delaunay-averaged. Both operations require a contact transformation of the phase-space variables, which I explicitly control. Using the first law of binary black hole mechanics, I then obtain the orbit-averaged redshift invariant for eccentric orbits at fourth post-Newtonian order; when properly accounting for the tail contributions, it perfectly agrees with analytical self-force at postgeodesic order [arXiv:2203.13832]. Finally, I use these results to re-express the fluxes of energy and angular momentum obtained at third post-Newtonian order in [arXiv:0711.0302] and [arXiv:0908.3854] in terms of fundamental frequencies.

</details>


### [82] [Diffusion in the stochastic Klein-Gordon equation](https://arxiv.org/abs/2511.10738)
*Jonathan Oppenheim,Emanuele Panella*

Main category: gr-qc

TL;DR: 该论文研究了经典-量子混合引力理论中的标量场随机波动，通过随机克莱因-戈登方程分析线性化混合引力的现象学，发现场协方差在光锥外非零且随时间线性增长。


<details>
  <summary>Details</summary>
Motivation: 研究经典度规引力理论中预测的引力场随机波动，理解线性化经典-量子混合引力的现象学特征。

Method: 使用随机克莱因-戈登方程作为起点，采用"模平方延迟"极点规定计算标量场的非平衡两点函数，分析初始状态在调节发散中的作用。

Result: 场协方差仅在光锥外非零，与时空点空间距离成反比且随时间线性增长；能量具有与量子情况类似的接触发散。

Conclusion: 讨论了混合引力理论中异常扩散的可能影响，特别关注可通过标量协方差推断的引力波背景中的能量密度。

Abstract: Theories of gravity in which the metric is fundamentally classical predict stochastic fluctuations in the gravitational field. In this article, we study the stochastic Klein-Gordon equation as a starting point to understand the phenomenology of linearised classical-quantum hybrid gravity. In particular, we describe how to compute the non-equilibrium two point function of the scalar field, showing explicitly the role of the initial state in regulating divergences. To do so, we use a "mod-squared-retarded" pole-prescription and find that the covariance in the field is non-zero only outside the lightcone, scales inversely with the spatial distance of the spacetime points and grows linearly in time. The energy has a contact divergence similar to that found in the quantum case. We conclude by discussing possible implications of anomalous diffusion for hybrid theories of gravity, especially looking at the energy density in the predicted gravitational waves background, which can be inferred from the scalar covariances.

</details>


### [83] [Noncommutative black holes in extended anti-de Sitter phase space](https://arxiv.org/abs/2511.10820)
*Athanasios G. Tzikas*

Main category: gr-qc

TL;DR: 研究了在扩展反德西特相空间中普通和低维非对易黑洞的热力学性质，将负宇宙常数和最小截止长度作为热力学变量，分别代表系统的压力和张力。


<details>
  <summary>Details</summary>
Motivation: 探索在扩展相空间框架下，非对易黑洞的热力学行为，特别是相变现象，以理解黑洞热力学与统计力学系统的类比关系。

Method: 在扩展反德西特相空间中，将负宇宙常数视为压力，最小截止长度视为张力，分析不同维度（4D、3D、2D）非对易黑洞的热力学性质。

Result: 四维时空中的规则黑洞表现出类似于范德瓦尔斯气体液/气相变的小/大黑洞相变；三维情况显示全局和局部热力学稳定性；二维情况揭示了一种称为反霍金-佩奇相变的新型相变。

Conclusion: 不同维度的非对易黑洞在扩展相空间中展现出丰富多样的热力学行为，包括相变和稳定性特征，为理解黑洞热力学提供了新的视角。

Abstract: We study thermodynamic aspects of ordinary and lower dimensional noncommutative black holes within an extended anti-de Sitter phase space by treating the negative cosmological constant and the minimal cut-off length as thermodynamic variables representing the pressure and tension of the system, respectively. In four-dimensional spacetime, the regular black hole exhibits a small/large black hole phase transition analogous to the liquid/gas transition of a Van der Waals gas. The three-dimensional case demonstrates global and local thermodynamic stability, while the two-dimensional case reveals a novel type of transition referred to as the anti-Hawking-Page transition.

</details>


### [84] [The Semiclasscical limit of $SU(3)$ Gauge Field Coherent States: Peakedness and Overlap Functions](https://arxiv.org/abs/2511.10969)
*Ye Zhang,Zichang Huang*

Main category: gr-qc

TL;DR: 使用热核方法构建了SU(3)规范群的微分同胚协变相干态，并数值验证了其在半经典极限下的峰值性质，为通过相干态路径积分推导SU(3)规范场与引力耦合的有效动力学提供了必要工具。


<details>
  <summary>Details</summary>
Motivation: 为SU(3)规范场与引力耦合系统的有效动力学研究提供数学工具，通过构建微分同胚协变的相干态来支持相干态路径积分方法。

Method: 采用热核方法构造SU(3)规范群的微分同胚协变相干态，并通过数值计算验证这些态在半经典极限下的性质。

Result: 数值证明了相干态在半经典极限下具有概率分布和重叠函数的峰值性质，并给出了在t→0和g→g'联合极限下重叠振幅的领头阶项。

Conclusion: 成功构建了SU(3)规范群的微分同胚协变相干态，这些态具有所需的半经典性质，为研究规范场与引力耦合的有效动力学奠定了数学基础。

Abstract: By using the heat kernel method, we construct diffeomorphism-covariant coherent states for the $SU(3)$ gauge group. We numerically demonstrate that these states exhibit the required semiclassical properties in the semiclassical limit: the peakedness property of the probability distribution and the peakedness property of the overlap function. We also provide the leading order term of the overlap amplitude in the combined limit where $t \rightarrow 0$ and $g\rightarrow g'$. This work provides the essential tool for deriving effective dynamics for $SU(3)$ gauge fields coupled to gravity via a coherent state path integral.

</details>


### [85] [CPT symmetry in the mirror universe](https://arxiv.org/abs/2511.11109)
*Natalia Gorobey,Alexander Lukyanenko,A. V. Goltsev*

Main category: gr-qc

TL;DR: 提出了一个基于量子引力理论的双层宇宙模型，通过定义3D不变且规范不变的宇宙固有时间，在封闭宇宙中引入统一时间概念，并基于CPT对称性原理构建了双层宇宙的协变量子场论。


<details>
  <summary>Details</summary>
Motivation: 在量子引力框架下建立统一的宇宙时间概念，并探索双层宇宙结构中的CPT对称性原理，为量子宇宙学提供新的理论基础。

Method: 使用狄拉克双旋子空间上的埃尔米特3D算子定义等效参考系，类比闵可夫斯基空间中的洛伦兹不变量子场论，通过迭代方法构建CPT对称的均匀各向同性双层宇宙模型。

Result: 成功构建了双层宇宙的CPT对称状态，其中Hartle-Hawking无边界波函数作为零阶近似，建立了协变的物质规范场量子理论。

Conclusion: 该模型为量子引力理论中的宇宙时间问题和CPT对称性提供了新的数学框架，在双层宇宙结构中实现了规范不变的量子场论描述。

Abstract: A model of a two-sheeted universe in the quantum theory of gravity is proposed, based on the definition of 3D invariant and gauge-invariant proper time of the universe. A uniform time in a closed universe is introduced in the class of equivalent reference systems defined by the spectrum of a Hermitian 3D operator on the space of Dirac bi-spinors, the equality to zero of which is equivalent to a system of gravitational constraints. Based on the analogy with the Lorentz-invariant quantum field theory in Minkowski space and the definition of discrete C-, P- and T-transformations separately, the principle of CPT symmetry in a two-sheeted universe is formulated. A covariant quantum theory of matter gauge fields consistent with the charge conjugation operation in a two-sheeted universe is proposed. The CPT symmetric state of a homogeneous isotropic two-sheeted model of the universe is constructed by an iterative method in which the no-boundary Hartle--Hawking wave function is used as a zeroth approximation.

</details>


### [86] [Quantum Electron Clouds near Black Holes: Black Atoms and Molecules](https://arxiv.org/abs/2511.11173)
*Hinako Iseki,Shin Sasaki,Kenta Shiozawa*

Main category: gr-qc

TL;DR: 研究黑洞附近量子波函数行为，发现强引力会吸引电子波函数使其局域在视界附近，影响原子化学性质


<details>
  <summary>Details</summary>
Motivation: 研究强引力场（黑洞）对量子系统的影响，特别是电子在黑洞引力场中的行为

Method: 使用DeWitt形式论推导Schwarzschild和Reissner-Nordström黑洞附近的薛定谔方程，求解"黑洞氢原子"的电子云分布

Result: 黑洞会吸引波函数使其局域在视界附近，电子最可能被捕获在视界区域

Conclusion: 强引力不仅影响经典物体，还会影响量子物质和原子的化学性质

Abstract: We study quantum mechanical wavefunctions near highly curved spaces, i.e., black holes. By utilizing the formalism developed by DeWitt, we derive the Schrödinger equations in the vicinity of the Schwarzschild and the Reissner-Nordström black hole geometries. The quantum electron cloud for the "black hydrogen atom" - an electron trapped by black holes - is particularly studied. We solve the equations and find that black holes generally attract the wavefunctions, localizing them near the horizon where the electrons are most likely to be trapped. These results imply that not only classical objects but also the quantum material and even the chemical properties of the atoms are affected by strong gravity. We also discuss black hydrogen molecules composed of multi-centered Majumdar-Papapetrou black holes.

</details>


### [87] [On Nonrelativistic Isotropic and Homogeneous Universe](https://arxiv.org/abs/2511.11268)
*R. G. G. Amorim,A. F. Santos,K. V. S. Araújo,S. C. Ulhoa*

Main category: gr-qc

TL;DR: 本文基于伽利略协变性构建了五维伽利略流形上的非相对论宇宙学模型，得到了类似FRW度量的各向同性解，通过降维自然产生各向异性和密度变化，在零空间曲率情况下重现米尔牛顿宇宙学。


<details>
  <summary>Details</summary>
Motivation: 在伽利略协变性框架下建立非相对论宇宙学模型，提供独立于相对论宇宙学的理论框架，探索无宇宙速度限制的宇宙动力学。

Method: 在五维伽利略流形中构造各向同性均匀度量，求解爱因斯坦类场方程，获得真空和尘埃主导两种解，通过特定嵌入进行3+1维降维。

Result: 得到两种解：真空配置产生指数-二次尺度因子，尘埃主导宇宙由非相互作用非相对论流体描述；降维后自然产生尺度因子和密度各向异性，与普朗克数据一致；零空间曲率时重现米尔牛顿宇宙学。

Conclusion: 该模型在伽利略协变性框架下成功构建了非相对论宇宙学，为宇宙动力学提供了独立的理论设置，并能自然地解释观测到的各向异性特征。

Abstract: This article deals with a nonrelativistic cosmological model based on Galilean covariance, formulated within a five-dimensional Galilean manifold. Within this framework, we construct an isotropic and homogeneous metric analogous to the Friedmann--Robertson--Walker metric but without a universal speed limit. Two distinct solutions of the Einstein-like field equations are obtained: (i) a vacuum configuration ($λ=0$) yielding an exponential--quadratic scale factor, and (ii) a dust-dominated universe ($λ=1$) described by a non-interacting nonrelativistic fluid. Upon dimensional reduction to $3+1$ spacetime through a specific embedding, the model naturally develops anisotropy in the scale factor and density, consistent with the near-zero spatial curvature inferred from Planck data. In the case of vanishing spatial curvature, the framework reproduces Milne's Newtonian cosmology because this condition leads to a vanishing pressure. This provides an independent nonrelativistic setting for cosmological dynamics within Galilean covariance.

</details>


### [88] [Molecular analogue for scalar dynamics in a tachyonic metric](https://arxiv.org/abs/2511.11379)
*Davi de Moura Esposti Moreira,Matheus Elias Pereira,Alexandre Grezzi de Miranda Schmidt*

Main category: gr-qc

TL;DR: 本文提出了氢分子离子作为与快子引力场相互作用的标量测试粒子动力学的模拟系统，通过计算准正规模态和霍金辐射谱，展示了分子系统可以模拟极端引力系统的动力学行为。


<details>
  <summary>Details</summary>
Motivation: 快子作为超光速假想粒子从未被观测到，研究其引力效应具有理论意义。本文旨在通过分子系统模拟快子引力场中的粒子动力学，为研究极端引力系统提供实验可行的替代方案。

Method: 使用AII度规建模快子时空，通过克莱因-戈登方程分析标量场在此背景下的行为。引入外部势场，证明氢分子离子中的电子动力学可以再现测试粒子的径向和角向波函数分量。

Result: 计算了系统的准正规模态和霍金辐射谱，成功展示了氢分子离子能够有效模拟快子引力场中测试粒子的动力学行为。

Conclusion: 氢分子离子可以作为快子引力系统的分子模拟模型，为研究极端引力现象提供了实验上可行的替代途径。

Abstract: Tachyons are hypothetical particles that propagate faster than light, yet they have never been observed in nature or in the laboratory. In this work, we introduce the hydrogen molecule ion as an analogue for the dynamics of a spinless test particle interacting with the gravitational field generated by a tachyon. The tachyonic spacetime is modeled using an AII metric, and the problem is analyzed through the Klein-Gordon equation for a scalar field in this background. We compute the quasinormal modes and the Hawking radiation spectrum associated with the system. By introducing an external potential, we demonstrate that both the radial and angular components of the test particles wave function can be effectively reproduced by the electron dynamics in the hydrogen molecule ion, thus proposing a molecular analogue model for an extreme gravitational system.

</details>


### [89] [Regularized Black Hole Solution from a New String Cloud Source](https://arxiv.org/abs/2511.11419)
*C. R. Muniz,Jonathan Alves Rebouças,Francisco Bento Lustosa,Leonardo Tavares de Oliveira,Francisco Tiago Barboza Sampaio*

Main category: gr-qc

TL;DR: 构建了由Letelier-Alencar弦云支持的新型正则黑洞解，通过有理Dagum型分布进行正则化，形成从弦云外区到反德西特核心的几何结构。分析了能量条件、热力学性质和黑洞阴影。


<details>
  <summary>Details</summary>
Motivation: 构建具有正则化物质分布的黑洞解，避免奇点并研究其物理性质，包括能量条件、热力学行为和观测特征。

Method: 使用有理Dagum型分布正则化Letelier-Alencar弦云，构建正则黑洞几何，分析能量条件、热力学性质，并采用Rényi非广延熵和拓扑热力学方法。

Result: 获得了有限曲率不变量的正则黑洞解，能量条件在核心和外区有不同表现，热力学性质显示熵仅依赖于正则化尺度，非广延变形稳定系统并消除相变，阴影半径符合EHT观测约束。

Conclusion: 成功构建了物理上合理的正则黑洞模型，该模型在热力学上稳定且与当前观测数据一致，为非广延引力理论提供了具体实现。

Abstract: We construct a new family of regular black hole solutions supported by the novel Letelier-Alencar string cloud and regularized through a rational Dagum-type distribution. The regulator smooths the matter profile and ensures finite curvature invariants, yielding a geometry that interpolates between a string-cloud exterior and an anti--de Sitter core. We analyze the energy conditions, identifying where the null, weak, dominant and strong conditions hold or fail across the core and exterior. The parameter space for horizon formation is mapped and the thermodynamic propertie -- mass, Hawking temperature, entropy and heat capacity -- are derived; notably, the entropy depends only on the regularization scale while the string parameter modifies temperature and heat capacity. Employing Rényi non-extensive entropy and the topological thermodynamics approach, we show the non-extensive deformation stabilizes the system and removes the standard phase transition. Finally, we compute the shadow radius and derive constraints compatible with current Event Horizon Telescope bounds for Sgr~A* and M87*.

</details>


### [90] [\textit{Euclid}: From Galaxies to Gravitational Waves -- Forecasting Stochastic Gravitational Wave Background Anisotropies and Their Cross-Correlation](https://arxiv.org/abs/2511.11509)
*K. Z. Yang,G. Cusin,V. Mandic,C. Scarlata,J. Suresh,B. Altieri,N. Auricchio,C. Baccigalupi,M. Baldi,S. Bardelli,A. Biviano,E. Branchini,M. Brescia,S. Camera,G. Cañas-Herrera,V. Capobianco,C. Carbone,J. Carretero,S. Casas,M. Castellano,G. Castignani,S. Cavuoti,K. C. Chambers,A. Cimatti,C. Colodro-Conde,G. Congedo,L. Conversi,Y. Copin,A. Costille,F. Courbin,H. M. Courtois,H. Degaudenzi,G. De Lucia,H. Dole,F. Dubath,X. Dupac,S. Dusini,S. Escoffier,M. Farina,R. Farinelli,F. Faustini,S. Ferriol,F. Finelli,P. Fosalba,N. Fourmanoit,M. Frailis,E. Franceschi,M. Fumana,S. Galeotta,K. George,B. Gillis,C. Giocoli,P. Gómez-Alvarez,J. Gracia-Carpio,A. Grazian,F. Grupp,S. V. H. Haugan,W. Holmes,F. Hormuth,A. Hornstrup,K. Jahnke,M. Jhabvala,B. Joachimi,E. Keihänen,S. Kermiche,A. Kiessling,B. Kubik,M. Kunz,H. Kurki-Suonio,A. M. C. Le Brun,S. Ligori,P. B. Lilje,V. Lindholm,I. Lloro,G. Mainetti,D. Maino,O. Mansutti,S. Marcin,O. Marggraf,M. Martinelli,N. Martinet,F. Marulli,E. Medinaceli,S. Mei,Y. Mellier,M. Meneghetti,E. Merlin,G. Meylan,A. Mora,M. Moresco,L. Moscardini,C. Neissner,S. -M. Niemi,C. Padilla,S. Paltani,F. Pasian,K. Pedersen,V. Pettorino,S. Pires,G. Polenta,M. Poncet,L. A. Popa,L. Pozzetti,F. Raison,A. Renzi,J. Rhodes,G. Riccio,E. Romelli,M. Roncarelli,R. Saglia,Z. Sakr,D. Sapone,B. Sartoris,M. Schirmer,P. Schneider,A. Secroun,E. Sefusatti,G. Seidel,S. Serrano,C. Sirignano,G. Sirri,L. Stanco,J. Steinwagner,P. Tallada-Crespí,A. N. Taylor,I. Tereno,N. Tessore,S. Toft,R. Toledo-Moreo,F. Torradeflot,I. Tutusaus,L. Valenziano,J. Valiviita,T. Vassallo,A. Veropalumbo,J. Weller,G. Zamorani,F. M. Zerbi,E. Zucca,T. Castro,J. García-Bellido,V. Scottez,M. Viel,P. Monaco*

Main category: gr-qc

TL;DR: 该论文通过欧几里得联盟的旗舰模拟星系目录，预测了致密双星并合产生的随机引力波背景的能量密度振幅和空间各向异性，并开发了贝叶斯框架来推断关键模型参数。


<details>
  <summary>Details</summary>
Motivation: 研究致密双星并合（包括双黑洞、双中子星和黑洞-中子星并合）产生的随机引力波背景的空间各向异性特征，为未来与欧几里得星系数据的相关性分析奠定基础。

Method: 使用欧几里得联盟的旗舰模拟星系目录，基于每个星系的质量和恒星形成率约束其恒星形成历史，预测其对引力波能量密度的贡献，并开发贝叶斯框架推断关键模型参数。

Result: 获得了致密双星并合随机引力波背景的频率谱和空间各向异性预测，并识别出一组能够捕捉模型关键特征的有效参数。

Conclusion: 这是开发全面框架的第一步，未来将能够关联随机引力波背景各向异性和欧几里得星系数据，从而从这个新观测量中提取有价值的宇宙学信息。

Abstract: We estimate the amplitude and spatial anisotropy in the stochastic gravitational wave background (SGWB) energy density due to compact binary coalescence (CBC) events: binary black holes (BBH), binary neutron stars (BNS), and black hole-neutron star (BHNS) mergers. Our starting point is the Flagship Simulation Galaxy Catalogue developed by the Euclid Consortium. For each galaxy in the Catalogue, we use the simulated mass and starformation to constrain the galaxy's star-formation history, and predict its contribution to the gravitational-wave energy density through CBC mergers. Combining such contributions from all galaxies in the Catalogue results in a prediction for the frequency spectrum and spatial anisotropy of the CBC SGWB. We also compare this prediction to semi-analytical models of SGWB generated by compact binaries. We identify a set of effective parameters that capture the key features of these models, and we apply a Bayesian framework to infer these parameters assuming an ideal scenario of cosmic variance-limited search. This represents the first step toward developing a comprehensive framework that will eventually enable the correlation of SGWB anisotropy and \textit{Euclid} galaxy data, potentially allowing us to extract valuable astrophysical information from this new observable.

</details>


### [91] [Accurate models for recoil velocity distribution in black hole mergers with comparable to extreme mass-ratios and their astrophysical implications](https://arxiv.org/abs/2511.11536)
*Tousif Islam,Digvijay Wadekar*

Main category: gr-qc

TL;DR: 提出了两个新的黑洞合并反冲速度模型：gwModel_kick_q200（解析模型）和gwModel_kick_prec_flow（归一化流模型），覆盖从可比到极端质量比的范围，性能优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有解析模型与数值相对论数据差异大，数据驱动模型限于q<=8（对齐自旋）和q<=4（进动自旋），且外推时失效。需要覆盖更大质量比范围的准确模型。

Method: 使用~5000个SXS和RIT数值相对论模拟（q<=128）和~100个黑洞微扰理论模拟（q<=200），结合后牛顿理论的解析洞察与数据驱动技术，开发了三种模型：解析模型、高斯过程回归模型和归一化流模型。

Result: 所有三个模型在各自领域内都优于现有模型。使用gwModel_kick_prec_flow模型时，低质量球状星团中黑洞保留概率有明显变化。

Conclusion: 新模型在从可比到极端质量比的整个参数空间内提供了高精度反冲速度预测，对理解层次合并和黑洞保留具有重要意义。模型通过gwModels包公开可用。

Abstract: Modeling the remnant recoil velocity (kick) distribution from binary black hole mergers is crucial for understanding hierarchical mergers in active galactic nuclei or globular clusters. Existing analytic models often show large discrepancies with numerical relativity (NR) data, while data-driven models are limited to mass ratios of q<=8 (aligned spins) and q<=4 (precessing spins) and break down when extrapolated outside their training ranges. Using ~5000 of NR simulations from the SXS and RIT catalogs up to q=128 and ~100 black hole perturbation theory simulations up to q=200, we present two classes of models: (i) gwModel_kick_q200 (gwModel_kick_q200_GPR), an analytic (Gaussian process regression) model for aligned-spin binaries. (ii) gwModel_kick_prec_flow, a normalizing-flow model for kick distribution from precessing binaries with isotropic spins. Our approach combines analytic insights from post-Newtonian theory with data-driven techniques to ensure correct limiting behavior and high accuracy across parameter space. Both gwModel_kick_q200 and gwModel_kick_prec_flow are valid from comparable to extreme mass ratios. Extensive validation shows all three models outperform existing ones within their respective domains. Finally, using both back-of-the-envelope estimates and 1404 detailed star cluster simulations incorporating our kick models, we find that the black hole retention probability in low mass globular clusters can vary noticeably when the gwModel_kick_prec_flow model is employed. The models are publicly available through the gwModels package.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [92] [A Hierarchy of Fibonacci Forbidden-Word Hamiltonians: From the Golden Chain to the Plastic Chain and Aperiodic Order](https://arxiv.org/abs/2511.10672)
*Marcelo Maciel Amaral*

Main category: quant-ph

TL;DR: 本文构建了一个无限、尺度对齐的一维无阻挫哈密顿量层次结构，通过逐步禁止Fibonacci词的最小禁止因子，从黄金链向Fibonacci子移位收敛，形成了拓扑熵的平台序列。


<details>
  <summary>Details</summary>
Motivation: 研究从高熵相到零熵非周期不动点的重整化群流，探索拓扑熵的阶梯式变化过程，并验证在量子退火器上的实现。

Method: 通过逐步禁止Fibonacci词的最小禁止因子（从长度F_K开始），构建哈密顿量层次结构，提出能量-熵标度关系，并在D-Wave量子退火器上进行实验验证。

Result: 证明了Plastic链（K=4）的基态计数遵循四项线性递推关系，其封闭解由塑料常数ρ≈1.3247控制；在量子退火实验中，K=3平凡，K=4具有单位能隙，K≥5需要反向退火才能达到99%以上的成功率。

Conclusion: 该层次结构提供了一个从初始高熵相到零熵非周期不动点的显式重整化群流，代数上只有K=3满足精确的Temperley-Lieb编织兼容性，更高层级定义了受约束的非周期哈密顿量码。

Abstract: We introduce an infinite, scale-aligned hierarchy of one-dimensional, frustration-free Hamiltonians by forbidding the minimal forbidden factors of the Fibonacci word up to length $F_K$, the $K$-th Fibonacci number. The ground-state languages have exponential growth constants $λ_K$ that decrease monotonically, starting from the value associated with the ``golden chain'' (approximately 1.618) and progressing toward 1. This process yields a staircase of topological-entropy plateaus that flows to an aperiodic fixed point, also known as the Fibonacci subshift. The first nontrivial rung ($K=4$) is the ``Plastic chain,'' which forbids \texttt{SS} and \texttt{LLL}. We prove its ground-state counts follow a specific four-term linear recurrence relation and provide a closed-form solution governed by the plastic constant $ρ\approx 1.3247$. We propose an energy-entropy scaling where the energy penalty for each new forbidden pattern is proportional to the logarithmic ratio of the growth constants from the previous and current rungs, turning the sequence of projectors into an explicit renormalization-group flow from the initial high-entropy phase to the zero-entropy aperiodic fixed point. Algebraically, exact Temperley-Lieb braiding compatibility holds only at the base rung, $K=3$ (which forbids only \texttt{SS}); higher rungs define constrained aperiodic Hamiltonian codes rather than Temperley-Lieb representations. Small instances realized on a D-Wave quantum annealer match these predictions: $K=3$ is trivial, $K=4$ resolves a unit gap with moderate success, and $K\ge 5$ instances require reverse annealing to exceed $99\%$ success, clarifying reduction penalties and embedding variability.

</details>


### [93] [Limitations of Quantum Advantage in Unsupervised Machine Learning](https://arxiv.org/abs/2511.10709)
*Apoorva D. Patel*

Main category: quant-ph

TL;DR: 该论文探讨了量子机器学习模型相对于经典模型的潜在优势，指出量子优势取决于输入数据和目标观测量的特性，并讨论了限制量子优势的约束条件。


<details>
  <summary>Details</summary>
Motivation: 研究量子机器学习模型在无监督学习任务中相对于经典模型的优势，探索量子密度矩阵中经典概率分布不具备的特征如何带来性能提升。

Method: 将经典模型中的玻尔兹曼分布替换为量子密度矩阵，利用量子态特有的特征进行模式识别和数据预测。

Result: 量子优势不是普遍存在的，而是依赖于输入数据和目标观测量的具体特性，存在限制量子优势的约束条件。

Conclusion: 量子优势具有问题依赖性，这对数据分析和传感应用都有重要影响，需要根据具体场景评估量子方法的适用性。

Abstract: Machine learning models are used for pattern recognition analysis of big data, without direct human intervention. The task of unsupervised learning is to find the probability distribution that would best describe the available data, and then use it to make predictions for observables of interest. Classical models generally fit the data to Boltzmann distribution of Hamiltonians with a large number of tunable parameters. Quantum extensions of these models replace classical probability distributions with quantum density matrices. An advantage can be obtained only when features of density matrices that are absent in classical probability distributions are exploited. Such situations depend on the input data as well as the targeted observables. Explicit examples are discussed that bring out the constraints limiting possible quantum advantage. The problem-dependent extent of quantum advantage has implications for both data analysis and sensing applications.

</details>


### [94] [Robust Entanglement Dynamics in Driven Open Quantum Systems](https://arxiv.org/abs/2511.10711)
*Aqsa Mushtaq,Chaimae Banouni,Mahboob Ul Haq,S. M. Zangi*

Main category: quant-ph

TL;DR: 研究双量子比特系统中量子关联（负性、量子失协、量子记忆辅助熵不确定度）在外部脉冲和各种退相干通道下的动力学行为，发现系统参数可调控关联的稳定性和寿命。


<details>
  <summary>Details</summary>
Motivation: 探索量子系统在外部扰动和退相干环境下的量子关联动态特性，为量子计算和安全通信等应用提供优化框架。

Method: 分析双量子比特系统在振幅阻尼、纯退相位和脉冲诱导退相位等退相干通道下，不同量子比特耦合强度、能级分裂和脉冲参数对量子关联的影响。

Result: 量子比特耦合和能级分裂显著影响动力学，产生弱耦合区的明显振荡并保护强耦合区的纠缠。负性最敏感，量子失协持续时间更长，量子记忆辅助熵不确定度反映残余量子记忆。脉冲参数有效控制关联的生成和耗散。

Conclusion: 通过调整系统参数可以控制量子关联的稳定性和寿命，为需要强纠缠和长相干时间的量子应用提供优化方案。

Abstract: We investigate the dynamics of key quantum correlations - Negativity (NG), Quantum Discord (QD), and Quantum-Memory-Assisted Entropic Uncertainty (QM-EUR) - in a bipartite two-qubit system under the influence of external pulses and various decoherence channels, including amplitude damping (gamma_amp), pure dephasing (gamma_deph), and pulse-induced dephasing (G), while different regimes of inter-qubit coupling (Jzz, Jxx), qubit energy splitting (epsilon), and pulse parameters (A_pulse, beta_pulse) are explored. Our results show that inter-qubit coupling and energy splitting epsilon significantly influence the dynamics, producing pronounced oscillations in the weak-coupling regime and protecting pre-existing entanglement in the strong-coupling regime. NG is the most sensitive, QD persists longer revealing nonclassical correlations independent of entanglement, and QM-EUR reflects residual quantum memory and entropic uncertainty, showing that quantum signatures survive even when NG and QD are weak. Pulse amplitude and width effectively control the generation and dissipation of correlations, while the intensity of pulse-induced dephasing modulates the balance between sustained oscillations and rapid decoherence. The initial state also plays a crucial role: a partially entangled initial state is more resilient to perturbations, preserving correlations over time, whereas a separable state exhibits cycles of entanglement creation and destruction. Thus, by adjusting system parameters, it is possible to control the stability and lifetime of correlations and coherence, providing a framework to optimize quantum systems for applications requiring both strong entanglement and long-lasting coherence, such as quantum computing and secure communication.

</details>


### [95] [Entanglement boosting: Low-volume logical Bell pair preparation for distributed fault-tolerant quantum computation](https://arxiv.org/abs/2511.10729)
*Shinichi Sunami,Yutaka Hirano,Toshihide Hinokuma,Hayata Yamasaki*

Main category: quant-ph

TL;DR: 提出了一种新的度量标准LLV来评估逻辑贝尔对制备的实际成本，并设计了纠缠提升协议，相比现有方法将LLV降低了几个数量级，为分布式容错量子计算的实用实现铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 分布式架构是扩展容错量子计算的重要途径，但现有的纠缠蒸馏协议主要关注最小化贝尔对消耗，而忽略了本地操作的成本，导致协议在实际实现中效率低下。

Method: 引入了链路限制体积(LLV)作为新的度量标准，结合了物理贝尔对消耗和本地操作体积；提出了纠缠提升协议，使用软信息解码器和后选择来抑制逻辑错误率；还提出了使用高码率量子纠错码的流水线实现。

Result: 纠缠提升协议能够从少于100个噪声物理贝尔对中制备出逻辑错误率约为10^-10的逻辑贝尔对，所有本地操作可在单个表面码补丁的空间区域内实现，LLV相比现有最优方法降低了几个数量级。

Conclusion: 这些结果为分布式容错量子计算的实用实现提供了可行方案，强化了快速互连技术的优势，并为协议和设备的高效设计提供了指导原则。

Abstract: Distributed architecture is a promising route to scaling fault-tolerant quantum computing (FTQC) beyond the inherent limitations of single processors. For practical implementation of distributed FTQC, logical Bell pair preparation must be designed not only for efficient Bell pair consumption but also for the spacetime volume of the protocol; however, entanglement distillation protocols have primarily focused on minimizing the consumption of Bell pairs, often resulting in protocols that require a substantial number of local operations. To resolve this issue, we introduce a metric for characterizing the practical cost of preparing high-fidelity logical Bell pairs, link-limited volume (LLV), which is a circuit-volume metric incorporating both the cost of physical Bell pair consumption and the volume associated with local operations. Guided by this metric, we propose entanglement boosting protocol, which achieves efficient preparation of logical Bell pairs encoded in rotated surface code with LLV reduced by orders of magnitude compared to prior state-of-the-art methods. In this protocol, paralleling recent advances in magic state cultivation, we employ soft-information decoders and postselection to suppress the logical error rates of Bell pairs to practical levels in the order of $10^{-10}$ from fewer than 100 noisy physical Bell pairs while all local operations are implementable within a spatial region of a single surface code patch. We also present a pipelined implementation of entanglement distillation using high-rate quantum error-correcting codes, enabling arbitrarily low logical error rates while also maintaining physically efficient implementations. These results pave the way for the practical implementation of distributed FTQC, reinforcing the benefits of fast interconnect technologies and serving as a guiding principle for the efficient design of protocols and devices.

</details>


### [96] [Optimal propagation distance for maximal biphoton entanglement through the weakly turbulent atmosphere](https://arxiv.org/abs/2511.10755)
*Luchang Niu,Saleem Iqbal,Yang Xu,Robert W. Boyd*

Main category: quant-ph

TL;DR: 本文分析了大气湍流对纠缠双光子态传播的影响，推导了通过SPDC产生的信号和闲频场在独立湍流通道中传播后的密度算子表达式，揭示了空间相关性的量子到经典转变过程。


<details>
  <summary>Details</summary>
Motivation: 理解大气湍流对纠缠双光子态传播的影响对于自由空间量子通信协议至关重要，需要研究湍流如何影响量子态的空间相关性和纠缠特性。

Method: 使用扩展的惠更斯-菲涅耳原理和Kolmogorov湍流模型，推导了SPDC产生的信号和闲频场在独立湍流通道中传播后的密度算子解析表达式，并在连续位置基中分析。

Result: 研究表明信号和闲频场之间的空间相关性在湍流中仍然存在，尽管状态纯度损失，相关性从量子性质转变为经典性质；同时识别出角动量-轨道角动量纠缠最大化的有限传播距离范围。

Conclusion: 该研究为设计在湍流大气中运行数公里的自由空间量子通信链路提供了有价值的见解，特别是确定了纠缠最大化的最佳传播距离范围。

Abstract: Understanding the influence of atmospheric turbulence on the propagation of entangled biphoton states is essential for free-space quantum communication protocols. Using the extended Huygens-Fresnel principle and the Kolmogorov turbulence model, we derive an analytical expression for the combined density operator of the signal and idler fields generated via SPDC, following propagation through separate turbulent channels. By expressing this density operator in the continuous position basis, we show how the spatial correlations between signal and idler persist through turbulence despite the loss of state purity, as they transition from being quantum to classical in nature. We further identify a finite range of propagation distances over which the angle-OAM entanglement is maximized, which provides valuable insights for designing free-space quantum communication links operating over several kilometers through the turbulent atmosphere.

</details>


### [97] [Understanding the Nature of Depth-1 Equivariant Quantum Circuit](https://arxiv.org/abs/2511.10756)
*Jonathan Teo,Lee Xin Wei,Hoong Chuin Lau*

Main category: quant-ph

TL;DR: 提出SIGS方法，将EQC量子电路扩展到350节点TSP问题，相比传统RL方法在100节点问题上减少96.4%模拟时间，同时保持相近性能。


<details>
  <summary>Details</summary>
Motivation: 解决EQC量子电路在大规模TSP问题上扩展困难的问题，包括量子电路模拟的指数级时间和内存需求，以及实际量子硬件上的噪声和退相干问题。

Method: 提出Size-Invariant Grid Search (SIGS)训练优化方法，利用Size-Invariant Properties理论，在量子强化学习框架下高效模拟训练好的Depth-1 EQC输出。

Result: 在100节点TSP问题上，将模拟时间从151分钟减少到6分钟以下，测试集上的平均最优性差距保持在0.005以内。成功扩展到350节点TSP实例。

Conclusion: SIGS为QRL社区提供了实用的基准测试工具，能够高效分析QRL算法在更大问题规模上的性能表现。

Abstract: The Equivariant Quantum Circuit (EQC) for the Travelling Salesman Problem (TSP) has been shown to achieve near-optimal performance in solving small TSP problems (up to 20 nodes) using only two parameters at depth 1. However, extending EQCs to larger TSP problem sizes remains challenging due to the exponential time and memory for quantum circuit simulation, as well as increasing noise and decoherence when running on actual quantum hardware. In this work, we propose the Size-Invariant Grid Search (SIGS), an efficient training optimization for Quantum Reinforcement Learning (QRL), and use it to simulate the outputs of a trained Depth-1 EQC up to 350-node TSP instances - well beyond previously tractable limits. At TSP with 100 nodes, we reduce total simulation times by 96.4%, when comparing to RL simulations with the analytical expression (151 minutes using RL to under 6 minutes using SIGS on TSP-100), while achieving a mean optimality gap within 0.005 of the RL trained model on the test set. SIGS provides a practical benchmarking tool for the QRL community, allowing us to efficiently analyze the performance of QRL algorithms on larger problem sizes. We provide a theoretical explanation for SIGS called the Size-Invariant Properties that goes beyond the concept of equivariance discussed in prior literature.

</details>


### [98] [Certifying the dimensionality of any quantum channel with minimal assumptions](https://arxiv.org/abs/2511.10758)
*Saheli Mukherjee,Bivas Mallick,Pratik Ghosal*

Main category: quant-ph

TL;DR: 提出了一种认证量子通道能否保持高于给定阈值的纠缠维度的忠实方法，无需传统假设如可靠纠缠态制备、辅助边信道或完美测量设备。


<details>
  <summary>Details</summary>
Motivation: 高维纠缠在信息处理任务中具有显著优势，但需要量子通道不仅保持纠缠还能维持其维度高于特定阈值。现有方法存在各种假设限制。

Method: 开发了一种忠实认证方法，可应用于任何量子通道，避免了传统假设，并能扩展到认证其他非资源破坏通道类别。

Result: 该方法能够有效认证量子通道的纠缠保持能力，并可扩展到非NPT破坏通道等其他类别的认证。

Conclusion: 提出的认证方案具有忠实性、普适性和可扩展性，为实验实现提供了明确的可能性。

Abstract: High-dimensional entanglement offers significant advantages over low-dimensional ones in various information-processing tasks. However, to harness these advantages, it is crucial that the quantum channels used to store or transmit the subsystems of an entangled system not only preserve entanglement but also maintain its dimensionality above a certain threshold. The maximum entanglement dimension that a channel can preserve is referred to as its effective dimensionality, since the channel cannot be used to transmit information of dimension greater than that in a single use. In this work, we present a method to certify whether a quantum channel can preserve entanglement dimension above a given threshold. Unlike existing approaches, our method is faithful -- it can be applied to any channel, and avoids common assumptions such as reliable preparation of entangled states, auxiliary side channels, or perfect measurement devices. Moreover, the method can be extended to faithfully certify other classes of non-resource-breaking channels, such as non-NPT-breaking channels. Finally, we discuss possible experimental realizations of our certification scheme through explicit examples.

</details>


### [99] [Correlated Purification for Restoring $N$-Representability in Quantum Simulation](https://arxiv.org/abs/2511.10789)
*Yuchen Wang,Irma Avdic,Michael Rose,Lillian I. Payne Torres,Anna O. Schouten,Kevin J. Sung,David A. Mazziotti*

Main category: quant-ph

TL;DR: 提出了一种基于半定规划的关联纯化框架，用于恢复噪声、非物理双电子约化密度矩阵的准确性，通过双目标优化最小化多电子能量和测量2-RDM变化的核范数。


<details>
  <summary>Details</summary>
Motivation: 经典阴影层析产生的约化密度矩阵由于统计和硬件噪声经常违反N-表示性条件，需要恢复其物理准确性。

Method: 使用半定规划进行双目标优化：最小化多电子能量和测量2-RDM变化的核范数，核范数促进低秩、物理有意义的修正，能量项作为正则化项改善基态纯度。

Result: 在大型氢链的费米子阴影层析应用中，关联纯化显著降低了能量和2-RDM误差，在解离曲线上达到化学精度。

Conclusion: 该框架为多体量子模拟中的层析提供了稳健策略，特别适用于基态，也可通过调整能量权重应用于激发态和非稳态。

Abstract: Classical shadow tomography offers a scalable route to estimating properties of quantum states, but the resulting reduced density matrices (RDMs) often violate constraints that ensure they represent $N$-electron states -- known as $N$-representability conditions -- because of statistical and hardware noise. We present a correlated purification framework based on semidefinite programming to restore accuracy to these noisy, unphysical two-electron RDMs. The method performs a bi-objective optimization that minimizes both the many-electron energy and the nuclear norm of the change in the measured 2-RDM. The nuclear norm, often employed in matrix completion, promotes low-rank, physically meaningful corrections to the 2-RDM, while the energy term acts as a regularization term that can improve the purity of the ground state. While the method is particularly effective for the ground state, it can also be applied to excited and non-stationary states by decreasing the weight of the energy relative to the error norm. In an application to fermionic shadow tomography of large hydrogen chains, correlated purification yields substantial reductions in both energy and 2-RDM error, achieving chemical accuracy across dissociation curves. This framework provides a robust strategy for tomography in many-body quantum simulations.

</details>


### [100] [Universal Thermodynamic Uncertainty Relation for Quantum $f-$Divergences](https://arxiv.org/abs/2511.10817)
*Domingos S. P. Salazar*

Main category: quant-ph

TL;DR: 本文证明了量子Petz f-散度具有通用的χ²混合表示，将量子态的可区分性表示为二次对比χ²_λ的正叠加，并推导出量子热力学不确定性关系的紧致通用下界。


<details>
  <summary>Details</summary>
Motivation: 研究量子f-散度的结构表示，揭示其与经典χ²散度的内在联系，为量子热力学不确定性关系提供统一的理论框架。

Method: 利用Stieltjes表示和算子凸函数理论，将f-散度分解为χ²_λ的加权和，并通过Chapman-Robbins变分表示映射到经典Pearson χ²散度。

Result: 获得了量子f-散度的通用χ²混合表示，推导出显式的权重函数w_f(λ)，并建立了紧致的量子热力学不确定性关系下界。

Conclusion: χ²_λ是量子f-散度的基本构建块，该表示统一了量子信息论和热力学中的不确定性关系，为相关领域提供了新的理论工具。

Abstract: We show that any Petz $f$-divergence (where $f$ is operator convex) between quantum states admits a universal $χ^2$-mixture representation: the distinguishability of $ρ$ from $σ$ is obtained as a positive superposition of quadratic contrasts $χ^2_λ$, with nonnegative weights $w_f(λ)$ determined explicitly from the Stieltjes representation of the generator $f$. This identifies $χ^2_λ$ as atomic building blocks for quantum $f$-divergences and yields closed-form $w_f$ for canonical choices (relative entropy/KL, Hellinger/Bures, R'{e}nyi). By mapping $χ^2_λ$ into a classical Pearson $χ^2$, we leverage the Chapman-Robbins variational representation and obtain a tight and universal quantum thermodynamic uncertainty relation: any $f$-divergence is lower bounded by a function of the statistics of quantum observables (mean and variance), reproducing previous and novel results in quantum thermodynamics as applications.

</details>


### [101] [Query complexities of quantum channel discrimination and estimation: A unified approach](https://arxiv.org/abs/2511.10832)
*Zixin Huang,Johannes Jakob Meyer,Theshani Nuradha,Mark M. Wilde*

Main category: quant-ph

TL;DR: 本文建立了量子信道判别和估计的查询复杂度下界，提出了基于等距扩展的统一分析框架。


<details>
  <summary>Details</summary>
Motivation: 量子信道判别和估计的目标是从离散或连续集合中确定未知信道的身份，需要研究其查询复杂度（即识别信道所需的最小调用次数）。

Method: 通过建立或应用信道平方Bures距离和对称对数导数Fisher信息的上界，在并行和自适应访问模型中分析查询复杂度，使用量子信道的等距扩展来简化证明。

Result: 建立了信道判别和估计的查询复杂度下界，为并行和自适应访问模型提供了统一的分析框架。

Conclusion: 提出的等距扩展框架为量子信道判别和估计提供了概念简单的证明方法，有助于解决该领域未来的问题。

Abstract: The goal of quantum channel discrimination and estimation is to determine the identity of an unknown channel from a discrete or continuous set, respectively. The query complexity of these tasks is equal to the minimum number of times one must call an unknown channel to identify it within a desired threshold on the error probability. In this paper, we establish lower bounds on the query complexities of channel discrimination and estimation, in both the parallel and adaptive access models. We do so by establishing new or applying known upper bounds on the squared Bures distance and symmetric logarithmic derivative Fisher information of channels. Phrasing our statements and proofs in terms of isometric extensions of quantum channels allows us to give conceptually simple proofs for both novel and known bounds. We also provide alternative proofs for several established results in an effort to present a consistent and unified framework for quantum channel discrimination and estimation, which we believe will be helpful in addressing future questions in the field.

</details>


### [102] [Efficient quantum Gibbs sampling of stabilizer codes using hybrid computation](https://arxiv.org/abs/2511.10839)
*Ivan H. C. Shum,Angela Capel*

Main category: quant-ph

TL;DR: 提出了混合Gibbs采样算法，用于旋转表面码和环面码的稳定子码哈密顿量，仅使用局部量子算法即可准备其Gibbs态。


<details>
  <summary>Details</summary>
Motivation: 开发高效的量子算法来准备稳定子码哈密顿量的Gibbs态，这对于量子模拟和量子计算应用具有重要意义。

Method: 使用混合Gibbs采样算法，对于旋转表面码哈密顿量使用约L/2量子电路深度，对于环面码哈密顿量使用L量子电路深度（L为方形晶格边长）。如果允许非局域门，一维周期Ising模型的Gibbs态可在对数深度和线性数量同时测量下准备。

Result: 成功实现了仅使用局部量子算法准备旋转表面码和环面码哈密顿量的Gibbs态，并展示了在非局域门条件下更高效的制备方法。

Conclusion: 该工作为稳定子码哈密顿量的Gibbs态制备提供了高效的量子算法方案，在量子电路深度方面取得了显著改进。

Abstract: We present hybrid Gibbs sampling algorithms for the stabilizer code Hamiltonians of the rotated surface code and the toric code with only local quantum algorithms, using $\sim L/2$ quantum circuit depth to prepare the Gibbs state of the rotated surface code Hamiltonian, and $L$ quantum circuit depth to prepare the Gibbs state of the toric code Hamiltonian, being $L$ the side of the side of the square lattice. We further show that if we allow for non-local gates, the Gibbs state of the periodic 1D Ising model can be prepared in logarithmic depth and linearly many simultaneous measurements.

</details>


### [103] [A New Quantum Secure Time Transfer System](https://arxiv.org/abs/2511.10847)
*Ravi Singh Adhikari,Aman Gupta,Anju Rani,Xiaoyu Ai,Robert Malaney*

Main category: quant-ph

TL;DR: 提出并实验验证了一种新的量子安全时间传输系统，用于时钟同步，能够有效防御拦截重发、欺骗和延迟等攻击。


<details>
  <summary>Details</summary>
Motivation: 当前时钟同步技术容易受到各种攻击，而量子通信、传感和定位等应用需要高精度的时钟同步，因此需要开发更安全的量子安全时间传输系统。

Method: 在混合量子/后量子架构中，优化使用自生成量子密钥来信息论安全地保护最大量的时序数据，并引入信息论安全的混淆加密序列来保护剩余时序数据。

Result: 实验证明该系统能够大幅削弱各种攻击，代表了迄今为止最鲁棒的量子安全时间传输实现。

Conclusion: 新提出的量子安全时间传输系统通过结合量子密钥和混淆加密技术，为网络分布式应用提供了高度安全的时钟同步解决方案。

Abstract: High-precision clock synchronization is essential for a wide range of network-distributed applications. In the quantum space, these applications include communication, sensing, and positioning. However, current synchronization techniques are vulnerable to attacks, such as intercept-resend attacks, spoofing, and delay attacks. Here, we propose and experimentally demonstrate a new quantum secure time transfer (QSTT) system, subsequently used for clock synchronization, that largely negates such attacks. Novel to our system is the optimal use of self-generated quantum keys within the QSTT to information-theoretically secure the maximum amount of timing data; as well as the introduction, within a hybrid quantum/post-quantum architecture, of an information-theoretic secure obfuscated encryption sequence of the remaining timing data. With these enhancements, we argue that our new system represents the most robust implementation of QSTT to date.

</details>


### [104] [Spontaneous Macroscopic Quantum Synchronization in an Ensemble of Two-level Systems](https://arxiv.org/abs/2511.10920)
*Zhen-huan Yang,Dan-Bo Zhang*

Main category: quant-ph

TL;DR: 该研究建立了二能级系统(TLS)集合的非线性量子主方程，获得了量子同步的自洽解析解，展示了耗散和相互作用如何驱动系统达到同步状态，并给出了宏观同步的相图。


<details>
  <summary>Details</summary>
Motivation: 研究自发宏观量子同步这一涌现现象，即量子振荡器集合通过相互作用和耗散的相互作用实现全局相位相干。

Method: 研究二能级系统(TLS)集合，建立相关的非线性量子主方程，获得量子同步的自洽解析解，分析布洛赫球上的轨迹，并研究不同自然频率的两个TLS组之间的同步行为。

Result: 获得了量子同步的自洽解析解，展示了耗散和相互作用驱动系统达到同步状态的轨迹，给出了宏观同步的相图，并证明了具有不同自然频率的两个TLS组之间可以实现完全同步和部分同步。

Conclusion: 该工作确立了二能级系统集合作为理解自发量子同步的重要系统。

Abstract: Spontaneous macroscopic quantum synchronization is an emergent phenomenon where an ensemble of quantum oscillators achieves global phase coherence through the interplay of interaction and dissipation. To illuminate this phenomenon, we study an ensemble of two-level systems (TLS) and establish its associated nonlinear quantum master equation, for which self-consistent analytical solutions of quantum synchronization can be obtained. The trajectories on the Bloch sphere vividly illustrate how dissipation and interaction drive the system toward a synchronized state. We present a phase diagram for macroscopic synchronization as a function of interaction strength and the gain-to-damping ratio. Furthermore, we demonstrate full synchronization and partial synchronization between two groups of TLS with different natural frequencies. This work establishes ensemble of TLS as a remarkable system for understanding spontaneous quantum synchronization.

</details>


### [105] [A Compilation Framework for Quantum Circuits with Mid-Circuit Measurement Error Awareness](https://arxiv.org/abs/2511.10921)
*Ming Zhong,Zhemin Zhang,Xiangyu Ren,Chenghong Zhu,Siyuan Niu,Zhiding Liang*

Main category: quant-ph

TL;DR: MERA是一个针对中程测量(MCM)错误的编译框架，通过误差感知的布局、路由和调度，显著提升量子电路的保真度。


<details>
  <summary>Details</summary>
Motivation: 现有编译器如Qiskit和QR-Map未考虑MCM误差的量子比特依赖性变化，导致频繁MCM操作的电路保真度大幅下降。

Method: MERA利用轻量级剖析获取稳定的每量子比特MCM误差分布，指导误差感知的量子比特映射和SWAP插入，并结合上下文感知的动态解耦调度。

Result: 在27个基准电路上，MERA相比Qiskit编译器保真度提升24.94%-52.00%，对QR-Map生成的电路平均提升29.26%，最佳情况提升122.58%。

Conclusion: MERA能有效提升MCM主导的动态电路的保真度，且不引入额外开销。

Abstract: Mid-circuit measurement (MCM) provides the capability for qubit reuse and dynamic control in quantum processors, enabling more resource-efficient algorithms and supporting error-correction procedures. However, MCM introduces several sources of error, including measurement-induced crosstalk, idling-qubit decoherence, and reset infidelity, and these errors exhibit pronounced qubit-dependent variability within a single device. Since existing compilers such as the Qiskit-compiler and QR-Map (the state-of-art qubit reuse compiler) do not account for this variability, circuits with frequent MCM operations often experience substantial fidelity loss.
  In thie paper, we propose MERA, a compilation framework that performs MCM-error-aware layout, routing, and scheduling. MERA leverages lightweight profiling to obtain a stable per-qubit MCM error distribution, which it uses to guide error-aware qubit mapping and SWAP insertions. To further mitigate MCM-related decoherence and crosstalk, MERA augments as-late-as-possible scheduling with context-aware dynamic decoupling. Evaluated on 27 benchmark circuits, MERA achieves 24.94% -- 52.00% fidelity improvement over the Qiskit compiler (optimization level 3) without introducing additional overhead. On QR-Map-generated circuits, it improves fidelity by 29.26% on average and up to 122.58% in the best case, demonstrating its effectiveness for dynamic circuits dominated by MCM operations.

</details>


### [106] [Maximizing the nondemolition nature of a quantum measurement via an adaptive readout protocol](https://arxiv.org/abs/2511.10978)
*Arjen Vaartjes,Rocky Yue Su,Laura A. O'Neill,Paul Steinacker,Gauri Goenka,Mark R. van Blankenstein,Xi Yu,Benjamin Wilhelm,Alexander M. Jakob,Fay E. Hudson,Kohei M. Itoh,Chih Hwan Yang,Andrew S. Dzurak,David N. Jamieson,Martin Nurizzo,Danielle Holmes,Arne Laucht,Andrea Morello*

Main category: quant-ph

TL;DR: 开发了一种自适应切换读取协议，通过负结果测量减少测量引起的误差，在硅中123Sb核量子比特上实现从98.93%到99.61%的读取保真度提升，同时将总读取时间减少三倍。


<details>
  <summary>Details</summary>
Motivation: 量子纠错需要非侵入性测量，但实际测量会偏离理想的量子非破坏性测量，从而干扰编码信息。需要解决测量引起的误差问题。

Method: 开发了D维系统的读取协议，在获得单个正结果后切换到仅探测剩余的D-1维子空间。这种自适应切换策略依赖不扰动哈密顿量的负结果测量结果。

Result: 在8维123Sb核量子比特上，读取保真度从(98.93±0.07)%提升到(99.61±0.04)%，总读取时间减少三倍。在10维73Ge核自旋中也观察到由超精细和四极相互作用引起的核自旋翻转。

Conclusion: 该研究揭示了非理想QND读取在不同平台上的影响，并引入了一种可在现有硬件上以最小FPGA逻辑实现的高效读取协议。

Abstract: Quantum error correction (QEC) requires non-invasive measurements for fault tolerant quantum computing. Deviations from ideal quantum non-demolition (QND) measurements can disturb the encoded information. To address this challenge, we develop a readout protocol for a $D-$dimensional system that, after a single positive outcome, switches to probing only the $D{-}1$ remaining subspace. This adaptive switching strategy minimizes measurement-induced errors by relying on negative-result measurement results that do not perturb the Hamiltonian. We apply the protocol on an 8-dimensional $^{123}{\rm Sb}$ nuclear qudit in silicon, and achieve an increase in the readout fidelity from $(98.93\pm0.07)\%$ to $(99.61\pm0.04)\%$, while reducing threefold the overall readout time. To highlight the broader relevance of measurement-induced errors, we study a 10-dimensional $^{73}{\rm Ge}$ nuclear spin read out through Pauli spin blockade, revealing nuclear spin flips arising from hyperfine and quadrupole interactions. These results unveil the effect of non-ideal QND readout across diverse platforms, and introduce an efficient readout protocol that can be implemented with minimal FPGA logic on existing hardware.

</details>


### [107] [Towards Global Quantum Key Distribution](https://arxiv.org/abs/2511.10982)
*Haoran Zhang,Haotao Zhu,Ruihua He,Yan Zhang,Chao Ding,Lajos Hanzo,Weibo Gao*

Main category: quant-ph

TL;DR: 量子密钥分发(QKD)已从实验室研究发展到商业应用，但仍面临性能限制、成本和安全挑战。卫星QKD和新协议的发展正在推动全球QKD网络的建设。


<details>
  <summary>Details</summary>
Motivation: 随着QKD从实验室走向全球应用，需要解决其实际部署中的性能、成本和安全性挑战，推动全球QKD网络的发展。

Method: 综述了QKD的实现方式，重点关注协议、设备和量子信道，讨论了实用化QKD的挑战和长距离QKD技术。

Result: 卫星QKD和新协议的发展为全球QKD网络铺平了道路，但实际应用中仍存在性能限制和安全问题需要解决。

Conclusion: QKD技术正在向全球网络发展，未来研究方向将显著推动这一目标的实现，重点关注协议创新、设备改进和信道优化。

Abstract: Quantum Key Distribution (QKD) supports the negotiation and sharing of private keys with unconditional security between authorized parties. Over the years, theoretical advances and experimental demonstrations have successfully transitioned QKD from laboratory research to commercial applications. As QKD expands its reach globally, it encounters challenges such as performance limitations, cost, and practical security concerns. Nonetheless, innovations in satellite-based QKD and the development of new protocols are paving the way towards a worldwide network. In this review, we provide an overview of QKD implementations, with a focus on protocols, devices, and quantum channels. We discuss the challenges of practical QKD and explore long-haul QKD. Additionally, we highlight the future research directions that are expected to significantly advance the realization of a global QKD network.

</details>


### [108] [Memory-Assisted Nonlocal Interferometer Towards Long-Baseline Telescopes](https://arxiv.org/abs/2511.10988)
*Bin Wang,Xi-Yu Luo,Bo-Feng Gao,Jian-Long Liu,Chao-Yang Wang,Zi Yan,Qiao-Mu Ke,Da Teng,Ming-Yang Zheng,Yuan Cao,Jun Li,Cheng-Zhi Peng,Qiang Zhang,Xiao-Hui Bao,Jian-Wei Pan*

Main category: quant-ph

TL;DR: 演示了基于量子存储器的非局域干涉仪，实现了20公里光纤基线，并能补偿1.5公里的几何延迟，为量子存储器在天文观测中的应用铺平道路。


<details>
  <summary>Details</summary>
Motivation: 量子网络和远程量子纠缠是未来量子通信的重要资源，关键方向是扩展光学干涉仪的基线以提高干涉成像的角度分辨率。

Method: 通过测量模拟热光场，构建了基于量子存储器的非局域干涉仪，利用光纤链路实现长基线干涉测量。

Result: 成功实现了20公里光纤基线，同时能够补偿1.5公里的几何延迟，展示了在光学波段利用离域单光子纠缠增强干涉成像角度分辨率的潜力。

Conclusion: 这项研究为量子存储器在天文观测中的未来应用开辟了道路，证明了长基线量子干涉测量的可行性。

Abstract: Quantum networks and remote quantum entanglement serve as vital future quantum communication resources with broad applicability. A key direction lies in extending the baseline of optical interferometers to enhance angular resolution in interferometric imaging. Here, by measuring a simulated thermal light field, we report the demonstration of a memory-assisted nonlocal interferometer achieving a fiber-link baseline up to 20 km while simultaneously showing its capability to compensate for a geometric delay equivalent to 1.5 km. This result demonstrates potential for enhancing the angular resolution of interferometric imaging in the optical band with delocalized single-photon entanglement, and paves the way for future application of quantum memories in astronomical observation.

</details>


### [109] [Unconditional and exponentially large violation of classicality](https://arxiv.org/abs/2511.11008)
*Marcello Benedetti,Gabriel Marin-Sanchez,Jordi Weggemans,Matthias Rosenkranz,Harry Buhrman*

Main category: quant-ph

TL;DR: 提出了一种基于互补采样的游戏来测试非经典性，该游戏可高效验证，并在量子与经典计算之间实现最大可能分离。在受Bernstein-Vazirani问题启发的输入限制下，该游戏无需依赖计算硬度假设即可实现指数级大的经典性违反。


<details>
  <summary>Details</summary>
Motivation: 现有测试量子力学预测的实验存在依赖复杂性理论假设、易受硬件噪声影响和验证效率低等问题，限制了其可扩展性。需要开发更高效、可验证的测试方法。

Method: 使用基于互补采样的游戏，在Quantinuum H2离子阱量子计算机上执行实验，包含数千个不同电路，最多使用55个量子比特。

Result: 在实验中观察到的分数可以通过系统采用量子策略来解释，进一步证实了硬件的量子性质。

Conclusion: 该方法提供了一种高效且可扩展的方式来验证量子硬件的非经典性质，无需依赖计算硬度假设。

Abstract: Testing the predictions of quantum mechanics has been one of the main experimental endeavors for decades. Recent advancements in technology led to a number of demonstrations which test non-classicality via specific computational tasks. Limitations of these experiments include dependence on complexity theory assumptions, susceptibility to hardware noise and inefficient verification, raising questions about their scalability. We propose to test non-classicality using a game based on complement sampling, an efficiently verifiable problem that achieves the largest possible separation between quantum and classical computation when both input and output represent samples from probability distributions. When restricting the input to instances inspired by the Bernstein-Vazirani problem, our game admits an exponentially large violation of classicality without relying on computational hardness assumptions. We execute the game on Quantinuum System Model H2 trapped-ion quantum computers, with experiments consisting of thousands of different circuits on up to 55 qubits. The observed scores can be explained by a systematic adoption of a quantum strategy, further corroborating the quantum nature of the hardware in an efficient and scalable way.

</details>


### [110] [Perfect displacement of a superconducting resonator via fast-forward scaling theory](https://arxiv.org/abs/2511.11056)
*Takaaki Aoki,Shumpei Masuda*

Main category: quant-ph

TL;DR: 基于快速前向缩放理论，通过调制驱动幅度实现超导谐振器的完美位移，并提出结合快速前向和时间缩放特性的方案，通过失谐调制实现完美位移。这些方案适用于可有效表示为驱动谐振器的子系统，特别是应用于Kerr参量振荡器之间耦合器的快速高保真位移。


<details>
  <summary>Details</summary>
Motivation: 研究超导谐振器在相干驱动下的快速前向和时间缩放特性，旨在实现谐振器的完美位移操作，这对于量子信息处理和量子计算中的快速态制备和操控具有重要意义。

Method: 提出两种方案：1) 基于快速前向缩放理论，通过调制驱动幅度实现完美位移；2) 结合快速前向和时间缩放特性，通过失谐调制实现完美位移。这些方法适用于可表示为驱动谐振器的子系统。

Result: 成功实现了超导谐振器的完美位移，并将后一种方案应用于Kerr参量振荡器之间耦合器的快速高保真位移。

Conclusion: 提出的方案能够有效实现超导谐振器的完美位移操作，特别是在量子信息处理系统中实现快速高保真的态操控，为量子计算和量子模拟提供了新的技术手段。

Abstract: We investigate the fast-forward and time-scaling properties of superconducting resonators under a coherent drive. We propose a scheme for perfect displacement of a superconducting resonator by modulating the drive amplitude based on fast-forward scaling theory. Furthermore, we propose a scheme exploiting both the fast-forward and time-scaling properties that enables perfect displacement through detuning modulation. The proposed schemes are also applicable to a subsystem that can be effectively represented by a driven resonator. In particular, we apply the latter scheme to fast and high-fidelity displacement of a coupler between Kerr parametric oscillators.

</details>


### [111] [Magnetic flux and its topological effects in Aharonov-Bohm effect](https://arxiv.org/abs/2511.11120)
*Manvendra Somvanshi,D. Jaffino Stargen*

Main category: quant-ph

TL;DR: 本文解释了Aharonov-Bohm效应中的表观非局域性，发现受限磁场在电荷的构型空间中产生穿孔，导致量子态因构型空间拓扑结构改变而获得相移。


<details>
  <summary>Details</summary>
Motivation: Aharonov-Bohm效应中带电粒子即使不与磁场相互作用也能获得相移，这种表观非局域性令人困惑且反直觉，需要解释其物理本质。

Method: 通过分析受限磁场在电荷构型空间中的作用，发现磁场在构型空间ℝ²中产生穿孔，将空间拓扑结构改变为ℝ²-{0}。

Result: 带电量子粒子的量子态获得相移是由于其对构型空间拓扑结构改变的反应，而非与磁场的直接相互作用。

Conclusion: Aharonov-Bohm效应的表观非局域性可以通过构型空间拓扑结构的改变来解释，相移源于电荷对穿孔构型空间的响应。

Abstract: The Aharonov-Bohm effect is a physical phenomenon in which the quantum state of a charged particle acquires a phase shift that is directly proportional to the magnetic flux, $Φ$, due to a (classical) magnetic field, ${\mathbf B}$, which is confined in a spatial region from which the magnetic field cannot escape. Even though the charged particle is not allowed to interact with the magnetic field, it accumulates a phase shift that affects the interference pattern produced. Not surprisingly, this apparent nonlocality is puzzling and counter intuitive. In this work, we provide an explanation that explains the physics underlying this apparent nonlocality. We find that the role of the confined magnetic field is to impart a puncture in the configuration space, $\mathbb{R}^2$, of the charge. Therefore, the quantum state corresponding to the charged quantum particle acquires the phase shift due to its response to the modified topology of the configuration space, $\mathbb{R}^2-\{0\}$, corresponding to the charge.

</details>


### [112] [Electrical thermography via centimetre-scale fiber-based distributed temperature sensing](https://arxiv.org/abs/2511.11184)
*Victor Cochet,Axel Faccio,Georgios Stoikos,Towsif Taher,Rob Thew,Jérôme Extermann,Enrico Pomarico*

Main category: quant-ph

TL;DR: 开发了一种基于拉曼散射的分布式温度传感器，可实现厘米级分辨率的电子电路热成像分析，特别适用于低温环境或红外成像无效的场景。


<details>
  <summary>Details</summary>
Motivation: 传统红外热成像在低温环境或复杂电子架构中效果有限，需要一种能够在这些条件下进行实时、空间分辨热成像的技术。

Method: 使用单模光纤在PCB板上布线，通过光学时域反射测量拉曼信号，采用超导纳米线单光子探测器检测信号，实现二维热成像。

Result: 实现了3厘米的空间分辨率和2°C的温度精度，集成时间为5分钟，可在77K低温下工作，发现PCB热阻比室温降低近一个数量级。

Conclusion: 厘米级RDTS技术为电子电路提供了强大的实时空间分辨热成像工具，特别适用于红外成像无效的低温环境和体积电子架构。

Abstract: We present a Raman-based Distributed Temperature Sensor (RDTS) with centimetre-scale resolution for thermographic analysis of electronic circuits. Temperature is measured along a single-mode fiber routed across a custom printed circuit board (PCB) with 1 cm$^2$ heating elements, using optical time-domain reflectometry of Raman signals detected by superconducting nanowire single-photon detectors (SNSPDs). This approach enables two-dimensional thermal mapping of the PCB under heating configurations with multiple hotspots. A spatial resolution of 3 cm and a temperature accuracy of 2 °C are achieved with an integration time of 5 minutes. Thermography can be performed down to 77 K, revealing that the PCB thermal resistance decreases by nearly an order of magnitude compared to room temperature, due to enhanced convective cooling in liquid nitrogen. These results establish centimetre-scale RDTS as a robust technique for real-time, spatially resolved thermography of electronic circuits, particularly in regimes where infrared imaging is ineffective, such as at low temperatures or within volumetric electronic architectures.

</details>


### [113] [The Riemann Hypothesis Emerges in Dynamical Quantum Phase Transitions](https://arxiv.org/abs/2511.11199)
*ShiJie Wei,Yue Zhai,Quanfeng Lu,Wentao Yang,Pan Gao,Chao Wei,Junda Song,Franco Nori,Tao Xin,GuiLu Long*

Main category: quant-ph

TL;DR: 该论文建立了黎曼假设与量子系统中动力学量子相变之间的直接对应关系，并通过实验验证了这种联系，为黎曼假设的量子数值验证提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 黎曼假设是数学中最深刻的未解决问题之一，建立其与物理现象的联系可以为理解其物理起源和验证提供新视角。

Method: 在两个可实现的量子系统中建立了zeta函数非平凡零点与动力学量子相变之间的精确对应关系，使用平均累积相位因子和Loschmidt振幅作为特征量，并在五量子比特自旋系统上进行了实验验证。

Result: 发现黎曼假设可以视为在特定温度下动力学量子相变的出现，提出了一个通用的量子模拟框架，能够用多项式资源高效实现这两个系统。

Conclusion: 这些发现揭示了非平衡临界动力学与黎曼假设之间的内在联系，将量子计算定位为探索这一数学猜想及其他问题的强大平台。

Abstract: The Riemann Hypothesis (RH), one of the most profound unsolved problems in mathematics, concerns the nontrivial zeros of the Riemann zeta function. Establishing connections between the RH and physical phenomena could offer new perspectives on its physical origin and verification. Here, we establish a direct correspondence between the nontrivial zeros of the zeta function and dynamical quantum phase transitions (DQPTs) in two realizable quantum systems, characterized by the averaged accumulated phase factor and the Loschmidt amplitude, respectively. This precise correspondence reveals that the RH can be viewed as the emergence of DQPTs at a specific temperature. We experimentally demonstrate this correspondence on a five-qubit spin-based system and further propose an universal quantum simulation framework for efficiently realizing both systems with polynomial resources, offering a quantum advantage for numerical verification of the RH. These findings uncover an intrinsic link between nonequilibrium critical dynamics and the RH, positioning quantum computing as a powerful platform for exploring one of mathematics' most enduring conjectures and beyond.

</details>


### [114] [Ultrafast quantum gates with fully quantized free-electron quantum optics](https://arxiv.org/abs/2511.11201)
*Yongcheng Ding*

Main category: quant-ph

TL;DR: 提出基于光栅的完全量子化自由电子量子光学架构，通过光子-电子相互作用映射到Jaynes-Cummings和Tavis-Cummings模型，设计超快单量子比特和双量子比特门，实现无腔飞行电子的通用量子计算。


<details>
  <summary>Details</summary>
Motivation: 自由电子量子光学为在量子水平上操纵电子提供了多功能平台，在量子信息技术中具有潜在应用价值。

Method: 使用光栅架构，通过Bloch-Floquet分析将光子-电子相互作用映射到Jaynes-Cummings和Tavis-Cummings模型，设计无腔飞行电子的量子门。

Result: 实现了超快单量子比特和双量子比特门，能够在实验可访问的设置中实现通用量子计算。

Conclusion: 该框架为探索自由电子量子光学和推进量子技术在模拟、传感和信息处理方面的应用建立了平台。

Abstract: Free-electron quantum optics provides a versatile platform for manipulating electrons at the quantum level with potential applications in quantum information technologies. We propose a grating-based architecture for fully quantized free-electron quantum optics, in which photon-electron interactions map onto Jaynes-Cummings and Tavis-Cummings models via Bloch-Floquet analysis. Within this framework, we design ultrafast single- and two-qubit gates with cavity-free flying electrons, enabling universal quantum computing in experimentally accessible setups. More broadly, this framework establishes a platform for probing free-electron quantum optics and advancing quantum technologies in simulation, sensing, and information processing.

</details>


### [115] [Relative entropy for locally squeezed states](https://arxiv.org/abs/2511.11203)
*Daniela Cadamuro,Markus B. Fröb,Dimitrios Katsinis,Jan Mandrysch*

Main category: quant-ph

TL;DR: 本文研究了多模压缩态与真空态之间的相对熵，发现局域压缩态虽然定义良好，但与真空态的相对熵通常发散，表明局域性与压缩之间存在严重不兼容性。


<details>
  <summary>Details</summary>
Motivation: 相对熵在量子信息理论和相对论量子场论中是状态可区分性的基本度量，但显式计算相对熵非常困难。目前仅对基态、相干态和单模压缩态有闭式结果，需要扩展到多模压缩态。

Method: 分析自由标量量子场在闵可夫斯基时空上的多模压缩态，要求压缩生成元在空间或时空上局域，从而产生连续压缩模式。连接了Wick平方本质自伴性的旧结果，并证明这些态位于闵可夫斯基真空表示的叶层中。

Result: 发现局域压缩态与真空态之间的相对熵通常发散，无论压缩多小。这表明局域压缩态虽然定义良好，但与真空态无限不同，与相干态形成鲜明对比（相干态与真空态的相对熵是有限的）。

Conclusion: 局域性与压缩之间存在严重不兼容性：局域压缩态是自由量子场状态空间中的明确定义元素，但与真空态相比是无限不同的，这揭示了量子场论中局域操作的基本限制。

Abstract: Relative entropy serves as a fundamental measure of state distinguishability in both quantum information theory and relativistic quantum field theory. Despite its conceptual importance, however, explicit computations of relative entropy remain notoriously difficult. Thus far, results in closed form have only been obtained for ground states, coherent states, and, more recently, single-mode squeezed states. In this work, we extend the analysis to multi-mode squeezed states, imposing that the squeezing generators be local either in space or in spacetime, which results in a continuum of squeezed modes. We provide a detailed and self-contained analysis of such states for a free scalar quantum field on Minkowski spacetime, connecting also with older results on the essential self-adjointness of the Wick square, and showing that they lie in the folium of the Minkowski vacuum representation. Although the local squeezing is natural from a foundational standpoint, we uncover a severe incompatibility between locality and squeezing: the relative entropy between a locally squeezed state and the vacuum generally diverges, however small the squeezing is. This shows that while locally squeezed states are well-defined elements of the state space of a free quantum field, they are infinitely different from the vacuum, in contrast to coherent states whose relative entropy with respect to the vacuum is finite.

</details>


### [116] [Efficient circuits for leaf-separable state preparation](https://arxiv.org/abs/2511.11227)
*Sunil Vittal,Anthony Wilkie,Nika Rastegari,Mostafa Atallah,Rebekah Herrman*

Main category: quant-ph

TL;DR: 提出了一种递归状态准备算法，结合对数深度的Dicke状态电路和汉明权重编码器，用于高效准备"叶可分离"量子状态。该算法基于二叉树划分、广义权重分布块和叶级编码器构建。


<details>
  <summary>Details</summary>
Motivation: 量子计算中高效状态准备是一个重要且具有挑战性的问题。需要为需要结构化输入（如Dicke或近Dicke状态）的量子算法提供可扩展的状态准备方法。

Method: 使用递归状态准备算法，结合对数深度的Dicke状态电路和汉明权重编码器。算法基于二叉树划分、广义权重分布块和叶级编码器构建。

Result: 相比需要O(2^n) CX门的一般状态准备方法，该算法实现了O(klog(n/k) + 2^k)的电路深度和O(n(k+2^k))的双量子比特门数，其中k<n表示子树大小。在4到15量子比特的随机生成目标状态上进行了数值模拟验证。

Conclusion: 该算法为需要Dicke或近Dicke状态等结构化输入的量子算法提供了可扩展的状态准备解决方案，并在电路深度和双量子比特门数方面实现了显著改进。

Abstract: Efficient state preparation is a challenging and important problem in quantum computing. In this work, we present a recursive state preparation algorithm that combines logarithmic-depth Dicke state circuits with Hamming weight encoders for efficiently preparing ``leaf-separable" quantum states. The algorithm is built on binary partition trees, generalized weight distribution blocks (gWDBs), and leaf-level encoders. We evaluate the performance of the algorithm by numerically simulating it on randomly generated target states with between 4 and 15 qubits. Compared to general state preparation approaches which require $O(2^n)$ CX gates, our algorithm achieves a circuit depth of $O(k\log\frac{n}{k} + 2^k)$ and uses $O(n(k+2^k))$ two-qubit gates, where $k < n$ denotes the subtree size. We also compare implementations of the algorithm with and without the use of ancilla qubits, providing a detailed analysis of the trade-offs in circuit depth and two-qubit gate counts. These results contribute to scalable state preparation for quantum algorithms that require structured inputs such as Dicke or near-Dicke states.

</details>


### [117] [Hyperpolarized Molecular Nuclear Spins Achieve Magnetic Amplification](https://arxiv.org/abs/2511.11242)
*Shengbang Zhou,Qing Li,Yi Ren,Jingyan Xu,Raphael Kircher,Danila A. Barskiy,Dmitry Budker,Min Jiang,Xinhua Peng*

Main category: quant-ph

TL;DR: 开发了一种基于超极化分子核自旋的新方法，实现了比现有质子磁强计和Overhauser磁强计高几个数量级的磁响应度提升，展示了线性和非线性磁放大效应。


<details>
  <summary>Details</summary>
Motivation: 核自旋作为物理传感系统的信号响应度较低，主要由于核旋磁比小和难以实现高自旋极化，需要开发新的方法来提升核自旋的磁响应能力。

Method: 使用超极化分子中的质子自旋，研究其对磁场的响应，并扩展到超极化标量耦合多自旋分子，观察磁放大效应。

Result: 实现了超过10%的显著磁放大，观察到具有色散频率依赖性的异常放大现象，源于磁干涉效应。

Conclusion: 超极化分子核自旋在量子传感器领域具有巨大潜力，可用于高精度绝对磁强测量和探索轴子-核子奇异相互作用等应用。

Abstract: The use of nuclear spins as physical sensing systems is disadvantaged by their low signal responsivity, particularly when compared to sensing techniques based on electron spins. This primarily results from the small nuclear gyromagnetic ratio and the difficulties in achieving high spin polarization. Here we develop a new approach to investigating the response of hyperpolarized molecular nuclear spins to magnetic fields and demonstrate orders-of-magnitude enhanced magnetic responsivity over state-of-the-art proton and Overhauser magnetometers. Using hyperpolarized molecules with proton spins, we report the realization of magnetic amplification in linear and nonlinear types. We further extend this amplification to hyperpolarized scalar-coupled multi-spin molecules and observe substantial magnetic amplification exceeding 10%. Moreover, we observe an anomalous amplification with dispersive frequency dependence that originates from magnetic interference effects. Our work highlights the potential of hyperpolarized molecular nuclear spins for use in a new class of quantum sensors, with promising applications in both applied and fundamental physics, including highly accurate absolute magnetometry and the exploration of axion-nucleon exotic interactions.

</details>


### [118] [Quantum limit cycles and synchronization from a measurement perspective](https://arxiv.org/abs/2511.11325)
*Tobias Nadolny,Christoph Bruder*

Main category: quant-ph

TL;DR: 该论文研究了量子极限环和同步现象，通过连续外差测量使量子极限环在量子轨迹中显现，重点关注量子van-der-Pol振荡器和两能级系统。


<details>
  <summary>Details</summary>
Motivation: 极限环振荡器是同步的基本构建模块，但量子极限环的概念一直不够清晰，需要明确量子系统中的极限环特性。

Method: 使用连续外差测量方法，分析量子轨迹（基于测量结果的量子态时间演化），研究量子van-der-Pol振荡器和两能级系统模型。

Result: 量子轨迹使量子极限环变得明显，量子极限环与受噪声影响的经典极限环具有相似性，并通过外差检测连接了量子同步的理论度量与实验可观测量。

Conclusion: 该工作深入理解了量子系统中的极限环现象，强调了量子极限环与经典极限环的相似性，并为实验观测量子同步提供了理论支持。

Abstract: Limit-cycle oscillators are the basic building blocks for synchronization; yet, the notion of a quantum limit cycle has remained unclear. Here, we study quantum limit cycles and synchronization in the presence of continuous heterodyne measurement. The resulting quantum trajectories, i.e., time evolutions of the quantum state conditioned on the measurement outcome, make the quantum limit cycles apparent. We focus on the paradigmatic model of the quantum van-der-Pol oscillator and on two-level systems. Our work provides insights into limit cycles in quantum systems, emphasizing their similarity to classical limit cycles subject to noise. Additionally, we connect theoretical measures of quantum synchronization to quantities experimentally accessible via heterodyne detection.

</details>


### [119] [Lorentz Transformation in Quantum Mechanics](https://arxiv.org/abs/2511.11342)
*Marcello Baldo*

Main category: quant-ph

TL;DR: 本文探讨了狭义相对论与量子力学的兼容性问题，通过将测量过程建模为随机过程，分析了量子力学在相对论框架下的不变性。


<details>
  <summary>Details</summary>
Motivation: 多个作者质疑狭义相对论与量子力学的兼容性，主要问题源于测量过程和波函数坍缩的引入。本文旨在通过明确描述测量过程来研究这一兼容性问题。

Method: 首先建立洛伦兹变换对时空波函数的影响，然后构建模型的相对论版本，最后通过思想实验分析量子力学在多大程度上遵循相对论不变性。

Result: 确定了量子力学可能违反相对论不变性的具体临界点，并讨论了这些分析对实验观测的相关性。

Conclusion: 通过将测量过程明确建模为随机过程，可以更清晰地识别量子力学与相对论兼容性问题的根源，为理解这一基础物理问题提供了新的视角。

Abstract: The compatibility of special relativity and Quantum Mechanics has been questioned by several authors. The origin of this tension can be traced back mainly to the introduction of the measurement processes and the corresponding wave function reduction, which play a crucial role in Quantum Mechanics. We approach this problem within a recent proposal for a model of Quantum Mechanics, where the measurement is explicitly described as a specific stochastic process. This implements ordinary Quantum Mechanics, where measurement and reduction are treated as phenomenological events of unknown origin without any physical justification. To state clearly the question, we first discuss and establish the effect of a Lorentz transformation on a generic wave function in space-time. This allows to formulate the relativistic version of the model. We then consider few thought experiments in order to analyze to what extent Quantum Mechanics follows relativistic invariance and find the specific critical points where non invariance possibly occurs. The relevance of this analysis on the experimental observations is also discussed.

</details>


### [120] [Subradiant Decay in 2D and 3D Atomic Arrays](https://arxiv.org/abs/2511.11374)
*Nicola Piovella,Romain Bachelard*

Main category: quant-ph

TL;DR: 该论文研究了二维和三维规则阵列中本征模的特性，重点关注亚辐射现象，并分析了有限尺寸效应对大阵列寿命的影响。


<details>
  <summary>Details</summary>
Motivation: 亚辐射现象中耦合发射器的辐射速率比独立发射器更慢，有序亚波长发射器阵列有望基于偶极相互作用设计高度协作的光学特性。

Method: 使用一种适用于无限和非常大系统的本征模表征方法，分析二维和三维规则阵列的本征模特性。

Result: 展示了有限尺寸效应对大阵列寿命的影响，揭示了阵列尺寸对亚辐射特性的重要影响。

Conclusion: 研究结果在量子存储器和有序原子阵列中的拓扑效应方面具有潜在应用价值。

Abstract: Subradiance is a phenomenon where coupled emitters radiate light at a slower rate than independent ones. While its observation was first reported in disordered cold atom clouds, ordered subwavelength arrays of emitters have emerged as promising platforms to design highly cooperative optical properties based on dipolar interactions. In this work we characterize the eigenmodes of 2D and 3D regular arrays, using a method which can be used for both infinite and very large systems. In particular, we show how finite-size effects impact the lifetimes of these large arrays. Our results may have interesting applications for quantum memories and topological effects in ordered atomic arrays.

</details>


### [121] [Variational Quantum Algorithms for Particle Track Reconstruction](https://arxiv.org/abs/2511.11397)
*Vincenzo Lipardi,Xenofon Chiotopoulos,Jacco A. de Vries,Domenica Dibenedetto,Kurt Driessens,Marcel Merk,Mark H. M. Winands*

Main category: quant-ph

TL;DR: 本文探讨了变分量子算法在粒子径迹重建问题中的应用，分析了两种不同的公式化方法，并使用量子架构搜索来设计量子电路。


<details>
  <summary>Details</summary>
Motivation: 量子计算在高能物理中具有解决计算挑战的潜力，本文旨在研究变分量子算法在粒子径迹重建问题中的潜力和局限性。

Method: 提出了两种公式化方法：基态能量问题和线性方程组系统，并使用基于蒙特卡洛树搜索的量子架构搜索方法来设计量子电路。

Result: 提供了针对不同问题规模的两种公式化方法的实验结果，评估了性能和计算成本。

Conclusion: 这项工作解决了变分量子算法在处理具有固定探测器几何结构的跟踪事件时的主要挑战，为量子计算在高能物理中的应用提供了有价值的探索。

Abstract: Quantum Computing is a rapidly developing field with the potential to tackle the increasing computational challenges faced in high-energy physics. In this work, we explore the potential and limitations of variational quantum algorithms in solving the particle track reconstruction problem. We present an analysis of two distinct formulations for identifying straight-line tracks in a multilayer detection system, inspired by the LHCb vertex detector. The first approach is formulated as a ground-state energy problem, while the second approach is formulated as a system of linear equations. This work addresses one of the main challenges when dealing with variational quantum algorithms on general problems, namely designing an expressive and efficient quantum ansatz working on tracking events with fixed detector geometry. For this purpose, we employed a quantum architecture search method based on Monte Carlo Tree Search to design the quantum circuits for different problem sizes. We provide experimental results to test our approach on both formulations for different problem sizes in terms of performance and computational cost.

</details>


### [122] [Bidimensional measurements of photon statistics within a multimodal temporal framework](https://arxiv.org/abs/2511.11403)
*C. Hainaut,K. Ouahrouche,A. Rancon,G. Patera,C. Ouarkoub,M. Le Parquier,P. Suret,A. Amo*

Main category: quant-ph

TL;DR: 本文开发了一种基于差频生成的二维光子统计超快成像方法，能够在皮秒分辨率下区分相干和热光子统计，并通过时间模式分解框架解释了测量偏差。


<details>
  <summary>Details</summary>
Motivation: 二维光子统计的超快成像对于探测非平衡和瞬态光学现象至关重要，但由于同时需要高时间分辨率和统计保真度，这在实验上具有挑战性。

Method: 使用非线性BBO晶体中的差频生成(DFG)进行空间分辨的单次光子数分布测量，并开发了时间模式分解框架来捕捉信号放大和荧光的基本物理过程。

Result: 平台能够在二维空间中区分相干和热光子统计，但发现提取的分布与理想分布存在偏差，这是由真空污染和放大器的多模响应造成的。

Conclusion: 建立了一种测量二维光子统计的稳健方法，同时阐明了限制此类测量保真度的基本因素。

Abstract: Ultrafast imaging of photon statistics in two dimensions is a powerful tool for probing non-equilibrium and transient optical phenomena, yet it remains experimentally challenging due to the simultaneous need for high temporal resolution and statistical fidelity. In this work, we demonstrate spatially resolved single-shot measurements of photon number distributions using difference-frequency generation (DFG) in a nonlinear BBO crystal. We show that our platform can discriminate between coherent and thermal photon statistics across two spatial dimensions with picosecond resolution. At the same time, we find that the retrieved distributions deviate from the ideal ones, a consequence of vacuum contamination and the multimodal response of the amplifier. To explain this, we develop a temporal mode decomposition framework that captures the essential physics of signal amplification and fluorescence, and quantitatively reproduces the experimental findings. This establishes a robust approach for measuring two-dimensional photon statistics while clarifying the fundamental factors that limit the fidelity of such measurements.

</details>


### [123] [Hamiltonian simulation with explicit formulas for Digital-Analog Quantum Computing](https://arxiv.org/abs/2511.11404)
*Mikel Garcia-de-Andoin,Thorge Müller,Gonzalo Camacho*

Main category: quant-ph

TL;DR: 本文提出了一个多项式时间内解决数字-模拟量子计算中哈密顿量分解问题的次优解，能够将任意双体哈密顿量表示为伊辛哈密顿量的局部幺正变换之和，所需项数最多为系统大小的二次方。


<details>
  <summary>Details</summary>
Motivation: 数字-模拟量子计算利用系统的自然相互作用哈密顿量作为纠缠资源，但设计使用最优量子资源的电路需要极大的经典计算时间。本文旨在解决这个指数级复杂问题。

Method: 提供精确解，将任意双体哈密顿量表示为任意伊辛哈密顿量的局部幺正变换之和，所需项数最多为系统大小的二次方，避免在预处理阶段对大量参数空间进行数值优化。

Result: 找到了该指数级问题的多项式时间次优解，能够设计数字-模拟仿真协议，最小化计算资源并支持进一步扩展。

Conclusion: 该方法避免了大规模参数空间的数值优化，显著减少了计算资源需求，为数字-模拟量子计算的扩展提供了可行方案。

Abstract: Digital-analog is a quantum computational paradigm that employs the natural interaction Hamiltonian of a system as the entangling resource, combined with single qubit gates, to implement universal quantum operations. As in the case of its digital gate-based counterpart, designing digital-analog circuits that employ optimal quantum resources often requires an exceedingly large classical computational time. In this work we find a suboptimal solution to this exponentially large problem, showing that it can be solved within polynomial computational time. In particular, we provide an exact solution for the problem of expressing arbitrary two-body Hamiltonians as the sum of local unitary transformations of an arbitrary Ising Hamiltonian, with the total number of required terms being at most quadratic in system size. This allows us to design a digital-analog simulation protocol that avoids employing numerical optimization over a large parameter space at the preprocessing stage, minimizing computational resources and allowing for further scaling.

</details>


### [124] [Photon correlation Fourier spectroscopy of a B center in hBN](https://arxiv.org/abs/2511.11428)
*Aymeric Delteil,Stéphanie Buil,Jean-Pierre Hermier*

Main category: quant-ph

TL;DR: 本研究使用光子相关傅里叶光谱技术，系统研究了六方氮化硼中B色心在非共振激发下的量子相干性和光谱扩散特性。


<details>
  <summary>Details</summary>
Motivation: 六方氮化硼中的B色心被认为是具有良好量子相干性的量子发射器，但之前的研究主要基于共振激发。在更易实现的非共振激发（光致发光）条件下，其相干特性尚未得到充分表征。

Method: 采用光子相关傅里叶光谱技术，在连续波激发条件下研究B色心的光致发光相干性和光谱扩散。

Result: 发现发射线形包含均匀展宽成分（线宽随激光功率增加而增大）和光谱扩散展宽（时间尺度为10-100微秒）。在低功率和短时间下，发射线宽仅比傅里叶极限宽约2倍；而在长时间下，非均匀线宽可超过1GHz。

Conclusion: 这项工作深化了对六方氮化硼中这一重要量子发射器家族退相干过程的理解。

Abstract: The potential of solid-state quantum emitters for applications critically depends on several key figures of merit. One of the most important is the quantum coherence of the emitted single photons, which can be compromised by fast dephasing and spectral diffusion. In hexagonal boron nitride (hBN), blue-emitting color centers (or B centers) are seen as favorable in this regard, in the light of prior studies mainly based on resonant excitation. Yet, their coherence properties in the more accessible regime of non-resonant excitation (or photoluminescence) has not been extensively characterized. Here, we investigate the coherence and spectral diffusion of the photoluminescence from a B center in the continuous wave regime using photon correlation Fourier spectroscopy. We determine that the emission lineshape consists in a homogeneous contribution, whose linewidth increases with the laser power, and which is broadened by spectral diffusion at a timescale of 10 to 100 microseconds. At low power and short time, the emission line is only a factor ~2 above the Fourier limit, while at long times, the inhomogeneous linewidth increases up to more than a gigahertz. Our work deepens the understanding of decoherence processes of this preeminent family of quantum emitters in hBN.

</details>


### [125] [TrackHHL: A Quantum Computing Algorithm for Track Reconstruction at the LHCb](https://arxiv.org/abs/2511.11458)
*Xenofon Chiotopoulos,Miriam Lucio Martinez,Davide Nicotra,Jacco A. de Vries,Kurt Driessens,Marcel Merk,Mark H. M. Winands*

Main category: quant-ph

TL;DR: 该论文提出了一种基于量子计算的新型带电粒子径迹重建方法，使用HHL量子算法解决矩阵反演问题，相比经典算法有望实现指数级加速，同时通过限制量子相位估计精度大幅降低电路深度。


<details>
  <summary>Details</summary>
Motivation: 在高亮度LHC时代，高能物理实验面临前所未有的计算挑战，需要开发更高效的径迹重建算法来应对海量数据处理需求。

Method: 采用Ising-like哈密顿量最小化方法，通过矩阵反演进行径迹重建。利用HHL量子算法求解线性系统，限制量子相位估计精度为1比特以大幅降低电路深度，并开发后处理算法重建事件主顶点。

Result: 经典求解矩阵反演可达到与当前最先进算法相当的效率，量子版本在满足条件的情况下有望在输入命中数上实现指数级加速，电路深度降低了10^4倍。

Conclusion: 该研究进一步阐明了量子计算在高能物理粒子径迹重建中的潜力，为未来实验数据处理提供了有前景的解决方案。

Abstract: In the future high-luminosity LHC era, high-energy physics experiments face unprecedented computational challenges for event reconstruction. Employing the LHCb vertex locator as a case study we investigate a novel approach for charged particle track reconstruction. The algorithm hinges on minimizing an Ising-like Hamiltonian using matrix inversion. Solving this matrix inversion classically achieves reconstruction efficiencies akin to current state-of-the-art algorithms. Exploiting the Harrow-Hassidim-Lloyd (HHL) quantum algorithm for linear systems holds the promise of an exponential speedup in the number of input hits over its classical counterpart, contingent on the conditions of efficient quantum phase estimation (QPE) and effectively reading out the algorithm's output. This contribution builds on previous work by Nicotra et al and strives to fulfill these conditions and further streamlines the algorithm's circuit depth by a factor up to $10^4$. Our version of the HHL algorithm restricts the QPE precision to one bit, largely reducing circuit depth and addressing HHL's readout issue. Furthermore, this allows for the implementation of a post-processing algorithm that reconstructs event Primary Vertices (PVs). The findings presented here aim to further illuminate the potential of harnessing quantum computing for the future of particle track reconstruction in high-energy physics.

</details>


### [126] [Photonic-integrated quantum sensor array for microscale magnetic localisation](https://arxiv.org/abs/2511.11496)
*Hao-Cheng Weng,John G. Rarity,Krishna C. Balram,Joe A. Smith*

Main category: quant-ph

TL;DR: 通过将氮空位中心与硅氮化物光子集成电路集成，实现了8个局部NV传感器的可扩展阵列操作，并利用机器学习方法进行多点磁场重建，展示了微米级磁定位能力。


<details>
  <summary>Details</summary>
Motivation: 利用多个NV传感器同时操作的优势，探测波动场的时空相关性或点缺陷动力学，为生物医学应用开发可扩展的多传感器平台。

Method: 将NV中心与硅氮化物光子集成电路集成，构建8个局部NV传感器阵列，采用机器学习方法进行多点磁场重建。

Result: 实验成功定位30微米针尖，定位误差低于其尺寸，并能高保真度动态跟踪；模拟验证了监测磁性微机器人位置和方向的可行性。

Conclusion: 该光子集成多传感器平台无需复杂体光学系统，为实验室外条件下的实际生物医学应用迈出了重要一步。

Abstract: Nitrogen-vacancy centres (NVs) are promising solid-state nanoscale quantum sensors for applications ranging from material science to biotechnology. Using multiple sensors simultaneously offers advantages for probing spatiotemporal correlations of fluctuating fields or the dynamics of point defects. In this work, by integrating NVs with foundry silicon-nitride photonic integrated circuits, we realise the scalable operation of eight localised NV sensors in an array, with simultaneous, distinct readout of the individual sensors. Using the eight NV sensors and machine-learning methods for multi-point magnetic field reconstruction, we demonstrate microscale magnetic localisation of a 30 $μ$m-sized needle tip. Experimentally, the needle tip can be localised with an error below its dimension and tracked dynamically with high fidelity. We further simulate the feasibility of our platform for monitoring the position and orientation of magnetic microrobots designed for biological and clinical purposes. Without the complexity of bulk optics, our photonic-integrated multi-sensor platform presents a step towards real-life biomedical applications under out-of-the-lab conditions.

</details>


### [127] [Collective Enhancement of Photon Blockade via Two-Photon Interactions](https://arxiv.org/abs/2511.11506)
*Lijuan Dong,Aanal Jayesh Shah,Peter Kirton,Hadiseh Alaeian,Simone Felicetti*

Main category: quant-ph

TL;DR: 本文研究了一种基于双光子耦合的集体增强光子阻塞效应，展示了通过增加原子数量可以增强单光子和多光子阻塞，突破了传统光子阻塞需要强光-物质耦合的限制。


<details>
  <summary>Details</summary>
Motivation: 传统光子阻塞需要实现强光-物质耦合，但增加原子数量无法增强反聚束效应。本文旨在探索通过双光子耦合机制实现集体增强的光子阻塞，为在无法实现个体强耦合的平台中产生量子光态提供新途径。

Method: 结合近似解析方法和全量子数值模拟，分析嵌入双光子耦合发射体集合的量子谐振器的光学传输特性，提出了不同的驱动方案来抑制二阶和三阶关联函数。

Result: 当光与物质通过双光子相互作用耦合时，单光子和多光子阻塞都能受益于集体增强。随着原子数量的增加，二阶和三阶关联函数被强烈抑制，且这种集体增强发生在具有单位传输的情况下。

Conclusion: 集体双光子耦合是实现光子阻塞的强大机制，即使在无法实现个体强耦合的平台中也能有效工作，最终限制仅来自退相干效应。

Abstract: Analogous to Coulomb blockade for electrons, photon blockade is a key quantum optical effect in which the presence of one photon prevents the transmission of subsequent ones through a nonlinear medium. Beyond its fundamental interest, photon and multi-photon blockade are actively studied as mechanisms for generating technologically-relevant quantum states of light. Although photon blockade typically requires achieving strong light-matter coupling, increasing the number of atoms fails to enhance antibunching. Here, we analyze the optical transmission properties of a quantum resonator that embeds a two-photon-coupled ensemble of emitters, combining an approximate analytical approach with full quantum numerical simulations. We show that when light and matter are coupled via a two-photon interaction, both single- and multi-photon blockade can benefit from a collective enhancement. We propose different driving schemes in which the second or third-order correlation functions are strongly suppressed with increasing atom number. Differently from established methods, this collective enhancement of non-classical properties occurs with unitary transmission and is ultimately constrained only by decoherence. This demonstrates that collective two-photon couplings are a powerful mechanism for realizing photon blockade even in platforms where individual strong coupling is not achievable.

</details>


### [128] [Efficient computation of quantum time-optimal control](https://arxiv.org/abs/2511.11508)
*Andrei A. Stepanenko,Kseniia S. Chernova,Maxim A. Gorlach*

Main category: quant-ph

TL;DR: 提出了一种结合量子最速曲线和Lax对技术的方法，用于计算量子系统的时间最优控制，能够高效研究大规模量子系统。


<details>
  <summary>Details</summary>
Motivation: 为了在大规模量子系统中找到时间最优的控制策略，特别是在固定耦合强度平方和约束下实现量子态的最快转移。

Method: 结合量子最速曲线方法和Lax对技术，通过分析量子系统的动力学特性来寻找最优控制路径。

Result: 成功应用于无限大量子比特晶格中单粒子激发的最快转移问题，在固定耦合强度平方和约束下找到了最优控制方案。

Conclusion: 该方法为大规模量子系统的时间最优控制提供了有效的计算框架，能够处理传统方法难以应对的系统规模。

Abstract: We present an approach to compute time-optimal control of a quantum system which combines quantum brachistochrone and Lax pair techniques and enables efficient investigation of large-scale quantum systems. We illustrate our method by finding the fastest way to transfer a single-particle excitation in a nearest-neighbor-coupled infinitely large qubit lattice with the fixed sum of squares of the couplings.

</details>


### [129] [Vector magnetometry using cavity-enhanced microwave readout in nitrogen-vacancy diamond](https://arxiv.org/abs/2511.11561)
*Reginald Wilcox,David Phillips,Matthew Steinecker,Erik Eisenach,Corey Hawkins,Linh Pham,Jennifer Schloss,Dirk Englund,Danielle Braje*

Main category: quant-ph

TL;DR: 使用金刚石中氮空位中心与微波腔耦合实现4π立体角矢量磁场传感，通过微波腔增强自旋-光子耦合，实现高效高对比度自旋态读取，无需笨重光学收集组件。


<details>
  <summary>Details</summary>
Motivation: 传统光学读取方法需要笨重的光学收集组件，且对比度较低。微波腔耦合可以增强自旋-光子耦合，提高读取效率和对比度，同时实现全空间矢量磁场测量。

Method: 利用微波腔增强氮空位中心的自旋-光子耦合，通过施加交流偏置磁场解除四个晶体学NV取向的零场简并，实现各取向的独立寻址和矢量磁场重建。

Result: 磁强计达到40%的对比度（比典型光学自旋系综读取高20倍），单轴灵敏度为250 pT/√Hz，在DC到1 kHz范围内保持平坦。微波幅度噪声是主要噪声源，热噪声极限预测为2 pT/√Hz。

Conclusion: 微波腔耦合的NV中心系统实现了高效的全空间矢量磁场传感，具有高对比度和良好灵敏度，为紧凑型高精度磁强计提供了可行方案。

Abstract: We demonstrate $4π$-steradian vector magnetic field sensing using an ensemble of nitrogen-vacancy (NV) centers in a single-crystal diamond coupled to a microwave (MW) cavity. The MW cavity enhances the spin-photon coupling which enables efficient, high-contrast spin-state readout via MW interrogation and removes the need for bulky optical collection components. An applied AC bias magnetic field lifts the zero-field degeneracy of the four crystallographic NV orientations, allowing each orientation to be individually addressed and used for vector reconstruction of the magnetic field. The resulting magnetometer has a 40\% contrast (20x higher than typical for optical spin-ensemble readout) and achieves a single-axis sensitivity of 250 pT/$\sqrt{\mathrm{Hz}}$ which is flat from DC to 1 kHz. Noise models of the composite spin-cavity system establish MW amplitude noise as the dominant noise source and predict a thermal noise limit of 2 pT/$\sqrt{\mathrm{Hz}}$.

</details>
