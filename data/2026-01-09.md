<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 78]
- [gr-qc](#gr-qc) [Total: 14]
- [quant-ph](#quant-ph) [Total: 47]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [The Forgotten Shield: Safety Grafting in Parameter-Space for Medical MLLMs](https://arxiv.org/abs/2601.04199)
*Jiale Zhao,Xing Mou,Jinlin Wu,Hongyuan Yu,Mingrui Sun,Yang Shi,Xuanwu Yin,Zhen Chen,Zhen Lei,Yaohua Wang*

Main category: cs.LG

TL;DR: 该论文针对医疗多模态大语言模型的安全性问题，建立了多维评估框架，发现现有模型存在普遍脆弱性，并提出了一种参数空间干预方法进行安全再对齐。


<details>
  <summary>Details</summary>
Motivation: 医疗多模态大语言模型在专业医疗任务上取得了显著进展，但其安全性研究滞后，存在实际部署风险。需要系统评估现有模型的安全漏洞，并解决医疗微调过程中导致的安全对齐遗忘问题。

Method: 首先建立多维评估框架系统评估SOTA医疗MLLMs的安全性。然后提出"参数空间干预"方法，从原始基础模型中提取内在安全知识表示，并在构建医疗能力时同时注入目标模型。还设计了细粒度参数搜索算法，在安全性和医疗性能之间实现最优权衡。

Result: 实证分析显示现有模型在通用和医疗特定安全维度上都存在普遍脆弱性，特别是对跨模态越狱攻击的脆弱性。医疗微调过程经常导致模型原始安全对齐的灾难性遗忘。提出的方法显著增强了医疗MLLMs的安全防护，无需额外领域特定安全数据，同时最小化核心医疗性能的下降。

Conclusion: 该研究揭示了医疗MLLMs的安全脆弱性，并提出了一种有效的安全再对齐方法，为医疗AI系统的安全部署提供了重要保障。

Abstract: Medical Multimodal Large Language Models (Medical MLLMs) have achieved remarkable progress in specialized medical tasks; however, research into their safety has lagged, posing potential risks for real-world deployment. In this paper, we first establish a multidimensional evaluation framework to systematically benchmark the safety of current SOTA Medical MLLMs. Our empirical analysis reveals pervasive vulnerabilities across both general and medical-specific safety dimensions in existing models, particularly highlighting their fragility against cross-modality jailbreak attacks. Furthermore, we find that the medical fine-tuning process frequently induces catastrophic forgetting of the model's original safety alignment. To address this challenge, we propose a novel "Parameter-Space Intervention" approach for efficient safety re-alignment. This method extracts intrinsic safety knowledge representations from original base models and concurrently injects them into the target model during the construction of medical capabilities. Additionally, we design a fine-grained parameter search algorithm to achieve an optimal trade-off between safety and medical performance. Experimental results demonstrate that our approach significantly bolsters the safety guardrails of Medical MLLMs without relying on additional domain-specific safety data, while minimizing degradation to core medical performance.

</details>


### [2] [Green MLOps: Closed-Loop, Energy-Aware Inference with NVIDIA Triton, FastAPI, and Bio-Inspired Thresholding](https://arxiv.org/abs/2601.04250)
*Mustapha Hamdi,Mourad Jabou*

Main category: cs.LG

TL;DR: 论文提出一种受生物启发的框架，将蛋白质折叠能量盆地映射到推理成本景观，通过衰减闭环阈值控制执行，仅在预期效用-能量权衡有利时处理请求，从而显著降低处理时间。


<details>
  <summary>Details</summary>
Motivation: AI部署中的能源效率是首要关注点，因为长期运行的推理累积碳排放可能超过训练阶段。需要开发能够减少推理能耗的实用方法。

Method: 提出受生物启发的框架，将蛋白质折叠能量盆地映射到推理成本景观，通过衰减闭环阈值控制执行。请求仅在预期效用-能量权衡有利时被接受（高置信度/效用、低边际能量和拥塞），偏向于第一个可接受的局部盆地而非追求代价高昂的全局最小值。

Result: 生物控制器相比标准开环执行减少42%处理时间（A100测试集上从0.50s降至0.29s），精度损失小于0.5%。建立了轻量级本地服务（ORT）与托管批处理（Triton）之间的效率边界。

Conclusion: 该研究将生物物理能量模型与绿色MLOps连接起来，为生产环境中闭环能源感知推理提供了实用且可审计的基础。

Abstract: Energy efficiency is a first-order concern in AI deployment, as long-running inference can exceed training in cumulative carbon impact. We propose a bio-inspired framework that maps protein-folding energy basins to inference cost landscapes and controls execution via a decaying, closed-loop threshold. A request is admitted only when the expected utility-to-energy trade-off is favorable (high confidence/utility at low marginal energy and congestion), biasing operation toward the first acceptable local basin rather than pursuing costly global minima. We evaluate DistilBERT and ResNet-18 served through FastAPI with ONNX Runtime and NVIDIA Triton on an RTX 4000 Ada GPU. Our ablation study reveals that the bio-controller reduces processing time by 42% compared to standard open-loop execution (0.50s vs 0.29s on A100 test set), with a minimal accuracy degradation (<0.5%). Furthermore, we establish the efficiency boundaries between lightweight local serving (ORT) and managed batching (Triton). The results connect biophysical energy models to Green MLOps and offer a practical, auditable basis for closed-loop energy-aware inference in production.

</details>


### [3] [Safety-Utility Conflicts Are Not Global: Surgical Alignment via Head-Level Diagnosis](https://arxiv.org/abs/2601.04262)
*Wang Cai,Yilin Wen,Jinchang Hou,Du Su,Guoqiu Wang,Zhonghou Lv,Chenfu Bao,Yunfang Wu*

Main category: cs.LG

TL;DR: CAST框架通过识别和跳过Transformer中高冲突注意力头，在保持安全性的同时减少通用能力下降，提供参数高效的稀疏微调方法。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型安全对齐方法采用全局梯度几何，忽视了Transformer模块异质性——不同注意力头的功能敏感性和冲突程度差异很大，导致次优权衡。

Method: 提出冲突感知稀疏调优(CAST)：1) 构建预对齐冲突图，综合优化冲突和功能敏感性；2) 基于冲突图选择性更新参数，跳过高冲突注意力头。

Result: 实验发现对齐冲突在LLMs中分布不均，通用能力下降主要来自更新一小部分高冲突头。跳过这些头能显著减少能力损失而不影响安全性。

Conclusion: CAST提供了一种可解释且参数高效的方法来改善安全性与通用能力之间的权衡，通过稀疏微调和选择性更新解决模块异质性问题。

Abstract: Safety alignment in Large Language Models (LLMs) inherently presents a multi-objective optimization conflict, often accompanied by an unintended degradation of general capabilities. Existing mitigation strategies typically rely on global gradient geometry to resolve these conflicts, yet they overlook Modular Heterogeneity within Transformers, specifically that the functional sensitivity and degree of conflict vary substantially across different attention heads. Such global approaches impose uniform update rules across all parameters, often resulting in suboptimal trade-offs by indiscriminately updating utility sensitive heads that exhibit intense gradient conflicts. To address this limitation, we propose Conflict-Aware Sparse Tuning (CAST), a framework that integrates head-level diagnosis with sparse fine-tuning. CAST first constructs a pre-alignment conflict map by synthesizing Optimization Conflict and Functional Sensitivity, which then guides the selective update of parameters. Experiments reveal that alignment conflicts in LLMs are not uniformly distributed. We find that the drop in general capabilities mainly comes from updating a small group of ``high-conflict'' heads. By simply skipping these heads during training, we significantly reduce this loss without compromising safety, offering an interpretable and parameter-efficient approach to improving the safety-utility trade-off.

</details>


### [4] [Learning to Reason: Temporal Saliency Distillation for Interpretable Knowledge Transfer](https://arxiv.org/abs/2601.04263)
*Nilushika Udayangani Hewa Dehigahawattage,Kishor Nandakishor,Marimuthu Palaniswami*

Main category: cs.LG

TL;DR: 本文提出了一种用于时间序列分析的Temporal Saliency Distillation方法，通过传递教师模型的时间显著性知识（而非仅预测结果），使学生模型不仅学习正确预测，还学习正确的推理过程。


<details>
  <summary>Details</summary>
Motivation: 当前时间序列知识蒸馏主要基于计算机视觉任务开发的logit和特征对齐技术，存在两个关键问题：1）由于logits和特征的可解释性差，转移知识如何帮助学生模型学习的过程不明确；2）这些方法仅传递有限知识，主要复制教师预测准确性，导致学生模型的预测分布与教师模型显著不同，阻碍其安全替代教师模型。

Method: 提出Temporal Saliency Distillation方法，从教师logits中提取时间显著性知识，捕捉每个输入时间步对教师预测的重要性。通过训练学生模型使用时间显著性蒸馏，鼓励其基于与教师相同的输入特征进行预测。该方法无需额外参数或特定架构假设。

Result: Temporal Saliency Distillation有效提高了基线方法的性能，同时实现了超越预测准确性的理想特性。学生模型不仅预测更准确，而且推理过程与教师模型更一致。

Conclusion: 该工作为时间序列分析中的可解释知识蒸馏建立了新范式，通过传递可解释的时间显著性知识，使学生模型能够学习教师的正确推理过程，而不仅仅是预测结果。

Abstract: Knowledge distillation has proven effective for model compression by transferring knowledge from a larger network called the teacher to a smaller network called the student. Current knowledge distillation in time series is predominantly based on logit and feature aligning techniques originally developed for computer vision tasks. These methods do not explicitly account for temporal data and fall short in two key aspects. First, the mechanisms by which the transferred knowledge helps the student model learning process remain unclear due to uninterpretability of logits and features. Second, these methods transfer only limited knowledge, primarily replicating the teacher predictive accuracy. As a result, student models often produce predictive distributions that differ significantly from those of their teachers, hindering their safe substitution for teacher models. In this work, we propose transferring interpretable knowledge by extending conventional logit transfer to convey not just the right prediction but also the right reasoning of the teacher. Specifically, we induce other useful knowledge from the teacher logits termed temporal saliency which captures the importance of each input timestep to the teacher prediction. By training the student with Temporal Saliency Distillation we encourage it to make predictions based on the same input features as the teacher. Temporal Saliency Distillation requires no additional parameters or architecture specific assumptions. We demonstrate that Temporal Saliency Distillation effectively improves the performance of baseline methods while also achieving desirable properties beyond predictive accuracy. We hope our work establishes a new paradigm for interpretable knowledge distillation in time series analysis.

</details>


### [5] [MemKD: Memory-Discrepancy Knowledge Distillation for Efficient Time Series Classification](https://arxiv.org/abs/2601.04264)
*Nilushika Udayangani,Kishor Nandakishor,Marimuthu Palaniswami*

Main category: cs.LG

TL;DR: 提出MemKD框架，通过捕捉教师和学生模型在时间序列子序列间的记忆保留差异，实现高效的知识蒸馏，使小型RNN模型在保持性能的同时大幅减少计算资源需求。


<details>
  <summary>Details</summary>
Motivation: 现有知识蒸馏方法主要针对计算机视觉任务设计，忽略了时间序列模型特有的时间依赖性和记忆保留特性，导致在资源受限环境下部署深度学习模型时效果不佳。

Method: 提出Memory-Discrepancy Knowledge Distillation (MemKD)框架，使用专门的损失函数来捕捉教师和学生模型在时间序列子序列间的记忆保留差异，确保学生模型有效模仿教师模型的行为。

Result: MemKD显著优于现有知识蒸馏方法，能将参数大小和内存使用减少约500倍，同时保持与教师模型相当的性能。

Conclusion: MemKD为资源受限环境下的实时时间序列分析任务提供了一种有效的解决方案，能够开发出紧凑且高性能的循环神经网络模型。

Abstract: Deep learning models, particularly recurrent neural networks and their variants, such as long short-term memory, have significantly advanced time series data analysis. These models capture complex, sequential patterns in time series, enabling real-time assessments. However, their high computational complexity and large model sizes pose challenges for deployment in resource-constrained environments, such as wearable devices and edge computing platforms. Knowledge Distillation (KD) offers a solution by transferring knowledge from a large, complex model (teacher) to a smaller, more efficient model (student), thereby retaining high performance while reducing computational demands. Current KD methods, originally designed for computer vision tasks, neglect the unique temporal dependencies and memory retention characteristics of time series models. To this end, we propose a novel KD framework termed Memory-Discrepancy Knowledge Distillation (MemKD). MemKD leverages a specialized loss function to capture memory retention discrepancies between the teacher and student models across subsequences within time series data, ensuring that the student model effectively mimics the teacher model's behaviour. This approach facilitates the development of compact, high-performing recurrent neural networks suitable for real-time, time series analysis tasks. Our extensive experiments demonstrate that MemKD significantly outperforms state-of-the-art KD methods. It reduces parameter size and memory usage by approximately 500 times while maintaining comparable performance to the teacher model.

</details>


### [6] [Making Tunable Parameters State-Dependent in Weather and Climate Models with Reinforcement Learning](https://arxiv.org/abs/2601.04268)
*Pritthijit Nath,Sebastian Schemm,Henry Moss,Peter Haynes,Emily Shuckburgh,Mark J. Webb*

Main category: cs.LG

TL;DR: 本研究提出一个使用强化学习在线学习参数化方案组件的框架，在多个理想化测试平台上评估，发现TQC、DDPG和TD3算法表现最佳，单智能体和联邦多智能体设置均能有效改进模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统天气和气候模型依赖固定系数的参数化方案，这些系数约束弱且离线调优，导致持续偏差，限制了模型适应底层物理过程的能力。需要开发能够在线学习、随模型状态演化的参数化方案。

Method: 使用强化学习框架在线学习参数化方案组件，在三个理想化测试平台评估：简单气候偏差校正（SCBC）、辐射对流平衡（RCE）和纬向平均能量平衡模型（EBM）。测试了九种RL算法，包括单智能体和联邦多智能体设置，使用面积加权RMSE、温度剖面和气压层诊断进行评估。

Result: TQC、DDPG和TD3算法在配置中表现出最高技能和最稳定的收敛性。对于EBM，单智能体RL优于静态参数调优，在热带和中纬度带改进最明显；联邦多智能体设置实现了地理专业化控制和更快收敛，六智能体DDPG配置在热带和中纬度带获得最低面积加权RMSE。学习到的修正具有物理意义，能够减少经向偏差、匹配垂直温度误差并限制漂移。

Conclusion: 强化学习能够提供技能高超、状态依赖和机制感知的参数化方案，为数值模型中的在线学习提供了可扩展的途径。

Abstract: Weather and climate models rely on parametrisations to represent unresolved sub-grid processes. Traditional schemes rely on fixed coefficients that are weakly constrained and tuned offline, contributing to persistent biases that limit their ability to adapt to the underlying physics. This study presents a framework that learns components of parametrisation schemes online as a function of the evolving model state using reinforcement learning (RL) and evaluates the resulting RL-driven parameter updates across a hierarchy of idealised testbeds spanning a simple climate bias correction (SCBC), a radiative-convective equilibrium (RCE), and a zonal mean energy balance model (EBM) with both single-agent and federated multi-agent settings. Across nine RL algorithms, Truncated Quantile Critics (TQC), Deep Deterministic Policy Gradient (DDPG), and Twin Delayed DDPG (TD3) achieved the highest skill and the most stable convergence across configurations, with performance assessed against a static baseline using area-weighted RMSE, temperature profile and pressure-level diagnostics. For the EBM, single-agent RL outperformed static parameter tuning with the strongest gains in tropical and mid-latitude bands, while federated RL on multi-agent setups enabled geographically specialised control and faster convergence, with a six-agent DDPG configuration using frequent aggregation yielding the lowest area-weighted RMSE across the tropics and mid-latitudes. The learnt corrections were also physically meaningful as agents modulated EBM radiative parameters to reduce meridional biases, adjusted RCE lapse rates to match vertical temperature errors, and stabilised SCBC heating increments to limit drift. Overall, results highlight RL to deliver skilful state-dependent, and regime-aware parametrisations, offering a scalable pathway for online learning within numerical models.

</details>


### [7] [Predictable Gradient Manifolds in Deep Learning: Temporal Path-Length and Intrinsic Rank as a Complexity Regime](https://arxiv.org/abs/2601.04270)
*Anherutowa Calvo*

Main category: cs.LG

TL;DR: 本文提出可测量框架分析深度学习优化中的可预测梯度流形，引入预测路径长度和可预测秩两个可计算量，证明收敛性和遗憾可依赖这些量而非最坏情况变化，实验显示梯度轨迹具有局部可预测性和低秩结构。


<details>
  <summary>Details</summary>
Motivation: 深度学习优化展现出无法用最坏情况梯度界捕捉的结构特征。经验上，训练轨迹中的梯度通常具有时间可预测性，并在低维子空间中演化。本文旨在通过可测量框架形式化这一观察。

Method: 引入两个可计算量：预测路径长度（衡量梯度从过去信息预测的能力）和可预测秩（量化梯度增量的内在时间维度）。展示经典在线和非凸优化保证可重述为依赖这些量而非最坏情况变化。使用轻量级随机投影从记录梯度中诊断这些性质。

Result: 在卷积网络、视觉Transformer、语言模型和合成控制任务中，发现梯度轨迹具有局部可预测性和随时间变化的强低秩结构。这些性质在不同架构和优化器间稳定存在。

Conclusion: 结果为理解现代深度学习中的优化动态提供了统一视角，将标准训练重新定义为在低复杂度时间机制中运行。这一视角为自适应优化器、秩感知跟踪和基于预测的算法设计提供了新方向。

Abstract: Deep learning optimization exhibits structure that is not captured by worst-case gradient bounds. Empirically, gradients along training trajectories are often temporally predictable and evolve within a low-dimensional subspace. In this work we formalize this observation through a measurable framework for predictable gradient manifolds.
  We introduce two computable quantities: a prediction-based path length that measures how well gradients can be forecast from past information, and a predictable rank that quantifies the intrinsic temporal dimension of gradient increments. We show how classical online and nonconvex optimization guarantees can be restated so that convergence and regret depend explicitly on these quantities, rather than on worst-case variation.
  Across convolutional networks, vision transformers, language models, and synthetic control tasks, we find that gradient trajectories are locally predictable and exhibit strong low-rank structure over time. These properties are stable across architectures and optimizers, and can be diagnosed directly from logged gradients using lightweight random projections.
  Our results provide a unifying lens for understanding optimization dynamics in modern deep learning, reframing standard training as operating in a low-complexity temporal regime. This perspective suggests new directions for adaptive optimizers, rank-aware tracking, and prediction-based algorithm design grounded in measurable properties of real training runs.

</details>


### [8] [Unlocking the Pre-Trained Model as a Dual-Alignment Calibrator for Post-Trained LLMs](https://arxiv.org/abs/2601.04277)
*Beier Luo,Cheng Wang,Hongxin Wei,Sharon Li,Xuefeng Du*

Main category: cs.LG

TL;DR: 本文提出Dual-Align框架，通过双重对齐（置信度对齐和过程对齐）来解决后训练语言模型的校准问题，使用单一温度参数同时纠正置信度漂移和过程漂移。


<details>
  <summary>Details</summary>
Motivation: 后训练虽然提升了大语言模型的性能，但往往导致置信度校准恶化，使模型变得过度自信。现有的无监督后处理方法仅关注静态输出分布匹配，忽视了后训练引入的推理时动态变化。

Method: 提出Dual-Align框架，包含两个对齐：1) 置信度对齐：通过最终分布匹配纠正置信度漂移；2) 过程对齐：定位轨迹分叉层并重新对齐后续推理稳定性。该方法学习单一温度参数来同时纠正两种漂移类型。

Result: 实验显示Dual-Align在基准测试中持续改进，显著减少校准误差，接近有监督oracle方法的性能，同时不牺牲后训练带来的性能增益。

Conclusion: 通过诊断校准误差的两种来源（置信度漂移和过程漂移），提出的双重对齐框架能有效解决后训练语言模型的校准问题，为无监督校准提供了新思路。

Abstract: Post-training improves large language models (LLMs) but often worsens confidence calibration, leading to systematic overconfidence. Recent unsupervised post-hoc methods for post-trained LMs (PoLMs) mitigate this by aligning PoLM confidence to that of well-calibrated pre-trained counterparts. However, framing calibration as static output-distribution matching overlooks the inference-time dynamics introduced by post-training. In particular, we show that calibration errors arise from two regimes: (i) confidence drift, where final confidence inflates despite largely consistent intermediate decision processes, and (ii) process drift, where intermediate inference pathways diverge. Guided by this diagnosis, we propose Dual-Align, an unsupervised post-hoc framework for dual alignment in confidence calibration. Dual-Align performs confidence alignment to correct confidence drift via final-distribution matching, and introduces process alignment to address process drift by locating the layer where trajectories diverge and realigning the stability of subsequent inference. This dual strategy learns a single temperature parameter that corrects both drift types without sacrificing post-training performance gains. Experiments show consistent improvements over baselines, reducing calibration errors and approaching a supervised oracle.

</details>


### [9] [Generation of synthetic delay time series for air transport applications](https://arxiv.org/abs/2601.04279)
*Pau Esteve,Massimiliano Zanin*

Main category: cs.LG

TL;DR: 本文比较了三种生成机场延误时间序列的合成数据方法，发现简化遗传算法能生成与真实数据几乎无法区分且保持高变异性的时间序列，并验证了其在检测机场间延误传播问题中的应用。


<details>
  <summary>Details</summary>
Motivation: 解决机场延误数据稀缺和隐私问题，为航空运输领域提供合成数据生成方案。合成数据生成在科学界越来越受关注，但在航空运输领域的应用刚开始。

Method: 比较了三种模型：两种基于深度学习算法，一种采用简化的遗传算法方法。使用欧洲和美国的大量航班运营数据作为基础，生成机场延误时间序列的合成数据。

Result: 简化遗传算法生成的延误时间序列与真实数据几乎无法区分，同时保持了高变异性。合成数据在检测机场间延误传播问题上得到验证，证明其有效性。

Conclusion: 简化遗传算法是生成机场延误合成数据的有效方法，生成的合成数据已向科学界公开，可用于进一步研究和应用。

Abstract: The generation of synthetic data is receiving increasing attention from the scientific community, thanks to its ability to solve problems like data scarcity and privacy, and is starting to find applications in air transport. We here tackle the problem of generating synthetic, yet realistic, time series of delays at airports, starting from large collections of operations in Europe and the US. We specifically compare three models, two of them based on state of the art Deep Learning algorithms, and one simplified Genetic Algorithm approach. We show how the latter can generate time series that are almost indistinguishable from real ones, while maintaining a high variability. We further validate the resulting time series in a problem of detecting delay propagations between airports. We finally make the synthetic data available to the scientific community.

</details>


### [10] [LEGATO: Good Identity Unlearning Is Continuous](https://arxiv.org/abs/2601.04282)
*Qiang Chen,Chun-Wun Cheng,Xiu Su,Hongyan Xu,Xi Lin,Shan You,Angelica I. Aviles-Rivero,Yi Chen*

Main category: cs.LG

TL;DR: LEGATO提出了一种基于神经ODE的连续轨迹方法，用于生成模型的身份遗忘，通过轻量级适配器实现可控遗忘，避免灾难性崩溃并减少微调参数。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法面临三个挑战：1) 效率低下，身份擦除需要微调所有模型参数；2) 可控性有限，遗忘强度无法控制且缺乏可解释性；3) 灾难性崩溃，随着遗忘进行，模型保留能力急剧下降。遗忘通常通过离散不稳定更新处理，需要全模型微调并导致灾难性崩溃。

Method: LEGATO将身份遗忘建模为连续轨迹，使用轨迹一致的神经ODE。方法为预训练生成器添加可微调的轻量级神经ODE适配器，实现平滑可控遗忘，同时保持原始模型权重冻结。通过ODE步长精确调节遗忘强度，提供可解释性和鲁棒性。引入轨迹一致性约束防止遗忘过程中的灾难性崩溃。

Result: 在领域内和领域外身份遗忘基准测试中，LEGATO实现了最先进的遗忘性能，避免了灾难性崩溃，并显著减少了需要微调的参数量。

Conclusion: LEGATO通过将身份遗忘建模为连续轨迹，使用神经ODE适配器，解决了现有机器遗忘方法的效率、可控性和稳定性问题，为生成模型的身份遗忘提供了有效解决方案。

Abstract: Machine unlearning has become a crucial role in enabling generative models trained on large datasets to remove sensitive, private, or copyright-protected data. However, existing machine unlearning methods face three challenges in learning to forget identity of generative models: 1) inefficient, where identity erasure requires fine-tuning all the model's parameters; 2) limited controllability, where forgetting intensity cannot be controlled and explainability is lacking; 3) catastrophic collapse, where the model's retention capability undergoes drastic degradation as forgetting progresses. Forgetting has typically been handled through discrete and unstable updates, often requiring full-model fine-tuning and leading to catastrophic collapse. In this work, we argue that identity forgetting should be modeled as a continuous trajectory, and introduce LEGATO - Learn to ForgEt Identity in GenerAtive Models via Trajectory-consistent Neural Ordinary Differential Equations. LEGATO augments pre-trained generators with fine-tunable lightweight Neural ODE adapters, enabling smooth, controllable forgetting while keeping the original model weights frozen. This formulation allows forgetting intensity to be precisely modulated via ODE step size, offering interpretability and robustness. To further ensure stability, we introduce trajectory consistency constraints that explicitly prevent catastrophic collapse during unlearning. Extensive experiments across in-domain and out-of-domain identity unlearning benchmarks show that LEGATO achieves state-of-the-art forgetting performance, avoids catastrophic collapse and reduces fine-tuned parameters.

</details>


### [11] [Mitigating Position-Shift Failures in Text-Based Modular Arithmetic via Position Curriculum and Template Diversity](https://arxiv.org/abs/2601.04283)
*Nikolay Yudin*

Main category: cs.LG

TL;DR: 研究字符级Transformer在模加法任务中的鲁棒性问题，发现即使模型在分布内准确率高，但在位置偏移和模板分布外情况下会灾难性失败，提出结合边界标记、位置课程、多样模板和一致性训练的方法来提升鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注分布内准确性，但忽略了模型在输入格式变化下的鲁棒性。本文旨在研究字符级Transformer在模加法任务中面对位置偏移和自然语言模板分布外变化时的脆弱性，并提出解决方案。

Method: 1) 使用显式表达式边界标记；2) 位置课程训练，扩大训练期间看到的绝对位置范围；3) 多样模板混合；4) 每个示例跨多个变体的一致性训练。在p=97的模加法任务上评估，使用不相交对分割。

Result: 基线模型在分布内表现良好，但在位置偏移和模板分布外情况下崩溃。提出的训练方法显著提高了对位置偏移和模板分布外的鲁棒性，同时保持高分布内准确性。ALiBi风格的消融实验在本设置下无法学习任务。

Conclusion: 在噪声监督下引导程序泛化需要显式训练数据分布中不存在的恒定性。研究提供了可重复的评估协议和实验成果，强调了训练输入不变性的重要性。

Abstract: Building on insights from the grokking literature, we study character-level Transformers trained to compute modular addition from text, and focus on robustness under input-format variation rather than only in-distribution accuracy. We identify a previously under-emphasized failure mode: models that achieve high in-distribution accuracy can fail catastrophically when the same expression is shifted to different absolute character positions ("position shift") or presented under out-of-distribution natural-language templates. Using a disjoint-pair split over all ordered pairs for p=97, we show that a baseline model reaches strong in-distribution performance yet collapses under position shift and template OOD. We then introduce a simple training recipe that combines (i) explicit expression boundary markers, (ii) position curriculum that broadens the range of absolute positions seen during training, (iii) diverse template mixtures, and (iv) consistency training across multiple variants per example. Across three seeds, this intervention substantially improves robustness to position shift and template OOD while maintaining high in-distribution accuracy, whereas an ALiBi-style ablation fails to learn the task under our setup. Our results suggest that steering procedural generalization under noisy supervision benefits from explicitly training invariances that are otherwise absent from the data distribution, and we provide a reproducible evaluation protocol and artifacts.

</details>


### [12] [Enhancing Robustness of Asynchronous EEG-Based Movement Prediction using Classifier Ensembles](https://arxiv.org/abs/2601.04286)
*Niklas Kueper,Kartik Chari,Elsa Andrea Kirchner*

Main category: cs.LG

TL;DR: 研究证明分类器集成和滑动窗口后处理能有效提升脑电信号异步运动意图检测的鲁棒性，特别是在在线分类中效果更显著。


<details>
  <summary>Details</summary>
Motivation: 中风是导致残疾的主要原因之一，机器人辅助运动治疗是很有前景的康复方法。要实现这一目标，需要检测患者的运动意图来触发机器人设备辅助。虽然可以从脑电信号中检测运动意图，但在线异步分类时解码特别具有挑战性。

Method: 分析两个包含14名健康受试者执行自发起臂部运动的脑电数据集。进行离线和伪在线评估，比较支持向量机、多层感知器和EEGNet分类模型的集成组合，并研究滑动窗口后处理技术的效果。

Result: 伪在线评估显示，在最优后处理窗口数量下，两种模型集成显著优于最佳单一模型。对于单一模型，增加后处理窗口数量显著提高了分类性能。有趣的是，在离线评估中，最佳单一模型和分类器集成之间没有显著差异。

Conclusion: 分类器集成和适当的后处理方法能有效增强脑电信号运动意图的异步检测。特别是分类器集成方法在线分类中的改进比离线分类更大，并能减少误检（早期假阳性）。

Abstract: Objective: Stroke is one of the leading causes of disabilities. One promising approach is to extend the rehabilitation with self-initiated robot-assisted movement therapy. To enable this, it is required to detect the patient's intention to move to trigger the assistance of a robotic device. This intention to move can be detected from human surface electroencephalography (EEG) signals; however, it is particularly challenging to decode when classifications are performed online and asynchronously. In this work, the effectiveness of classifier ensembles and a sliding-window postprocessing technique was investigated to enhance the robustness of such asynchronous classification. Approach: To investigate the effectiveness of classifier ensembles and a sliding-window postprocessing, two EEG datasets with 14 healthy subjects who performed self-initiated arm movements were analyzed. Offline and pseudo-online evaluations were conducted to compare ensemble combinations of the support vector machine (SVM), multilayer perceptron (MLP), and EEGNet classification models. Results: The results of the pseudo-online evaluation show that the two model ensembles significantly outperformed the best single model for the optimal number of postprocessing windows. In particular, for single models, an increased number of postprocessing windows significantly improved classification performances. Interestingly, we found no significant improvements between performances of the best single model and classifier ensembles in the offline evaluation. Significance: We demonstrated that classifier ensembles and appropriate postprocessing methods effectively enhance the asynchronous detection of movement intentions from EEG signals. In particular, the classifier ensemble approach yields greater improvements in online classification than in offline classification, and reduces false detections, i.e., early false positives.

</details>


### [13] [Online Action-Stacking Improves Reinforcement Learning Performance for Air Traffic Control](https://arxiv.org/abs/2601.04287)
*Ben Carvell,George De Ath,Eseoghene Benjamin,Richard Everson*

Main category: cs.LG

TL;DR: 在线动作堆叠是一种推理时包装器，可将强化学习策略的原始动作编译为符合空管领域要求的复合指令，使用小动作空间训练但能产生专业级控制命令。


<details>
  <summary>Details</summary>
Motivation: 标准强化学习动作空间与空管操作要求之间存在差距，需要一种方法既能使用简单动作训练策略，又能生成符合领域规范的复合指令。

Method: 训练时使用简单的航向或高度增量调整作为基础动作，配合动作阻尼惩罚减少指令频率；推理时通过在线动作堆叠将原始动作序列编译为复合管制指令。

Result: 在横向导航实验中，动作堆叠显著减少了指令数量（相比阻尼基线），仅用5个动作就达到了与37维动作空间策略相当的性能。

Conclusion: 在线动作堆叠填补了标准强化学习与空管操作要求之间的关键差距，为扩展到更复杂控制场景提供了简单机制。

Abstract: We introduce online action-stacking, an inference-time wrapper for reinforcement learning policies that produces realistic air traffic control commands while allowing training on a much smaller discrete action space. Policies are trained with simple incremental heading or level adjustments, together with an action-damping penalty that reduces instruction frequency and leads agents to issue commands in short bursts. At inference, online action-stacking compiles these bursts of primitive actions into domain-appropriate compound clearances. Using Proximal Policy Optimisation and the BluebirdDT digital twin platform, we train agents to navigate aircraft along lateral routes, manage climb and descent to target flight levels, and perform two-aircraft collision avoidance under a minimum separation constraint. In our lateral navigation experiments, action stacking greatly reduces the number of issued instructions relative to a damped baseline and achieves comparable performance to a policy trained with a 37-dimensional action space, despite operating with only five actions. These results indicate that online action-stacking helps bridge a key gap between standard reinforcement learning formulations and operational ATC requirements, and provides a simple mechanism for scaling to more complex control scenarios.

</details>


### [14] [ArtCognition: A Multimodal AI Framework for Affective State Sensing from Visual and Kinematic Drawing Cues](https://arxiv.org/abs/2601.04297)
*Behrad Binaei-Haghighi,Nafiseh Sadat Sajadi,Mehrad Liviyan,Reyhane Akhavan Kharazi,Fatemeh Amirkhani,Behnam Bahrak*

Main category: cs.LG

TL;DR: ArtCognition：一个用于自动分析房树人测试的多模态框架，融合视觉特征和绘画行为动态特征，通过RAG架构增强心理学解释性


<details>
  <summary>Details</summary>
Motivation: 通过非语言渠道客观评估人类情感和心理状态具有挑战性，数字绘画作为未被充分探索的情感感知模态具有潜力。房树人测试是广泛使用的心理评估工具，但传统分析依赖临床专家，缺乏自动化、可扩展的解决方案。

Method: 提出ArtCognition多模态框架：1）从最终艺术品提取静态视觉特征（计算机视觉模型）；2）从绘画过程提取动态行为运动学特征（笔画速度、停顿、流畅度）；3）使用检索增强生成（RAG）架构将低层特征与高层心理学解释连接，基于心理学知识增强可解释性。

Result: 视觉特征和行为运动学特征的融合比单一模态提供更细致的评估。提取的多模态特征与标准化心理指标显著相关，验证了框架作为可扩展临床支持工具的潜力。

Conclusion: 该工作为非侵入性情感状态评估提供了新方法，为技术辅助心理健康护理开辟了新途径。ArtCognition框架通过结合多模态数据和心理学知识，增强了自动化心理评估的可解释性和可靠性。

Abstract: The objective assessment of human affective and psychological states presents a significant challenge, particularly through non-verbal channels. This paper introduces digital drawing as a rich and underexplored modality for affective sensing. We present a novel multimodal framework, named ArtCognition, for the automated analysis of the House-Tree-Person (HTP) test, a widely used psychological instrument. ArtCognition uniquely fuses two distinct data streams: static visual features from the final artwork, captured by computer vision models, and dynamic behavioral kinematic cues derived from the drawing process itself, such as stroke speed, pauses, and smoothness. To bridge the gap between low-level features and high-level psychological interpretation, we employ a Retrieval-Augmented Generation (RAG) architecture. This grounds the analysis in established psychological knowledge, enhancing explainability and reducing the potential for model hallucination. Our results demonstrate that the fusion of visual and behavioral kinematic cues provides a more nuanced assessment than either modality alone. We show significant correlations between the extracted multimodal features and standardized psychological metrics, validating the framework's potential as a scalable tool to support clinicians. This work contributes a new methodology for non-intrusive affective state assessment and opens new avenues for technology-assisted mental healthcare.

</details>


### [15] [Transformer-Based Multi-Modal Temporal Embeddings for Explainable Metabolic Phenotyping in Type 1 Diabetes](https://arxiv.org/abs/2601.04299)
*Pir Bakhsh Khokhar,Carmine Gravino,Fabio Palomba,Sule Yildrim Yayilgan,Sarang Shaikh*

Main category: cs.LG

TL;DR: 提出可解释深度学习框架，整合连续血糖监测和实验室数据，识别1型糖尿病患者的5种潜在代谢表型，支持超越单一生物标志物的风险分层。


<details>
  <summary>Details</summary>
Motivation: 1型糖尿病具有高度代谢异质性，传统生物标志物如糖化血红蛋白无法充分表征疾病特征，需要更全面的方法来识别代谢亚组和风险分层。

Method: 提出可解释深度学习框架，整合连续血糖监测数据和实验室资料，使用Transformer编码器建模跨模态时间依赖关系，通过高斯混合模型识别潜在代谢表型，利用Transformer注意力可视化和SHAP特征归因实现模型可解释性。

Result: 在577名1型糖尿病患者中识别出5种潜在代谢表型（从代谢稳定到心血管代谢风险升高），这些表型在血糖控制、脂质代谢、肾功能标志物和促甲状腺激素水平等方面表现出显著差异。注意力分析显示血糖变异性是主要时间因素，SHAP分析识别出糖化血红蛋白、甘油三酯、胆固醇、肌酐和促甲状腺激素是表型分化的关键贡献因素。

Conclusion: 该可解释多模态时间嵌入框架揭示了1型糖尿病中生理学上一致的代谢亚组，支持超越单一生物标志物的风险分层，为个性化医疗提供了新方法。

Abstract: Type 1 diabetes (T1D) is a highly metabolically heterogeneous disease that cannot be adequately characterized by conventional biomarkers such as glycated hemoglobin (HbA1c). This study proposes an explainable deep learning framework that integrates continuous glucose monitoring (CGM) data with laboratory profiles to learn multimodal temporal embeddings of individual metabolic status. Temporal dependencies across modalities are modeled using a transformer encoder, while latent metabolic phenotypes are identified via Gaussian mixture modeling. Model interpretability is achieved through transformer attention visualization and SHAP-based feature attribution. Five latent metabolic phenotypes, ranging from metabolic stability to elevated cardiometabolic risk, were identified among 577 individuals with T1D. These phenotypes exhibit distinct biochemical profiles, including differences in glycemic control, lipid metabolism, renal markers, and thyrotropin (TSH) levels. Attention analysis highlights glucose variability as a dominant temporal factor, while SHAP analysis identifies HbA1c, triglycerides, cholesterol, creatinine, and TSH as key contributors to phenotype differentiation. Phenotype membership shows statistically significant, albeit modest, associations with hypertension, myocardial infarction, and heart failure. Overall, this explainable multimodal temporal embedding framework reveals physiologically coherent metabolic subgroups in T1D and supports risk stratification beyond single biomarkers.

</details>


### [16] [Quantifying the Effect of Test Set Contamination on Generative Evaluations](https://arxiv.org/abs/2601.04301)
*Rylan Schaeffer,Joshua Kazdan,Baber Abbasi,Ken Ziyu Liu,Brando Miranda,Ahmed Ahmed,Abhay Puri,Niloofar Mireshghallah,Sanmi Koyejo*

Main category: cs.LG

TL;DR: 研究测试集污染对生成式评估的影响，发现即使少量污染也能显著降低损失，并探讨了微调、推理温度等因素如何调节记忆效应。


<details>
  <summary>Details</summary>
Motivation: 前沿AI系统在网页规模数据上预训练时，测试集污染已成为准确评估其能力的关键问题。虽然已有研究调查了测试集污染对判别式评估（如选择题）的影响，但对生成式评估影响的研究相对较少。

Method: 在MATH基准测试中预训练语言模型，控制模型大小和测试集副本污染数量；使用缩放定律分析；研究进一步训练（新鲜数据微调、监督微调）；在推理阶段分析采样温度和解决方案长度对记忆的影响。

Result: 性能随污染和模型大小而提升；即使单个测试集副本也能使模型达到比无污染训练更低损失；新鲜数据微调可减少污染影响，监督微调效果取决于污染程度；高温采样可缓解污染效应，长解决方案比短解决方案更难记忆。

Conclusion: 测试集污染对生成式评估有显著影响，与判别式评估不同；通过表征生成与记忆的相互作用，揭示了AI系统可信评估的新复杂性层次。

Abstract: As frontier AI systems are pretrained on web-scale data, test set contamination has become a critical concern for accurately assessing their capabilities. While research has thoroughly investigated the impact of test set contamination on discriminative evaluations like multiple-choice question-answering, comparatively little research has studied the impact of test set contamination on generative evaluations. In this work, we quantitatively assess the effect of test set contamination on generative evaluations through the language model lifecycle. We pretrain language models on mixtures of web data and the MATH benchmark, sweeping model sizes and number of test set replicas contaminating the pretraining corpus; performance improves with contamination and model size. Using scaling laws, we make a surprising discovery: including even a single test set replica enables models to achieve lower loss than the irreducible error of training on the uncontaminated corpus. We then study further training: overtraining with fresh data reduces the effects of contamination, whereas supervised finetuning on the training set can either increase or decrease performance on test data, depending on the amount of pretraining contamination. Finally, at inference, we identify factors that modulate memorization: high sampling temperatures mitigate contamination effects, and longer solutions are exponentially more difficult to memorize than shorter ones, presenting a contrast with discriminative evaluations, where solutions are only a few tokens in length. By characterizing how generation and memorization interact, we highlight a new layer of complexity for trustworthy evaluation of AI systems.

</details>


### [17] [Causally-Aware Information Bottleneck for Domain Adaptation](https://arxiv.org/abs/2601.04361)
*Mohammad Ali Javidian*

Main category: cs.LG

TL;DR: 该论文提出了一种因果域适应方法，用于在目标变量在目标域完全缺失的情况下进行目标变量填补。方法基于学习机制稳定的紧凑表示，通过信息瓶颈框架实现，提供线性高斯模型的闭式解和非线性/非高斯数据的变分编码器-预测器方案。


<details>
  <summary>Details</summary>
Motivation: 解决因果系统中常见的域适应问题：目标变量在源域中可观测，但在目标域中完全缺失。需要在各种分布偏移下，从目标域中剩余的观测变量中填补目标变量。

Method: 1) 学习紧凑的机制稳定表示，保留预测目标所需信息同时丢弃虚假变异；2) 对于线性高斯因果模型，推导出闭式高斯信息瓶颈(GIB)解，简化为CCA式投影，并可选择DAG感知选项；3) 对于非线性/非高斯数据，引入变分信息瓶颈(VIB)编码器-预测器，可在源数据上训练并零样本部署到目标域。

Result: 在合成和真实数据集上，该方法始终能获得准确的填补结果，支持在高维因果模型中的实际应用，为因果域适应提供了统一、轻量级的工具包。

Conclusion: 该方法成功解决了因果域适应中的目标变量填补问题，通过信息瓶颈框架学习机制稳定表示，为线性高斯模型提供理论闭式解，为非线性/非高斯数据提供可扩展的变分方法，实现了零样本域适应。

Abstract: We tackle a common domain adaptation setting in causal systems. In this setting, the target variable is observed in the source domain but is entirely missing in the target domain. We aim to impute the target variable in the target domain from the remaining observed variables under various shifts. We frame this as learning a compact, mechanism-stable representation. This representation preserves information relevant for predicting the target while discarding spurious variation. For linear Gaussian causal models, we derive a closed-form Gaussian Information Bottleneck (GIB) solution. This solution reduces to a canonical correlation analysis (CCA)-style projection and offers Directed Acyclic Graph (DAG)-aware options when desired. For nonlinear or non-Gaussian data, we introduce a Variational Information Bottleneck (VIB) encoder-predictor. This approach scales to high dimensions and can be trained on source data and deployed zero-shot to the target domain. Across synthetic and real datasets, our approach consistently attains accurate imputations, supporting practical use in high-dimensional causal models and furnishing a unified, lightweight toolkit for causal domain adaptation.

</details>


### [18] [Phasor Agents: Oscillatory Graphs with Three-Factor Plasticity and Sleep-Staged Learning](https://arxiv.org/abs/2601.04362)
*Rodja Trappe*

Main category: cs.LG

TL;DR: Phasor Agents是一种基于耦合Stuart-Landau振荡器图（相位图）的动态系统，通过三因素局部可塑性学习耦合权重，采用醒/睡分离机制解决稳定性问题，实现了无反向传播的学习。


<details>
  <summary>Details</summary>
Motivation: 解决振荡器基质中的稳定性挑战：在线权重更新可能导致网络陷入全局同步等不良状态，破坏表示多样性。受突触标记-捕获和睡眠阶段动态启发，需要分离清醒标记和离线巩固过程。

Method: 使用相位图作为内部状态表示，通过三因素局部可塑性学习耦合权重（资格迹由稀疏全局调制器和振荡定时写入窗口门控）。采用醒/睡分离机制：深睡阶段门控捕获安全提交标记变化，REM阶段回放重构和扰动经验用于规划。

Result: 实验验证：资格迹在延迟调制下保持信用；压缩进展信号通过时间戳洗牌控制；相位相干检索在噪声下达到扩散基线的4倍；醒/睡分离在匹配权重范数预算下扩展稳定学习67%；REM回放提高迷宫成功率45.5个百分点；出现Tolman式潜在学习特征。

Conclusion: Phasor Agents展示了基于振荡器动态的无反向传播学习框架，通过醒/睡分离机制解决了稳定性问题，实现了内部模型的形成和规划能力，为生物启发计算提供了新途径。

Abstract: Phasor Agents are dynamical systems whose internal state is a Phasor Graph: a weighted graph of coupled Stuart-Landau oscillators. A Stuart-Landau oscillator is a minimal stable "rhythm generator" (the normal form near a Hopf bifurcation); each oscillator is treated as an abstract computational unit (inspired by, but not claiming to model, biological oscillatory populations). In this interpretation, oscillator phase tracks relative timing (coherence), while amplitude tracks local gain or activity. Relative phase structure serves as a representational medium; coupling weights are learned via three-factor local plasticity - eligibility traces gated by sparse global modulators and oscillation-timed write windows - without backpropagation.
  A central challenge in oscillatory substrates is stability: online weight updates can drive the network into unwanted regimes (e.g., global synchrony), collapsing representational diversity. We therefore separate wake tagging from offline consolidation, inspired by synaptic tagging-and-capture and sleep-stage dynamics: deep-sleep-like gated capture commits tagged changes safely, while REM-like replay reconstructs and perturbs experience for planning.
  A staged experiment suite validates each mechanism with ablations and falsifiers: eligibility traces preserve credit under delayed modulation; compression-progress signals pass timestamp-shuffle controls; phase-coherent retrieval reaches 4x diffusive baselines under noise; wake/sleep separation expands stable learning by 67 percent under matched weight-norm budgets; REM replay improves maze success rate by +45.5 percentage points; and a Tolman-style latent-learning signature - immediate competence and detour advantage after unrewarded exploration, consistent with an internal model - emerges from replay (Tolman, 1948).
  The codebase and all artifacts are open-source.

</details>


### [19] [Survival Dynamics of Neural and Programmatic Policies in Evolutionary Reinforcement Learning](https://arxiv.org/abs/2601.04365)
*Anton Roupassov-Ruiz,Yiyang Zuo*

Main category: cs.LG

TL;DR: 论文研究了在进化强化学习中，程序化策略（PERL）相比神经网络策略（NERL）在生存性能上的优势，发现PERL平均多存活201.69步，且仅用学习的SDDL代理比同时使用学习和进化的神经网络代理多存活73.67步。


<details>
  <summary>Details</summary>
Motivation: 传统进化强化学习中的神经网络策略缺乏显式的模块化结构，限制了行为解释性。研究旨在探索程序化策略是否能匹配甚至超越神经网络策略的性能。

Method: 使用软可微分决策列表（SDDL）实现程序化策略，并首次提供了1992年人工生命进化强化学习测试平台的完整开源重新实现。通过4000次独立试验进行严格的生存分析，使用Kaplan-Meier曲线和受限平均生存时间（RMST）指标。

Result: PERL和NERL在生存概率上存在统计显著差异：PERL代理平均比NERL代理多存活201.69步；仅使用学习的SDDL代理比同时使用学习和进化的神经网络代理多存活73.67步。

Conclusion: 程序化策略在人工生命环境中能够超越神经网络策略的生存性能，为进化强化学习提供了更具解释性的替代方案。

Abstract: In evolutionary reinforcement learning tasks (ERL), agent policies are often encoded as small artificial neural networks (NERL). Such representations lack explicit modular structure, limiting behavioral interpretation. We investigate whether programmatic policies (PERL), implemented as soft, differentiable decision lists (SDDL), can match the performance of NERL. To support reproducible evaluation, we provide the first fully specified and open-source reimplementation of the classic 1992 Artificial Life (ALife) ERL testbed. We conduct a rigorous survival analysis across 4000 independent trials utilizing Kaplan-Meier curves and Restricted Mean Survival Time (RMST) metrics absent in the original study. We find a statistically significant difference in survival probability between PERL and NERL. PERL agents survive on average 201.69 steps longer than NERL agents. Moreover, SDDL agents using learning alone (no evolution) survive on average 73.67 steps longer than neural agents using both learning and evaluation. These results demonstrate that programmatic policies can exceed the survival performance of neural policies in ALife.

</details>


### [20] [Machine Learning Model for Sparse PCM Completion](https://arxiv.org/abs/2601.04366)
*Selcuk Koyuncu,Ronak Nouri,Stephen Providence*

Main category: cs.LG

TL;DR: 提出一种结合经典成对比较矩阵方法与图学习技术的机器学习模型，用于稀疏成对比较矩阵，并通过数值实验验证了方法的有效性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 传统成对比较矩阵方法在处理稀疏数据时面临挑战，需要结合现代机器学习技术来提高处理效率和准确性。

Method: 将经典成对比较矩阵方法与图学习技术相结合，构建机器学习模型来处理稀疏成对比较矩阵。

Result: 数值实验结果表明，所提出的方法在有效性和可扩展性方面表现良好。

Conclusion: 结合经典成对比较矩阵方法与图学习技术的机器学习模型能够有效处理稀疏成对比较矩阵问题，具有良好的应用前景。

Abstract: In this paper, we propose a machine learning model for sparse pairwise comparison matrices (PCMs), combining classical PCM approaches with graph-based learning techniques. Numerical results are provided to demonstrate the effectiveness and scalability of the proposed method.

</details>


### [21] [Aligned explanations in neural networks](https://arxiv.org/abs/2601.04378)
*Corentin Lobet,Francesca Chiaromonte*

Main category: cs.LG

TL;DR: 提出PiNets作为可解释深度学习框架，通过伪线性网络实现线性可读性，确保解释与预测直接对齐


<details>
  <summary>Details</summary>
Motivation: 现有特征归因方法只是对黑盒模型的表面解释，缺乏与预测过程的直接关联，需要实现解释与预测的对齐以提高可信度

Method: 提出PiNets（伪线性网络）框架，在任意特征空间中生成实例级别的线性预测，实现线性可读性

Result: 在图像分类和分割任务中验证了PiNets能够产生忠实于模型预测过程的解释，满足多个对齐标准

Conclusion: 模型可读性是实现解释与预测对齐的关键设计原则，PiNets为深度学习提供了可解释且可信的建模框架

Abstract: Feature attribution is the dominant paradigm for explaining deep neural networks. However, most existing methods only loosely reflect the model's prediction-making process, thereby merely white-painting the black box. We argue that explanatory alignment is a key aspect of trustworthiness in prediction tasks: explanations must be directly linked to predictions, rather than serving as post-hoc rationalizations. We present model readability as a design principle enabling alignment, and PiNets as a modeling framework to pursue it in a deep learning context. PiNets are pseudo-linear networks that produce instance-wise linear predictions in an arbitrary feature space, making them linearly readable. We illustrate their use on image classification and segmentation tasks, demonstrating how PiNets produce explanations that are faithful across multiple criteria in addition to alignment.

</details>


### [22] [Enhanced-FQL($λ$), an Efficient and Interpretable RL with novel Fuzzy Eligibility Traces and Segmented Experience Replay](https://arxiv.org/abs/2601.04392)
*Mohsen Jalaeian-Farimani*

Main category: cs.LG

TL;DR: 论文提出Enhanced-FQL(λ)模糊强化学习框架，集成模糊化资格迹和分段经验回放，用于连续控制任务，在保持可解释性的同时实现竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度强化学习方法在连续控制任务中虽然性能优秀，但存在计算复杂度高、缺乏可解释性等问题，不适合安全关键应用。需要一种既能保持性能又具有可解释性和计算效率的方法。

Method: 提出Enhanced-FQL(λ)框架，核心包括：1）模糊化贝尔曼方程与模糊化资格迹，实现稳定的多步信用分配；2）分段经验回放机制，提高样本效率；3）使用可解释的模糊规则库而非复杂神经网络架构。

Result: 理论分析证明方法在标准假设下收敛。在连续控制领域的实验表明，相比n步模糊TD和模糊SARSA(λ)基线，Enhanced-FQL(λ)具有更好的样本效率和更低的方差，同时计算复杂度显著低于DDPG等深度RL方法。

Conclusion: Enhanced-FQL(λ)框架结合了可解释性、计算效率和理论收敛保证，特别适合安全关键应用，在保持透明度和资源约束的同时实现竞争性性能。

Abstract: This paper introduces a fuzzy reinforcement learning framework, Enhanced-FQL($λ$), that integrates novel Fuzzified Eligibility Traces (FET) and Segmented Experience Replay (SER) into fuzzy Q-learning with Fuzzified Bellman Equation (FBE) for continuous control tasks. The proposed approach employs an interpretable fuzzy rule base instead of complex neural architectures, while maintaining competitive performance through two key innovations: a fuzzified Bellman equation with eligibility traces for stable multi-step credit assignment, and a memory-efficient segment-based experience replay mechanism for enhanced sample efficiency. Theoretical analysis proves the proposed method convergence under standard assumptions. Extensive evaluations in continuous control domains demonstrate that Enhanced-FQL($λ$) achieves superior sample efficiency and reduced variance compared to n-step fuzzy TD and fuzzy SARSA($λ$) baselines, while maintaining substantially lower computational complexity than deep RL alternatives such as DDPG. The framework's inherent interpretability, combined with its computational efficiency and theoretical convergence guarantees, makes it particularly suitable for safety-critical applications where transparency and resource constraints are essential.

</details>


### [23] [Rate or Fate? RLV$^\varepsilon$R: Reinforcement Learning with Verifiable Noisy Rewards](https://arxiv.org/abs/2601.04411)
*Ali Rad,Khashayar Filom,Darioush Keivan,Peyman Mohajerin Esfahani,Ehsan Kamalinejad*

Main category: cs.LG

TL;DR: RLVR（可验证奖励的强化学习）在噪声验证下存在相变：当Youden指数J>0时学习成功，J<0时系统崩溃，J=0时中性演化。


<details>
  <summary>Details</summary>
Motivation: 现实中的RLVR验证器存在噪声（单元测试不完整、人工标签不完美、LLM判断有噪声），特别是在编程等困难领域。需要研究验证噪声是仅减慢学习速度，还是能改变学习结果。

Method: 建立可分析的多臂老虎机模型来研究RLVR动态，使用GRPO实例化，通过受控实验验证。将错误分为假阳性和假阴性，将补全分组为重复推理模式，得到概率单纯形上的复制器式（自然选择）流。

Result: 动态过程解耦为正确模式内竞争和一维错误模式质量演化，其漂移由Youden指数J=TPR-FPR决定。发现尖锐相变：J>0时错误模式被消除（学习）；J=0时中性过程；J<0时错误模式放大直至主导（反学习和崩溃）。在J>0的学习区域，噪声主要重新缩放收敛时间。

Conclusion: 验证噪声在Youden指数J>0时主要影响收敛速度而非结果，但J<0会导致系统崩溃。该框架为分析RLVR稳定性、收敛性和算法干预提供了通用视角。

Abstract: Reinforcement learning with verifiable rewards (RLVR) is a simple but powerful paradigm for training LLMs: sample a completion, verify it, and update. In practice, however, the verifier is almost never clean--unit tests probe only limited corner cases; human and synthetic labels are imperfect; and LLM judges (e.g., RLAIF) are noisy and can be exploited--and this problem worsens on harder domains (especially coding) where tests are sparse and increasingly model-generated. We ask a pragmatic question: does the verification noise merely slow down the learning (rate), or can it flip the outcome (fate)?
  To address this, we develop an analytically tractable multi-armed bandit view of RLVR dynamics, instantiated with GRPO and validated in controlled experiments. Modeling false positives and false negatives and grouping completions into recurring reasoning modes yields a replicator-style (natural-selection) flow on the probability simplex. The dynamics decouples into within-correct-mode competition and a one-dimensional evolution for the mass on incorrect modes, whose drift is determined solely by Youden's index J=TPR-FPR. This yields a sharp phase transition: when J>0, the incorrect mass is driven toward extinction (learning); when J=0, the process is neutral; and when J<0, incorrect modes amplify until they dominate (anti-learning and collapse). In the learning regime J>0, noise primarily rescales convergence time ("rate, not fate"). Experiments on verifiable programming tasks under synthetic noise reproduce the predicted J=0 boundary. Beyond noise, the framework offers a general lens for analyzing RLVR stability, convergence, and algorithmic interventions.

</details>


### [24] [Distribution-Guided and Constrained Quantum Machine Unlearning](https://arxiv.org/abs/2601.04413)
*Nausherwan Malik,Zubair Khalid,Muhammad Faryad*

Main category: cs.LG

TL;DR: 本文提出了一种基于分布引导的量子机器学习遗忘框架，通过可调目标分布和锚点约束实现类级遗忘，在保留模型性能的同时有效抑制遗忘类置信度。


<details>
  <summary>Details</summary>
Motivation: 现有量子机器学习遗忘方法主要依赖固定均匀的目标分布，未能明确控制遗忘与保留模型行为之间的权衡，需要更可靠和可解释的量子遗忘方法。

Method: 提出分布引导的量子机器学习遗忘框架，将遗忘问题建模为约束优化问题：1）引入基于模型相似性统计的可调目标分布，解耦遗忘类置信度抑制与保留类分布假设；2）采用锚点保留约束，在选定保留数据上明确维持预测行为，控制优化轨迹偏离。

Result: 在Iris和Covertype数据集上的变分量子分类器评估显示：1）显著抑制遗忘类置信度；2）保留类性能退化最小；3）相比均匀目标遗忘方法，更接近黄金重训练模型基线。

Conclusion: 目标分布设计和基于约束的公式对于实现可靠且可解释的量子机器学习遗忘至关重要，提出的框架在遗忘效果和模型保留之间取得了更好平衡。

Abstract: Machine unlearning aims to remove the influence of specific training data from a learned model without full retraining. While recent work has begun to explore unlearning in quantum machine learning, existing approaches largely rely on fixed, uniform target distributions and do not explicitly control the trade-off between forgetting and retained model behaviour. In this work, we propose a distribution-guided framework for class-level quantum machine unlearning that treats unlearning as a constrained optimization problem. Our method introduces a tunable target distribution derived from model similarity statistics, decoupling the suppression of forgotten-class confidence from assumptions about redistribution among retained classes. We further incorporate an anchor-based preservation constraint that explicitly maintains predictive behaviour on selected retained data, yielding a controlled optimization trajectory that limits deviation from the original model. We evaluate the approach on variational quantum classifiers trained on the Iris and Covertype datasets. Results demonstrate sharp suppression of forgotten-class confidence, minimal degradation of retained-class performance, and closer alignment with the gold retrained model baselines compared to uniform-target unlearning. These findings highlight the importance of target design and constraint-based formulations for reliable and interpretable quantum machine unlearning.

</details>


### [25] [Improving and Accelerating Offline RL in Large Discrete Action Spaces with Structured Policy Initialization](https://arxiv.org/abs/2601.04441)
*Matthew Landers,Taylor W. Killian,Thomas Hartvigsen,Afsaneh Doryab*

Main category: cs.LG

TL;DR: SPIN：两阶段强化学习框架，先预训练动作结构模型捕捉有效动作流形，再冻结表示训练轻量策略头，在离散组合动作空间中显著提升性能和收敛速度


<details>
  <summary>Details</summary>
Motivation: 离散组合动作空间的强化学习需要搜索指数级多的联合动作。现有方法要么假设子动作独立导致动作不连贯或无效，要么联合学习动作结构和控制导致训练缓慢不稳定

Method: 提出结构化策略初始化（SPIN）框架：1）预训练动作结构模型（ASM）捕捉有效动作流形；2）冻结该表示，训练轻量级策略头进行控制

Result: 在离散DM Control基准测试中，SPIN比现有最佳方法平均回报提升高达39%，收敛时间减少高达12.8倍

Conclusion: SPIN通过分离动作结构学习和控制学习，有效解决了离散组合动作空间中的策略学习问题，在性能和效率上都取得了显著提升

Abstract: Reinforcement learning in discrete combinatorial action spaces requires searching over exponentially many joint actions to simultaneously select multiple sub-actions that form coherent combinations. Existing approaches either simplify policy learning by assuming independence across sub-actions, which often yields incoherent or invalid actions, or attempt to learn action structure and control jointly, which is slow and unstable. We introduce Structured Policy Initialization (SPIN), a two-stage framework that first pre-trains an Action Structure Model (ASM) to capture the manifold of valid actions, then freezes this representation and trains lightweight policy heads for control. On challenging discrete DM Control benchmarks, SPIN improves average return by up to 39% over the state of the art while reducing time to convergence by up to 12.8$\times$.

</details>


### [26] [When Predictions Shape Reality: A Socio-Technical Synthesis of Performative Predictions in Machine Learning](https://arxiv.org/abs/2601.04447)
*Gal Fybish,Teo Susnjak*

Main category: cs.LG

TL;DR: 这篇SoK论文系统化地综述了执行性预测（performative prediction）领域，提出了"执行强度vs影响矩阵"评估框架，帮助从业者评估预测模型部署后的动态影响并选择适当干预措施。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在高风险领域部署时，其预测会主动塑造运行环境（执行性预测现象），导致反馈循环、性能问题和社会风险。现有文献缺乏对这一现象的系统化概念梳理和实践指导。

Method: 采用系统化知识（SoK）方法，全面综述执行性预测文献，分析执行性表现的主要机制，建立相关风险的类型学，并调查文献中提出的解决方案。

Result: 提出了"执行强度vs影响矩阵"评估框架，这是一个实用工具，帮助从业者评估执行性对部署预测模型的潜在影响和严重程度，并选择适当的算法或人工干预级别。

Conclusion: 该SoK填补了执行性预测领域系统化综合的空白，为理解和应对机器学习模型部署中的动态反馈效应提供了概念框架和实践指导。

Abstract: Machine learning models are increasingly used in high-stakes domains where their predictions can actively shape the environments in which they operate, a phenomenon known as performative prediction. This dynamic, in which the deployment of the model influences the very outcome it seeks to predict, can lead to unintended consequences, including feedback loops, performance issues, and significant societal risks. While the literature in the field has grown rapidly in recent years, a socio-technical synthesis that systemises the phenomenon concepts and provides practical guidance has been lacking. This Systematisation of Knowledge (SoK) addresses this gap by providing a comprehensive review of the literature on performative predictions. We provide an overview of the primary mechanisms through which performativity manifests, present a typology of associated risks, and survey the proposed solutions offered in the literature. Our primary contribution is the ``Performative Strength vs. Impact Matrix" assessment framework. This practical tool is designed to help practitioners assess the potential influence and severity of performativity on their deployed predictive models and select the appropriate level of algorithmic or human intervention.

</details>


### [27] [Explainable Admission-Level Predictive Modeling for Prolonged Hospital Stay in Elderly Populations: Challenges in Low- and Middle-Income Countries](https://arxiv.org/abs/2601.04449)
*Daniel Sierra-Botero,Ana Molina-Taborda,Leonardo Espinosa-Leal,Alexander Karpenko,Alejandro Hernandez,Olga Lopez-Acevedo*

Main category: cs.LG

TL;DR: 开发并解释了一个预测住院时间延长(pLoS)的模型，使用入院患者和医院管理数据，通过特征选择方法获得9个可解释变量，在验证队列中AUC-ROC达到0.82。


<details>
  <summary>Details</summary>
Motivation: 住院时间延长(pLoS)是与院内不良事件风险相关的重要因素，需要开发预测模型来帮助医院管理和制定干预措施。

Method: 使用图论方法进行特征选择，选择信息价值最高且不相关的特征，然后训练逻辑回归模型预测pLoS（以7天为界分为两类），使用训练、测试和验证队列（67%、22%、11%）。

Result: 特征选择方法返回9个可解释变量，验证队列中模型特异性0.83、敏感性0.64、准确率0.76、精确率0.67、AUC-ROC 0.82，表现出强预测性能。

Conclusion: 该模型具有强预测性能，能提供影响住院时间延长因素的见解，是医院管理和未来干预研究的有价值工具。

Abstract: Prolonged length of stay (pLoS) is a significant factor associated with the risk of adverse in-hospital events. We develop and explain a predictive model for pLos using admission-level patient and hospital administrative data. The approach includes a feature selection method by selecting non-correlated features with the highest information value. The method uses features weights of evidence to select a representative within cliques from graph theory. The prognosis study analyzed the records from 120,354 hospital admissions at the Hospital Alma Mater de Antioquia between January 2017 and March 2022. After a cleaning process the dataset was split into training (67%), test (22%), and validation (11%) cohorts. A logistic regression model was trained to predict the pLoS in two classes: less than or greater than 7 days. The performance of the model was evaluated using accuracy, precision, sensitivity, specificity, and AUC-ROC metrics. The feature selection method returns nine interpretable variables, enhancing the models' transparency. In the validation cohort, the pLoS model achieved a specificity of 0.83 (95% CI, 0.82-0.84), sensitivity of 0.64 (95% CI, 0.62-0.65), accuracy of 0.76 (95% CI, 0.76-0.77), precision of 0.67 (95% CI, 0.66-0.69), and AUC-ROC of 0.82 (95% CI, 0.81-0.83). The model exhibits strong predictive performance and offers insights into the factors that influence prolonged hospital stays. This makes it a valuable tool for hospital management and for developing future intervention studies aimed at reducing pLoS.

</details>


### [28] [Using Large Language Models to Detect Socially Shared Regulation of Collaborative Learning](https://arxiv.org/abs/2601.04458)
*Jiayi Zhang,Conrad Borchers,Clayton Cohn,Namrata Srivastava,Caitlin Snyder,Siyuan Guo,Ashwin T S,Naveeduddin Mohammed,Haley Noh,Gautam Biswas*

Main category: cs.LG

TL;DR: 该研究将预测模型扩展到协作计算建模环境中，使用基于嵌入的方法自动检测学习的社会共享调节行为，发现文本嵌入在检测执行或群体动态相关行为方面表现更好，而上下文和多模态特征对规划和反思等构念有补充作用。


<details>
  <summary>Details</summary>
Motivation: 学习分析领域在自动化检测多模态数据中的复杂学习过程方面取得了显著进展，但大多数进展集中在个性化问题解决而非协作性、开放式问题解决上。协作学习环境既提供了更丰富的数据，也带来了低内聚性的挑战，需要扩展预测模型来检测社会共享调节学习行为。

Method: 使用基于嵌入的方法，利用大型语言模型作为总结工具生成与系统日志对齐的学生对话的任务感知表示。将这些总结与纯文本嵌入、上下文增强嵌入和日志衍生特征结合，训练预测模型来检测社会共享调节学习行为。

Result: 纯文本嵌入在检测与执行或群体动态相关的社会共享调节学习行为（如离题行为或请求帮助）方面通常表现更强。而上下文和多模态特征对规划和反思等构念提供了补充优势。基于嵌入的模型显示出扩展学习分析的潜力。

Conclusion: 基于嵌入的模型有望通过实现社会共享调节学习行为的可扩展检测来扩展学习分析，最终支持协作学习环境中教师重视的实时反馈和适应性支架，为协作学习环境中的行为预测提供了有效方法。

Abstract: The field of learning analytics has made notable strides in automating the detection of complex learning processes in multimodal data. However, most advancements have focused on individualized problem-solving instead of collaborative, open-ended problem-solving, which may offer both affordances (richer data) and challenges (low cohesion) to behavioral prediction. Here, we extend predictive models to automatically detect socially shared regulation of learning (SSRL) behaviors in collaborative computational modeling environments using embedding-based approaches. We leverage large language models (LLMs) as summarization tools to generate task-aware representations of student dialogue aligned with system logs. These summaries, combined with text-only embeddings, context-enriched embeddings, and log-derived features, were used to train predictive models. Results show that text-only embeddings often achieve stronger performance in detecting SSRL behaviors related to enactment or group dynamics (e.g., off-task behavior or requesting assistance). In contrast, contextual and multimodal features provide complementary benefits for constructs such as planning and reflection. Overall, our findings highlight the promise of embedding-based models for extending learning analytics by enabling scalable detection of SSRL behaviors, ultimately supporting real-time feedback and adaptive scaffolding in collaborative learning environments that teachers value.

</details>


### [29] [Meta-probabilistic Modeling](https://arxiv.org/abs/2601.04462)
*Kevin Zhang,Yixin Wang*

Main category: cs.LG

TL;DR: 提出元概率建模（MPM），一种元学习算法，通过从多个相关数据集中学习来直接优化生成模型结构，避免传统模型选择中的试错过程。


<details>
  <summary>Details</summary>
Motivation: 概率图模型的有效性依赖于良好指定的模型结构，但在实践中识别合适的模型结构具有挑战性，通常需要反复试错。需要一种能够直接从多个相关数据集中学习生成模型结构的方法。

Method: 提出元概率建模（MPM），采用分层架构：全局模型规范在多个数据集间共享，局部参数保持数据集特定。使用变分自编码器（VAE）启发的可处理代理目标，通过双层优化进行学习：局部变量通过坐标上升法解析更新，全局参数使用基于梯度的方法训练。

Result: 在面向对象的图像建模和序列文本建模任务上评估MPM，证明该方法能够使生成模型适应数据，同时恢复有意义的潜在表示。

Conclusion: MPM提供了一种有效的元学习方法，能够直接从多个相关数据集中学习生成模型结构，避免了传统模型选择中的试错过程，在图像和文本建模任务中表现出良好性能。

Abstract: While probabilistic graphical models can discover latent structure in data, their effectiveness hinges on choosing well-specified models. Identifying such models is challenging in practice, often requiring iterative checking and revision through trial and error. To this end, we propose meta-probabilistic modeling (MPM), a meta-learning algorithm that learns generative model structure directly from multiple related datasets. MPM uses a hierarchical architecture where global model specifications are shared across datasets while local parameters remain dataset-specific. For learning and inference, we propose a tractable VAE-inspired surrogate objective, and optimize it through bi-level optimization: local variables are updated analytically via coordinate ascent, while global parameters are trained with gradient-based methods. We evaluate MPM on object-centric image modeling and sequential text modeling, demonstrating that it adapts generative models to data while recovering meaningful latent representations.

</details>


### [30] [When Models Manipulate Manifolds: The Geometry of a Counting Task](https://arxiv.org/abs/2601.04480)
*Wes Gurnee,Emmanuel Ameisen,Isaac Kauvar,Julius Tarng,Adam Pearce,Chris Olah,Joshua Batson*

Main category: cs.LG

TL;DR: Claude 3.5 Haiku模型通过低维流形几何变换实现固定宽度文本的换行决策，类似于生物位置细胞机制


<details>
  <summary>Details</summary>
Motivation: 研究语言模型如何仅通过token序列感知文本的视觉属性（如固定宽度文本换行），探索其底层机制

Method: 通过机制性分析研究Claude 3.5 Haiku的换行任务，发现字符计数在低维弯曲流形上表示，通过几何变换序列实现预测：token长度累积→字符计数流形→注意力头扭曲流形估计边界距离→正交排列估计创建线性决策边界

Result: 发现字符计数由稀疏特征族离散化的低维弯曲流形表示，准确预测来自几何变换序列，通过因果干预验证发现，并发现可劫持计数机制的视觉错觉字符序列

Conclusion: 早期层具有丰富的感官处理能力，注意力算法复杂精细，需要结合基于特征和几何视角的可解释性方法

Abstract: Language models can perceive visual properties of text despite receiving only sequences of tokens-we mechanistically investigate how Claude 3.5 Haiku accomplishes one such task: linebreaking in fixed-width text. We find that character counts are represented on low-dimensional curved manifolds discretized by sparse feature families, analogous to biological place cells. Accurate predictions emerge from a sequence of geometric transformations: token lengths are accumulated into character count manifolds, attention heads twist these manifolds to estimate distance to the line boundary, and the decision to break the line is enabled by arranging estimates orthogonally to create a linear decision boundary. We validate our findings through causal interventions and discover visual illusions--character sequences that hijack the counting mechanism. Our work demonstrates the rich sensory processing of early layers, the intricacy of attention algorithms, and the importance of combining feature-based and geometric views of interpretability.

</details>


### [31] [Hybrid Federated Learning for Noise-Robust Training](https://arxiv.org/abs/2601.04483)
*Yongjun Kim,Hyeongjun Park,Hwanjin Kim,Junil Choi*

Main category: cs.LG

TL;DR: 提出混合联邦学习(HFL)框架，结合联邦学习(FL)和联邦蒸馏(FD)优势，通过自适应用户设备聚类和权重选择优化性能


<details>
  <summary>Details</summary>
Motivation: 联邦学习(FL)和联邦蒸馏(FD)各有优缺点：FL对噪声更鲁棒但学习速度慢，FD学习速度快但对噪声敏感。需要结合两者优势以在隐私保护下获得更好的学习性能。

Method: 提出混合联邦学习(HFL)框架：1) 用户设备可选择传输梯度或logits；2) 基站自适应选择每轮FL和FD更新的权重；3) 引入两种自由度利用方法：通过Jenks优化进行自适应用户设备聚类，以及通过阻尼牛顿法进行自适应权重选择。

Result: 数值实验表明，当同时利用两种自由度时，HFL在低信噪比(SNR)条件下实现了优越的测试准确率。

Conclusion: HFL框架成功结合了FL和FD的优势，通过自适应聚类和权重选择机制，在低信噪比环境下显著提升了分布式学习的性能。

Abstract: Federated learning (FL) and federated distillation (FD) are distributed learning paradigms that train UE models with enhanced privacy, each offering different trade-offs between noise robustness and learning speed. To mitigate their respective weaknesses, we propose a hybrid federated learning (HFL) framework in which each user equipment (UE) transmits either gradients or logits, and the base station (BS) selects the per-round weights of FL and FD updates. We derive convergence of HFL framework and introduce two methods to exploit degrees of freedom (DoF) in HFL, which are (i) adaptive UE clustering via Jenks optimization and (ii) adaptive weight selection via a damped Newton method. Numerical results show that HFL achieves superior test accuracy at low SNR when both DoF are exploited.

</details>


### [32] [IGenBench: Benchmarking the Reliability of Text-to-Infographic Generation](https://arxiv.org/abs/2601.04498)
*Yinghao Tang,Xueding Liu,Boyuan Zhang,Tingfeng Lan,Yupeng Xie,Jiale Lao,Yiyao Wang,Haoxuan Li,Tingting Gao,Bo Pan,Luoxuan Weng,Xiuqi Huang,Minfeng Zhu,Yingchaojie Feng,Yuyu Luo,Wei Chen*

Main category: cs.LG

TL;DR: IGENBENCH是首个评估文本到信息图生成可靠性的基准，包含600个测试用例，通过自动化框架评估10种T2I模型，发现数据相关维度是普遍瓶颈。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像模型虽然能生成美观的图像，但在生成信息图时的可靠性尚不明确，可能存在数据编码失真或文本内容错误等容易被忽视的问题。

Method: 构建包含600个测试用例的IGENBENCH基准，涵盖30种信息图类型；设计自动化评估框架，将可靠性验证分解为基于10种问题类型的原子是/否问题；使用多模态大语言模型进行验证。

Result: 评估10个最先进的T2I模型发现：1）性能呈现三层等级，最佳模型问题级准确率0.90但信息图级准确率仅0.49；2）数据相关维度是普遍瓶颈（如数据完整性0.21）；3）所有模型都难以实现端到端正确性。

Conclusion: IGENBENCH为评估文本到信息图生成可靠性提供了首个基准，揭示了当前模型的局限性，特别是数据相关维度的挑战，为未来模型开发提供了重要见解。

Abstract: Infographics are composite visual artifacts that combine data visualizations with textual and illustrative elements to communicate information. While recent text-to-image (T2I) models can generate aesthetically appealing images, their reliability in generating infographics remains unclear. Generated infographics may appear correct at first glance but contain easily overlooked issues, such as distorted data encoding or incorrect textual content. We present IGENBENCH, the first benchmark for evaluating the reliability of text-to-infographic generation, comprising 600 curated test cases spanning 30 infographic types. We design an automated evaluation framework that decomposes reliability verification into atomic yes/no questions based on a taxonomy of 10 question types. We employ multimodal large language models (MLLMs) to verify each question, yielding question-level accuracy (Q-ACC) and infographic-level accuracy (I-ACC). We comprehensively evaluate 10 state-of-the-art T2I models on IGENBENCH. Our systematic analysis reveals key insights for future model development: (i) a three-tier performance hierarchy with the top model achieving Q-ACC of 0.90 but I-ACC of only 0.49; (ii) data-related dimensions emerging as universal bottlenecks (e.g., Data Completeness: 0.21); and (iii) the challenge of achieving end-to-end correctness across all models. We release IGENBENCH at https://igen-bench.vercel.app/.

</details>


### [33] [Surface-based Molecular Design with Multi-modal Flow Matching](https://arxiv.org/abs/2601.04506)
*Fang Wu,Zhengyuan Zhou,Shuting Jin,Xiangxiang Zeng,Jure Leskovec,Jinbo Xu*

Main category: cs.LG

TL;DR: SurfFlow是一种基于分子表面的肽生成算法，通过多模态条件流匹配架构共同设计肽的序列、结构和表面，在PepMerge基准测试中优于全原子基线方法。


<details>
  <summary>Details</summary>
Motivation: 治疗性肽在靶向传统难以药物化的结合位点方面具有潜力，但现有深度生成模型主要关注全原子设计，忽略了分子表面在蛋白质-蛋白质相互作用中的关键作用。

Method: 提出SurfFlow表面生成算法，采用多模态条件流匹配架构学习表面几何形状和生化特性的分布，实现肽序列、结构和表面的全面协同设计。

Result: 在PepMerge基准测试中，SurfFlow在所有指标上一致优于全原子基线方法，证明了考虑分子表面在肽发现中的优势。

Conclusion: 分子表面在肽设计中的考虑至关重要，整合多种蛋白质模态能够实现更有效的治疗性肽发现，SurfFlow展示了这一整合的潜力。

Abstract: Therapeutic peptides show promise in targeting previously undruggable binding sites, with recent advancements in deep generative models enabling full-atom peptide co-design for specific protein receptors. However, the critical role of molecular surfaces in protein-protein interactions (PPIs) has been underexplored. To bridge this gap, we propose an omni-design peptides generation paradigm, called SurfFlow, a novel surface-based generative algorithm that enables comprehensive co-design of sequence, structure, and surface for peptides. SurfFlow employs a multi-modality conditional flow matching (CFM) architecture to learn distributions of surface geometries and biochemical properties, enhancing peptide binding accuracy. Evaluated on the comprehensive PepMerge benchmark, SurfFlow consistently outperforms full-atom baselines across all metrics. These results highlight the advantages of considering molecular surfaces in de novo peptide discovery and demonstrate the potential of integrating multiple protein modalities for more effective therapeutic peptide discovery.

</details>


### [34] [TSSR: Two-Stage Swap-Reward-Driven Reinforcement Learning for Character-Level SMILES Generation](https://arxiv.org/abs/2601.04521)
*Jacob Ede Levine,Yun Lyan Luo,Sai Chandra Kosaraju*

Main category: cs.LG

TL;DR: TSSR：一种两阶段、交换奖励驱动的强化学习框架，用于字符级SMILES生成，通过语法修复和化学感知反馈提高分子生成的有效性和多样性。


<details>
  <summary>Details</summary>
Motivation: 当前基于SMILES的化学语言模型存在复合令牌错误问题，许多生成的分子无法解析或化学上不合理，而硬约束又会限制化学空间的探索。需要一种既能提高生成质量又不牺牲多样性的方法。

Method: TSSR采用两阶段强化学习框架：第一阶段奖励局部令牌交换以修复语法错误，使无效字符串变得可解析；第二阶段通过RDKit诊断提供化学感知反馈，奖励减少价态、芳香性和连接性问题。奖励函数可分解为可解释的组件，无需特定任务标签或手工语法。

Result: 在MOSES基准测试中，TSSR显著提高了语法有效性、化学有效性和新颖性。在纯强化学习中改善所有指标，在微调强化学习中保持药物相似性和可合成性的同时提高有效性和新颖性。令牌级分析显示语法编辑和化学修复共同减少RDKit检测的错误。

Conclusion: TSSR将稀疏的终端目标转化为更密集、更可解释的奖励，在不降低多样性的情况下同时提高语法和化学质量。该框架与数据集无关，可适应各种强化学习方法。

Abstract: The design of reliable, valid, and diverse molecules is fundamental to modern drug discovery, as improved molecular generation supports efficient exploration of the chemical space for potential drug candidates and reduces the cost of early design efforts. Despite these needs, current chemical language models that generate molecules as SMILES strings are vulnerable to compounding token errors: many samples are unparseable or chemically implausible, and hard constraints meant to prevent failure can restrict exploration. To address this gap, we introduce TSSR, a Two-Stage, Swap-Reward-driven reinforcement learning (RL) framework for character-level SMILES generation. Stage one rewards local token swaps that repair syntax, promoting transitions from invalid to parseable strings. Stage two provides chemistry-aware feedback from RDKit diagnostics, rewarding reductions in valence, aromaticity, and connectivity issues. The reward decomposes into interpretable terms (swap efficiency, error reduction, distance to validity), is model agnostic, and requires no task-specific labels or hand-crafted grammars. We evaluated TSSR on the MOSES benchmark using a GRU policy trained with PPO in both pure RL (P-RL) from random initialization and fine-tuning RL (F-RL) starting from a pretrained chemical language model, assessing 10,000 generated SMILES per run. In P-RL, TSSR significantly improves syntactic validity, chemical validity, and novelty. In F-RL, TSSR preserves drug-likeness and synthesizability while increasing validity and novelty. Token-level analysis shows that syntax edits and chemistry fixes act jointly to reduce RDKit detected errors. TSSR converts a sparse terminal objective into a denser and more interpretable reward, improving both syntactic and chemical quality without reducing diversity. TSSR is dataset-agnostic and can be adapted to various reinforcement learning approaches.

</details>


### [35] [Not All Steps are Informative: On the Linearity of LLMs' RLVR Training](https://arxiv.org/abs/2601.04537)
*Tianle Wang,Zhongyuan Wu,Shenghao Jin,Hao Xu,Wei Chen,Ning Miao*

Main category: cs.LG

TL;DR: 论文发现RLVR训练中LLM呈强线性演化，提出通过权重和外推法预测未来模型状态，显著减少计算成本


<details>
  <summary>Details</summary>
Motivation: RLVR训练需要数千步才能达到强性能，计算成本高昂，主要归因于长时间的探索过程。作者观察到RLVR训练中LLM呈强线性演化，这启发他们探索是否可以通过外推法预测未来模型状态来避免继续昂贵的训练

Method: 提出两种外推方法：1) 权重外推法：从中间检查点预测未来模型权重；2) 对数外推法：直接外推模型输出的对数概率。这两种方法都利用了RLVR训练中观察到的强线性特性

Result: 权重外推法产生的模型性能与标准RL训练相当，但计算需求显著减少。对数外推法在四个基准测试中都优于继续RL训练，特别是在RL训练保持稳定的步数范围之外进行外推时表现更好

Conclusion: RLVR训练中LLM的强线性演化特性使得通过外推法预测未来模型状态成为可能，这可以显著减少计算成本，同时保持甚至提升模型性能，为高效的RLVR训练提供了新思路

Abstract: Reinforcement learning with verifiable rewards (RLVR) has become a central component of large language model (LLM) post-training. Unlike supervised fine-tuning (SFT), RLVR lets an LLM generate multiple candidate solutions and reinforces those that lead to a verifiably correct final answer. However, in practice, RLVR often requires thousands of training steps to reach strong performance, incurring substantial computation largely attributed to prolonged exploration. In this work, we make a surprising observation: during RLVR, LLMs evolve in a strongly linear manner. Specifically, both model weights and model output log-probabilities exhibit strong linear correlations with RL training steps. This suggests that RLVR predominantly amplifies trends that emerge early in training, rather than continuously discovering new behaviors throughout the entire optimization trajectory. Motivated by this linearity, we investigate whether future model states can be predicted from intermediate checkpoints via extrapolation, avoiding continued expensive training. We show that Weight Extrapolation produces models with performance comparable to standard RL training while requiring significantly less computation. Moreover, Logits Extrapolation consistently outperforms continued RL training on all four benchmarks by extrapolating beyond the step range where RL training remains stable.

</details>


### [36] [Timeliness-Oriented Scheduling and Resource Allocation in Multi-Region Collaborative Perception](https://arxiv.org/abs/2601.04542)
*Mengmeng Zhu,Yuxuan Sun,Yukuan Jia,Wei Chen,Bo Ai,Sheng Zhou*

Main category: cs.LG

TL;DR: 提出TAMP调度算法，在协作感知场景中平衡感知精度与通信资源使用，通过时效性感知的多区域优先级调度，在真实数据集上实现AP提升达27%


<details>
  <summary>Details</summary>
Motivation: 协作感知面临两大挑战：1) 环境动态变化导致信息时效性对感知性能至关重要；2) 传感器计算能力和无线带宽有限，需要精心设计通信量以确保特征表示的有效性和充分性

Method: 提出时效性感知的多区域优先级调度算法(TAMP)，基于Lyapunov优化策略，将长期平均目标分解为时隙级优先级问题，平衡调度价值与资源成本。通过经验惩罚函数将信息年龄和通信量的联合影响映射到感知性能

Result: 在真实世界RCooper数据集的交叉路口和走廊场景中进行广泛仿真，TAMP算法优于最佳基线方法，在各种配置下平均精度提升最高达27%

Conclusion: TAMP调度算法有效解决了协作感知中的动态调度问题，通过时效性感知的优先级调度，在有限通信资源下显著提升了感知性能

Abstract: Collaborative perception (CP) is a critical technology in applications like autonomous driving and smart cities. It involves the sharing and fusion of information among sensors to overcome the limitations of individual perception, such as blind spots and range limitations. However, CP faces two primary challenges. First, due to the dynamic nature of the environment, the timeliness of the transmitted information is critical to perception performance. Second, with limited computational power at the sensors and constrained wireless bandwidth, the communication volume must be carefully designed to ensure feature representations are both effective and sufficient. This work studies the dynamic scheduling problem in a multi-region CP scenario, and presents a Timeliness-Aware Multi-region Prioritized (TAMP) scheduling algorithm to trade-off perception accuracy and communication resource usage. Timeliness reflects the utility of information that decays as time elapses, which is manifested by the perception performance in CP tasks. We propose an empirical penalty function that maps the joint impact of Age of Information (AoI) and communication volume to perception performance. Aiming to minimize this timeliness-oriented penalty in the long-term, and recognizing that scheduling decisions have a cumulative effect on subsequent system states, we propose the TAMP scheduling algorithm. TAMP is a Lyapunov-based optimization policy that decomposes the long-term average objective into a per-slot prioritization problem, balancing the scheduling worth against resource cost. We validate our algorithm in both intersection and corridor scenarios with the real-world Roadside Cooperative perception (RCooper) dataset. Extensive simulations demonstrate that TAMP outperforms the best-performing baseline, achieving an Average Precision (AP) improvement of up to 27% across various configurations.

</details>


### [37] [GEnSHIN: Graphical Enhanced Spatio-temporal Hierarchical Inference Network for Traffic Flow Prediction](https://arxiv.org/abs/2601.04550)
*Zhiyan Zhou,Junjie Liao,Manho Zhang,Yingyi Liao,Ziai Wang*

Main category: cs.LG

TL;DR: 提出GEnSHIN网络用于交通流预测，通过注意力增强图卷积循环单元、非对称双嵌入图生成机制和动态记忆库模块，在METR-LA数据集上取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 随着城市化加速，智能交通系统对准确交通流预测的需求日益增长。现有方法难以有效处理交通流中复杂的时空依赖关系。

Method: 提出GEnSHIN网络，包含三个核心设计：1) 注意力增强图卷积循环单元(GCRU)，引入Transformer模块增强长期时序依赖建模；2) 非对称双嵌入图生成机制，结合真实路网和数据驱动的潜在非对称拓扑；3) 动态记忆库模块，使用可学习的交通模式原型，并在解码阶段引入轻量级图更新器。

Result: 在METR-LA数据集上，GEnSHIN在MAE、RMSE、MAPE等多个指标上达到或超越对比模型性能。特别在早晚高峰时段表现出优异的预测稳定性。消融实验验证了各核心模块的有效性。

Conclusion: GEnSHIN通过创新的图增强时空分层推理架构，有效解决了交通流预测中的复杂时空依赖问题，为智能交通系统提供了更准确的预测工具。

Abstract: With the acceleration of urbanization, intelligent transportation systems have an increasing demand for accurate traffic flow prediction. This paper proposes a novel Graph Enhanced Spatio-temporal Hierarchical Inference Network (GEnSHIN) to handle the complex spatio-temporal dependencies in traffic flow prediction. The model integrates three innovative designs: 1) An attention-enhanced Graph Convolutional Recurrent Unit (GCRU), which strengthens the modeling capability for long-term temporal dependencies by introducing Transformer modules; 2) An asymmetric dual-embedding graph generation mechanism, which leverages the real road network and data-driven latent asymmetric topology to generate graph structures that better fit the characteristics of actual traffic flow; 3) A dynamic memory bank module, which utilizes learnable traffic pattern prototypes to provide personalized traffic pattern representations for each sensor node, and introduces a lightweight graph updater during the decoding phase to adapt to dynamic changes in road network states. Extensive experiments on the public dataset METR-LA show that GEnSHIN achieves or surpasses the performance of comparative models across multiple metrics such as Mean Absolute Error (MAE), Root Mean Square Error (RMSE), and Mean Absolute Percentage Error (MAPE). Notably, the model demonstrates excellent prediction stability during peak morning and evening traffic hours. Ablation experiments further validate the effectiveness of each core module and its contribution to the final performance.

</details>


### [38] [Improving Semi-Supervised Contrastive Learning via Entropy-Weighted Confidence Integration of Anchor-Positive Pairs](https://arxiv.org/abs/2601.04555)
*Shogo Nakayama,Masahiro Okuda*

Main category: cs.LG

TL;DR: 提出基于信息熵的自适应加权对比学习损失函数，改进半监督学习中的伪标签分配策略


<details>
  <summary>Details</summary>
Motivation: 传统半监督对比学习方法只对预测概率超过阈值的样本分配伪标签，这限制了训练数据的利用效率，特别是在低标签条件下可能导致学习不稳定

Method: 提出新的损失函数，基于预测概率分布的信息熵估计样本置信度，应用置信度自适应加权，允许对之前被排除的样本也分配伪标签，并考虑锚点和正样本的置信度进行对比学习

Result: 实验结果表明，该方法提高了分类准确率，在低标签条件下实现了更稳定的学习性能

Conclusion: 基于信息熵的置信度自适应加权对比学习方法能更有效地利用未标记数据，提升半监督学习效果

Abstract: Conventional semi-supervised contrastive learning methods assign pseudo-labels only to samples whose highest predicted class probability exceeds a predefined threshold, and then perform supervised contrastive learning using those selected samples. In this study, we propose a novel loss function that estimates the confidence of each sample based on the entropy of its predicted probability distribution and applies confidence-based adaptive weighting. This approach enables pseudo-label assignment even to samples that were previously excluded from training and facilitates contrastive learning that accounts for the confidence of both anchor and positive samples in a more principled manner. Experimental results demonstrate that the proposed method improves classification accuracy and achieves more stable learning performance even under low-label conditions.

</details>


### [39] [A Vision for Multisensory Intelligence: Sensing, Synergy, and Science](https://arxiv.org/abs/2601.04563)
*Paul Pu Liang*

Main category: cs.LG

TL;DR: 该论文提出了未来十年多感官人工智能的研究愿景，旨在将AI从数字模态扩展到人类所有感官体验，通过传感、科学和协同三个主题推动该领域发展。


<details>
  <summary>Details</summary>
Motivation: 当前人工智能主要局限于文本、视觉和音频等数字模态，而人类体验是多感官的。为了让人工智能更好地理解和交互真实世界，需要将其扩展到触觉、味觉、嗅觉等更多感官维度，连接AI与人类感官体验。

Method: 提出通过三个相互关联的主题推进多感官AI：1）传感：扩展AI捕捉世界的方式，超越数字媒介；2）科学：建立量化多模态异质性和交互的原理性科学，开发统一建模架构和表示；3）协同：学习模态之间以及人与AI之间的协同作用。

Result: 论文提出了完整的研究框架和愿景，并介绍了MIT媒体实验室多感官智能小组的最新进展、项目、资源和演示，为未来十年该领域的发展指明了方向。

Conclusion: 多感官人工智能将改变人类与AI的交互方式，通过连接AI到人类感官和丰富的生理、触觉、物理和社会信号，创造更自然、丰富的交互体验，需要跨学科合作推动传感、科学和协同三个方面的技术进步。

Abstract: Our experience of the world is multisensory, spanning a synthesis of language, sight, sound, touch, taste, and smell. Yet, artificial intelligence has primarily advanced in digital modalities like text, vision, and audio. This paper outlines a research vision for multisensory artificial intelligence over the next decade. This new set of technologies can change how humans and AI experience and interact with one another, by connecting AI to the human senses and a rich spectrum of signals from physiological and tactile cues on the body, to physical and social signals in homes, cities, and the environment. We outline how this field must advance through three interrelated themes of sensing, science, and synergy. Firstly, research in sensing should extend how AI captures the world in richer ways beyond the digital medium. Secondly, developing a principled science for quantifying multimodal heterogeneity and interactions, developing unified modeling architectures and representations, and understanding cross-modal transfer. Finally, we present new technical challenges to learn synergy between modalities and between humans and AI, covering multisensory integration, alignment, reasoning, generation, generalization, and experience. Accompanying this vision paper are a series of projects, resources, and demos of latest advances from the Multisensory Intelligence group at the MIT Media Lab, see https://mit-mi.github.io/.

</details>


### [40] [Spatial-Temporal Feedback Diffusion Guidance for Controlled Traffic Imputation](https://arxiv.org/abs/2601.04572)
*Xiaowei Mao,Huihu Ding,Yan Lin,Tingrui Wu,Shengnan Guo,Dazhuo Qiu,Feiling Fang,Jilin Hu,Huaiyu Wan*

Main category: cs.LG

TL;DR: FENCE提出了一种时空反馈扩散引导方法，通过动态调整引导尺度来改进交通数据缺失值插补，特别针对高缺失率节点。


<details>
  <summary>Details</summary>
Motivation: 现有基于分数的扩散模型在时空交通数据插补中通常对所有节点使用统一的引导尺度，这对于高缺失率节点效果不佳。稀疏观测无法提供足够的条件引导，导致生成过程偏向先验分布而非条件观测，从而影响插补性能。

Method: FENCE包含两个核心机制：1）基于后验似然近似的动态反馈机制，根据生成值与观测值的偏差自适应调整引导尺度；2）基于注意力分数对节点进行聚类，在集群级别计算引导尺度，利用时空相关性提供更精确的引导。

Result: 在真实世界交通数据集上的实验结果表明，FENCE显著提升了插补准确性。

Conclusion: FENCE通过自适应调整引导尺度和集群级引导策略，有效解决了高缺失率节点的插补问题，提高了扩散模型在时空交通数据插补中的性能。

Abstract: Imputing missing values in spatial-temporal traffic data is essential for intelligent transportation systems. Among advanced imputation methods, score-based diffusion models have demonstrated competitive performance. These models generate data by reversing a noising process, using observed values as conditional guidance. However, existing diffusion models typically apply a uniform guidance scale across both spatial and temporal dimensions, which is inadequate for nodes with high missing data rates. Sparse observations provide insufficient conditional guidance, causing the generative process to drift toward the learned prior distribution rather than closely following the conditional observations, resulting in suboptimal imputation performance.
  To address this, we propose FENCE, a spatial-temporal feedback diffusion guidance method designed to adaptively control guidance scales during imputation. First, FENCE introduces a dynamic feedback mechanism that adjusts the guidance scale based on the posterior likelihood approximations. The guidance scale is increased when generated values diverge from observations and reduced when alignment improves, preventing overcorrection. Second, because alignment to observations varies across nodes and denoising steps, a global guidance scale for all nodes is suboptimal. FENCE computes guidance scales at the cluster level by grouping nodes based on their attention scores, leveraging spatial-temporal correlations to provide more accurate guidance. Experimental results on real-world traffic datasets show that FENCE significantly enhances imputation accuracy.

</details>


### [41] [FedKDX: Federated Learning with Negative Knowledge Distillation for Enhanced Healthcare AI Systems](https://arxiv.org/abs/2601.04587)
*Quang-Tu Pham,Hoang-Dieu Vu,Dinh-Dat Pham,Hieu H. Pham*

Main category: cs.LG

TL;DR: FedKDX是一个联邦学习框架，通过负知识蒸馏（NKD）改进医疗AI，在保护隐私的同时提升模型泛化能力，在非IID数据上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习方法在医疗AI中存在局限性，主要关注正知识转移而忽略了非目标信息，难以处理医疗数据中的统计异质性和隐私约束。

Method: 提出FedKDX框架，整合传统知识蒸馏、对比学习和负知识蒸馏（NKD），在统一架构中同时捕获目标和非目标信息，减少通信成本并保护隐私。

Result: 在SLEEP、UCI-HAR和PAMAP2医疗数据集上，FedKDX比现有方法准确率提升最高达2.53%，收敛更快，在非IID数据分布上表现更好。

Conclusion: FedKDX为HIPAA和GDPR等监管框架下的隐私敏感医疗应用提供了平衡性能和实际需求的解决方案，理论分析支持NKD处理分布式医疗数据统计异质性的有效性。

Abstract: This paper introduces FedKDX, a federated learning framework that addresses limitations in healthcare AI through Negative Knowledge Distillation (NKD). Unlike existing approaches that focus solely on positive knowledge transfer, FedKDX captures both target and non-target information to improve model generalization in healthcare applications. The framework integrates multiple knowledge transfer techniques--including traditional knowledge distillation, contrastive learning, and NKD--within a unified architecture that maintains privacy while reducing communication costs. Through experiments on healthcare datasets (SLEEP, UCI-HAR, and PAMAP2), FedKDX demonstrates improved accuracy (up to 2.53% over state-of-the-art methods), faster convergence, and better performance on non-IID data distributions. Theoretical analysis supports NKD's contribution to addressing statistical heterogeneity in distributed healthcare data. The approach shows promise for privacy-sensitive medical applications under regulatory frameworks like HIPAA and GDPR, offering a balanced solution between performance and practical implementation requirements in decentralized healthcare settings. The code and model are available at https://github.com/phamdinhdat-ai/Fed_2024.

</details>


### [42] [Density Matrix RNN (DM-RNN): A Quantum Information Theoretic Framework for Modeling Musical Context and Polyphony](https://arxiv.org/abs/2601.04592)
*Joonwon Seo,Mariana Montiel*

Main category: cs.LG

TL;DR: 提出DM-RNN架构，使用密度矩阵表示音乐的不确定性，通过量子通道建模时序动态，确保物理有效性，并用量子信息论工具分析音乐结构。


<details>
  <summary>Details</summary>
Motivation: 传统RNN将音乐上下文总结为确定性隐藏状态向量，形成了信息瓶颈，无法捕捉音乐固有的模糊性和多义性。音乐中存在多种可能的解释和不确定性，需要更丰富的表示方法。

Method: 提出密度矩阵RNN（DM-RNN）架构，使用密度矩阵表示音乐解释的统计集合（混合状态），捕捉经典概率和量子相干性。使用时序动态的量子通道（CPTP映射）建模，基于Choi-Jamiolkowski同构的参数化策略确保学习到的动态保持物理有效性（CPTP）。

Result: 建立了使用冯·诺依曼熵量化音乐不确定性和量子互信息（QMI）测量声部间纠缠的分析框架。DM-RNN为建模复杂、模糊的音乐结构提供了数学严谨的框架。

Conclusion: DM-RNN通过量子信息论的概念，为音乐建模提供了更丰富的表示能力，能够捕捉音乐中的不确定性和多义性，为复杂音乐结构分析提供了新的理论工具。

Abstract: Classical Recurrent Neural Networks (RNNs) summarize musical context into a deterministic hidden state vector, imposing an information bottleneck that fails to capture the inherent ambiguity in music. We propose the Density Matrix RNN (DM-RNN), a novel theoretical architecture utilizing the Density Matrix. This allows the model to maintain a statistical ensemble of musical interpretations (a mixed state), capturing both classical probabilities and quantum coherences. We rigorously define the temporal dynamics using Quantum Channels (CPTP maps). Crucially, we detail a parameterization strategy based on the Choi-Jamiolkowski isomorphism, ensuring the learned dynamics remain physically valid (CPTP) by construction. We introduce an analytical framework using Von Neumann Entropy to quantify musical uncertainty and Quantum Mutual Information (QMI) to measure entanglement between voices. The DM-RNN provides a mathematically rigorous framework for modeling complex, ambiguous musical structures.

</details>


### [43] [DeepHalo: A Neural Choice Model with Controllable Context Effects](https://arxiv.org/abs/2601.04616)
*Shuhan Zhang,Zhi Wang,Rui Gao,Shuang Li*

Main category: cs.LG

TL;DR: DeepHalo：一个神经建模框架，用于建模人类决策中的上下文效应（光环效应），支持特征集成、显式控制交互阶数，并提供可解释性。


<details>
  <summary>Details</summary>
Motivation: 人类决策建模在推荐、偏好学习和人机对齐等应用中至关重要。传统模型假设上下文无关的选择行为，但行为研究表明偏好常受选择集组成影响（上下文效应/光环效应）。现有模型要么忽略特征，要么交互结构受限，或所有阶数交互纠缠，限制了可解释性。

Method: 提出DeepHalo神经建模框架：1）集成特征信息；2）显式控制交互阶数（可指定一阶、二阶等）；3）提供上下文效应的原则性解释；4）在无特征设置下可作为上下文相关选择函数的通用逼近器。

Result: 在合成和真实数据集上的实验表明：1）强大的预测性能；2）提供对选择驱动因素的更大透明度；3）能够系统识别按阶数分类的交互效应。

Conclusion: DeepHalo框架成功解决了现有模型在特征集成、交互阶数控制和可解释性方面的限制，为建模上下文依赖的人类决策提供了更透明、更灵活的工具。

Abstract: Modeling human decision-making is central to applications such as recommendation, preference learning, and human-AI alignment. While many classic models assume context-independent choice behavior, a large body of behavioral research shows that preferences are often influenced by the composition of the choice set itself -- a phenomenon known as the context effect or Halo effect. These effects can manifest as pairwise (first-order) or even higher-order interactions among the available alternatives. Recent models that attempt to capture such effects either focus on the featureless setting or, in the feature-based setting, rely on restrictive interaction structures or entangle interactions across all orders, which limits interpretability. In this work, we propose DeepHalo, a neural modeling framework that incorporates features while enabling explicit control over interaction order and principled interpretation of context effects. Our model enables systematic identification of interaction effects by order and serves as a universal approximator of context-dependent choice functions when specialized to a featureless setting. Experiments on synthetic and real-world datasets demonstrate strong predictive performance while providing greater transparency into the drivers of choice.

</details>


### [44] [Learning Dynamics in RL Post-Training for Language Models](https://arxiv.org/abs/2601.04670)
*Akiyoshi Tomihari*

Main category: cs.LG

TL;DR: 本文通过神经正切核框架分析RL后训练的学习动态，发现特征表示多样性有限会导致模型置信度系统性增加，从而解释输出多样性减少现象，并提出分类器优先强化学习策略。


<details>
  <summary>Details</summary>
Motivation: 强化学习后训练是语言模型开发的关键阶段，但其中一些现象（如输出多样性减少）尚未得到充分理解。本文旨在从监督学习中已有但强化学习中未充分探索的角度，更广泛地理解RL后训练的学习动态。

Method: 采用经验神经正切核框架，将NTK分解为两个组件来分析RL更新如何在训练样本间传播。基于分析结果提出分类器优先强化学习策略，该策略优先更新分类器再进行标准RL优化。

Result: 分析表明特征表示多样性有限会导致RL更新系统性增加模型置信度，解释了输出多样性减少现象。CF-RL策略实验验证了理论分析，显示能增加模型置信度并加速优化，且其机制不同于监督学习中的线性探测再微调。

Conclusion: 本研究形式化了RL后训练的学习动态，为理解输出多样性减少等现象提供了理论解释，并提出了有效的改进策略，为进一步分析和改进RL后训练奠定了基础。

Abstract: Reinforcement learning (RL) post-training is a critical stage in modern language model development, playing a key role in improving alignment and reasoning ability. However, several phenomena remain poorly understood, including the reduction in output diversity. To gain a broader understanding of RL post-training, we analyze the learning dynamics of RL post-training from a perspective that has been studied in supervised learning but remains underexplored in RL. We adopt an empirical neural tangent kernel (NTK) framework and decompose the NTK into two components to characterize how RL updates propagate across training samples. Our analysis reveals that limited variability in feature representations can cause RL updates to systematically increase model confidence, providing an explanation for the commonly observed reduction in output diversity after RL post-training. Furthermore, we show that effective learning in this regime depends on rapidly shaping the classifier, which directly affects the gradient component of the NTK. Motivated by these insights, we propose classifier-first reinforcement learning (CF-RL), a simple two-stage training strategy that prioritizes classifier updates before standard RL optimization. Experimental results validate our theoretical analysis by demonstrating increased model confidence and accelerated optimization under CF-RL. Additional analysis shows that the mechanism underlying CF-RL differs from that of linear-probing-then-fine-tuning in supervised learning. Overall, our study formalizes the learning dynamics of RL post-training and motivates further analysis and improvement.

</details>


### [45] [Estimating Causal Effects in Gaussian Linear SCMs with Finite Data](https://arxiv.org/abs/2601.04673)
*Aurghya Maiti,Prateek Jain*

Main category: cs.LG

TL;DR: 该论文提出了集中化高斯线性结构因果模型（CGL-SCMs），解决了在存在潜在混杂因素时从观测数据估计因果效应的挑战，并开发了基于EM的估计算法。


<details>
  <summary>Details</summary>
Motivation: 从观测数据估计因果效应是因果推断的基本挑战，特别是在存在潜在混杂因素的情况下。高斯线性结构因果模型（GL-SCMs）虽然分析上易于处理，但由于过度参数化，在有限数据下参数估计往往不可行。

Method: 提出了集中化高斯线性结构因果模型（CGL-SCMs），这是一个简化但表达能力强的子类，其中外生变量遵循标准化分布。开发了基于EM的估计算法，可以从有限观测样本中学习CGL-SCM参数并估计可识别的因果效应。

Result: 理论分析表明CGL-SCMs在因果效应可识别性方面与GL-SCMs具有同等表达能力。在合成数据和基准因果图上的实验验证了学习模型能够准确恢复因果分布。

Conclusion: CGL-SCMs为从有限观测数据估计因果效应提供了一个可行的框架，解决了传统GL-SCMs中的过度参数化问题，并通过EM算法实现了有效的参数学习和因果效应估计。

Abstract: Estimating causal effects from observational data remains a fundamental challenge in causal inference, especially in the presence of latent confounders. This paper focuses on estimating causal effects in Gaussian Linear Structural Causal Models (GL-SCMs), which are widely used due to their analytical tractability. However, parameter estimation in GL-SCMs is often infeasible with finite data, primarily due to overparameterization. To address this, we introduce the class of Centralized Gaussian Linear SCMs (CGL-SCMs), a simplified yet expressive subclass where exogenous variables follow standardized distributions. We show that CGL-SCMs are equally expressive in terms of causal effect identifiability from observational distributions and present a novel EM-based estimation algorithm that can learn CGL-SCM parameters and estimate identifiable causal effects from finite observational samples. Our theoretical analysis is validated through experiments on synthetic data and benchmark causal graphs, demonstrating that the learned models accurately recover causal distributions.

</details>


### [46] [Nightmare Dreamer: Dreaming About Unsafe States And Planning Ahead](https://arxiv.org/abs/2601.04686)
*Oluwatosin Oseni,Shengjie Wang,Jun Zhu,Micah Corah*

Main category: cs.LG

TL;DR: Nightmare Dreamer是一种基于模型的安全强化学习算法，通过世界模型预测安全违规并规划动作，在Safety Gymnasium任务上实现近乎零安全违规和20倍效率提升。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习在机器人控制等实际应用中表现出色，但由于缺乏足够的安全保证，其应用仍然受限。现有方法无法充分解决安全问题，限制了RL的广泛采用。

Method: 提出Nightmare Dreamer算法，这是一种基于模型的安全强化学习方法。算法通过学习世界模型来预测潜在的安全违规，并据此规划动作。该方法仅使用图像观测，在Safety Gymnasium任务上进行评估。

Result: Nightmare Dreamer在Safety Gymnasium任务上表现优异，实现了近乎零安全违规，同时最大化奖励。与无模型基线相比，效率提升了近20倍。

Conclusion: Nightmare Dreamer通过基于模型的方法有效解决了强化学习中的安全问题，在保持高性能的同时显著减少了安全违规，为安全强化学习的实际应用提供了有前景的解决方案。

Abstract: Reinforcement Learning (RL) has shown remarkable success in real-world applications, particularly in robotics control. However, RL adoption remains limited due to insufficient safety guarantees. We introduce Nightmare Dreamer, a model-based Safe RL algorithm that addresses safety concerns by leveraging a learned world model to predict potential safety violations and plan actions accordingly. Nightmare Dreamer achieves nearly zero safety violations while maximizing rewards. Nightmare Dreamer outperforms model-free baselines on Safety Gymnasium tasks using only image observations, achieving nearly a 20x improvement in efficiency.

</details>


### [47] [Do LLMs Benefit from User and Item Embeddings in Recommendation Tasks?](https://arxiv.org/abs/2601.04690)
*Mir Rayat Imtiaz Hossain,Leo Feng,Leonid Sigal,Mohamed Osama Ahmed*

Main category: cs.LG

TL;DR: 提出一种将协同过滤嵌入投影到LLM标记空间的方法，结合文本和协同信号来改进基于LLM的推荐系统


<details>
  <summary>Details</summary>
Motivation: 现有LLM推荐方法主要依赖文本语义，对协同信号利用有限，难以处理用户历史中的多个项目嵌入，忽略了丰富的协同信息

Method: 通过轻量级投影模块将协同过滤学习到的用户和项目嵌入投影到LLM标记空间，微调LLM同时处理投影嵌入和文本标记来生成推荐

Result: 初步结果显示该方法能有效利用结构化用户-项目交互数据，相比纯文本LLM基线提升了推荐性能

Conclusion: 该方法为传统推荐系统与现代LLM的融合提供了实用路径，能更好地结合文本语义和协同信号

Abstract: Large Language Models (LLMs) have emerged as promising recommendation systems, offering novel ways to model user preferences through generative approaches. However, many existing methods often rely solely on text semantics or incorporate collaborative signals in a limited manner, typically using only user or item embeddings. These methods struggle to handle multiple item embeddings representing user history, reverting to textual semantics and neglecting richer collaborative information. In this work, we propose a simple yet effective solution that projects user and item embeddings, learned from collaborative filtering, into the LLM token space via separate lightweight projector modules. A finetuned LLM then conditions on these projected embeddings alongside textual tokens to generate recommendations. Preliminary results show that this design effectively leverages structured user-item interaction data, improves recommendation performance over text-only LLM baselines, and offers a practical path for bridging traditional recommendation systems with modern LLMs.

</details>


### [48] [A zone-based training approach for last-mile routing using Graph Neural Networks and Pointer Networks](https://arxiv.org/abs/2601.04705)
*Àngel Ruiz-Fas,Carlos Granell,José Francisco Ramos,Joaquín Huerta,Sergio Trilles*

Main category: cs.LG

TL;DR: 提出基于深度学习的最后一公里配送路径优化方法，通过地理分区训练模型，在亚马逊配送挑战数据集上验证了分区训练比通用训练效果更好


<details>
  <summary>Details</summary>
Motivation: 电商快速增长使最后一公里配送网络面临极限，传统启发式方法难以适应高度不对称的旅行时间（如单行道、拥堵）。需要更智能的路径规划方法来降低成本、加快服务并减少排放

Method: 采用编码器-解码器架构：图神经网络编码器处理节点嵌入，指针网络解码器顺序选择下一站点。使用离散全球网格系统划分地理区域，为每个区域训练独立模型，只考虑该区域内的配送站点

Result: 在亚马逊最后一公里配送挑战的洛杉矶路线上评估，分区训练相比通用训练减少了平均预测路径长度。随着每路线站点数量增加，分区方法的性能提升更加显著

Conclusion: 基于深度学习的分区训练方法能有效优化最后一公里配送路径，特别适用于站点密集的不对称旅行时间场景，为实际物流配送提供了可行的智能解决方案

Abstract: Rapid e-commerce growth has pushed last-mile delivery networks to their limits, where small routing gains translate into lower costs, faster service, and fewer emissions. Classical heuristics struggle to adapt when travel times are highly asymmetric (e.g., one-way streets, congestion). A deep learning-based approach to the last-mile routing problem is presented to generate geographical zones composed of stop sequences to minimize last-mile delivery times.
  The presented approach is an encoder-decoder architecture. Each route is represented as a complete directed graph whose nodes are stops and whose edge weights are asymmetric travel times. A Graph Neural Network encoder produces node embeddings that captures the spatial relationships between stops. A Pointer Network decoder then takes the embeddings and the route's start node to sequentially select the next stops, assigning a probability to each unvisited node as the next destination.
  Cells of a Discrete Global Grid System which contain route stops in the training data are obtained and clustered to generate geographical zones of similar size in which the process of training and inference are divided. Subsequently, a different instance of the model is trained per zone only considering the stops of the training routes which are included in that zone.
  This approach is evaluated using the Los Angeles routes from the 2021 Amazon Last Mile Routing Challenge. Results from general and zone-based training are compared, showing a reduction in the average predicted route length in the zone-based training compared to the general training. The performance improvement of the zone-based approach becomes more pronounced as the number of stops per route increases.

</details>


### [49] [MQ-GNN: A Multi-Queue Pipelined Architecture for Scalable and Efficient GNN Training](https://arxiv.org/abs/2601.04707)
*Irfan Ullah,Young-Koo Lee*

Main category: cs.LG

TL;DR: MQ-GNN是一个多队列流水线框架，通过交错GNN训练阶段和优化资源利用，实现多GPU GNN训练的高效扩展，相比现有方法达到4.6倍加速和30%GPU利用率提升。


<details>
  <summary>Details</summary>
Motivation: 图神经网络(GNNs)在处理图结构数据时面临可扩展性挑战，包括低效的小批量生成、数据传输瓶颈和昂贵的GPU间同步。现有训练框架无法重叠这些阶段，导致资源利用不足。

Method: 提出MQ-GNN框架：1) 引入RaCoM(就绪更新异步一致性模型)，支持异步梯度共享和模型更新，通过自适应周期性同步确保全局一致性；2) 采用全局邻居采样与缓存减少数据传输开销；3) 使用自适应队列大小策略平衡计算和内存效率。

Result: 在四个大规模数据集和十个基线模型上的实验表明，MQ-GNN实现高达4.6倍的训练加速和30%的GPU利用率提升，同时保持竞争力的准确率。

Conclusion: MQ-GNN为多GPU GNN训练提供了一个可扩展且高效的解决方案，通过流水线化训练阶段和优化资源利用，显著提升了训练效率。

Abstract: Graph Neural Networks (GNNs) are powerful tools for learning graph-structured data, but their scalability is hindered by inefficient mini-batch generation, data transfer bottlenecks, and costly inter-GPU synchronization. Existing training frameworks fail to overlap these stages, leading to suboptimal resource utilization. This paper proposes MQ-GNN, a multi-queue pipelined framework that maximizes training efficiency by interleaving GNN training stages and optimizing resource utilization. MQ-GNN introduces Ready-to-Update Asynchronous Consistent Model (RaCoM), which enables asynchronous gradient sharing and model updates while ensuring global consistency through adaptive periodic synchronization. Additionally, it employs global neighbor sampling with caching to reduce data transfer overhead and an adaptive queue-sizing strategy to balance computation and memory efficiency. Experiments on four large-scale datasets and ten baseline models demonstrate that MQ-GNN achieves up to \boldmath $\bm{4.6\,\times}$ faster training time and 30% improved GPU utilization while maintaining competitive accuracy. These results establish MQ-GNN as a scalable and efficient solution for multi-GPU GNN training.

</details>


### [50] [GPU-Accelerated INT8 Quantization for KV Cache Compression in Large Language Models](https://arxiv.org/abs/2601.04719)
*Maanas Taneja,Purab Shingvi*

Main category: cs.LG

TL;DR: 论文实现了GPU加速的INT8量化KV缓存压缩，通过4种CUDA内核变体实现4倍内存减少，在10亿元素规模下保持低误差，推理延迟仅增加6-58ms。


<details>
  <summary>Details</summary>
Motivation: 大语言模型推理时，KV缓存的内存占用随序列长度线性增长，常常超过模型权重本身，成为显著的内存瓶颈。

Method: 开发了四种CUDA内核变体（naive、tiled、coarsened、vectorized），实现GPU加速的INT8量化KV缓存压缩，在10亿元素规模下进行基准测试。

Result: 向量化内核相比CPU基线实现高达1694倍加速，重建误差低于0.004，注意力分数误差低于0.1（即使是8K维度头），内存减少4倍，推理延迟仅增加6-58ms。

Conclusion: INT8量化为减少LLM推理内存压力提供了实用方法，计算开销可忽略，对下游模型行为影响极小。

Abstract: The key-value (KV) cache in large language models presents a significant memory bottleneck during inference, growing linearly with sequence length and often exceeding the memory footprint of model weights themselves. We implement and evaluate GPU-accelerated INT8 quantization for KV cache compression, achieving 4$\times$ memory reduction with minimal accuracy degradation. We develop four CUDA kernel variants -- naive, tiled, coarsened, and vectorized -- and benchmark them across realistic workload sizes up to 1 billion elements. Our vectorized kernel achieves up to 1,694$\times$ speedup over CPU baselines while maintaining reconstruction error below 0.004 and attention score error below 0.1 even for 8K-dimensional heads. These results demonstrate that INT8 quantization provides a practical approach for reducing memory pressure in LLM inference with negligible computational overhead (6--58ms) and minimal impact on downstream model behavior

</details>


### [51] [Excess Description Length of Learning Generalizable Predictors](https://arxiv.org/abs/2601.04728)
*Elizabeth Donoway,Hailey Joren,Fabien Roger,Jan Leike*

Main category: cs.LG

TL;DR: 论文提出了一个基于信息论的框架Excess Description Length (EDL)来量化微调过程中从训练数据提取并写入模型参数的结构信息，区分能力激发与能力教学。


<details>
  <summary>Details</summary>
Motivation: 理解微调是激发语言模型的潜在能力还是教授新能力，对于模型评估和安全至关重要。需要建立理论框架来量化微调过程中从训练数据提取的信息量。

Method: 提出Excess Description Length (EDL)这一核心指标，基于前向编码(prequential coding)理论，衡量在线训练过程中编码训练标签所需的比特数与最终训练模型下的剩余编码成本之间的差距。

Result: EDL在期望上非负，在无限数据极限下收敛到剩余描述长度，并提供期望泛化增益的边界。通过玩具模型澄清了学习中的常见混淆：随机标签的EDL接近零，单个示例能消除大量不确定性，罕见输入上学到的结构对泛化贡献小，格式学习产生与能力获取不同的早期瞬态。

Conclusion: 该框架为能力激发与能力教学具有不同扩展特征的实证观察提供了严格的理论基础，有助于更精确地理解微调过程中信息流动的本质。

Abstract: Understanding whether fine-tuning elicits latent capabilities or teaches new ones is a fundamental question for language model evaluation and safety. We develop a formal information-theoretic framework for quantifying how much predictive structure fine-tuning extracts from the train dataset and writes into a model's parameters. Our central quantity, Excess Description Length (EDL), is defined via prequential coding and measures the gap between the bits required to encode training labels sequentially using an evolving model (trained online) and the residual encoding cost under the final trained model. We establish that EDL is non-negative in expectation, converges to surplus description length in the infinite-data limit, and provides bounds on expected generalization gain. Through a series of toy models, we clarify common confusions about information in learning: why random labels yield EDL near zero, how a single example can eliminate many bits of uncertainty about the underlying rule(s) that describe the data distribution, why structure learned on rare inputs contributes proportionally little to expected generalization, and how format learning creates early transients distinct from capability acquisition. This framework provides rigorous foundations for the empirical observation that capability elicitation and teaching exhibit qualitatively distinct scaling signatures.

</details>


### [52] [Fast Mining and Dynamic Time-to-Event Prediction over Multi-sensor Data Streams](https://arxiv.org/abs/2601.04741)
*Kota Nakamura,Koki Kawabata,Yasuko Matsubara,Yasushi Sakurai*

Main category: cs.LG

TL;DR: TimeCast是一个动态预测框架，用于实时分析多传感器数据流，预测机器故障时间，能够适应数据模式变化并在线更新模型。


<details>
  <summary>Details</summary>
Motivation: 现实世界的数据流具有动态特性，底层模式会随时间演变，需要能够适应这些变化并提供准确实时预测的方法来预测机器故障时间。

Method: 提出TimeCast动态预测框架，识别随时间演变的不同模式（阶段），为每个阶段学习单独模型，基于模式转变进行自适应预测。该方法能够发现捕捉多传感器间时变相互依赖关系的有意义阶段。

Result: 在真实数据集上的广泛实验表明，TimeCast比最先进方法提供更高的预测准确性，同时能够发现数据流中的动态变化，并大幅减少计算时间。

Conclusion: TimeCast是一个动态、实用且可扩展的框架，能够有效处理实时传感器数据流的动态特性，为机器故障预测提供准确、自适应的实时预测能力。

Abstract: Given real-time sensor data streams obtained from machines, how can we continuously predict when a machine failure will occur? This work aims to continuously forecast the timing of future events by analyzing multi-sensor data streams. A key characteristic of real-world data streams is their dynamic nature, where the underlying patterns evolve over time. To address this, we present TimeCast, a dynamic prediction framework designed to adapt to these changes and provide accurate, real-time predictions of future event time. Our proposed method has the following properties: (a) Dynamic: it identifies the distinct time-evolving patterns (i.e., stages) and learns individual models for each, enabling us to make adaptive predictions based on pattern shifts. (b) Practical: it finds meaningful stages that capture time-varying interdependencies between multiple sensors and improve prediction performance; (c) Scalable: our algorithm scales linearly with the input size and enables online model updates on data streams. Extensive experiments on real datasets demonstrate that TimeCast provides higher prediction accuracy than state-of-the-art methods while finding dynamic changes in data streams with a great reduction in computational time.

</details>


### [53] [Intraday spatiotemporal PV power prediction at national scale using satellite-based solar forecast models](https://arxiv.org/abs/2601.04751)
*Luca Lanzilao,Angela Meyer*

Main category: cs.LG

TL;DR: 该研究提出了一个时空光伏功率预测框架，评估了7种日内光伏功率临近预报模型，发现基于卫星的方法在短预报时效内优于数值天气预报系统，其中SolarSTEPS和SHADECast表现最佳。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏国家尺度的时空光伏功率预测研究，需要评估不同模型（卫星深度学习、光流法、物理数值天气预报）在光伏功率预测中的性能，特别是对中尺度云系统如何影响国家光伏发电的机制理解不足。

Method: 建立时空光伏功率预测框架，首先用卫星数据验证表面太阳辐照度预测，然后通过站点特定的机器学习模型将辐照度转换为光伏功率，使用瑞士6434个光伏站点的生产数据进行对比分析。

Result: 基于卫星的方法（特别是SolarSTEPS和SHADECast）在短预报时效内优于IFS-ENS数值天气预报系统；SHADECast提供最可靠的集合预报分布；确定性模型IrradianceNet获得最低均方根误差；预报技能随海拔升高而降低；国家尺度上82%的日总光伏发电预测相对误差低于10%。

Conclusion: 这是首个国家尺度的时空光伏功率预测研究，展示了基于卫星的模型在操作应用中的潜力，能够准确预测中尺度云系统对光伏发电的影响，为电网调度和能源管理提供可靠支持。

Abstract: We present a novel framework for spatiotemporal photovoltaic (PV) power forecasting and use it to evaluate the reliability, sharpness, and overall performance of seven intraday PV power nowcasting models. The model suite includes satellite-based deep learning and optical-flow approaches and physics-based numerical weather prediction models, covering both deterministic and probabilistic formulations. Forecasts are first validated against satellite-derived surface solar irradiance (SSI). Irradiance fields are then converted into PV power using station-specific machine learning models, enabling comparison with production data from 6434 PV stations across Switzerland. To our knowledge, this is the first study to investigate spatiotemporal PV forecasting at a national scale. We additionally provide the first visualizations of how mesoscale cloud systems shape national PV production on hourly and sub-hourly timescales. Our results show that satellite-based approaches outperform the Integrated Forecast System (IFS-ENS), particularly at short lead times. Among them, SolarSTEPS and SHADECast deliver the most accurate SSI and PV power predictions, with SHADECast providing the most reliable ensemble spread. The deterministic model IrradianceNet achieves the lowest root mean square error, while probabilistic forecasts of SolarSTEPS and SHADECast provide better-calibrated uncertainty. Forecast skill generally decreases with elevation. At a national scale, satellite-based models forecast the daily total PV generation with relative errors below 10% for 82% of the days in 2019-2020, demonstrating robustness and their potential for operational use.

</details>


### [54] [Smart IoT-Based Wearable Device for Detection and Monitoring of Common Cow Diseases Using a Novel Machine Learning Technique](https://arxiv.org/abs/2601.04761)
*Rupsa Rani Mishra,D. Chandrasekhar Rao,Ajaya Kumar Tripathy*

Main category: cs.LG

TL;DR: 提出基于物联网和机器学习的奶牛健康监测系统，通过生理和行为数据自动检测多种常见疾病，解决人工监测效率低、成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 大规模养殖场中人工监测奶牛疾病存在劳动强度大、时间消耗多、准确性低的问题，导致疾病识别延迟，影响动物健康和农场生产效率。人工监测需要专业技能人员，成本高且管理复杂。

Method: 提出物联网支持的物理信息系统框架，收集奶牛日常活动和健康状态的生理与行为数据。开发新型机器学习算法，通过分析综合的生理和行为特征来预测多种常见疾病。

Result: 该系统能够实现奶牛健康监测的自动化，提高疾病检测的准确性和效率，同时降低运营成本。机器学习算法能够同时预测多种疾病，提供准确高效的健康评估。

Conclusion: 物联网和机器学习技术能够有效解决大规模养殖中奶牛健康监测的挑战，提出的自动化系统框架和算法为实现低成本、高可靠性的智能奶牛健康管理提供了可行方案。

Abstract: Manual observation and monitoring of individual cows for disease detection present significant challenges in large-scale farming operations, as the process is labor-intensive, time-consuming, and prone to reduced accuracy. The reliance on human observation often leads to delays in identifying symptoms, as the sheer number of animals can hinder timely attention to each cow. Consequently, the accuracy and precision of disease detection are significantly compromised, potentially affecting animal health and overall farm productivity. Furthermore, organizing and managing human resources for the manual observation and monitoring of cow health is a complex and economically demanding task. It necessitates the involvement of skilled personnel, thereby contributing to elevated farm maintenance costs and operational inefficiencies. Therefore, the development of an automated, low-cost, and reliable smart system is essential to address these challenges effectively. Although several studies have been conducted in this domain, very few have simultaneously considered the detection of multiple common diseases with high prediction accuracy. However, advancements in Internet of Things (IoT), Machine Learning (ML), and Cyber-Physical Systems have enabled the automation of cow health monitoring with enhanced accuracy and reduced operational costs. This study proposes an IoT-enabled Cyber-Physical System framework designed to monitor the daily activities and health status of cow. A novel ML algorithm is proposed for the diagnosis of common cow diseases using collected physiological and behavioral data. The algorithm is designed to predict multiple diseases by analyzing a comprehensive set of recorded physiological and behavioral features, enabling accurate and efficient health assessment.

</details>


### [55] [AgentOCR: Reimagining Agent History via Optical Self-Compression](https://arxiv.org/abs/2601.04786)
*Lang Feng,Fuchao Yang,Feng Chen,Xin Cheng,Haiyang Xu,Zhenglin Wan,Ming Yan,Bo An*

Main category: cs.LG

TL;DR: AgentOCR框架通过将文本历史转换为紧凑的图像表示，结合分段光学缓存和智能自压缩机制，显著降低LLM智能体系统的token消耗和内存使用，同时保持任务性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型智能体系统在多轮交互中会产生大量文本历史，导致token预算和内存使用急剧增长，成为实际部署的主要瓶颈。

Method: 1) 将累积的观察-动作历史渲染为紧凑的图像表示；2) 分段光学缓存机制，将历史分解为可哈希片段并维护视觉缓存，消除冗余重渲染；3) 智能自压缩机制，智能体主动发出压缩率，通过压缩感知奖励训练，自适应平衡任务成功和token效率。

Result: 在ALFWorld和搜索式QA等挑战性基准测试中，AgentOCR保持了超过95%的基于文本智能体的性能，同时显著减少token消耗(>50%)，实现了持续的token和内存效率。分段光学缓存带来20倍的渲染加速，自压缩机制有效实现战略平衡。

Conclusion: AgentOCR通过视觉token的信息密度优势、高效缓存机制和智能压缩策略，为LLM智能体系统提供了可扩展的解决方案，显著降低了部署成本，同时保持了任务性能。

Abstract: Recent advances in large language models (LLMs) enable agentic systems trained with reinforcement learning (RL) over multi-turn interaction trajectories, but practical deployment is bottlenecked by rapidly growing textual histories that inflate token budgets and memory usage. We introduce AgentOCR, a framework that exploits the superior information density of visual tokens by representing the accumulated observation-action history as a compact rendered image. To make multi-turn rollouts scalable, AgentOCR proposes segment optical caching. By decomposing history into hashable segments and maintaining a visual cache, this mechanism eliminates redundant re-rendering. Beyond fixed rendering, AgentOCR introduces agentic self-compression, where the agent actively emits a compression rate and is trained with compression-aware reward to adaptively balance task success and token efficiency. We conduct extensive experiments on challenging agentic benchmarks, ALFWorld and search-based QA. Remarkably, results demonstrate that AgentOCR preserves over 95\% of text-based agent performance while substantially reducing token consumption (>50\%), yielding consistent token and memory efficiency. Our further analysis validates a 20x rendering speedup from segment optical caching and the effective strategic balancing of self-compression.

</details>


### [56] [Neural-Symbolic Integration with Evolvable Policies](https://arxiv.org/abs/2601.04799)
*Marios Thoma,Vassilis Vassiliades,Loizos Michael*

Main category: cs.LG

TL;DR: 提出一个通过进化过程同时学习不可微分符号策略和神经网络权重的神经符号AI框架，无需预定义策略或可微分性要求


<details>
  <summary>Details</summary>
Motivation: 现有神经符号框架通常需要预定义符号策略或可微分策略，限制了在缺乏领域专家知识或策略本质不可微分情况下的应用

Method: 将神经符号系统视为种群中的有机体，通过进化过程（符号规则添加和神经网络权重变化的突变）和基于适应度的选择来学习；扩展NEUROLOG架构使符号策略可训练，将Valiant的可进化性框架适配到神经符号上下文，使用Machine Coaching语义处理可变符号表示，通过符号组件的溯因推理训练神经网络

Result: 从空策略和随机神经网络权重开始的神经符号系统能够成功近似隐藏的不可微分目标策略，中位数正确性能接近100%

Conclusion: 这项工作推动了神经符号AI在难以从专家获取符号知识领域的研究，使系统能够在没有预定义策略的情况下学习不可微分策略

Abstract: Neural-Symbolic (NeSy) Artificial Intelligence has emerged as a promising approach for combining the learning capabilities of neural networks with the interpretable reasoning of symbolic systems. However, existing NeSy frameworks typically require either predefined symbolic policies or policies that are differentiable, limiting their applicability when domain expertise is unavailable or when policies are inherently non-differentiable. We propose a framework that addresses this limitation by enabling the concurrent learning of both non-differentiable symbolic policies and neural network weights through an evolutionary process. Our approach casts NeSy systems as organisms in a population that evolve through mutations (both symbolic rule additions and neural weight changes), with fitness-based selection guiding convergence toward hidden target policies. The framework extends the NEUROLOG architecture to make symbolic policies trainable, adapts Valiant's Evolvability framework to the NeSy context, and employs Machine Coaching semantics for mutable symbolic representations. Neural networks are trained through abductive reasoning from the symbolic component, eliminating differentiability requirements. Through extensive experimentation, we demonstrate that NeSy systems starting with empty policies and random neural weights can successfully approximate hidden non-differentiable target policies, achieving median correct performance approaching 100%. This work represents a step toward enabling NeSy research in domains where the acquisition of symbolic knowledge from experts is challenging or infeasible.

</details>


### [57] [Parallelizing Node-Level Explainability in Graph Neural Networks](https://arxiv.org/abs/2601.04807)
*Oscar Llorente,Jaime Boal,Eugenio F. Sánchez-Úbeda,Antonio Diaz-Cano,Miguel Familiar*

Main category: cs.LG

TL;DR: 提出基于图划分的GNN节点级可解释性并行计算方法，通过将图分解为不相交子图实现并行计算，显著提升可扩展性和效率，同时保持结果正确性。


<details>
  <summary>Details</summary>
Motivation: GNN在节点分类等任务中表现出色，但随着图规模增大，计算节点级可解释性变得极其耗时，而批处理策略通常会降低解释质量。需要一种既能保持解释质量又能提高计算效率的解决方案。

Method: 1. 基于图划分的并行化方法：将图分解为不相交子图，实现节点邻居可解释性的并行计算；2. 针对内存受限场景的dropout重建机制：提供内存使用与解释保真度之间的可控权衡。

Result: 在真实世界数据集上的实验结果表明，该方法实现了显著的加速效果，能够为大规模GNN模型提供可扩展且透明的可解释性。

Conclusion: 提出的图划分并行化方法有效解决了GNN节点级可解释性计算的可扩展性问题，在保证结果正确性的前提下显著提升效率，为大规模GNN模型的可解释性分析提供了实用解决方案。

Abstract: Graph Neural Networks (GNNs) have demonstrated remarkable performance in a wide range of tasks, such as node classification, link prediction, and graph classification, by exploiting the structural information in graph-structured data. However, in node classification, computing node-level explainability becomes extremely time-consuming as the size of the graph increases, while batching strategies often degrade explanation quality. This paper introduces a novel approach to parallelizing node-level explainability in GNNs through graph partitioning. By decomposing the graph into disjoint subgraphs, we enable parallel computation of explainability for node neighbors, significantly improving the scalability and efficiency without affecting the correctness of the results, provided sufficient memory is available. For scenarios where memory is limited, we further propose a dropout-based reconstruction mechanism that offers a controllable trade-off between memory usage and explanation fidelity. Experimental results on real-world datasets demonstrate substantial speedups, enabling scalable and transparent explainability for large-scale GNN models.

</details>


### [58] [Rethinking GNNs and Missing Features: Challenges, Evaluation and a Robust Solution](https://arxiv.org/abs/2601.04855)
*Francesco Ferrini,Veronica Lachi,Antonio Longa,Bruno Lepri,Matono Akiyoshi,Andrea Passerini,Xin Liu,Manfred Jaeger*

Main category: cs.LG

TL;DR: 该论文针对图神经网络处理缺失节点特征的问题，提出了更真实的评估框架和有效的基线方法GNNmim。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多在相对理想化的场景下评估GNN处理缺失特征的能力：(1)使用高维稀疏特征，掩盖了缺失带来的信息损失；(2)采用完全随机缺失机制，不符合现实情况。需要更真实的评估框架来推动该领域发展。

Method: 1) 理论证明高稀疏性会限制信息损失，导致模型表现失真；2) 引入一个合成和三个真实数据集，具有密集且语义丰富的特征；3) 设计超越MCAR的更真实缺失机制评估协议；4) 提出理论框架明确缺失过程的假设；5) 提出简单有效的基线方法GNNmim。

Result: 实验表明，GNNmim在多样化数据集和缺失机制下，与专门架构相比具有竞争力。提出的评估框架能更真实地反映不同方法在缺失特征处理上的性能差异。

Conclusion: 该研究为GNN处理缺失节点特征提供了更真实的评估基准和理论基础，提出的GNNmim基线方法简单有效，能促进该领域的发展。

Abstract: Handling missing node features is a key challenge for deploying Graph Neural Networks (GNNs) in real-world domains such as healthcare and sensor networks. Existing studies mostly address relatively benign scenarios, namely benchmark datasets with (a) high-dimensional but sparse node features and (b) incomplete data generated under Missing Completely At Random (MCAR) mechanisms. For (a), we theoretically prove that high sparsity substantially limits the information loss caused by missingness, making all models appear robust and preventing a meaningful comparison of their performance. To overcome this limitation, we introduce one synthetic and three real-world datasets with dense, semantically meaningful features. For (b), we move beyond MCAR and design evaluation protocols with more realistic missingness mechanisms. Moreover, we provide a theoretical background to state explicit assumptions on the missingness process and analyze their implications for different methods. Building on this analysis, we propose GNNmim, a simple yet effective baseline for node classification with incomplete feature data. Experiments show that GNNmim is competitive with respect to specialized architectures across diverse datasets and missingness regimes.

</details>


### [59] [FibreCastML: An Open Web Platform for Predicting Electrospun Nanofibre Diameter Distributions](https://arxiv.org/abs/2601.04873)
*Elisa Roldan,Kirstie Andrews,Stephen M. Richardson,Reyhaneh Fatahian,Glen Cooper,Rasool Erfani,Tasneem Sabir,Neil D. Reeves*

Main category: cs.LG

TL;DR: 开发了FibreCastML框架，使用机器学习预测静电纺丝纤维的完整直径分布，而不仅仅是平均直径，提高了支架性能优化的可预测性。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习方法主要预测静电纺丝纤维的平均直径，忽略了决定支架性能的完整直径分布。需要开发能够预测完整纤维直径谱的框架，以更好地优化组织工程、药物输送和伤口护理应用中的支架结构。

Method: 从1778项研究中提取68538个纤维直径测量值构建元数据集，使用6个标准处理参数训练7种ML模型，采用嵌套交叉验证和留一研究外部折叠。通过变量重要性分析、SHAP解释、相关矩阵和三维参数图实现模型可解释性。

Result: 非线性模型优于线性基线，对多种常用聚合物达到0.91以上的决定系数。溶液浓度是纤维直径分布的主要驱动因素。不同静电纺丝系统的实验验证显示预测分布与实测分布高度一致。

Conclusion: FibreCastML框架能够预测完整的纤维直径分布，提供了可解释的过程-结构关系洞察，实现了更可重复和数据驱动的静电纺丝支架结构优化。

Abstract: Electrospinning is a scalable technique for producing fibrous scaffolds with tunable micro- and nanoscale architectures for applications in tissue engineering, drug delivery, and wound care. While machine learning (ML) has been used to support electrospinning process optimisation, most existing approaches predict only mean fibre diameters, neglecting the full diameter distribution that governs scaffold performance. This work presents FibreCastML, an open, distribution-aware ML framework that predicts complete fibre diameter spectra from routinely reported electrospinning parameters and provides interpretable insights into process structure relationships.
  A meta-dataset comprising 68538 individual fibre diameter measurements extracted from 1778 studies across 16 biomedical polymers was curated. Six standard processing parameters, namely solution concentration, applied voltage, flow rate, tip to collector distance, needle diameter, and collector rotation speed, were used to train seven ML models using nested cross validation with leave one study out external folds. Model interpretability was achieved using variable importance analysis, SHapley Additive exPlanations, correlation matrices, and three dimensional parameter maps.
  Non linear models consistently outperformed linear baselines, achieving coefficients of determination above 0.91 for several widely used polymers. Solution concentration emerged as the dominant global driver of fibre diameter distributions. Experimental validation across different electrospinning systems demonstrated close agreement between predicted and measured distributions. FibreCastML enables more reproducible and data driven optimisation of electrospun scaffold architectures.

</details>


### [60] [Learnable Multipliers: Freeing the Scale of Language Model Matrix Layers](https://arxiv.org/abs/2601.04890)
*Maksim Velikanov,Ilyas Chahed,Jingwei Zuo,Dhia Eddine Rhaiem,Younes Belkada,Hakim Hacid*

Main category: cs.LG

TL;DR: 论文提出通过引入可学习的乘数器来优化权重衰减（WD）与随机梯度噪声之间的平衡，替代传统的固定WD-noise均衡范数，从而提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统训练中，权重衰减与随机梯度噪声会形成WD-noise均衡，导致权重矩阵范数固定。作者认为这种均衡范数是训练过程的次优产物，限制了模型性能。

Method: 引入可学习的乘数器来优化权重尺度：1) 为权重矩阵W添加可学习的标量乘数器；2) 进一步引入可学习的每行和每列乘数器，释放行列范数的约束。该方法可视为muP乘数器的可学习、更通用的扩展。

Result: 方法优于精心调优的muP基线，减少了乘数器调优的计算开销，提升了下游任务性能。在Adam和Muon优化器上均验证有效，性能提升相当于从Adam切换到Muon的改进幅度。

Conclusion: 可学习的乘数器能够自适应数据优化权重尺度，打破传统WD-noise均衡的次优约束，是更灵活有效的训练方法，并提出了前向传播对称性和学习乘数器宽度缩放等实际问题。

Abstract: Applying weight decay (WD) to matrix layers is standard practice in large-language-model pretraining. Prior work suggests that stochastic gradient noise induces a Brownian-like expansion of the weight matrices W, whose growth is counteracted by WD, leading to a WD-noise equilibrium with a certain weight norm ||W||. In this work, we view the equilibrium norm as a harmful artifact of the training procedure, and address it by introducing learnable multipliers to learn the optimal scale. First, we attach a learnable scalar multiplier to W and confirm that the WD-noise equilibrium norm is suboptimal: the learned scale adapts to data and improves performance. We then argue that individual row and column norms are similarly constrained, and free their scale by introducing learnable per-row and per-column multipliers. Our method can be viewed as a learnable, more expressive generalization of muP multipliers. It outperforms a well-tuned muP baseline, reduces the computational overhead of multiplier tuning, and surfaces practical questions such as forward-pass symmetries and the width-scaling of the learned multipliers. Finally, we validate learnable multipliers with both Adam and Muon optimizers, where it shows improvement in downstream evaluations matching the improvement of the switching from Adam to Muon.

</details>


### [61] [Distributed Online Convex Optimization with Efficient Communication: Improved Algorithm and Lower bounds](https://arxiv.org/abs/2601.04907)
*Sifan Yang,Wenhao Yang,Wei Jiang,Lijun Zhang*

Main category: cs.LG

TL;DR: 本文研究了分布式在线凸优化中的压缩通信问题，提出了新的算法显著改进了现有遗憾界，将ω的依赖从二次/四次降低到线性/平方根，并建立了该问题的首个下界。


<details>
  <summary>Details</summary>
Motivation: 现有分布式在线凸优化算法在压缩通信下的遗憾界存在两个主要问题：1) 对压缩质量因子ω的依赖过强（二次或四次）；2) 对学习者数量n的依赖是超线性的。这些限制影响了算法在实际压缩通信场景中的效率和可扩展性。

Method: 提出了一种新颖的两级阻塞更新框架，包含两个关键创新：在线gossip策略和误差补偿方案。这两种机制协同工作以实现更好的学习者间共识。对于bandit反馈场景，还结合了经典的梯度估计器来扩展方法。

Result: 新算法在凸函数下实现了$\tilde{O}(ω^{-1/2}ρ^{-1}n\sqrt{T})$的遗憾界，在强凸函数下实现了$\tilde{O}(ω^{-1}ρ^{-2}n\ln{T})$的遗憾界，显著改进了现有结果。同时建立了该问题的首个下界，证明了结果在ω和T方面的最优性。

Conclusion: 本文通过创新的两级阻塞更新框架，显著改善了分布式在线凸优化中压缩通信的遗憾界，解决了现有方法对压缩质量和学习者数量的过度依赖问题，并建立了理论下界证明了结果的紧致性。

Abstract: We investigate distributed online convex optimization with compressed communication, where $n$ learners connected by a network collaboratively minimize a sequence of global loss functions using only local information and compressed data from neighbors. Prior work has established regret bounds of $O(\max\{ω^{-2}ρ^{-4}n^{1/2},ω^{-4}ρ^{-8}\}n\sqrt{T})$ and $O(\max\{ω^{-2}ρ^{-4}n^{1/2},ω^{-4}ρ^{-8}\}n\ln{T})$ for convex and strongly convex functions, respectively, where $ω\in(0,1]$ is the compression quality factor ($ω=1$ means no compression) and $ρ<1$ is the spectral gap of the communication matrix. However, these regret bounds suffer from a \emph{quadratic} or even \emph{quartic} dependence on $ω^{-1}$. Moreover, the \emph{super-linear} dependence on $n$ is also undesirable. To overcome these limitations, we propose a novel algorithm that achieves improved regret bounds of $\tilde{O}(ω^{-1/2}ρ^{-1}n\sqrt{T})$ and $\tilde{O}(ω^{-1}ρ^{-2}n\ln{T})$ for convex and strongly convex functions, respectively. The primary idea is to design a \emph{two-level blocking update framework} incorporating two novel ingredients: an online gossip strategy and an error compensation scheme, which collaborate to \emph{achieve a better consensus} among learners. Furthermore, we establish the first lower bounds for this problem, justifying the optimality of our results with respect to both $ω$ and $T$. Additionally, we consider the bandit feedback scenario, and extend our method with the classic gradient estimators to enhance existing regret bounds.

</details>


### [62] [Cardinality augmented loss functions](https://arxiv.org/abs/2601.04941)
*Miguel O'Malley*

Main category: cs.LG

TL;DR: 论文提出使用基数增强损失函数解决神经网络训练中的类别不平衡问题，通过数学中的magnitude和spread等不变量来评估数据的"有效多样性"，在人工不平衡数据集和真实材料科学数据集上都取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 类别不平衡是神经网络训练中常见且有害的问题，不平衡的多数类会主导训练过程，导致分类器性能偏向多数类结果。需要一种自然的方法来解决训练数据过于同质化的问题。

Method: 引入基数增强损失函数，这些函数源自现代数学文献中的基数类不变量，如magnitude和spread。这些不变量通过评估度量空间的"有效多样性"来丰富基数的概念。建立了在神经网络训练中应用基数增强损失函数的方法论。

Result: 在人工不平衡数据集和真实世界的材料科学不平衡数据集上都取得了显著性能提升。观察到少数类性能显著改善，整体性能指标也有所提高。

Conclusion: 基数增强损失函数为处理神经网络训练中的类别不平衡问题提供了一种有效的解决方案，通过数学中的基数类不变量来评估数据的有效多样性，能够显著提升少数类的分类性能。

Abstract: Class imbalance is a common and pernicious issue for the training of neural networks. Often, an imbalanced majority class can dominate training to skew classifier performance towards the majority outcome. To address this problem we introduce cardinality augmented loss functions, derived from cardinality-like invariants in modern mathematics literature such as magnitude and the spread. These invariants enrich the concept of cardinality by evaluating the `effective diversity' of a metric space, and as such represent a natural solution to overly homogeneous training data. In this work, we establish a methodology for applying cardinality augmented loss functions in the training of neural networks and report results on both artificially imbalanced datasets as well as a real-world imbalanced material science dataset. We observe significant performance improvement among minority classes, as well as improvement in overall performance metrics.

</details>


### [63] [Precision over Diversity: High-Precision Reward Generalizes to Robust Instruction Following](https://arxiv.org/abs/2601.04954)
*Yirong Zeng,Yufei Liu,Xiao Ding,Yutai Hou,Yuxian Wang,Haonan Song,Wu Ning,Dandan Tu,Qixun Zhang,Bibo Cai,Yuxiang He,Ting Liu*

Main category: cs.LG

TL;DR: 研究发现，在指令跟随任务中，仅使用可验证的硬约束训练模型比混合硬软约束效果更好，奖励精度比约束多样性更重要，并提出基于高精度奖励的数据中心化优化策略。


<details>
  <summary>Details</summary>
Motivation: 挑战当前主流观点，即认为指令跟随任务需要混合可验证硬约束和不可验证软约束才能泛化到未见指令。通过系统实证研究检验这一共识。

Method: 进行广泛的实验分析，发现LLM评判器在检测错误响应时召回率低导致严重奖励攻击；提出简单有效的数据中心化优化策略，优先考虑奖励精度而非多样性。

Result: 在五个基准测试中，该方法比竞争基线性能提升13.4%，训练时间减少58%，且在指令跟随之外保持强泛化能力。

Conclusion: 研究主张范式转变：从盲目追求数据多样性转向关注高精度奖励，奖励精度而非约束多样性是有效对齐的主要驱动力。

Abstract: A central belief in scaling reinforcement learning with verifiable rewards for instruction following (IF) tasks is that, a diverse mixture of verifiable hard and unverifiable soft constraints is essential for generalizing to unseen instructions. In this work, we challenge this prevailing consensus through a systematic empirical investigation. Counter-intuitively, we find that models trained on hard-only constraints consistently outperform those trained on mixed datasets. Extensive experiments reveal that reward precision, rather than constraint diversity, is the primary driver of effective alignment. The LLM judge suffers from a low recall rate in detecting false response, which leads to severe reward hacking, thereby undermining the benefits of diversity. Furthermore, analysis of the attention mechanism reveals that high-precision rewards develop a transferable meta-skill for IF. Motivated by these insights, we propose a simple yet effective data-centric refinement strategy that prioritizes reward precision. Evaluated on five benchmarks, our approach outperforms competitive baselines by 13.4\% in performance while achieving a 58\% reduction in training time, maintaining strong generalization beyond instruction following. Our findings advocate for a paradigm shift: moving away from the indiscriminate pursuit of data diversity toward high-precision rewards.

</details>


### [64] [On the Definition and Detection of Cherry-Picking in Counterfactual Explanations](https://arxiv.org/abs/2601.04977)
*James Hinns,Sofie Goethals,Stephan Van der Veeken,Theodoros Evgeniou,David Martens*

Main category: cs.LG

TL;DR: 该论文研究反事实解释中的"选择性呈现"问题，即解释提供者可能从多个有效反事实中挑选有利解释来操纵叙事，并探讨审计者检测这种操纵的局限性。


<details>
  <summary>Details</summary>
Motivation: 反事实解释被广泛用于说明输入如何改变才能改变模型预测。对于单个实例，可能存在多个有效反事实，这为解释提供者创造了选择性呈现的机会，他们可以挑选有利的解释来突出良好行为，同时隐藏揭示问题行为的例子。这种操纵风险需要被正式研究和检测。

Method: 论文首先形式化定义了反事实解释中的选择性呈现问题，通过可接受解释空间（由生成过程指定）和效用函数来描述。然后研究外部审计者在三种不同访问级别下检测这种操纵的能力：完全过程访问、部分过程访问和仅解释访问。通过理论分析和实证评估，考察选择性呈现解释与基线解释在统计上的可区分性。

Result: 研究发现检测在实践中极为有限。即使在完全过程访问的情况下，选择性呈现的解释仍然难以与非选择性呈现的解释区分，因为有效反事实的多样性和解释规范的灵活性提供了足够的自由度来掩盖故意选择。实证表明，这种变异性通常超过选择性呈现对标准反事实质量指标（如接近性、合理性和稀疏性）的影响，使得选择性呈现解释在统计上与基线解释无法区分。

Conclusion: 由于检测选择性呈现的局限性，保障措施应优先考虑可重复性、标准化和过程约束，而不是事后检测。论文为算法开发者、解释提供者和审计者提供了具体建议，强调需要建立更严格的解释生成规范和审计流程来防止操纵。

Abstract: Counterfactual explanations are widely used to communicate how inputs must change for a model to alter its prediction. For a single instance, many valid counterfactuals can exist, which leaves open the possibility for an explanation provider to cherry-pick explanations that better suit a narrative of their choice, highlighting favourable behaviour and withholding examples that reveal problematic behaviour. We formally define cherry-picking for counterfactual explanations in terms of an admissible explanation space, specified by the generation procedure, and a utility function. We then study to what extent an external auditor can detect such manipulation. Considering three levels of access to the explanation process: full procedural access, partial procedural access, and explanation-only access, we show that detection is extremely limited in practice. Even with full procedural access, cherry-picked explanations can remain difficult to distinguish from non cherry-picked explanations, because the multiplicity of valid counterfactuals and flexibility in the explanation specification provide sufficient degrees of freedom to mask deliberate selection. Empirically, we demonstrate that this variability often exceeds the effect of cherry-picking on standard counterfactual quality metrics such as proximity, plausibility, and sparsity, making cherry-picked explanations statistically indistinguishable from baseline explanations. We argue that safeguards should therefore prioritise reproducibility, standardisation, and procedural constraints over post-hoc detection, and we provide recommendations for algorithm developers, explanation providers, and auditors.

</details>


### [65] [On the Hidden Objective Biases of Group-based Reinforcement Learning](https://arxiv.org/abs/2601.05002)
*Aleksandar Fontana,Marco Simoni,Giulio Rossolini,Andrea Saracino,Paolo Mori*

Main category: cs.LG

TL;DR: 本文对GRPO等基于群体的强化学习方法进行理论分析，揭示了其奖励优化与训练目标之间的结构不匹配问题，发现了梯度偏差、优化器交互和动量效应等系统性缺陷。


<details>
  <summary>Details</summary>
Motivation: 尽管基于群体的强化学习方法（如GRPO）在大型语言模型的后训练中被广泛使用并取得了经验成功，但这些方法存在奖励优化与底层训练目标之间的结构不匹配问题。本文旨在通过理论分析揭示这些方法的根本局限性。

Method: 通过统一的代理公式（surrogate formulation）对GRPO风格方法进行理论分析，从这一视角研究这些方法的共同特性，重点关注梯度偏差、优化器交互和动量效应等系统性问题。

Result: 分析揭示了三个关键特性：（1）非均匀群体加权会在共享前缀标记上引入系统性梯度偏差；（2）与AdamW优化器的交互使训练动态对奖励缩放基本不敏感；（3）优化器动量在重复优化步骤中可能将策略更新推至预期的裁剪区域之外。

Conclusion: 这些发现突显了当前方法的基本局限性，为未来公式设计提供了原则性指导，表明需要重新思考基于群体的强化学习方法的理论基础。

Abstract: Group-based reinforcement learning methods, like Group Relative Policy Optimization (GRPO), are widely used nowadays to post-train large language models. Despite their empirical success, they exhibit structural mismatches between reward optimization and the underlying training objective. In this paper, we present a theoretical analysis of GRPO style methods by studying them within a unified surrogate formulation. This perspective reveals recurring properties that affect all the methods under analysis: (i) non-uniform group weighting induces systematic gradient biases on shared prefix tokens; (ii) interactions with the AdamW optimizer make training dynamics largely insensitive to reward scaling; and (iii) optimizer momentum can push policy updates beyond the intended clipping region under repeated optimization steps. We believe that these findings highlight fundamental limitations of current approaches and provide principled guidance for the design of future formulations.

</details>


### [66] [HMVI: Unifying Heterogeneous Attributes with Natural Neighbors for Missing Value Inference](https://arxiv.org/abs/2601.05017)
*Xiaopeng Luo,Zexi Tan,Zhuowei Wang*

Main category: cs.LG

TL;DR: 提出了一种新颖的缺失值填补方法，通过统一框架显式建模异构特征间的跨类型依赖关系，优于现有技术并显著提升下游机器学习任务性能。


<details>
  <summary>Details</summary>
Motivation: 当前缺失值填补方法通常独立处理数值和分类属性，忽略了异构特征间的关键相互依赖关系，这限制了填补的准确性和一致性。

Method: 提出了一种新颖的填补方法，在统一框架中显式建模跨类型特征依赖关系，同时利用完整和不完整实例来确保表格数据中准确一致的填补。

Result: 大量实验结果表明，该方法在性能上优于现有技术，并显著增强了下游机器学习任务，为现实系统中缺失数据提供了稳健解决方案。

Conclusion: 该方法通过建模异构特征间的跨类型依赖关系，为缺失值填补提供了更有效的解决方案，能够提升现实世界系统的数据完整性和机器学习性能。

Abstract: Missing value imputation is a fundamental challenge in machine intelligence, heavily dependent on data completeness. Current imputation methods often handle numerical and categorical attributes independently, overlooking critical interdependencies among heterogeneous features. To address these limitations, we propose a novel imputation approach that explicitly models cross-type feature dependencies within a unified framework. Our method leverages both complete and incomplete instances to ensure accurate and consistent imputation in tabular data. Extensive experimental results demonstrate that the proposed approach achieves superior performance over existing techniques and significantly enhances downstream machine learning tasks, providing a robust solution for real-world systems with missing data.

</details>


### [67] [Approximate equivariance via projection-based regularisation](https://arxiv.org/abs/2601.05028)
*Torben Berndt,Jan Stühmer*

Main category: cs.LG

TL;DR: 本文提出了一种基于投影的正则化方法来实现近似等变性，通过线性层的正交分解来惩罚非等变成分，相比现有方法在性能和效率上都有显著提升。


<details>
  <summary>Details</summary>
Motivation: 等变性是神经网络中强大的归纳偏置，但非等变模型在运行时性能和现实世界的不完美对称性方面表现更好。现有近似等变方法通常依赖数据增强，样本复杂度高，特别是对于连续群如SO(3)。

Method: 提出基于投影的正则化方法，利用线性层到等变和非等变成分的正交分解。在算子级别惩罚非等变性，而不是逐点惩罚。提供了在空间域和谱域精确高效计算非等变惩罚的数学框架。

Result: 实验表明，该方法在模型性能和效率上一致优于先前的近似等变方法，相比基于样本的正则化方法实现了显著的运行时增益。

Conclusion: 基于投影的正则化方法为近似等变性提供了一种高效且有效的解决方案，通过算子级别的惩罚机制克服了现有方法的样本复杂度问题。

Abstract: Equivariance is a powerful inductive bias in neural networks, improving generalisation and physical consistency. Recently, however, non-equivariant models have regained attention, due to their better runtime performance and imperfect symmetries that might arise in real-world applications. This has motivated the development of approximately equivariant models that strike a middle ground between respecting symmetries and fitting the data distribution. Existing approaches in this field usually apply sample-based regularisers which depend on data augmentation at training time, incurring a high sample complexity, in particular for continuous groups such as $SO(3)$. This work instead approaches approximate equivariance via a projection-based regulariser which leverages the orthogonal decomposition of linear layers into equivariant and non-equivariant components. In contrast to existing methods, this penalises non-equivariance at an operator level across the full group orbit, rather than point-wise. We present a mathematical framework for computing the non-equivariance penalty exactly and efficiently in both the spatial and spectral domain. In our experiments, our method consistently outperforms prior approximate equivariance approaches in both model performance and efficiency, achieving substantial runtime gains over sample-based regularisers.

</details>


### [68] [A Data-Driven Predictive Framework for Inventory Optimization Using Context-Augmented Machine Learning Models](https://arxiv.org/abs/2601.05033)
*Anees Fatima,Mohammad Abdus Salam*

Main category: cs.LG

TL;DR: 该研究使用四种机器学习算法（XGBoost、ARIMA、Facebook Prophet、SVR）预测零售和自动售货机需求，发现加入外部因素（工作日、节假日、销售偏差指标）能显著提升预测精度，其中XGBoost表现最佳。


<details>
  <summary>Details</summary>
Motivation: 供应链管理中的需求预测对优化库存、减少浪费和提高客户满意度至关重要。传统方法经常忽略天气、节日和设备故障等外部因素，导致效率低下。

Method: 研究采用四种机器学习算法：XGBoost、ARIMA、Facebook Prophet和SVR来预测库存需求。系统性地整合了工作日、节假日和销售偏差指标等外部因素以提高预测精度。

Result: XGBoost表现最佳，在加入外部变量后达到最低平均绝对误差（MAE）22.7。ARIMAX和Facebook Prophet也显示出显著改进，而SVR表现较差。外部因素的加入显著提高了需求预测模型的精度。

Conclusion: 外部因素能显著提升需求预测模型的准确性，XGBoost是最有效的算法。该研究为改进零售和自动售货机系统的库存管理提供了强有力的框架。

Abstract: Demand forecasting in supply chain management (SCM) is critical for optimizing inventory, reducing waste, and improving customer satisfaction. Conventional approaches frequently neglect external influences like weather, festivities, and equipment breakdowns, resulting in inefficiencies. This research investigates the use of machine learning (ML) algorithms to improve demand prediction in retail and vending machine sectors. Four machine learning algorithms. Extreme Gradient Boosting (XGBoost), Autoregressive Integrated Moving Average (ARIMA), Facebook Prophet (Fb Prophet), and Support Vector Regression (SVR) were used to forecast inventory requirements. Ex-ternal factors like weekdays, holidays, and sales deviation indicators were methodically incorporated to enhance precision. XGBoost surpassed other models, reaching the lowest Mean Absolute Error (MAE) of 22.7 with the inclusion of external variables. ARIMAX and Fb Prophet demonstrated noteworthy enhancements, whereas SVR fell short in performance. Incorporating external factors greatly improves the precision of demand forecasting models, and XGBoost is identified as the most efficient algorithm. This study offers a strong framework for enhancing inventory management in retail and vending machine systems.

</details>


### [69] [DeepWeightFlow: Re-Basined Flow Matching for Generating Neural Network Weights](https://arxiv.org/abs/2601.05052)
*Saumya Gupta,Scott Biggs,Moritz Laber,Zohair Shafi,Robin Walters,Ayan Paul*

Main category: cs.LG

TL;DR: DeepWeightFlow是一种基于Flow Matching的生成模型，可直接在权重空间中生成多样且高精度的神经网络权重，无需微调即可达到良好性能，并能扩展到大型网络。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络权重生成模型面临高维权重空间和对称性挑战，要么只能生成部分权重（特别是对于ResNet、ViT等大型模型），要么生成完整权重但速度慢或需要微调。

Method: 使用Flow Matching模型直接在权重空间操作，结合Git Re-Basin和TransFusion进行神经网络规范化，以处理置换对称性问题并提高大型模型的生成效率。

Result: 生成的神经网络无需微调即可表现良好，可扩展到大型网络，在迁移学习中表现出色，能在几分钟内生成数百个神经网络的集成，远超基于扩散的方法的效率。

Conclusion: DeepWeightFlow为高效、可扩展地生成多样化神经网络集合开辟了新途径。

Abstract: Building efficient and effective generative models for neural network weights has been a research focus of significant interest that faces challenges posed by the high-dimensional weight spaces of modern neural networks and their symmetries. Several prior generative models are limited to generating partial neural network weights, particularly for larger models, such as ResNet and ViT. Those that do generate complete weights struggle with generation speed or require finetuning of the generated models. In this work, we present DeepWeightFlow, a Flow Matching model that operates directly in weight space to generate diverse and high-accuracy neural network weights for a variety of architectures, neural network sizes, and data modalities. The neural networks generated by DeepWeightFlow do not require fine-tuning to perform well and can scale to large networks. We apply Git Re-Basin and TransFusion for neural network canonicalization in the context of generative weight models to account for the impact of neural network permutation symmetries and to improve generation efficiency for larger model sizes. The generated networks excel at transfer learning, and ensembles of hundreds of neural networks can be generated in minutes, far exceeding the efficiency of diffusion-based methods. DeepWeightFlow models pave the way for more efficient and scalable generation of diverse sets of neural networks.

</details>


### [70] [Milestones over Outcome: Unlocking Geometric Reasoning with Sub-Goal Verifiable Reward](https://arxiv.org/abs/2601.05073)
*Jianlong Chen,Daocheng Fu,Shengze Xu,Jiawei Chen,Yuan Feng,Yue Yang,Junchi Yan,Hongyuan Zha,Renqiu Xia*

Main category: cs.LG

TL;DR: 提出GeoGoal基准和SGVR框架，通过子目标验证奖励解决MLLMs几何推理问题，提升推理质量而非仅结果准确性


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在复杂几何推理上表现不佳，因为传统的"黑箱"结果监督无法区分幸运猜测和严谨推理，需要更细粒度的评估和学习方法

Method: 1) 构建GeoGoal基准，通过形式化验证数据引擎将抽象证明转换为可验证的数值子目标；2) 提出子目标可验证奖励框架，用基于骨架率的密集奖励替代稀疏信号

Result: SGVR框架显著提升几何推理性能(+9.7%)，并展现出强泛化能力：在一般数学任务上提升+8.0%，在其他一般推理任务上提升+2.8%

Conclusion: 子目标级评估和学习是解决MLLMs几何推理问题的有效范式，SGVR框架不仅提升几何推理能力，还具有跨领域的广泛适用性

Abstract: Multimodal Large Language Models (MLLMs) struggle with complex geometric reasoning, largely because "black box" outcome-based supervision fails to distinguish between lucky guesses and rigorous deduction. To address this, we introduce a paradigm shift towards subgoal-level evaluation and learning. We first construct GeoGoal, a benchmark synthesized via a rigorous formal verification data engine, which converts abstract proofs into verifiable numeric subgoals. This structure reveals a critical divergence between reasoning quality and outcome accuracy. Leveraging this, we propose the Sub-Goal Verifiable Reward (SGVR) framework, which replaces sparse signals with dense rewards based on the Skeleton Rate. Experiments demonstrate that SGVR not only enhances geometric performance (+9.7%) but also exhibits strong generalization, transferring gains to general math (+8.0%) and other general reasoning tasks (+2.8%), demonstrating broad applicability across diverse domains.

</details>


### [71] [Exploring Student Expectations and Confidence in Learning Analytics](https://arxiv.org/abs/2601.05082)
*Hayk Asatryan,Basile Tousside,Janis Mohr,Malte Neugebauer,Hildo Bijl,Paul Spiegelberg,Claudia Frohn-Schauf,Jörg Frochte*

Main category: cs.LG

TL;DR: 使用SELAQ问卷分析学生对学习分析的数据处理期望和信心，识别出四类学生群体：热情者、现实者、谨慎者和漠不关心者


<details>
  <summary>Details</summary>
Motivation: 学习分析在教育系统中广泛应用，但数据收集需符合日益严格的隐私法规要求。需要了解学生对学习分析数据处理的态度和期望，以平衡教育优化与隐私保护的需求。

Method: 使用学生学习分析期望问卷（SELAQ）收集不同院系学生对学习分析数据处理的期望和信心数据，然后通过聚类算法对数据进行分析。

Result: 通过聚类分析识别出四类学生群体：1) 热情者（Enthusiasts）- 对学习分析持积极态度；2) 现实者（Realists）- 理性看待学习分析；3) 谨慎者（Cautious）- 对隐私保护有顾虑；4) 漠不关心者（Indifferents）- 对学习分析不感兴趣。

Conclusion: 这种结构化分析为理解学生对学习分析的接受度和批评提供了有价值的见解，有助于在教育优化和隐私保护之间找到平衡点。

Abstract: Learning Analytics (LA) is nowadays ubiquitous in many educational systems, providing the ability to collect and analyze student data in order to understand and optimize learning and the environments in which it occurs. On the other hand, the collection of data requires to comply with the growing demand regarding privacy legislation. In this paper, we use the Student Expectation of Learning Analytics Questionnaire (SELAQ) to analyze the expectations and confidence of students from different faculties regarding the processing of their data for Learning Analytics purposes. This allows us to identify four clusters of students through clustering algorithms: Enthusiasts, Realists, Cautious and Indifferents. This structured analysis provides valuable insights into the acceptance and criticism of Learning Analytics among students.

</details>


### [72] [Sequential Subspace Noise Injection Prevents Accuracy Collapse in Certified Unlearning](https://arxiv.org/abs/2601.05134)
*Polina Dolgova,Sebastian U. Stich*

Main category: cs.LG

TL;DR: 提出序列噪声调度方法，将噪声预算分配到参数空间的正交子空间，在保持差分隐私认证保证的同时显著提升遗忘后模型精度。


<details>
  <summary>Details</summary>
Motivation: 基于差分隐私的认证遗忘方法虽然提供强保证，但现有噪声微调方法严重降低模型精度，导致实际应用困难。

Method: 提出序列噪声调度方法，将噪声预算分配到参数空间的正交子空间，而不是一次性注入所有噪声。扩展了噪声微调分析到子空间设置，证明保持相同的(ε,δ)隐私预算。

Result: 在图像分类基准测试中，该方法显著提高了遗忘后的模型精度，同时保持对成员推理攻击的鲁棒性。

Conclusion: 认证遗忘方法可以同时实现严格的隐私保证和实际应用价值，序列噪声调度是解决现有方法精度损失问题的有效方案。

Abstract: Certified unlearning based on differential privacy offers strong guarantees but remains largely impractical: the noisy fine-tuning approaches proposed so far achieve these guarantees but severely reduce model accuracy. We propose sequential noise scheduling, which distributes the noise budget across orthogonal subspaces of the parameter space, rather than injecting it all at once. This simple modification mitigates the destructive effect of noise while preserving the original certification guarantees. We extend the analysis of noisy fine-tuning to the subspace setting, proving that the same $(\varepsilon,δ)$ privacy budget is retained. Empirical results on image classification benchmarks show that our approach substantially improves accuracy after unlearning while remaining robust to membership inference attacks. These results show that certified unlearning can achieve both rigorous guarantees and practical utility.

</details>


### [73] [Safe Continual Reinforcement Learning Methods for Nonstationary Environments. Towards a Survey of the State of the Art](https://arxiv.org/abs/2601.05152)
*Timofey Tomashevskiy*

Main category: cs.LG

TL;DR: 本文对持续安全在线强化学习（COSRL）方法进行了最新综述，讨论了理论方面、挑战和开放性问题，提供了基于安全学习机制的分类，并探讨了构建可靠安全在线学习算法的前景。


<details>
  <summary>Details</summary>
Motivation: 随着强化学习在现实世界应用中的扩展，需要在非平稳环境中实现持续在线学习的同时确保安全性。当前缺乏对持续安全在线强化学习方法的系统性综述，需要梳理理论框架、挑战和未来方向。

Method: 通过文献综述方法，对持续安全在线强化学习方法进行分类分析。基于安全学习机制的类型进行分类，考虑对非平稳性的适应。同时分类在线强化学习算法的安全约束表述。

Result: 建立了持续安全在线强化学习的分类体系，涵盖了HM-MDP、NSMDP、POMDP、安全POMDP等多种模型框架。识别了安全约束表述的不同方法，并指出了当前研究的关键挑战和开放性问题。

Conclusion: 持续安全在线强化学习是一个重要且具有挑战性的研究领域，需要进一步发展可靠的安全在线学习算法。未来的研究应关注非平稳环境下的安全约束制定、适应机制设计以及理论保证的建立。

Abstract: This work provides a state-of-the-art survey of continual safe online reinforcement learning (COSRL) methods. We discuss theoretical aspects, challenges, and open questions in building continual online safe reinforcement learning algorithms. We provide the taxonomy and the details of continual online safe reinforcement learning methods based on the type of safe learning mechanism that takes adaptation to nonstationarity into account. We categorize safety constraints formulation for online reinforcement learning algorithms, and finally, we discuss prospects for creating reliable, safe online learning algorithms.
  Keywords: safe RL in nonstationary environments, safe continual reinforcement learning under nonstationarity, HM-MDP, NSMDP, POMDP, safe POMDP, constraints for continual learning, safe continual reinforcement learning review, safe continual reinforcement learning survey, safe continual reinforcement learning, safe online learning under distribution shift, safe continual online adaptation, safe reinforcement learning, safe exploration, safe adaptation, constrained Markov decision processes, safe reinforcement learning, partially observable Markov decision process, safe reinforcement learning and hidden Markov decision processes, Safe Online Reinforcement Learning, safe online reinforcement learning, safe online reinforcement learning, safe meta-learning, safe meta-reinforcement learning, safe context-based reinforcement learning, formulating safety constraints for continual learning

</details>


### [74] [FaST: Efficient and Effective Long-Horizon Forecasting for Large-Scale Spatial-Temporal Graphs via Mixture-of-Experts](https://arxiv.org/abs/2601.05174)
*Yiji Zhao,Zihao Zhong,Ao Wang,Haomin Wen,Ming Jin,Yuxuan Liang,Huaiyu Wan,Hao Wu*

Main category: cs.LG

TL;DR: FaST是一个基于异构感知专家混合的时空图预测框架，能够高效处理大规模图上的长时预测，实现一周前（672步）的预测，显著降低计算和内存消耗。


<details>
  <summary>Details</summary>
Motivation: 现有时空图预测模型主要关注短期预测，在扩展到长时预测和大规模图时面临计算成本高、内存消耗大的问题。

Method: 提出自适应图代理注意力机制减轻大规模图上的计算负担，并使用基于门控线性单元的并行专家混合模块替代传统前馈网络。

Result: 在真实数据集上的实验表明，FaST在长时预测精度和计算效率方面均优于现有最先进方法。

Conclusion: FaST框架有效解决了大规模时空图长时预测的计算效率问题，为实际应用提供了可行的解决方案。

Abstract: Spatial-Temporal Graph (STG) forecasting on large-scale networks has garnered significant attention. However, existing models predominantly focus on short-horizon predictions and suffer from notorious computational costs and memory consumption when scaling to long-horizon predictions and large graphs. Targeting the above challenges, we present FaST, an effective and efficient framework based on heterogeneity-aware Mixture-of-Experts (MoEs) for long-horizon and large-scale STG forecasting, which unlocks one-week-ahead (672 steps at a 15-minute granularity) prediction with thousands of nodes. FaST is underpinned by two key innovations. First, an adaptive graph agent attention mechanism is proposed to alleviate the computational burden inherent in conventional graph convolution and self-attention modules when applied to large-scale graphs. Second, we propose a new parallel MoE module that replaces traditional feed-forward networks with Gated Linear Units (GLUs), enabling an efficient and scalable parallel structure. Extensive experiments on real-world datasets demonstrate that FaST not only delivers superior long-horizon predictive accuracy but also achieves remarkable computational efficiency compared to state-of-the-art baselines. Our source code is available at: https://github.com/yijizhao/FaST.

</details>


### [75] [An interpretable data-driven approach to optimizing clinical fall risk assessment](https://arxiv.org/abs/2601.05194)
*Fardin Ganjkhanloo,Emmett Springer,Erik H. Hoyer,Daniel L. Young,Holley Farley,Kimia Ghobadi*

Main category: cs.LG

TL;DR: 通过约束评分优化模型重新调整约翰霍普金斯跌倒风险评估工具的权重，显著提升预测性能，每周可多保护35名高风险患者


<details>
  <summary>Details</summary>
Motivation: 现有约翰霍普金斯跌倒风险评估工具(JHFRAT)的预测能力有限，需要更好地与临床有意义的指标对齐，以改善住院患者跌倒预防和患者安全

Method: 采用约束评分优化(CSO)模型重新调整JHFRAT的评分权重，保持其可加性结构和临床阈值，同时纳入临床知识并保持可解释性；基于54,209例住院患者数据进行回顾性队列分析

Result: CSO模型显著提升预测性能(AUC-ROC=0.91 vs JHFRAT的0.86)，每周可多保护35名高风险患者；虽然XGBoost性能更好(AUC-ROC=0.94)，但CSO在风险标签变化时表现更稳健

Conclusion: 基于证据的数据驱动优化方法为医疗系统提供了增强住院患者跌倒预防协议的坚实基础，有助于改善风险评估和医疗资源分配

Abstract: In this study, we aim to better align fall risk prediction from the Johns Hopkins Fall Risk Assessment Tool (JHFRAT) with additional clinically meaningful measures via a data-driven modelling approach. We conducted a retrospective cohort analysis of 54,209 inpatient admissions from three Johns Hopkins Health System hospitals between March 2022 and October 2023. A total of 20,208 admissions were included as high fall risk encounters, and 13,941 were included as low fall risk encounters. To incorporate clinical knowledge and maintain interpretability, we employed constrained score optimization (CSO) models to reweight the JHFRAT scoring weights, while preserving its additive structure and clinical thresholds. Recalibration refers to adjusting item weights so that the resulting score can order encounters more consistently by the study's risk labels, and without changing the tool's form factor or deployment workflow. The model demonstrated significant improvements in predictive performance over the current JHFRAT (CSO AUC-ROC=0.91, JHFRAT AUC-ROC=0.86). This performance improvement translates to protecting an additional 35 high-risk patients per week across the Johns Hopkins Health System. The constrained score optimization models performed similarly with and without the EHR variables. Although the benchmark black-box model (XGBoost), improves upon the performance metrics of the knowledge-based constrained logistic regression (AUC-ROC=0.94), the CSO demonstrates more robustness to variations in risk labeling. This evidence-based approach provides a robust foundation for health systems to systematically enhance inpatient fall prevention protocols and patient safety using data-driven optimization techniques, contributing to improved risk assessment and resource allocation in healthcare settings.

</details>


### [76] [EARL: Energy-Aware Optimization of Liquid State Machines for Pervasive AI](https://arxiv.org/abs/2601.05205)
*Zain Iqbal,Lorenzo Valerio*

Main category: cs.LG

TL;DR: EARL是一个能量感知的强化学习框架，通过贝叶斯优化和自适应强化学习策略联合优化液体状态机的准确性和能耗，显著提高了资源受限设备上AI应用的效率。


<details>
  <summary>Details</summary>
Motivation: 随着普及AI对设备端学习系统的需求增长，需要低延迟、高能效的计算方案。液体状态机（LSM）虽然为低功耗时序处理提供了有前景的方法，但其部署面临超参数敏感度高和传统优化方法忽略能量约束的问题。

Method: EARL框架整合了贝叶斯优化和自适应强化学习选择策略，采用代理模型进行全局探索，强化学习进行动态候选优先级排序，并引入早期终止机制来消除冗余评估，从而降低计算开销。

Result: 在三个基准数据集上的实验表明，EARL相比领先的超参数调优框架，实现了6-15%的准确率提升，60-80%的能耗降低，以及高达一个数量级的优化时间减少。

Conclusion: 能量感知的自适应搜索能有效提高液体状态机在资源受限设备端AI应用中的效率和可扩展性，为普及AI系统提供了实用的优化解决方案。

Abstract: Pervasive AI increasingly depends on on-device learning systems that deliver low-latency and energy-efficient computation under strict resource constraints. Liquid State Machines (LSMs) offer a promising approach for low-power temporal processing in pervasive and neuromorphic systems, but their deployment remains challenging due to high hyperparameter sensitivity and the computational cost of traditional optimization methods that ignore energy constraints. This work presents EARL, an energy-aware reinforcement learning framework that integrates Bayesian optimization with an adaptive reinforcement learning based selection policy to jointly optimize accuracy and energy consumption. EARL employs surrogate modeling for global exploration, reinforcement learning for dynamic candidate prioritization, and an early termination mechanism to eliminate redundant evaluations, substantially reducing computational overhead. Experiments on three benchmark datasets demonstrate that EARL achieves 6 to 15 percent higher accuracy, 60 to 80 percent lower energy consumption, and up to an order of magnitude reduction in optimization time compared to leading hyperparameter tuning frameworks. These results highlight the effectiveness of energy-aware adaptive search in improving the efficiency and scalability of LSMs for resource-constrained on-device AI applications.

</details>


### [77] [Robust Reasoning as a Symmetry-Protected Topological Phase](https://arxiv.org/abs/2601.05240)
*Ilmo Sung*

Main category: cs.LG

TL;DR: 论文提出将大型语言模型的幻觉问题视为"度量相"中的自发对称性破缺，并提出通过非阿贝尔规范对称性实现鲁棒推理的拓扑保护相，在符号推理任务中展示指数级外推能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在"幻觉"问题，即由语义噪声引起的逻辑不一致性。当前架构在"度量相"中运行，因果顺序容易受到自发对称性破缺的影响，导致推理脆弱性。

Method: 提出将鲁棒推理建模为对称性保护的拓扑相，其中逻辑操作形式上同构于非阿贝尔任意子编织，用鲁棒的拓扑不变量替代脆弱的几何插值。实现Holonomic Network，利用非阿贝尔规范对称性保护逻辑推理。

Result: 实验显示尖锐的拓扑相变：Transformer和RNN表现出无间隙衰减，而Holonomic Network展现出宏观"质量间隙"，在临界噪声阈值下保持不变保真度。在S10（360万状态）的变量绑定任务中，拓扑模型在训练范围外推100倍（L=50→5000）时保持完美保真度，而Transformer失去逻辑一致性。消融研究表明这种保护严格来自非阿贝尔规范对称性。

Conclusion: 这为逻辑推理提供了一个新的普适性类别，将因果稳定性与语义流形的拓扑结构联系起来。非阿贝尔规范对称性能够实现理论上无限的因果视界，为构建鲁棒推理系统提供了新范式。

Abstract: Large language models suffer from "hallucinations"-logical inconsistencies induced by semantic noise. We propose that current architectures operate in a "Metric Phase," where causal order is vulnerable to spontaneous symmetry breaking. Here, we identify robust inference as an effective Symmetry-Protected Topological phase, where logical operations are formally isomorphic to non-Abelian anyon braiding, replacing fragile geometric interpolation with robust topological invariants. Empirically, we demonstrate a sharp topological phase transition: while Transformers and RNNs exhibit gapless decay, our Holonomic Network reveals a macroscopic "mass gap," maintaining invariant fidelity below a critical noise threshold. Furthermore, in a variable-binding task on $S_{10}$ ($3.6 \times 10^6$ states) representing symbolic manipulation, we demonstrate holonomic generalization: the topological model maintains perfect fidelity extrapolating $100\times$ beyond training ($L=50 \to 5000$), consistent with a theoretically indefinite causal horizon, whereas Transformers lose logical coherence. Ablation studies indicate this protection emerges strictly from non-Abelian gauge symmetry. This provides strong evidence for a new universality class for logical reasoning, linking causal stability to the topology of the semantic manifold.

</details>


### [78] [Optimal Lower Bounds for Online Multicalibration](https://arxiv.org/abs/2601.05245)
*Natalie Collina,Jiuyao Lu,Georgy Noarov,Aaron Roth*

Main category: cs.LG

TL;DR: 该论文证明了在线多校准的紧下界，建立了与边际校准的信息论分离。在一般设置下，使用三个不相交二元组证明了Ω(T^{2/3})下界；在组函数仅依赖上下文的更困难情况下，通过正交函数系统构造Θ(T)大小的组族证明了Ω̃(T^{2/3})下界。


<details>
  <summary>Details</summary>
Motivation: 研究在线多校准与边际校准之间的计算复杂性差异，探索多校准问题在信息论意义上的固有难度，特别是在不同组函数依赖关系下的下界。

Method: 采用信息论方法证明下界：1）对于组函数依赖上下文和预测的一般情况，构造三个不相交二元组证明Ω(T^{2/3})下界；2）对于组函数仅依赖上下文的情况，使用正交函数系统构造Θ(T)大小的组族证明Ω̃(T^{2/3})下界。

Result: 1）一般设置下：Ω(T^{2/3})下界匹配Noarov等人(2025)的上界（对数因子内），且超过边际校准的O(T^{2/3-ε})上界，从而分离了两个问题；2）组函数仅依赖上下文的情况：Ω̃(T^{2/3})下界匹配现有上界（对数因子内）。

Conclusion: 在线多校准比边际校准在信息论意义上更难，具有Ω(T^{2/3})的固有下界，这一下界在不同组函数依赖设置下都是紧的，揭示了多校准问题的本质复杂性。

Abstract: We prove tight lower bounds for online multicalibration, establishing an information-theoretic separation from marginal calibration.
  In the general setting where group functions can depend on both context and the learner's predictions, we prove an $Ω(T^{2/3})$ lower bound on expected multicalibration error using just three disjoint binary groups. This matches the upper bounds of Noarov et al. (2025) up to logarithmic factors and exceeds the $O(T^{2/3-\varepsilon})$ upper bound for marginal calibration (Dagan et al., 2025), thereby separating the two problems.
  We then turn to lower bounds for the more difficult case of group functions that may depend on context but not on the learner's predictions. In this case, we establish an $\widetildeΩ(T^{2/3})$ lower bound for online multicalibration via a $Θ(T)$-sized group family constructed using orthogonal function systems, again matching upper bounds up to logarithmic factors.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [79] [A Relativistic MOND](https://arxiv.org/abs/2601.04290)
*Tejinder P. Singh*

Main category: gr-qc

TL;DR: 提出了一种最小相对论性MOND完成方案，在强加速度区域精确恢复广义相对论，在弱加速度区域出现Bekenstein-Milgrom方程，无需引入额外传播场。


<details>
  <summary>Details</summary>
Motivation: 为修正牛顿动力学(MOND)提供相对论性框架，同时保持广义相对论在强加速度区域的精确性，避免引入额外传播场，通过对称性原理固定深MOND极限。

Method: 基于E_6×E_6框架，通过SU(3)_R→SU(2)_R×U(1)_{Y'}→U(1)_{dem}对称性破缺，利用Plebanski/MacDowell-Mansouri机制从SU(2)_R联络产生引力，通过红外度量变形ΔS_IR[g]实现MOND。

Result: 成功构建了最小相对论性MOND理论，在强加速度区域精确恢复广义相对论，在弱加速度区域得到Bekenstein-Milgrom方程，MOND加速度标度由动态选择的de Sitter半径设定。

Conclusion: 该框架为MOND提供了相对论性完成，统一了广义相对论和修正牛顿动力学，MOND效应出现在扰动和准静态系统中，均匀FRW背景由红外真空运动学而非人为宇宙学常数控制。

Abstract: We present a minimal relativistic completion of MOND in which (i) General Relativity is recovered exactly in the high-acceleration regime, while (ii) the Bekenstein--Milgrom (AQUAL) equation emerges in the low-acceleration regime, without introducing additional propagating fields beyond those already present in a right-handed gauge sector. The construction is motivated by an $E_6\times E_6$ framework in which $SU(3)_R\rightarrow SU(2)_R\times U(1)_{Y'}\rightarrow U(1)_{\rm dem}$, leaving a healthy repulsive $U(1)_{\rm dem}$ interaction whose charge is the square-root mass label. Gravity itself arises from the $SU(2)_R$ connection via a Plebanski/MacDowell--Mansouri mechanism, yielding an emergent tetrad and the Einstein--Hilbert action. MOND is implemented by an infrared (IR) metric deformation $ΔS_{\rm IR}[g]$ that is UV-vanishing (so GR is recovered) while its deep-MOND/static limit is fixed by a symmetry principle: in three spatial dimensions, the deep-MOND action is conformally invariant with a 10-parameter group isomorphic to $SO(4,1)$ (the de Sitter group). The single MOND acceleration scale is set by a de Sitter radius selected dynamically in the IR, $a_0=c^2/(ξ\,\ell_{\rm dS})$ with $ξ={ O}(1)$ fixed by matching to the static limit. MOND resides in perturbations and quasistatic systems; the homogeneous FRW background is controlled by the IR vacuum kinematics rather than an ad hoc cosmological constant.

</details>


### [80] [Could black hole thermodynamics play a role in black hole mergers?](https://arxiv.org/abs/2601.04379)
*George Ruppeiner*

Main category: gr-qc

TL;DR: 论文探讨引力波观测到的黑洞自旋值聚集现象是否与黑洞热力学的Davies相变点有关，并构建了满足热力学涨落理论和热平衡要求的理论框架。


<details>
  <summary>Details</summary>
Motivation: 观测数据显示169个双黑洞合并产生的黑洞自旋值显著聚集在平均值0.6869附近，这与黑洞热力学中的Davies相变点0.68125非常接近。作者想探究这种聚集现象是否与热力学相变有直接联系。

Method: 1. 从Kerr黑洞模型的黑洞热力学出发，确定正确的涨落变量选择；2. 要求事件视界（霍金温度约μK）与外部宇宙（约3K）之间达到热平衡，这需要Novikov-Thorne吸积盘模型；3. 构建满足这两个要求的完整热力学涨落理论。

Result: 建立了能够解释黑洞自旋值聚集现象的热力学涨落理论框架，表明黑洞合并可能基于某种未知的动力学模型，其极限吸引子状态位于Davies点。

Conclusion: 黑洞自旋值的观测聚集现象可能与Davies相变点存在联系，这为理解黑洞合并动力学提供了新的可能性，即存在某种动力学模型以Davies点作为吸引子状态。

Abstract: Gravitational waves from binary black hole mergers yield values for both the black hole remnant mass $M$ and it's spin $a$, with the $169$ $a$ values collected so far crowding significantly around their average $\bar{a}=0.6869\pm 0.087$. Could this crowding relate directly to the Davies phase transition point at $a=0.68125$ from black hole thermodynamics? I argue that a necessary challenge for such a connection requires a consistent application of the thermodynamic fluctuation theory that follows from black hole thermodynamics (BHT). Specifically, necessary are a correct choice of fluctuating variables, as well as thermal equilibrium between the event horizon at the Hawking temperature $\sim μK$ and the outside universe $\sim 3 K$. I show that the former requirement follows in straightforward fashion from the BHT of the Kerr model, while the later requires an accretion disk following the Novikov-Thorne accretion disk model. I construct a thermodynamic fluctuation theory meeting both these requirements. My results open the possibility that black hole mergers are based on some dynamical model (not known to me) with a limiting attractor state at the Davies point.

</details>


### [81] [Future Rip Scenarios in Fractional Holographic Dark Energy](https://arxiv.org/abs/2601.04414)
*Ayush Bidlan,Paulo Moniz,Oem Trivedi*

Main category: gr-qc

TL;DR: 该研究探讨了在相互作用的分数全息暗能量框架下，晚期宇宙奇点（特别是撕裂奇点）的出现条件，分析了不同红外截断方案对撕裂奇点类型的影响。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解在分数全息暗能量框架下，不同类型的晚期宇宙奇点（大撕裂、小撕裂、伪撕裂）如何出现，以及不同红外截断方案对这些奇点形成条件的影响。

Method: 采用两种红外截断方案：1) Granda-Oliveros截断，分析Lévy指数α的范围与不同撕裂奇点的关系；2) Hubble截断，通过构建基于假设的方法，研究小撕裂和伪撕裂奇点的出现条件，并数值计算状态方程和平方声速等宇宙学参数。

Result: 发现：1) 在GO截断下，大撕裂出现在1<α≤2范围内；2) 伪撕裂需要α>2，但在GO截断下被排除；3) 小撕裂在GO截断下需要特定的红外截断形式；4) 在Hubble截断和非线性相互作用项下，小撕裂和伪撕裂可以出现。

Conclusion: 分数全息暗能量框架中撕裂奇点的出现强烈依赖于红外截断方案的选择，不同截断方案允许不同类型的撕裂奇点，Hubble截断配合非线性相互作用项能够支持小撕裂和伪撕裂奇点的形成。

Abstract: In this paper, we investigate the occurrence of late-time cosmological singularities, namely, the rip scenarios within the framework of interacting Fractional Holographic Dark Energy (FHDE). We start our investigation with the Granda-Oliveros (GO) cutoff, i.e., $L=(γH^{2}+δ\dot{H})^{-\frac{1}{2}}$, and highlight the range of allowed $α$ (Lévy's index) values for which big, little and pseudo rip can occur. In particular, we highlight the occurrence of a big rip for fractional values of the Lévy's index in the allowed range $1<α\leq2$. Moreover, we conclude that the occurrence of a pseudo-rip requires Lévy's index to be $α>2$. Therefore, we reject the possibility of pseudo-rip within the GO cutoff. Furthermore, we demonstrate that the occurrence of the little rip in FHDE equipped with a GO cutoff is rather contrived and requires a specific functional form of the IR cutoff $L\sim(γH^{2}+g(H))^{-\frac{1}{2}}$, which belongs to a larger class of Nojiri-Odintsov (NO) cutoffs. To extend our perspective beyond the GO cutoff, we investigate the interacting FHDE framework equipped with the Hubble cutoff, i.e., $L=H^{-1}$, in developing an ansatz-based approach to the little and pseudo-rip singularities as they fail to appear in the GO cutoff. Within this approach, we invoke the expression of the Hubble parameter, $H(t)$, which corresponds to the little and pseudo-rip, into the cosmological parameters such as the Equation of State (EoS) and Squared Sound Speed (SSS) as a function of cosmic time $t$. We produce numerical plots of these parameters in both linear and non-linear $Q$ regimes, which supplement our theoretical findings. In summary, our results highlight the occurrence of little and pseudo-rip singularities within a Hubble cutoff for a non-linear $Q$ term within the FHDE framework.

</details>


### [82] [Quasi-Homogeneous Thermodynamics and Microscopic Structure of the Quantum-Corrected FLRW Universe](https://arxiv.org/abs/2601.04639)
*Carlos E. Romero-Figueroa,Hernando Quevedo*

Main category: gr-qc

TL;DR: 该论文提出了一种新的宇宙视界热力学描述方法，解决了相变存在与热力学定律之间的矛盾，并在量子引力修正下发现了与黑洞类似的相变行为。


<details>
  <summary>Details</summary>
Motivation: 宇宙时空中的相变分析表明，相变的存在需要随时间变化的表观视界半径，这又与暗能量流体的状态方程不同。这种条件与同时满足Hayward统一引力第一定律和表观视界基本热力学方程不兼容。为了解决这个问题，需要寻找新的热力学描述框架。

Method: 1. 引入替代性表述，将宇宙视界建模为准均匀热力学系统；2. 将此方法应用于受广义不确定性原理（GUP）量子引力修正的FLRW宇宙；3. 将变形参数提升为热力学变量，获得不依赖传统压力-体积解释的一致热力学描述；4. 使用几何热力学（GTD）分析相变行为；5. 对GTD标量曲率在相变点附近的行为进行数值分析。

Result: 1. 获得了不依赖压力-体积解释的一致热力学描述；2. 发现GUP参数的涨落可以诱导出与黑洞构型非常相似的相变；3. 数值分析显示GTD标量曲率在相变点附近表现出标度行为，临界指数接近1，且与平衡空间维度无关；4. 量子引力修正不仅改变了宇宙模型的热力学一致性，还加强了引力系统间的热力学普适性概念。

Conclusion: 该研究证实了几何热力学（GTD）作为揭示时空涌现热力学微观结构的强大几何工具。量子引力修正不仅修正了宇宙模型的热力学一致性，还强化了引力系统间的热力学普适性概念，表明宇宙视界和黑洞在热力学行为上具有深刻的相似性。

Abstract: The analysis of phase transitions in cosmological spacetimes shows that their existence requires a time-dependent apparent horizon radius, which in turn implies an equation of state different from that of a dark energy fluid. This condition is not compatible with the simultaneous fulfillment of Hayward's unified gravitational first law and the fundamental thermodynamic equation of the apparent horizon. To solve this problem, we introduce an alternative formulation in which the cosmological horizon is modeled as a quasi-homogeneous thermodynamic system. We apply this approach to the Friedmann-Lemaître-Robertson-Walker (FLRW) universe under quantum gravity corrections encoded by the Generalized Uncertainty Principle (GUP), promote the deformation parameter to a thermodynamic variable, and obtain a consistent thermodynamic description without relying on the usual pressure-volume interpretation. Using Geometrothermodynamics (GTD), we show that fluctuations of the GUP parameter can induce phase transitions closely resembling those of black hole configurations. Finally, we perform a numerical analysis of the behavior of the GTD scalar curvature near the phase transition point, where we find a scaling behavior characterized by the critical exponent close to 1, independently of the dimension of the equilibrium space. This reveals that quantum gravity corrections not only modify the thermodynamic consistency of cosmological models but also strengthen the notion of thermodynamic universality across gravitational systems. Our findings confirm GTD as a powerful geometric tool to unveil the emergent thermodynamic microstructure of spacetime.

</details>


### [83] [Inflationary Dynamics and Perturbations in Fractal Cosmology](https://arxiv.org/abs/2601.04691)
*Aarav Shah,Paulo Moniz,Maxim Khlopov,Oem Trivedi,Maxim Krasnov*

Main category: gr-qc

TL;DR: 研究分形宇宙学框架下的暴胀动力学，其中时空具有非整数有效维度，通过修正弗里德曼方程和连续性方程，推导广义慢滚参数，并建立分形扩展的Mukhanov-Sasaki方程，得到依赖分形维度D和分数尺度L的功率谱修正。


<details>
  <summary>Details</summary>
Motivation: 探索分形宇宙学框架下的暴胀动力学，其中时空具有非整数有效维度，这源于对宇宙学原理的松弛。研究分形几何如何影响暴胀动力学和标量扰动，为宇宙早期演化提供新的理论视角。

Method: 使用由有效分形维度D修正的弗里德曼方程和连续性方程，推导广义慢滚参数，并研究其在立方、Starobinsky和自然暴胀势下的演化。通过引入由空间拉普拉斯算子的分形分解产生的有效动量项k_eff，建立分形扩展的Mukhanov-Sasaki方程。

Result: 得到功率谱的修正和显式依赖于分形维度D和分数尺度L的标量谱指数n_s。与Planck 2018数据（n_s=0.9649±0.0042）比较，约束了D的允许范围（2.7≲D≲3），具体取决于所采用的宇宙学和暴胀模型。

Conclusion: 分形宇宙学为暴胀动力学提供了新的理论框架，通过引入有效分形维度D和分数尺度L，能够修正功率谱和标量谱指数，并与观测数据相符，约束了分形维度的物理范围。

Abstract: We study inflationary dynamics within the framework of fractal cosmology, where spacetime exhibits a non-integer effective dimension, sourced through a relaxation of the cosmological principle. Using Friedmann and continuity equations, modified by an effective fractal dimension $D$; we derive generalized slow-roll parameters and examine their evolution for cubic, Starobinsky and Natural inflationary potentials. We then formulate a fractal extension of the Mukhanov-Sasaki equation by introducing an effective momentum term $k_{\text{eff}}$, arising from the fractal decomposition of the spatial Laplacian, that captures the geometric influence of fractal cosmology on scalar perturbations. This leads to corrections in the power spectrum and a scalar spectral index $n_s$ that depends explicitly on both the fractal dimension $D$ and a fractional scale $L$, which controls the strength of the fractal deformation. Comparison with the Planck 2018 data ($n_s=0.9649\pm 0.0042$) constrains the allowed range of $D$ ($2.7\lesssim D\lesssim3$) depending on the cosmological and inflationary model assumed.

</details>


### [84] [Dynamical system approach to the spectral (in)stability of black holes under localised potential perturbations](https://arxiv.org/abs/2601.04892)
*T. Torres,S. R. Dolan*

Main category: gr-qc

TL;DR: 研究黑洞在扰动下的共振谱稳定性，发现弱扰动会导致非线性不稳定性，而强扰动则使共振迁移至吸引点


<details>
  <summary>Details</summary>
Motivation: 理解黑洞在附近天体（如致密天体或吸积盘）扰动下的共振谱行为，探究线性和非线性谱稳定性问题

Method: 研究局部delta函数扰动对球对称系统共振谱的影响，分析Nariai时空（Poschl-Teller势）和Schwarzschild时空两种情况

Result: 共振谱随扰动位置和强度平滑连续变化；强扰动时共振迁移至硬壁情景决定的吸引点；弱扰动时存在非线性不稳定性

Conclusion: 黑洞共振谱在扰动下表现出复杂的动力学行为，弱扰动导致线性近似失效的非线性不稳定性，强扰动则使系统趋向硬壁情景

Abstract: The aim of this work is to improve understanding of the resonant spectra of black holes under perturbations arising from e.g. compact objects or accretion disks in their vicinity. It is known that adding a weak perturbation to the radial potential can strongly disrupt the spectrum of quasinormal modes and Regge poles of a black hole spacetime. Here we examine the effect of (weak or strong) localised delta-function perturbations on the resonant spectra of spherically-symmetric systems, to address fundamental questions around linear and non-linear spectral stability. We examine two cases: the Nariai spacetime with a Poschl-Teller potential and the Schwarzschild spacetime. We show that, in either case, the spectrum deforms in a smooth and continuous manner as the position and strength of the perturbation is varied. As the strength of the perturbation is increased, resonances migrate along trajectories in the complex plane which ultimately tend towards attracting points determined by a hard-wall scenario. However, for weak perturbations the trajectory near the unperturbed resonance is typically strongly influenced by a set of repelling points which, for perturbations far from the system, lie very close to the unperturbed resonances; hence there arises a non-linear instability (i.e. the failure of a linearised approximation). Taking a dynamical systems perspective, the sets of attracting and repelling spectral points follow their own trajectories as the position of the perturbation is varied, and these are tracked and understood.

</details>


### [85] [Fermi Acceleration Mechanisms Beyond Lorentz Symmetry](https://arxiv.org/abs/2601.04961)
*Erick Aguiar,A. A. Araújo Filho,Valdir B. Bezerra,Gilson A. Ferreira,Iarley P. Lobo*

Main category: gr-qc

TL;DR: 该研究构建了包含一般框架变换、色散关系和守恒律的粒子费米加速模型，并在此框架下研究了κ-庞加莱代数对洛伦兹对称性的形变。


<details>
  <summary>Details</summary>
Motivation: 研究动机是建立一个统一的框架来研究粒子费米加速过程中的对称性形变，特别是洛伦兹对称性的不同修正方案（形变、破坏等），并比较它们对加速过程的影响。

Method: 构建了包含一般框架变换、色散关系和守恒律的粒子费米加速模型框架，在此框架下具体研究了κ-庞加莱代数的双叉积基和经典基，分别对应形变和保持相对论色散关系的情况，并与显式洛伦兹对称性破坏及狭义相对论进行比较。

Result: 建立了能够统一处理不同对称性修正方案的费米加速理论框架，具体分析了κ-庞加莱代数不同基下的对称性形变特征，比较了形变相对论、显式对称性破坏与标准相对论在粒子加速过程中的差异。

Conclusion: 该研究提供了一个系统研究粒子费米加速中对称性修正的理论框架，揭示了不同对称性形变方案（特别是κ-庞加莱代数的不同基）对加速过程的特征性影响，为探索量子引力效应在宇宙线加速中的可能表现提供了理论工具。

Abstract: We construct models for first- and second-order Fermi acceleration of particles, incorporating generic frame transformations, dispersion relations, and conservation laws. Within this framework, we study deformations of Lorentz symmetry via the $κ$-Poincaré algebra in the bicrossproduct and classical bases, which respectively deform and preserve the relativistic dispersion relation. We also examine explicit Lorentz symmetry violation and compare the results with deformed relativity and special relativity.

</details>


### [86] [Shadow of F(R)-EH Black Hole and Constraints from EHT Observations](https://arxiv.org/abs/2601.05040)
*Khadije Jafarzade,Saira Yasmin,Mubasher Jamil*

Main category: gr-qc

TL;DR: 研究f(R)引力与欧拉-海森堡非线性电动力学耦合的带电黑洞光学性质，分析光子轨迹、参数对光传播的影响，用EHT观测约束模型参数，并研究能量发射率。


<details>
  <summary>Details</summary>
Motivation: 探索f(R)引力理论与非线性电动力学耦合的带电黑洞的光学特性，理解引力与电磁效应的相互作用，并通过天文观测数据约束理论模型参数。

Method: 在静态球对称带电黑洞背景下分析光子轨迹，研究模型参数对光传播的影响；识别物理一致的黑洞阴影参数空间；利用事件视界望远镜对M87*的观测数据约束模型；分析能量发射率。

Result: 模型参数影响光传播，导致更宽范围的透镜轨迹和光子环；增加电荷和fR0会扩大物理一致的黑洞阴影参数空间；de Sitter黑洞解与EHT观测兼容，而反de Sitter解在低电荷和fR0>-1时被排除；高电荷增强黑洞蒸发，强非线性电动力学效应和大fR0值抑制蒸发。

Conclusion: f(R)引力与非线性电动力学耦合的带电黑洞模型能够产生物理一致的光学特性，其参数空间受天文观测约束，揭示了引力与电磁效应的复杂相互作用，对黑洞蒸发过程有重要影响。

Abstract: This work investigates the optical properties of a static, spherically symmetric, electrically charged black hole in f(R) gravity coupled to Euler-Heisenberg(EH) nonlinear electrodynamics(NLED). By analyzing photon trajectories in this background spacetime, we show how the model parameters affect light propagation, leading to wider ranges of lensed trajectories and photon rings. We identify regions of parameter space that admit physically consistent black hole shadows, characterized by the existence of a photon sphere located outside the event horizon and a shadow formed beyond it. These viable regions expand with increasing electric charge and increasing fR0, illustrating the interplay between gravitational and electromagnetic effects. By constraining the model using Event Horizon Telescope observations of M87*, we find that de Sitter black hole solutions remain compatible with the observational data, whereas anti-de Sitter solutions are disfavored for low electric charge and fR0 > -1. Finally, an analysis of the energy emission rate shows that higher electric charge enhances black hole evaporation, while stronger nonlinear electrodynamics effects and larger values of fR0 suppress it.

</details>


### [87] [Quantum fields in boson star spacetime](https://arxiv.org/abs/2601.05129)
*Paul M. Saffin,Qi-Xin Xie*

Main category: gr-qc

TL;DR: 论文研究了玻色星时空中的量子标量场和应力张量，发现强曲率是量子效应的主要来源，量子修正会改变经典玻色星解。


<details>
  <summary>Details</summary>
Motivation: 玻色星在经典引力中已被广泛研究，但其量子性质相对未被探索。论文旨在研究玻色星时空中的量子场论效应，了解量子修正如何影响经典引力解。

Method: 在半经典引力框架下计算玻色星时空中的量子标量场和应力张量。使用Pauli-Villars场正则化发散，采用谱方法获得精确数值结果。利用相干态直接比较应力张量的经典部分和量子涨落。

Result: 强时空曲率是产生大量子效应的主要来源。重整化的量子能量密度大多为正，但径向压力为负，表明经典玻色星解需要量子修正。在强曲率区域，量子涨落可占总应力张量的显著部分。

Conclusion: 量子效应会显著改变经典玻色星解，特别是在强曲率区域。所开发的方法可推广到其他致密天体，用于研究它们对量子修正的响应。

Abstract: Boson stars have been extensively studied in classical gravity, but their quantum properties remain comparatively unexplored. In this paper, we compute the quantum scalar fields and stress tensor in boson star spacetimes within the framework of semiclassical gravity. Divergences are regularized using Pauli-Villars fields, and accurate numerical results are obtained through spectral methods. Employing coherent states enables a direct comparison between the classical part of the stress tensor and the quantum fluctuation. Our results indicate that strong spacetime curvature is the primary source of large quantum effects. The renormalized quantum energy density is mostly positive but the radial pressure is negative, suggesting that classical boson star solutions require modification once quantum effects are included. Moreover, in regimes of large curvature, the quantum fluctuations can constitute a significant fraction of the total stress tensor. The methods developed here can be generalized to other compact objects and used to study their response to quantum corrections.

</details>


### [88] [Superluminal modes in a quantum field simulator for cosmology from analog Transplanckian physics](https://arxiv.org/abs/2601.05141)
*Christian F. Schmidt,Stefan Floerchinger*

Main category: gr-qc

TL;DR: 该论文发展了超越声学近似的Bose-Einstein凝聚体U(1)-Goldstone玻色子的量子场论描述，将其映射到具有超光速色散关系的彩虹宇宙时空，研究了模拟宇宙粒子产生时色散效应对功率谱的影响。


<details>
  <summary>Details</summary>
Motivation: 研究Bose-Einstein凝聚体中模拟宇宙学场景时，超越声学近似（Bogoliubov理论）的量子场论描述，以更精确地理解模拟宇宙粒子产生过程中的色散效应和紫外行为。

Method: 基于Bogoliubov理论发展时间依赖接触相互作用的标量Bose-Einstein凝聚体的U(1)-Goldstone玻色子量子场论描述，将其映射到具有Corley-Jacobson色散关系的相对论量子场论，分析指数膨胀和幂律收缩时空中的非绝热跃迁。

Result: 发现当截断尺度与视界交叉尺度分离不足时，色散效应会导致尺度不变性的破坏（Transplanckian阻尼效应）；在指数膨胀情况下，紫外区域会收敛到另一个尺度不变平台，其中高色散抑制了非绝热跃迁。

Conclusion: 该框架为更剧烈的模拟宇宙学场景提供了定量分析工具，提高了紫外区域的预测能力，可能最终在实验室中观测到尺度不变的宇宙功率谱。

Abstract: The quantum-field-theoretic description for the U(1)-Goldstone boson of a scalar Bose-Einstein condensate with time-dependent contact interactions is developed beyond the acoustic approximation in accordance with Bogoliubov theory. The resulting effective action is mapped to a relativistic quantum field theory on a dispersive (or rainbow) cosmological spacetime which has a superluminal Corley-Jacobson dispersion relation. Time-dependent changes of the s-wave scattering length to quantum-simulate cosmological particle production are accompanied by a time-dependent healing length that can be interpreted as an analog Planck length in the comoving frame. Non-adiabatic transitions acquire a dispersive character, which is thoroughly discussed. The framework is applied to exponentially expanding or power-law contracting $(2+1)$-dimensional spacetimes which are known to produce scale-invariant cosmological power spectra. The sensitivity of these scenarios to the time-dependence of the Bogoliubov dispersion is investigated: We find a violation of scale-invariance via analytically trackable Transplanckian damping effects if the cut-off scale is not well separated from the horizon-crossing scale. In case of the exponential expansion, these damping effects remarkably settle and converge to another scale-invariant plateau in the far ultraviolet regime where non-adiabatic transitions are suppressed by the high dispersion. The developed framework enables quantitative access to more drastic analog cosmological scenarios with improved predictability in the ultraviolet regime that ultimately may lead to the observation of a scale-invariant cosmological power spectrum in the laboratory.

</details>


### [89] [A new code for computing differentially rotating neutron stars](https://arxiv.org/abs/2601.05176)
*Samuel D. Tootle,Terrence Pierre Jacques,Marie Cassing*

Main category: gr-qc

TL;DR: 开发了FUKA初始数据代码，用于在广义相对论中构建微分旋转中子星的轴对称平衡模型，支持多种坐标系统和状态方程，具有高精度和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 需要更精确和高效的数值工具来模拟微分旋转中子星的平衡构型，以支持引力波天体物理学研究，并作为动力学模拟的初始条件。

Method: 使用KADATH谱库求解爱因斯坦方程，采用两种求解器：准各向同性坐标（QIC）在球坐标系中求解，以及扩展共形薄三明治（XCTS）分解在笛卡尔坐标系中求解。采用Komatsu-Eriguchi-Hachisu微分旋转定律，支持3D表格化状态方程。

Result: 实现了高精度和高效的平衡构型构建，通过收敛测试验证了谱方法的指数精度，与文献中已有模型和RNS代码进行了验证比较，并分析了初始数据分辨率对动力学模拟的影响。

Conclusion: FUKA代码为构建微分旋转相对论性恒星提供了可靠工具，为未来扩展到更一般的构型（包括磁场、非等熵假设和双星系统）奠定了基础，代码已公开供社区使用。

Abstract: We present new initial data codes for constructing stationary, axisymmetric equilibrium models of differentially rotating neutron stars in full general relativity within the Frankfurt University/KADATH (FUKA) suite of initial data codes. FUKA leverages the KADATH spectral library to solve the Einstein equations under the assumption of an isentropic fluid without magnetic fields while incorporating GRHayLEOS to support 3D tabulated equations of state in \textit{stellar collapse} format. The two solvers explored in this work include one using quasi-isotropic coordinates (QIC) in Spherical coordinates while the other solves the eXtended Conformal Thin Sandwich (XCTS) decomposition in Cartesian coordinates, enabling the construction of equilibrium configurations with high accuracy and efficiency. In this work we adopt the Komatsu-Eriguchi-Hachisu differential rotation law, however, the code is designed to be extensible to other rotation laws, allowing for exploration of physically relevant sequences and critical rotation thresholds. Furthermore, we perform convergence tests demonstrating the exponential accuracy of the spectral approach, we validate QIC and XCTS solutions against models well-studied in the literature, and we also compare FUKA solutions against the well-known RNS code. Finally, we explore the impact that initial data resolution has on dynamical simulations and recover the convergence order of the evolution scheme, the dominate source of error in this study. The new FUKA codes and results presented here lay the foundation for future extensions to more general configurations, including magnetic fields, removal of isentropic assumptions, and binary systems, and have been made publicly available to support community efforts in modeling differentially rotating relativistic stars.

</details>


### [90] [The End of the Road for Bulk Fields in Braneworlds](https://arxiv.org/abs/2601.05190)
*G. Alencar,R. S. Almeida,R. N. Costa Filho,T. M. Crispim,Francisco S. N. Lobo*

Main category: gr-qc

TL;DR: 本文推广了先前工作，为任意维度膜世界场景中的体场推导了一套完整的局域一致性条件，首次实现了完全局域且维度无关的推广。结果显示：自由标量场一致且局域化，Maxwell场违反条件（任意维度不成立），非线性电动力学中仅L(F)=b√F模型允许一致零模，p-形式中仅自由0-形式一致，Dirac费米子不一致。结论不依赖内部几何或扭曲因子。


<details>
  <summary>Details</summary>
Motivation: 先前关于膜世界中体场一致性条件的研究存在局限性，缺乏完全局域且维度无关的推广。本文旨在建立一套普适的局域一致性框架，统一所有已知判据，揭示不依赖特定几何结构的普遍约束。

Method: 推广参考文献[1]的方法，推导任意维度膜世界场景中体场的完整局域一致性条件。采用完全局域且维度无关的数学框架，分析各类场论模型（标量场、Maxwell场、非线性电动力学、p-形式、Dirac费米子）在一致性条件下的表现。

Result: 1. 自由标量场满足一致性条件且可局域化；2. 最小和非最小耦合的Maxwell场违反条件，任意维度均不成立；3. 非线性电动力学中仅L(F)=b√F模型允许一致且可归一化的零模；4. p-形式场中仅自由0-形式一致；5. Dirac费米子（含或不含Yukawa项）均不一致，不能在体中传播。

Conclusion: 建立了一套完全局域且维度无关的一致性条件框架，揭示了膜世界中体场传播的普遍约束。这些结论不依赖特定内部几何或扭曲因子，先前已知结果仅为该普适框架的特例，突显了所推导约束的普适性。

Abstract: In this manuscript we generalize Ref. [1] and derive a complete set of local consistency conditions for bulk fields in braneworld scenarios with an arbitrary number of dimensions. This provides the first fully local and dimension-independent generalization of all known criteria for bulk fields. Within this framework, we show that a free scalar field is consistent and localized, whereas minimally and non-minimally coupled Maxwell fields violate the conditions, leading to a no-go theorem valid in any dimension. For nonlinear electrodynamics, we find that only the model $L(F)=b\sqrt{F}$ admits a consistent and normalizable zero mode, and that among p-forms, consistency occurs solely for the free 0-form. We also demonstrate that Dirac fermions, with or without Yukawa terms, are inconsistent within this framework and therefore cannot propagate in the bulk. Our local approach makes explicit that these conclusions do not depend on any particular internal geometry or warp factor: previously known results arise merely as special cases of a broader and strictly local structure, highlighting the universality of the constraints derived here.

</details>


### [91] [Towards a unified quantum field theory of dark energy and inflation: unstable de Sitter vacuum and running vacuum](https://arxiv.org/abs/2601.05218)
*Joan Solà Peracaula,Àlex González-Fuentes,Cristian Moreno-Pulido*

Main category: gr-qc

TL;DR: 论文提出了一种不需要暴胀子场的暴胀机制——RVM暴胀，通过量子场论效应在动态背景上实现早期宇宙快速膨胀，并将暴胀和暗能量统一为动态真空能量。


<details>
  <summary>Details</summary>
Motivation: 传统暴胀模型需要引入特设的暴胀子标量场来修复标准宇宙学模型的基本不一致性。本文旨在探索更少特设性的替代方案，在运行真空模型框架下，通过纯量子场论效应实现暴胀。

Method: 在运行真空模型框架中，真空能量密度是哈勃参数H及其时间导数的函数。在早期宇宙中，真空涨落诱导出H的高次幂项（如H⁴），能够在H近似恒定的短时间内驱动快速暴胀。研究还分析了精确德西特真空衰变为FLRW时空辐射主导时期的过程。

Result: 研究发现RVM暴胀和德西特真空衰变两种情况下，暴胀都由H⁴项驱动，同时存在次主导的H²项，这有助于平滑过渡到辐射主导时期。在晚期宇宙中，真空能量密度呈现温和演化：δρ_vac ∼ O(m_Pl² H²)。

Conclusion: 该工作提供了一个统一的量子场论方法，将暴胀和暗能量（作为动态真空能量）统一起来，具有可测量的现象学后果，可能有助于解决当前宇宙学中的张力问题。

Abstract: Inflation is a necessary cosmic mechanism to cure basic inconsistencies of the standard model of cosmology. These problems are usually `fixed' by postulating the existence of a scalar field (called the ``inflaton''). However, other less ad hoc options are possible. In the running vacuum model (RVM) framework, the vacuum energy density (VED) is a function of the Hubble rate $H$ and its time derivatives: $ρ_{\rm vac}=ρ_{\rm vac}(H, \dot{H},\ddot{H},\dots)$. In this context, the VED is dynamical (there is no rigid cosmological constant $Λ$). In the FLRW epoch, $ρ_{\rm vac}$ evolves very slowly with expansion, as befits the observed $Λ\simeq$const. behavior. In contrast, in the very early universe the vacuum fluctuations induce higher powers $H^N$ capable of unleashing fast inflation in a short period in which $H\simeq$ const. We call this mechanism `RVM-inflation'. It does not require an inflaton field since inflation is brought about by pure quantum field theory (QFT) effects on the dynamical background. It is different from Starobinsky's inflation, in which $H$ is never constant. In this work, we study a closely related scenario: the decay of the exact de Sitter vacuum into FLRW spacetime in its radiation epoch and the subsequent impact on the current universe, and compare with the RVM. We find that in both cases inflation is driven by $H^4$ powers together with subleading contributions of order $H^2$ that ease a graceful-exit transition into the radiation-dominated epoch, where the FLRW regime starts and ultimately develops a mildly evolving VED in the late universe: $δρ_{\rm vac}\sim {\cal O}(m_{\rm Pl} ^2 H^2)$. The outcome is an unified QFT approach to inflation and dark energy (conceived as dynamical vacuum energy) with potentially measurable phenomenological consequences in the present universe which can help to cure the cosmological tensions.

</details>


### [92] [Constants of motion in gravitational self-force theory](https://arxiv.org/abs/2601.05223)
*David Trestini,Zachary Nasipak,Adam Pound*

Main category: gr-qc

TL;DR: 该论文提出利用自洽理论中的守恒量（能量、角动量、径向和极向作用量）来统一处理引力双星问题，建立与后牛顿理论的一致性，并应用于特殊轨道的扰动计算。


<details>
  <summary>Details</summary>
Motivation: 传统上自洽理论与其他引力双星问题方法的协同依赖于轨道频率相关的规范不变量计算。然而，直接利用守恒量可以简化参数空间比较、促进方法融合，并通过通量平衡定律更高效地生成波形。

Method: 针对无自旋双星系统，在一阶自洽近似下，数值和解析计算守恒量及基本频率修正（后牛顿展开至9PN），并与现有最高阶（4PN）后牛顿结果进行一致性验证。

Result: 建立了守恒量与频率修正的数值和解析结果，与4PN后牛顿理论一致。应用结果确定了参数空间中特殊曲线的扰动位置：圆轨道以及束缚轨道与坠入轨道之间的分界线。

Conclusion: 利用守恒量为引力双星问题提供了更统一的框架，简化了不同方法间的比较与融合，为波形生成和参数空间分析提供了更高效的工具。

Abstract: Synergies between self-force theory and other approaches to the gravitational two-body problem have traditionally relied on calculations of gauge-invariant observables as functions of orbital frequencies. However, in self-force theory one can also define a complete set of constants of motion: energy, azimuthal angular momentum, and radial and polar actions. Here we outline how directly utilizing these constants allows for more straightforward comparisons and hybridizations across the parameter space, as well as more streamlined waveform generation through flux-balance laws. Restricting to the case of nonspinning binaries and first order in self-force, we compute the constants of motion and the corrections to fundamental frequencies numerically as well as analytically (to 9PN in a post-Newtonian expansion), establishing consistency with the highest-order (4PN) results available from post-Newtonian theory. We also apply the results to identify the perturbed locations of special curves in the parameter space: circular orbits and the separatrix between bound and plunging orbits.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [93] [Quantum Elastic Network Models and their Application to Graphene](https://arxiv.org/abs/2601.05161)
*Ioannis Kolotouros,Adithya Sireesh,Stuart Ferguson,Sean Thrasher,Petros Wallden,Julien Michel*

Main category: quant-ph

TL;DR: 提出量子弹性网络模型(QENM)，利用量子算法指数级加速耦合振荡器系统的模拟，应用于二维材料如石墨烯的厘米级原子模拟


<details>
  <summary>Details</summary>
Motivation: 传统分子动力学模拟在宏观尺度上具有原子级分辨率时计算不可行，即使使用最简单的弹性网络模型(ENM)也面临内存和计算时间限制

Method: 引入量子弹性网络模型(QENM)，利用Babbush等人的量子算法在特定条件下指数级加速耦合振荡器系统的模拟，应用于二维平面材料

Result: 展示了该方法在模拟二维石墨烯片中的应用，分析了初始态制备、哈密顿量模拟和测量的精确复杂度，提供了热传递和面外波纹效应的实际应用示例

Conclusion: 厘米级原子模拟的石墨烯片传统上需要数百PB内存和不可行的运行时间，而量子方法仅需约160个逻辑量子比特即可编码和模拟，展示了量子计算在材料模拟中的巨大潜力

Abstract: Molecular dynamics simulations are a central computational methodology in materials design for relating atomic composition to mechanical properties. However, simulating materials with atomic-level resolution on a macroscopic scale is infeasible on current classical hardware, even when using the simplest elastic network models (ENMs) that represent molecular vibrations as a network of coupled oscillators. To address this issue, we introduce Quantum Elastic Network Models (QENMs) and utilize the quantum algorithm of Babbush et al. (PRX, 2023), which offers an exponential advantage when simulating systems of coupled oscillators under some specific conditions and assumptions. Here, we demonstrate how our method enables the efficient simulation of planar materials. As an example, we apply our algorithm to the task of simulating a 2D graphene sheet. We analyze the exact complexity for initial-state preparation, Hamiltonian simulation, and measurement of this material, and provide two real-world applications: heat transfer and the out-of-plane rippling effect. We estimate that an atomistic simulation of a graphene sheet on the centimeter scale, classically requiring hundreds of petabytes of memory and prohibitive runtimes, could be encoded and simulated with as few as $\sim 160$ logical qubits.

</details>


### [94] [Microscopic Dynamics of False Vacuum Decay in the $2+1$D Quantum Ising Model](https://arxiv.org/abs/2601.04305)
*Umberto Borla,Achilleas Lazarides,Christian Groß,Jad C. Halimeh*

Main category: quant-ph

TL;DR: 该论文研究了2+1维量子伊辛模型中的假真空衰变，通过树张量网络模拟自旋畴的微观动力学，探索气泡膨胀或坍缩的几何特征依赖性，并提出了基于里德堡原子阵列的量子模拟方案。


<details>
  <summary>Details</summary>
Motivation: 假真空衰变是基本粒子物理和早期宇宙学中的重要现象，通常通过气泡成核发生。理解其在更高空间维度中的微观动力学是当前的主要挑战和研究重点。最近数值技术的进步使得在中等时间尺度上提取二维空间相关特征成为可能。

Method: 研究聚焦于2+1维量子伊辛模型，利用纵向场将两个Z2对称破缺铁磁基态能量分离，使其成为"真"和"假"真空。使用树张量网络模拟均匀淬火后自旋向下畴在自旋向上背景中的微观动力学，参数选择使畴对应于假真空背景中的真空气泡。

Result: 研究确定了气泡最终命运（无限膨胀或坍缩）如何依赖于其几何特征和伊辛哈密顿量的微观参数。发现气泡动力学与几何特征和微观参数密切相关。

Conclusion: 该研究不仅揭示了气泡膨胀或坍缩的几何依赖性，还提出了基于原子里德堡阵列的现实量子模拟方案，为在可控量子系统中探测气泡动力学提供了可行途径。

Abstract: False vacuum decay, which is understood to happen through bubble nucleation, is a prominent phenomenon relevant to elementary particle physics and early-universe cosmology. Understanding its microscopic dynamics in higher spatial dimensions is currently a major challenge and research thrust. Recent advances in numerical techniques allow for the extraction of related signatures in tractable systems in two spatial dimensions over intermediate timescales. Here, we focus on the $2+1$D quantum Ising model, where a longitudinal field is used to energetically separate the two $\mathbb{Z}_2$ symmetry-broken ferromagnetic ground states, turning them into a ``true'' and ``false'' vacuum. Using tree tensor networks, we simulate the microscopic dynamics of a spin-down domain in a spin-up background after a homogeneous quench, with parameters chosen so that the domain corresponds to a bubble of the true vacuum in a false-vacuum background. Our study identifies how the ultimate fate of the bubble -- indefinite expansion or collapse -- depends on its geometrical features and on the microscopic parameters of the Ising Hamiltonian. We further provide a realistic quantum-simulation scheme, aimed at probing bubble dynamics on atomic Rydberg arrays.

</details>


### [95] [Rare-Event Quantum Sensing using Logical Qubits](https://arxiv.org/abs/2601.04313)
*Robert Ott,Torsten V. Zache,Soonwon Choi,Adam M. Kaufman,Hannes Pichler*

Main category: quant-ph

TL;DR: 提出一种基于量子纠错（QEC）的新协议，利用QEC过程中的非线性处理区分信号与噪声，通过高阶相关性检测稀有信号，相比传统传感策略提高了灵敏度。


<details>
  <summary>Details</summary>
Motivation: 在嘈杂环境中检测稀有信号是一个挑战，传统方法难以有效区分信号与噪声。量子传感需要克服噪声干扰，特别是在存在局部马尔可夫噪声的情况下，提高对稀有信号的检测灵敏度。

Method: 利用量子纠错（QEC）协议，通过QEC过程中的非线性处理（特别是在综合征提取阶段）产生信号与噪声之间的高阶相关性差异。QEC有两个作用：1）牺牲部分信号ε，记录减小的随机逻辑相位φ_L = O(ε³)；2）纠正物理噪声并延长逻辑相干时间用于信号采集。

Result: 对于在局部马尔可夫噪声中随机出现的稀有信号，该协议明确展示了比传统传感策略更高的灵敏度。通过QEC的非线性处理有效区分信号与噪声，实现了改进的信号检测性能。

Conclusion: 基于量子纠错的协议为嘈杂环境中的稀有信号检测提供了新方法，通过利用QEC过程中的非线性效应和高阶相关性，显著提高了检测灵敏度，为量子传感领域带来了重要进展。

Abstract: We present a novel protocol to detect rare signals in a noisy environment using quantum error correction (QEC). The key feature of our protocol is the discrimination between signal and noise through distinct higher-order correlations, realized by the non-linear processing that occurs during syndrome extraction in QEC. In this scheme, QEC has two effects: First, it sacrifices part of the signal $ε$ by recording a reduced, stochastic, logical phase $φ_L = \mathcal{O}(ε^3)$. Second, it corrects the physical noise and extends the (logical) coherence time for signal acquisition. For rare signals occurring at random times in the presence of local Markovian noise, we explicitly demonstrate an improved sensitivity of our approach over more conventional sensing strategies.

</details>


### [96] [Quantum sensing with critical systems: impact of symmetry, imperfections, and decoherence](https://arxiv.org/abs/2601.04364)
*Yinan Chen,Sara Murciano,Pablo Sala,Jason Alicea*

Main category: quant-ph

TL;DR: 基于量子临界波函数的干涉测量协议，通过对称性算法优化测量策略，在特定条件下超越GHZ态和自旋压缩态的传感性能


<details>
  <summary>Details</summary>
Motivation: 纠缠多体态可实现超越标准量子极限的高精度量子传感，但需要开发更优的传感协议并比较不同量子态的性能

Method: 开发基于量子临界波函数的干涉测量协议；引入基于对称性的算法识别最优测量策略；研究在非幺正变形、对称性保持/破坏退相干和量子比特丢失下的鲁棒性

Result: 识别出临界系统优于GHZ态的特定区域；发现非幺正变形甚至能增强传感精度；结合临界波函数的对数深度制备，该传感方案前景广阔

Conclusion: 基于量子临界波函数的干涉测量传感方案在特定条件下性能优越，结合其高效制备方法，在量子传感领域具有重要应用前景

Abstract: Entangled many-body states enable high-precision quantum sensing beyond the standard quantum limit. We develop interferometric sensing protocols based on quantum critical wavefunctions and compare their performance with Greenberger-Horne-Zeilinger (GHZ) and spin-squeezed states. Building on the idea of symmetries as a metrological resource, we introduce a symmetry-based algorithm to identify optimal measurement strategies. We illustrate this algorithm both for magnetic systems with internal symmetries and Rydberg-atom arrays with spatial symmetries. We study the robustness of criticality for quantum sensing under non-unitary deformations, symmetry-preserving and symmetry-breaking decoherence, and qubit loss -- identifying regimes where critical systems outperform GHZ states and showing that non-unitary deformation can even enhance sensing precision. Combined with recent results on log-depth preparation of critical wavefunctions, interferometric sensing in this setting appears increasingly promising.

</details>


### [97] [Solving nonlinear PDEs with Quantum Neural Networks: A variational approach to the Bratu Equation](https://arxiv.org/abs/2601.04372)
*Nikolaos Cheimarios*

Main category: quant-ph

TL;DR: 提出一种变分量子算法求解一维非线性Bratu方程，通过量子神经网络编码解，将边值问题转化为量子电路参数优化问题


<details>
  <summary>Details</summary>
Motivation: 探索量子计算在求解非线性微分方程中的应用潜力，特别是处理具有多解分支的Bratu方程这类复杂问题

Method: 采用变分量子算法框架，将Bratu边值问题转化为变分优化问题；使用参数化量子神经网络编码解，构造包含经典近似和边界强制项的试探解，通过优化量子电路参数最小化微分算子残差

Result: 在无噪声量子模拟器上验证了该方法能够准确捕捉Bratu方程的两个解分支，并与经典伪弧长延拓方法结果高度一致

Conclusion: 变分量子算法能够有效求解非线性微分方程，为量子计算在科学计算领域提供了有前景的应用方向

Abstract: We present a variational quantum algorithm (VQA) to solve the nonlinear one-dimensional Bratu equation. By formulating the boundary value problem within a variational framework and encoding the solution in a parameterized quantum neural network (QNN), the problem reduces to an optimization task over quantum circuit parameters. The trial solution incorporates both classical approximations and boundary-enforcing terms, allowing the circuit to focus on minimizing the residual of the differential operator. Using a noiseless quantum simulator, we demonstrate that the method accurately captures both solution branches of the Bratu equation and shows excellent agreement with classical pseudo arc-length continuation results.

</details>


### [98] [Thermodynamic significance of QUBO encoding on quantum annealers](https://arxiv.org/abs/2601.04402)
*Emery Doucet,Zakaria Mzaouali,Reece Robertson,Bartłomiej Gardas,Sebastian Deffner,Krzysztof Domino*

Main category: quant-ph

TL;DR: 研究QUBO编码中惩罚参数对量子退火器性能的影响，发现惩罚参数不仅影响计算难度，还调控热力学耗散，为噪声中尺度量子退火器提供热力学感知的编码策略。


<details>
  <summary>Details</summary>
Motivation: QUBO是量子退火器的标准接口，但约束任务有多种编码方式，惩罚参数选择会重塑硬件体验的能量景观。需要研究惩罚参数如何影响计算性能和热力学行为。

Method: 使用Job Shop Scheduling实例，研究由惩罚权重$p_{\rm sum}$（one-hot/求和约束）和$p_{\rm pair}$（优先约束）控制的双参数编码族。扫描$(p_{\rm sum},p_{\rm pair})$，观察经典退火启发式算法和D-Wave Advantage处理器上的可行性转变和求解器成功率。将退火器视为开放热力学系统，进行循环反向退火实验，测量随机处理器能量变化，通过热力学不确定性关系推断熵产生、功和交换热的下界。

Result: 观察到惩罚参数导致计算硬度的急剧转变，同时重组耗散：弱惩罚产生低能量不可行流形，而过强惩罚抑制有效问题能量尺度并增加不可逆性，降低热力学效率。编码转变既控制计算难度也调控热力学行为。

Conclusion: QUBO惩罚参数可作为热力学控制旋钮，为噪声中尺度量子退火器提供热力学感知的编码策略，优化计算性能和热力学效率。

Abstract: Quadratic unconstrained binary optimization (QUBO) is the standard interface to quantum annealers, yet a single constrained task admits many QUBO encodings whose penalty choices reshape the energy landscape experienced by hardware. We study a Job Shop Scheduling instance using a two-parameter family of encodings controlled by penalty weights $p_{\rm sum}$ (one-hot/sum constraints) and $p_{\rm pair}$ (precedence constraints). Sweeping $(p_{\rm sum},p_{\rm pair})$, we observe sharp transitions in feasibility and solver success across classical annealing-inspired heuristics and on a D-Wave Advantage processor. Going beyond solution probability, we treat the annealer as an open thermodynamic system and perform cyclic reverse-annealing experiments initialized from thermal samples, measuring the stochastic processor energy change. From the first two moments of this energy change we infer lower bounds on entropy production, work, and exchanged heat via thermodynamic uncertainty relations, and corroborate the observed trends with adiabatic master equation simulations. We find that the same encoding transitions that govern computational hardness also reorganize dissipation: weak penalties generate low-energy infeasible manifolds, while overly strong penalties suppress the effective problem energy scale and increase irreversibility, reducing the thermodynamic efficiency. Our results establish QUBO penalties as thermodynamic control knobs and motivate thermodynamics-aware encoding strategies for noisy intermediate-scale quantum annealers.

</details>


### [99] [Exact Multimode Quantization of Superconducting Circuits via Boundary Admittance](https://arxiv.org/abs/2601.04407)
*Mustafa Bakr,Robin Wopalenski*

Main category: quant-ph

TL;DR: 提出基于节点导纳矩阵的Schur补的四步量子化方法，用于约瑟夫森结电路，确保紫外收敛并导出标准电路QED参数。


<details>
  <summary>Details</summary>
Motivation: 为约瑟夫森结电路提供系统化的量子化方法，避免人为截断，确保紫外收敛，并明确标准电路QED参数的有效条件。

Method: 1) 计算或测量输入导纳Y_in(s)；2) 解边界条件sY_in(s)+1/L_J=0得频率；3) 合成等效无源网络；4) 保留完整余弦非线性进行量子化。

Result: 证明当结端口有有限并联电容时，结参与度在高频下以O(ω_n^{-1})衰减，确保微扰求和的紫外收敛性，无需人为截断。

Conclusion: 该方法为约瑟夫森结电路提供系统化量子化框架，导出标准电路QED参数(g, α, χ)并明确其有效条件，确保理论自洽性。

Abstract: We show that the Schur complement of the nodal admittance matrix, which reduces a multiport electromagnetic environment to the driving-point admittance $Y_{\mathrm{in}}(s)$ at the Josephson junction, naturally leads to an eigenvalue-dependent boundary condition determining the dressed mode spectrum. This identification provides a four-step quantization procedure: (i) compute or measure $Y_{\mathrm{in}}(s)$, (ii) solve the boundary condition $sY_{\mathrm{in}}(s) + 1/L_J = 0$ for dressed frequencies, (iii) synthesize an equivalent passive network, (iv) quantize with the full cosine nonlinearity retained. Within passive lumped-element circuit theory, we prove that junction participation decays as, we prove that junction participation decays as $O(ω_n^{-1})$ at high frequencies when the junction port has finite shunt capacitance, ensuring ultraviolet convergence of perturbative sums without imposed cutoffs. The standard circuit QED parameters, coupling strength $g$, anharmonicity $α$, and dispersive shift $χ$, emerge as controlled limits with explicit validity conditions.

</details>


### [100] [Implementation of Tensor Network Simulation TN-Sim under NWQ-Sim](https://arxiv.org/abs/2601.04422)
*Aaron C. Hoyt,Jonathan S. Bersson,Sean Garner,Chenxu Liu,Ang Li*

Main category: quant-ph

TL;DR: TN-Sim是一个基于TAMM框架的分布式张量网络模拟器，支持从本地到HPC集群的量子电路模拟，在Perlmutter超算上展示了MPS方法的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 大规模张量网络模拟对于量子计算的复杂性理论边界、电路切割方法和电路编译优化至关重要，而现代百亿亿次HPC平台为提升张量网络量子电路模拟能力提供了巨大潜力。

Method: 在NWQ-Sim软件包中实现TN-Sim张量网络模拟后端，利用TAMM框架支持分布式HPC计算和本地ITensor模拟，采用基于任务的并行化方案优化多节点计算，并集成TAMM框架与MPS张量网络方法。

Result: 在先进的Perlmutter（NVIDIA）超级计算机上展示了MPS张量网络模拟器的运行，证明了该软件在HPC集群（如Frontier和Aurora）上的可移植性，实现了从本地系统到HPC集群的可扩展模拟环境。

Conclusion: TN-Sim为量子电路模拟提供了可扩展的HPC解决方案，未来将支持更多张量网络拓扑并提升计算效率，有助于在有限量子资源上实现高效量子计算。

Abstract: Large-scale tensor network simulations are crucial for developing robust complexity-theoretic bounds on classical quantum simulation, enabling circuit cutting approaches, and optimizing circuit compilation, all of which aid efficient quantum computation on limited quantum resources. Modern exascale high-performance computing platforms offer significant potential for advancing tensor network quantum circuit simulation capabilities. We implement TN-Sim, a tensor network simulator backend within the NWQ-Sim software package that utilizes the Tensor Algebra for Many-body Methods (TAMM) framework to support both distributed HPC-scale computations and local simulations with ITensor. To optimize the scale up in computation across multiple nodes we implement a task based parallelization scheme to demonstrate parallelized gate contraction for wide quantum circuits with many gates per layer. Through the integration of the TAMM framework with Matrix Product State (MPS) tensor network approaches, we deliver a simulation environment that can scale from local systems to HPC clusters. We demonstrate an MPS tensor network simulator running on the state-of-the-art Perlmutter (NVIDIA) supercomputer and discuss the potential portability of this software to HPC clusters such as Frontier (AMD) and Aurora (Intel). We also discuss future improvements including support for different tensor network topologies and enhanced computational efficiency.

</details>


### [101] [Solving nonlinear differential equations on noisy $156$-qubit quantum computers](https://arxiv.org/abs/2601.04439)
*Karla Baumann,Youcef Modheb,Roman Randrianarisoa,Roland Katz,Aoife Boyle,Frédéric Holweck*

Main category: quant-ph

TL;DR: 该论文展示了在IBM量子平台上使用混合经典-量子算法H-DES求解非线性微分方程，成功解决了一维材料变形问题和无粘性Burgers方程


<details>
  <summary>Details</summary>
Motivation: 探索在当前噪声中等规模量子（NISQ）设备上执行物理相关模拟的可能性，推动量子计算在科学计算和工程模拟领域的应用

Method: 采用混合经典-量子算法H-DES，在IBM的156量子比特量子计算机上实现非线性微分方程的求解

Result: 成功求解了一维材料变形问题和无粘性Burgers方程，验证了算法在当前NISQ设备上的可行性

Conclusion: 这些结果为在当前NISQ设备上执行物理相关模拟迈出了重要一步，展示了量子计算在科学计算领域的应用潜力

Abstract: In this paper, we report on the resolution of nonlinear differential equations using IBM's quantum platform. More specifically, we demonstrate that the hybrid classical-quantum algorithm H-DES successfully solves a one-dimensional material deformation problem and the inviscid Burgers' equation on IBM's 156-qubit quantum computers. These results constitute a step toward performing physically relevant simulations on present-day Noisy Intermediate-Scale Quantum (NISQ) devices.

</details>


### [102] [A Broadband Nanowire Quantum Dot Cavity Design for the Efficient Extraction of Entangled Photons](https://arxiv.org/abs/2601.04440)
*Sayan Gangopadhyay,Sasan V. Grayli,Sathursan Kokilathasan,Michael E. Reimer*

Main category: quant-ph

TL;DR: 提出一种基于准束缚态连续体的纳米线腔设计，用于增强量子点纠缠光子源的单光子不可区分性和提取效率


<details>
  <summary>Details</summary>
Motivation: 量子网络需要高质量纠缠光子源，但现有纳米线波导量子点源的单光子不可区分性较差，需要同时实现高Purcell增强和保持纳米线优势（定向发射、宽带宽、高提取效率）

Method: 设计基于准束缚态连续体的纳米线腔，通过两个谐振光学模式的强耦合形成腔模式，支持4nm带宽和Purcell增强约17倍

Result: 数值模拟显示该腔模式具有定向远场发射特性（与高斯模式重叠度88%），光提取效率约74%

Conclusion: 该设计为实现具有增强提取效率和单光子不可区分性的纠缠光子对生成开辟了新途径，有望推动量子网络的实用化

Abstract: A bright source of on-demand entangled photons is needed for quantum networks. A single quantum dot in a site-selected nanowire waveguide is a promising candidate for realizing such sources. However, such sources are associated with poor single-photon indistinguishability, limiting their applicability in quantum networks. A common approach for enhancing the single-photon indistinguishability in quantum dot-based entangled photon sources is to implement a broadband optical cavity. Achieving a high-Purcell cavity while retaining the advantages of the nanowire, such as directional emission, a broad operational bandwidth, and high light extraction efficiency, has been a significant challenge. Here, we propose a nanowire cavity based on quasi-bound states in the continuum formed by the strong coupling of two resonant optical modes. We numerically predict this design to support a cavity mode with 4 nm bandwidth and a Purcell enhancement of $\sim$17. This cavity mode enables a directional far-field emission profile (88% overlap with a Gaussian) with a light extraction efficiency of $\sim$74%. Our solution opens up a route for generating entangled photon pairs with enhanced extraction efficiency and single-photon indistinguishability for the practical realization of quantum networks.

</details>


### [103] [Pauli Measurements Are Near-Optimal for Pure State Tomography](https://arxiv.org/abs/2601.04444)
*Sabee Grewal,Meghal Gupta,William He,Aniruddha Sen,Mihir Singhal*

Main category: quant-ph

TL;DR: 提出一种使用单量子比特测量的纯态层析算法，具有接近最优的副本复杂度，仅需非自适应泡利测量，运行时间为多项式级别


<details>
  <summary>Details</summary>
Motivation: 纯态层析是量子信息处理中的基本任务，现有方法需要大量副本或复杂测量。先前最佳算法需要 $\widetilde{O}(3^n/ε)$ 副本，存在改进空间以降低资源需求

Method: 使用非自适应泡利测量，仅需单量子比特测量，算法运行时间为 $\mathrm{poly}(2^n,1/ε)$，通过优化测量策略和重建算法实现

Result: 将纯态层析的副本复杂度从 $\widetilde{O}(3^n/ε)$ 改进到 $\widetilde{O}(2^n/ε)$，达到接近最优的复杂度，同时保持高保真度 $1-ε$

Conclusion: 该算法在纯态层析中实现了显著的资源效率提升，仅需单量子比特非自适应测量，为量子态表征提供了更实用的解决方案

Abstract: We give an algorithm for pure state tomography with near-optimal copy complexity using single-qubit measurements. Specifically, given $\widetilde{O}(2^n/ε)$ copies of an unknown pure $n$-qubit state $\lvertψ\rangle$, the algorithm performs only \textit{nonadaptive Pauli measurements}, runs in time $\mathrm{poly}(2^n,1/ε)$, and outputs $\lvert \widehatψ \rangle$ that has fidelity $1-ε$ with $\lvert ψ\rangle$ with high probability. This improves upon the previous best copy complexity bound of $\widetilde{O}(3^n/ε)$.

</details>


### [104] [Holographic codes seen through ZX-calculus](https://arxiv.org/abs/2601.04467)
*Kwok Ho Wan,H. C. W. Price,Qing Yao*

Main category: quant-ph

TL;DR: 从ZX演算视角重新审视五边形全息量子纠错码，通过ZX图研究其稳定子结构，并推广到双曲铺砌上的ZX图码族


<details>
  <summary>Details</summary>
Motivation: 从ZX演算的新视角研究五边形全息量子纠错码，利用ZX图的优势更清晰地理解码的结构特性

Method: 将五边形全息码的张量表示为ZX图，通过泡利网研究稳定子结构，并基于此构造双曲铺砌上的ZX图码族

Result: 获得了码的逻辑算子、编码等距、Rényi熵和黑洞/虫洞玩具模型的图表示，新码族在置信传播解码器下表现出良好的逻辑错误率

Conclusion: ZX演算为研究全息量子纠错码提供了强大的图表示工具，能够统一理解码的多种特性并构造新的码族

Abstract: We re-visit the pentagon holographic quantum error correcting code from a ZX-calculus perspective. By expressing the underlying tensors as ZX-diagrams, we study the stabiliser structure of the code via Pauli webs. In addition, we obtain a diagrammatic understanding of its logical operators, encoding isometries, Rényi entropy and toy models of black holes/wormholes. Then, motivated by the pentagon holographic code's ZX-diagram, we introduce a family of codes constructed from ZX-diagrams on its dual hyperbolic tessellations and study their logical error rates using belief propagation decoders.

</details>


### [105] [Momentum-Space Entanglement Entropy as a Universal Signature of Dynamical Quantum Phase Transitions](https://arxiv.org/abs/2601.04535)
*Kaiyuan Cao,Mingzhi Li,Xiang-Ping Jiang,Shu Chen,Jian Wang*

Main category: quant-ph

TL;DR: 动量空间纠缠熵可作为动力学量子相变的通用特征：在TFI和SSH模型中，每个与DQPT相关的临界动量模式都会使其纠缠熵饱和到最大值ln2，与Loschmidt回波消失同时发生。


<details>
  <summary>Details</summary>
Motivation: 本文旨在建立动力学量子相变(DQPTs)的统一纠缠视角。传统上DQPTs通过Loschmidt回波的非解析性来表征，但缺乏直接的量子关联特征。作者希望找到能够直接量化DQPTs中量子关联的物理量。

Method: 引入动量空间纠缠熵来量化淬火后不同动量模式之间的量子关联。在横向场伊辛模型(TFI)和Su-Schrieffer-Heeger(SSH)链中，作者通过解析证明建立了动量空间纠缠熵与DQPTs的关系。

Result: 证明在TFI和SSH模型中，每个与DQPT相关的临界动量k*都会使其纠缠熵饱和到最大值ln2（d=2），这与Loschmidt回波的消失完全一致。这种模式纠缠的饱和为DQPTs提供了通用、直接的信号。

Conclusion: 动量空间纠缠熵的饱和是DQPTs的通用特征，为动力学量子相变提供了统一的纠缠基础视角。这项工作建立了DQPTs与量子纠缠之间的直接联系。

Abstract: We introduce a momentum-space entanglement entropy to quantify quantum correlations between distinct momentum modes following a quench. We prove analytically in the transverse-field Ising (TFI) model and the Su-Schrieffer-Heeger (SSH) chain that every critical momentum $k^{*}$ associated with a dynamical quantum phase transition (DQPT) saturates its entanglement entropy to the maximal value $\ln{d}$ ($d=2$ in TFI and SSH models), coinciding with the vanishing of the Loschmidt echo. This saturation of mode entanglement thus provides a universal, direct signature of DQPTs. Our work thus establishes a unified, entanglement-based perspective on dynamical quantum phase transitions.

</details>


### [106] [Increasing the secret key rates and point-to-multipoint extension for experimental coherent-one-way quantum key distribution protocol](https://arxiv.org/abs/2601.04543)
*Venkat Abhignan,Mohit Mittal,Aditi Das,Megha Shrivastava*

Main category: quant-ph

TL;DR: 通过结合两个探测器的时隙信息，提高COW QKD协议的密钥率，并实现点对多点QKD系统


<details>
  <summary>Details</summary>
Motivation: 量子密钥分发(QKD)在实际网络应用中，单光子探测器成为性能瓶颈，限制了密钥率。需要优化组件使用和协议设计来提高密钥率并支持多用户传输。

Method: 1) 在COW QKD协议接收端的数据线上，结合两个探测器的时隙信息来提高密钥率；2) 实现点对多点COW QKD协议，增加接收模块，三个用户通过后处理共享密钥，依赖一次一密加密。

Result: 实验表明，结合两个探测器的时隙信息可以在量子比特误码率(QBER)最小增加的情况下提高密钥率。双接收器扩展可以改善系统的组合密钥率，但需要在安全范围内优化实验参数。

Conclusion: 这些方法具有通用性，可应用于任何COW协议实现，为实际QKD网络中的连续运行和多用户传输提供了有效解决方案。

Abstract: Using quantum key distribution (QKD) protocols, a secret key is created between two distant users (transmitter and receiver) at a particular key rate. Quantum technology can facilitate secure communication for cryptographic applications, combining QKD with one-time-pad (OTP) encryption. In order to ensure the continuous operation of QKD in real-world networks, efforts have been concentrated on optimizing the use of components and effective QKD protocols to improve secret key rates and increase the transmission between multiple users. Generally, in experimental implementations, the secret key rates are limited by single-photon detectors, which are used at the receivers of QKD and create a bottleneck due to their limited detection rates (detectors with low detection efficiency and high detector dead-time). We experimentally show that secret key rates can be increased by combining the time-bin information of two such detectors on the data line of the receiver for the coherent-one-way (COW) QKD protocol with a minimal increase in quantum bit error rate (QBER, the proportion of erroneous bits). Further, we implement a point-to-multipoint COW QKD protocol, introducing an additional receiver module. The three users (one transmitter and two receivers) share the secret key in post-processing, relying on OTP encryption. Typically, the dual-receiver extension can improve the combined secret key rates of the system; however, one has to optimise the experimental parameters to achieve this within security margins. These methods are general and can be applied to any implementation of the COW protocol.

</details>


### [107] [Observation of ΔJ=0 Rotational Excitation in Dense Hydrogens](https://arxiv.org/abs/2601.04549)
*Jie Feng,XiaoDi Liu,Haian Xu,Pu Wang,Graeme J. Ackland,Eugene Gregoryanz*

Main category: quant-ph

TL;DR: 在高压低温条件下，H2、D2及其混合物中观测到ΔJ=0旋转激发，该激发在固态时具有非零拉曼位移，表现出独特的同位素无关性。


<details>
  <summary>Details</summary>
Motivation: 研究高压低温条件下氢同位素分子体系的旋转激发行为，探索不同于传统谐振子和量子转子的新型激发模式。

Method: 在宽压力-温度范围内对致密H2、D2和H2+D2混合物进行拉曼光谱测量，分析ΔJ=0旋转激发的频率变化。

Result: ΔJ=0激发在气/流体态时拉曼位移为零，但在固态时非零（如50GPa、10K时约75cm-1）；该激发频率不遵循旋转或振动模式的同位素标度规律，表现出完全的同位素无关性。

Conclusion: ΔJ=0激发代表了一种独特的基本激发类型，既不同于传统谐振子也不同于量子转子，其同位素无关性揭示了分子环境对称性破缺的复杂特性。

Abstract: Raman measurements performed on dense H2, D2 and H2+D2 in a wide pressure-temperature range reveal the presence of the ΔJ=0 rotational excitation. In the gas/fluid state this excitation has zero Raman shift, but in the solid, the crystal field drive s it away from the zero value e.g. 75 cm-1 at around 50 GPa and 10 K for both isotopes and their mixture. In the case of deuterium, the ΔJ=0 mode splits upon entering phase II suggesting a very complex molecular environment of the broken symmetry phase (BSP). In the fluid state and phases I and II the frequencies (energies) of the ΔJ=0 transition for H2 and D2 do not scale either as rotational (by factor of 2) nor vibrational (by square 2) modes and appear to be completely isotope independent. This independence on mass marks this transition as unique and a fundamentally different type of excitation from the commonly considered harmonic oscillator and quantum rotor.

</details>


### [108] [Multimode Fock-State Measurements using Dispersive Shifts in a Trapped Ion](https://arxiv.org/abs/2601.04591)
*Wonhyeong Choi,Jiyong Kang,Kyunghye Kim,Jaehun You,Kyungmin Lee,Taehyun Kim*

Main category: quant-ph

TL;DR: 利用单自旋测量多模玻色寄存器的技术，通过远失谐多模Jaynes-Cummings相互作用的色散位移实现多模自旋依赖旋转，用于提取Fock态分布、宇称滤波和非破坏性单次测量。


<details>
  <summary>Details</summary>
Motivation: 囚禁离子系统天然包含多个振动模式和长寿命自旋量子比特，构成可扩展的多模玻色寄存器。高效表征这种寄存器需要利用有限的自旋资源访问多个振动模式。

Method: 引入基于远失谐多模Jaynes-Cummings相互作用色散位移的单自旋多模测量原语，实现Ramsey序列将声子数依赖相位映射到自旋上，形成多模自旋依赖旋转。还引入选择性解耦方案消除载波AC-Stark位移引起的相位，同时保留色散位移引起的声子数依赖相位。

Result: 在单个囚禁离子上实验提取双模Fock态分布，执行基于宇称的双模振动态滤波，并通过重复滤波步骤实现单模Fock态的非破坏性单次测量。

Conclusion: 该方法为多模玻色寄存器的高效表征提供了实用工具，特别适用于有限自旋资源下的多模量子态测量和滤波操作。

Abstract: Trapped ions naturally host multiple motional modes alongside long-lived spin qubits, providing a scalable multimode bosonic register. Efficiently characterizing such bosonic registers requires the ability to access many motional modes with limited spin resources. Here we introduce a single-spin, multimode measurement primitive using dispersive shifts in the far-detuned multimode Jaynes-Cummings interaction. We implement a Ramsey sequence that maps phonon-number-dependent phases onto the spin, thereby realizing a multimode spin-dependent rotation (SDR). We also introduce a selective-decoupling scheme that cancels the phase induced by the carrier AC-Stark shift while preserving the phonon-number-dependent phase induced by the dispersive shift. Using this SDR-based Ramsey sequence on a single trapped ion, we experimentally extract two-mode Fock-state distributions, perform parity-based filtering of two-mode motional states, and realize a nondestructive single-shot measurement of a single-mode Fock state via repeated filtering steps.

</details>


### [109] [Path Integral Lindblad Dynamics in Presence of Time-Dependent Fields](https://arxiv.org/abs/2601.04604)
*Amartya Bose*

Main category: quant-ph

TL;DR: 提出改进的路径积分Lindblad动力学方法，能够处理含时外场和Floquet系统


<details>
  <summary>Details</summary>
Motivation: 原始的PILD方法基于Nakajima-Zwanzig记忆核的时间平移不变性，无法处理含时外场，需要改进以超越这一限制

Method: 提出替代的、更简单的PILD公式，不需要直接计算非马尔可夫记忆核，从而能够应用于含时系统

Result: 新方法能够处理含时外场，并可应用于Floquet系统，突破了原始PILD的时间平移不变性限制

Conclusion: 通过简化公式，成功扩展了PILD方法的应用范围，使其能够处理更广泛的含时量子系统动力学问题

Abstract: The path integral Lindblad dynamics (PILD) method [A. Bose, J. Phys. Chem. Lett. 15(12), 3363-3368 (2024)] had been introduced as a way of incorporating the impact of certain empirical processes like pumps and drains on the dynamics of quantum systems interacting with thermal environments. The method being based on the time-translational invariance of the Nakajima-Zwanzig memory kernel, however, was not able to account for time-dependent external fields. In this communication, we give an alternate, simpler formulation of PILD, that allows us to go beyond this limitation. It does not require the evaluation of the non-Markovian memory kernel directly, and consequently can be applied to Floquet systems as well.

</details>


### [110] [Hardy nonlocality for entangled pairs in a four-particle system](https://arxiv.org/abs/2601.04636)
*Duc Manh Doan,Hung Q. Nguyen*

Main category: quant-ph

TL;DR: 本文研究了四粒子循环纠缠结构中的Hardy型非定域性，发现相比完全纠缠系统，这种结构提供了更多导致与局域隐变量模型矛盾的条件，并通过量子电路模拟和IBM量子硬件实验进行了验证。


<details>
  <summary>Details</summary>
Motivation: Hardy悖论或Hardy型非定域性为研究纠缠态的非定域性提供了一种无需不等式的方法。以往研究主要集中在完全纠缠系统，而其他纠缠构型（如循环纠缠结构）的研究较少。本文旨在探索四粒子循环纠缠结构中的非定域性特性。

Method: 研究四粒子循环纠缠系统，其中每个粒子与两个相邻粒子形成纠缠对，而非相邻粒子不纠缠。设计并实现了与这种循环纠缠结构兼容的量子电路，通过模拟识别相关模式和感兴趣的状态。进一步在IBM Brisbane量子硬件上执行所提出的电路。

Result: 发现循环纠缠结构相比完全纠缠系统提供了更多导致与局域隐变量模型矛盾的条件。这种增强归因于存在多个排除态和相关性，其中粒子的测量结果仅影响其配对伙伴的结果。模拟成功识别了相关模式和目标状态，但在IBM Brisbane硬件上的实验结果与模拟结果存在显著偏差。

Conclusion: 循环纠缠结构在Hardy型非定域性研究中展现出比完全纠缠系统更丰富的特性，提供了更多违反局域隐变量模型的条件。虽然量子硬件实验存在偏差，但该研究为探索不同纠缠构型的非定域性提供了新视角。

Abstract: Nonlocality can be studied through different approaches, such as Bell's inequalities, and it can be found in numerous quantum states, including GHZ states or graph states. Hardy's paradox, or Hardy-type nonlocality, provides a way to investigate nonlocality for entangled states of particles without using inequalities. Previous studies of Hardy's nonlocality have mostly focused on the fully entangled systems, while other entanglement configurations remain less explored. In this work, the system under investigation consists of four particles arranged in a cyclic entanglement configuration, where each particle forms entangled pairs with two neighbors, while non-neighboring particles remain unentangled. We found that this entanglement structure offers a larger set of conditions that lead to the contradiction with the LHV model, compared to the fully entangled systems. This enhancement can be attributed to the presence of multiple excluded states and correlations, in which the measurement result of a particle only influences the result of its paired partners. We implement quantum circuits compatible with the cyclic entanglement structure, and through simulation, the correlation patterns and the states of interest are identified. We further execute the proposed circuits on IBM Brisbane, a practical backend; however, the results show considerable deviations from the simulation counterparts.

</details>


### [111] [SurgeQ: A Hybrid Framework for Ultra-Fast Quantum Processor Design and Crosstalk-Aware Circuit Execution](https://arxiv.org/abs/2601.04645)
*Xinxuan Chen,Hongxiang Zhu,Zhaohui Yang,Zhaofeng Su,Jianxin Chen,Feng Wu,Hui-Hai Zhao*

Main category: quant-ph

TL;DR: SurgeQ是一种硬件软件协同设计策略，通过增强耦合强度的快速双量子比特门和定制调度来平衡门错误和串扰，实现加速电路执行和提高保真度。


<details>
  <summary>Details</summary>
Motivation: 在超导平台上执行量子电路需要在门错误和串扰之间取得平衡，现有方法难以同时优化这两个方面。

Method: SurgeQ采用硬件软件协同设计策略，包含设计阶段和执行阶段：使用耦合增强的快速双量子比特门，并通过定制调度策略缓解增加的串扰；建立系统评估流程确定最佳耦合强度。

Result: 在真实世界基准测试中，SurgeQ通常比最新基线获得更高保真度，能有效对抗指数级保真度衰减，在大规模电路中实现高达百万倍的改进。

Conclusion: SurgeQ通过硬件软件协同设计成功平衡了门速度和串扰的权衡，为量子电路执行提供了有效的加速和保真度提升方案。

Abstract: Executing quantum circuits on superconducting platforms requires balancing the trade-off between gate errors and crosstalk. To address this, we introduce SurgeQ, a hardware-software co-design strategy consisting of a design phase and an execution phase, to achieve accelerated circuit execution and improve overall program fidelity. SurgeQ employs coupling-strengthened, faster two-qubit gates while mitigating their increased crosstalk through a tailored scheduling strategy. With detailed consideration of composite noise models, we establish a systematic evaluation pipeline to identify the optimal coupling strength. Evaluations on a comprehensive suite of real-world benchmarks show that SurgeQ generally achieves higher fidelity than up-to-date baselines, and remains effective in combating exponential fidelity decay, achieving up to a million-fold improvement in large-scale circuits.

</details>


### [112] [Regularization from Superpositions of Time Evolutions](https://arxiv.org/abs/2601.04685)
*Eliahu Cohen,Tomer Shushi*

Main category: quant-ph

TL;DR: 提出一种通过相干控制和后选择叠加演化实现平滑能量滤波器的方法，用于正则化路径积分中的奇异性问题


<details>
  <summary>Details</summary>
Motivation: 短时近似和路径积分在高能或大场贡献下可能被主导，特别是在存在奇异相互作用时，需要可移除的抑制性正则化器

Method: 通过相干控制的后选择演化叠加产生条件映射，实现高斯能量滤波器。在量子力学中，后选择算符为V_{σ,Δt}=e^{-iHΔt}e^{-\frac12σ^2Δt^2H^2}；在标量QFT中，通过局部高斯平滑四次耦合项

Result: 该方法使奇异势下的短时核在时间切片路径积分近似中表现良好，目标幺正动力学可在σ→0或Δt→0时恢复。在标量QFT中，该方法诱导出正定的(σ^2/2)φ^8项，提供对称兼容的大场稳定器

Conclusion: 相干控制和后选择演化叠加提供了一种自然的正则化方法，可作为传统正则化方案的替代，具有对称兼容性和可移除性

Abstract: Short-time approximations and path integrals can be dominated by high-energy or large-field contributions, especially in the presence of singular interactions, motivating regulators that are suppressive yet removable. Standard regulators typically impose such suppressions by hand (e.g. cutoffs, higher-derivative terms, heat-kernel smearing, lattice discretizations), while here we show that closely related smooth filters can arise as the conditional map produced by interference in a coherently controlled, postselected superposition of evolutions. A successful postselection implements a single heralded operator that is a coherent linear combination of time-evolution operators. For a Gaussian superposition of time translations in quantum mechanics, the postselected step is $V_{σ,Δt}=e^{-iHΔt}\,e^{-\frac12σ^2Δt^2H^2}$, i.e.\ the desired unitary step multiplied by a Gaussian energy filter suppressing energies above order $1/(σΔt)$. This renders short-time kernels in time-sliced path-integral approximations well behaved for singular potentials, while the target unitary dynamics is recovered as $σ\to0$ and (for fixed $σ$) also as $Δt\to0$ at fixed $t$. In scalar QFT, a local Gaussian smearing of the quartic coupling induces a positive $(σ^2/2)φ^8$ term in the Euclidean action, providing a symmetry-compatible large-field stabilizer; it is naturally viewed as an irrelevant operator whose effects can be renormalized at fixed $σ$ (together with a conventional UV regulator) and removed by taking $σ\to0$. We give short-time error bounds and analyze multi-step success probabilities.

</details>


### [113] [The Role of Quantum in Hybrid Quantum-Classical Neural Networks: A Realistic Assessment](https://arxiv.org/abs/2601.04732)
*Dominik Freinberger,Philipp Moser*

Main category: quant-ph

TL;DR: 该论文通过严格的统计分析，研究了混合量子-经典神经网络中量子组件的实际贡献，发现在最佳情况下混合模型性能与经典模型相当，但多数情况下量子组件会降低性能。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习被认为是近期量子硬件的有前景应用领域，但混合量子-经典模型中量子组件的具体贡献仍是一个重要开放问题。作者旨在通过统计分析阐明量子处理在混合架构中的实际影响。

Method: 对常见的混合模型进行系统评估，使用医学信号数据以及平面和体积图像数据，考察编码方案、纠缠和电路规模等经典和量子方面的影响。

Result: 在最佳情况下，混合模型表现出与经典模型相当的性能，但在大多数情况下，受量子组件影响，性能指标会恶化。多模态分析提供了量子组件贡献的现实见解。

Conclusion: 研究为混合量子-经典模型中量子组件的实际贡献提供了现实洞察，建议在近期应用中谨慎声明和设计选择。

Abstract: Quantum machine learning has emerged as a promising application domain for near-term quantum hardware, particularly through hybrid quantum-classical models that leverage both classical and quantum processing. Although numerous hybrid architectures have been proposed and demonstrated successfully on benchmark tasks, a significant open question remains regarding the specific contribution of quantum components to the overall performance of these models. In this work, we aim to shed light on the impact of quantum processing within hybrid quantum-classical neural network architectures through a rigorous statistical study. We systematically assess common hybrid models on medical signal data as well as planar and volumetric images, examining the influence attributable to classical and quantum aspects such as encoding schemes, entanglement, and circuit size. We find that in best-case scenarios, hybrid models show performance comparable to their classical counterparts, however, in most cases, performance metrics deteriorate under the influence of quantum components. Our multi-modal analysis provides realistic insights into the contributions of quantum components and advocates for cautious claims and design choices for hybrid models in near-term applications.

</details>


### [114] [A scalable gallium-phosphide-on-diamond spin-photon interface](https://arxiv.org/abs/2601.04733)
*Nicholas S. Yama,Chun-Chi Wu,Fariba Hatami,Kai-Mei C. Fu*

Main category: quant-ph

TL;DR: 首次在可扩展平面平台上实现量子缺陷与混合集成纳米光子器件的高协同性耦合，使用GaP-on-diamond平台，观测到自旋相关传输切换和单次读出量子跳跃。


<details>
  <summary>Details</summary>
Motivation: 量子发射器与光子的高效接口是量子网络的基础。虽然金刚石中的硅空位中心具有优异的光学和自旋相干性，但其悬浮结构和弱非线性限制了长期可扩展性，需要耦合到第二个处理芯片。

Method: 在金刚石衬底上集成600多个磷化镓纳米光子腔体，与近表面硅空位中心耦合。详细研究具有两个强耦合硅空位中心的特定器件，通过多个独立测量确认协同性大于1。使用永磁体施加外部磁场实现自旋跃迁的光学分辨。

Result: 实现了量子缺陷与混合集成纳米光子器件的首次高协同性耦合（C>1）。在4K下测得自旋弛豫时间T₁>0.4 ms。利用高协同性耦合观测到自旋相关传输切换和硅空位自旋的单次读出量子跳跃。

Conclusion: 结合磷化镓的强非线性特性，GaP-on-diamond平台为量子网络应用提供了一个可扩展的平面平台，解决了传统金刚石纳米光子器件的可扩展性限制。

Abstract: The efficient interfacing of quantum emitters and photons is fundamental to quantum networking. Quantum defects embedded in integrated nanophotonic circuits are promising for such applications due to the deterministic light-matter interactions of high-cooperativity ($C>1$) cavity quantum electrodynamics and potential for scalable integration with active photonic processing. Silicon-vacancy (SiV) centers embedded in diamond nanophotonic cavities are a leading approach due to their excellent optical and spin coherence, however their long-term scalability is limited by the diamond itself, as its suspended geometry and weak nonlinearity necessitates coupling to a second processing chip. Here we realize the first high-cooperativity coupling of quantum defects to hybrid-integrated nanophotonics in a scalable, planar platform. We integrate more than 600 gallium phosphide (GaP) nanophotonic cavities on a diamond substrate with near-surface SiV centers. We examine a particular device with two strongly coupled SiV centers in detail, confirming above-unity cooperativity via multiple independent measurements. Application of an external magnetic field via a permanent magnet enables optical resolution of the SiV spin transitions from which we determine a spin-relaxation time $T_1>0.4$ ms at 4 K. We utilize the high cooperativity coupling to observe spin-dependent transmission switching and the quantum jumps of the SiV spin via single-shot readout. These results, coupled with GaP's strong nonlinear properties, establish GaP-on-diamond as a scalable planar platform for quantum network applications.

</details>


### [115] [Bound state solutions with a linear combination of Yuakawa plus four-parameter diatomic potentials using path integral approach: Thermodynamic properties](https://arxiv.org/abs/2601.04806)
*Mohamed Améziane Sadoun,Redouane Zamoum,Abdellah Touati*

Main category: quant-ph

TL;DR: 研究双原子分子势能（Yukawa势和四参数势）的近似解析束缚态，使用路径积分形式推导能谱和波函数


<details>
  <summary>Details</summary>
Motivation: 研究双原子分子系统的束缚态问题，特别是结合Yukawa势和四参数势的复杂势能形式，为分子物理和量子化学提供理论分析工具

Method: 采用路径积分形式体系，通过适当的离心项近似，从格林函数的极点及其留数推导束缚态能谱和归一化波函数

Result: 获得了能量谱、归一化波函数、配分函数及其他热力学性质，能量方程采用紧凑形式表示

Conclusion: 成功建立了双原子分子势能束缚态的近似解析方法，为研究分子系统的量子态和热力学性质提供了有效工具

Abstract: In this paper, we investigate the approximate analytical bound states with a linear combination of two diatomic molecule potentials, Yukawa and four parameters potentials, within the framework of the path integral formalism. With the help of an appropriate approximation to evaluate the centrifugal term, the energy spectrum and the normalized wave functions of the bound states are derived from the poles of Green's function and its residues. The partition function and other thermodynamic properties were obtained using the compact form of the energy equation.

</details>


### [116] [Fast thermal state preparation beyond native interactions](https://arxiv.org/abs/2601.04810)
*Alexander van Lomwel,Paul M. Schindler,Modesto Orozco-Ruiz,Marin Bukov,Nguyen H. Le,Florian Mintert*

Main category: quant-ph

TL;DR: 提出基于纯幺正动力学的量子模拟框架，用于生成包含非原生相互作用哈密顿量的热态，适用于数字和模拟量子设备


<details>
  <summary>Details</summary>
Motivation: 当前量子模拟研究主要关注有效相互作用的实现（基态物理）或原生相互作用下的热态动力学（热物理），但许多开放问题涉及合成相互作用的热态，需要新的模拟方法

Method: 开发基于纯幺正动力学的框架，通过经典计算寻找控制序列，使系统达到目标热态，适用于包含非原生相互作用的哈密顿量，如团簇伊辛模型中的三体相互作用

Result: 该方法能够处理远超状态向量或密度矩阵控制方法能力范围的系统规模，所需实验资源（如总演化时间）与温度和临界性无关

Conclusion: 提出的框架为量子模拟包含非原生相互作用的热态提供了可行方案，适用于当前数字和模拟量子设备，且资源需求不随温度和临界性变化

Abstract: While questions on quantum simulation of ground state physics are mostly focussed on the realization of effective interactions, most work on quantum simulation of thermal physics explores the realization of dynamics towards a thermal mixed state under native interactions. Many open questions that could be answered with quantum simulations, however, involve thermal states with respect to synthetic interactions. We present a framework based solely on unitary dynamics to design quantum simulations for thermal states with respect to Hamiltonians that include non-native interactions, suitable for both present-day digital and analogue devices. By classical means, our method finds the control sequence to reach a target thermal state for system sizes well out of reach of state-vector or density-matrix control methods, even though quantum hardware is required to explicitly simulate the thermal state dynamics. With the illustrative example of the cluster Ising model that includes non-native three-body interactions, we find that required experimental resources, such as the total evolution time, are independent of temperature and criticality.

</details>


### [117] [Quantum Wiener architecture for quantum reservoir computing](https://arxiv.org/abs/2601.04812)
*Alessio Benavoli,Felix Binder*

Main category: quant-ph

TL;DR: 量子Wiener架构（qWiener）在量子线性动态网络和弱连续测量下，保留了经典Wiener系统的渐近记忆特性和普适性，并表现出优于经典和量子储备计算的性能。


<details>
  <summary>Details</summary>
Motivation: 研究量子储备计算，特别是量子Wiener架构，旨在探索量子系统在储备计算中的潜力，并验证其在量子约束下是否仍能保持经典Wiener系统的关键特性。

Method: 采用量子线性动态网络结合弱连续测量和经典非线性静态读出，构建量子Wiener系统。通过严格数学证明验证其渐近记忆特性，发展核理论解释，并实证评估在标准基准上的性能。

Result: 首次严格证明qWiener系统在量子约束下仍保持渐近记忆特性和普适性；核理论分析显示其自然诱导深度核；在标准基准测试中系统性优于先前经典和量子储备计算模型。

Conclusion: 量子Wiener架构成功将经典Wiener系统的理论保证扩展到量子领域，为量子储备计算提供了理论基础，并在实践中展现出优越性能，为量子机器学习开辟了新方向。

Abstract: This work focuses on quantum reservoir computing and, in particular, on quantum Wiener architectures (qWiener), consisting of quantum linear dynamic networks with weak continuous measurements and classical nonlinear static readouts. We provide the first rigorous proof that qWiener systems retain the fading-memory property and universality of classical Wiener architectures, despite quantum constraints on linear dynamics and measurement back-action. Furthermore, we develop a kernel-theoretic interpretation showing that qWiener reservoirs naturally induce deep kernels, providing a principled framework for analysing their expressiveness. We further characterise the simplest qWiener instantiation, consisting of concatenated quantum harmonic oscillators, and show the difference with respect to the classical case. Finally, we empirically evaluate the architecture on standard reservoir computing benchmarks, demonstrating systematic performance gains over prior classical and quantum reservoir computing models.

</details>


### [118] [PACOX: A FPGA-based Pauli Composer Accelerator for Pauli String Computation](https://arxiv.org/abs/2601.04827)
*Tran Xuan Hieu Le,Tuan Hai Vu,Vu Trung Duong Le,Hoai Luan Pham,Yasuhiko Nakashima*

Main category: quant-ph

TL;DR: 本文提出了PACOX，首个基于FPGA的Pauli字符串计算专用加速器，通过二进制编码和并行流水线架构，在19量子比特内实现100倍加速和超低功耗。


<details>
  <summary>Details</summary>
Motivation: Pauli字符串是混合量子-经典算法的核心计算原语，但随着量子比特数增加，经典计算面临指数复杂度挑战，成为性能瓶颈，需要专用硬件加速。

Method: 提出紧凑二进制编码，采用XOR索引置换和相位累积；设计并行流水线处理单元集群架构，在FPGA上高效利用数据级并行性。

Result: 在Xilinx ZCU102 FPGA上，PACOX运行频率250MHz，功耗0.33W，资源占用适中；对于19量子比特Pauli字符串，相比CPU方法实现100倍加速，内存需求更低，功耗延迟积更优。

Conclusion: PACOX为混合量子-经典系统中的Pauli计算工作负载提供了高计算速度和卓越的能效，展示了专用硬件加速器的优势。

Abstract: Pauli strings are a fundamental computational primitive in hybrid quantum-classical algorithms. However, classical computation of Pauli strings suffers from exponential complexity and quickly becomes a performance bottleneck as the number of qubits increases. To address this challenge, this paper proposes the Pauli Composer Accelerator (PACOX), the first dedicated FPGA-based accelerator for Pauli string computation. PACOX employs a compact binary encoding with XOR-based index permutation and phase accumulation. Based on this formulation, we design a parallel and pipelined processing element (PE) cluster architecture that efficiently exploits data-level parallelism on FPGA. Experimental results on a Xilinx ZCU102 FPGA show that PACOX operates at 250 MHz with a dynamic power consumption of 0.33 W, using 8,052 LUTs, 10,934 FFs, and 324 BRAMs. For Pauli strings of up to 19 qubits, PACOX achieves speedups of up to 100 times compared with state-of-the-art CPU-based methods, while requiring significantly less memory and achieving a much lower power-delay product. These results demonstrate that PACOX delivers high computational speed with superior energy efficiency for Pauli-based workloads in hybrid quantum-classical systems.

</details>


### [119] [Noise tailoring for error mitigation and for diagnozing digital quantum computers](https://arxiv.org/abs/2601.04830)
*Thibault Scoquart,Hugo Perrin,Kyrylo Snizhko*

Main category: quant-ph

TL;DR: 论文提出噪声定制(NT)方法，通过统计采样修改双量子比特门的噪声结构，结合误差缓解(EM)可将精度提升5倍，但实际量子计算机中NT受限于非马尔可夫泡利噪声，建议用NT表征硬件误差源。


<details>
  <summary>Details</summary>
Motivation: NISQ量子计算机中噪声严重影响输出精度，现有误差缓解方法对特定噪声类型有效，但实际硬件噪声可能不匹配，需要新策略来优化噪声结构以提高误差缓解效果。

Method: 提出噪声定制(NT)方法，通过统计采样修改双量子比特门的噪声结构，将实际噪声调整为更适合现有误差缓解协议的形式，然后结合误差缓解技术。

Result: 经典仿真显示，对于实际的泡利噪声，NT+EM比单独使用EM精度提升高达5倍；但在IBM量子计算机上，NT受限于各种非马尔可夫泡利噪声的小误差源。

Conclusion: 噪声定制方法能显著提升误差缓解效果，但实际硬件中的非理想噪声限制了其性能；建议将NT方法用于表征量子计算机的误差源，为硬件开发提供信息。

Abstract: Error mitigation (EM) methods are crucial for obtaining reliable results in the realm of noisy intermediate-scale quantum (NISQ) computers, where noise significantly impacts output accuracy. Some EM protocols are particularly efficient for specific types of noise. Yet the noise in the actual hardware may not align with that. In this article, we introduce Noise Tailoring (NT) -- an innovative strategy designed to modify the structure of the noise associated with two-qubit gates through statistical sampling. We perform classical emulation of the protocol behavior and find that the NT+EM results can be up to 5 times more accurate than the results of EM alone for realistic Pauli noise acting on two-qubit gates. At the same time, on actual IBM quantum computers, the NT method falls victim to various small error sources beyond Markovian Pauli noise. We propose to use the NT method for characterizing such error sources on quantum computers in order to inform hardware development.

</details>


### [120] [Unconditionally teleported quantum gates between remote solid-state qubit registers](https://arxiv.org/abs/2601.04848)
*Mariagrazia Iuliano,Nicolas Demetriou,H. Benjamin van Ommen,Constantijn Karels,Tim H. Taminiau,Ronald Hanson*

Main category: quant-ph

TL;DR: 该论文展示了远程金刚石量子比特设备间的无条件CNOT量子门，实现了固态量子网络的关键能力


<details>
  <summary>Details</summary>
Motivation: 量子网络通过光子连接实现分布式模块化量子计算，远程量子门需要远程纠缠、本地量子逻辑和经典通信，但现有系统难以实现无后选择的无条件远程门操作

Method: 使用金刚石基量子比特设备，以碳-13核自旋作为控制和目标量子比特，NV电子自旋实现本地逻辑、读取和远程纠缠生成，采用确定性逻辑、单次读取和实时前馈技术

Result: 实现了远程量子比特间的无条件CNOT门，通过创建GHZ态展示了节点间真正的4方纠缠，实现了无后选择的非局域门操作

Conclusion: 该成果展示了固态量子网络的关键能力，为分布式量子计算和复杂网络协议的测试提供了基础，推动了完全集成系统的探索

Abstract: Quantum networks connecting quantum processing nodes via photonic links enable distributed and modular quantum computation. In this framework, quantum gates between remote qubits can be realized using quantum teleportation protocols. The essential requirements for such non-local gates are remote entanglement, local quantum logic within each processor, and classical communication between nodes to perform operations based on measurement outcomes. Here, we demonstrate an unconditional Controlled-NOT quantum gate between remote diamond-based qubit devices. The control and target qubits are Carbon-13 nuclear spins, while NV electron spins enable local logic, readout, and remote entanglement generation. We benchmark the system by creating a Greenberger-Horne-Zeilinger state, showing genuine 4-partite entanglement shared between nodes. Using deterministic logic, single-shot readout, and real-time feed-forward, we implement non-local gates without post-selection. These results demonstrate a key capability for solid-state quantum networks, enabling exploration of distributed quantum computing and testing of complex network protocols on fully integrated systems.

</details>


### [121] [Distinguishing Coherent and Incoherent Errors in Multi-Round Time-Reversed Dynamics via Scramblons](https://arxiv.org/abs/2601.04856)
*Zeyu Liu,Pengfei Zhang*

Main category: quant-ph

TL;DR: 该论文研究了量子混沌系统中相干误差和非相干误差在时间反演动力学中的不同积累行为，发现非相干误差随轮数线性积累，而相干误差则呈现从二次到线性的交叉行为。


<details>
  <summary>Details</summary>
Motivation: 量子科学和技术快速发展，但误差不可避免且在量子模拟和计算中起关键作用。量子混沌系统中，由哈密顿量控制不完美引起的相干误差和由环境耦合引起的非相干误差都会因信息扰乱而在时间演化中被指数放大。需要理解这两类误差在多体动力学不可逆性中的不同特征。

Method: 通过研究多轮时间反演动力学，应用scramblon理论推导Loschmidt回波的闭式表达式，分析相干和非相干误差的积累行为。使用可解的Sachdev-Ye-Kitaev模型进行验证。

Result: 非相干误差随轮数线性积累，而相干误差则呈现从二次到线性的交叉积累行为。这些预测在SYK模型中得到了明确验证。

Conclusion: 研究结果为表征和校准时间反演动力学中的相干和非相干误差提供了理论基础，对核磁共振系统具有特别相关性。

Abstract: Despite the rapid development of quantum science and technology, errors are inevitable and play a crucial role in quantum simulation and quantum computation. In quantum chaotic systems, coherent errors arising from imperfect Hamiltonian control and incoherent errors induced by coupling to the environment are both exponentially amplified during time evolution due to information scrambling. A fundamental question is how these two classes of errors imprint distinct signatures on the emergent irreversibility of many-body dynamics. In this Letter, we address this question by investigating multi-round time-reversed dynamics in the presence of both coherent and incoherent errors. By applying scramblon theory, we obtain closed-form expressions for the Loschmidt echo over different rounds of time-reversed evolution. For incoherent errors, the error accumulates linearly with the number of rounds, whereas coherent errors exhibit a crossover from quadratic to linear accumulation. These predictions are explicitly verified using the solvable Sachdev-Ye-Kitaev model. Our results provide a theoretical foundation for characterizing and calibrating coherent and incoherent errors in reversed dynamics, with particular relevance to nuclear magnetic resonance systems.

</details>


### [122] [Quantenlogische Systeme und Tensorproduktraeume](https://arxiv.org/abs/2601.04880)
*Tobias Starke*

Main category: quant-ph

TL;DR: 该论文详细分析了Aerts和Daubechies关于使用张量积描述复合量子系统的物理论证，通过格理论和c-态射理论证明了量子力学中复合系统必须用张量积空间描述。


<details>
  <summary>Details</summary>
Motivation: 本文旨在详细讨论Aerts和Daubechies论文中关于使用张量积描述两个量子系统作为联合系统的物理论证，展示经典和量子力学中复合物理系统应如何逻辑描述。

Method: 采用George Mackey的量子逻辑公理系统构造，基于格理论和c-态射理论，分析一类公理化定义的复合物理系统，提供详细证明过程。

Result: 证明了在量子力学情况下，复合物理系统必须通过张量积空间来描述，为量子系统的复合提供了严格的数学基础。

Conclusion: 通过严格的数学证明，确认了张量积在描述量子复合系统中的必要性，为量子逻辑和复合系统理论提供了重要支持。

Abstract: In this work we present an intuitive construction of the quantum logical axiomatic system provided by George Mackey. The goal of this work is a detailed discussion of the results from the paper 'Physical justification for using the tensor product to describe two quantum systems as one joint system' [1] published by Diederik Aerts and Ingrid Daubechies. This means that we want to show how certain composed physical systems from classical and quantum mechanics should be described logically. To reach this goal, we will, like in [1], discuss a special class of axiomatically defined composed physical systems. With the help of certain results from lattice and c-morphism theory (see [2] and [23]), we will present a detailed proof of the statement, that in the quantum mechanical case, a composed physical system must be described via a tensor product space.

</details>


### [123] [Virtual temperatures as a key quantifier for passive states in quantum thermodynamic processes](https://arxiv.org/abs/2601.04905)
*Sachin Sonkar,Ramandeep S. Johal*

Main category: quant-ph

TL;DR: 该论文通过主化理论分析被动量子态中的虚拟温度作用，定义了相邻能级虚拟温度的平均温度，探讨了其在量子热机中的关键作用。


<details>
  <summary>Details</summary>
Motivation: 研究虚拟温度在被动量子态中的作用，建立虚拟温度与热流方向、量子热机性能之间的联系，为量子热力学过程提供新的理论框架。

Method: 使用主化理论分析虚拟温度，定义相邻能级虚拟温度的平均温度，基于最小-最大虚拟温度值分析热流方向，并以耦合自旋系统为例进行具体计算。

Result: 发现虚拟温度在确定系统与环境间热流方向中起关键作用，推导出量子奥托效率的上界可用工作介质的最小-最大虚拟温度表示，建立了量子热力学过程与经典对应之间的有趣类比。

Conclusion: 虚拟温度是连接被动性、主化理论与量子热机最优性能的关键操作量，为量子热力学研究提供了新的分析工具和理论视角。

Abstract: We analyze the role of virtual temperatures for passive quantum states through the lens of majorization theory. A mean temperature over the virtual temperatures of adjacent energy levels is defined to compare the passive states of the system resulting from isoenergetic and isoentropic transformations. The role of the minimum and the maximum (min-max) values of the virtual temperatures in determining the direction of heat flow between the system and the environment is argued based on majorization relations. We characterize the intermediate passive states in a quantum Otto engine using these virtual temperatures and derive an upper bound for the Otto efficiency that can be expressed in terms of the min-max virtual temperatures of the working medium. An explicit example of the coupled-spins system is worked out. Moreover, virtual temperatures serve to draw interesting parallels between the quantum thermodynamic processes and their classical counterparts. Thus, virtual temperature emerges as a key operational quantity linking passivity and majorization to the optimal performance of quantum thermal machines.

</details>


### [124] [High-Rate Free-Running Reference-Frame-Independent Measurement-Device-Independent Quantum Key Distribution with Classified Distillation](https://arxiv.org/abs/2601.04949)
*Xin Liu,Zhicheng Luo,Kaibiao Qin,Jiawang Liu,Zhenrong Zhang,Kejin Wei*

Main category: quant-ph

TL;DR: 提出了一种自由运行的参考系无关测量设备无关量子密钥分发协议，能够在快速参考系变化下保持高密钥率，无需修改实验装置，性能显著优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 现有RFI-MDI-QKD协议通常假设固定或缓慢漂移的参考系失配，但在现实环境中（如移动平台、卫星链路），参考系会快速自由运行变化，这会严重降低传统RFI-MDI-QKD的密钥率和传输距离。

Method: 提出分类蒸馏方法，通过重新分类总检测事件来提取安全密钥，无需修改实验装置。该方法能够处理快速自由运行的参考系变化。

Result: 协议密钥率比之前最佳RFI-MDI-QKD方案提高9倍以上，容忍超过24dB的信道损耗（而先前方法在此条件下失效）。

Conclusion: 该协议使量子密钥分发能够在移动平台上实用化，包括卫星对地链路和空中节点，解决了现实环境中快速参考系变化的问题。

Abstract: Reference-frame-independent measurement-device-independent quantum key distribution (RFI-MDI-QKD) eliminates detector side-channel attacks and avoids reference-frame calibration. While its feasibility has been widely demonstrated, existing implementations typically assume fixed or slowly drifting reference-frame misalignment, conditions rarely satisfied outside the laboratory. In realistic environments, rapid and free-running reference-frame variations can severely degrade both the key rate and transmission distance of conventional RFI-MDI-QKD. Here we propose a free-running RFI-MDI-QKD protocol that maintains high-rate key generation under rapid reference-frame variations. By introducing a classification-distillation method that reclassifies total detection events, secure keys can be extracted without modifying the experimental setup. Our protocol achieves a key rate more than nine times higher than the best previous RFI-MDI-QKD scheme and tolerates channel losses exceeding 24 dB, where earlier approaches fail. These results enable practical quantum key distribution on mobile platforms, including satellite-to-ground links and airborne nodes.

</details>


### [125] [Fast, high-fidelity Transmon readout with intrinsic Purcell protection via nonperturbative cross-Kerr coupling](https://arxiv.org/abs/2601.04975)
*Guillaume Beaulieu,Jun-Zhe Chen,Marco Scigliuzzo,Othmane Benhayoune-Khadraoui,Alex A. Chapple,Peter A. Spring,Alexandre Blais,Pasquale Scarlino*

Main category: quant-ph

TL;DR: 本文提出了一种新型的量子比特读取架构——结读取，通过电容和约瑟夫森结的混合耦合实现强交叉克尔相互作用，避免了传统色散读取的Purcell衰减和测量诱导态跃迁问题，实现了快速高保真度的量子测量。


<details>
  <summary>Details</summary>
Motivation: 传统色散读取存在Purcell衰减和测量诱导态跃迁问题，读取速度和保真度通常落后于单量子比特和双量子比特门操作。需要一种新的读取架构来克服这些限制。

Method: 提出结读取架构，通过电容和约瑟夫森结的混合耦合将transmon量子比特与读取谐振器连接，实现强交叉克尔相互作用。利用这种非线性耦合工程化谐振器的大克尔非线性，实现基于分岔的读取方案。

Result: 实现了99.4%的分配保真度（68纳秒积分时间）和98.4%的量子非破坏性保真度，无需外部Purcell滤波器或近量子极限放大器。

Conclusion: 结读取架构结合基于分岔的读取方案为色散读取提供了可扩展且实用的替代方案，能够实现快速高保真度的量子比特测量，同时减少硬件开销。

Abstract: Dispersive readout of superconducting qubits relies on a transverse capacitive coupling that hybridizes the qubit with the readout resonator, subjecting the qubit to Purcell decay and measurement-induced state transitions (MIST). Despite the widespread use of Purcell filters to suppress qubit decay and near-quantum-limited amplifiers, dispersive readout often lags behind single- and two-qubit gates in both speed and fidelity. Here, we experimentally demonstrate junction readout, a simple readout architecture that realizes a strong qubit-resonator cross-Kerr interaction without relying on a transverse coupling. This interaction is achieved by coupling a transmon qubit to its readout resonator through both a capacitance and a Josephson junction. By varying the qubit frequency, we show that this hybrid coupling provides intrinsic Purcell protection and enhanced resilience to MIST, enabling readout at high photon numbers. While junction readout is compatible with conventional linear measurement, in this work we exploit the nonlinear coupling to intentionally engineer a large Kerr nonlinearity in the resonator, enabling bifurcation-based readout. Using this approach, we achieve a 99.4 % assignment fidelity with a 68 ns integration time and a 98.4 % QND fidelity without an external Purcell filter or a near-quantum-limited amplifier. These results establish the junction readout architecture with bifurcation-based readout as a scalable and practical alternative to dispersive readout, enabling fast, high-fidelity qubit measurement with reduced hardware overhead.

</details>


### [126] [Machine learning-aided direct estimation of coherence and entanglement for unknown states](https://arxiv.org/abs/2601.04976)
*Ting Lin,Zhihua Chen,Kai Wu,Zhihua Guo,Zhihao Ma,Shao-Ming Fei*

Main category: quant-ph

TL;DR: 基于支持向量回归的机器学习方法，仅需密度矩阵对角元及迹信息即可高效估计量子相干性和纠缠度，显著减少资源开销并保持高精度。


<details>
  <summary>Details</summary>
Motivation: 量子相干性和纠缠是量子技术中的基本资源，但在高维系统中，使用最小实验资源对未知态进行高效估计仍然具有挑战性。

Method: 采用支持向量回归(SVR)机器学习方法，仅需密度矩阵对角元、密度矩阵平方和立方的迹来估计量子相干性；对于量子纠缠估计，还需约化密度矩阵平方和立方的迹。这些量可通过随机测量或混合量子-经典框架获得。使用支持向量分位数回归(SVQR)和pinball损失防止SVR高估。

Result: 该方法相比量子态层析显著减少资源开销，同时保持高精度。SVQR模型确保在大多数情况下超过95%的预测是保守下界，即使在输入特征存在2%扰动时，仍能保持超过93%的下界可靠性。

Conclusion: 该技术为计算、通信和计量应用中的量子资源表征提供了实用且可扩展的工具。

Abstract: Quantum coherence and entanglement are fundamental resources in quantum technologies, yet their efficient estimation for unknown states by employing minimal resources in experimental settings remains challenging, particularly in high-dimensional systems. We present a machine learning approach based on support vector regression (SVR) that directly estimates the coherence measures and the geometric measure of quantum entanglement using minimal experimental resources. Our method requires only the diagonal entries of the density matrix, along with the traces of the squared and cubed density matrices for quantum coherence, and additionally along with the traces of the squared and cubed reduced density matrix for estimating quantum entanglement. These quantities can be obtained through random measurements or a hybrid quantum-classical framework. This approach significantly reduces the resource overhead compared to quantum state tomography while maintaining high accuracy. {Furthermore, the support vector quantile regression (SVQR) with pinball loss is employed to prevent SVR overestimation. This model not only ensures that over 95\% of predictions are conservative lower bounds in most cases, but also maintains this lower-bound reliability for over 93\% of predictions, despite 2\% perturbations in the input features.} The proposed technique provides a practical and scalable tool for characterizing quantum resources across computation, communication, and metrology applications.

</details>


### [127] [Signatures of Spin Coherence in Chiral Coupled Quantum Dots](https://arxiv.org/abs/2601.04981)
*Hanna T. Fridman,Rotem Malkinson,Amir Hen,Shira Yochelis,Yossi Paltiel,Nir Bar-gill*

Main category: quant-ph

TL;DR: 该研究首次探索了手性诱导自旋选择性（CISS）效应的量子相干性，通过手性连接的多层量子点组装体，在室温下观察到自旋相关的光致发光寿命调制，揭示了CISS效应的量子相干表现。


<details>
  <summary>Details</summary>
Motivation: 虽然手性诱导自旋选择性（CISS）效应已被广泛研究，但其量子相干性尚未被探索。本研究旨在建立手性量子点组装体作为室温平台，用于探测CISS效应的量子相干表现。

Method: 使用手性连接的多层量子点组装体，在外部磁场存在下采用圆偏振激发，测量光致发光动力学。通过改变磁场大小和几何构型，观察自旋相关的寿命调制效应。

Result: 观察到光致发光寿命的显著调制，依赖于磁场大小和几何构型。左旋和右旋圆偏振激发之间的寿命差异表现出与磁场角度相关的依赖性，与自旋进动现象一致。建立的耦合自旋进动和衰减模型成功复现了实验趋势。

Conclusion: 该研究确立了手性量子点组装体作为室温下探测CISS效应量子相干表现的平台，为自旋电子学和量子技术提供了新的可能性。

Abstract: Chiral-induced spin selectivity (CISS) enables spin selectivity of charge carriers in chiral molecular systems without magnetic materials. While spin selectivity has been widely investigated, its quantum coherence has not yet been explored. Here, we investigate spin-dependent photoluminescence (PL) dynamics in multilayer quantum-dot (QD) assemblies coupled by chiral linkers. Using circularly polarized excitation in the presence of an external magnetic field, we observe a pronounced modulation of the PL lifetime that depends on the magnetic field magnitude and geometry. The lifetime difference between left- and right-circularly polarized excitations exhibits a field-angle dependence, consistent with spin precession driven by the transverse magnetic-field component relative to the chiral axis. A model incorporating coupled spin precession and decay processes reproduces the experimental trends. These results establish chiral QD assemblies as a room-temperature platform for probing quantum coherent manifestations of the CISS effect, with implications for spintronic and quantum technologies.

</details>


### [128] [Quantum Neural Network Training and Inference with Low Resolution Control Electronics](https://arxiv.org/abs/2601.04983)
*Rupayan Bhattacharjee,Sergi Abadal,Carmen G. Almudever,Eduard Alarcon*

Main category: quant-ph

TL;DR: 量子计算机控制电子设备中的低分辨率DAC（6位）在推理阶段几乎不影响QNN性能，但训练阶段需要12位以上分辨率以避免梯度死锁。通过温度控制随机性方法，可在4-10位分辨率下成功训练QNN，性能匹配甚至超过无限精度基线。


<details>
  <summary>Details</summary>
Motivation: 量子计算机扩展需要将低温控制电子设备与量子处理器紧密集成，其中DAC面临严重的功耗和面积限制。需要研究在有限DAC分辨率约束下量子神经网络训练和推理的可行性，以降低控制系统的功耗和面积。

Method: 研究不同DAC分辨率下QNN的训练和推理性能。发现预训练QNN在6位DAC上推理性能接近无限精度基线，但训练时低于12位分辨率会出现梯度死锁。提出温度控制随机性方法，通过概率性参数更新克服梯度死锁问题。

Result: 预训练QNN在6位DAC控制电子设备上部署时，准确率几乎与无限精度基线无法区分，4位以上收益递减。训练时，温度控制随机性方法使QNN能在4-10位分辨率下成功训练，性能匹配甚至超过无限精度基线。

Conclusion: 低分辨率控制电子设备不会损害QML性能，可实现低温控制系统的显著功耗和面积减少，为量子硬件扩展的实际部署提供支持。

Abstract: Scaling quantum computers requires tight integration of cryogenic control electronics with quantum processors, where Digital-to-Analog Converters (DACs) face severe power and area constraints. We investigate quantum neural network (QNN) training and inference under finite DAC resolution constraints across various DAC resolutions. Pre-trained QNNs achieve accuracy nearly indistinguishable from infinite-precision baselines when deployed on quantum systems with 6-bit DAC control electronics, exhibiting an elbow curve with diminishing returns beyond 4 bits. However, training under quantization reveals gradient deadlock below 12-bit resolution as gradient magnitudes fall below quantization step sizes. We introduce temperature-controlled stochasticity that overcomes this through probabilistic parameter updates, enabling successful training at 4-10 bit resolutions that remarkably matches or exceeds infinite-precision baseline performance. Our findings demonstrate that low-resolution control electronics need not compromise QML performance, enabling significant power and area reduction in cryogenic control systems for practical deployment as quantum hardware scales.

</details>


### [129] [Encoding complex-balanced thermalization in quantum circuits](https://arxiv.org/abs/2601.04998)
*Yiting Mao,Peigeng Zhong,Haiqing Lin,Xiaoqun Wang,Shijie Hu*

Main category: quant-ph

TL;DR: 提出一种在量子电路平台上通过马尔可夫过程有效实现复杂平衡热化的协议，利用量子比特本征态的非正交性实现非均匀加热和放大-耗散动力学，为在给定温度下实现非平衡态提供新方法。


<details>
  <summary>Details</summary>
Motivation: 传统热库难以实现某些非平衡态，如时间相关双色发射和有限温度下的Liouvillian异常点保护量子同步。需要开发新的平台来有效实现复杂平衡热化并支持非均匀加热和放大-耗散动力学。

Method: 在量子电路平台上设计协议，将系统与工程化的库量子比特耦合，通过马尔可夫过程实现复杂平衡热化。利用量子比特本征态的非正交性，通过修改的Kubo-Martin-Schwinger关系实现非均匀加热，同时通过违反微观时间可逆性支持放大-耗散动力学。

Result: 成功实现了两种应用：1) 时间相关双色发射；2) 有限温度下Liouvillian异常点保护的量子同步。这两种应用在传统热库中都难以实现。

Conclusion: 该协议为在给定温度下实现非平衡态提供了新方法，通过量子比特本征态的非正交性实现了非均匀加热和放大-耗散动力学，展示了在量子电路平台上实现传统热库难以达到的非平衡现象的能力。

Abstract: We propose a protocol for effectively implementing complex-balanced thermalization via Markovian processes on a quantum-circuit platform that couples the system with engineered reservoir qubits. The non-orthogonality of qubit eigenstates facilitates non-uniform heating through a modified Kubo-Martin-Schwinger relation, while simultaneously supports amplification-dissipation dynamics by violating microscopic time-reversibility. This offers a new approach to realizing out-of-equilibrium states at given temperatures. We show two applications of this platform: temporally-correlated dichromatic emission and Liouvillian exception point protected quantum synchronization at finite temperatures, both of which are challenging to achieve with conventional thermal reservoirs.

</details>


### [130] [Landau Zener Interaction Enhanced Quantum Sensing in Spin Defects of Hexagonal Boron Nitride](https://arxiv.org/abs/2601.05013)
*Mohammad Abdullah Sadi,Tiamike Dudley,Luca Basso,Thomas Poirier,James H. Edgar,Jacob Henshaw,Peter A. Bermel,Yong P. Chen,Andrew Mounce*

Main category: quant-ph

TL;DR: 通过频率调制微波脉冲实现六方氮化硼中硼空位缺陷的量子传感性能提升


<details>
  <summary>Details</summary>
Motivation: 六方氮化硼中的带负电硼空位(VB-)是一种有前景的量子传感平台，可在室温下光学寻址并转移到样品上。然而，由于传统共振激发的光谱覆盖有限，其宽泛的超精细分裂自旋跃迁对量子传感构成挑战。虽然使用10B和15N同位素富集的h10B15N显示出更锐利的光谱特征，但显著的非均匀展宽仍然存在。

Method: 通过FPGA实现频率调制，采用频率扫描微波脉冲。与传统共振微波激发相比，该方法实现了约4倍的|0⟩→|-1⟩自旋态布居转移和对比度提升。通过量子动力学模拟，结合弛豫的有效二态Landau-Zener模型捕捉了布居反转与脉冲长度之间的复杂关系。

Result: 频率扫描微波脉冲实现了约4倍的自旋态布居转移和对比度提升，从而使基于自旋弛豫的量子传感测量时间缩短16倍。该方法在噪声环境中对六方氮化硼中的自旋缺陷进行量子弛豫测量具有鲁棒性和价值。

Conclusion: 频率调制微波脉冲方法显著提升了六方氮化硼中硼空位缺陷的量子传感性能，特别是在噪声环境中具有鲁棒性，为量子弛豫测量提供了有价值的解决方案。

Abstract: Negatively charged boron vacancies (V$_{\text{B}}^{-}$) in hexagonal boron nitride (hBN) comprise a promising quantum sensing platform, optically addressable at room temperature and transferrable onto samples. However, broad hyperfine-split spin transitions of the ensemble pose challenges for quantum sensing with conventional resonant excitation due to limited spectral coverage. While isotopically enriched hBN using $^{10}$B and $^{15}$N isotopes (h$^{10}$B$^{15}$N) exhibits sharper spectral features, significant inhomogeneous broadening persists. We demonstrate that, implemented via frequency modulation on an FPGA, a frequency-ramped microwave pulse achieves around 4-fold greater $|0\rangle\rightarrow|-1\rangle$ spin-state population transfer and thus contrast than resonant microwave excitation and thus 16-fold shorter measurement time for spin relaxation based quantum sensing. Quantum dynamics simulations reveal that an effective two-state Landau-Zener model captures the complex relationship between population inversion and pulse length with relaxations incorporated. Our approach is robust and valuable for quantum relaxometry with spin defects in hBN in noisy environments.

</details>


### [131] [Exponential capacity scaling of classical GANs compared to hybrid latent style-based quantum GANs](https://arxiv.org/abs/2601.05036)
*Milan Liepelt,Julien Baglio*

Main category: quant-ph

TL;DR: 量子生成对抗网络在混合潜变量风格架构中展现指数级容量优势，量子生成器容量与经典判别器/生成器容量呈指数关系，暗示量子生成建模的量子优势。


<details>
  <summary>Details</summary>
Motivation: 量子生成建模是寻找数据分析实际优势的研究热点，量子生成对抗网络是主要候选方案。虽然潜变量风格QGAN在图像生成和药物设计中被证明高效且参数更少，但这种优势从未被系统研究。

Method: 采用混合潜变量风格QGAN架构：首先使用经典变分自编码器将输入数据编码到潜空间，然后使用风格化QGAN进行数据生成。对SAT4图像生成进行综合实验分析，仔细调优自编码器以获得稳定可靠结果。

Result: 当训练稳定且FID分数低且稳定时，经典判别器的最优容量（可训练参数数量）相对于量子生成器容量呈指数级缩放，经典生成器容量也呈现相同规律。量子生成器在混合架构中展现出指数级容量缩放优势。

Conclusion: 这是首次系统证明量子生成对抗网络在混合潜变量风格架构中的容量优势，量子生成器容量与经典组件容量呈指数关系，暗示量子生成建模存在量子优势。

Abstract: Quantum generative modeling is a very active area of research in looking for practical advantage in data analysis. Quantum generative adversarial networks (QGANs) are leading candidates for quantum generative modeling and have been applied to diverse areas, from high-energy physics to image generation. The latent style-based QGAN, relying on a classical variational autoencoder to encode the input data into a latent space and then using a style-based QGAN for data generation has been proven to be efficient for image generation or drug design, hinting at the use of far less trainable parameters than their classical counterpart to achieve comparable performance, however this advantage has never been systematically studied. We present in this work the first comprehensive experimental analysis of this advantage of QGANS applied to SAT4 image generation, obtaining an exponential advantage in capacity scaling for a quantum generator in the hybrid latent style-based QGAN architecture. Careful tuning of the autoencoder is crucial to obtain stable, reliable results. Once this tuning is performed and defining training optimality as when the training is stable and the FID score is low and stable as well, the optimal capacity (or number of trainable parameters) of the classical discriminator scales exponentially with respect to the capacity of the quantum generator, and the same is true for the capacity of the classical generator. This hints toward a type of quantum advantage for quantum generative modeling.

</details>


### [132] [Anomaly to Resource: The Mpemba Effect in Quantum Thermometry](https://arxiv.org/abs/2601.05046)
*Pritam Chattopadhyay,Jonas F. G. Santos,Avijit Misra*

Main category: quant-ph

TL;DR: 量子测温中，非平衡初始态（特别是Mpemba效应）可在有限时间内增强温度估计的量子费舍尔信息，实现超快纳米级传感。


<details>
  <summary>Details</summary>
Motivation: 传统量子测温依赖平衡初始态，灵敏度受限于长时间热化过程，无法在快速、噪声或非平稳环境中提升性能。需要探索非平衡策略来突破这些限制。

Method: 证明Mpemba型反转通常能增强温度估计的量子费舍尔信息，通过分析两能级和Λ能级探针与玻色浴耦合的具体案例，展示非平衡初始化的优势。

Result: 非平衡初始化可在瞬态过程中超越平衡策略和更冷状态，实现"计量学Mpemba效应"，为超快纳米级温度传感提供新途径。

Conclusion: 异常弛豫效应可作为非平衡量子测温的通用设计原则，利用瞬态动力学而非避免它，实现更快速、更灵敏的温度测量。

Abstract: Quantum thermometry provides a key capability for nanoscale devices and quantum technologies, but most existing strategies rely on probes initialized near equilibrium. This equilibrium paradigm imposes intrinsic limitations: sensitivity is tied to long-time thermalization and often cannot be improved in fast, noisy, or nonstationary settings. In contrast, the \textit{Mpemba effect}, the counterintuitive phenomenon where hotter states relax faster than colder ones, has mostly been viewed as a thermodynamic anomaly. Here, we bridge this gap by proving that Mpemba-type inversions generically yield a finite-time enhancement of the quantum Fisher information (QFI) for temperature estimation, thereby converting an anomalous relaxation effect into a concrete metrological resource. Through explicit analyses of two-level and $Λ$-level probes coupled to bosonic baths, we show that nonequilibrium initializations can transiently outperform both equilibrium strategies and colder states, realizing a \emph{metrological Mpemba effect}. Our results establish anomalous relaxation as a general design principle for nonequilibrium quantum thermometry, enabling ultrafast and nanoscale sensing protocols that exploit, rather than avoid, transient dynamics.

</details>


### [133] [Preconditioned Multivariate Quantum Solution Extraction](https://arxiv.org/abs/2601.05077)
*Gumaro Rendon,Stepan Smid*

Main category: quant-ph

TL;DR: 提出一种从量子态振幅中提取平滑正函数的技术，实现海森堡极限缩放，改进先前方法并降低量子复杂度


<details>
  <summary>Details</summary>
Motivation: 量子计算机在求解PDE方面具有多项式加速潜力，但现有算法通常只生成编码解的量子态，而提取解的显式性质会削弱潜在加速效果

Method: 通过采样给定函数的累积分布，用切比雪夫多项式拟合，然后提取整个编码函数的表示，使用预处理消除对函数最小值的依赖

Result: 该方法实现了海森堡极限缩放，支持更高维函数，显著减少编码函数所需量子比特的量子复杂度，并通过小规模数值模拟验证

Conclusion: 提出的技术能够高效从量子态振幅中提取平滑正函数，为量子PDE求解的实际应用提供了更有效的解决方案

Abstract: Numerically solving partial differential equations is a ubiquitous computational task with broad applications in many fields of science. Quantum computers can potentially provide high-degree polynomial speed-ups for solving PDEs, however many algorithms simply end with preparing the quantum state encoding the solution in its amplitudes. Trying to access explicit properties of the solution naively with quantum amplitude estimation can subsequently diminish the potential speed-up. In this work, we present a technique for extracting a smooth positive function encoded in the amplitudes of a quantum state, which achieves the Heisenberg limit scaling. We improve upon previous methods by allowing higher dimensional functions, by significantly reducing the quantum complexity with respect to the number of qubits encoding the function, and by removing the dependency on the minimum of the function using preconditioning. Our technique works by sampling the cumulative distribution of the given function, fitting it with Chebyshev polynomials, and subsequently extracting a representation of the whole encoded function. Finally, we trial our method by carrying out small scale numerical simulations.

</details>


### [134] [Unitary fault-tolerant encoding of Pauli states in surface codes](https://arxiv.org/abs/2601.05113)
*Luis Colmenarez,Remmy Zen,Jan Olle,Florian Marquardt,Markus Müller*

Main category: quant-ph

TL;DR: 提出一种用于表面码的保距、可扩展、幺正的泡利本征态编码方案，相比传统测量方案可降低逻辑错误率一个数量级


<details>
  <summary>Details</summary>
Motivation: 容错量子计算中逻辑态制备是关键子程序，但即使是简单态的制备也存在挑战。现有幺正方法在增加码距时保护距离保持不变，无法充分利用码的保护能力

Method: 基于强化学习发现的表面-17码策略，推广到任意码距和旋转/非旋转表面码。使用几何局域门，仅需二维平面连接，电路深度为O(d)。设计了有无辅助比特连接的显式稳定子扩展电路

Result: 数值模拟显示，在去极化噪声下，无辅助比特的幺正编码优于标准稳定子测量方案，逻辑错误率降低最多一个数量级。特别适合测量成本高、空闲噪声弱的平台

Conclusion: 该工作弥合了表面码态测量编码与幺正编码之间的差距，为容错量子计算中的保距态制备开辟了新方向

Abstract: In fault-tolerant quantum computation, the preparation of logical states is a ubiquitous subroutine, yet significant challenges persist even for the simplest states required. In the present work, we present a unitary, scalable, distance-preserving encoding scheme for preparing Pauli eigenstates in surface codes. Unlike previous unitary approaches whose fault-distance remains constant with increasing code distance, our scheme ensures that the protection offered by the code is preserved during state preparation. Building on strategies discovered by reinforcement learning for the surface-17 code, we generalize the construction to arbitrary code distances and both rotated and unrotated surface codes. The proposed encoding relies only on geometrically local gates, and is therefore fully compatible with planar 2D qubit connectivity, and it achieves circuit depth scaling as $\mathcal{O}(d)$, consistent with fundamental entanglement-generation bounds. We design explicit stabilizer-expanding circuits with and without ancilla-mediated connectivity and analyze their error-propagation behavior. Numerical simulations under depolarizing noise show that our unitary encoding without ancillas outperforms standard stabilizer-measurement-based schemes, reducing logical error rates by up to an order of magnitude. These results make the scheme particularly relevant for platforms such as trapped ions and neutral atoms, where measurements are costly relative to gates and idling noise is considerably weaker than gate noise. Our work bridges the gap between measurement-based and unitary encodings of surface-code states and opens new directions for distance-preserving state preparation in fault-tolerant quantum computation.

</details>


### [135] [Scalable Generation of Macroscopic Fock States Exceeding 10,000 Photons](https://arxiv.org/abs/2601.05118)
*Ming Li,Weizhou Cai,Ziyue Hua,Yifang Xu,Yilong Zhou,Zi-Jie Chen,Xu-Bo Zou,Guang-Can Guo,Luyan Sun,Chang-Ling Zou*

Main category: quant-ph

TL;DR: 提出一种基于Kerr工程多透镜协议的新方法，在单玻色模式中确定性生成超过10,000个光子的Fock态，突破了现有技术仅能产生几十个激发的限制。


<details>
  <summary>Details</summary>
Motivation: 玻色量子态的可扩展制备面临基本挑战，现有理论实验仅能实现每模式几十个激发，受限于控制复杂性和光子损耗率。

Method: 基于Fock态空间量子态演化与波导阵列中光学波函数传播的对偶性，引入Kerr工程多透镜协议，通过优化透镜组间的相位和位移操作来补偿非傍轴像差。

Result: 数值模拟显示可生成高达N=100,000个光子的Fock态，保真度超过73%；执行时间随目标光子数N按N^{-1/2}缩放，对光子损耗具有鲁棒性。

Conclusion: 该框架为探索巨Fock态的量子-经典转变、实现具有显著量子增益的先进量子计量学以及高维希尔伯特空间中的纠错量子信息处理开辟了新途径。

Abstract: The scalable preparation of bosonic quantum states with macroscopic excitations poses a fundamental challenge in quantum technologies, limited by control complexity and photon-loss rates that severely constrain prior theoretical and experimental efforts to merely dozens of excitations per mode. Here, based on the duality of the quantum state evolution in Fock state space and the optical wave-function propagation in a waveguide array, we introduce a Kerr-engineered multi-lens protocol in a single bosonic mode to deterministically generate Fock states exceeding $10,000$ photons. By optimizing phase and displacement operations across lens groups, our approach compensates for non-paraxial aberrations, achieving fidelities above $73\%$ in numerical simulations for photon numbers up to $N=100,000$. Counterintuitively, the protocol's execution time scales as $N^{-1/2}$ with the target photon number $N$, exhibiting robustness against the photon loss. Our framework enables exploration of quantum-to-classical transitions of giant Fock states, paving the way for advanced quantum metrology with significant quantum gains, and error-corrected quantum information processing in high-dimensional Hilbert spaces.

</details>


### [136] [Simulation of noisy quantum circuits using frame representations](https://arxiv.org/abs/2601.05131)
*Janek Denzler,Jose Carrasco,Jens Eisert,Tommaso Guaita*

Main category: quant-ph

TL;DR: 提出基于框架理论的量子电路经典模拟统一框架，涵盖现有模拟策略，通过准概率分布的一范数衡量计算成本，并发现基于广义泡利框架的新方法。


<details>
  <summary>Details</summary>
Motivation: 研究量子计算理论的核心问题：确定噪声量子电路的经典模拟在何种程度上可能，以及量子优势何时显现。需要统一现有模拟方法并提供系统化的分析框架。

Method: 引入基于框架理论的统一框架，将模拟算法的计算成本与准概率分布的一范数关联。利用凸优化工具探索不同框架选择，包括稳定子态模拟、泡利反向传播等现有方法，并发现基于广义泡利框架的新方法。

Result: 建立了量子电路经典模拟的统一理论框架，为现有方法提供了新见解和改进边界，并发现了基于广义泡利框架的性能更优的新模拟方法。

Conclusion: 框架理论视角超越了传统的量子资源分类，为经典模拟技术提供了直接益处，展示了统一框架在理解和改进量子电路模拟方面的价值。

Abstract: One of the core research questions in the theory of quantum computing is to find out to what precise extent the classical simulation of a noisy quantum circuits is possible and where potential quantum advantages can set in. In this work, we introduce a unified framework for the classical simulation of quantum circuits based on frame theory, encompassing and generalizing a broad class of existing simulation strategies. Within this framework, the computational cost of a simulation algorithm is determined by the one-norm of an associated quasi-probability distribution, providing a common quantitative measure across different simulation approaches. This enables a comprehensive perspective on common methods for the simulation of noisy circuits based on different quantum resources, such as entanglement or non-stabilizerness. It further provides a clear scheme for generating novel classical simulation algorithms. Indeed, by exploring different choices of frames within this formalism and resorting to tools of convex optimization, we are able not only to obtain new insights and improved bounds for existing methods -- such as stabilizer state simulation or Pauli back-propagation -- but also to discover a new approach with an improved performance based on a generalization of the Pauli frame. We, thereby, show that classical simulation techniques can directly benefit from a perspective -- that of frames -- that goes beyond the traditional classification of quantum resources.

</details>


### [137] [Composable simultaneous purification: when all communication scenarios reduce to spatial correlations](https://arxiv.org/abs/2601.05158)
*Matilde Baroni,Dominik Leichtle,Ivan Šupić,Damian Markham,Marco Túlio Quintino*

Main category: quant-ph

TL;DR: 该论文将非定域性分析从无通信的Bell场景扩展到允许通信的多方通信场景，证明了非信号量子操作的任意组合都无法超越标准空间量子Bell关联集。


<details>
  <summary>Details</summary>
Motivation: 研究在允许通信的情况下，如何区分经典、量子及后量子资源。传统Bell非定域性框架依赖于无通信玩家，但许多量子理论的独特特征本质上是多方的，不能简化为两方行为。因此需要将同时纯化方法扩展到所有多方通信方案。

Method: 首先将同时纯化结果从状态扩展到仪器和超仪器（可组合结构），然后证明非信号量子操作的任意组合都无法超越标准空间量子Bell关联集。使用非信号量子操作组合的方法来分析复杂通信场景。

Result: 建立了非信号量子操作任意组合的界限：任何超出标准空间量子Bell关联集的交互式量子实现都必须涉及至少一个信号量子操作集合，即使最终产生的关联是非信号的。

Conclusion: 该工作将Bell非定域性框架扩展到允许通信的场景，为区分量子与后量子资源提供了新工具，并揭示了即使在允许通信的情况下，非信号量子操作的内在限制。

Abstract: Bell non-locality is a powerful framework to distinguish classical, quantum and post-quantum resources, which relies on non-communicating players. Under which restriction can we have the same separations, if we allow for communication? Non-signalling state assemblages, and the fact that they can always be simultaneously purified, turned out to be the key element to restrict the simplest bipartite communication scenario, the prepare-and-measure, to the standard bipartite Bell scenario. Yet, many distinctive features of quantum theory are genuinely multipartite and cannot be reduced to two-party behaviour. In this work we are interested in extending this simultaneous purification inspired result to all multipartite communication schemes. As a first step, we unify and extend the simultaneous purification result from states to instruments and super-instruments, which are composable structures, and open up the possibility to explore more complex communication scenarios. Our main contribution is to establish that arbitrary compositions of non-signalling assemblages cannot escape the standard spatial quantum Bell correlations set. As a consequence, any interactive quantum realization of correlations outside of this set must involve at least one signalling assemblage of quantum operations, even when the resulting correlations are non-signalling.

</details>


### [138] [Fast convergence of Majorana Propagation for weakly interacting fermions](https://arxiv.org/abs/2601.05226)
*Giorgio Facelli,Hamza Fawzi,Omar Fawzi*

Main category: quant-ph

TL;DR: 该论文证明了Majorana Propagation算法在存在低阶近似时能高效模拟哈密顿演化，并给出了稀疏四次哈密顿量的可模拟时间范围。


<details>
  <summary>Details</summary>
Motivation: 哈密顿演化时间动力学模拟是量子优势的重要候选，但通常没有高效经典算法。本文旨在为Majorana Propagation算法提供首个理论保证，并确定其有效应用范围。

Method: 提出Majorana Propagation算法，结合Trotter分解和截断技术，当存在低阶近似时能高效找到时间演化可观测量。

Result: 证明了Majorana Propagation能高效模拟稀疏四次哈密顿量的时间动力学，运行时间为N^{O(log(t/ε))}，在弱相互作用极限下可模拟任意长时间。

Conclusion: 该工作为Majorana Propagation算法提供了首个理论保证，建立了哈密顿演化模拟的经典高效算法框架，特别在弱相互作用体系中具有重要应用价值。

Abstract: Simulating the time dynamics of an observable under Hamiltonian evolution is one of the most promising candidates for quantum advantage as we do not expect efficient classical algorithms for this problem except in restricted settings. Here, we introduce such a setting by showing that Majorana Propagation, a simple algorithm combining Trotter steps and truncations, efficiently finds a low-degree approximation of the time-evolved observable as soon as such an approximation exists. This provides the first provable guarantee about Majorana Propagation for Hamiltonian evolution. As an application of this result, we prove that Majorana Propagation can efficiently simulate the time dynamics of any sparse quartic Hamiltonian up to time $t_{\text{max}}(u)$ depending on the interaction strength $u$. For a time horizon $t \leq t_{\text{max}}(u)$, the runtime of the algorithm is $N^{O(\log(t/\varepsilon))}$ where $N$ is the number of Majorana modes and $\varepsilon$ is the error measured in the normalized Frobenius norm. Importantly, in the limit of small $u$, $t_{\text{max}}(u)$ goes to $+\infty$, formalizing the intuition that the algorithm is accurate at all times when the Hamiltonian is quadratic.

</details>


### [139] [Scalable Suppression of XY Crosstalk by Pulse-Level Control in Superconducting Quantum Processors](https://arxiv.org/abs/2601.05231)
*Hui-Hang Chen,Chiao-Hsuan Wang*

Main category: quant-ph

TL;DR: 提出基于频率调制和动态解耦的可扩展脉冲控制框架，用于抑制超导量子处理器中的XY串扰误差


<details>
  <summary>Details</summary>
Motivation: 随着超导量子处理器规模扩大，密集集成架构中邻近量子比特之间的XY相互作用导致串扰误差，限制了操作性能。硬件层面的频率失谐设计在大规模系统中受到频率拥挤限制，难以实现充分频率分离。

Method: 提出可扩展的脉冲级控制框架，结合频率调制和动态解耦技术来抑制XY串扰误差。该框架独立于耦合强度，减少校准开销，支持多量子比特连接。

Result: 数值模拟显示，在两量子比特系统中，空闲和单量子比特门的保真度误差降低了数个数量级。在五量子比特布局中验证了可扩展性，同时抑制了中心量子比特与四个邻居之间的串扰。

Conclusion: 该串扰抑制框架为密集超导架构中的高保真度操作提供了实用途径，有助于实现大规模量子处理器的可扩展控制。

Abstract: As superconducting quantum processors continue to scale, high-performance quantum control becomes increasingly critical. In densely integrated architectures, unwanted interactions between nearby qubits give rise to crosstalk errors that limit operational performance. In particular, direct exchange-type (XY) interactions are typically minimized by designing large frequency detunings between neighboring qubits at the hardware level. However, frequency crowding in large-scale systems ultimately restricts the achievable frequency separation. While such XY coupling facilitates entangling gate operations, its residual presence poses a key challenge during single-qubit controls. Here, we propose a scalable pulse-level control framework, incorporating frequency modulation (FM) and dynamical decoupling (DD), to suppress XY crosstalk errors. This framework operates independently of coupling strengths, reducing calibration overhead and naturally supporting multi-qubit connectivity. Numerical simulations show orders-of-magnitude reductions in infidelity for both idle and single-qubit gates in a two-qubit system. We further validate scalability in a five-qubit layout, where crosstalk between a central qubit and four neighbors is simultaneously suppressed. Our crosstalk suppression framework provides a practical route toward high-fidelity operation in dense superconducting architectures.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [140] [A joint voxel flow - phase field framework for ultra-long microstructure evolution prediction with physical regularization](https://arxiv.org/abs/2601.04898)
*Ao Zhou,Salma Zahran,Chi Chen,Zhengyang Zhang,Yanming Wang*

Main category: physics.comp-ph

TL;DR: 提出结合体素流网络与相场模拟的联合框架，用于微结构演化的超长时间尺度预测，解决了现有方法灵活性差、泛化能力弱和预测时间短的问题。


<details>
  <summary>Details</summary>
Motivation: 相场模拟计算成本高，现有机器学习方法（如PINNs、convLSTM）在预测微结构演化时存在灵活性差、泛化能力弱和预测时间短的问题，需要开发更有效的预测框架。

Method: 提出交替耦合体素流网络与相场模拟的联合框架：VFN通过学习过去快照的像素流迭代预测未来演化并保持周期性边界；周期性相场模拟抑制非物理伪影、减少累积误差并延长可靠预测时间。

Result: VFN比GPU上的相场模拟快约1000倍；在晶粒生长和旋节分解验证中，仅用2帧输入预测18帧时MSE保持6.76%、SSIM保持0.911；超长预测（2帧输入预测82帧）中晶粒数从600减少到29，平均晶粒面积的NMSE保持1.64%。

Conclusion: 该联合框架实现了基于图像数据的快速、泛化、灵活且物理一致的微结构超长时间尺度预测，显著提升了预测性能和可靠性。

Abstract: Phase-field (PF) modeling is a powerful tool for simulating microstructure evolution. To overcome the high computational cost of PF in solving complex PDEs, machine learning methods such as PINNs, convLSTM have been used to predict PF evolution. However, current methods still face shortages of low flexibility, poor generalization and short predicting time length. In this work, we present a joint framework coupling voxel-flow network (VFN) with PF simulations in an alternating manner for long-horizon temporal prediction of microstructure evolution. The VFN iteratively predicts future evolution by learning the flow of pixels from past snapshots, with periodic boundaries preserved in the process. Periodical PF simulations suppresses nonphysical artifacts, reduces accumulated error, and extends reliable prediction time length. The VFN is about 1,000 times faster than PF simulation on GPU. In validation using grain growth and spinodal decomposition, MSE and SSIM remain 6.76% and 0.911 when predicted 18 frames from only 2 input frames, outperforming similar predicting methods. For an ultra-long grain growth prediction for 82 frames from 2 input frames, grain number decreases from 600 to 29 with NMSE of average grain area remaining 1.64%. This joint framework enables rapid, generalized, flexible and physically consistent microstructure forecasting from image-based data for ultra-long time scales.

</details>
