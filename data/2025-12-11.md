<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 71]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [gr-qc](#gr-qc) [Total: 11]
- [quant-ph](#quant-ph) [Total: 45]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Optimizing Algorithms for Mobile Health Interventions with Active Querying Optimization](https://arxiv.org/abs/2512.08950)
*Aseel Rawashdeh*

Main category: cs.LG

TL;DR: 提出了ATM（Act-Then-Measure）的贝叶斯扩展，用卡尔曼滤波式贝叶斯更新替代标准Q学习，在移动健康干预中实现更稳定、样本效率更高的强化学习。


<details>
  <summary>Details</summary>
Motivation: 移动健康干预中的强化学习需要在干预效果和用户负担之间取得平衡，特别是在状态测量（如用户调查或反馈）成本高昂但又必不可少的情况下。标准的ATM算法使用时间差分启发的Q学习方法，在稀疏和嘈杂环境中容易不稳定。

Method: 提出了ATM的贝叶斯扩展，用卡尔曼滤波式贝叶斯更新替代标准Q学习，保持Q值的不确定性感知估计。该方法在ACNO-MDP框架内运行，将控制动作和测量动作解耦。

Result: 在小规模表格环境中，贝叶斯ATM实现了相当或改进的标量化回报，方差显著降低，策略行为更稳定。但在更大、更复杂的移动健康设置中，标准和贝叶斯ATM变体都表现不佳。

Conclusion: 不确定性感知方法在低数据设置中具有价值，但需要新的强化学习算法来显式建模因果结构、连续状态和观测成本约束下的延迟反馈，以应对现实世界移动健康领域的结构挑战。

Abstract: Reinforcement learning in mobile health (mHealth) interventions requires balancing intervention efficacy with user burden, particularly when state measurements (for example, user surveys or feedback) are costly yet essential. The Act-Then-Measure (ATM) heuristic addresses this challenge by decoupling control and measurement actions within the Action-Contingent Noiselessly Observable Markov Decision Process (ACNO-MDP) framework. However, the standard ATM algorithm relies on a temporal-difference-inspired Q-learning method, which is prone to instability in sparse and noisy environments. In this work, we propose a Bayesian extension to ATM that replaces standard Q-learning with a Kalman filter-style Bayesian update, maintaining uncertainty-aware estimates of Q-values and enabling more stable and sample-efficient learning. We evaluate our method in both toy environments and clinically motivated testbeds. In small, tabular environments, Bayesian ATM achieves comparable or improved scalarized returns with substantially lower variance and more stable policy behavior. In contrast, in larger and more complex mHealth settings, both the standard and Bayesian ATM variants perform poorly, suggesting a mismatch between ATM's modeling assumptions and the structural challenges of real-world mHealth domains. These findings highlight the value of uncertainty-aware methods in low-data settings while underscoring the need for new RL algorithms that explicitly model causal structure, continuous states, and delayed feedback under observation cost constraints.

</details>


### [2] [Learning When to Ask: Simulation-Trained Humanoids for Mental-Health Diagnosis](https://arxiv.org/abs/2512.08952)
*Filippo Cenacchi,Deborah Richards,Longbing Cao*

Main category: cs.LG

TL;DR: 开发了一个用于训练人形机器人对话技能的虚拟仿真系统，将真实访谈数据转化为276个虚拟患者，通过强化学习训练对话控制器，TD3算法在对话完整性和社交时机方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 在真实人形机器人上进行用户测试存在速度慢、设备磨损、迭代受限等问题，但抑郁症和PTSD筛查需要机器人掌握复杂的对话技能，包括时机把握、韵律、反馈信号以及面部和语音注意力分配。

Method: 创建了以智能体为中心的仿真优先流程：将访谈数据转化为276个Unreal Engine MetaHuman虚拟患者，包含同步语音、注视/面部表情和头躯干姿态。采用感知-融合-策略循环决策何时说话、何时反馈、如何避免打断，并配备安全防护。训练使用反事实回放（有界非语言扰动）和不确定性感知的轮次管理器。

Result: 在三种控制器比较中，自定义TD3算法优于PPO和CEM，实现了接近完美的对话覆盖率，在相似奖励下保持更稳定的节奏。决策质量分析显示可忽略的轮次重叠、对齐的打断时机、更少的澄清提示和更短的等待时间。性能在模态丢失和渲染器更换下保持稳定。

Conclusion: 提出了一个完整的虚拟训练系统，能够有效训练人形机器人的对话技能，特别在社交时机和融洽关系建立方面表现优异，为临床监督下的人形机器人试点奠定了基础。

Abstract: Testing humanoid robots with users is slow, causes wear, and limits iteration and diversity. Yet screening agents must master conversational timing, prosody, backchannels, and what to attend to in faces and speech for Depression and PTSD. Most simulators omit policy learning with nonverbal dynamics; many controllers chase task accuracy while underweighting trust, pacing, and rapport. We virtualise the humanoid as a conversational agent to train without hardware burden. Our agent-centred, simulation-first pipeline turns interview data into 276 Unreal Engine MetaHuman patients with synchronised speech, gaze/face, and head-torso poses, plus PHQ-8 and PCL-C flows. A perception-fusion-policy loop decides what and when to speak, when to backchannel, and how to avoid interruptions, under a safety shield. Training uses counterfactual replay (bounded nonverbal perturbations) and an uncertainty-aware turn manager that probes to reduce diagnostic ambiguity. Results are simulation-only; the humanoid is the transfer target. In comparing three controllers, a custom TD3 (Twin Delayed DDPG) outperformed PPO and CEM, achieving near-ceiling coverage with steadier pace at comparable rewards. Decision-quality analyses show negligible turn overlap, aligned cut timing, fewer clarification prompts, and shorter waits. Performance stays stable under modality dropout and a renderer swap, and rankings hold on a held-out patient split. Contributions: (1) an agent-centred simulator that turns interviews into 276 interactive patients with bounded nonverbal counterfactuals; (2) a safe learning loop that treats timing and rapport as first-class control variables; (3) a comparative study (TD3 vs PPO/CEM) with clear gains in completeness and social timing; and (4) ablations and robustness analyses explaining the gains and enabling clinician-supervised humanoid pilots.

</details>


### [3] [An Electrocardiogram Multi-task Benchmark with Comprehensive Evaluations and Insightful Findings](https://arxiv.org/abs/2512.08954)
*Yuhao Xu,Jiaying Lu,Sirui Ding,Defu Cao,Xiao Hu,Carl Yang*

Main category: cs.LG

TL;DR: 该研究评估了基础模型在ECG分析中的有效性，发现通用时间序列/ECG基础模型能达到80%的顶级性能，证明了它们在心电图分析中的实用性。


<details>
  <summary>Details</summary>
Motivation: 心电图分析需要领域专业知识，这限制了人工智能在医疗保健中的应用。虽然自监督学习和基础模型使AI系统能够获取领域知识而不完全依赖人类专家，但缺乏对基础模型在ECG分析性能的全面评估。

Method: 评估语言/通用时间序列/ECG基础模型，并与时间序列深度学习模型进行比较。使用公开可用的ECG数据集进行综合实验。

Result: 实验结果显示，通用时间序列/ECG基础模型达到了80%的顶级性能率，表明它们在ECG分析中是有效的。研究还提供了深入分析和见解。

Conclusion: 该研究强调了基础模型在推进生理波形分析方面的局限性和潜力，为ECG分析的基础模型应用提供了基准和指导。

Abstract: In the process of patient diagnosis, non-invasive measurements are widely used due to their low risks and quick results. Electrocardiogram (ECG), as a non-invasive method to collect heart activities, is used to diagnose cardiac conditions. Analyzing the ECG typically requires domain expertise, which is a roadblock to applying artificial intelligence (AI) for healthcare. Through advances in self-supervised learning and foundation models, AI systems can now acquire and leverage domain knowledge without relying solely on human expertise. However, there is a lack of comprehensive analyses over the foundation models' performance on ECG. This study aims to answer the research question: "Are Foundation Models Useful for ECG Analysis?" To address it, we evaluate language/general time-series/ECG foundation models in comparison with time-series deep learning models. The experimental results show that general time-series/ECG foundation models achieve a top performance rate of 80%, indicating their effectiveness in ECG analysis. In-depth analyses and insights are provided along with comprehensive experimental results. This study highlights the limitations and potential of foundation models in advancing physiological waveform analysis. The data and code for this benchmark are publicly available at https://github.com/yuhaoxu99/ECGMultitasks-Benchmark.

</details>


### [4] [LLM4XCE: Large Language Models for Extremely Large-Scale Massive MIMO Channel Estimation](https://arxiv.org/abs/2512.08955)
*Renbin Li,Shuangshuang Li,Peihao Dong*

Main category: cs.LG

TL;DR: 提出LLM4XCE框架，利用大语言模型的语义建模能力进行XL-MIMO信道估计，在混合场条件下显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: XL-MIMO是6G网络的关键技术，但混合场信道中的近场和远场共存效应给准确估计带来挑战，传统方法泛化能力不足。大语言模型在语义通信中表现出色，可应用于信道估计任务。

Method: 提出LLM4XCE框架，包含精心设计的嵌入模块和并行特征-空间注意力机制，深度融合导频特征和空间结构，构建语义丰富的LLM输入表示。仅微调顶部两层Transformer层，高效捕获导频数据中的潜在依赖关系。

Result: 大量仿真表明，LLM4XCE在混合场条件下显著优于现有最先进方法，实现了优越的估计精度和泛化性能。

Conclusion: LLM4XCE成功将大语言模型的语义建模能力应用于XL-MIMO信道估计，为解决混合场信道估计挑战提供了有效方案，展示了语义通信在无线通信任务中的潜力。

Abstract: Extremely large-scale massive multiple-input multiple-output (XL-MIMO) is a key enabler for sixth-generation (6G) networks, offering massive spatial degrees of freedom. Despite these advantages, the coexistence of near-field and far-field effects in hybrid-field channels presents significant challenges for accurate estimation, where traditional methods often struggle to generalize effectively. In recent years, large language models (LLMs) have achieved impressive performance on downstream tasks via fine-tuning, aligning with the semantic communication shift toward task-oriented understanding over bit-level accuracy.
  Motivated by this, we propose Large Language Models for XL-MIMO Channel Estimation (LLM4XCE), a novel channel estimation framework that leverages the semantic modeling capabilities of large language models to recover essential spatial-channel representations for downstream tasks. The model integrates a carefully designed embedding module with Parallel Feature-Spatial Attention, enabling deep fusion of pilot features and spatial structures to construct a semantically rich representation for LLM input. By fine-tuning only the top two Transformer layers, our method effectively captures latent dependencies in the pilot data while ensuring high training efficiency. Extensive simulations demonstrate that LLM4XCE significantly outperforms existing state-of-the-art methods under hybrid-field conditions, achieving superior estimation accuracy and generalization performance.

</details>


### [5] [DW-KNN: A Transparent Local Classifier Integrating Distance Consistency and Neighbor Reliability](https://arxiv.org/abs/2512.08956)
*Kumarjit Pathak,Karthik K,Sachin Madan,Jitin Kapila*

Main category: cs.LG

TL;DR: DW-KNN是一种改进的KNN分类器，通过结合指数距离和邻居有效性双重加权，提高预测可靠性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统KNN及其变体假设所有k个邻居同样可靠，但在异构特征空间中这一假设限制了预测的可靠性。

Method: 提出DW-KNN（双重加权KNN），整合指数距离和邻居有效性，实现实例级可解释性，抑制噪声或错误标记样本，降低超参数敏感性。

Result: 在9个数据集上平均准确率达到0.8988，在6种方法中排名第2，与最佳集成KNN相差仅0.2%，交叉验证方差最低（0.0156），统计显著优于紧凑性加权KNN（+4.09%）和核加权KNN（+1.13%）。

Conclusion: DW-KNN为复杂自适应方案提供了简单有效的替代方案，特别适用于需要可解释预测的高风险应用场景。

Abstract: K-Nearest Neighbors (KNN) is one of the most used ML classifiers. However, if we observe closely, standard distance-weighted KNN and relative variants assume all 'k' neighbors are equally reliable. In heterogeneous feature space, this becomes a limitation that hinders reliability in predicting true levels of the observation.
  We propose DW-KNN (Double Weighted KNN), a transparent and robust variant that integrates exponential distance with neighbor validity. This enables instance-level interpretability, suppresses noisy or mislabeled samples, and reduces hyperparameter sensitivity.
  Comprehensive evaluation on 9 data-sets helps to demonstrate that DW-KNN achieves 0.8988 accuracy on average. It ranks 2nd among six methods and within 0.2% of the best-performing Ensemble KNN. It also exhibits the lowest cross-validation variance (0.0156), indicating reliable prediction stability. Statistical significance test confirmed ($p < 0.001$) improvement over compactness weighted KNN (+4.09\%) and Kernel weighted KNN (+1.13\%). The method provides a simple yet effective alternative to complex adaptive schemes, particularly valuable for high-stakes applications requiring explainable predictions.

</details>


### [6] [LUMOS: Large User MOdels for User Behavior Prediction](https://arxiv.org/abs/2512.08957)
*Dhruv Nigam*

Main category: cs.LG

TL;DR: LUMOS是一个基于Transformer的大规模用户模型，通过联合学习多个任务并利用原始用户活动数据，消除了任务特定模型和手动特征工程的需求，显著提升了用户行为预测性能。


<details>
  <summary>Details</summary>
Motivation: 在线B2C平台面临大规模用户行为预测的挑战。传统方法依赖任务特定模型和领域特征工程，耗时、计算成本高、需要专业知识且难以扩展。

Method: LUMOS采用基于Transformer的架构，引入新颖的交叉注意力机制，使预测能够基于未来已知事件（如节假日、促销等）。采用多模态标记化，将用户交易、事件上下文和静态用户人口统计属性通过专门的嵌入路径处理。

Result: 在包含2750亿用户活动标记、2.5亿用户的生产数据集上，LUMOS在5个任务中相比传统任务特定模型平均提升：二分类任务ROC-AUC提高0.025，回归任务MAPE降低4.6%。在线A/B测试显示每日活跃用户增加3.15%。

Conclusion: LUMOS通过消除任务特定模型和手动特征工程，提供了一种可扩展的大规模用户行为预测解决方案，显著提升预测性能并带来可衡量的业务影响。

Abstract: User behavior prediction at scale remains a critical challenge for online B2C platforms. Traditional approaches rely heavily on task-specific models and domain-specific feature engineering. This is time-consuming, computationally expensive, and requires domain expertise and therefore not scalable. We present LUMOS (Large User MOdel Series), a transformer-based architecture that eliminates task-specific models and manual feature engineering by learning multiple tasks jointly using only raw user activity data. LUMOS introduces a novel cross-attention mechanism that conditions predictions on future known events (e.g., holidays, sales, etc.), enabling the model to predict complex behaviour patterns like "how will upcoming holidays affect user engagement?" The architecture also employs multi-modal tokenization, combining user transactions, event context, and static user demographic attributes into rich representations processed through specialized embedding pathways.
  Through extensive experiments on a production dataset spanning 275 billion user activity tokens from 250 million users, we demonstrate that LUMOS achieves superior performance compared to traditional task-specific models. Across 5 tasks with established baselines, we achieve an average improvement of 0.025 in ROC-AUC for binary classification tasks and 4.6\% reduction in MAPE for regression tasks. Online A/B testing validates these improvements translate to measurable business impact with a 3.15\% increase in Daily Active Users.

</details>


### [7] [EEG-Bench: A Benchmark for EEG Foundation Models in Clinical Applications](https://arxiv.org/abs/2512.08959)
*Ard Kastrati,Josua Bürki,Jonas Lauer,Cheng Xuan,Raffaele Iaquinto,Roger Wattenhofer*

Main category: cs.LG

TL;DR: 提出了一个统一的基准测试框架，用于评估基于EEG的基础模型在临床诊断任务中的表现，涵盖11种疾病和14个公开数据集，结果显示基础模型在某些场景表现良好，但简单模型在临床分布偏移下仍具竞争力。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏统一的基准测试框架来评估EEG基础模型在临床应用中的表现，需要标准化评估协议来比较传统方法和现代基础模型的性能。

Method: 构建了一个统一的基准测试框架，涵盖11个临床诊断任务和14个公开EEG数据集，采用最小化预处理和标准化评估协议，支持传统基线模型和现代基础模型的并行比较。

Result: 基础模型在某些设置下表现强劲，但简单模型在临床分布偏移情况下仍保持竞争力，特别是在面对真实临床数据变化时。

Conclusion: 该框架为EEG基础模型的临床评估提供了标准化工具，强调了简单模型在临床环境中的持续价值，并开源了所有数据和代码以促进可重复性和采用。

Abstract: We introduce a unified benchmarking framework focused on evaluating EEG-based foundation models in clinical applications. The benchmark spans 11 well-defined diagnostic tasks across 14 publicly available EEG datasets, including epilepsy, schizophrenia, Parkinson's disease, OCD, and mild traumatic brain injury. It features minimal preprocessing, standardized evaluation protocols, and enables side-by-side comparisons of classical baselines and modern foundation models. Our results show that while foundation models achieve strong performance in certain settings, simpler models often remain competitive, particularly under clinical distribution shifts. To facilitate reproducibility and adoption, we release all prepared data and code in an accessible and extensible format.

</details>


### [8] [Resolving Conflicts in Lifelong Learning via Aligning Updates in Subspaces](https://arxiv.org/abs/2512.08960)
*Yueer Zhou,Yichen Wu,Ying Wei*

Main category: cs.LG

TL;DR: PS-LoRA通过双正则化目标解决LoRA在持续学习中的灾难性遗忘问题，通过惩罚冲突方向和对齐优化子空间中的更新来保持参数稳定性。


<details>
  <summary>Details</summary>
Motivation: LoRA在持续学习中常遭受灾难性遗忘，主要原因是新任务梯度与历史权重轨迹之间的对抗性方向更新。需要解决这种破坏性干扰以保持学习表示的稳定性。

Method: 提出PS-LoRA框架：1) 双正则化目标：惩罚冲突方向并约束幅度偏差；2) 基于幅度的合并策略：将顺序适配器合并为鲁棒表示而无需重新训练；3) 在优化子空间中对齐更新以解决冲突。

Result: 在NLP和视觉基准测试中，PS-LoRA优于最先进方法，在有效适应新领域的同时保持了学习表示的稳定性。

Conclusion: PS-LoRA通过解决对抗性方向更新问题，显著缓解了LoRA在持续学习中的灾难性遗忘，实现了参数稳定性和任务适应性的平衡。

Abstract: Low-Rank Adaptation (LoRA) enables efficient Continual Learning but often suffers from catastrophic forgetting due to destructive interference between tasks. Our analysis reveals that this degradation is primarily driven by antagonistic directional updates where new task gradients directly oppose the historical weight trajectory. To address this, we propose PS-LoRA (Parameter Stability LoRA), a framework designed to resolve conflicts by aligning updates within the optimization subspace. Our approach employs a dual-regularization objective that penalizes conflicting directions and constrains magnitude deviations to ensure consistency with prior knowledge. Additionally, we implement a magnitude-based merging strategy to consolidate sequential adapters into a robust representation without retraining. Experiments on NLP and Vision benchmarks show that PS-LoRA outperforms state-of-the-art methods by preserving the stability of learned representations while efficiently adapting to new domains.

</details>


### [9] [SEA: Spectral Edge Attacks on Graph Neural Networks](https://arxiv.org/abs/2512.08964)
*Yongyu Wang*

Main category: cs.LG

TL;DR: 提出SEA攻击方法，利用谱分析评估图结构脆弱性，通过删除稳健边和添加不兼容边来攻击GNN


<details>
  <summary>Details</summary>
Motivation: 现有图结构攻击方法大多基于梯度启发式或局部连接模式，将边视为同等重要的候选修改对象，缺乏对图结构全局脆弱性的系统性分析

Method: 计算谱嵌入捕获输入流形的最脆弱方向，为每条边或非边分配稳健性分数，提出两种攻击变体：谱引导删除攻击（移除最稳健的边）和谱引导添加攻击（在谱空间最不兼容的节点间添加边）

Result: 在基准测试中验证了SEA攻击的有效性，能够显著降低GNN性能，且无需梯度信息，可轻松集成到现有GNN架构中

Conclusion: SEA提供了一种新的基于谱分析的图结构攻击框架，揭示了图神经网络在谱空间中的脆弱性，为评估和提升GNN鲁棒性提供了新视角

Abstract: Graph Neural Networks (GNNs) achieve strong performance on graph-structured data, but are notoriously vulnerable to small, carefully crafted perturbations of the graph structure. Most existing structure-based attacks rely on gradient-based heuristics or local connectivity patterns, and treat edges as equally important candidates for manipulation. In this paper, we propose Spectral Edge Attacks (SEA), a new family of adversarial attacks that explicitly leverage spectral robustness evaluation to guide structural perturbations. Our key idea is to compute a spectral embedding that captures the most fragile directions of the input manifold and to use it to assign a robustness score to each edge or non-edge. Based on these scores, we introduce two complementary attack variants: (i) a Spade-guided deletion attack that removes the most spectrally robust edges, and (ii) a Spade-guided addition attack that inserts edges between nodes that are maximally incompatible in the fragile spectral space. Both attacks operate at the graph level, are model-aware but conceptually simple, and can be plugged into existing GNN architectures without requiring gradients. We describe the spectral formulation, the attack algorithms, and experiments on benchmarks.

</details>


### [10] [Financial Instruction Following Evaluation (FIFE)](https://arxiv.org/abs/2512.08965)
*Glenn Matlin,Siddharth,Anirudh JM,Aditya Shukla,Yahya Hassan,Sudheer Chava*

Main category: cs.LG

TL;DR: FIFE是一个用于评估语言模型在金融分析任务中遵循复杂指令能力的高难度基准测试，包含88个人工编写的提示和可验证约束系统，评估显示开源权重模型优于专有系统，但所有模型都难以完全满足复杂要求。


<details>
  <summary>Details</summary>
Motivation: 语言模型在处理复杂、相互依赖的指令方面存在困难，特别是在金融等高风险领域需要精确性的场景。目前缺乏专门评估语言模型在金融分析任务中指令遵循能力的基准测试。

Method: 提出FIFE基准测试，包含88个人工编写的金融分析提示，采用带有可链接、可验证约束的验证系统，为细粒度奖励信号提供支持。在零样本设置下评估了53个模型（专有、开源权重、开源）。

Result: 评估结果显示明确的性能层次：顶级开源权重模型（严格76.1/宽松79.5）优于领先的专有系统（严格65.9/宽松70.5），而最佳开源模型表现显著落后（严格45.5/宽松48.9）。所有模型都难以完全满足FIFE的复杂要求。

Conclusion: FIFE基准测试揭示了语言模型在金融领域复杂指令遵循方面的局限性，开源数据集和代码将促进金融领域强化学习研究的发展。

Abstract: Language Models (LMs) struggle with complex, interdependent instructions, particularly in high-stakes domains like finance where precision is critical. We introduce FIFE, a novel, high-difficulty benchmark designed to assess LM instruction-following capabilities for financial analysis tasks. FIFE comprises 88 human-authored prompts and employs a verification system with chainable, verifiable constraints for fine-grained reward signals. We evaluate 53 models (proprietary, open-weight, open-source) in a zero-shot setting. Our key findings reveal a clear performance hierarchy: the top open-weight model (76.1 strict / 79.5 loose) surpasses the leading proprietary system (65.9 strict / 70.5 loose), while the best open-source models lag significantly (45.5 strict / 48.9 loose). However, even top-performing models struggle with FIFE's complex requirements, failing to achieve perfect compliance. We release our dataset and code as an open-source resource to promote research in Reinforcement Learning for the financial domain.

</details>


### [11] [CluCERT: Certifying LLM Robustness via Clustering-Guided Denoising Smoothing](https://arxiv.org/abs/2512.08967)
*Zixia Wang,Gaojie Jin,Jia Hu,Ronghui Mu*

Main category: cs.LG

TL;DR: CluCERT：通过聚类引导的去噪平滑来认证大语言模型鲁棒性的新框架，相比现有方法提供更紧的鲁棒性边界和更高的计算效率


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型能力强大，但仍易受对抗攻击（如同义词替换等语义保留的微小改动），现有认证方法存在鲁棒性边界松散和计算成本高的问题

Method: 提出CluCERT框架：1）语义聚类过滤器减少噪声样本保留有意义的扰动；2）精炼模块提取核心语义；3）快速同义词替换策略加速去噪过程

Result: 在各种下游任务和越狱防御场景的实验中，该方法在鲁棒性边界和计算效率方面均优于现有认证方法

Conclusion: CluCERT通过聚类引导的去噪平滑有效解决了现有LLM鲁棒性认证方法的局限性，为对抗攻击防御提供了更优的解决方案

Abstract: Recent advancements in Large Language Models (LLMs) have led to their widespread adoption in daily applications. Despite their impressive capabilities, they remain vulnerable to adversarial attacks, as even minor meaning-preserving changes such as synonym substitutions can lead to incorrect predictions. As a result, certifying the robustness of LLMs against such adversarial prompts is of vital importance. Existing approaches focused on word deletion or simple denoising strategies to achieve robustness certification. However, these methods face two critical limitations: (1) they yield loose robustness bounds due to the lack of semantic validation for perturbed outputs and (2) they suffer from high computational costs due to repeated sampling. To address these limitations, we propose CluCERT, a novel framework for certifying LLM robustness via clustering-guided denoising smoothing. Specifically, to achieve tighter certified bounds, we introduce a semantic clustering filter that reduces noisy samples and retains meaningful perturbations, supported by theoretical analysis. Furthermore, we enhance computational efficiency through two mechanisms: a refine module that extracts core semantics, and a fast synonym substitution strategy that accelerates the denoising process. Finally, we conduct extensive experiments on various downstream tasks and jailbreak defense scenarios. Experimental results demonstrate that our method outperforms existing certified approaches in both robustness bounds and computational efficiency.

</details>


### [12] [StructuredDNA: A Bio-Physical Framework for Energy-Aware Transformer Routing](https://arxiv.org/abs/2512.08968)
*Mustapha Hamdi*

Main category: cs.LG

TL;DR: StructuredDNA：基于生物物理能量最小化的稀疏Transformer路由框架，通过语义能量引导的动态专家选择，显著降低计算能耗


<details>
  <summary>Details</summary>
Motivation: 大规模计算模型的快速扩展导致能源和计算成本急剧增加。受生物系统中结构和功能从低能量配置中涌现的启发，需要开发能量感知的稀疏架构框架

Method: 提出StructuredDNA框架，用基于语义能量最小化的生物物理能量引导路由层替代密集的Mixture-of-Experts路由。输入被动态分组为语义密码子，通过最小化结合内聚性、不确定性和计算成本的全局能量函数来选择单个专家

Result: 在BioASQ基准测试中（K=50），实现了97.7%的能源利用密度降低和0.998的语义稳定性指数。在WikiText-103上展示了语义缩放定律，在扩展到2048个专家时仍保持99%以上的能源效率

Conclusion: StructuredDNA建立了生物物理原理与Transformer稀疏专家路由之间的明确联系，为未来能量感知、模块化和可扩展的计算系统提供了领域无关的范式

Abstract: The rapid scaling of large computational models has led to a critical increase in energy and compute costs. Inspired by biological systems where structure and function emerge from low-energy configurations, we introduce StructuredDNA, a sparse architecture framework for modular, energy-aware Transformer routing. StructuredDNA replaces dense Mixture-of-Experts routing with a bio-physical, energy-guided routing layer based on semantic energy minimization. Inputs are dynamically grouped into semantic codons, and routing selects a single expert by minimizing a global energy functional that combines cohesion, uncertainty, and computational cost.
  We validate StructuredDNA on both specialized (BioASQ) and open-domain benchmarks (WikiText-103). On BioASQ (K = 50), we achieve a 97.7% reduction in Energy Utilization Density (EUD) and a Semantic Stability Index (SSI) of 0.998. We further demonstrate a Semantic Scaling Law on WikiText-103, showing that the architecture generalizes to open domains by scaling expert granularity (K = 2048) while maintaining more than 99% energy efficiency. StructuredDNA thus establishes a robust, domain-agnostic paradigm for future sparse computational frameworks.
  StructuredDNA provides an explicit link between bio-physical principles and sparse expert routing in Transformer architectures, and points toward future energy-aware, modular, and scalable computational systems. We discuss limitations of this proof-of-concept study and outline directions for scaling the approach to larger models, datasets, and hardware platforms. The StructuredDNA implementation is available at https://github.com/InnoDeep-repos/StructuredDNA .

</details>


### [13] [Learning Robust Representations for Malicious Content Detection via Contrastive Sampling and Uncertainty Estimation](https://arxiv.org/abs/2512.08969)
*Elias Hossain,Umesh Biswas,Charan Gudla,Sai Phani Parsa*

Main category: cs.LG

TL;DR: UCF是一个正例-未标记表示学习框架，通过不确定性感知对比损失、自适应温度缩放和自注意力LSTM编码器，在噪声和不平衡条件下改善分类性能。


<details>
  <summary>Details</summary>
Motivation: 解决在噪声和不平衡条件下（如网络安全、生物医学文本挖掘等高风险领域）进行正例-未标记学习时，传统方法难以获得高质量表示的问题。

Method: 提出不确定性对比框架（UCF），包含：1）基于样本置信度动态调整对比权重的损失函数；2）使用正例锚点稳定训练；3）自适应温度参数调整以适应批次级变化；4）自注意力引导的LSTM编码器。

Result: 在恶意内容分类任务中，UCF生成的嵌入使多个传统分类器达到93.38%以上的准确率、0.93以上的精确率，接近完美的召回率，假阴性极少，ROC-AUC得分具有竞争力。可视化分析显示正例和未标记实例之间有清晰分离。

Conclusion: UCF是一个稳健且可扩展的解决方案，能够产生校准的、有区分度的嵌入，适用于高风险领域的正例-未标记学习任务。

Abstract: We propose the Uncertainty Contrastive Framework (UCF), a Positive-Unlabeled (PU) representation learning framework that integrates uncertainty-aware contrastive loss, adaptive temperature scaling, and a self-attention-guided LSTM encoder to improve classification under noisy and imbalanced conditions. UCF dynamically adjusts contrastive weighting based on sample confidence, stabilizes training using positive anchors, and adapts temperature parameters to batch-level variability. Applied to malicious content classification, UCF-generated embeddings enable multiple traditional classifiers to achieve more than 93.38% accuracy, precision above 0.93, and near-perfect recall, with minimal false negatives and competitive ROC-AUC scores. Visual analyses confirm clear separation between positive and unlabeled instances, highlighting the framework's ability to produce calibrated, discriminative embeddings. These results position UCF as a robust and scalable solution for PU learning in high-stakes domains such as cybersecurity and biomedical text mining.

</details>


### [14] [Peek-a-Boo Reasoning: Contrastive Region Masking in MLLMs](https://arxiv.org/abs/2512.08976)
*Isha Chaturvedi,Anjana Nair,Yushen Li,Adhitya Rajendra Kumar,Kevin Zhu,Sunishchal Dev,Ashwinee Panda,Vasu Sharma*

Main category: cs.LG

TL;DR: CRM是一种无需训练的诊断方法，通过对比性区域掩码揭示多模态大语言模型在思维链推理中对特定视觉区域的依赖，从答案正确性评估转向推理忠实性评估。


<details>
  <summary>Details</summary>
Motivation: 现有方法局限于最终答案或注意力图分析，无法提供因果、步骤级别的归因来理解MLLMs在视觉推理中如何依赖特定区域，需要更精细的诊断工具来评估推理的稳健性和忠实性。

Method: 提出对比性区域掩码(CRM)：系统性地掩码标注的视觉区域，对比掩码与未掩码情况下的推理轨迹，提供因果、步骤级别的归因分析，应用于VisArgs等数据集。

Result: 揭示了两种不同的失败模式：一些模型保持推理结构但在证据缺失时产生幻觉，另一些模型紧密依赖视觉线索但在扰动下崩溃，将视觉基准重构为诊断工具。

Conclusion: CRM通过从答案正确性评估转向推理忠实性评估，强调了需要多模态评估框架来测量性能、稳健性和推理忠实性，为理解MLLMs的视觉推理机制提供了新视角。

Abstract: We introduce Contrastive Region Masking (CRM), a training free diagnostic that reveals how multimodal large language models (MLLMs) depend on specific visual regions at each step of chain-of-thought (CoT) reasoning. Unlike prior approaches limited to final answers or attention maps, CRM provides causal, step-level attri- bution by systematically masking annotated regions and contrasting the resulting reasoning traces with unmasked baselines. Applied to datasets such as VisArgs, CRM reveals distinct failure modes: some models preserve reasoning structure, but hallucinate when evidence is missing, while others ground tightly to visual cues yet collapse under perturbations. By shifting the evaluation from correctness of an- swers to faithfulness of reasoning, CRM reframes visual benchmarks as diagnostic tools, highlighting the need for multimodal evaluation frameworks that measure not just performance, but also robustness and fidelity of reasoning.

</details>


### [15] [Graph Deep Learning for Intracranial Aneurysm Blood Flow Simulation and Risk Assessment](https://arxiv.org/abs/2512.09013)
*Paul Garnier,Pablo Jeken-Rico,Vincent Lannelongue,Chiara Faitini,Aurèle Goetz,Lea Chanvillard,Ramy Nemer,Jonathan Viquerat,Ugo Pelissier,Philippe Meliga,Jacques Sédat,Thomas Liebig,Yves Chau,Elie Hachem*

Main category: cs.LG

TL;DR: 提出基于图神经网络的颅内动脉瘤血流动力学替代模型，能在1分钟内从血管几何结构生成全场血流动力学预测，无需计算流体力学专家，实现床边实时分析。


<details>
  <summary>Details</summary>
Motivation: 传统计算流体力学模拟准确但耗时且需要专业知识，临床4D Flow MRI分辨率不足且昂贵不实用，需要一种快速、高分辨率、易于临床部署的血流动力学预测方法。

Method: 使用图神经网络替代模型，结合图变换器和自回归预测，在患者特异性动脉瘤高保真模拟数据集上训练，直接从血管几何结构生成血流、壁面剪切应力和振荡剪切指数。

Result: 模型能在每个心动周期1分钟内生成全场血流动力学预测，泛化到未见过的患者几何结构和流入条件，无需网格特定校准，提供高分辨率血流场。

Conclusion: 该工作将高保真模拟从专家研究工具转变为可部署的数据驱动决策支持系统，实现床边实时动脉瘤分析，为临床可解释的血流动力学预测奠定基础。

Abstract: Intracranial aneurysms remain a major cause of neurological morbidity and mortality worldwide, where rupture risk is tightly coupled to local hemodynamics particularly wall shear stress and oscillatory shear index. Conventional computational fluid dynamics simulations provide accurate insights but are prohibitively slow and require specialized expertise. Clinical imaging alternatives such as 4D Flow MRI offer direct in-vivo measurements, yet their spatial resolution remains insufficient to capture the fine-scale shear patterns that drive endothelial remodeling and rupture risk while being extremely impractical and expensive.
  We present a graph neural network surrogate model that bridges this gap by reproducing full-field hemodynamics directly from vascular geometries in less than one minute per cardiac cycle. Trained on a comprehensive dataset of high-fidelity simulations of patient-specific aneurysms, our architecture combines graph transformers with autoregressive predictions to accurately simulate blood flow, wall shear stress, and oscillatory shear index. The model generalizes across unseen patient geometries and inflow conditions without mesh-specific calibration. Beyond accelerating simulation, our framework establishes the foundation for clinically interpretable hemodynamic prediction. By enabling near real-time inference integrated with existing imaging pipelines, it allows direct comparison with hospital phase-diagram assessments and extends them with physically grounded, high-resolution flow fields.
  This work transforms high-fidelity simulations from an expert-only research tool into a deployable, data-driven decision support system. Our full pipeline delivers high-resolution hemodynamic predictions within minutes of patient imaging, without requiring computational specialists, marking a step-change toward real-time, bedside aneurysm analysis.

</details>


### [16] [Improving Multi-Class Calibration through Normalization-Aware Isotonic Techniques](https://arxiv.org/abs/2512.09054)
*Alon Arad,Saharon Rosset*

Main category: cs.LG

TL;DR: 提出两种新的多类校准方法：NA-FIR（归一化感知保序回归）和SCIR（累积双变量保序回归），通过考虑概率归一化约束，显著提升了多类概率预测的校准性能。


<details>
  <summary>Details</summary>
Motivation: 多类监督学习需要准确可靠的概率预测，但现有的保序回归方法（如一对多校准）在多类问题上表现不佳，限制了实际应用。需要开发能够考虑概率归一化约束的多类校准方法。

Method: 提出两种归一化感知的保序回归方法：1) NA-FIR：将归一化直接纳入优化过程；2) SCIR：将问题建模为累积双变量保序回归。两种方法都基于实践者期望的自然直观假设。

Result: 在多种文本和图像分类数据集及不同模型架构上的实验表明，该方法在负对数似然（NLL）和期望校准误差（ECE）指标上持续改进，优于现有方法。

Conclusion: 提出的归一化感知保序回归方法有效解决了多类校准问题，通过考虑概率归一化约束，显著提升了校准性能，为实际应用提供了可靠的多类概率预测解决方案。

Abstract: Accurate and reliable probability predictions are essential for multi-class supervised learning tasks, where well-calibrated models enable rational decision-making. While isotonic regression has proven effective for binary calibration, its extension to multi-class problems via one-vs-rest calibration produced suboptimal results when compared to parametric methods, limiting its practical adoption. In this work, we propose novel isotonic normalization-aware techniques for multiclass calibration, grounded in natural and intuitive assumptions expected by practitioners. Unlike prior approaches, our methods inherently account for probability normalization by either incorporating normalization directly into the optimization process (NA-FIR) or modeling the problem as a cumulative bivariate isotonic regression (SCIR). Empirical evaluation on a variety of text and image classification datasets across different model architectures reveals that our approach consistently improves negative log-likelihood (NLL) and expected calibration error (ECE) metrics.

</details>


### [17] [A Diffusion-Based Framework for High-Resolution Precipitation Forecasting over CONUS](https://arxiv.org/abs/2512.09059)
*Marina Vicens-Miquel,Amy McGovern,Aaron J. Hill,Efi Foufoula-Georgiou,Clement Guilloteau,Samuel S. P. Shen*

Main category: cs.LG

TL;DR: 提出基于扩散模型的深度学习框架，比较三种残差预测策略（纯观测、纯HRRR预报、混合数据），在CONUS区域实现1-12小时降水预报，混合模型在短时效最优，HRRR修正模型在长时效最优。


<details>
  <summary>Details</summary>
Motivation: 准确的降水预报对水文气象风险管理至关重要，特别是预测可能导致山洪暴发和基础设施损坏的极端降雨。现有数值天气预报系统存在局限性，需要深度学习方法来提升预报技能。

Method: 引入基于扩散的深度学习框架，系统比较三种残差预测策略：1) 纯数据驱动模型（仅使用MRMS观测数据）；2) 纯修正模型（仅使用HRRR数值预报）；3) 混合模型（整合MRMS观测和HRRR预报变量）。在统一设置下评估，实现1公里空间分辨率，1-12小时自回归滚动预报。

Result: 深度学习框架在所有预报时效均优于HRRR基准。混合模型在最短预报时效表现最佳，而HRRR修正模型在较长预报时效优于其他模型，保持高技能至12小时。通过校准的不确定性量化评估可靠性。

Conclusion: 该研究通过提升预报技能、可靠性和区域适用性，推进了基于深度学习的降水预报。特别是在较长预报时效的改进对应急准备至关重要，适度的预报时效延长可改善决策制定。

Abstract: Accurate precipitation forecasting is essential for hydrometeorological risk management, especially for anticipating extreme rainfall that can lead to flash flooding and infrastructure damage. This study introduces a diffusion-based deep learning (DL) framework that systematically compares three residual prediction strategies differing only in their input sources: (1) a fully data-driven model using only past observations from the Multi-Radar Multi-Sensor (MRMS) system, (2) a corrective model using only forecasts from the High-Resolution Rapid Refresh (HRRR) numerical weather prediction system, and (3) a hybrid model integrating both MRMS and selected HRRR forecast variables. By evaluating these approaches under a unified setup, we provide a clearer understanding of how each data source contributes to predictive skill over the Continental United States (CONUS). Forecasts are produced at 1-km spatial resolution, beginning with direct 1-hour predictions and extending to 12 hours using autoregressive rollouts. Performance is evaluated using both CONUS-wide and region-specific metrics that assess overall performance and skill at extreme rainfall thresholds. Across all lead times, our DL framework consistently outperforms the HRRR baseline in pixel-wise and spatiostatistical metrics. The hybrid model performs best at the shortest lead time, while the HRRR-corrective model outperforms others at longer lead times, maintaining high skill through 12 hours. To assess reliability, we incorporate calibrated uncertainty quantification tailored to the residual learning setup. These gains, particularly at longer lead times, are critical for emergency preparedness, where modest increases in forecast horizon can improve decision-making. This work advances DL-based precipitation forecasting by enhancing predictive skill, reliability, and applicability across regions.

</details>


### [18] [Contrast transfer functions help quantify neural network out-of-distribution generalization in HRTEM](https://arxiv.org/abs/2512.09067)
*Luis Rangel DaCosta,Mary C. Scott*

Main category: cs.LG

TL;DR: 该论文研究了神经网络在HRTEM纳米颗粒分割任务中的分布外泛化能力，通过大规模仿真数据训练和测试了12,000多个模型，发现模型性能会随成像条件变化而平滑可预测地下降。


<details>
  <summary>Details</summary>
Motivation: 神经网络在分布外（OOD）场景下的泛化能力不足是其实际部署的主要障碍，特别是在实验条件变化或地面真实信息难以获取的科学应用中。理解神经网络在HRTEM纳米颗粒分割中的OOD泛化行为对于其在实验工作流中的成功应用至关重要。

Method: 使用基于仿真的数据生成方法，通过随机结构采样和多层切片模拟生成合成数据，训练和测试了超过12,000个神经网络分割模型。开发了一个基于HRTEM对比度传递函数的框架来比较数据集的信息内容并量化OOD域偏移。

Result: 神经网络分割模型表现出显著的性能稳定性，但随着成像条件从训练分布偏移，其性能会平滑且可预测地下降。研究还揭示了该方法在解释其他OOD偏移（如原子结构变化）方面的局限性。

Conclusion: 该研究为理解神经网络在HRTEM成像中的OOD泛化行为提供了系统框架，表明模型性能会随成像条件变化而可预测地下降，同时指出了在更复杂OOD场景下需要补充技术来全面理解泛化能力。

Abstract: Neural networks, while effective for tackling many challenging scientific tasks, are not known to perform well out-of-distribution (OOD), i.e., within domains which differ from their training data. Understanding neural network OOD generalization is paramount to their successful deployment in experimental workflows, especially when ground-truth knowledge about the experiment is hard to establish or experimental conditions significantly vary. With inherent access to ground-truth information and fine-grained control of underlying distributions, simulation-based data curation facilitates precise investigation of OOD generalization behavior. Here, we probe generalization with respect to imaging conditions of neural network segmentation models for high-resolution transmission electron microscopy (HRTEM) imaging of nanoparticles, training and measuring the OOD generalization of over 12,000 neural networks using synthetic data generated via random structure sampling and multislice simulation. Using the HRTEM contrast transfer function, we further develop a framework to compare information content of HRTEM datasets and quantify OOD domain shifts. We demonstrate that neural network segmentation models enjoy significant performance stability, but will smoothly and predictably worsen as imaging conditions shift from the training distribution. Lastly, we consider limitations of our approach in explaining other OOD shifts, such as of the atomic structures, and discuss complementary techniques for understanding generalization in such settings.

</details>


### [19] [Modular Deep-Learning-Based Early Warning System for Deadly Heatwave Prediction](https://arxiv.org/abs/2512.09074)
*Shangqing Xu,Zhiyuan Zhao,Megha Sharma,José María Martín-Olalla,Alexander Rodríguez,Gregory A. Wellenius,B. Aditya Prakash*

Main category: cs.LG

TL;DR: DeepTherm：无需热相关死亡历史数据的模块化致命热浪预警系统，通过深度学习双预测管道分离基线死亡率，在西班牙真实数据上验证了其一致性、鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 城市严重热浪对公共健康构成重大威胁，需要建立早期预警策略。然而，预测即将到来的致命热浪面临挑战，因为难以定义和估计热相关死亡率，且早期预警系统需要满足数据可用性、时空鲁棒性和决策成本等额外要求。

Method: 提出DeepTherm模块化早期预警系统，采用深度学习双预测管道，从全因死亡率中分离出无热浪和其他异常事件时的基线死亡率，无需热相关死亡历史数据。

Result: 在西班牙真实数据上评估显示，DeepTherm在不同地区、时间段和人群组中表现出一致、鲁棒和准确的性能，同时允许在漏报和误报之间进行权衡。

Conclusion: DeepTherm成功解决了致命热浪预测的挑战，提供了一个无需历史热相关死亡数据的灵活预警系统，为城市热浪早期预警提供了有效解决方案。

Abstract: Severe heatwaves in urban areas significantly threaten public health, calling for establishing early warning strategies. Despite predicting occurrence of heatwaves and attributing historical mortality, predicting an incoming deadly heatwave remains a challenge due to the difficulty in defining and estimating heat-related mortality. Furthermore, establishing an early warning system imposes additional requirements, including data availability, spatial and temporal robustness, and decision costs. To address these challenges, we propose DeepTherm, a modular early warning system for deadly heatwave prediction without requiring heat-related mortality history. By highlighting the flexibility of deep learning, DeepTherm employs a dual-prediction pipeline, disentangling baseline mortality in the absence of heatwaves and other irregular events from all-cause mortality. We evaluated DeepTherm on real-world data across Spain. Results demonstrate consistent, robust, and accurate performance across diverse regions, time periods, and population groups while allowing trade-off between missed alarms and false alarms.

</details>


### [20] [Beyond the Hype: Comparing Lightweight and Deep Learning Models for Air Quality Forecasting](https://arxiv.org/abs/2512.09076)
*Moazzam Umer Gondal,Hamad ul Qudous,Asma Ahmad Farhan*

Main category: cs.LG

TL;DR: 轻量级可加模型（Facebook Prophet和NeuralProphet）在北京PM2.5和PM10预测中表现优于复杂深度学习模型和传统统计方法，提供准确性、可解释性和易部署性的平衡。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习模型虽然主导空气污染预测研究，但其复杂性和有限的可解释性阻碍了实际应用。本研究旨在探索轻量级可加模型是否能在保持竞争力的同时提供更好的可解释性和易部署性。

Method: 使用多年污染物和气象数据，应用系统特征选择（相关性、互信息、mRMR）、防泄漏缩放和按时间顺序的数据划分。训练Facebook Prophet和NeuralProphet模型，并对比LSTM、LightGBM和SARIMAX基线模型。NeuralProphet额外利用了滞后依赖关系。

Result: Facebook Prophet在7天保留测试集上表现最佳，对两种污染物的测试R²均超过0.94，优于NeuralProphet、SARIMAX和机器学习基线模型。

Conclusion: 可解释的可加模型在空气污染预测中与传统方法和复杂方法相比仍具有竞争力，提供了准确性、透明度和易部署性的实用平衡。

Abstract: Accurate forecasting of urban air pollution is essential for protecting public health and guiding mitigation policies. While Deep Learning (DL) and hybrid pipelines dominate recent research, their complexity and limited interpretability hinder operational use. This study investigates whether lightweight additive models -- Facebook Prophet (FBP) and NeuralProphet (NP) -- can deliver competitive forecasts for particulate matter (PM$_{2.5}$, PM$_{10}$) in Beijing, China. Using multi-year pollutant and meteorological data, we applied systematic feature selection (correlation, mutual information, mRMR), leakage-safe scaling, and chronological data splits. Both models were trained with pollutant and precursor regressors, with NP additionally leveraging lagged dependencies. For context, two machine learning baselines (LSTM, LightGBM) and one traditional statistical model (SARIMAX) were also implemented. Performance was evaluated on a 7-day holdout using MAE, RMSE, and $R^2$. Results show that FBP consistently outperformed NP, SARIMAX, and the learning-based baselines, achieving test $R^2$ above 0.94 for both pollutants. These findings demonstrate that interpretable additive models remain competitive with both traditional and complex approaches, offering a practical balance of accuracy, transparency, and ease of deployment.

</details>


### [21] [GS-KAN: Parameter-Efficient Kolmogorov-Arnold Networks via Sprecher-Type Shared Basis Functions](https://arxiv.org/abs/2512.09084)
*Oscar Eliasson*

Main category: cs.LG

TL;DR: GS-KAN是一种轻量化的Kolmogorov-Arnold网络架构，通过在每层使用单个共享父函数和可学习线性变换来构建边缘函数，解决了传统KAN参数效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 传统Kolmogorov-Arnold网络（KANs）虽然具有强大的逼近能力，但由于需要为每个网络边缘维护独立的参数化，导致参数效率低下，限制了其在高维场景下的应用。

Method: 提出GS-KAN架构，受David Sprecher对叠加定理的改进启发，通过为每层使用单个可学习的共享父函数，并对其应用可学习的线性变换来构建独特的边缘函数，从而大幅减少参数数量。

Result: 在连续函数逼近任务中，GS-KAN优于MLPs和标准KAN基线，同时保持卓越的参数效率；在表格数据回归中与现有KAN架构竞争，在高维分类任务中优于MLPs。

Conclusion: GS-KAN实现了参数高效的KAN架构，使其能够在严格参数约束的高维场景中部署，解决了传统KAN因参数爆炸而不可行的问题。

Abstract: The Kolmogorov-Arnold representation theorem offers a theoretical alternative to Multi-Layer Perceptrons (MLPs) by placing learnable univariate functions on edges rather than nodes. While recent implementations such as Kolmogorov-Arnold Networks (KANs) demonstrate high approximation capabilities, they suffer from significant parameter inefficiency due to the requirement of maintaining unique parameterizations for every network edge. In this work, we propose GS-KAN (Generalized Sprecher-KAN), a lightweight architecture inspired by David Sprecher's refinement of the superposition theorem. GS-KAN constructs unique edge functions by applying learnable linear transformations to a single learnable, shared parent function per layer. We evaluate GS-KAN against existing KAN architectures and MLPs across synthetic function approximation, tabular data regression and image classification tasks. Our results demonstrate that GS-KAN outperforms both MLPs and standard KAN baselines on continuous function approximation tasks while maintaining superior parameter efficiency. Additionally, GS-KAN achieves competitive performance with existing KAN architectures on tabular regression and outperforms MLPs on high-dimensional classification tasks. Crucially, the proposed architecture enables the deployment of KAN-based architectures in high-dimensional regimes under strict parameter constraints, a setting where standard implementations are typically infeasible due to parameter explosion. The source code is available at https://github.com/rambamn48/gs-impl.

</details>


### [22] [Natural Geometry of Robust Data Attribution: From Convex Models to Deep Networks](https://arxiv.org/abs/2512.09103)
*Shihao Li,Jiachen Li,Dongmei Chen*

Main category: cs.LG

TL;DR: 提出首个针对深度网络数据归因的认证鲁棒性框架，通过自然Wasserstein度量消除谱放大效应，显著提升归因稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有数据归因方法对分布扰动敏感，缺乏可靠性保证，需要建立认证鲁棒归因框架。

Method: 提出统一认证鲁棒归因框架：对凸模型推导Wasserstein-Robust Influence Functions；对深度网络提出自然Wasserstein度量，消除谱放大效应，开发Natural W-TRAK方法。

Result: 在CIFAR-10上，Natural W-TRAK认证68.7%的排序对（欧氏基线为0%）；Self-Influence在标签噪声检测中达到0.970 AUROC，仅检查前20%训练数据即可识别94.1%的污染标签。

Conclusion: 自然Wasserstein度量有效消除深度网络归因的谱放大问题，首次实现神经网络归因的非空认证边界，为鲁棒数据归因提供理论框架。

Abstract: Data attribution methods identify which training examples are responsible for a model's predictions, but their sensitivity to distributional perturbations undermines practical reliability. We present a unified framework for certified robust attribution that extends from convex models to deep networks. For convex settings, we derive Wasserstein-Robust Influence Functions (W-RIF) with provable coverage guarantees. For deep networks, we demonstrate that Euclidean certification is rendered vacuous by spectral amplification -- a mechanism where the inherent ill-conditioning of deep representations inflates Lipschitz bounds by over $10{,}000\times$. This explains why standard TRAK scores, while accurate point estimates, are geometrically fragile: naive Euclidean robustness analysis yields 0\% certification. Our key contribution is the Natural Wasserstein metric, which measures perturbations in the geometry induced by the model's own feature covariance. This eliminates spectral amplification, reducing worst-case sensitivity by $76\times$ and stabilizing attribution estimates. On CIFAR-10 with ResNet-18, Natural W-TRAK certifies 68.7\% of ranking pairs compared to 0\% for Euclidean baselines -- to our knowledge, the first non-vacuous certified bounds for neural network attribution. Furthermore, we prove that the Self-Influence term arising from our analysis equals the Lipschitz constant governing attribution stability, providing theoretical grounding for leverage-based anomaly detection. Empirically, Self-Influence achieves 0.970 AUROC for label noise detection, identifying 94.1\% of corrupted labels by examining just the top 20\% of training data.

</details>


### [23] [Learning Unmasking Policies for Diffusion Language Models](https://arxiv.org/abs/2512.09106)
*Metod Jazbec,Theo X. Olausson,Louis Béthune,Pierre Ablin,Michael Kirchhof,Joao Monterio,Victor Turrisi,Jason Ramapuram,Marco Cuturi*

Main category: cs.LG

TL;DR: 本文提出使用强化学习训练扩散语言模型的采样策略，替代传统启发式方法，在保持生成质量的同时提升效率。


<details>
  <summary>Details</summary>
Motivation: 当前扩散语言模型使用启发式采样策略（如置信度阈值）存在需要手动调参、在大缓冲区下性能下降的问题，需要更智能的自适应采样方法。

Method: 将掩码扩散采样形式化为马尔可夫决策过程，使用单层Transformer架构的轻量级策略网络，根据dLLM的token置信度做出解掩码决策。

Result: 训练的策略在结合半自回归生成时达到SOTA启发式方法性能，在全扩散设置中表现更优，且能泛化到新的dLLM和更长序列。

Conclusion: 强化学习训练的采样策略是启发式方法的有效替代，但存在域外数据泛化问题和精度-效率权衡的微调挑战。

Abstract: Diffusion (Large) Language Models (dLLMs) now match the downstream performance of their autoregressive counterparts on many tasks, while holding the promise of being more efficient during inference. One particularly successful variant is masked discrete diffusion, in which a buffer filled with special mask tokens is progressively replaced with tokens sampled from the model's vocabulary. Efficiency can be gained by unmasking several tokens in parallel, but doing too many at once risks degrading the generation quality. Thus, one critical design aspect of dLLMs is the sampling procedure that selects, at each step of the diffusion process, which tokens to replace. Indeed, recent work has found that heuristic strategies such as confidence thresholding lead to both higher quality and token throughput compared to random unmasking. However, such heuristics have downsides: they require manual tuning, and we observe that their performance degrades with larger buffer sizes. In this work, we instead propose to train sampling procedures using reinforcement learning. Specifically, we formalize masked diffusion sampling as a Markov decision process in which the dLLM serves as the environment, and propose a lightweight policy architecture based on a single-layer transformer that maps dLLM token confidences to unmasking decisions. Our experiments show that these trained policies match the performance of state-of-the-art heuristics when combined with semi-autoregressive generation, while outperforming them in the full diffusion setting. We also examine the transferability of these policies, finding that they can generalize to new underlying dLLMs and longer sequence lengths. However, we also observe that their performance degrades when applied to out-of-domain data, and that fine-grained tuning of the accuracy-efficiency trade-off can be challenging with our approach.

</details>


### [24] [Spectral Embedding via Chebyshev Bases for Robust DeepONet Approximation](https://arxiv.org/abs/2512.09165)
*Muhammad Abid,Omer San*

Main category: cs.LG

TL;DR: 提出SEDONet，一种基于Chebyshev谱字典的DeepONet变体，用于解决标准DeepONet在处理有界域上非周期结构时的局限性，在多个PDE基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 标准DeepONet的trunk设计基于全连接层处理原始坐标，难以有效表示有界域上Dirichlet或Neumann边界条件下的尖锐梯度、边界层和非周期结构。

Method: 提出SEDONet，使用固定的Chebyshev谱字典驱动trunk而非原始坐标输入，为有界域提供非周期谱嵌入的归纳偏置。

Result: 在2D Poisson、1D Burgers、1D advection-diffusion、Allen-Cahn动力学和Lorenz-96混沌系统等PDE基准测试中，SEDONet始终获得最低的相对L2误差，比基线DeepONet平均改进30-40%，在非周期几何上优于Fourier嵌入变体。

Conclusion: SEDONet通过简单的参数中性修改，为有界域上的PDE代理建模提供了稳健高效的谱框架，能更准确地保留高频和边界局部化特征。

Abstract: Deep Operator Networks (DeepONets) have become a central tool in data-driven operator learning, providing flexible surrogates for nonlinear mappings arising in partial differential equations (PDEs). However, the standard trunk design based on fully connected layers acting on raw spatial or spatiotemporal coordinates struggles to represent sharp gradients, boundary layers, and non-periodic structures commonly found in PDEs posed on bounded domains with Dirichlet or Neumann boundary conditions. To address these limitations, we introduce the Spectral-Embedded DeepONet (SEDONet), a new DeepONet variant in which the trunk is driven by a fixed Chebyshev spectral dictionary rather than coordinate inputs. This non-periodic spectral embedding provides a principled inductive bias tailored to bounded domains, enabling the learned operator to capture fine-scale non-periodic features that are difficult for Fourier or MLP trunks to represent. SEDONet is evaluated on a suite of PDE benchmarks including 2D Poisson, 1D Burgers, 1D advection-diffusion, Allen-Cahn dynamics, and the Lorenz-96 chaotic system, covering elliptic, parabolic, advective, and multiscale temporal phenomena, all of which can be viewed as canonical problems in computational mechanics. Across all datasets, SEDONet consistently achieves the lowest relative L2 errors among DeepONet, FEDONet, and SEDONet, with average improvements of about 30-40% over the baseline DeepONet and meaningful gains over Fourier-embedded variants on non-periodic geometries. Spectral analyses further show that SEDONet more accurately preserves high-frequency and boundary-localized features, demonstrating the value of Chebyshev embeddings in non-periodic operator learning. The proposed architecture offers a simple, parameter-neutral modification to DeepONets, delivering a robust and efficient spectral framework for surrogate modeling of PDEs on bounded domains.

</details>


### [25] [Understanding the Failure Modes of Transformers through the Lens of Graph Neural Networks](https://arxiv.org/abs/2512.09182)
*Hunjae Lee*

Main category: cs.LG

TL;DR: 本文从图神经网络理论视角分析Transformer的失败模式，认为深度学习本质上是可学习的信息混合与传播，而模型失败模式源于信息传播瓶颈。作者指出Transformer面临的许多问题与GNN相似，并分析了因果解码器Transformer在信息传播中的几何特性导致的失败模式。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer在现代LLM架构中占主导地位且表现优异，但它们存在令人惊讶的失败模式和可预测的不对称性能退化。当前对Transformer失败模式的理论理解不足，现有解决方案往往是临时性的、基于直觉而非理论驱动。本文旨在通过GNN理论视角，为Transformer的失败模式提供理论解释，弥合观察到的失败模式与理论理解之间的差距。

Method: 1. 论证深度学习（包括Transformer）本质上是可学习的信息混合与传播；2. 将模型失败模式研究转化为信息传播瓶颈研究；3. 利用GNN理论中已有的丰富文献分析信息传播瓶颈和理论失败模式；4. 分析因果解码器Transformer在信息传播中产生的几何特性；5. 将现有Transformer解决方案统一到理论视角下，解释其工作原理和解决的问题。

Result: 1. 建立了Transformer失败模式与GNN理论之间的联系；2. 识别了因果解码器Transformer在信息传播中的几何特性导致的失败模式；3. 为现有Transformer解决方案提供了理论解释，说明它们实际上在解决信息传播瓶颈问题；4. 提出了改进方案以针对Transformer特定失败模式的理论框架。

Conclusion: 本文成功地将GNN理论应用于分析Transformer的失败模式，为理解Transformer的局限性提供了理论框架。通过将深度学习视为信息混合与传播过程，作者展示了如何利用GNN理论分析信息传播瓶颈，并为改进Transformer架构提供了理论指导。这项工作有助于弥合Transformer实践观察与理论理解之间的差距，推动更理论驱动的模型改进。

Abstract: Transformers and more specifically decoder-only transformers dominate modern LLM architectures. While they have shown to work exceptionally well, they are not without issues, resulting in surprising failure modes and predictably asymmetric performance degradation. This article is a study of many of these observed failure modes of transformers through the lens of graph neural network (GNN) theory. We first make the case that much of deep learning, including transformers, is about learnable information mixing and propagation. This makes the study of model failure modes a study of bottlenecks in information propagation. This naturally leads to GNN theory, where there is already a rich literature on information propagation bottlenecks and theoretical failure modes of models. We then make the case that many issues faced by GNNs are also experienced by transformers. In addition, we analyze how the causal nature of decoder-only transformers create interesting geometric properties in information propagation, resulting in predictable and potentially devastating failure modes. Finally, we observe that existing solutions in transformer research tend to be ad-hoc and driven by intuition rather than grounded theoretical motivation. As such, we unify many such solutions under a more theoretical perspective, providing insight into why they work, what problem they are actually solving, and how they can be further improved to target specific failure modes of transformers. Overall, this article is an attempt to bridge the gap between observed failure modes in transformers and a general lack of theoretical understanding of them in this space.

</details>


### [26] [Towards Optimal Valve Prescription for Transcatheter Aortic Valve Replacement (TAVR) Surgery: A Machine Learning Approach](https://arxiv.org/abs/2512.09198)
*Phevos Paschalidis,Vasiliki Stoumpou,Lisa Everest,Yu Ma,Talhat Azemi,Jawad Haider,Steven Zweibel,Eleftherios M. Protopapas,Jeff Mather,Maciej Tysarowski,George E. Sarris,Robert C. Hagberg,Howard L. Haronian,Dimitris Bertsimas*

Main category: cs.LG

TL;DR: 开发数据驱动的临床决策工具，通过整合多国多源数据，为经导管主动脉瓣置换术患者选择最优瓣膜类型，以降低永久起搏器植入风险。


<details>
  <summary>Details</summary>
Motivation: TAVR已成为治疗严重主动脉瓣狭窄的微创方法，但不同经导管心脏瓣膜的选择指南存在争议。永久起搏器植入是主要术后并发症，需要个性化瓣膜选择策略来降低风险。

Method: 整合美国和希腊患者数据，融合人口统计学、CT扫描和超声心动图三种数据源，采用叶级分析利用人群异质性，避免与不确定的反事实风险估计进行基准比较。

Result: 最终处方模型在美国内部人群和希腊外部验证队列中，分别比当前标准护理降低了26%和16%的永久起搏器植入率。

Conclusion: 这是首个统一的、个性化的经导管心脏瓣膜选择处方策略，通过数据驱动方法显著降低了TAVR术后永久起搏器植入风险。

Abstract: Transcatheter Aortic Valve Replacement (TAVR) has emerged as a minimally invasive treatment option for patients with severe aortic stenosis, a life-threatening cardiovascular condition. Multiple transcatheter heart valves (THV) have been approved for use in TAVR, but current guidelines regarding valve type prescription remain an active topic of debate. We propose a data-driven clinical support tool to identify the optimal valve type with the objective of minimizing the risk of permanent pacemaker implantation (PPI), a predominant postoperative complication. We synthesize a novel dataset that combines U.S. and Greek patient populations and integrates three distinct data sources (patient demographics, computed tomography scans, echocardiograms) while harmonizing differences in each country's record system. We introduce a leaf-level analysis to leverage population heterogeneity and avoid benchmarking against uncertain counterfactual risk estimates. The final prescriptive model shows a reduction in PPI rates of 26% and 16% compared with the current standard of care in our internal U.S. population and external Greek validation cohort, respectively. To the best of our knowledge, this work represents the first unified, personalized prescription strategy for THV selection in TAVR.

</details>


### [27] [LLMs for Analog Circuit Design Continuum (ACDC)](https://arxiv.org/abs/2512.09199)
*Yasaman Esfandiari,Jocelyn Rego,Austin Meyer,Jonathan Gallagher,Mia Levy*

Main category: cs.LG

TL;DR: 该研究探讨了大型语言模型在模拟电路设计中的可靠性和鲁棒性，发现模型对数据格式敏感、生成设计不稳定、泛化能力有限等关键挑战。


<details>
  <summary>Details</summary>
Motivation: 虽然LLMs和Transformer架构在各种自然语言任务中表现出色，但它们在真实工程领域（特别是需要领域专业知识、物理约束和结构化表示的模拟电路设计）的可靠性和鲁棒性尚未得到充分探索，这限制了它们在实际工程工作流程中的应用。

Method: 研究调查了LLMs在模拟电路设计中的适用性和一致性，重点关注AI辅助设计中人类保持在环的情况。研究了不同数据表示对模型行为的影响，比较了小型模型（如T5、GPT-2）与大型基础模型（如Mistral-7B、GPT-oss-20B）在不同训练条件下的表现。

Result: 研究结果突出了几个关键可靠性挑战：1）对数据格式的敏感性；2）生成设计的不稳定性；3）对未见电路配置的泛化能力有限。这些发现揭示了LLMs在复杂工程任务中作为增强人类能力工具的局限性。

Conclusion: 该研究为LLMs作为结构化、真实世界应用中可靠、可部署的基础模型的潜力提供了早期证据，同时指出了当前限制。研究结果为设计用于复杂工程任务的可靠AI辅助工具提供了重要见解，强调了在人类保持在环的情况下，模型可靠性、鲁棒性和可解释性的重要性。

Abstract: Large Language Models (LLMs) and transformer architectures have shown impressive reasoning and generation capabilities across diverse natural language tasks. However, their reliability and robustness in real-world engineering domains remain largely unexplored, limiting their practical utility in human-centric workflows. In this work, we investigate the applicability and consistency of LLMs for analog circuit design -- a task requiring domain-specific reasoning, adherence to physical constraints, and structured representations -- focusing on AI-assisted design where humans remain in the loop. We study how different data representations influence model behavior and compare smaller models (e.g., T5, GPT-2) with larger foundation models (e.g., Mistral-7B, GPT-oss-20B) under varying training conditions. Our results highlight key reliability challenges, including sensitivity to data format, instability in generated designs, and limited generalization to unseen circuit configurations. These findings provide early evidence on the limits and potential of LLMs as tools to enhance human capabilities in complex engineering tasks, offering insights into designing reliable, deployable foundation models for structured, real-world applications.

</details>


### [28] [Tensor-Compressed and Fully-Quantized Training of Neural PDE Solvers](https://arxiv.org/abs/2512.09202)
*Jinming Lu,Jiayi Tian,Yequan Zhao,Hai Li,Zheng Zhang*

Main category: cs.LG

TL;DR: 提出一个用于边缘设备的高效PINN训练框架，结合量化训练、Stein估计器和张量分解，实现显著的速度提升和能耗节省。


<details>
  <summary>Details</summary>
Motivation: PINNs在求解偏微分方程方面很有前景，但在资源受限的边缘设备上部署面临计算和内存开销大的挑战，主要源于高阶自动微分、密集张量操作和全精度运算。

Method: 提出一个集成全量化训练、基于Stein估计器的残差损失计算和TT分解权重压缩的框架。包括三个创新：1) 使用SMX格式的混合精度训练方法消除反向传播中的数据重复；2) 基于差分的Stein估计器量化方案缓解下溢；3) TT层的部分重构方案减少量化误差累积。还设计了PINTA硬件加速器。

Result: 在2-D Poisson、20-D HJB和100-D Heat方程上的实验表明，该框架达到与全精度基线相当或更好的精度，同时实现5.5x到83.5x的速度提升和159.6x到2324.1x的能耗节省。

Conclusion: 该工作实现了边缘设备上的实时PDE求解，为大规模能效科学计算铺平了道路。

Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a promising paradigm for solving partial differential equations (PDEs) by embedding physical laws into neural network training objectives. However, their deployment on resource-constrained platforms is hindered by substantial computational and memory overhead, primarily stemming from higher-order automatic differentiation, intensive tensor operations, and reliance on full-precision arithmetic. To address these challenges, we present a framework that enables scalable and energy-efficient PINN training on edge devices. This framework integrates fully quantized training, Stein's estimator (SE)-based residual loss computation, and tensor-train (TT) decomposition for weight compression. It contributes three key innovations: (1) a mixed-precision training method that use a square-block MX (SMX) format to eliminate data duplication during backpropagation; (2) a difference-based quantization scheme for the Stein's estimator that mitigates underflow; and (3) a partial-reconstruction scheme (PRS) for TT-Layers that reduces quantization-error accumulation. We further design PINTA, a precision-scalable hardware accelerator, to fully exploit the performance of the framework. Experiments on the 2-D Poisson, 20-D Hamilton-Jacobi-Bellman (HJB), and 100-D Heat equations demonstrate that the proposed framework achieves accuracy comparable to or better than full-precision, uncompressed baselines while delivering 5.5x to 83.5x speedups and 159.6x to 2324.1x energy savings. This work enables real-time PDE solving on edge devices and paves the way for energy-efficient scientific computing at scale.

</details>


### [29] [Contrastive Learning for Semi-Supervised Deep Regression with Generalized Ordinal Rankings from Spectral Seriation](https://arxiv.org/abs/2512.09267)
*Ce Wang,Weihang Dai,Hanru Bai,Xiaomeng Li*

Main category: cs.LG

TL;DR: 提出一种半监督对比回归方法，利用标记和未标记样本构建特征相似度矩阵，通过谱排序算法恢复未标记样本的序数关系，用于对比学习和预测监督。


<details>
  <summary>Details</summary>
Motivation: 现有对比回归方法高度依赖标签信息来恢复特征的序数关系，限制了在半监督回归中的应用。需要减少对昂贵标注的依赖，利用未标记数据提升回归模型的表示能力。

Method: 1) 在mini-batch中构建标记和未标记样本的特征相似度矩阵；2) 使用谱排序算法恢复未标记样本的序数关系；3) 利用标记样本提供正则化指导；4) 使用动态规划算法选择鲁棒特征；5) 将恢复的序数关系用于未标记样本的对比学习和预测监督。

Result: 在多个数据集上的实验表明，该方法超越了现有的最先进半监督深度回归方法，提供了理论保证和实证验证。

Conclusion: 该方法成功将对比回归扩展到半监督设置，通过利用未标记数据恢复序数关系，实现了更鲁棒的特征表示学习，减少了标注成本依赖。

Abstract: Contrastive learning methods enforce label distance relationships in feature space to improve representation capability for regression models. However, these methods highly depend on label information to correctly recover ordinal relationships of features, limiting their applications to semi-supervised regression. In this work, we extend contrastive regression methods to allow unlabeled data to be used in the semi-supervised setting, thereby reducing the dependence on costly annotations. Particularly we construct the feature similarity matrix with both labeled and unlabeled samples in a mini-batch to reflect inter-sample relationships, and an accurate ordinal ranking of involved unlabeled samples can be recovered through spectral seriation algorithms if the level of error is within certain bounds. The introduction of labeled samples above provides regularization of the ordinal ranking with guidance from the ground-truth label information, making the ranking more reliable. To reduce feature perturbations, we further utilize the dynamic programming algorithm to select robust features for the matrix construction. The recovered ordinal relationship is then used for contrastive learning on unlabeled samples, and we thus allow more data to be used for feature representation learning, thereby achieving more robust results. The ordinal rankings can also be used to supervise predictions on unlabeled samples, serving as an additional training signal. We provide theoretical guarantees and empirical verification through experiments on various datasets, demonstrating that our method can surpass existing state-of-the-art semi-supervised deep regression methods. Our code have been released on https://github.com/xmed-lab/CLSS.

</details>


### [30] [Goal inference with Rao-Blackwellized Particle Filters](https://arxiv.org/abs/2512.09269)
*Yixuan Wang,Dan P. Guralnik,Warren E. Dixon*

Main category: cs.LG

TL;DR: 提出一种基于Rao-Blackwellized粒子滤波的意图推断方法，通过分析线性高斯子结构提高采样效率，引入两种差异估计器，并量化对手恢复意图的能力。


<details>
  <summary>Details</summary>
Motivation: 从移动代理的噪声轨迹观测中推断其最终目标是一个基本估计问题，但现有方法在采样效率和准确性方面存在局限，需要更有效的意图推断框架。

Method: 使用Rao-Blackwellized粒子滤波变体，利用代理的闭环行为和可证明的稳定性特性，分析性地边缘化线性高斯子结构，仅更新粒子权重，提高采样效率。引入两种差异估计器：基于RBPF权重的高斯混合模型和限制在有效样本上的简化版本。

Result: 通过信息论泄漏度量量化对手恢复意图的能力，提供KL散度的可计算下界。实验显示对合规代理的意图恢复快速准确，简化估计器性能接近完整版本。

Conclusion: 该方法为移动代理意图推断提供了有效的框架，证明了RBPF在意图恢复中的优势，并为未来设计意图混淆控制器提供了基础。

Abstract: Inferring the eventual goal of a mobile agent from noisy observations of its trajectory is a fundamental estimation problem. We initiate the study of such intent inference using a variant of a Rao-Blackwellized Particle Filter (RBPF), subject to the assumption that the agent's intent manifests through closed-loop behavior with a state-of-the-art provable practical stability property. Leveraging the assumed closed-form agent dynamics, the RBPF analytically marginalizes the linear-Gaussian substructure and updates particle weights only, improving sample efficiency over a standard particle filter. Two difference estimators are introduced: a Gaussian mixture model using the RBPF weights and a reduced version confining the mixture to the effective sample. We quantify how well the adversary can recover the agent's intent using information-theoretic leakage metrics and provide computable lower bounds on the Kullback-Leibler (KL) divergence between the true intent distribution and RBPF estimates via Gaussian-mixture KL bounds. We also provide a bound on the difference in performance between the two estimators, highlighting the fact that the reduced estimator performs almost as well as the complete one. Experiments illustrate fast and accurate intent recovery for compliant agents, motivating future work on designing intent-obfuscating controllers.

</details>


### [31] [Hetero-SplitEE: Split Learning of Neural Networks with Early Exits for Heterogeneous IoT Devices](https://arxiv.org/abs/2512.09313)
*Yuki Oda,Yuta Ono,Hiroshi Nakamura,Hideki Takase*

Main category: cs.LG

TL;DR: 提出Hetero-SplitEE方法，允许异构物联网设备根据计算能力选择不同分割点，通过两种协作策略实现并行协作训练，在保持准确性的同时支持不同计算约束。


<details>
  <summary>Details</summary>
Motivation: 现有分割学习方法假设客户端同质性和统一分割点，这限制了在计算资源异构的真实物联网系统中的适用性。需要解决异构设备协作训练的问题。

Method: 提出Hetero-SplitEE方法，将异构早期退出集成到分层训练中，允许每个客户端根据计算能力选择不同的分割点（切割层）。提出两种协作训练策略：顺序策略（顺序训练客户端，共享服务器模型）和平均策略（并行客户端训练，定期跨层聚合）。

Result: 在CIFAR-10、CIFAR-100和STL-10数据集上使用ResNet-18进行实验，证明该方法在保持竞争性准确性的同时，能有效支持不同的计算约束。

Conclusion: Hetero-SplitEE方法使异构物联网设备能够协作训练共享深度神经网络，支持实际部署在异构物联网生态系统中的协作深度学习。

Abstract: The continuous scaling of deep neural networks has fundamentally transformed machine learning, with larger models demonstrating improved performance across diverse tasks. This growth in model size has dramatically increased the computational resources required for the training process. Consequently, distributed approaches, such as Federated Learning and Split Learning, have become essential paradigms for scalable deployment. However, existing Split Learning approaches assume client homogeneity and uniform split points across all participants. This critically limits their applicability to real-world IoT systems where devices exhibit heterogeneity in computational resources. To address this limitation, this paper proposes Hetero-SplitEE, a novel method that enables heterogeneous IoT devices to train a shared deep neural network in parallel collaboratively. By integrating heterogeneous early exits into hierarchical training, our approach allows each client to select distinct split points (cut layers) tailored to its computational capacity. In addition, we propose two cooperative training strategies, the Sequential strategy and the Averaging strategy, to facilitate this collaboration among clients with different split points. The Sequential strategy trains clients sequentially with a shared server model to reduce computational overhead. The Averaging strategy enables parallel client training with periodic cross-layer aggregation. Extensive experiments on CIFAR-10, CIFAR-100, and STL-10 datasets using ResNet-18 demonstrate that our method maintains competitive accuracy while efficiently supporting diverse computational constraints, enabling practical deployment of collaborative deep learning in heterogeneous IoT ecosystems.

</details>


### [32] [Self-Supervised Learning with Gaussian Processes](https://arxiv.org/abs/2512.09322)
*Yunshan Duan,Sinead Williamson*

Main category: cs.LG

TL;DR: 提出GPSSL方法，利用高斯过程进行自监督学习，无需显式定义正样本对，并能提供不确定性量化


<details>
  <summary>Details</summary>
Motivation: 传统自监督学习方法需要生成相似样本对，这在某些数据类型中很困难，且缺乏不确定性量化，在样本外预测中表现不佳

Method: 将高斯过程先验施加于表示学习，通过最小化损失函数获得广义贝叶斯后验，利用GP的协方差函数自然地将相似单元的表示拉近

Result: GPSSL在多个数据集上的分类和回归任务中，在准确性、不确定性量化和误差控制方面优于传统方法

Conclusion: GPSSL提供了一种无需显式正样本对的自监督学习框架，能够进行不确定性量化并传播到下游任务，与核PCA和VICReg相关但具有后验不确定性优势

Abstract: Self supervised learning (SSL) is a machine learning paradigm where models learn to understand the underlying structure of data without explicit supervision from labeled samples. The acquired representations from SSL have demonstrated useful for many downstream tasks including clustering, and linear classification, etc. To ensure smoothness of the representation space, most SSL methods rely on the ability to generate pairs of observations that are similar to a given instance. However, generating these pairs may be challenging for many types of data. Moreover, these methods lack consideration of uncertainty quantification and can perform poorly in out-of-sample prediction settings. To address these limitations, we propose Gaussian process self supervised learning (GPSSL), a novel approach that utilizes Gaussian processes (GP) models on representation learning. GP priors are imposed on the representations, and we obtain a generalized Bayesian posterior minimizing a loss function that encourages informative representations. The covariance function inherent in GPs naturally pulls representations of similar units together, serving as an alternative to using explicitly defined positive samples. We show that GPSSL is closely related to both kernel PCA and VICReg, a popular neural network-based SSL method, but unlike both allows for posterior uncertainties that can be propagated to downstream tasks. Experiments on various datasets, considering classification and regression tasks, demonstrate that GPSSL outperforms traditional methods in terms of accuracy, uncertainty quantification, and error control.

</details>


### [33] [Self Distillation Fine-Tuning of Protein Language Models Improves Versatility in Protein Design](https://arxiv.org/abs/2512.09329)
*Amin Tavakoli,Raswanth Murugan,Ozan Gokdemir,Arvind Ramanathan,Frances Arnold,Anima Anandkumar*

Main category: cs.LG

TL;DR: 提出一种简单通用的蛋白质语言模型快速监督微调方法，利用模型自身生成高质量训练数据，无需昂贵实验数据集，能生成更稳定、功能更好的新型酶序列。


<details>
  <summary>Details</summary>
Motivation: 蛋白质序列建模中，高质量标注数据获取困难，现有监督微调方法依赖昂贵的预编译实验数据集，限制了蛋白质语言模型在专业领域的应用。

Method: 结合轻量级筛选管道和领域特定过滤器，利用蛋白质语言模型自身构建高质量训练数据，进行快速监督微调，该方法与具体模型和蛋白质系统无关。

Result: 在色氨酸合酶家族上应用该方法，监督微调后的模型生成的序列不仅更新颖，而且在目标设计约束和新兴蛋白质性质指标上都表现出改进特性。

Conclusion: 该方法为蛋白质语言模型提供了一种简单有效的快速监督微调方案，能够生成更稳定、功能更好的新型酶序列，扩展了蛋白质序列空间的探索能力。

Abstract: Supervised fine-tuning (SFT) is a standard approach for adapting large language models to specialized domains, yet its application to protein sequence modeling and protein language models (PLMs) remains ad hoc. This is in part because high-quality annotated data are far more difficult to obtain for proteins than for natural language. We present a simple and general recipe for fast SFT of PLMs, designed to improve the fidelity, reliability, and novelty of generated protein sequences. Unlike existing approaches that require costly precompiled experimental datasets for SFT, our method leverages the PLM itself, integrating a lightweight curation pipeline with domain-specific filters to construct high-quality training data. These filters can independently refine a PLM's output and identify candidates for in vitro evaluation; when combined with SFT, they enable PLMs to generate more stable and functional enzymes, while expanding exploration into protein sequence space beyond natural variants. Although our approach is agnostic to both the choice of protein language model (PLM) and the protein system, we demonstrate its effectiveness with a genome-scale PLM (GenSLM) applied to the tryptophan synthase enzyme family. The supervised fine-tuned model generates sequences that are not only more novel but also display improved characteristics across both targeted design constraints and emergent protein property measures.

</details>


### [34] [Improved Physics-Driven Neural Network to Solve Inverse Scattering Problems](https://arxiv.org/abs/2512.09333)
*Yutong Du,Zicheng Liu,Bo Wu,Jingwei Kou,Hang Li,Changyou Li,Yali Zong,Bo Qi*

Main category: cs.LG

TL;DR: 提出改进的物理驱动神经网络框架IPDNN，用于电磁逆散射问题求解，引入GLOW激活函数、动态散射子区域识别策略和迁移学习，实现高精度、鲁棒且高效的电磁目标重建。


<details>
  <summary>Details</summary>
Motivation: 电磁逆散射问题在医学成像、无损检测等领域有重要应用，但传统方法存在收敛不稳定、计算成本高、泛化能力有限等问题。需要结合物理模型的可解释性和神经网络的实时推理能力，开发更高效准确的求解器。

Method: 1. 提出GLOW激活函数（高斯局部化振荡抑制窗口），稳定收敛并实现轻量级网络架构；2. 开发动态散射子区域识别策略，自适应细化计算域，避免漏检并降低计算成本；3. 引入迁移学习，扩展求解器到实际应用场景；4. 结合迭代算法的物理可解释性和神经网络的实时推理能力。

Result: 数值模拟和实验结果表明，所提出的求解器在重建精度、鲁棒性和效率方面均优于现有最先进方法，实现了更准确、更稳定的电磁目标重建。

Conclusion: IPDNN框架成功解决了电磁逆散射问题中的关键挑战，通过创新的激活函数、自适应区域识别和迁移学习策略，实现了物理可解释性与计算效率的良好平衡，为实际电磁成像应用提供了有效的解决方案。

Abstract: This paper presents an improved physics-driven neural network (IPDNN) framework for solving electromagnetic inverse scattering problems (ISPs). A new Gaussian-localized oscillation-suppressing window (GLOW) activation function is introduced to stabilize convergence and enable a lightweight yet accurate network architecture. A dynamic scatter subregion identification strategy is further developed to adaptively refine the computational domain, preventing missed detections and reducing computational cost. Moreover, transfer learning is incorporated to extend the solver's applicability to practical scenarios, integrating the physical interpretability of iterative algorithms with the real-time inference capability of neural networks. Numerical simulations and experimental results demonstrate that the proposed solver achieves superior reconstruction accuracy, robustness, and efficiency compared with existing state-of-the-art methods.

</details>


### [35] [Branching Strategies Based on Subgraph GNNs: A Study on Theoretical Promise versus Practical Reality](https://arxiv.org/abs/2512.09355)
*Junru Zhou,Yicheng Wang,Pan Li*

Main category: cs.LG

TL;DR: 节点锚定的子图GNN理论上能近似强分支评分，但实践中计算开销过大，导致实际求解时间比简单GNN和启发式方法更慢。


<details>
  <summary>Details</summary>
Motivation: 研究GNN在MILP分支选择中的应用，寻找表达能力和计算效率之间的平衡点。标准MPNN表达能力不足，高阶GNN计算成本过高，需要探索中间方案。

Method: 采用节点锚定的子图GNN作为理论中间方案，证明其表达能力虽低于3-WL但足以近似强分支评分，并在四个基准数据集上进行实证评估。

Result: 理论证明节点锚定子图GNN能近似强分支，但实证显示其O(n)复杂度导致内存瓶颈和更慢的求解时间，实际性能不如MPNN和启发式方法。

Conclusion: 对于MILP分支选择，当前表达性GNN的计算成本超过了决策质量提升的收益，未来研究需关注保持效率的表达性提升方法。

Abstract: Graph Neural Networks (GNNs) have emerged as a promising approach for ``learning to branch'' in Mixed-Integer Linear Programming (MILP). While standard Message-Passing GNNs (MPNNs) are efficient, they theoretically lack the expressive power to fully represent MILP structures. Conversely, higher-order GNNs (like 2-FGNNs) are expressive but computationally prohibitive. In this work, we investigate Subgraph GNNs as a theoretical middle ground. Crucially, while previous work [Chen et al., 2025] demonstrated that GNNs with 3-WL expressive power can approximate Strong Branching, we prove a sharper result: node-anchored Subgraph GNNs whose expressive power is strictly lower than 3-WL [Zhang et al., 2023] are sufficient to approximate Strong Branching scores. However, our extensive empirical evaluation on four benchmark datasets reveals a stark contrast between theory and practice. While node-anchored Subgraph GNNs theoretically offer superior branching decisions, their $O(n)$ complexity overhead results in significant memory bottlenecks and slower solving times than MPNNs and heuristics. Our results indicate that for MILP branching, the computational cost of expressive GNNs currently outweighs their gains in decision quality, suggesting that future research must focus on efficiency-preserving expressivity.

</details>


### [36] [A Granular Framework for Construction Material Price Forecasting: Econometric and Machine-Learning Approaches](https://arxiv.org/abs/2512.09360)
*Boge Lyu,Qianye Yin,Iris Denise Tommelein,Hanyang Liu,Karnamohit Ranka,Karthik Yeluripati,Junzhe Shi*

Main category: cs.LG

TL;DR: 该研究开发了一个基于CSI MasterFormat的建筑材料价格预测框架，通过整合原材料价格、商品指数和宏观经济指标等解释变量，显著提高了预测精度，其中LSTM模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 建筑材料价格的持续波动对成本估算、预算编制和项目交付构成重大风险，迫切需要开发更精细、可扩展的预测方法。

Method: 研究开发了一个预测框架，以CSI MasterFormat为目标数据结构，支持六位数章节级别的预测。框架整合了原材料价格、商品指数和宏观经济指标等解释变量，并评估了四种时间序列模型：LSTM、ARIMA、VECM和Chronos-Bolt，分别在仅使用CSI数据的基准配置和包含解释变量的扩展版本中进行测试。

Result: 结果表明，整合解释变量显著提高了所有模型的预测性能。LSTM模型表现最佳，RMSE值低至1.390，MAPE值为0.957，比传统ARIMA模型提高了高达59%的精度。在多个CSI分部的验证证实了框架的可扩展性。

Conclusion: 该研究提供了一个稳健的方法论，使业主和承包商能够改进预算实践，在确定性水平上实现更可靠的成本估算。

Abstract: The persistent volatility of construction material prices poses significant risks to cost estimation, budgeting, and project delivery, underscoring the urgent need for granular and scalable forecasting methods. This study develops a forecasting framework that leverages the Construction Specifications Institute (CSI) MasterFormat as the target data structure, enabling predictions at the six-digit section level and supporting detailed cost projections across a wide spectrum of building materials. To enhance predictive accuracy, the framework integrates explanatory variables such as raw material prices, commodity indexes, and macroeconomic indicators. Four time-series models, Long Short-Term Memory (LSTM), Autoregressive Integrated Moving Average (ARIMA), Vector Error Correction Model (VECM), and Chronos-Bolt, were evaluated under both baseline configurations (using CSI data only) and extended versions with explanatory variables. Results demonstrate that incorporating explanatory variables significantly improves predictive performance across all models. Among the tested approaches, the LSTM model consistently achieved the highest accuracy, with RMSE values as low as 1.390 and MAPE values of 0.957, representing improvements of up to 59\% over the traditional statistical time-series model, ARIMA. Validation across multiple CSI divisions confirmed the framework's scalability, while Division 06 (Wood, Plastics, and Composites) is presented in detail as a demonstration case. This research offers a robust methodology that enables owners and contractors to improve budgeting practices and achieve more reliable cost estimation at the Definitive level.

</details>


### [37] [KGOT: Unified Knowledge Graph and Optimal Transport Pseudo-Labeling for Molecule-Protein Interaction Prediction](https://arxiv.org/abs/2512.09365)
*Jiayu Qin,Zhengquan Luo,Guy Tadmor,Changyou Chen,David Zeevi,Zhiqiang Xu*

Main category: cs.LG

TL;DR: 提出一种利用最优传输生成伪标签的分子-蛋白质相互作用预测框架，通过整合多模态生物数据解决数据稀缺问题


<details>
  <summary>Details</summary>
Motivation: 现有MPI预测模型面临两大挑战：1) 标记分子-蛋白质对数据稀缺，限制了模型性能；2) 大多数方法仅依赖分子和蛋白质特征，忽略了基因、代谢通路等更广泛的生物背景信息

Method: 首先整合多种生物数据集（分子、蛋白质、基因和通路水平相互作用），然后开发基于最优传输的方法为未标记分子-蛋白质对生成高质量伪标签，利用已知相互作用的底层分布指导标签分配

Result: 在多个MPI数据集（包括虚拟筛选和蛋白质检索任务）上评估，相比最先进方法在预测准确性和零样本能力方面有显著提升

Conclusion: 该方法不仅改进了MPI预测，还为利用多样化生物数据源解决传统单模态或双模态学习受限问题提供了新范式，为计算生物学和药物发现领域的未来发展铺平道路

Abstract: Predicting molecule-protein interactions (MPIs) is a fundamental task in computational biology, with crucial applications in drug discovery and molecular function annotation. However, existing MPI models face two major challenges. First, the scarcity of labeled molecule-protein pairs significantly limits model performance, as available datasets capture only a small fraction of biological relevant interactions. Second, most methods rely solely on molecular and protein features, ignoring broader biological context such as genes, metabolic pathways, and functional annotations that could provide essential complementary information. To address these limitations, our framework first aggregates diverse biological datasets, including molecular, protein, genes and pathway-level interactions, and then develop an optimal transport-based approach to generate high-quality pseudo-labels for unlabeled molecule-protein pairs, leveraging the underlying distribution of known interactions to guide label assignment. By treating pseudo-labeling as a mechanism for bridging disparate biological modalities, our approach enables the effective use of heterogeneous data to enhance MPI prediction. We evaluate our framework on multiple MPI datasets including virtual screening tasks and protein retrieval tasks, demonstrating substantial improvements over state-of-the-art methods in prediction accuracies and zero shot ability across unseen interactions. Beyond MPI prediction, our approach provides a new paradigm for leveraging diverse biological data sources to tackle problems traditionally constrained by single- or bi-modal learning, paving the way for future advances in computational biology and drug discovery.

</details>


### [38] [CFLight: Enhancing Safety with Traffic Signal Control through Counterfactual Learning](https://arxiv.org/abs/2512.09368)
*Mingyuan Li,Chunyu Liu,Zhuojun Li,Xiao Liu,Guangsheng Yu,Bo Du,Jun Shen,Qiang Wu*

Main category: cs.LG

TL;DR: 提出CFLight框架，通过反事实学习增强交通信号控制中的安全性，在保持效率的同时显著减少碰撞事故


<details>
  <summary>Details</summary>
Motivation: 交通信号控制中现有强化学习方法过度关注效率而忽视安全性，且缺乏可解释性，需要平衡安全与效率的新方法

Method: 提出基于反事实学习的框架，构建结构因果模型预测不同行动结果，整合CF模块和X模块，开发CFLight算法实现近零碰撞控制策略

Result: 在真实世界和合成数据集上，CFLight相比传统RL方法和近期安全RL模型，显著减少碰撞并提升整体交通性能

Conclusion: CFLight为RL方法提供了一个通用且安全的框架，在交通信号控制中有效平衡安全与效率，并可扩展到其他领域

Abstract: Traffic accidents result in millions of injuries and fatalities globally, with a significant number occurring at intersections each year. Traffic Signal Control (TSC) is an effective strategy for enhancing safety at these urban junctures. Despite the growing popularity of Reinforcement Learning (RL) methods in optimizing TSC, these methods often prioritize driving efficiency over safety, thus failing to address the critical balance between these two aspects. Additionally, these methods usually need more interpretability. CounterFactual (CF) learning is a promising approach for various causal analysis fields. In this study, we introduce a novel framework to improve RL for safety aspects in TSC. This framework introduces a novel method based on CF learning to address the question: ``What if, when an unsafe event occurs, we backtrack to perform alternative actions, and will this unsafe event still occur in the subsequent period?'' To answer this question, we propose a new structure causal model to predict the result after executing different actions, and we propose a new CF module that integrates with additional ``X'' modules to promote safe RL practices. Our new algorithm, CFLight, which is derived from this framework, effectively tackles challenging safety events and significantly improves safety at intersections through a near-zero collision control strategy. Through extensive numerical experiments on both real-world and synthetic datasets, we demonstrate that CFLight reduces collisions and improves overall traffic performance compared to conventional RL methods and the recent safe RL model. Moreover, our method represents a generalized and safe framework for RL methods, opening possibilities for applications in other domains. The data and code are available in the github https://github.com/MJLee00/CFLight-Enhancing-Safety-with-Traffic-Signal-Control-through-Counterfactual-Learning.

</details>


### [39] [Are Hypervectors Enough? Single-Call LLM Reasoning over Knowledge Graphs](https://arxiv.org/abs/2512.09369)
*Yezi Liu,William Youngwoo Chung,Hanning Chen,Calvin Yeung,Mohsen Imani*

Main category: cs.LG

TL;DR: PathHD：基于超维度计算的轻量级知识图谱推理框架，用HDC替代神经路径评分，每个查询只需一次LLM调用，实现高效、可解释的KG-LLM推理。


<details>
  <summary>Details</summary>
Motivation: 现有基于知识图谱的LLM推理方法依赖重型神经编码器或重复LLM调用，导致高延迟、高GPU成本和不透明的决策，阻碍了可扩展的忠实部署。

Method: 提出PathHD框架：1）使用超维度计算将关系路径编码为块对角GHRR超向量；2）通过块状余弦相似度和Top-K剪枝对候选路径排序；3）执行一次性LLM裁决生成最终答案并引用支持路径。

Result: 在WebQSP、CWQ和GrailQA数据集上：1）每个查询只需一次LLM调用，达到或超过强神经基线的Hits@1性能；2）端到端延迟降低40-60%，GPU内存减少3-5倍；3）提供忠实、基于路径的推理依据，改善错误诊断和可控性。

Conclusion: 精心设计的HDC表示为高效KG-LLM推理提供了实用基础，在准确性、效率和可解释性之间实现了有利的权衡。

Abstract: Recent advances in large language models (LLMs) have enabled strong reasoning over both structured and unstructured knowledge. When grounded on knowledge graphs (KGs), however, prevailing pipelines rely on heavy neural encoders to embed and score symbolic paths or on repeated LLM calls to rank candidates, leading to high latency, GPU cost, and opaque decisions that hinder faithful, scalable deployment. We propose PathHD, a lightweight and encoder-free KG reasoning framework that replaces neural path scoring with hyperdimensional computing (HDC) and uses only a single LLM call per query. PathHD encodes relation paths into block-diagonal GHRR hypervectors, ranks candidates with blockwise cosine similarity and Top-K pruning, and then performs a one-shot LLM adjudication to produce the final answer together with cited supporting paths. Technically, PathHD is built on three ingredients: (i) an order-aware, non-commutative binding operator for path composition, (ii) a calibrated similarity for robust hypervector-based retrieval, and (iii) a one-shot adjudication step that preserves interpretability while eliminating per-path LLM scoring. On WebQSP, CWQ, and the GrailQA split, PathHD (i) attains comparable or better Hits@1 than strong neural baselines while using one LLM call per query; (ii) reduces end-to-end latency by $40-60\%$ and GPU memory by $3-5\times$ thanks to encoder-free retrieval; and (iii) delivers faithful, path-grounded rationales that improve error diagnosis and controllability. These results indicate that carefully designed HDC representations provide a practical substrate for efficient KG-LLM reasoning, offering a favorable accuracy-efficiency-interpretability trade-off.

</details>


### [40] [Rates and architectures for learning geometrically non-trivial operators](https://arxiv.org/abs/2512.09376)
*T. Mitchell Roddenberry,Leo Tzou,Ivan Dokmanić,Maarten V. de Hoop,Richard G. Baraniuk*

Main category: cs.LG

TL;DR: 该论文将算子学习理论扩展到包含双纤维化变换（几何积分算子），证明这类算子不受维度诅咒影响，误差随训练样本数超代数衰减，并提出基于水平集方法的交叉注意力架构能有效学习这类变换。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在恢复椭圆算子等简单几何算子时表现出数据高效性，但科学机器学习常涉及波、对流、流体动力学等传播奇异性问题。需要扩展学习理论以包含双纤维化变换这类几何积分算子。

Method: 将学习理论扩展到双纤维化变换（包括广义Radon和测地线射线变换），证明其误差衰减性质，并提出基于水平集方法的交叉注意力架构来显式编码几何结构。

Result: 证明双纤维化变换类算子不受维度诅咒影响，误差随训练样本数超代数衰减（快于任何固定幂次）。提出的架构具有通用性、稳定性，并能从极少训练样本中学习双纤维化变换。

Conclusion: 该研究扩展了科学机器学习中算子学习的理论框架，为处理传播奇异性问题提供了理论基础和有效架构，推动了科学机器学习理论的发展。

Abstract: Deep learning methods have proven capable of recovering operators between high-dimensional spaces, such as solution maps of PDEs and similar objects in mathematical physics, from very few training samples. This phenomenon of data-efficiency has been proven for certain classes of elliptic operators with simple geometry, i.e., operators that do not change the domain of the function or propagate singularities. However, scientific machine learning is commonly used for problems that do involve the propagation of singularities in a priori unknown ways, such as waves, advection, and fluid dynamics. In light of this, we expand the learning theory to include double fibration transforms--geometric integral operators that include generalized Radon and geodesic ray transforms. We prove that this class of operators does not suffer from the curse of dimensionality: the error decays superalgebraically, that is, faster than any fixed power of the reciprocal of the number of training samples. Furthermore, we investigate architectures that explicitly encode the geometry of these transforms, demonstrating that an architecture reminiscent of cross-attention based on levelset methods yields a parameterization that is universal, stable, and learns double fibration transforms from very few training examples. Our results contribute to a rapidly-growing line of theoretical work on learning operators for scientific machine learning.

</details>


### [41] [Federated Distillation Assisted Vehicle Edge Caching Scheme Based on Lightweight DDPM](https://arxiv.org/abs/2512.09378)
*Xun Li,Qiong Wu,Pingyi Fan,Kezhi Wang,Wen Chen,Khaled B. Letaief*

Main category: cs.LG

TL;DR: 提出基于轻量级去噪扩散概率模型(LDPM)的联邦蒸馏辅助车辆边缘缓存方案，解决传统联邦学习的通信开销大和车辆移动性导致的训练失败问题。


<details>
  <summary>Details</summary>
Motivation: 车辆边缘缓存能显著降低车辆用户访问内容的延迟，但需要准确预测用户感兴趣内容而不暴露隐私。传统联邦学习虽然能保护隐私，但频繁模型传输带来巨大通信开销，且车辆可能在训练完成前离开RSU覆盖范围导致训练失败。

Method: 提出基于轻量级去噪扩散概率模型(LDPM)的联邦蒸馏辅助车辆边缘缓存方案。该方法结合联邦蒸馏技术，减少模型传输需求，同时利用LDPM处理车辆移动性和通信限制。

Result: 仿真结果表明，所提方案对车辆速度变化具有良好的鲁棒性，显著降低了通信开销，并提高了缓存命中率。

Conclusion: 提出的联邦蒸馏辅助车辆边缘缓存方案有效解决了传统联邦学习在车辆边缘缓存中的通信开销和移动性问题，实现了隐私保护下的高效内容预测和缓存。

Abstract: Vehicle edge caching is a promising technology that can significantly reduce the latency for vehicle users (VUs) to access content by pre-caching user-interested content at edge nodes. It is crucial to accurately predict the content that VUs are interested in without exposing their privacy. Traditional federated learning (FL) can protect user privacy by sharing models rather than raw data. However, the training of FL requires frequent model transmission, which can result in significant communication overhead. Additionally, vehicles may leave the road side unit (RSU) coverage area before training is completed, leading to training failures. To address these issues, in this letter, we propose a federated distillation-assisted vehicle edge caching scheme based on lightweight denoising diffusion probabilistic model (LDPM). The simulation results demonstrate that the proposed vehicle edge caching scheme has good robustness to variations in vehicle speed, significantly reducing communication overhead and improving cache hit percentage.

</details>


### [42] [Towards Resilient Transportation: A Conditional Transformer for Accident-Informed Traffic Forecasting](https://arxiv.org/abs/2512.09398)
*Hongjun Wang,Jiawei Yong,Jiawei Wang,Shintaro Fukushima,Renhe Jiang*

Main category: cs.LG

TL;DR: 提出ConFormer框架，整合交通事故和管制数据，通过图传播和引导归一化层动态调整时空关系，在东京和加州数据集上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 交通预测面临外部因素（如交通事故、交通管制）的复杂影响，现有模型因数据整合有限而忽视这些因素，导致预测准确性受限。

Method: 1) 构建包含交通事故和管制数据的东京和加州交通数据集；2) 提出ConFormer框架，结合图传播和引导归一化层，基于历史模式动态调整时空节点关系。

Result: ConFormer在预测性能和效率上均超越当前最优的STAEFormer，计算成本更低、参数需求更少，在多个指标上优于主流时空基线模型。

Conclusion: ConFormer通过有效整合外部因素数据，显著提升交通预测准确性，为交通预测研究提供了有前景的新方向。

Abstract: Traffic prediction remains a key challenge in spatio-temporal data mining, despite progress in deep learning. Accurate forecasting is hindered by the complex influence of external factors such as traffic accidents and regulations, often overlooked by existing models due to limited data integration. To address these limitations, we present two enriched traffic datasets from Tokyo and California, incorporating traffic accident and regulation data. Leveraging these datasets, we propose ConFormer (Conditional Transformer), a novel framework that integrates graph propagation with guided normalization layer. This design dynamically adjusts spatial and temporal node relationships based on historical patterns, enhancing predictive accuracy. Our model surpasses the state-of-the-art STAEFormer in both predictive performance and efficiency, achieving lower computational costs and reduced parameter demands. Extensive evaluations demonstrate that ConFormer consistently outperforms mainstream spatio-temporal baselines across multiple metrics, underscoring its potential to advance traffic prediction research.

</details>


### [43] [Black-Box Behavioral Distillation Breaks Safety Alignment in Medical LLMs](https://arxiv.org/abs/2512.09403)
*Sohely Jahan,Ruimin Sun*

Main category: cs.LG

TL;DR: 通过黑盒蒸馏攻击，仅用输出级访问就能复制安全对齐医疗大语言模型的功能，同时剥离其安全机制，揭示功能-伦理差距


<details>
  <summary>Details</summary>
Motivation: 随着医疗大语言模型在临床工作流中的集成，对其对齐鲁棒性和安全性的担忧日益增加。先前研究主要关注分类模型或记忆泄漏，而安全对齐的生成式医疗大语言模型的脆弱性尚未充分探索

Method: 提出黑盒蒸馏攻击：向Meditron-7B发出48,000条指令查询，收集25,000个良性指令-响应对，在零对齐监督设置下通过参数高效的LoRA微调LLaMA3 8B代理模型。开发动态对抗评估框架，结合基于生成查询的有害提示生成、验证器过滤、类别化失败分析和自适应随机搜索越狱攻击

Result: 仅花费12美元，代理模型在良性输入上保持高保真度，同时对86%的对抗性提示产生不安全完成，远超Meditron-7B（66%）和未调优基础模型（46%）。揭示了明显的功能-伦理差距：任务效用转移而对齐崩溃

Conclusion: 仅基于良性数据的黑盒蒸馏暴露了实际且未被充分认识的威胁：攻击者可以廉价复制医疗大语言模型能力同时剥离安全机制，强调需要提取感知的安全监控。提出了分层防御系统作为黑盒部署中实时对齐漂移的原型检测器

Abstract: As medical large language models (LLMs) become increasingly integrated into clinical workflows, concerns around alignment robustness, and safety are escalating. Prior work on model extraction has focused on classification models or memorization leakage, leaving the vulnerability of safety-aligned generative medical LLMs underexplored.
  We present a black-box distillation attack that replicates the domain-specific reasoning of safety-aligned medical LLMs using only output-level access. By issuing 48,000 instruction queries to Meditron-7B and collecting 25,000 benign instruction response pairs, we fine-tune a LLaMA3 8B surrogate via parameter efficient LoRA under a zero-alignment supervision setting, requiring no access to model weights, safety filters, or training data. With a cost of $12, the surrogate achieves strong fidelity on benign inputs while producing unsafe completions for 86% of adversarial prompts, far exceeding both Meditron-7B (66%) and the untuned base model (46%). This reveals a pronounced functional-ethical gap, task utility transfers, while alignment collapses. To analyze this collapse, we develop a dynamic adversarial evaluation framework combining Generative Query (GQ)-based harmful prompt generation, verifier filtering, category-wise failure analysis, and adaptive Random Search (RS) jailbreak attacks. We also propose a layered defense system, as a prototype detector for real-time alignment drift in black-box deployments.
  Our findings show that benign-only black-box distillation exposes a practical and under-recognized threat: adversaries can cheaply replicate medical LLM capabilities while stripping safety mechanisms, underscoring the need for extraction-aware safety monitoring.

</details>


### [44] [Cauchy-Schwarz Fairness Regularizer](https://arxiv.org/abs/2512.09467)
*Yezi Liu,Hanning Chen,Wenjun Huang,Yang Ni,Mohsen Imani*

Main category: cs.LG

TL;DR: 提出基于柯西-施瓦茨散度的公平性正则化器，通过惩罚敏感群体间预测分布的差异来提升模型公平性，相比现有方法具有更紧的泛化界和更稳定的性能。


<details>
  <summary>Details</summary>
Motivation: 现有公平性正则化器基于不同的距离度量和设计选择，导致行为难以解释且性能在不同任务中不一致。需要研究什么特性构成一个好的公平性正则化器。

Method: 将现有方法分为三类：跨敏感群体匹配预测统计量、对齐潜在表示、直接最小化预测与敏感属性间的依赖性。基于理想距离度量的特性，提出柯西-施瓦茨公平性正则化器，惩罚敏感群体间预测分布的经验CS散度。

Result: 在四个表格基准和一个图像数据集上的实验表明，CS正则化器在保持竞争性准确率的同时，持续改善人口统计均等和机会均等指标，相比先前正则化器在超参数设置下实现更稳定的效用-公平性权衡。

Conclusion: 柯西-施瓦茨散度是构建公平性正则化器的有效距离度量，具有紧的泛化界、对尺度差异的鲁棒性以及处理任意预测分布的能力，为机器学习中的群体公平性提供了更一致和可解释的解决方案。

Abstract: Group fairness in machine learning is often enforced by adding a regularizer that reduces the dependence between model predictions and sensitive attributes. However, existing regularizers are built on heterogeneous distance measures and design choices, which makes their behavior hard to reason about and their performance inconsistent across tasks. This raises a basic question: what properties make a good fairness regularizer? We address this question by first organizing existing in-process methods into three families: (i) matching prediction statistics across sensitive groups, (ii) aligning latent representations, and (iii) directly minimizing dependence between predictions and sensitive attributes. Through this lens, we identify desirable properties of the underlying distance measure, including tight generalization bounds, robustness to scale differences, and the ability to handle arbitrary prediction distributions. Motivated by these properties, we propose a Cauchy-Schwarz (CS) fairness regularizer that penalizes the empirical CS divergence between prediction distributions conditioned on sensitive groups. Under a Gaussian comparison, we show that CS divergence yields a tighter bound than Kullback-Leibler divergence, Maximum Mean Discrepancy, and the mean disparity used in Demographic Parity, and we discuss how these advantages translate to a distribution-free, kernel-based estimator that naturally extends to multiple sensitive attributes. Extensive experiments on four tabular benchmarks and one image dataset demonstrate that the proposed CS regularizer consistently improves Demographic Parity and Equal Opportunity metrics while maintaining competitive accuracy, and achieves a more stable utility-fairness trade-off across hyperparameter settings compared to prior regularizers.

</details>


### [45] [Representation Invariance and Allocation: When Subgroup Balance Matters](https://arxiv.org/abs/2512.09496)
*Anissa Alloula,Charles Jones,Zuzanna Wakefield-Skorniewska,Francesco Quinzan,Bartłomiej Papież*

Main category: cs.LG

TL;DR: 本文提出"潜在分离假说"，认为微调模型对子群表示的依赖程度由预训练模型潜在空间中子群的分离程度决定，挑战了传统的数据平衡假设。


<details>
  <summary>Details</summary>
Motivation: 训练数据中人口统计群体的不平衡表示会影响模型在不同群体间的泛化能力。传统做法假设平衡子群表示能优化性能，但近期实证结果与此矛盾：在某些情况下，不平衡数据分布反而改善子群性能，而在其他情况下，即使训练数据完全缺失某个子群，其性能也不受影响。

Method: 对四个视觉和语言模型进行系统研究，通过改变训练数据组成来表征子群性能对数据平衡的敏感性。提出潜在分离假说，认为部分微调模型对子群表示的依赖程度由预训练模型潜在空间中子群的分离程度决定。对该假说进行形式化、理论分析，并进行实证验证。

Result: 验证了潜在分离假说，表明子群性能对数据平衡的敏感性确实与潜在空间中的分离程度相关。当子群在潜在空间中高度分离时，平衡数据分布对性能影响显著；当子群在潜在空间中重叠时，数据平衡的影响较小。

Conclusion: 挑战了传统的数据平衡假设，提出潜在分离假说为理解子群性能与数据表示之间的关系提供了新视角。该分析可实际应用于基础模型微调，通过量化潜在子群分离程度来指导数据收集和平衡决策。

Abstract: Unequal representation of demographic groups in training data poses challenges to model generalisation across populations. Standard practice assumes that balancing subgroup representation optimises performance. However, recent empirical results contradict this assumption: in some cases, imbalanced data distributions actually improve subgroup performance, while in others, subgroup performance remains unaffected by the absence of an entire subgroup during training. We conduct a systematic study of subgroup allocation across four vision and language models, varying training data composition to characterise the sensitivity of subgroup performance to data balance. We propose the latent separation hypothesis, which states that a partially fine-tuned model's dependence on subgroup representation is determined by the degree of separation between subgroups in the latent space of the pre-trained model. We formalise this hypothesis, provide theoretical analysis, and validate it empirically. Finally, we present a practical application to foundation model fine-tuning, demonstrating that quantitative analysis of latent subgroup separation can inform data collection and balancing decisions.

</details>


### [46] [Contextual Dynamic Pricing with Heterogeneous Buyers](https://arxiv.org/abs/2512.09513)
*Thodoris Lykouris,Sloan Nietert,Princewill Okoroafor,Chara Podimata,Julian Zimmert*

Main category: cs.LG

TL;DR: 研究异构买家群体的上下文动态定价问题，提出基于乐观后验采样的算法，达到近乎最优的遗憾界。


<details>
  <summary>Details</summary>
Motivation: 现有动态定价研究大多假设买家类型同质，而现实世界中买家估值类型通常来自未知的有限支撑分布。本文旨在解决异构买家群体下的上下文动态定价问题。

Method: 提出基于乐观后验采样的上下文定价算法，利用买家类型分布的有限支撑特性。对于非上下文情况，设计了方差感知的缩放算法。

Result: 上下文算法达到 $\widetilde{O}(K_{\star}\sqrt{dT})$ 的遗憾界，在 $d$ 和 $T$ 维度上达到近乎最优。非上下文算法在 $K_{\star}$ 依赖上达到最优。

Conclusion: 成功解决了异构买家群体的上下文动态定价问题，提出了高效算法并证明了理论最优性，为实际定价系统提供了理论基础。

Abstract: We initiate the study of contextual dynamic pricing with a heterogeneous population of buyers, where a seller repeatedly posts prices (over $T$ rounds) that depend on the observable $d$-dimensional context and receives binary purchase feedback. Unlike prior work assuming homogeneous buyer types, in our setting the buyer's valuation type is drawn from an unknown distribution with finite support size $K_{\star}$. We develop a contextual pricing algorithm based on optimistic posterior sampling with regret $\widetilde{O}(K_{\star}\sqrt{dT})$, which we prove to be tight in $d$ and $T$ up to logarithmic terms. Finally, we refine our analysis for the non-contextual pricing case, proposing a variance-aware zooming algorithm that achieves the optimal dependence on $K_{\star}$.

</details>


### [47] [QuanvNeXt: An end-to-end quanvolutional neural network for EEG-based detection of major depressive disorder](https://arxiv.org/abs/2512.09517)
*Nabil Anan Orka,Ehtashamul Haque,Maftahul Jannat,Md Abdul Awal,Mohammad Ali Moni*

Main category: cs.LG

TL;DR: QuanvNeXt：用于EEG抑郁症诊断的端到端全量子卷积模型，通过Cross Residual块减少特征同质性并增强跨特征关系，在两个数据集上达到93.1%准确率和97.2% AUC-ROC，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 开发一个高效可靠的基于EEG的抑郁症诊断模型，解决现有方法在特征同质性、参数效率和诊断准确性方面的不足。

Method: 提出QuanvNeXt模型，包含新颖的Cross Residual块，该块能减少特征同质性并增强跨特征关系，同时保持参数效率。模型采用端到端全量子卷积架构。

Result: 在两个开源数据集上平均准确率93.1%，平均AUC-ROC 97.2%，优于InceptionTime等SOTA基线。不确定性分析显示即使在最高扰动(ε=0.1)下，ECE分数保持较低(0.0436)到中等(0.1159)。可解释性分析确认模型能有效识别和学习区分健康对照与抑郁症的频谱时间模式。

Conclusion: QuanvNeXt为基于EEG的抑郁症诊断建立了一个高效可靠的方法，在准确性、鲁棒性和可解释性方面均表现优异。

Abstract: This study presents QuanvNeXt, an end-to-end fully quanvolutional model for EEG-based depression diagnosis. QuanvNeXt incorporates a novel Cross Residual block, which reduces feature homogeneity and strengthens cross-feature relationships while retaining parameter efficiency. We evaluated QuanvNeXt on two open-source datasets, where it achieved an average accuracy of 93.1% and an average AUC-ROC of 97.2%, outperforming state-of-the-art baselines such as InceptionTime (91.7% accuracy, 95.9% AUC-ROC). An uncertainty analysis across Gaussian noise levels demonstrated well-calibrated predictions, with ECE scores remaining low (0.0436, Dataset 1) to moderate (0.1159, Dataset 2) even at the highest perturbation (ε = 0.1). Additionally, a post-hoc explainable AI analysis confirmed that QuanvNeXt effectively identifies and learns spectrotemporal patterns that distinguish between healthy controls and major depressive disorder. Overall, QuanvNeXt establishes an efficient and reliable approach for EEG-based depression diagnosis.

</details>


### [48] [Latent-Autoregressive GP-VAE Language Model](https://arxiv.org/abs/2512.09535)
*Yves Ruffenach*

Main category: cs.LG

TL;DR: 提出了一种基于高斯过程的完全潜在自回归方案，集成到变分自编码器中，将序列动态从观测空间转移到连续潜在空间，同时通过非自回归解码器保持并行语言生成。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型中时间结构是否可以通过潜在空间的概率几何来支持，而不是依赖显式的神经操作。将序列动态转移到连续潜在空间，同时保持语言生成的并行性。

Method: 提出完全潜在自回归方案：1）使用因果高斯过程先验；2）结构化摊销后验；3）基于正则化ELBO的训练协议；4）非自回归解码器实现并行语言生成。

Result: 在概念验证框架中的实证评估表明：1）模型可以稳定训练；2）序列采样和并行采样变体表现一致；3）部分时间结构可以通过潜在空间的概率几何来支持。

Conclusion: 语言模型中的部分时间结构可以由潜在空间的概率几何支持，而不完全依赖显式神经操作。该方法为序列建模提供了新的视角，将序列动态与生成过程解耦。

Abstract: We investigate a fully Latent AutoRegressive scheme based on a Gaussian Process (GP) integrated into a Variational Autoencoder (VAE). In this setting, sequential dynamics are transferred from the observation space to a continuous latent space, while linguistic generation remains parallel through a non-autoregressive decoder. We present a complete methodological formulation, including a causal GP prior, a structured amortized posterior, and a training protocol based on a regularized ELBO. Empirical evaluation, conducted within a deliberately constrained proof-of-concept (POC) framework, shows that the model can be trained stably and that the sequential and parallel sampling variants exhibit consistent behavior. Overall, the results suggest that part of the temporal structure in a language model can be supported by the probabilistic geometry of the latent space rather than by explicit neural operations.

</details>


### [49] [Stanford Sleep Bench: Evaluating Polysomnography Pre-training Methods for Sleep Foundation Models](https://arxiv.org/abs/2512.09591)
*Magnus Ruud Kjaer,Rahul Thapa,Gauri Ganjoo,Hyatt Moore,Poul Joergen Jennum,Brandon M. Westover,James Zou,Emmanuel Mignot,Bryan He,Andreas Brink-Kjaer*

Main category: cs.LG

TL;DR: 斯坦福睡眠基准是一个大规模多导睡眠图数据集，包含17,467条记录和13个临床疾病预测任务，用于系统评估自监督表示学习方法在睡眠分析中的表现。


<details>
  <summary>Details</summary>
Motivation: 多导睡眠图产生大量多模态临床数据，但睡眠基础模型发展面临两个关键限制：缺乏共享数据集和基准，以及缺乏对自监督学习方法在睡眠相关任务上的系统评估。

Method: 引入斯坦福睡眠基准数据集，包含17,467条记录（超过163,000小时），涵盖13个临床疾病预测任务和经典睡眠任务。系统评估多种自监督预训练方法在四个下游任务上的表现。

Result: 多种预训练方法在睡眠分期、呼吸暂停诊断和年龄估计任务上表现相当。但在死亡率和疾病预测任务上，对比学习显著优于其他方法，且预训练收敛更快。

Conclusion: 斯坦福睡眠基准填补了睡眠研究的数据集和评估空白，对比学习在临床预测任务上表现优异。将发布数据集、预训练模型权重、训练管道和评估代码以促进可重复性和睡眠研究进展。

Abstract: Polysomnography (PSG), the gold standard test for sleep analysis, generates vast amounts of multimodal clinical data, presenting an opportunity to leverage self-supervised representation learning (SSRL) for pre-training foundation models to enhance sleep analysis. However, progress in sleep foundation models is hindered by two key limitations: (1) the lack of a shared dataset and benchmark with diverse tasks for training and evaluation, and (2) the absence of a systematic evaluation of SSRL approaches across sleep-related tasks. To address these gaps, we introduce Stanford Sleep Bench, a large-scale PSG dataset comprising 17,467 recordings totaling over 163,000 hours from a major sleep clinic, including 13 clinical disease prediction tasks alongside canonical sleep-related tasks such as sleep staging, apnea diagnosis, and age estimation. We systematically evaluate SSRL pre-training methods on Stanford Sleep Bench, assessing downstream performance across four tasks: sleep staging, apnea diagnosis, age estimation, and disease and mortality prediction. Our results show that multiple pretraining methods achieve comparable performance for sleep staging, apnea diagnosis, and age estimation. However, for mortality and disease prediction, contrastive learning significantly outperforms other approaches while also converging faster during pretraining. To facilitate reproducibility and advance sleep research, we will release Stanford Sleep Bench along with pretrained model weights, training pipelines, and evaluation code.

</details>


### [50] [Semantic-Aware Cooperative Communication and Computation Framework in Vehicular Networks](https://arxiv.org/abs/2512.09621)
*Jingbo Zhang,Maoxin Ji,Qiong Wu,Pingyi Fan,Kezhi Wang,Wen Chen*

Main category: cs.LG

TL;DR: 提出基于参数分布噪声的多智能体近端策略优化任务卸载优化方法（MAPPO-PDN）和线性规划的三方协作语义通信框架，用于车联网边缘计算场景


<details>
  <summary>Details</summary>
Motivation: 车联网中语义通信与车载边缘计算结合能提供高效的任务处理，但高速公路场景下的任务卸载优化面临挑战，需要同时考虑任务延迟和语义符号数量

Method: 提出三方协作语义通信框架，将混合整数非线性规划问题分解为两个子问题：1）使用MAPPO-PDN优化语义符号数量；2）使用线性规划优化卸载比例

Result: 仿真结果表明该方案性能优于其他对比算法

Conclusion: TCSC框架结合MAPPO-PDN和线性规划能有效优化车联网语义通信任务卸载，在高速公路场景下实现更好的性能

Abstract: Semantic Communication (SC) combined with Vehicular edge computing (VEC) provides an efficient edge task processing paradigm for Internet of Vehicles (IoV). Focusing on highway scenarios, this paper proposes a Tripartite Cooperative Semantic Communication (TCSC) framework, which enables Vehicle Users (VUs) to perform semantic task offloading via Vehicle-to-Infrastructure (V2I) and Vehicle-to-Vehicle (V2V) communications. Considering task latency and the number of semantic symbols, the framework constructs a Mixed-Integer Nonlinear Programming (MINLP) problem, which is transformed into two subproblems. First, we innovatively propose a multi-agent proximal policy optimization task offloading optimization method based on parametric distribution noise (MAPPO-PDN) to solve the optimization problem of the number of semantic symbols; second, linear programming (LP) is used to solve offloading ratio. Simulations show that performance of this scheme is superior to that of other algorithms.

</details>


### [51] [Membership and Dataset Inference Attacks on Large Audio Generative Models](https://arxiv.org/abs/2512.09654)
*Jakub Proboszcz,Paweł Kochanski,Karol Korszun,Donato Crisostomi,Giorgio Strano,Emanuele Rodolà,Kamil Deja,Jan Dubinski*

Main category: cs.LG

TL;DR: 该论文研究了生成音频模型的版权保护问题，发现传统的成员推理攻击在大规模数据集上效果有限，但数据集推理方法通过聚合多个样本的证据，能有效检测艺术家的作品是否被用于模型训练。


<details>
  <summary>Details</summary>
Motivation: 随着生成音频模型（基于扩散和自回归架构）在质量和表现力上的快速进步，引发了紧迫的版权问题。这些模型通常在大量艺术和商业作品上进行训练，需要一种可靠的方法来验证艺术家的材料是否被包含在训练数据中，以便版权持有者保护其内容。

Method: 研究通过成员推理攻击（MIA）来验证特定音频样本是否属于训练集，但发现该方法在大规模多样化数据集上效果有限。随后转向数据集推理（DI）方法，该方法聚合多个样本的成员证据，借鉴了文本和视觉领域的先前工作，应用于音频领域。

Result: 实证结果表明：成员推理攻击在规模上效果有限，因为在大规模多样化数据集上，单个样本的成员信号很弱。然而，数据集推理在音频领域是成功的，能够通过聚合多个样本的证据，更实际地评估艺术家的作品是否对模型训练有贡献。

Conclusion: 数据集推理为大型音频生成模型时代的版权保护和数据集问责提供了一个有前景的方向。该方法比传统的成员推理攻击更实用，能够帮助艺术家和媒体所有者验证其作品集合是否被用于模型训练。

Abstract: Generative audio models, based on diffusion and autoregressive architectures, have advanced rapidly in both quality and expressiveness. This progress, however, raises pressing copyright concerns, as such models are often trained on vast corpora of artistic and commercial works. A central question is whether one can reliably verify if an artist's material was included in training, thereby providing a means for copyright holders to protect their content. In this work, we investigate the feasibility of such verification through membership inference attacks (MIA) on open-source generative audio models, which attempt to determine whether a specific audio sample was part of the training set. Our empirical results show that membership inference alone is of limited effectiveness at scale, as the per-sample membership signal is weak for models trained on large and diverse datasets. However, artists and media owners typically hold collections of works rather than isolated samples. Building on prior work in text and vision domains, in this work we focus on dataset inference (DI), which aggregates diverse membership evidence across multiple samples. We find that DI is successful in the audio domain, offering a more practical mechanism for assessing whether an artist's works contributed to model training. Our results suggest DI as a promising direction for copyright protection and dataset accountability in the era of large audio generative models.

</details>


### [52] [Drawback of Enforcing Equivariance and its Compensation via the Lens of Expressive Power](https://arxiv.org/abs/2512.09673)
*Yuzhu Chen,Tian Qin,Xinmei Tian,Fengxiang He,Dacheng Tao*

Main category: cs.LG

TL;DR: 本文研究等变神经网络（特别是2层ReLU网络）的表达能力，发现等变约束会限制表达能力，但可通过扩大模型规模来补偿，且等变网络即使模型更大仍具有更低复杂度假设空间，从而有更好的泛化性。


<details>
  <summary>Details</summary>
Motivation: 等变神经网络通过编码对称性作为归纳偏置在许多领域取得了良好性能，但其表达能力尚未得到很好理解。本文旨在研究等变约束对网络表达能力的影响。

Method: 聚焦于2层ReLU网络，通过检查ReLU网络的边界超平面和通道向量，构建示例展示等变约束如何限制表达能力，并分析通过扩大模型规模来补偿这种限制的方法。

Result: 等变约束确实会严格限制表达能力，但这种限制可以通过扩大模型规模来补偿。更重要的是，即使模型规模更大，等变网络对应的假设空间复杂度更低，表明其具有更好的泛化能力。

Conclusion: 等变神经网络虽然因对称性约束而表达能力受限，但通过适当扩大模型规模可以弥补这一缺陷，同时由于其假设空间复杂度更低，等变网络在泛化性能上具有优势。

Abstract: Equivariant neural networks encode symmetry as an inductive bias and have achieved strong empirical performance in wide domains. However, their expressive power remains not well understood. Focusing on 2-layer ReLU networks, this paper investigates the impact of equivariance constraints on the expressivity of equivariant and layer-wise equivariant networks. By examining the boundary hyperplanes and the channel vectors of ReLU networks, we construct an example showing that equivariance constraints could strictly limit expressive power. However, we demonstrate that this drawback can be compensated via enlarging the model size. Furthermore, we show that despite a larger model size, the resulting architecture could still correspond to a hypothesis space with lower complexity, implying superior generalizability for equivariant networks.

</details>


### [53] [A data-driven approach to linking design features with manufacturing process data for sustainable product development](https://arxiv.org/abs/2512.09690)
*Jiahang Li,Lucas Cazzonelli,Jacqueline Höllig,Markus Doellken,Sven Matthiesen*

Main category: cs.LG

TL;DR: 提出一种数据驱动方法，通过机器学习模型建立设计特征与制造过程数据之间的映射关系，实现自动化设计改进建议，支持可持续产品开发。


<details>
  <summary>Details</summary>
Motivation: 工业物联网技术实现了制造过程数据的实时采集，但现有数据驱动方法通常局限于特定领域（如设计或制造），缺乏设计特征与制造过程数据的集成。由于设计决策显著影响制造结果（如错误率、能耗、加工时间），这种集成不足限制了数据驱动产品设计改进的潜力。

Method: 开发了全面的系统架构以确保连续的数据采集和集成，建立了设计特征与制造过程数据之间的关联，并以此为基础开发机器学习模型，实现自动化设计改进建议。通过将制造过程数据与可持续性指标集成，支持可持续产品开发。

Result: 该方法能够建立设计特征与制造过程数据之间的映射关系，通过机器学习模型提供自动化设计改进建议，为可持续产品开发开辟了新的可能性。

Conclusion: 提出的数据驱动方法通过集成设计特征和制造过程数据，利用机器学习实现自动化设计优化，为数据驱动的可持续产品开发提供了有效途径。

Abstract: The growing adoption of Industrial Internet of Things (IIoT) technologies enables automated, real-time collection of manufacturing process data, unlocking new opportunities for data-driven product development. Current data-driven methods are generally applied within specific domains, such as design or manufacturing, with limited exploration of integrating design features and manufacturing process data. Since design decisions significantly affect manufacturing outcomes, such as error rates, energy consumption, and processing times, the lack of such integration restricts the potential for data-driven product design improvements. This paper presents a data-driven approach to mapping and analyzing the relationship between design features and manufacturing process data. A comprehensive system architecture is developed to ensure continuous data collection and integration. The linkage between design features and manufacturing process data serves as the basis for developing a machine learning model that enables automated design improvement suggestions. By integrating manufacturing process data with sustainability metrics, this approach opens new possibilities for sustainable product development.

</details>


### [54] [Training One Model to Master Cross-Level Agentic Actions via Reinforcement Learning](https://arxiv.org/abs/2512.09706)
*Kaichen He,Zihao Wang,Muyao Li,Anji Liu,Yitao Liang*

Main category: cs.LG

TL;DR: CrossAgent是一个统一的智能体模型，能够掌握异构动作空间并自主选择每个轨迹步骤的最有效接口，在Minecraft环境中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有智能体通常局限于静态、预定义的动作空间（如API、GUI事件或机器人命令），这种刚性限制了它们在动态环境中的适应性，因为最优交互粒度会随上下文变化。

Method: 提出了一个综合训练流程，结合冷启动监督微调和多轮组相对策略优化（GRPO）算法，使智能体能够学习自适应动作切换，无需人工指定规则。

Result: 在开放世界Minecraft环境中的800多个任务上进行广泛实验，CrossAgent实现了最先进的性能，通过动态利用不同动作空间的优势，显著优于固定动作基线，在长时程推理中表现出卓越的泛化能力和效率。

Conclusion: CrossAgent通过掌握异构动作空间和自主选择最优接口，为智能体AI提供了更灵活、自适应的解决方案，在动态环境中展现出优越性能。

Abstract: The paradigm of agentic AI is shifting from engineered complex workflows to post-training native models. However, existing agents are typically confined to static, predefined action spaces--such as exclusively using APIs, GUI events, or robotic commands. This rigidity limits their adaptability in dynamic environments where the optimal granularity of interaction varies contextually. To bridge this gap, we propose CrossAgent, a unified agentic model that masters heterogeneous action spaces and autonomously selects the most effective interface for each step of a trajectory. We introduce a comprehensive training pipeline that integrates cold-start supervised fine-tuning with a Multi-Turn Group Relative Policy Optimization (GRPO) algorithm. This approach enables the agent to learn adaptive action switching--balancing high-level efficiency with low-level precision--without human-specified rules. Extensive experiments on over 800 tasks in the open-world Minecraft environment demonstrate that CrossAgent achieves state-of-the-art performance. By dynamically leveraging the strengths of diverse action spaces, our model significantly outperforms fixed-action baselines, exhibiting superior generalization and efficiency in long-horizon reasoning. All code and models are available at https://github.com/CraftJarvis/OpenHA

</details>


### [55] [Mixture of Lookup Key-Value Experts](https://arxiv.org/abs/2512.09723)
*Zongcheng Wang*

Main category: cs.LG

TL;DR: MoLKV模型通过引入基于键值对的上下文感知专家选择机制，改进了MoLE仅依赖输入ID的上下文无关专家选择限制，在小型评估中实现了显著更低的验证损失。


<details>
  <summary>Details</summary>
Motivation: MoLE（查找专家混合）模型虽然适合资源受限设备，但其仅基于输入ID的上下文无关专家选择机制可能限制模型性能。需要一种能考虑上下文信息的改进方法。

Method: 提出MoLKV（查找键值专家混合）模型，将每个专家构建为键值对。对于给定输入，从输入派生的查询与当前序列缓存的键值专家进行交互，生成上下文感知的专家输出。

Result: 实验结果表明，MoLKV在小型评估中实现了显著更低的验证损失，证明了上下文感知机制的有效性。

Conclusion: MoLKV通过引入上下文感知的专家选择机制，成功解决了MoLE模型的局限性，在保持适合资源受限设备特性的同时提升了模型性能。

Abstract: Recent research has developed several LLM architectures suitable for inference on end-user devices, such as the Mixture of Lookup Experts (MoLE)~\parencite{jie_mixture_2025}. A key feature of MoLE is that each token id is associated with a dedicated group of experts. For a given input, only the experts corresponding to the input token id will be activated. Since the communication overhead of loading this small number of activated experts into RAM during inference is negligible, expert parameters can be offloaded to storage, making MoLE suitable for resource-constrained devices. However, MoLE's context-independent expert selection mechanism, based solely on input ids, may limit model performance. To address this, we propose the \textbf{M}ixture \textbf{o}f \textbf{L}ookup \textbf{K}ey-\textbf{V}alue Experts (\textbf{MoLKV}) model. In MoLKV, each expert is structured as a key-value pair. For a given input, the input-derived query interacts with the cached key-value experts from the current sequence, generating a context-aware expert output. This context-aware mechanism alleviates the limitation of MoLE, and experimental results demonstrate that MoLKV achieves significantly lower validation loss in small-scale evaluations.

</details>


### [56] [Circuits, Features, and Heuristics in Molecular Transformers](https://arxiv.org/abs/2512.09757)
*Kristof Varadi,Mark Marosi,Peter Antal*

Main category: cs.LG

TL;DR: 该论文对用于生成小分子化学结构的自回归Transformer模型进行了机制分析，揭示了模型在不同抽象层次上捕捉分子表示规则的内部计算模式。


<details>
  <summary>Details</summary>
Motivation: 虽然Transformer模型能够生成有效且多样的化学结构，但人们对这些模型如何捕捉分子表示规则的机制知之甚少。作者希望揭示这些模型在不同抽象层次上的计算结构，以理解其内部工作机制。

Method: 使用稀疏自编码器（SAEs）提取与化学相关激活模式相关的特征字典，对在药物样小分子上训练的自回归Transformer进行机制分析，识别从低层语法解析到高层化学有效性约束的计算模式。

Result: 识别出与低层语法解析和高层化学有效性约束一致的计算模式，通过SAEs成功提取了与化学相关激活模式的特征字典，并在下游任务中验证了这些发现。

Conclusion: 机制分析能够揭示Transformer模型捕捉化学结构规则的内部计算模式，这些机制洞察可以转化为各种实际场景中的预测性能提升，为理解化学结构生成的深度学习模型提供了新的视角。

Abstract: Transformers generate valid and diverse chemical structures, but little is known about the mechanisms that enable these models to capture the rules of molecular representation. We present a mechanistic analysis of autoregressive transformers trained on drug-like small molecules to reveal the computational structure underlying their capabilities across multiple levels of abstraction. We identify computational patterns consistent with low-level syntactic parsing and more abstract chemical validity constraints. Using sparse autoencoders (SAEs), we extract feature dictionaries associated with chemically relevant activation patterns. We validate our findings on downstream tasks and find that mechanistic insights can translate to predictive performance in various practical settings.

</details>


### [57] [Physics-Aware Heterogeneous GNN Architecture for Real-Time BESS Optimization in Unbalanced Distribution Systems](https://arxiv.org/abs/2512.09780)
*Aoxiang Ma,Salah Ghamizi,Jun Cao,Pedro Rodriguez*

Main category: cs.LG

TL;DR: 该论文提出了一种基于异构图神经网络的三相不平衡配电网电池储能系统优化调度方法，通过嵌入详细的三相电网信息并使用物理信息损失函数来确保约束合规性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法缺乏明确的三相表示，难以准确建模相特定动态和强制执行运行约束，导致调度方案不可行。需要一种能够同时实现高精度预测和约束合规的方法。

Method: 1. 将详细的三相电网信息（相电压、不平衡负载、BESS状态）嵌入到异构图节点中；2. 使用多种GNN架构（GCN、GAT、GraphSAGE、GPS）联合预测网络状态变量；3. 设计物理信息损失函数，通过软惩罚项纳入电池约束（SoC和C-rate限制）。

Result: 在CIGRE 18节点配电系统上的实验验证显示：该方法实现了低预测误差，总线电压MSE分别为GCN 6.92e-07、GAT 1.21e-06、GPS 3.29e-05、SAGE 9.04e-07。更重要的是，物理信息方法确保了几乎为零的SoC和C-rate约束违反，证明了其在可靠、约束合规调度中的有效性。

Conclusion: 通过将详细的三相电网信息嵌入到异构图节点中，并结合物理信息损失函数，该方法能够实现高精度的网络状态预测，同时确保电池运行约束得到满足，为三相不平衡配电网中的BESS优化调度提供了可靠且实用的解决方案。

Abstract: Battery energy storage systems (BESS) have become increasingly vital in three-phase unbalanced distribution grids for maintaining voltage stability and enabling optimal dispatch. However, existing deep learning approaches often lack explicit three-phase representation, making it difficult to accurately model phase-specific dynamics and enforce operational constraints--leading to infeasible dispatch solutions. This paper demonstrates that by embedding detailed three-phase grid information--including phase voltages, unbalanced loads, and BESS states--into heterogeneous graph nodes, diverse GNN architectures (GCN, GAT, GraphSAGE, GPS) can jointly predict network state variables with high accuracy. Moreover, a physics-informed loss function incorporates critical battery constraints--SoC and C-rate limits--via soft penalties during training. Experimental validation on the CIGRE 18-bus distribution system shows that this embedding-loss approach achieves low prediction errors, with bus voltage MSEs of 6.92e-07 (GCN), 1.21e-06 (GAT), 3.29e-05 (GPS), and 9.04e-07 (SAGE). Importantly, the physics-informed method ensures nearly zero SoC and C-rate constraint violations, confirming its effectiveness for reliable, constraint-compliant dispatch.

</details>


### [58] [Predicting Polymer Solubility in Solvents Using SMILES Strings](https://arxiv.org/abs/2512.09784)
*Andrew Reinhard*

Main category: cs.LG

TL;DR: 开发基于SMILES的深度学习框架，直接从聚合物和溶剂的SMILES表示预测溶解度（wt%），在8049个模拟数据上训练，在25个实验数据上验证，支持高通量溶剂筛选。


<details>
  <summary>Details</summary>
Motivation: 聚合物溶解度预测对回收利用、药物制剂等应用至关重要，传统方法效率低，需要开发可扩展的机器学习方法进行高通量溶剂筛选。

Method: 构建包含8049个聚合物-溶剂对的模拟数据集，将SMILES转换为2394维特征表示，使用六层全连接神经网络，Adam优化器，均方误差损失函数训练。

Result: 模型在模拟数据上预测与实际溶解度值高度一致，在Materials Genome Project的25个未见聚合物-溶剂组合实验数据上保持高精度，验证了泛化能力。

Conclusion: 基于SMILES的机器学习模型可用于可扩展的溶解度预测和高通量溶剂筛选，支持绿色化学、聚合物加工和材料设计应用。

Abstract: Understanding and predicting polymer solubility in various solvents is critical for applications ranging from recycling to pharmaceutical formulation. This work presents a deep learning framework that predicts polymer solubility, expressed as weight percent (wt%), directly from SMILES representations of both polymers and solvents. A dataset of 8,049 polymer solvent pairs at 25 deg C was constructed from calibrated molecular dynamics simulations (Zhou et al., 2023), and molecular descriptors and fingerprints were combined into a 2,394 feature representation per sample. A fully connected neural network with six hidden layers was trained using the Adam optimizer and evaluated using mean squared error loss, achieving strong agreement between predicted and actual solubility values. Generalizability was demonstrated using experimentally measured data from the Materials Genome Project, where the model maintained high accuracy on 25 unseen polymer solvent combinations. These findings highlight the viability of SMILES based machine learning models for scalable solubility prediction and high-throughput solvent screening, supporting applications in green chemistry, polymer processing, and materials design.

</details>


### [59] [TinyDéjàVu: Smaller Memory Footprint & Faster Inference on Sensor Data Streams with Always-On Microcontrollers](https://arxiv.org/abs/2512.09786)
*Zhaolan Huang,Emmanuel Baccelli*

Main category: cs.LG

TL;DR: TinyDéjàVu是一个用于在微控制器上优化时序传感器数据神经网络推理的框架，可减少60%内存使用并消除90%冗余计算


<details>
  <summary>Details</summary>
Motivation: 随着常开传感器需要运行各种微型神经网络进行持续推理，而微控制器内存预算有限（如128kB RAM），优化神经网络层间的数据流变得至关重要

Method: 提出了TinyDéjàVu框架和新算法，通过减少滑动窗口输入重叠部分的冗余计算来优化内存使用，并在硬件上进行可复现基准测试

Result: TinyDéjàVu可以节省超过60%的RAM使用量，并消除滑动窗口输入重叠部分高达90%的冗余计算

Conclusion: TinyDéjàVu框架能显著降低微控制器上时序传感器数据神经网络推理的内存需求，已开源实现并在硬件上验证了其有效性

Abstract: Always-on sensors are increasingly expected to embark a variety of tiny neural networks and to continuously perform inference on time-series of the data they sense. In order to fit lifetime and energy consumption requirements when operating on battery, such hardware uses microcontrollers (MCUs) with tiny memory budget e.g., 128kB of RAM. In this context, optimizing data flows across neural network layers becomes crucial. In this paper, we introduce TinyDéjàVu, a new framework and novel algorithms we designed to drastically reduce the RAM footprint required by inference using various tiny ML models for sensor data time-series on typical microcontroller hardware. We publish the implementation of TinyDéjàVu as open source, and we perform reproducible benchmarks on hardware. We show that TinyDéjàVu can save more than 60% of RAM usage and eliminate up to 90% of redundant compute on overlapping sliding window inputs.

</details>


### [60] [Knowledge Diversion for Efficient Morphology Control and Policy Transfer](https://arxiv.org/abs/2512.09796)
*Fu Feng,Ruixiao Shi,Yucheng Xie,Jianlu Shen,Jing Wang,Xin Geng*

Main category: cs.LG

TL;DR: DivMorph：一种通过知识分流学习可分解控制器的模块化训练范式，利用SVD分解Transformer权重，通过动态软门控实现知识解耦，显著提升跨任务泛化能力和部署效率。


<details>
  <summary>Details</summary>
Motivation: 当前通用形态控制方法存在两个主要问题：1）基于Transformer的控制器计算成本高，部署开销大；2）现有方法跨任务泛化能力有限，每个新任务都需要从头训练。

Method: DivMorph采用模块化训练范式：1）通过SVD将随机初始化的Transformer权重分解为因子单元；2）基于任务和形态嵌入使用动态软门控调制这些单元，将其分离为共享的"learngenes"和特定于形态/任务的"tailors"；3）通过选择性激活相关组件实现知识解耦。

Result: DivMorph在跨任务迁移中比直接微调提高3倍样本效率，单智能体部署时模型大小减少17倍，实现了最先进的性能。

Conclusion: DivMorph通过知识分流和模块化设计，解决了通用形态控制中的计算成本和跨任务泛化问题，实现了高效可扩展的策略部署和有效的新任务策略迁移。

Abstract: Universal morphology control aims to learn a universal policy that generalizes across heterogeneous agent morphologies, with Transformer-based controllers emerging as a popular choice. However, such architectures incur substantial computational costs, resulting in high deployment overhead, and existing methods exhibit limited cross-task generalization, necessitating training from scratch for each new task. To this end, we propose \textbf{DivMorph}, a modular training paradigm that leverages knowledge diversion to learn decomposable controllers. DivMorph factorizes randomly initialized Transformer weights into factor units via SVD prior to training and employs dynamic soft gating to modulate these units based on task and morphology embeddings, separating them into shared \textit{learngenes} and morphology- and task-specific \textit{tailors}, thereby achieving knowledge disentanglement. By selectively activating relevant components, DivMorph enables scalable and efficient policy deployment while supporting effective policy transfer to novel tasks. Extensive experiments demonstrate that DivMorph achieves state-of-the-art performance, achieving a 3$\times$ improvement in sample efficiency over direct finetuning for cross-task transfer and a 17$\times$ reduction in model size for single-agent deployment.

</details>


### [61] [Ariel-ML: Computing Parallelization with Embedded Rust for Neural Networks on Heterogeneous Multi-core Microcontrollers](https://arxiv.org/abs/2512.09800)
*Zhaolan Huang,Kaspar Schleiser,Gyungmin Myung,Emmanuel Baccelli*

Main category: cs.LG

TL;DR: Ariel-ML：首个支持多核MCU并行推理的Rust嵌入式TinyML平台，性能优于现有方案，内存占用与C/C++相当


<details>
  <summary>Details</summary>
Motivation: 随着低功耗MCU从单核向多核演进，Rust在嵌入式领域逐渐取代C/C++，同时TinyML模型在边缘AI应用增多。但现有平台缺乏能自动利用多核MCU并行计算能力的Rust嵌入式软件平台，无法高效执行任意TinyML模型。

Method: 提出Ariel-ML工具包，结合通用TinyML流水线和嵌入式Rust软件平台，能够充分利用多种32位微控制器家族（Arm Cortex-M、RISC-V、ESP-32）的多核能力。提供完整的开源实现，并使用多种TinyML模型进行基准测试。

Result: Ariel-ML在推理延迟方面优于现有技术，与使用嵌入式C/C++的现有工具包相比，内存占用相当。为TinyML实践者和资源受限的嵌入式Rust开发者提供了有用基础。

Conclusion: Ariel-ML填补了Rust嵌入式软件平台在多核MCU上自动并行化TinyML推理计算的空白，在保持内存效率的同时显著提升性能，是边缘AI部署的重要工具。

Abstract: Low-power microcontroller (MCU) hardware is currently evolving from single-core architectures to predominantly multi-core architectures. In parallel, new embedded software building blocks are more and more written in Rust, while C/C++ dominance fades in this domain. On the other hand, small artificial neural networks (ANN) of various kinds are increasingly deployed in edge AI use cases, thus deployed and executed directly on low-power MCUs. In this context, both incremental improvements and novel innovative services will have to be continuously retrofitted using ANNs execution in software embedded on sensing/actuating systems already deployed in the field. However, there was so far no Rust embedded software platform automating parallelization for inference computation on multi-core MCUs executing arbitrary TinyML models. This paper thus fills this gap by introducing Ariel-ML, a novel toolkit we designed combining a generic TinyML pipeline and an embedded Rust software platform which can take full advantage of multi-core capabilities of various 32bit microcontroller families (Arm Cortex-M, RISC-V, ESP-32). We published the full open source code of its implementation, which we used to benchmark its capabilities using a zoo of various TinyML models. We show that Ariel-ML outperforms prior art in terms of inference latency as expected, and we show that, compared to pre-existing toolkits using embedded C/C++, Ariel-ML achieves comparable memory footprints. Ariel-ML thus provides a useful basis for TinyML practitioners and resource-constrained embedded Rust developers.

</details>


### [62] [Incorporating Fairness in Neighborhood Graphs for Fair Spectral Clustering](https://arxiv.org/abs/2512.09810)
*Adithya K Moorthy,V Vijaya Saradhi,Bhanu Prasad*

Main category: cs.LG

TL;DR: 该论文提出了一种在kNN和ε邻域图构建阶段就引入公平性约束的新方法，通过确保每个节点的邻域中敏感群体比例均衡，为公平谱聚类提供预处理解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统图聚类方法在构建图时存在偏见，可能导致某些群体在图中代表性不足。现有的kNN和ε邻域图构建方法会传播基于边的差异影响，导致聚类结果偏向某些敏感群体。需要在图构建的最早阶段就解决公平性问题。

Method: 提出了公平kNN图和公平ε邻域图的构建方法，在邻域选择步骤中主动强制执行人口统计均等约束。通过将公平性约束纳入图构建过程，确保每个节点的邻域中敏感特征的比例代表性，同时保持几何一致性。

Result: 在3个合成数据集、7个真实世界表格数据集和3个真实世界图像数据集上的实验证明，提出的公平图构建方法在图表聚任务中超越了现有基线方法。

Conclusion: 图构建中的拓扑公平性对于实现公平聚类结果至关重要。通过在预处理阶段确保图的拓扑特征反映公平的群体比例，可以在不改变聚类算法本身的情况下实现更公平的谱聚类结果，填补了公平无监督学习中的重要空白。

Abstract: Graph clustering plays a pivotal role in unsupervised learning methods like spectral clustering, yet traditional methods for graph clustering often perpetuate bias through unfair graph constructions that may underrepresent some groups. The current research introduces novel approaches for constructing fair k-nearest neighbor (kNN) and fair epsilon-neighborhood graphs that proactively enforce demographic parity during graph formation. By incorporating fairness constraints at the earliest stage of neighborhood selection steps, our approaches incorporate proportional representation of sensitive features into the local graph structure while maintaining geometric consistency.Our work addresses a critical gap in pre-processing for fair spectral clustering, demonstrating that topological fairness in graph construction is essential for achieving equitable clustering outcomes. Widely used graph construction methods like kNN and epsilon-neighborhood graphs propagate edge based disparate impact on sensitive groups, leading to biased clustering results. Providing representation of each sensitive group in the neighborhood of every node leads to fairer spectral clustering results because the topological features of the graph naturally reflect equitable group ratios. This research fills an essential shortcoming in fair unsupervised learning, by illustrating how topological fairness in graph construction inherently facilitates fairer spectral clustering results without the need for changes to the clustering algorithm itself. Thorough experiments on three synthetic datasets, seven real-world tabular datasets, and three real-world image datasets prove that our fair graph construction methods surpass the current baselines in graph clustering tasks.

</details>


### [63] [Predicting the Containment Time of California Wildfires Using Machine Learning](https://arxiv.org/abs/2512.09835)
*Shashank Bhardwaj*

Main category: cs.LG

TL;DR: 使用机器学习模型预测加州野火完全控制所需天数，将持续时间预测作为回归任务而非分类任务，比较了随机森林、XGBoost和LSTM模型的性能。


<details>
  <summary>Details</summary>
Motivation: 加州野火季节日益严重，应急响应团队不堪重负，需要准确实用的预测来协助资源分配。现有研究大多关注火灾风险或蔓延，少数研究持续时间预测也仅使用宽泛分类而非连续测量。

Method: 结合加州林业和消防部门FRAP的三个公开数据集，将野火持续时间预测作为回归任务，比较了基线集成回归器、随机森林、XGBoost和LSTM神经网络模型的性能。

Result: XGBoost模型略优于随机森林，可能因其对静态特征处理更佳；LSTM模型表现较差，因为数据集缺乏时序特征。根据特征可用性，野火管理者可选择最合适的模型。

Conclusion: 研究证明机器学习模型可准确预测野火控制持续时间，帮助资源有效分配。特征可用性决定模型选择：XGBoost适合静态特征，而LSTM需要时序数据才能发挥优势。

Abstract: California's wildfire season keeps getting worse over the years, overwhelming the emergency response teams. These fires cause massive destruction to both property and human life. Because of these reasons, there's a growing need for accurate and practical predictions that can help assist with resources allocation for the Wildfire managers or the response teams. In this research, we built machine learning models to predict the number of days it will require to fully contain a wildfire in California. Here, we addressed an important gap in the current literature. Most prior research has concentrated on wildfire risk or how fires spread, and the few that examine the duration typically predict it in broader categories rather than a continuous measure. This research treats the wildfire duration prediction as a regression task, which allows for more detailed and precise forecasts rather than just the broader categorical predictions used in prior work. We built the models by combining three publicly available datasets from California Department of Forestry and Fire Protection's Fire and Resource Assessment Program (FRAP). This study compared the performance of baseline ensemble regressor, Random Forest and XGBoost, with a Long Short-Term Memory (LSTM) neural network. The results show that the XGBoost model slightly outperforms the Random Forest model, likely due to its superior handling of static features in the dataset. The LSTM model, on the other hand, performed worse than the ensemble models because the dataset lacked temporal features. Overall, this study shows that, depending on the feature availability, Wildfire managers or Fire management authorities can select the most appropriate model to accurately predict wildfire containment duration and allocate resources effectively.

</details>


### [64] [Conformal Bandits: Bringing statistical validity and reward efficiency to the small-gap regime](https://arxiv.org/abs/2512.09850)
*Simone Cuonzo,Nina Deliu*

Main category: cs.LG

TL;DR: 将Conformal Prediction融入bandit问题，在保持遗憾最小化的同时提供有限时间统计覆盖保证，特别在小差距场景和投资组合分配应用中表现优异


<details>
  <summary>Details</summary>
Motivation: 传统bandit策略如Thompson Sampling和UCB依赖分布假设或渐近保证，主要关注遗憾最小化而忽视统计特性，无法在小差距场景下达到最优遗憾边界

Method: 提出Conformal Bandits框架，将Conformal Prediction与bandit决策策略结合，在投资组合应用中集成隐马尔可夫模型捕捉市场状态切换行为

Result: 在小差距场景下优于经典UCB策略，实现名义覆盖保证，在投资组合应用中通过状态切换建模提升风险调整后的遗憾效率回报，同时保持覆盖保证

Conclusion: Conformal Bandits成功将遗憾最小化与统计保证结合，为小差距场景和实际应用如投资组合分配提供了更优的决策框架

Abstract: We introduce Conformal Bandits, a novel framework integrating Conformal Prediction (CP) into bandit problems, a classic paradigm for sequential decision-making under uncertainty. Traditional regret-minimisation bandit strategies like Thompson Sampling and Upper Confidence Bound (UCB) typically rely on distributional assumptions or asymptotic guarantees; further, they remain largely focused on regret, neglecting their statistical properties. We address this gap. Through the adoption of CP, we bridge the regret-minimising potential of a decision-making bandit policy with statistical guarantees in the form of finite-time prediction coverage.
  We demonstrate the potential of it Conformal Bandits through simulation studies and an application to portfolio allocation, a typical small-gap regime, where differences in arm rewards are far too small for classical policies to achieve optimal regret bounds in finite sample. Motivated by this, we showcase our framework's practical advantage in terms of regret in small-gap settings, as well as its added value in achieving nominal coverage guarantees where classical UCB policies fail. Focusing on our application of interest, we further illustrate how integrating hidden Markov models to capture the regime-switching behaviour of financial markets, enhances the exploration-exploitation trade-off, and translates into higher risk-adjusted regret efficiency returns, while preserving coverage guarantees.

</details>


### [65] [HPM-KD: Hierarchical Progressive Multi-Teacher Framework for Knowledge Distillation and Efficient Model Compression](https://arxiv.org/abs/2512.09886)
*Gustavo Coelho Haase,Paulo Henrique Dourado da Silva*

Main category: cs.LG

TL;DR: HPM-KD是一个知识蒸馏框架，通过六个协同组件解决传统KD的四大限制：自动超参数调优、渐进蒸馏链、注意力加权多教师集成、元学习温度调度、并行处理和共享优化内存，实现高效模型压缩。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏存在四大关键限制：1) 对超参数敏感需要大量手动调优；2) 从大教师模型到小学生模型存在容量差距；3) 多教师场景下协调不优；4) 计算资源使用效率低。需要一种更自动化和高效的蒸馏框架。

Method: HPM-KD框架包含六个协同组件：1) 基于元学习的自适应配置管理器，消除手动超参数调优；2) 自动确定中间模型的渐进蒸馏链；3) 学习动态每样本权重的注意力加权多教师集成；4) 适应训练过程中温度变化的元学习温度调度器；5) 智能负载均衡的并行处理流水线；6) 跨实验重用的共享优化内存。

Result: 在CIFAR-10、CIFAR-100和表格数据集上的实验表明：HPM-KD实现10-15倍压缩同时保持85%准确率保留，消除手动调优需求，通过并行化减少30-40%训练时间。消融研究确认每个组件的独立贡献（0.10-0.98个百分点）。

Conclusion: HPM-KD成功解决了传统知识蒸馏的关键限制，提供了一种自动化、高效且可扩展的模型压缩框架，已作为开源DeepBridge库的一部分提供。

Abstract: Knowledge Distillation (KD) has emerged as a promising technique for model compression but faces critical limitations: (1) sensitivity to hyperparameters requiring extensive manual tuning, (2) capacity gap when distilling from very large teachers to small students, (3) suboptimal coordination in multi-teacher scenarios, and (4) inefficient use of computational resources. We present \textbf{HPM-KD}, a framework that integrates six synergistic components: (i) Adaptive Configuration Manager via meta-learning that eliminates manual hyperparameter tuning, (ii) Progressive Distillation Chain with automatically determined intermediate models, (iii) Attention-Weighted Multi-Teacher Ensemble that learns dynamic per-sample weights, (iv) Meta-Learned Temperature Scheduler that adapts temperature throughout training, (v) Parallel Processing Pipeline with intelligent load balancing, and (vi) Shared Optimization Memory for cross-experiment reuse. Experiments on CIFAR-10, CIFAR-100, and tabular datasets demonstrate that HPM-KD: achieves 10x-15x compression while maintaining 85% accuracy retention, eliminates the need for manual tuning, and reduces training time by 30-40% via parallelization. Ablation studies confirm independent contribution of each component (0.10-0.98 pp). HPM-KD is available as part of the open-source DeepBridge library.

</details>


### [66] [Analysis of Dirichlet Energies as Over-smoothing Measures](https://arxiv.org/abs/2512.09890)
*Anna Bison,Alessandro Sperduti*

Main category: cs.LG

TL;DR: 分析两种图拉普拉斯算子诱导的狄利克雷能量作为过平滑度量的区别，指出归一化图拉普拉斯不满足节点相似性度量的公理化定义，强调选择与GNN架构谱兼容的度量的重要性。


<details>
  <summary>Details</summary>
Motivation: 在GNN训练中，过平滑是一个关键问题，但文献中常混用未归一化和归一化图拉普拉斯诱导的狄利克雷能量作为过平滑度量，这导致监控动态时存在模糊性。需要澄清这两种度量的区别，并建立选择合适度量的理论基础。

Method: 通过形式化分析两种图拉普拉斯算子的基本谱性质，比较它们诱导的狄利克雷能量。特别地，检验归一化图拉普拉斯是否满足Rusch等人提出的节点相似性度量的公理化定义。

Result: 证明归一化图拉普拉斯诱导的狄利克雷能量不满足节点相似性度量的公理化定义，而这两种度量在谱性质上存在关键区别。这些区别对于选择与特定GNN架构谱兼容的过平滑度量至关重要。

Conclusion: 选择过平滑度量时需要考虑其与GNN架构的谱兼容性。归一化图拉普拉斯诱导的狄利克雷能量不适合作为节点相似性度量，这一发现有助于解决监控GNN训练动态时的模糊性问题。

Abstract: We analyze the distinctions between two functionals often used as over-smoothing measures: the Dirichlet energies induced by the unnormalized graph Laplacian and the normalized graph Laplacian. We demonstrate that the latter fails to satisfy the axiomatic definition of a node-similarity measure proposed by Rusch \textit{et al.} By formalizing fundamental spectral properties of these two definitions, we highlight critical distinctions necessary to select the metric that is spectrally compatible with the GNN architecture, thereby resolving ambiguities in monitoring the dynamics.

</details>


### [67] [Provably Learning from Modern Language Models via Low Logit Rank](https://arxiv.org/abs/2512.09892)
*Noah Golowich,Allen Liu,Abhishek Shetty*

Main category: cs.LG

TL;DR: 本文提出了一种基于低logit秩假设的语言模型学习算法，该算法能够从查询中高效学习任何近似低logit秩模型，为现代语言模型提供了首个端到端学习保证。


<details>
  <summary>Details</summary>
Motivation: 现代语言模型虽然复杂，但经验观察发现它们都具有近似低logit秩的特性。这一结构特性为算法设计提供了可能，但如何利用这一结构获得可证明的学习保证仍待探索。

Method: 采用查询学习模型，通过logit查询访问语言模型API。设计了一种高效算法，利用低logit秩的结构特性来学习任何近似低logit秩模型。

Result: 提出了一个能够从查询中高效学习任何近似低logit秩模型的算法，为现代语言模型提供了首个端到端学习保证。

Conclusion: 低logit秩的结构假设很好地反映了现代语言模型的经验行为，基于此设计的算法为理解语言模型的学习提供了理论保证，是首个能够捕获现代语言模型特性的生成模型学习结果。

Abstract: While modern language models and their inner workings are incredibly complex, recent work (Golowich, Liu & Shetty; 2025) has proposed a simple and potentially tractable abstraction for them through the observation that empirically, these language models all seem to have approximately low logit rank. Roughly, this means that a matrix formed by the model's log probabilities of various tokens conditioned on certain sequences of tokens is well approximated by a low rank matrix.
  In this paper, our focus is on understanding how this structure can be exploited algorithmically for obtaining provable learning guarantees. Since low logit rank models can encode hard-to-learn distributions such as noisy parities, we study a query learning model with logit queries that reflects the access model for common APIs. Our main result is an efficient algorithm for learning any approximately low logit rank model from queries. We emphasize that our structural assumption closely reflects the behavior that is empirically observed in modern language models. Thus, our result gives what we believe is the first end-to-end learning guarantee for a generative model that plausibly captures modern language models.

</details>


### [68] [Exploring Protein Language Model Architecture-Induced Biases for Antibody Comprehension](https://arxiv.org/abs/2512.09894)
*Mengren,Liu,Yixiang Zhang,Yiming,Zhang*

Main category: cs.LG

TL;DR: 系统评估不同蛋白质语言模型架构在抗体特异性预测任务中的表现，发现抗体专用模型能自然关注CDR区域，而通用模型需要显式CDR训练策略。


<details>
  <summary>Details</summary>
Motivation: 尽管蛋白质语言模型在理解蛋白质序列方面表现出色，但不同模型架构如何捕捉抗体特异性生物学特性尚未被探索，需要系统研究模型架构选择对理解抗体序列特征和功能的影响。

Method: 评估三种最先进的蛋白质语言模型（AntiBERTa、BioBERT、ESM2）与通用语言模型（GPT-2）基线在抗体靶标特异性预测任务上的表现，通过注意力归因分析研究模型如何关注不同生物学特征。

Result: 所有蛋白质语言模型都实现了高分类准确率，但在捕捉V基因使用、体细胞超突变模式和同种型信息等生物学特征方面表现出不同的偏差。抗体专用模型如AntiBERTa能自然学习关注互补决定区（CDRs），而通用蛋白质模型从显式CDR聚焦训练策略中显著受益。

Conclusion: 研究揭示了模型架构与生物学特征提取之间的关系，为计算抗体设计中未来蛋白质语言模型的发展提供了有价值的指导，强调了针对特定生物学特性的模型设计重要性。

Abstract: Recent advances in protein language models (PLMs) have demonstrated remarkable capabilities in understanding protein sequences. However, the extent to which different model architectures capture antibody-specific biological properties remains unexplored. In this work, we systematically investigate how architectural choices in PLMs influence their ability to comprehend antibody sequence characteristics and functions. We evaluate three state-of-the-art PLMs-AntiBERTa, BioBERT, and ESM2--against a general-purpose language model (GPT-2) baseline on antibody target specificity prediction tasks. Our results demonstrate that while all PLMs achieve high classification accuracy, they exhibit distinct biases in capturing biological features such as V gene usage, somatic hypermutation patterns, and isotype information. Through attention attribution analysis, we show that antibody-specific models like AntiBERTa naturally learn to focus on complementarity-determining regions (CDRs), while general protein models benefit significantly from explicit CDR-focused training strategies. These findings provide insights into the relationship between model architecture and biological feature extraction, offering valuable guidance for future PLM development in computational antibody design.

</details>


### [69] [STACHE: Local Black-Box Explanations for Reinforcement Learning Policies](https://arxiv.org/abs/2512.09909)
*Andrew Elashkin,Orna Grumberg*

Main category: cs.LG

TL;DR: STACHE框架为离散马尔可夫游戏中的智能体行为提供局部黑盒解释，包含鲁棒性区域和最小反事实两个互补组件，通过精确搜索算法避免代理模型保真度差距。


<details>
  <summary>Details</summary>
Motivation: 强化学习智能体在稀疏奖励或安全关键环境中常表现出意外行为，需要可靠的调试和验证工具来理解其决策逻辑。

Method: 提出STACHE框架，生成包含鲁棒性区域（智能体决策不变的连通邻域状态）和最小反事实（改变决策所需的最小状态扰动）的复合解释。利用因子化状态空间结构，引入精确的基于搜索的算法，避免代理模型的保真度差距。

Result: 在Gymnasium环境中的实证验证表明，该框架不仅能解释策略动作，还能有效捕捉训练过程中策略逻辑的演变——从不稳定行为到优化鲁棒策略，提供对智能体敏感性和决策边界的可行见解。

Conclusion: STACHE为强化学习智能体提供了全面的局部黑盒解释框架，通过鲁棒性区域和最小反事实的互补组合，增强了智能体行为的可解释性和调试能力，有助于理解决策边界和策略演变过程。

Abstract: Reinforcement learning agents often behave unexpectedly in sparse-reward or safety-critical environments, creating a strong need for reliable debugging and verification tools. In this paper, we propose STACHE, a comprehensive framework for generating local, black-box explanations for an agent's specific action within discrete Markov games. Our method produces a Composite Explanation consisting of two complementary components: (1) a Robustness Region, the connected neighborhood of states where the agent's action remains invariant, and (2) Minimal Counterfactuals, the smallest state perturbations required to alter that decision. By exploiting the structure of factored state spaces, we introduce an exact, search-based algorithm that circumvents the fidelity gaps of surrogate models. Empirical validation on Gymnasium environments demonstrates that our framework not only explains policy actions, but also effectively captures the evolution of policy logic during training - from erratic, unstable behavior to optimized, robust strategies - providing actionable insights into agent sensitivity and decision boundaries.

</details>


### [70] [FALCON: Few-step Accurate Likelihoods for Continuous Flows](https://arxiv.org/abs/2512.09914)
*Danyal Rehman,Tara Akhound-Sadegh,Artem Gazizov,Yoshua Bengio,Alexander Tong*

Main category: cs.LG

TL;DR: 提出FALCON方法，通过混合训练目标实现可逆性，使连续流模型能用少量步数采样并保持足够准确的似然，用于分子玻尔兹曼采样，比现有方法快两个数量级。


<details>
  <summary>Details</summary>
Motivation: 热力学平衡中分子状态的可扩展采样是统计物理的长期挑战。现有玻尔兹曼生成器使用连续归一化流，但似然计算成本极高（每个样本需要数千次函数评估），严重限制了其应用。

Method: 提出FALCON方法，通过引入混合训练目标来鼓励可逆性，使连续流模型能够用少量步数进行采样，同时保持足够准确的似然用于重要性采样应用。

Result: FALCON在分子玻尔兹曼采样方面优于最先进的归一化流模型，比性能相当的CNF模型快两个数量级。

Conclusion: FALCON通过混合训练目标实现了连续流模型的快速准确采样，解决了现有玻尔兹曼生成器计算成本过高的问题，为分子状态采样提供了高效解决方案。

Abstract: Scalable sampling of molecular states in thermodynamic equilibrium is a long-standing challenge in statistical physics. Boltzmann Generators tackle this problem by pairing a generative model, capable of exact likelihood computation, with importance sampling to obtain consistent samples under the target distribution. Current Boltzmann Generators primarily use continuous normalizing flows (CNFs) trained with flow matching for efficient training of powerful models. However, likelihood calculation for these models is extremely costly, requiring thousands of function evaluations per sample, severely limiting their adoption. In this work, we propose Few-step Accurate Likelihoods for Continuous Flows (FALCON), a method which allows for few-step sampling with a likelihood accurate enough for importance sampling applications by introducing a hybrid training objective that encourages invertibility. We show FALCON outperforms state-of-the-art normalizing flow models for molecular Boltzmann sampling and is two orders of magnitude faster than the equivalently performing CNF model.

</details>


### [71] [Closing the Train-Test Gap in World Models for Gradient-Based Planning](https://arxiv.org/abs/2512.09929)
*Arjun Parthasarathy,Nimit Kalra,Rohun Agrawal,Yann LeCun,Oumayma Bounou,Pavel Izmailov,Micah Goldblum*

Main category: cs.LG

TL;DR: 提出改进世界模型训练方法，通过缩小训练-测试差距，使基于梯度的规划在10%时间预算内达到或超越传统无梯度方法性能


<details>
  <summary>Details</summary>
Motivation: 基于梯度的规划虽然计算效率高，但性能一直落后于其他方法。世界模型在训练时使用下一状态预测目标，但在测试时却用于估计动作序列，存在训练-测试差距

Method: 提出训练时数据合成技术，缩小训练-测试差距，改进现有世界模型的基于梯度规划能力

Result: 在10%的时间预算内，在多种物体操作和导航任务中，性能达到或超越传统无梯度交叉熵方法(CEM)

Conclusion: 通过改进世界模型训练方法，可以有效缩小训练-测试差距，使基于梯度的规划在保持计算效率的同时达到竞争性性能

Abstract: World models paired with model predictive control (MPC) can be trained offline on large-scale datasets of expert trajectories and enable generalization to a wide range of planning tasks at inference time. Compared to traditional MPC procedures, which rely on slow search algorithms or on iteratively solving optimization problems exactly, gradient-based planning offers a computationally efficient alternative. However, the performance of gradient-based planning has thus far lagged behind that of other approaches. In this paper, we propose improved methods for training world models that enable efficient gradient-based planning. We begin with the observation that although a world model is trained on a next-state prediction objective, it is used at test-time to instead estimate a sequence of actions. The goal of our work is to close this train-test gap. To that end, we propose train-time data synthesis techniques that enable significantly improved gradient-based planning with existing world models. At test time, our approach outperforms or matches the classical gradient-free cross-entropy method (CEM) across a variety of object manipulation and navigation tasks in 10% of the time budget.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [72] [Data-driven time-dependent bases for turbulent airfoil wake-extreme vortex gust interactions](https://arxiv.org/abs/2512.09523)
*Shaghayegh Zamani Ashtiani,Kai Fukami*

Main category: physics.comp-ph

TL;DR: 该研究使用数据驱动框架分析湍流翼型尾流与极端强阵风相互作用，通过时变基函数和降维协方差矩阵推导闭合演化方程，避免了全历史存储需求。


<details>
  <summary>Details</summary>
Motivation: 研究极端阵风与翼型尾流相互作用对于理解飞行器在恶劣天气条件下的气动特性至关重要，传统方法难以处理这种瞬态强非线性现象。

Method: 采用数据驱动框架，使用时变基函数（二维平面模态和一维展向模态）结合降维协方差矩阵，推导闭合演化方程，仅需小滚动窗口进行时间推进。

Result: 在Re=5000的极端涡阵风-翼型相互作用中，发现撞击前第一平面模态主导，撞击后第二模态能量增强（随阵风强度/尺寸增大而放大）；主导模态能量间隙大小反映了流动相干结构和恢复速度。

Conclusion: 该工作提供了一种可解释的、时变的数据驱动模态分析方法，能够有效分析极端阵风遭遇过程，揭示了模态能量演化与瞬态升力动力学的关联。

Abstract: We analyze interactions between turbulent airfoil wake and an extremely strong gust using a data-driven framework with time-dependent bases. The current approach represents each snapshot with time-varying bases consisting of two-dimensional in-plane modes and one-dimensional spanwise modes, together with a reduced covariance matrix. We derive closed-form evolution equations for these time-varying components and advance them over time, requiring only a small rolling window and avoiding full-history storage. Applied to extreme vortex gust-airfoil interaction at Re=5000, we examine how in-plane modes and their associated energy level evolve across gust conditions of varying intensity and size. Before impingement, the first in-plane mode dominates; after impingement, the second mode gains energy_amplified by stronger/larger gusts. A larger leading-mode energy gap implies coherent structure and faster recovery; a smaller gap with slower decay indicates richer multiscale activity and delayed re-stabilization. These trends follow the transient lift dynamics as well, with higher amplitude and more oscillations indicated by a rise in the leading singular values. This work provides an interpretable, time-varying data-driven modal analysis of extreme gust encounter.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [73] [Degenerate higher-order scalar-tensor theories in metric-affine gravity](https://arxiv.org/abs/2512.08972)
*Hamed Bouzari Nezhad*

Main category: gr-qc

TL;DR: 构建了二次退化高阶标量张量（DHOST）理论的度量仿射类比，通过求解联络方程得到闭式有效度量理论，并分析了引力波传播速度对理论的限制。


<details>
  <summary>Details</summary>
Motivation: 研究度量仿射框架下的标量张量理论，将标准的度量DHOST理论推广到包含联络自由度的更一般情形，探索联络动力学对理论结构的影响。

Method: 从一般的度量仿射标量张量作用量出发，该作用量在曲率上是线性的，包含所有至多对标量场协变二阶导数的二次算子。通过完全分解畸变张量来求解联络方程，得到闭式有效度量理论，然后施加标准的度量DHOST退化条件。

Result: 得到了一个Palatini Class Ia分支，由原始作用量中的两个自由函数完全确定。分析张量部分发现，要求引力波以光速传播进一步将理论限制为单函数族。

Conclusion: 在给定的算子基下，对二次度量仿射Class Ia扇区进行了详细且自洽的表征，并识别了引力波观测所隐含的理论条件，为度量仿射DHOST理论提供了系统的分类框架。

Abstract: We construct the metric-affine analogue of the quadratic degenerate higher-order scalar-tensor (DHOST) theories. We begin with a general metric-affine scalar-tensor action that is linear in curvature and contains all operators that are at most quadratic in the covariant second derivatives of the scalar field, ensuring that the connection enters only through curvature and through these second derivatives. Solving the connection equation by performing a full decomposition of the distortion tensor gives a closed-form effective metric theory. Imposing the standard metric DHOST degeneracy conditions then selects a Palatini Class Ia branch that is fully determined by two free functions in the original action. Analyzing the tensor sector shows that requiring gravitational waves to propagate at the speed of light further restricts the theory to a one-function family. These results provide a detailed and self-contained characterization of the quadratic metric-affine Class Ia sector within this operator basis and identify the theoretical conditions implied by gravitational wave observations.

</details>


### [74] [About possible measures in Quantum Gravity](https://arxiv.org/abs/2512.09191)
*O. P. Santillán*

Main category: gr-qc

TL;DR: 该论文探讨量子引力理论中的测度选择问题，分析不变与非不变测度的可能性，并特别关注非协变测度在弯曲时空量子化中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究量子引力理论中测度选择的数学基础，特别是当理论需要在弯曲时空背景下进行量子化时，传统的协变测度可能不足，需要探索非协变测度的可能性及其物理意义。

Method: 分析微分同胚不变测度与非不变测度的数学性质，探讨通过抵消项重新定义模型来补偿测度异常的可能性，特别关注非协变测度在推广Veltmann恒等式方面的应用。

Result: 提出了在量子引力理论中使用非协变测度的可能性，只要测度异常能够通过抵消项重新定义得到补偿。特别针对Stelle引力模型（在平直时空可重整但在弯曲时空未知）给出了具体结果。

Conclusion: 非协变测度在量子引力理论中是可接受的，前提是其异常能够被适当补偿。这种测度选择对于在弯曲时空背景下量子化引力理论，特别是推广Veltmann恒等式具有重要意义。

Abstract: Possible measures for Quantum Gravity are considered. Choices that are invariant under diffeomorphisms are analyzed, but the possibility of employing non invariant measures is also taken into account. The last possibility may be accepted if the anomaly in the measure is compensated by counter term redefinitions of the model under analysis. Particular attention is paid to some concrete examples of non covariant looking measures, which may be useful for generalizing the Veltmann identities when quantizing around curved space times. The results are specified for the Stelle gravity model [1]-[2], which is known to be renormalizable in flat space, although not known to be so in curved ones.

</details>


### [75] [Gravitational-Wave Signatures of Massive Black Hole Formation](https://arxiv.org/abs/2512.09197)
*Bernard J. Kelly,Sarah Gossan,Leonardo R. Werneck,John Wise,Zachariah B. Etienne,Thiago Assumpção,Aláine Lee,John G. Baker*

Main category: gr-qc

TL;DR: 该论文研究早期宇宙中直接坍缩黑洞的形成、坍缩和合并过程，旨在提取相应的引力波信号，为LISA探测提供理论支持。


<details>
  <summary>Details</summary>
Motivation: 直接坍缩黑洞是早期宇宙大质量黑洞的重要组成部分，它们的形成和早期合并将在LISA的观测数据中占据显著位置。然而，目前对这些早期黑洞的种群特性和双星性质了解甚少，其质量、质量比、自旋和轨道偏心率等参数强烈依赖于形成过程的细节以及周围物质环境的影响。

Method: 通过模拟直接坍缩黑洞区域的形成、坍缩和合并过程，提取由此产生的引力波信号。研究考虑了周围物质（重子和非重子物质）对黑洞合并过程的影响。

Result: 论文报告了初步的模拟工作，建立了直接坍缩黑洞形成和合并的数值模型，为后续提取引力波信号奠定了基础。

Conclusion: 直接坍缩黑洞的引力波信号模拟对于理解早期宇宙黑洞种群特性和LISA观测数据解释至关重要，需要进一步研究其形成机制和周围物质环境的影响。

Abstract: Direct-collapse black holes (DCBHs) are an important component of the massive black hole population of the early universe, and their formation and early mergers will be prominent in the data stream of the Laser Interferometer Space Antenna (LISA). However, the population and binary properties of these early black holes are poorly understood, with masses, mass ratios, spins, and orbital eccentricities strongly dependent on the details of their formation, and the properties of the remaining exterior material (baryonic and non-baryonic), which may be substantial to the point of merger.
  We report on initial work to simulate the formation, collapse, and/or merger of such DCBH regions in order to extract the resulting gravitational-wave signals.

</details>


### [76] [Massless Majorana spinors in the Kerr spacetime](https://arxiv.org/abs/2512.09253)
*Tianyuan Cai,Xiao Zhang*

Main category: gr-qc

TL;DR: 论文证明在Kerr和Kerr-(A)dS时空中，不存在t或φ依赖的大质量Majorana旋量。对于无质量Majorana旋量，在非极端Kerr时空中可分离变量求解，但存在L^p可积性限制。哈密顿量自伴性要求角动量为零，时空间化为Schwarzschild时空，且旋量必须φ独立。在Schwarzschild时空中，无质量Majorana旋量在紧致区域内的概率随时间趋于零。


<details>
  <summary>Details</summary>
Motivation: 研究Majorana旋量在旋转黑洞（Kerr）和带宇宙学常数的Kerr-(A)dS时空中的存在性和性质，特别关注时间周期解和角向依赖解，探索量子场论在弯曲时空中的行为。

Method: 使用Dirac方程分离变量法，将旋量分解为径向和角向方程；引入复常数参数ε₁、ε₂；分析解的L^p可积性条件；建立哈密顿量形式体系并研究其自伴性；在Schwarzschild时空中分析时间演化行为。

Result: 1. 大质量Majorana旋量在Kerr/Kerr-(A)dS时空中若依赖t或φ则不存在；2. 无质量Majorana旋量在非极端Kerr时空中可分离变量，当ε₁或ε₂为零时可显式求解；3. 当ε₁、ε₂非零时，存在L^p可积性限制下无时间周期解；4. 哈密顿量自伴性要求角动量a=0，时空间化为Schwarzschild，且旋量必须φ独立；5. 在Schwarzschild时空中，初始数据L^2衰减时，紧致区域内概率随时间趋于零。

Conclusion: Majorana旋量在旋转黑洞时空中受到严格限制：大质量解基本不存在，无质量解仅在特定条件下存在，且哈密顿量自伴性迫使时空退化为非旋转的Schwarzschild黑洞。这表明旋转时空对Majorana旋量的量子性质有深刻影响，可能对弯曲时空中的量子场论有重要启示。

Abstract: In this paper, we show that massive Majorana spinors \eqref{1.2} do not exist if they are $t$-dependent or $φ$-dependent in Kerr, or Kerr-(A)dS spacetimes. For massless Majorana spinors in the non-extreme Kerr spacetime, the Dirac equation can be separated into radial and angular equations, parameterized by two complex constants $ε_1$, $ε_2$. If at least one of $ε_1$, $ε_2$ is zero, massless Majorana spinors can be solved explicitly. If $ε_1$, $ε_2$ are nonzero, we prove the nonexistence of massless time-periodic Majorana spinors in the non-extreme Kerr spacetime which are $L^p$ outside the event horizon for $ 0<p\le\frac{6}{|ε_1|+|ε_2| +2}$. We then provide the Hamiltonian formulation for massless Majorana spinors and prove that the self-adjointness of the Hamiltonian leads to the angular momentum $a=0$ and spacetime reduces to the Schwarzschild spacetime, moreover, the massless Majorana spinor must be $φ$-independent. Finally, we show that, in the Schwarzschild spacetime, for initial data with $L^2$ decay at infinity, the probability of the massless Majorana spinors to be in any compact region of space tends to zero as time tends to infinity.

</details>


### [77] [Gravitational lensing in a warm plasma](https://arxiv.org/abs/2512.09341)
*Barbora Bezděková,Volker Perlick*

Main category: gr-qc

TL;DR: 本文研究温暖等离子体（非零温度）中光线在黑洞等致密天体附近的弯曲效应，计算了弯曲角和阴影，并应用于史瓦西和克尔时空中的静态/下落等离子体。


<details>
  <summary>Details</summary>
Motivation: 现有研究多假设冷等离子体（温度为零），但某些天体物理环境中等离子体温度很高，冷等离子体近似不再适用。需要研究温暖等离子体（小但非零温度）对光线弯曲的影响。

Method: 考虑温暖非磁化电子-离子等离子体，温度足够小以便线性化处理。建立广义相对论时空中此类介质的光线方程，聚焦于轴对称稳态情况（包含球对称静态情况）。计算温暖等离子体对弯曲角的影响，在球对称静态情况下计算阴影。

Result: 推导出温暖等离子体中光线弯曲的一般方程，计算了弯曲角的具体表达式，得到了阴影的解析结果。将理论应用于史瓦西和克尔时空中的静态（或共转）及下落温暖等离子体，展示了温度效应。

Conclusion: 温暖等离子体（即使温度很小）对光线弯曲和阴影有可观测的影响，为高温度天体物理环境中的光线传播提供了更精确的理论框架，扩展了冷等离子体近似的适用范围。

Abstract: Analytical studies of light bending in a dispersive medium near compact objects, e.g., black holes or neutron stars, are most challenged by a suitable definition of the medium. The most realistic model would be a hot magnetized plasma. In such a medium, however, an analytical description of light rays is very difficult. Therefore, usually an isotropic dispersive medium is assumed in analytical calculations. While it is possible to formulate equations for a general refractive index, which some studies do, most attention in the literature is given to the particular case of a cold, non-magnetized electron-ion plasma. Whereas this model covers many astrophysically relevant situations, there are indications that in some cases the plasma temperature is so high that the approximation of a cold plasma is no longer valid. For this reason, we consider in this paper a warm, non-magnetized electron-ion plasma, where the temperature is not set equal to zero but assumed to be small enough, such that relevant equations can be linearized with respect to it. After discussing the general equations for light rays in such a medium on a general-relativistic spacetime, we specify to the axially symmetric and stationary case which includes the spherically symmetric and static case. In particular, we calculate the influence of a warm plasma on the bending angle. In the spherically symmetric and static case, we also calculate the shadow in a warm plasma. We illustrate the general results with a static (respectively corotating) and an infalling warm plasma on Schwarzschild and Kerr spacetimes.

</details>


### [78] [Warm Inflation in a Braneworld Scenario](https://arxiv.org/abs/2512.09389)
*Sabina Yeasmin,Atri Deshamukhya*

Main category: gr-qc

TL;DR: 该论文研究了膜世界场景中的暖暴胀模型，考虑了恒定和可变的耗散系数，分析了强耗散和弱耗散两种机制下的模型表现，并利用Planck 2018和BICEP数据约束模型参数。


<details>
  <summary>Details</summary>
Motivation: 虽然文献中已有很多暖暴胀模型，但缺乏在膜世界场景下对暖暴胀模型的系统研究，特别是考虑不同耗散系数和耗散机制的情况。需要探索这种结合模型在宇宙学观测上的表现。

Method: 在膜世界场景下构建暖暴胀模型，考虑恒定和可变两种耗散系数。在慢滚近似下研究模型动力学，分析强耗散和弱耗散两种机制。计算宇宙学可观测量（谱指数和张标比），利用Planck 2018和BICEP观测数据约束模型参数。

Result: 获得了膜世界暖暴胀模型在两种耗散机制下的动力学行为，计算了相应的谱指数和张标比。通过观测数据约束了模型参数，验证了模型与当前宇宙学观测的一致性。

Conclusion: 膜世界场景下的暖暴胀模型是可行的，能够与当前宇宙学观测数据相符合。不同耗散系数和机制对模型预测有显著影响，这为理解早期宇宙暴胀机制提供了新的视角。

Abstract: In the literature, many warm inflationary models are formulated. In this piece of work, a warm inflationary model in the braneworld scenario is studied, considering constant and variable dissipation coefficients. Performance of the model has been considered in both strong and weak dissipative regimes. We study the dynamics of this scenario under slow-roll approximation and estimate cosmological observables, viz., the spectral index and tensor-to-scalar ratio. In order to constrain the parameters in our model, we consider data from Planck 2018 and BICEP.

</details>


### [79] [Dual Effective Field Theory formulation of Metric--Affine and Symmetric Teleparallel Gravity](https://arxiv.org/abs/2512.09516)
*Ginés R. Pérez Teruel*

Main category: gr-qc

TL;DR: 该论文提出了一个统一的代数与有效场论框架，用于处理具有独立联络的非黎曼广义相对论扩展，包括度量-仿射f(R,Q)引力、EiBI引力和对称远平行f(Q)引力。


<details>
  <summary>Details</summary>
Motivation: 为不同类型的非黎曼引力理论（度量-仿射引力、Born-Infeld型引力、非度量性引力）建立一个统一的代数与有效场论表述框架，解决联络方程的求解问题。

Method: 1. 对度量-仿射f(R,Q)引力，证明联络方程存在精确矩阵解，其平方根结构产生以应力张量T_μν为幂的收敛二项式/诺依曼展开；2. 对EiBI理论，证明联络可代数求解，其行列式场方程产生类似的诺依曼展开；3. 将爱因斯坦型方程重写为g_μν的有效爱因斯坦方程，带有局部代数修正(ΔT)_μν；4. 建立基于T_ν^μ谱半径的收敛准则；5. 将框架扩展到对称远平行f(Q)引力。

Result: 1. 获得了度量-仿射f(R,Q)引力和EiBI理论中联络方程的代数解；2. 证明了EiBI引力可作为相同T-塔的行列式重求和；3. 建立了收敛准则；4. 对f(Q)=Q+αQ^2给出了背景匹配；5. 构建了度量-仿射、Born-Infeld和非度量性引力的共同代数语言。

Conclusion: 该研究为不同类型的非黎曼引力理论建立了一个统一的代数与有效场论框架，通过联络方程的代数求解和诺依曼展开，将复杂的场方程转化为有效爱因斯坦方程形式，为这些理论的研究提供了新的数学工具和物理理解。

Abstract: We develop a unified algebraic and effective field theory (EFT) formulation for non--Riemannian extensions of General Relativity with an independent connection. For metric--affine $f(R,Q)$ gravity we show that the connection equations admit an exact matrix solution, whose square--root structure generates a convergent binomial/Neumann expansion in powers of the stress tensor $T_{μν}$. For the Eddington--inspired Born--Infeld (EiBI) theory we show that the connection can be solved algebraically as well, and that its determinantal field equations produce a parallel Neumann expansion with coefficients fixed by the underlying determinant operator. This allows us to rewrite the Einstein--like equations in the auxiliary metric as an effective Einstein equation for $g_{μν}$ with a local algebraic correction $(ΔT)_{μν}$ that follows from a dual EFT built from the invariants $\{T,\,T^2,\,T_{μν}T^{μν},\ldots\}$, organised by a characteristic density scale. We prove a convergence criterion based on the spectral radius of $\hat T^μ_ν$ and interpret EiBI gravity as a determinantal resummation of the same $T$--tower. Extending the framework to symmetric teleparallel $f(Q)$ gravity, we identify the EFT coefficients in terms of $f_Q$ and $f_{QQ}$ and present a background matching for $f(Q)=Q+αQ^2$. The resulting dual EFT provides a common algebraic language for metric--affine, Born--Infeld and non--metricity gravities.

</details>


### [80] [Improving the inference of the stellar quantities using the extended $I$-Love-$Q$-$δM$ relations](https://arxiv.org/abs/2512.09554)
*Eneko Aranguren,José A. Font,Nicolas Sanchis-Gual,Raül Vera*

Main category: gr-qc

TL;DR: 论文回顾了相对论天体物理中的I-Love-Q关系，讨论了使用背景质量M0进行归一化带来的观测限制，比较了两种解决方案：近似假设M0=Ms（仅适用于慢速旋转）和更精确的I-Love-Q-δM关系方法。


<details>
  <summary>Details</summary>
Motivation: I-Love-Q关系在天体物理中很有用，但使用不可观测的背景质量M0进行归一化限制了其直接应用。现有解决方案要么近似假设M0等于实际星体质量Ms（仅适用于慢速旋转），要么需要更精确的方法来克服这一限制。

Method: 回顾并数值比较两种方法：1）近似假设M0=Ms，适用于χ_S<0.1的慢速旋转；2）更精确的I-Love-Q-δM关系方法，通过额外参数δM来推断M0，克服了慢速旋转的限制。

Result: 数值比较显示，近似方法在慢速旋转（χ_S<0.1）时足够准确，但在快速旋转时误差显著增大。I-Love-Q-δM关系方法能够在更广泛的旋转参数范围内准确推断背景质量M0，提高了关系的实用性。

Conclusion: I-Love-Q-δM关系方法比简单的M0=Ms近似更优越，能够克服背景质量不可观测的限制，使I-Love-Q关系在更广泛的旋转参数范围内具有实际应用价值。

Abstract: In relativistic Astrophysics the $I$-Love-$Q$ relations refer to approximately EoS-independent relations involving the moment of inertia, Love number, and quadrupole moment through some quantities that are normalised by the mass $M_0$ of the background configuration of the perturbative scheme. Since $M_0$ is not an observable quantity, this normalisation hinders the direct applicability of the relations. A common remedy assumes that $M_0$ coincides with the actual mass of the star $M_S$; however, this approximation is only adequate for very slow rotation (when the dimensionless spin parameter is $χ_S<0.1$). The more accurate alternative approach, based on the $I$-Love-$Q$-$δM$ set of relations, circumvents this limitation by enabling the inference of $M_0$. Here we review both approaches and provide numerical comparisons.

</details>


### [81] [Relativistic accretion process onto rotating black holes in Einstein-Euler-Heisenberg nonlinear electrodynamic gravity](https://arxiv.org/abs/2512.09845)
*Orhan Donmez,G. Mustafa,Himanshu Chaudhary,M. Yousaf,Abdelmalek Bouzenada,Allah Ditta,Farruh Atamurotov*

Main category: gr-qc

TL;DR: 研究在EEH非线性电动力学框架下，通过分析测试粒子运动并数值求解广义相对论流体动力学方程，揭示了旋转黑洞周围的吸积动力学和振荡行为，发现电荷参数Q和自旋参数a显著改变强引力场并产生可观测的QPO特征。


<details>
  <summary>Details</summary>
Motivation: 探索非线性电动力学（EEH框架）如何影响旋转黑洞周围的吸积过程和振荡行为，特别是电荷参数Q和自旋参数a对强引力场特征频率和准周期振荡（QPO）的影响，为通过观测测试非线性电动力学理论提供依据。

Method: 1. 在EEH几何下计算圆轨道结构、有效势和力；2. 评估轨道、径向和垂直方向上的星体频率，以及Lense-Thirring和近星点进动率；3. 通过BHL机制数值模拟物质向EEH黑洞吸积的动力学结构；4. 对吸积率进行时间序列分析以识别QPO；5. 系统探索参数空间以确定EEH修正最大化QPO活动的区域。

Result: 1. 与Kerr模型相比，电荷参数Q和自旋参数a显著改变强引力场并移动特征频率；2. 参数Q增加落入黑洞的物质量并增强视界附近的激波锥不稳定性，但在远离黑洞处抑制吸积并减少湍流；3. 吸积率时间序列分析显示稳健的QPO，低频分量源于激波锥进动，高频分量则是由Q和a修改的强场不稳定性所致；4. 参数空间探索确定了EEH修正最大化QPO活动的区域。

Conclusion: 非线性电动力学可以在吸积流上留下可观测的印记，特别是通过影响QPO特征和视界尺度观测，这为通过天文观测测试非线性电动力学理论提供了可能途径。

Abstract: In this study, we uncover the accretion dynamics and oscillatory behavior around rotating black holes within the EEH nonlinear electrodynamic framework by analyzing both the motion of test particles and numerically solving the general relativistic hydrodynamic equations. Using EEH geometry, we compute the structure of circular motion, the effective potential and force, and we evaluate the orbital, radial, and vertical epicyclic frequencies together with the Lense-Thirring and periastron precession rates. Our calculations show that, compared to the Kerr model, the charge parameter $Q$ and the spin parameter $a$ significantly modify the strong gravitational field and shift the characteristic frequencies. We then model the dynamical structure formed by matter accreting toward the EEH black hole through the BHL mechanism, finding that the parameter $Q$ increases the amount of infalling matter and strengthens shock-cone instabilities near the horizon, while farther from the black hole it suppresses accretion and reduces turbulence. Time-series analysis of the accretion rate reveals robust QPOs, whose low-frequency components arise from the precession of the shock cone, while high-frequency components appear as a consequence of strong-field instabilities modified by $Q$ and $a$. A systematic parameter-space exploration identifies the regions where EEH corrections maximize QPO activity, indicating that nonlinear electrodynamics can leave observable imprints on accretion flows and may be testable with QPO and horizon-scale observations.

</details>


### [82] [Static Charged Polytropic Spheres with a Cosmological Constant: Physical Acceptability and Trapped Orbits](https://arxiv.org/abs/2512.09846)
*Alex Stornelli,Anish Agashe*

Main category: gr-qc

TL;DR: 研究带宇宙学常数的静态带电流体球，采用多方状态方程和幂律电荷分布，通过数值求解TOV方程分析物理性质，研究不同粒子（中性/带电、有质量/无质量）在参数空间中的轨道囚禁现象。


<details>
  <summary>Details</summary>
Motivation: 研究带电流体球在广义相对论框架下的物理性质，特别是超越传统零测地线研究，探索带电/有质量粒子的轨道囚禁现象，理解粒子自身属性对囚禁的影响。

Method: 采用多方状态方程(p∝ρ^Γ)和幂律电荷分布(q∝r^n)，将广义TOV方程转化为质量分布的微分方程，通过数值求解分析物理和几何性质，施加亚光速声速和能量条件约束物理可接受配置。

Result: 数值分析显示：仅中性零质量粒子的囚禁完全取决于时空性质；其他三种情况（带电/有质量粒子）的囚禁还依赖于粒子自身的电荷和能量属性；所有类型粒子的囚禁在广泛的n-Γ参数空间中都是可能的。

Conclusion: 带电流体球支持多种粒子的轨道囚禁，中性零质量粒子的囚禁是纯粹的时空几何效应，而带电/有质量粒子的囚禁则涉及粒子与背景场的相互作用，为理解致密天体中的粒子动力学提供了新视角。

Abstract: We consider static charged fluid spheres with a cosmological constant. We assume a polytropic equation of state, $p \propto ρ^Γ$, and a power law charge distribution, $q\propto r^n$. Using this, we convert the generalised Tolman-Oppenheimer-Volkoff equation into a differential equation for the mass profile. By solving this equation numerically, we analyse both physical and geometric properties of these charged fluid spheres for different values of $n$ and $Γ$. By imposing subluminal sound speeds and energy conditions, we restrict ourselves to configurations that are physically acceptable. Then, within these physical models, we study internal trapping of circular geodesics and find the trapping regions in the $n$-$Γ$ parameter space. Going beyond the traditionally studied case of null geodesics, we consider orbits of charged and/or massive particles. We show that for neutral null particles (and only for them), their trapping depends purely on the properties of the space-time. In the other three cases, properties such as the particle's own charge and/or energy also play a role. In general, we find that trapping of all types of particles is allowed for a broad range of $n$ and $Γ$.

</details>


### [83] [Light trajectories and optical appearances in asymptotically Anti-de Sitter-Schwarzschild and black string space-times](https://arxiv.org/abs/2512.09869)
*G. Alencar,Arthur Lima,Diego Rubiera-Garcia,Diego Sáez-Chillón Gómez*

Main category: gr-qc

TL;DR: 本文研究非渐近平坦（Anti-de Sitter）时空中的黑洞和超致密天体在事件视界望远镜观测中的光学特征，探讨其与标准Kerr黑洞的区别。


<details>
  <summary>Details</summary>
Motivation: 事件视界望远镜对M87和银河系中心天体的观测支持Kerr黑洞模型。随着VLBI技术的发展，需要研究各种修正黑洞和超致密天体的光学特征。本文特别关注非渐近平坦（Anti-de Sitter）时空中的天体，因为这种时空结构会显著影响光线轨迹和观测图像。

Method: 研究Anti-de Sitter时空中的天体（如Schwarzschild-Anti-de Sitter黑洞和黑洞弦）的光线轨迹模拟和光学图像重建。分析这些非渐近平坦时空如何影响光线传播路径，从而产生与标准渐近平坦黑洞不同的观测特征。

Result: Anti-de Sitter时空结构显著改变了光线轨迹，导致观测图像与标准Kerr黑洞存在明显差异。这些差异形成了独特的"指纹"，可用于未来VLBI观测中区分不同类型的黑洞模型。

Conclusion: 非渐近平坦时空中的黑洞和超致密天体具有独特的光学特征，这些特征可用于未来VLBI观测测试Kerr黑洞范式的替代理论。研究为区分不同时空几何提供了理论框架。

Abstract: The Event Horizon Telescope (EHT) imaging of the central objects in the M87 and Milky Way galaxies provide compelling evidence that these objects are consistent with (Kerr) black holes. In view of these observations and the future expectations of Very Long Baseline Interferometry (VLBI) on which the EHT observations are based, an intensive research work has been carried out in the literature to simulating light trajectories and reconstructing the corresponding optical appearance for a wide array of modified black holes and ultra-compact objects. The corresponding images are directly affected not only by the background space-time geometry but also by the physics of the accretion disk, whose combination yields a characteristic fingerprint. In this paper, we consider such a fingerprint for objects which are not asymptotically flat but instead approach a Anti-de Sitter space-time. This assumption significantly influences light trajectories and, consequently, the corresponding images of the objects as seen by an observer at some distance, which can be used in future VLBI observations for testing alternatives of this kind to the Kerr paradigm. We illustrate our considerations with the examples of a Schwarzschild-Anti-de Sitter black hole and a black string, discussing their most notable departures from canonical, asymptotically-flat black hole space-times.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [84] [Rotational excitation of molecules in the regime of strong ro-vibrational coupling: Comparison between an optical centrifuge and a transform-limited pulse](https://arxiv.org/abs/2512.09746)
*J. M. García-Garrido,V. Milner,C. P. Koch,R. González-Férez*

Main category: quant-ph

TL;DR: 光学离心机可在刚性转子近似失效时控制分子转动，实现高转动态激发同时保持振动坐标的低展宽，优于线性偏振高斯脉冲


<details>
  <summary>Details</summary>
Motivation: 研究光学离心机在刚性转子近似失效情况下的分子转动控制能力，此时振动和转动自由度之间存在耦合

Method: 理论分析光学离心机（线性偏振以加速速率旋转的激光脉冲）对分子转动的控制效果，并与具有相同光谱宽度和脉冲能量的线性偏振高斯脉冲进行对比

Result: 离心机场能够实现高转动态的可控激发，同时保持振动坐标的相对低展宽；而线性偏振高斯脉冲虽然能产生相当的转动激发，但不可避免地伴随显著的振动波包展宽

Conclusion: 光学离心机在振动-转动耦合存在的情况下，能够更有效地控制分子转动，实现高转动激发的同时最小化振动激发，为分子动力学控制提供了优势方法

Abstract: We investigate theoretically the ability of an optical centrifuge - a laser pulse whose linear polarization is rotating at an accelerated rate, to control molecular rotation in the regime when the rigid-rotor approximation breaks down due to coupling between the vibrational and rotational degrees of freedom. Our analysis demonstrates that the centrifuge field enables controlled excitation of high rotational states while maintaining relatively low spread along the vibrational coordinate. We contrast this to the rotational excitation by a linearly polarized Gaussian pulse of equal spectral width and pulse energy which, although comparable to the centrifuge-induced rotation, is unavoidably accompanied by a substantial broadening of the vibrational wavepacket.

</details>


### [85] [An ETH-ansatz-based environmental-branch approach to master equation](https://arxiv.org/abs/2512.09007)
*Wen-ge Wang*

Main category: quant-ph

TL;DR: 提出一种推导主方程的方法，适用于与满足本征态热化假设的量子混沌环境局部耦合的小量子系统，无需Born近似和Markov近似。


<details>
  <summary>Details</summary>
Motivation: 传统推导主方程的方法通常依赖于Born近似和Markov近似，这些近似在环境是量子混沌系统时可能不成立。本文旨在开发一种更通用的方法，适用于量子混沌环境，不依赖这些传统近似。

Method: 基于总系统的薛定谔演化，初始条件要求环境分支与相互作用哈密顿量无关联。推导主方程采用分段使用环境分支演化的形式表达式的二阶展开，近似主要基于环境的动力学特性。

Result: 开发了一种新的主方程推导方法，适用于与量子混沌环境耦合的小量子系统，该方法不依赖Born近似和Markov近似，而是基于环境的动态特性。

Conclusion: 该方法为研究量子混沌环境中的开放量子系统动力学提供了一种更准确的理论框架，特别适用于传统近似失效的情况。

Abstract: In this paper, a method for deriving master equation is developed for a generic small quantum system, which is locally coupled to an environment as a many-body quantum chaotic system that satisfies the eigenstate thermalization hypothesis ansatz, resorting to neither the Born approximation nor the Markov approximation. The total system undergoes Schrödinger evolution, under an initial condition in which the environmental branches possess no correlation with the interaction Hamiltonian. Derivation of the master equation is based on piecewise usage of a second-order expansion of a formal expression, which is derived for the evolution of the environmental branches. Approximations used in the derivation are mainly based on dynamic properties of the environment.

</details>


### [86] [The Richness of Bell Nonlocality: Generalized Bell Polygamy and Hyper-Polygamy](https://arxiv.org/abs/2512.09034)
*Gerard Anglès Munné,Paweł Cieśliński,Jan Wójcik,Wiesław Laskowski*

Main category: quant-ph

TL;DR: 该论文展示了多体量子系统中贝尔非定域性的"超多配偶"现象：单个N量子比特态可以同时违反所有相关的(N-k)体贝尔不等式，揭示了多体量子态中非定域性的丰富性。


<details>
  <summary>Details</summary>
Motivation: 研究多体量子系统中贝尔非定域性的多配偶性质，探索量子非定域性在多体系统中的丰富表现，为量子技术应用提供新视角。

Method: 通过对称化(N-k)量子比特的贝尔不等式构造N量子比特贝尔不等式，利用MABK不等式的对称性质进行分析，比较GHZ态的违反情况。

Result: 证明了单个N量子比特态可以同时违反所有binom(N,k)个相关的(N-k)体贝尔不等式，展示了超多配偶现象，且多配偶在多体场景中具有优势。

Conclusion: 多体量子态中存在丰富的非定域性结构，超多配偶现象为量子设备中非经典性的可扩展认证提供了新见解，在量子技术中具有应用前景。

Abstract: Non-classical quantum correlations underpin both the foundations of quantum mechanics and modern quantum technologies. Among them, Bell nonlocality is a central example. For bipartite Bell inequalities, nonlocal correlations obey strict monogamy: a violation of one inequality precludes violations of other inequalities on the overlapping subsystems. In the multipartite setting, however, Bell nonlocality becomes inherently polygamous. This was previously shown for subsystems obtained by removing a single particle from an $N$-partite system. Here, we generalize this result to arbitrary $(N-k)$-partite subsystems with $k>0$. We demonstrate that a single $N$-qubit state can violate all $\binom{N}{k}$ relevant Bell inequalities simultaneously. We further construct an $N$-qubit Bell inequality, obtained by symmetrizing the $(N-k)$-qubit ones, that is maximally violated by states exhibiting this generalized polygamy. We compare these violations with those achievable by GHZ states and show that polygamy offers an advantage in multipartite scenarios, providing new insights into scalable certification of non-classicality in quantum devices. Our analysis relies on symmetry properties of the MABK inequalities. Finally, we show that this behavior can occur across multiple subsystem sizes, a phenomenon we call hyper-polygamy. These structures reveal the remarkable abundance of nonlocality present in multipartite quantum states and offer perspectives for their applications in quantum technologies.

</details>


### [87] [Slow dynamics and magnon bound states in the 2D long-range quantum Ising model](https://arxiv.org/abs/2512.09037)
*Vighnesh Dattatraya Naik,Markus Heyl*

Main category: quant-ph

TL;DR: 利用神经量子态模拟长程量子伊辛模型在2D中的全局淬火动力学，发现慢弛豫和长寿命振荡，解释为幂律相互作用导致的磁振子束缚态形成。


<details>
  <summary>Details</summary>
Motivation: 长程量子伊辛模型的动力学是实验物理的前沿（如囚禁离子或里德堡原子系统），但传统方法难以描述1D以上的理论，需要新方法解决这一挑战。

Method: 使用神经量子态方法模拟2D量子伊辛模型从完全极化铁磁态的全局淬火动力学，该模型具有幂律衰减相互作用。

Result: 数值精确模拟显示动力学呈现慢弛豫和长寿命振荡行为，通过磁振子束缚态形成理论解释，表明幂律相互作用导致磁振子间存在有效吸引相互作用。

Conclusion: 研究结果可直接在现有量子模拟平台（如里德堡原子系统）中观测，为理解长程相互作用模型的动力学提供了新见解。

Abstract: The dynamics of long-range quantum Ising models represents a current frontier in experimental physics, notably in trapped ions or Rydberg atomic systems. However, a theoretical description of these dynamics beyond 1D remains a significant challenge for conventional methods. Here, we address this challenge by means of neural quantum states to simulate global quenches from the fully polarized ferromagnetic state in the 2D quantum Ising model with power-law decaying interactions. From these numerically exact simulations, we find that the dynamics exhibit slow relaxation with long-lived oscillations. We explain this behavior through a theory for the formation of magnon bound states, which are generated, as we show, through effective attractive interactions between magnons that persist over several lattice sites due to the power-law nature of the interactions. Our results are readily observable in current quantum simulation platforms realizing long-range interacting models such as in Rydberg atomic systems.

</details>


### [88] [Optimizing the dynamical preparation of quantum spin lakes on the ruby lattice](https://arxiv.org/abs/2512.09040)
*DinhDuy Vu,Dominik S. Kufel,Jack Kemp,Lode Pollet,Chris R. Laumann,Norman Y. Yao*

Main category: quant-ph

TL;DR: 利用近似对称神经量子态模拟Rydberg量子模拟器中的量子自旋"湖"态动态制备，在384原子系统中优化得到接近ln2拓扑纠缠熵的自旋液体性质


<details>
  <summary>Details</summary>
Motivation: 实验发现Rydberg量子模拟器可动态制备具有量子自旋液体关联的态，即使基态相图不包含拓扑相。理解这种量子自旋"湖"态的微观本质及其与平衡自旋液体序的关系至关重要

Method: 扩展近似对称神经量子态用于实时演化，直接模拟动态制备过程，在N=384原子系统中分析多种自旋液体诊断指标，优化量子自旋湖的扩展范围

Result: 最优制备状态下，自旋液体性质扩展到系统尺寸的一半，拓扑纠缠熵接近γ=ln2。提取两个物理长度尺度λ和ξ，分别从上下约束量子自旋湖的扩展范围ℓ

Conclusion: 成功利用神经量子态模拟量子自旋湖的动态制备，揭示了其微观特性与长度尺度约束，为理解非平衡量子自旋液体提供了新见解

Abstract: Quantum spin liquids are elusive long-range entangled states. Motivated by experiments in Rydberg quantum simulators, recent excitement has centered on the possibility of dynamically preparing a state with quantum spin liquid correlation even when the ground state phase diagram does not exhibit such a topological phase. Understanding the microscopic nature of such quantum spin "lake" states and their relationship to equilibrium spin liquid order remains an essential question. Here, we extend the use of approximately symmetric neural quantum states for real-time evolution and directly simulate the dynamical preparation in systems of up to $N=384$ atoms. We analyze a variety of spin liquid diagnostics as a function of the preparation protocol and optimize the extent of the quantum spin lake thus obtained. In the optimal case, the prepared state shows spin-liquid properties extending over half the system size, with a topological entanglement entropy plateauing close to $γ= \ln 2$. We extract two physical length scales $λ$ and $ξ$ which constrain the extent of the quantum spin lake $\ell$ from above and below.

</details>


### [89] [Quantum bootstrap for central potentials](https://arxiv.org/abs/2512.09041)
*Scott Lawrence,Brian McPeak*

Main category: quant-ph

TL;DR: 该论文研究量子力学自举方法在三维中心势束缚态中的应用，展示了该方法对非代数势（如Yukawa势和高斯势）的适用性，并实现了Cornell势的高精度计算。


<details>
  <summary>Details</summary>
Motivation: 探索量子力学自举方法在更广泛势场中的应用，特别是针对非代数势，以验证该方法作为高精度数值计算工具的通用性和有效性。

Method: 采用量子力学自举方法，通过构建算符期望值的约束条件来求解束缚态能量。该方法适用于多种中心势，包括Coulomb势、Cornell势、Yukawa势和高斯势等。

Result: 成功将自举方法应用于非代数势，实现了Cornell势临界耦合常数的高精度计算（精度优于10^-7），这是目前最精确的测定结果。同时获得了高精度的能量下界（部分精度超过10^-8），并讨论了获得有意义上界的情况。

Conclusion: 量子力学自举方法是一种强大的高精度数值计算工具，适用于包括非代数势在内的多种势场，特别适用于基态物理的高精度计算，为量子力学数值方法提供了新的可能性。

Abstract: We study the quantum-mechanical bootstrap as it applies to the bound states of several central potentials in three dimensions. As part of this effort, we show how the bootstrap approach may be applied to ``non-algebraic'' potentials, such as the Yukawa potential (which asymptotically decays as an exponential) and a Gaussian potential. We additionally review the bootstrap of the Coulomb potential, demonstrate a high-precision bootstrap of the Cornell potential, and study conformal quantum mechanics. These results further recommend the bootstrap as a numerical method for high-precision calculations of ground-state physics, where applicable: for example, we are able to determine the critical coupling in the Cornell potential to better than one part in $10^7$, the most precise determination to date. Lower bounds on energies are also of high precision, occasionally one part in greater than $10^8$. Finally, we discuss the circumstances under which we are able to obtain meaningful upper bounds on ground-state energies.

</details>


### [90] [Dressed-state Hamiltonian engineering in a strongly interacting solid-state spin ensemble](https://arxiv.org/abs/2512.09043)
*Haoyang Gao,Nathaniel T. Leitao,Siddharth Dandavate,Lillian B. Hughes Wyatt,Piotr Put,Mathew Mammen,Leigh S. Martin,Hongkun Park,Ania C. Bleszynski Jayich,Mikhail D. Lukin*

Main category: quant-ph

TL;DR: 本文提出了一种直接调控金刚石中氮空位中心自旋相互作用的量子调控方法，相比传统Floquet工程，将相干参数提升3.2倍，磁测量灵敏度提升2.6倍（8.3dB）。


<details>
  <summary>Details</summary>
Motivation: 传统Floquet工程方法虽然能调控自旋间的偶极相互作用，但通常会降低相互作用强度，从而削弱与目标传感场的耦合，限制了量子计量学的灵敏度。

Method: 采用垂直于晶体晶格取向的磁场下的dressed-state量子比特编码方法，直接调控氮空位中心自旋系综中的原生相互作用。

Result: 实现了无量纲相干参数JT₂相比最先进Floquet工程提升3.2倍，交流磁测量灵敏度提升2.6倍（8.3dB），并利用延长的相干时间实验探测了中晚期自旋输运。

Conclusion: 该方法为氮空位中心系综和其他相互作用的高自旋（S>½）系统研究提供了强大的哈密顿量工程工具。

Abstract: In quantum science applications, ranging from many-body physics to quantum metrology, dipolar interactions in spin ensembles are controlled via Floquet engineering. However, this technique typically reduces the interaction strength between spins, and effectively weakens the coupling to a target sensing field, limiting the metrological sensitivity. In this work, we develop and demonstrate a method for direct tuning of the native interaction in an ensemble of nitrogen-vacancy (NV) centers in diamond. Our approach utilizes dressed-state qubit encoding under a magnetic field perpendicular to the crystal lattice orientation. This method leads to a $3.2\times$ enhancement of the dimensionless coherence parameter $JT_2$ compared to state-of-the-art Floquet engineering, and a $2.6\times$ ($8.3~$dB) enhanced sensitivity in AC magnetometry. Utilizing the extended coherence we experimentally probe spin transport at intermediate to late times. Our results provide a powerful Hamiltonian engineering tool for future studies with NV ensembles and other interacting higher-spin ($S>\frac{1}{2}$) systems.

</details>


### [91] [Subradiant collective states for precision sensing via transmission spectra](https://arxiv.org/abs/2512.09050)
*Diego Zafra-Bono,Oriol Rubies-Bigorda,Susanne F. Yelin*

Main category: quant-ph

TL;DR: 利用亚辐射态进行量子计量学，通过原子阵列或波导耦合系统产生窄线宽特征，提高对外部扰动的灵敏度


<details>
  <summary>Details</summary>
Motivation: 量子发射体与共同辐射场相互作用会产生超辐射和亚辐射态，其中亚辐射态具有窄线宽特性。本文旨在利用这些亚辐射态进行量子计量学应用，提高对外部扰动的测量灵敏度。

Method: 提出利用亚波长间距的原子阵列（自由空间）或小规模发射体集合（耦合到一维波导）中自然产生的亚辐射态。通过分析这些系统的集体光学响应，研究其在透射光谱中产生的尖锐、窄线宽特征。

Result: 亚辐射态的集体光学响应在透射光谱中产生尖锐的窄线宽特征，这些特征可用于增强对外部扰动的灵敏度。这种改进的灵敏度可应用于原子钟操作、发射体位置的空间分辨成像，以及精确检测全局和空间变化的失谐（如电磁场或引力梯度引起的失谐）。

Conclusion: 亚辐射态为量子计量学提供了有前景的平台，其窄线宽特征能够显著提高测量灵敏度，在原子钟、空间成像和精密检测等领域具有重要应用价值。

Abstract: When an ensemble of quantum emitters interacts with a common radiation field, their emission becomes collective, giving rise to superradiant and subradiant states, characterized by broadened and narrowed linewidths. In this work, we propose to harness subradiant states for quantum metrology; such states naturally arise in subwavelength-spaced atomic arrays in free space and in small ensembles of emitters coupled to one-dimensional waveguides. We demonstrate that their collective optical response yields sharp, narrow features in the transmittance spectrum, which can be used to enhance sensitivity to external perturbations. This improved sensitivity can be applied to atomic clock operation, spatially resolved imaging of emitter positions, and enables precise detection of both global and spatially varying detunings (such as those induced by electromagnetic fields or gravitational gradients).

</details>


### [92] [Quantum Clocks Tick Faster: Entanglement, Contextuality, and the Flow of Time](https://arxiv.org/abs/2512.09100)
*Karl Svozil*

Main category: quant-ph

TL;DR: 纠缠时钟协议利用单重态关联定义时空度规，在钝角测量几何下比经典模型快13%，其非经典特性需要同时考虑多个角度的关联并违反贝尔不等式来认证。


<details>
  <summary>Details</summary>
Motivation: 基于"单一真实时钟足以定义时空度规"的提议，探索如何用量子纠缠系统建立共享时间标准，研究量子时间同步与经典模型的根本区别。

Method: 提出基于单重态关联的纠缠时钟协议，利用Zeilinger基础原理分析局部时间流的随机性，比较量子预测与Peres经典"炸弹碎片"模型的符合率。

Result: 在钝角相对角度下，纠缠时钟比线性经典基准的同步滴答率高13%，这种"时间加速"与量子语境性相关，但单一角度下经典模型可复制量子速率。

Conclusion: 纠缠时钟的真正非经典特性需要同时考虑多个角度的关联并违反贝尔型不等式来认证，这为共享时间标准提供了量子认证方法。

Abstract: Building on the recent proposal that a single ``bona fide'' clock suffices to define spacetime's metric, we introduce an Entangled Clock protocol based on singlet-state correlations. Invoking Zeilinger's Foundational Principle, we argue that while the local flow of time, operationally defined as a sequence of detector ``ticks,'' is irreducibly random (one bit per elementary system), the synchronized flow between spatially separated observers depends on their measurement geometry. Comparing the quantum prediction for the coincidence rate with Peres' classical ``bomb fragment'' model, we find that at obtuse relative angles the entangled clock exhibits a 13 percent higher synchronized tick rate than this linear classical benchmark. This ``temporal acceleration'' is linked to contextuality: following Peres, ``unperformed experiments have no results,'' and quantum systems are not constrained to maintain consistency with all counterfactual measurement settings. We stress, however, that for any single measurement angle a suitably tailored classical model can reproduce the quantum rate. The genuinely nonclassical character of the entangled clock emerges only when correlations at several angles are considered simultaneously and are shown to violate Bell-type inequalities. In this sense, the violation of Bell-type bounds serves as a certification that the shared time standard is genuinely quantum.

</details>


### [93] [Islands of Instability in Nonlinear Wavefunction Models in the Continuum: A Different Route to "Chaos"](https://arxiv.org/abs/2512.09109)
*W. David Wick*

Main category: quant-ph

TL;DR: 作者提出了一种绕过精确解限制的方法，通过将测试函数代入可计算表达式来验证波函数模型中非线性演化导致的不稳定性判据，适用于实际分子间势能。


<details>
  <summary>Details</summary>
Motivation: 先前研究发现了非线性波函数演化中可能出现的"不稳定岛"，但连续模型的例子仅限于线性薛定谔方程可精确求解的情况。由于多体问题的精确解罕见，需要开发不依赖精确解的方法来验证不稳定性判据。

Method: 提出通过将测试函数代入可计算表达式来验证不稳定性判据的方法，绕过精确解的限制。该方法可以处理实际的分子间势能，适用于流体和气体中的不稳定性研究。

Result: 开发了一种不依赖精确解的方法来验证波函数模型中非线性演化导致的不稳定性判据，使研究能够扩展到更实际的物理系统。

Conclusion: 该方法突破了精确解的限制，使得研究非线性波函数演化中的不稳定性可以应用于更广泛的物理系统，包括具有实际分子间势能的流体和气体。

Abstract: In two previous papers the author described ``Islands of Instability" that may appear in wavefunction models with nonlinear evolution (of a type proposed originally in the context of the Measurement Problem). Such ``IsoI" represent a new scenario for Hamiltonian systems implying so-called ``chaos". Criteria was derived for, and shown to be fulfilled in, some finite-dimensional (multi-qubit) models, and generalized in the second paper to continuum models. But the only example produced of the latter was a model whose linear Schrodinger equation was exactly-solvable. As exact solutions of many-body problems are rare, here I show that the instability criteria can be verified by plugging test-functions into certain computable expressions, bypassing the solvability blockade. The method can accommodate realistic inter-molecular potentials and so may be relevant to instabilities in fluids and gasses.

</details>


### [94] [Enhanced Squeezing and Faster Metrology from Layered Quantum Neural Networks](https://arxiv.org/abs/2512.09137)
*Nickholas Gutierrez,Rodrigo Araiza Bravo,Susanne Yelin*

Main category: quant-ph

TL;DR: 量子神经网络结构可用于设计更快、更灵敏的压缩型量子传感器，多层QNN相比QRC和单层感知器在灵敏度和压缩时间上都有优势


<details>
  <summary>Details</summary>
Motivation: 比较不同量子架构（量子储备计算机、量子感知器、多层量子神经网络）作为压缩型场传感器的性能，探索量子神经网络结构在量子传感中的应用潜力

Method: 采用标准计量序列：相干自旋制备、单轴扭曲动力学、弱旋转场编码、时间反转和集体读出。比较三种架构在相同条件下的性能，特别分析多层QNN中压缩加速效应

Result: 单层量子感知器与QRC具有相同最优灵敏度，但在微扰区域有加速压缩效应。多层QNN（N_in输入、N_out输出）可将最优压缩时间减少N_out倍，同时保持海森堡极限灵敏度Δφ～1/(N_in+N_out)。当层间顺序使用时，灵敏度比QRC提高√2倍。L层QNN的计量增益按√L缩放，所需压缩时间按1/N_l减少

Conclusion: 量子神经网络结构不仅可用于计算，还能用于设计更快、更灵敏的压缩型量子传感器，多层结构通过层间相互作用实现加速压缩和灵敏度增强

Abstract: Spin squeezing is a powerful resource for quantum metrology, and recent hardware platforms based on interacting qubits provide multiple possible architectures to generate and reverse squeezing during a sensing protocol. In this work, we compare the sensing performance of three such architectures: quantum reservoir computers (QRCs), quantum perceptrons, and multi-layer quantum neural networks (QNNs), when used as squeezing-based field sensors. For all models, we consider a standard metrological sequence consisting of coherent-spin preparation, one-axis-twisting dynamics, field encoding via a weak rotation, time-reversal, and collective readout. We show that a single quantum perceptron generates the same optimal sensitivity as a QRC, but in the perturbative regime it benefits from accelerated squeezing due to steering by the output qubit. Stacking perceptrons into a QNN further amplifies this effect: in a 2-layer QNN with N_in input and N_out output qubits, the optimal squeezing time is reduced by a factor of N_out, while the achievable phase sensitivity remains Heisenberg-limited, Delta phi ~ 1/(N_in + N_out). Moreover, if the layers are used sequentially, first using the outputs to squeeze the inputs and then the inputs to squeeze the outputs, the two contributions to the response add constructively. This yields a sqrt(2) enhancement in sensitivity over a QRC when N_in = N_out and requires shorter total squeezing time. Generalizing to L layers, we show that the metrological gain scales as sqrt(L) while the required squeezing time decreases as 1/N_l, where N_l is the number of qubits per layer. Our results demonstrate that the structure of quantum neural networks can be exploited not only for computation, but also to engineer faster and more sensitive squeezing-based quantum sensors.

</details>


### [95] [Spontaneous Decoherence from Imaginary-Order Spectral Deformations](https://arxiv.org/abs/2512.09236)
*Sridhar Tayur*

Main category: quant-ph

TL;DR: 该论文提出一种通过哈密顿量的虚阶谱形变 $H^{1+iβ}$ 实现自发退相干的机制，其中快速振荡的相位因子 $E^{iβ}$ 抑制不同能量态之间的干涉。


<details>
  <summary>Details</summary>
Motivation: 物理动机来源于时钟不完美性、重整化群和有效作用量修正引入的对数谱项，以及半经典量子引力分析中复数作用量产生的 $E^{iβ}$ 型谱因子。这些因素在量子引力有效理论中普遍出现对数谱修正。

Method: 将量子动力学生成元替换为正定哈密顿量 $H$ 的虚阶谱形变 $H^{1+iβ}$。通过非驻相分析定量估计振幅或退相干泛函中振荡贡献的衰减速率（至少为 $O(1/|β|)$）。

Result: 该机制在保持玻恩规则和希尔伯特空间内积不变的前提下，通过确定性谱相位实现退相干。具体示例包括FRW迷你超空间、四次势、弯曲背景哈密顿量和类史瓦西内部模型，展示了明确的退相干速率。参数 $β$ 可通过低噪声量子平台的精密相干测量进行实验约束。

Conclusion: 该框架作为量子引力有效理论中对数谱修正的紧凑且可测试的现象学表示，与Milburn型内禀退相干、Diosi-Penrose引力坍缩和实阶分数动力学不同，它完全通过单个哈密顿量的确定性谱相位作用。

Abstract: We examine a mechanism of spontaneous decoherence in which the generator of quantum dynamics is replaced by the imaginary-order spectral deformation $H^{1+iβ}$ of a positive Hamiltonian $H$. The deformation modifies dynamical phases through the factor $E^{iβ} = e^{iβ\log E}$, whose rapid oscillation suppresses interference between distinct energies. A non-stationary-phase analysis yields quantitative estimates showing that oscillatory contributions to amplitudes or decoherence functionals decay at least as $O(1/|β|)$. The Born rule and the Hilbert-space inner product remain unchanged; the modification is entirely dynamical.
  The physical motivation for the deformation arises from clock imperfections, renormalization-group and effective-action corrections that introduce logarithmic spectral terms, and semiclassical quantum-gravity analyses in which complex actions produce spectral factors of the form $E^{iβ}$. Examples including FRW minisuperspace, quartic potentials, curved-background Hamiltonians, and a Schwarzschild interior-type model illustrate how the mechanism yields explicit decoherence rates. The parameter $β$ may be experimentally constrained through precision coherence measurements in low-noise quantum platforms. The mechanism contrasts with Milburn-type intrinsic decoherence, Diosi-Penrose gravitational collapse, and real-order fractional dynamics in that it acts purely through deterministic spectral phases of a single Hamiltonian. The analysis positions the framework as a compact and testable phenomenological representation of logarithmic spectral corrections appearing in quantum-gravity-motivated effective theories.

</details>


### [96] [Transition rates and their applications in accelerated single-qubit for fermionic spinor field coupling](https://arxiv.org/abs/2512.09144)
*Arnab Mukherjee,Sunandan Gangopadhyay,P. H. M. Barros,H. A. S. Costa*

Main category: quant-ph

TL;DR: 研究加速量子比特与费米子场的相互作用，发现费米子场耦合比标量场导致更快的量子相干性退相干，而粒子质量对Unruh效应引起的退相干具有保护作用。


<details>
  <summary>Details</summary>
Motivation: 研究均匀加速的量子比特与费米子旋量场（包括无质量和有质量情况）的相互作用，探索Unruh-DeWitt探测器在费米子场中的量子相干性演化，并与标量场情况进行比较。

Method: 采用微扰理论研究有限时间内量子比特与费米子场的相互作用，计算跃迁概率率，并基于此评估初始处于量子比特态的Unruh-DeWitt探测器的量子相干性。

Result: 1. UDW探测器与费米子场耦合时响应更强；2. 费米子场情况下的量子相干性退相干比标量场情况快得多；3. 粒子质量对Unruh效应引起的退相干具有保护作用，当静止质量能与探测器能级间距相当时，探测器激发概率和响应减小，从而减缓量子相干性退化。

Conclusion: 费米子场耦合比标量场导致更剧烈的量子相干性退相干，而粒子质量可以作为对抗Unruh效应引起的退相干的保护机制，这对理解加速量子系统的量子特性具有重要意义。

Abstract: In this work, we investigate the interaction between a uniformly accelerated single qubit and a fermionic spinor field. Here we consider both the massless and the massive fermionic spinor fields. The qubit-field interaction occurs over a finite time and was evolved via perturbation theory. This approach yields the transition probability rates, from which we subsequently evaluate the quantum coherence of an Unruh-DeWitt (UDW) detector initially prepared in a qubit state. Our findings reveal that the UDW detector responds more when coupled with the fermionic field, and consequently, quantum coherence (for the fermionic case) degrades much more rapidly when compared to the case of the qubit linearly coupled with the scalar field. Moreover, the analysis suggests that particle mass plays a protective role against Unruh-induced decoherence as the rest mass energy becomes comparable to the detector's energy-level spacing, the detector's excitation probability and response decreases, which leads to the mitigation of quantum coherence degradation in accelerated quantum systems.

</details>


### [97] [Harvesting entanglement from the Lorentz-violating quantum field vacuum in a dipolar Bose-Einstein condensate](https://arxiv.org/abs/2512.09263)
*Zehua Tian,Weiping Yao,Xiaobao Liu,Mengjie Wang,Jieci Wang,Jiliang Jing*

Main category: quant-ph

TL;DR: 提出利用偶极玻色-爱因斯坦凝聚体作为洛伦兹破缺量子场真空，通过浸入其中的杂质对作为Unruh-DeWitt探测器，研究从洛伦兹破缺量子场真空中提取纠缠的方案。


<details>
  <summary>Details</summary>
Motivation: 探索从洛伦兹破缺量子场真空中提取纠缠的机制，为研究量子场论中的洛伦兹破缺提供实验可行的测试平台。

Method: 使用超低温偶极BEC模拟洛伦兹破缺量子场真空，两个杂质作为Unruh-DeWitt探测器，研究探测器从BEC准粒子中提取纠缠的参数依赖性。

Result: 发现与洛伦兹不变情况不同：1）更平滑的探测器开关不能增强纠缠提取效率；2）洛伦兹破缺强度会改变探测器的最优能级结构；3）确定了优化纠缠提取的关键参数依赖关系。

Conclusion: 该量子流体平台为从有效洛伦兹破缺量子场真空中提取纠缠提供了实验可行的测试床，对探索量子场论中的洛伦兹破缺具有潜在意义。

Abstract: We theoretically propose an experimentally viable scheme to explore the transfer of nonclassical correlations from a dipolar Bose-Einstein condensate (BEC) to a pair of impurities immersed in it. Operating at ultra-low temperature, density fluctuations of the dipolar BEC emulate a vacuum field with Lorentz-violating dispersion, while the two impurities function as Unruh-DeWitt detectors for the BEC quasiparticles. We study the harvesting of entanglement from the quantum vacuum of this analogue Lorentz-violating quantum field by spatially separated Unruh-DeWitt detectors. Our analysis reveals key parameter dependencies that optimize the harvesting of entanglement. In particular, unlike the Lorentz-invariant case, smoother detector switchings does not enhance the entanglement harvesting efficiency from the Lorentz-violating quantum field vacuum. Moreover, the strength of the Lorentz-invariant violation can shift the optimal energy structure of the detectors for harvesting entanglement from the Lorentz-violating quantum field vacuum-a clear deviation from the Lorentz-invariant scenario. As a fundamental quantum mechanical setup, our quantum fluid platform provides an experimentally realizable testbed for examining the entanglement harvesting protocol from an effective Lorentz-violating quantum field vacuum using a pair of impurity probers, which may also has potential implications for exploring the Lorentz-invariant violation in quantum field theory.

</details>


### [98] [Exact and Efficient Stabilizer Simulation of Thermal-Relaxation Noise for Quantum Error Correction](https://arxiv.org/abs/2512.09189)
*Sean R. Garner,Nathan M. Myers,Meng Wang,Samuel Stein,Chenxu Liu,Ang Li*

Main category: quant-ph

TL;DR: 开发了量子比特热弛豫噪声的精确稳定器兼容模型，解决了传统Pauli-twirling近似对物理相关通道（如热弛豫）的失真问题，为量子纠错码的准确模拟提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 传统的稳定器模拟依赖Pauli-twirling近似（PTA）来处理非Clifford噪声，但PTA会扭曲热弛豫等物理相关通道的行为。需要物理准确的噪声模拟来训练解码器并理解量子纠错码的噪声抑制能力。

Method: 开发了量子比特热弛豫噪声的精确稳定器兼容模型，展示了振幅阻尼和退相干组合通道在T2≤T1时可分解为Clifford操作和重置的正概率分解。对于T2>T1的情况，虽然分解为负概率但采样开销更小。还引入了带重置的近似误差通道以消除负概率，同时比PTA获得更高的通道保真度。

Result: 当T2≤T1时，组合通道允许完全正概率分解为Clifford操作和重置。对于T2>T1，虽然分解为负概率但采样开销更小。近似误差通道在消除负概率的同时，比PTA对真实热弛豫的通道保真度更高。将精确组合模型应用于超导平台上的大表面码和双变量自行车码，发现不同码态的逻辑性能差异表明噪声模型感知的解码器对准确捕捉热噪声结构至关重要。

Conclusion: 开发了热弛豫噪声的精确稳定器兼容模型，解决了PTA的失真问题。不同码态的逻辑性能差异表明，未来容错架构中需要噪声模型感知的解码器来准确捕捉热噪声结构。

Abstract: Stabilizer-based simulation of quantum error-correcting codes typically relies on the Pauli-twirling approximation (PTA) to render non-Clifford noise classically tractable, but PTA can distort the behavior of physically relevant channels such as thermal relaxation. Physically accurate noise simulation is needed to train decoders and understand the noise suppression capabilities of quantum error correction codes. In this work, we develop an exact and stabilizer-compatible model of qubit thermal relaxation noise and show that the combined amplitude damping and dephasing channel admits a fully positive probability decomposition into Clifford operations and reset whenever $T_2 \leqslant T_1$. For $T_2 > T_1$, the resulting decomposition is negative, but allows a smaller sampling overhead versus independent channels. We further introduce an approximated error channel with reset that removes the negativity of the decomposition while achieving higher channel fidelity to the true thermal relaxation than PTA, and extend our construction to finite temperature relaxation. We apply the exact combined model to investigate large surface codes and bivariate bicycle codes on superconducting platforms with realistic thermal relaxation error. The differing logical performances across code states further indicate that noise-model-informed decoders will be essential for accurately capturing thermal-noise structure in future fault-tolerant architectures.

</details>


### [99] [Parallel accelerated electron paramagnetic resonance spectroscopy using diamond sensors](https://arxiv.org/abs/2512.09230)
*Zhehua Huang,Zhengze Zhao,Fei Kong,Zhecheng Wang,Pengju Zhao,Xiangtian Gong,Xiangyu Ye,Ya Wang,Fazhan Shi,Jiangfeng Du*

Main category: quant-ph

TL;DR: 提出一种基于氮空位中心(NV center)的零场交叉弛豫电子顺磁共振(EPR)光谱方法，通过振幅调制控制场匹配目标，克服传感器和目标不均匀性问题，实现高效EPR测量。


<details>
  <summary>Details</summary>
Motivation: 虽然金刚石芯片可以集成大量NV中心以提高磁场灵敏度，但使用NV系综进行EPR光谱测量效率较低，主要原因是传感器和目标的不均匀性导致谱线展宽，这对光谱分析有害。

Method: 开发了一种零场交叉弛豫EPR光谱技术，通过振幅调制的控制场来调节传感器以匹配目标。调制使检测对传感器不均匀性具有鲁棒性，而零场EPR自然对目标不均匀性具有鲁棒性。

Result: 在约30000个NV中心的系综上实现了高效的EPR测量，不仅能够获取自由基的无歧义EPR光谱，还能实时监测其光谱动力学。

Conclusion: 该方法通过调制技术和零场测量策略，有效解决了NV系综EPR光谱中的不均匀性问题，为基于NV中心的磁传感应用提供了更高效可靠的光谱测量方案。

Abstract: The nitrogen-vacancy (NV) center can serve as a magnetic sensor for electron paramagnetic resonance (EPR) measurements. Benefiting from its atomic size, the diamond chip can integrate a tremendous amount of NV centers to improve the magnetic-field sensitivity. However, EPR spectroscopy using NV ensembles is less efficient due to inhomogeneities in both sensors and targets. Spectral line broadening induced by ensemble averaging is even detrimental to spectroscopy. Here we show a kind of cross-relaxation EPR spectroscopy at zero field, where the sensor is tuned by an amplitude-modulated control field to match the target. The modulation makes detection robust to the sensor's inhomogeneity, while zero-field EPR is naturally robust to the target's inhomogeneity. We demonstrate an efficient EPR measurement on an ensemble of roughly 30000 NV centers. Our method shows the ability to not only acquire unambiguous EPR spectra of free radicals, but also monitor their spectroscopic dynamics in real time.

</details>


### [100] [Mpemba as an Emergent Effect of System Relaxation](https://arxiv.org/abs/2512.09324)
*Gourab Das*

Main category: quant-ph

TL;DR: 该论文提出了一个解释量子系统中Mpemba效应的通用模型，表明该效应源于系统的集体行为，即使在没有共享环境的情况下，各向异性弛豫系统也能自然展现Mpemba效应。


<details>
  <summary>Details</summary>
Motivation: Mpemba效应（远离平衡态的系统比接近平衡态的系统弛豫更快）是一个反直觉现象。虽然已有多种系统特定理论解释驱动系统中的这种异常行为，但对于最初观察到该效应的非驱动系统，其基本机制仍未解决。需要建立一个通用模型来解释量子系统中的Mpemba效应。

Method: 提出了一个适用于遵循马尔可夫弛豫动力学的量子系统的通用Mpemba效应模型。关键在于初始态与快速弛豫模式的重叠：系统组分通过共享环境的相互作用创建快速衰减模式来展现Mpemba效应。同时表明，即使粒子间没有共享环境，具有各向异性弛豫的系统也能自然展现Mpemba效应。

Result: 建立了量子系统中Mpemba效应的通用解释框架，表明该效应源于系统的集体行为。初始态与快速弛豫模式的重叠是产生Mpemba效应的关键机制。各向异性弛豫系统即使在没有共享环境的情况下也能自然展现Mpemba效应。

Conclusion: Mpemba效应是量子系统集体行为的结果，可以通过初始态与快速弛豫模式的重叠来解释。该通用模型适用于任何遵循马尔可夫弛豫动力学的量子系统，为理解这一反直觉现象提供了统一的理论框架。

Abstract: The Mpemba effect (MpE), where a far-from-equilibrium state of a system relaxes faster compared to a state closer to it, is a well-known counterintuitive phenomenon in classical and quantum systems. Various system-specific theories have been proposed to explain this anomalous behavior in driven systems, though the fundamental mechanism of MpE in undriven systems, where MpE was first observed, remains unresolved. This paper provides a generic model of MpE for a quantum system following Markovian relaxation dynamics, regardless of system structure or environment. The key lies in the overlap of initial states with the fast relaxation mode; here, the constituents create a fast decay mode via interaction through the shared environment to show MpE, indicating MpE happens due to the collective behavior of the system. I also show that a system with anisotropic relaxation naturally exhibits MpE, even without a shared environment among the particles.

</details>


### [101] [Routes of Transport in the Path Integral Lindblad Dynamics through State-to-State Analysis](https://arxiv.org/abs/2512.09362)
*Devansh Sharma,Amartya Bose*

Main category: quant-ph

TL;DR: 该论文扩展了状态到状态分析方法，从非厄米系统扩展到包含Lindblad算符的开放量子系统，用于分析热浴和一般耗散、泵浦、退相干过程共同作用下的输运机制。


<details>
  <summary>Details</summary>
Motivation: 现有非厄米描述无法处理更一般的经验过程（包括各种泵浦过程），需要扩展状态到状态分析方法以包含Lindblad描述的一般耗散、泵浦和退相干过程。

Method: 将状态到状态分析扩展到Lindblad描述，考虑系统与热浴交换能量，同时受到Lindblad跳跃算符作用，建立Lindblad状态到状态方法。

Result: 该方法能够阐明系统在热浴耦合和Lindblad跳跃算符共同作用下的输运路径，通过激子聚集体的非相干泵浦和排空过程示例，展示了稳态激子电流的建立。

Conclusion: Lindblad状态到状态方法为量化开放量子系统中的输运过程提供了新的第一性原理方法，特别适用于分析热浴和一般耗散过程共同作用的复杂系统。

Abstract: Analyzing routes of transport for open quantum systems with non-equilibrium initial conditions is extremely challenging. The state-to-state approach [A. Bose, and P.L. Walters, J. Chem. Theory Comput. 2023, 19, 15, 4828-4836] has proven to be a useful method for understanding transport mechanisms in quantum systems interacting with dissipative thermal baths, and has been recently extended to non-Hermitian systems to account for empirical loss. These non-Hermitian descriptions are, however, not capable of describing empirical processes of more general nature, including but not limited to a variety of pumping processes. We extend the state-to-state analysis to account for Lindbladian descriptions of generic dissipative, pumping and decohering processes acting on a system which is exchanging energy with a thermal bath. This Lindblad state-to-state method can elucidate routes of transport in systems coupled to a bath and additionally acted upon by Lindblad jump operators. The method is demonstrated using examples of excitonic aggregates subject to incoherent pumping and draining processes. Using this new state-to-state formalism, we demonstrate the establishment of steady-state excitonic currents across molecular aggregates, yielding a different first-principles approach to quantifying the same.

</details>


### [102] [Compact and efficient quantum frequency conversion of a fiber-pigtailed single-photon source](https://arxiv.org/abs/2512.09390)
*Mathis Cohen,Anthony Martin,Romain Dalidet,Florian Pastier,Marie Billard,Aristide Lemaitre,Valérian Giesz,Niccolo Somaschi,Sarah Thomas,Pascale Senellart-Mardon,Sébastien Tanzilli,Laurent Labonté*

Main category: quant-ph

TL;DR: 量子频率转换器将量子点产生的单光子从925.7nm转换到电信C波段，实现48.4%端到端效率，保持光子纯度和不可区分性


<details>
  <summary>Details</summary>
Motivation: 量子频率转换是连接量子发射器和电信光子的关键技术，对于实现不同波长量子信息处理系统的实用化互联至关重要

Method: 采用光纤耦合的非线性光学铌酸锂波导与光纤尾纤量子点单光子源相结合的相干频率转换方案

Result: 实现48.4%的端到端转换效率，完全保持单光子纯度和不可区分性，将925.7nm光子成功转换到电信C波段

Conclusion: 两个光纤模块的集成实现了顶级性能，是迈向不同波长量子信息处理系统实用化互联的重要一步

Abstract: Quantum frequency converters are key enabling technologies in photonic quantum information science to bridge the gap between quantum emitters and telecom photons. Here, we report a co- herent frequency converter scheme combining a fiber-coupled nonlinear optical Lithium Niobate waveguide with a fiber-pigtailed single-photon source based on semiconductor quantum dots. Single and indistinguishable photons are converted from 925.7 nm to the telecommunication C-band, with a 48.4% end-to-end efficiency and full preservation of single-photon purity and indistinguishability. The integration of the two fiber-based modules achieving top-level performance represents an im- portant step toward the practical interconnection of future quantum information processing systems operating at different wavelengths.

</details>


### [103] [Two-Photon Bandwidth of Hyper-Entangled Photons in Complex Media](https://arxiv.org/abs/2512.09456)
*Ronen Shekel,Ohad Lib,Sébastien M. Popoff,Yaron Bromberg*

Main category: quant-ph

TL;DR: 利用超纠缠光子对的空间-光谱纠缠特性，在复杂介质中实现模态色散抵消，从而显著扩展量子光学的带宽能力


<details>
  <summary>Details</summary>
Motivation: 光在复杂介质中传播时，输出空间分布对波长高度敏感，这限制了从成像到通信等应用的带宽。需要解决量子光在复杂介质中的色散问题

Method: 使用空间和光谱同时纠缠的超纠缠光子对，通过一个光子的色散模态被其光谱反相关的孪生光子抵消，实现模态色散的一阶抵消

Result: 在多种介质（多模光纤、薄散射体、闪耀光栅）中实现了模态色散抵消，定义了一个远超经典对应物的"双光子带宽"，可用于宽带波前整形

Conclusion: 这些发现深化了对量子光在复杂介质中行为的理解，在量子成像、通信和传感等领域具有重要应用前景

Abstract: When light propagates through complex media, its output spatial distribution is highly sensitive to its wavelength. This fundamentally limits the bandwidth of applications ranging from imaging to communication. Here, we demonstrate analytically and numerically that the spatial correlations of hyper-entangled photon pairs, simultaneously entangled spatially and spectrally, remain stable across a broad bandwidth: The chromatic modal dispersion experienced by one photon is canceled to first order by its spectrally anti-correlated twin, defining a "two-photon bandwidth" that can far exceed its classical counterpart. We illustrate this modal dispersion cancellation in multimode fibers, thin diffusers and blazed gratings, and demonstrate its utility for broadband wavefront shaping of quantum states. These findings advance our fundamental understanding of quantum light in complex media with applications in quantum imaging, communication, and sensing.

</details>


### [104] [LiePrune: Lie Group and Quantum Geometric Dual Representation for One-Shot Structured Pruning of Quantum Neural Networks](https://arxiv.org/abs/2512.09469)
*Haijian Shao,Bowen Yang,Wei Liu,Xing Deng,Yingtao Jiang*

Main category: quant-ph

TL;DR: 提出LiePrune框架，首次基于数学原理对量子神经网络进行一次性结构化剪枝，利用李群结构和量子几何信息实现超过10倍的压缩，同时保持甚至提升任务性能。


<details>
  <summary>Details</summary>
Motivation: 量子神经网络和参数化量子电路在近期量子机器学习中至关重要，但其可扩展性受到过多参数、梯度消失（barren plateaus）和硬件限制的约束。

Method: 提出LiePrune框架，将每个量子门在李群-李代数对偶空间和量子几何特征空间中联合表示，实现基于数学原理的冗余检测和激进压缩。

Result: 在量子分类（MNIST、FashionMNIST）、量子生成建模（Bars-and-Stripes）和量子化学（LiH VQE）实验中，LiePrune实现了超过10倍的压缩，任务性能几乎没有损失甚至有所提升。

Conclusion: LiePrune是首个基于数学原理的量子神经网络一次性结构化剪枝框架，提供了冗余检测、函数逼近和计算复杂度的可证明保证，显著提升了量子神经网络的可扩展性。

Abstract: Quantum neural networks (QNNs) and parameterized quantum circuits (PQCs) are key building blocks for near-term quantum machine learning. However, their scalability is constrained by excessive parameters, barren plateaus, and hardware limitations. We propose LiePrune, the first mathematically grounded one-shot structured pruning framework for QNNs that leverages Lie group structure and quantum geometric information. Each gate is jointly represented in a Lie group--Lie algebra dual space and a quantum geometric feature space, enabling principled redundancy detection and aggressive compression. Experiments on quantum classification (MNIST, FashionMNIST), quantum generative modeling (Bars-and-Stripes), and quantum chemistry (LiH VQE) show that LiePrune achieves over $10\times$ compression with negligible or even improved task performance, while providing provable guarantees on redundancy detection, functional approximation, and computational complexity.

</details>


### [105] [Can Intense Quantum Light Beat Classical Uncertainty Relations?](https://arxiv.org/abs/2512.09558)
*Felipe Reibnitz Willemann,Mauro Antezza,Johannes Feist*

Main category: quant-ph

TL;DR: 该论文研究了光的多模量子态中时间延迟和频率带宽的不确定性关系，发现违反联合不确定性边界可以认证纠缠，且非经典修正与平均光子数成反比。


<details>
  <summary>Details</summary>
Motivation: 不确定性关系是量子力学的基础，编码了共轭可观测量同时测量的极限。违反联合不确定性边界可以认证纠缠——这是量子信息协议的关键资源，在强场物理中也越来越重要。

Method: 研究任意多模光量子态中成对的时间延迟和频率带宽不确定性，推导出它们联合乘积的一般下界。

Result: 发现非经典修正与平均光子数成反比，这种行为源于所谓的"纠缠单配性"。这些结果阐明了非经典光态中量子优势的强度标度。

Conclusion: 研究结果突出了纠缠和光子统计之间的相互作用，为理解量子优势在非经典光态中的强度依赖性提供了清晰的理论框架。

Abstract: Uncertainty relations are fundamental to quantum mechanics, encoding limits on the simultaneous measurement of conjugate observables. Violations of joint uncertainty bounds can certify entanglement -- a resource critical for quantum information protocols and increasingly relevant in strong-field physics. Here, we investigate the pairwise time-delay and frequency-bandwidth uncertainties for arbitrary multimode quantum states of light, deriving a general lower bound for their joint product. We find that the nonclassical correction scales inversely with the average photon number, a behavior rooted in the so-called ``monogamy of entanglement''. These results clarify the intensity scaling of quantum advantages in nonclassical light states and highlight the interplay between entanglement and photon statistics.

</details>


### [106] [Exceptional points of arbitrary high orders induced by non-Markovian dynamics](https://arxiv.org/abs/2512.09582)
*Timofey T. Sergeev,Evgeny S. Andrianov,Alexander A. Zyablovsky*

Main category: quant-ph

TL;DR: 非马尔可夫效应可使系统表现出高于其自由度数量的高阶异常点行为


<details>
  <summary>Details</summary>
Motivation: 传统观点认为异常点的阶数受限于非厄米系统的自由度数量，本文旨在挑战这一观点，探索非马尔可夫效应如何突破这一限制

Method: 通过分析非马尔可夫系统中能量从环境返回系统的过程，研究系统动力学被分为多个区间的情况，每个区间由指数函数与递增阶数多项式函数的乘积描述

Result: 通过选择观测时间，可以观察到任意高阶的异常点，突破了自由度数量对异常点阶数的限制

Conclusion: 非马尔可夫效应能够产生高于系统自由度数量的高阶异常点行为，这为理解和设计具有高阶奇异性的非厄米系统开辟了新途径

Abstract: Exceptional points are singularities in the spectrum of non-Hermitian systems in which several eigenvectors are linearly dependent and their eigenvalues are equal to each other. Usually it is assumed that the order of the exceptional point is limited by the number of degrees of freedom of a non-Hermitian system. In this letter, we refute this common opinion and show that non-Markovian effects can lead to dynamics characteristic of systems with exceptional points of higher orders than the number of degrees of freedom in the system. This takes place when the energy returns from reservoir to the system such that the dynamics of the system are divided into intervals in which it describes by the product of the exponential and a polynomial function of ever-increasing order. We demonstrate that by choosing the observation time, it is possible to observe exceptional points of arbitrary high orders.

</details>


### [107] [Graph-Based Bayesian Optimization for Quantum Circuit Architecture Search with Uncertainty Calibrated Surrogates](https://arxiv.org/abs/2512.09586)
*Prashant Kumar Choudhary,Nouhaila Innan,Muhammad Shafique,Rajeev Singh*

Main category: quant-ph

TL;DR: 提出基于图神经网络贝叶斯优化的自动化变分量子电路发现框架，在网络安全数据集上实现低复杂度高性能电路设计


<details>
  <summary>Details</summary>
Motivation: 量子电路设计是实际量子机器学习应用的关键瓶颈，需要自动化方法来发现和优化变分量子电路

Method: 使用图神经网络作为代理模型的图基贝叶斯优化框架，将电路表示为图结构，通过期望改进获取函数进行电路变异和选择，结合蒙特卡洛dropout处理不确定性

Result: GNN引导的优化器始终找到比基线方法（MLP代理、随机搜索、贪婪GNN选择）复杂度更低且分类精度相当或更优的电路，并通过多种量子噪声通道验证了鲁棒性

Conclusion: 该框架为自动化量子电路发现提供了可扩展且可解释的途径，实现了完全可复现的实现、时间基准测试和最佳电路导出

Abstract: Quantum circuit design is a key bottleneck for practical quantum machine learning on complex, real-world data. We present an automated framework that discovers and refines variational quantum circuits (VQCs) using graph-based Bayesian optimization with a graph neural network (GNN) surrogate. Circuits are represented as graphs and mutated and selected via an expected improvement acquisition function informed by surrogate uncertainty with Monte Carlo dropout. Candidate circuits are evaluated with a hybrid quantum-classical variational classifier on the next generation firewall telemetry and network internet of things (NF-ToN-IoT-V2) cybersecurity dataset, after feature selection and scaling for quantum embedding. We benchmark our pipeline against an MLP-based surrogate, random search, and greedy GNN selection. The GNN-guided optimizer consistently finds circuits with lower complexity and competitive or superior classification accuracy compared to all baselines. Robustness is assessed via a noise study across standard quantum noise channels, including amplitude damping, phase damping, thermal relaxation, depolarizing, and readout bit flip noise. The implementation is fully reproducible, with time benchmarking and export of best found circuits, providing a scalable and interpretable route to automated quantum circuit discovery.

</details>


### [108] [Quantum Gradient Flow Algorithm for Symmetric Positive Definite Systems via Quantum Eigenvalue Transformation: Towards Quantum CAE](https://arxiv.org/abs/2512.09623)
*Yuto Lewis Terashima,Tadashi Kadowaki,Yohichi Suzuki,Mayu Muramatsu,Katsuhiro Endo*

Main category: quant-ph

TL;DR: 提出量子梯度流算法（QGFA），基于变分原理和时间演化动力学解决对称正定线性系统，相比传统量子矩阵逆算法在条件数较大时表现更好，并应用于弹性力学有限元分析。


<details>
  <summary>Details</summary>
Motivation: 传统量子线性求解器（如QMIA）在条件数增大时计算效率下降，而经典SPD求解器（如最速下降法和共轭梯度法）基于变分优化原理收敛更快，因此需要开发结合量子计算优势且保持经典算法优点的量子线性求解器。

Method: 基于变分原理，通过对应二次能量泛函的梯度流过程获得解向量，结合量子信号处理（QSP）相位因子，应用于二维线性弹性问题的位移基有限元法（FEM）。

Result: 即使使用中等数量的QSP相位因子，QGFA也能准确收敛到经典FEM解；相比QMIA，在合适初始状态下获得更低的相对误差和更快的收敛速度。

Conclusion: QGFA为量子计算机辅助工程（Quantum CAE）提供了基础框架，建立了经典迭代求解器与量子计算范式之间的物理可解释连接，有望应用于非线性和多物理场模拟。

Abstract: In this study, we propose the Quantum Gradient Flow Algorithm (QGFA), a novel quantum algorithm for solving symmetric positive definite (SPD) linear systems based on the variational formulation and time-evolution dynamics. Conventional quantum linear solvers, such as the quantum matrix inverse algorithm (QMIA), focus on approximating the matrix inverse through quantum signal processing (QSP). However, QMIA suffers from a crucial drawback: its computational efficiency deteriorates as the condition number increases. In contrast, classical SPD linear solvers, such as the steepest descent and conjugate gradient methods, are known for their fast convergence, which stems from the variational optimization principle of SPD systems. Inspired by this, we develop QGFA, which obtains the solution vector through the gradient-flow process of the corresponding quadratic energy functional. To validate the proposed method, we apply QGFA to the displacement-based finite element method (FEM) for two-dimensional linear elastic problems under plane stress conditions. The algorithm demonstrates accurate convergence toward classical FEM solutions even with a moderate number of QSP phase factors. Compared with QMIA, QGFA achieves lower relative errors and faster convergence when initialized with suitable initial states, demonstrating its potential as an efficient preconditioned quantum linear solver. The proposed framework provides a physically interpretable connection between classical iterative solvers and quantum computational paradigms. These findings suggest that QGFA can serve as a foundation for future developments in Quantum Computer-Aided Engineering (Quantum CAE), including nonlinear and multiphysics simulations.

</details>


### [109] [Geometric Origin of Quantum Entanglement](https://arxiv.org/abs/2512.09640)
*Marco Zaopo*

Main category: quant-ph

TL;DR: 该论文研究了扩展庞加莱群的质量零表示，发现这些表示不同于标准庞加莱群的维格纳表示，具有额外的自由度，并证明这些表示与两量子比特的纠缠态是幺正等价的。


<details>
  <summary>Details</summary>
Motivation: 研究扩展庞加莱群的质量零表示，探索这些表示与标准维格纳表示的区别，并寻找量子纠缠在量子场论框架下的几何起源。

Method: 分析扩展庞加莱群的质量零表示，证明这些幺正不可约表示必须分解为质量零正向（正零分量动量）和质量零反向（负零分量动量）维格纳表示的直接和，并通过两值内部自由度连接。

Result: 证明了这些表示与两量子比特的纠缠态是幺正等价的，为光子的量子纠缠提供了几何起源：光子表现为依赖于两值参数的正向和反向传播电磁波的叠加，这种依赖性产生了与两量子比特纠缠态相同的局部可观测量相关性。

Conclusion: 扩展庞加莱群的质量零表示提供了量子纠缠的几何解释，并提出了能够区分连接正向和反向质量零表示的两值参数的实验，为该理论提供了实验验证的可能性。

Abstract: We investigate massless representations related to the extension of Poincarè group constructed in [1]. These representations differ from Wigner's ones of standard Poincarè group because the stabilizer of lightlike orbits has extra degrees of freedom. The unitary irreducible representations (UIRs) of massless particles in this extension must decompose as a direct sum of a massless forward (positive zeroth component momentum) and massless backward (negative zeroth component momentum) Wigner's representations linked by internal two valued degree of freedom. We prove that these representations are unitarily equivalent to entangled states of two qubits. This provides a geometric origin of quantum entanglement for photons in the framework of quantum field theory: photons appear as superpositions of backward and forward propagating electromagnetic waves depending on a two valued parameter and this dependency gives rise to correlations between the values of local observables identical to those experienced with an entangled state of two qubits. Finally we describe an experiment capable of distinguishing the two different values of the parameter that links backward and forward massless representations providing experimental falsification of the theory.

</details>


### [110] [Optyx: A ZX-based Python library for networked quantum architectures](https://arxiv.org/abs/2512.09648)
*Mateusz Kupper,Richie Yeung,Boldizsár Poór,Alexis Toumi,William Cashman,Giovanni de Felice*

Main category: quant-ph

TL;DR: Optyx是一个开源Python框架，用于统一编程、模拟和原型化混合量子网络系统，支持量子比特寄存器、光子模式、损耗通道等混合组件，通过ZX/ZW演算编译为优化的张量网络形式进行高效模拟。


<details>
  <summary>Details</summary>
Motivation: 大规模分布式量子计算需要将物质量子比特与光子链路结合的架构，但现有软件栈要么针对基于门的芯片，要么针对线性光学器件，缺乏统一的混合系统编程框架。

Method: 开发Optyx开源框架，提供统一语言编程混合系统，通过ZX/ZW演算将实验编译为优化的张量网络形式，利用Quimb和Cotengra的最先进张量网络收缩调度器执行。

Result: 基准测试显示，相比基于永久数的方法，张量网络收缩在低深度电路和纠缠光子源模拟中可带来数量级的速度提升，并原生支持损耗和可区分性。

Conclusion: Optyx既是一个高性能的模拟器，也是下一代光子网络实验的快速原型环境，为混合量子网络系统提供了统一的编程和仿真平台。

Abstract: Distributed, large-scale quantum computing will need architectures that combine matter-based qubits with photonic links, but today's software stacks target either gate-based chips or linear-optical devices in isolation. We introduce Optyx, an open-source Python framework offering a unified language to program, simulate, and prototype hybrid, networked systems: users create experiments that mix qubit registers, discrete-variable photonic modes, lossy channels, heralded measurements, and real-time feedback; Optyx compiles them via ZX/ZW calculus into optimised tensor-network forms, and executes with state-of-the-art contraction schedulers based on Quimb and Cotengra. Benchmarking on exact multi-photon circuit simulations shows that, versus permanent-based methods, tensor network contraction can deliver speedups of orders of magnitude for low-depth circuits and entangled photon sources, and natively supports loss and distinguishability -- establishing it as both a high-performance simulator and a rapid-prototyping environment for next-generation photonic-network experiments.

</details>


### [111] [Entanglement with a mode observable via a tunable interaction with a qubit](https://arxiv.org/abs/2512.09658)
*Małgorzata Strzałka,Radim Filip,Katarzyna Roszak*

Main category: quant-ph

TL;DR: 研究通过仅测量量子比特来检测"自旋-玻色子"纠缠的可能性，利用可调耦合克服对称性限制，以超导transmon量子比特与微波腔系统为例


<details>
  <summary>Details</summary>
Motivation: 先前提出的固定系统-环境相互作用方案由于耦合和初始态的固有对称性，无法检测自旋-玻色子纠缠。需要开发新方法利用可调耦合特性来突破这一限制。

Method: 利用量子比特-环境耦合可调的特性（如超导transmon量子比特与微波腔系统），提出适合的哈密顿量参数用于纠缠制备和测量阶段，即使在有限温度下也能获得可检测信号。

Result: 提出的检测方案能够克服固有对称性限制，在有限温度下仍能产生非可忽略的检测信号，为实验验证自旋-玻色子纠缠提供了可行方案。

Conclusion: 通过利用量子比特-环境耦合的可调性，可以实现仅通过量子比特测量来检测自旋-玻色子纠缠，这在量子信息处理中具有重要意义，特别是在超导量子比特系统中。

Abstract: We study the possibility of detection of ``spin-boson'' entanglement by qubit only measurements. Such entanglement is impossible to detect by previously proposed schemes that involve a fixed system-environment interaction, because of inherent symmetries within the coupling and the initial state of the environment. We take advantage of the possibility of tuning of qubit-environment coupling, that is available in some qubit realizations. As an example we study a superconducting transmon qubit interacting with a microwave cavity, which is one of such systems and is, furthermore, essential in the context of quantum information processing. We propose suitable Hamiltonian parameters for the preparation and measurement phases of the detection scheme that allow for an experimental test, and verify that the reported signal is nonnegligibly large still at finite temperatures.

</details>


### [112] [Pattern Based Quantum Key Distribution using the five qubit perfect code for eavesdropper detection](https://arxiv.org/abs/2512.09672)
*Mehedi Hasan Rumi*

Main category: quant-ph

TL;DR: 提出一种基于五量子比特纠错码的量子密钥分发协议，能可靠检测窃听者存在


<details>
  <summary>Details</summary>
Motivation: 传统量子密钥分发协议在检测窃听方面存在局限性，需要更可靠的窃听检测机制来增强安全性

Method: 使用五量子比特纠错码将逻辑量子比特编码到五个物理量子比特块中，通过特定模式选择实现安全，错误模式选择会增加多量子比特错误率

Result: 协议能将任何信息理论攻击转化为经典模式猜测问题，五量子比特码能将窃听者的逻辑扰动转化为可检测的签名，并能与自然信道噪声区分

Conclusion: 该协议提供了一种可靠的窃听检测方法，通过模式选择机制增强量子密钥分发的安全性，在一定距离内能有效区分窃听和自然噪声

Abstract: I propose a new quantum key distribution protocol that uses the five qubit error correction code to detect the presence of eavesdropper reliably. The protocol turns any information theoretical attacks into a classical guess about the pattern. The logical qubit is encoded with a specific pattern into a block of five physical qubits. The security of the protocol relies on the correct pattern choice of Alice and Bob. Decoding with any wrong pattern choice increases multi qubit error rate and the 5 qubit code transforms an eavesdropper's logical disturbance into a signature that is detectable and distinguishable from natural channel noise up to a certain distance.

</details>


### [113] [Three-body interaction in a magnon-Andreev-superconducting qubit system: collapse-revival phenomena and entanglement redistribution](https://arxiv.org/abs/2512.09697)
*Sheng Zhao,Peng-Bo Li*

Main category: quant-ph

TL;DR: 该论文提出了一种混合量子架构，利用磁振子模式、安德烈夫自旋量子比特和超导量子比特实现单量子水平上的强三体相互作用，展示了三体相互作用带来的独特量子现象。


<details>
  <summary>Details</summary>
Motivation: 三体相互作用对于实现超越两体物理的新奇量子现象至关重要，但特别是在不同量子系统之间实现三体相互作用仍然具有挑战性。现有系统难以在不同类型的量子系统之间实现强三体耦合。

Method: 提出混合量子架构：包含磁振子模式（YIG球体）、安德烈夫自旋量子比特（ASQ）和超导量子比特（SCQ）。利用ASQ的自旋依赖超电流和电路集成灵活性，设计强三方耦合，使得磁振子湮灭时同时激发两个量子比特（或ASQ退激发时激发磁振子和SCQ）。通过分析和数值研究验证该相互作用。

Result: 当磁振子初始处于相干态时，该三体相互作用诱导量子比特布居数的同步坍缩和复苏。在坍缩区域（布居数保持静态），纠缠结构经历剧烈且连续的重组。真正的三方纠缠被重新分配到两个量子比特之间的两体纠缠中，反之亦然，总纠缠守恒。这些现象无法通过两体耦合实现。

Conclusion: 三体相互作用具有探索内在新量子效应和推进混合量子信息平台的潜力。该工作展示了三体相互作用带来的独特量子现象，为超越传统两体物理的量子研究开辟了新途径。

Abstract: Three-body interactions are fundamental for realizing novel quantum phenomena beyond pairwise physics, yet their implementation -- particularly among distinct quantum systems -- remains challenging. Here, we propose a hybrid quantum architecture comprising a magnonic mode (in a YIG sphere), an Andreev spin qubit (ASQ), and a superconducting qubit (SCQ), to realize a strong three-body interaction at the single-quantum level. Leveraging the spin-dependent supercurrent and circuit-integration flexibility of the ASQ, it is possible to engineer a strong tripartite coupling that jointly excites both qubits upon magnon annihilation (or excites magnons and SCQs upon ASQ deexcitation). Through analytical and numerical studies, we demonstrate that this interaction induces synchronized collapse and revival in qubit populations when the magnon is initially prepared in a coherent state. Notably, during the collapse region -- where populations remain static -- the entanglement structure undergoes a dramatic and continuous reorganization. We show that the genuine tripartite entanglement is redistributed into bipartite entanglement between the two qubits, and vice versa, with the total entanglement conserved. These phenomena, unattainable via two-body couplings, underscore the potential of three-body interactions for exploring intrinsically new quantum effects and advancing hybrid quantum information platforms.

</details>


### [114] [Device Independent Quantum Secret Sharing Using Multiparty Pseudo-telepathy Game](https://arxiv.org/abs/2512.09699)
*Santanu Majhi,Goutam Paul*

Main category: quant-ph

TL;DR: 基于多体伪心灵感应奇偶校验游戏的设备无关量子秘密共享协议，无需专用测试轮次，同时实现设备无关验证和密钥生成


<details>
  <summary>Details</summary>
Motivation: 克服不可信量子设备带来的安全限制，解决传统CHSH方案需要专用测试轮次的问题，实现更高效的设备无关量子秘密共享

Method: 利用多体伪心灵感应奇偶校验游戏构建DI-QSS协议，基于七量子比特GHZ态配置，无需专用测试轮次即可同时进行设备无关验证和密钥生成

Result: 协议在七量子比特GHZ态配置下达到最优性能，相比先前协议减少了相同原始密钥长度所需的资源，且在噪声环境中保持鲁棒性

Conclusion: 提出的基于多体伪心灵感应奇偶校验游戏的DI-QSS协议实现了高效的同时设备无关验证和密钥生成，具有资源效率高和噪声鲁棒性强的优势

Abstract: Device-independent quantum secret sharing (DI-QSS) is a cryptographic protocol that overcomes the security limitations posed by untrusted quantum devices. We propose a DI-QSS protocol based on the multipartite pseudo-telepathy parity game, which achieves device-independence with simultaneous key generation without requiring dedicated test rounds, unlike CHSH-based schemes [Zhang et al., Phys. Rev. A, 2024]. Notably, the proposed scheme allows simultaneous device-independence verification and key-generation phases, achieving optimal performance for a seven-qubit GHZ state configuration. Further, we analyse the security of our protocol against collective attack and establish reduced resource requirement for the same length of the raw key compared to the previous protocol. Finally, we show that our protocol remains robust even in a noisy environment.

</details>


### [115] [Dynamic stimulated emission for deterministic addition and subtraction of propagating photons](https://arxiv.org/abs/2512.09711)
*Haoyuan Luo,Parth S. Shah,Frank Yang,Mohammad Mirhosseini,Sahand Mahmoodian*

Main category: quant-ph

TL;DR: 提出动态受激发射概念，利用量子发射体实现确定性单光子加减法，无需传统线性光学和光子数分辨探测的低成功率方法


<details>
  <summary>Details</summary>
Motivation: 传统光子加减法使用线性光学和光子数分辨探测，成功率低。需要更高效的方法来生成非高斯量子态

Method: 引入动态受激发射概念，利用时间依赖耦合的量子发射体（两能级和三能级系统），提供半解析解实现确定性光子加减法

Result: 实现保真度>0.996的确定性单光子加减法；能从压缩真空态制备薛定谔猫态；能以高保真度>0.99向压缩位移态添加光子

Conclusion: 该方法为构建高效单模非高斯光源提供了新途径，可将量子发射体从单光子源扩展为单光子添加高斯态源

Abstract: Photon subtraction and addition are essential non-Gaussian processes in quantum optics, where conventional methods using linear optics and number-resolving detection often suffer from low success probability. Here, we introduce the concept of \textit{dynamic stimulated emission}, whereby a quantum emitter undergoes stimulated emission with a time-dependent coupling. We show that, for both two- and three-level emitters, this process can be used to deterministically add or subtract a photon to a single propagating optical mode. We provide semi-analytic solutions to this problem for Fock states, enabling deterministic and unconditional single-photon subtraction and addition with fidelity ${\cal F}>0.996$. Our semi-analytic solutions are provided for both dynamically coupled two-level systems and for three-level systems whose dynamical coupling is controlled by a coherent laser drive. Moving beyond individual Fock states, we further showcase the ability to subtract and add single photons to photon-number superposition states. We show that Schrödinger cat states can be prepared from squeezed vacuum input via cascaded subtraction or cascaded addition. Finally, we show that our photon-addition process can be used to add a photon to any squeezed and displaced state with high success probability and fidelity ${\cal F}>0.99$, thereby potentially converting quantum emitters from single-photon sources to sources of single-photon-added Gaussian states without the need for inline squeezing. Our protocols provide a path towards integrating quantum emitters to construct efficient sources of single-mode non-Gaussian light beyond single photons.

</details>


### [116] [Quantum random number generation from the continuous variable payload for the SPOQC mission](https://arxiv.org/abs/2512.09716)
*Vinod N. Rao,Killian Murphy,Fadi Ahwal,Emma Tien Hwai Medlock,Timothy P. Spiller,Rupesh Kumar*

Main category: quant-ph

TL;DR: 利用SPOQC任务的连续变量有效载荷实现CV-QRNG，通过零差测量真空态产生随机数，从约1Mb原始数据中提取约19.5Kb认证随机数


<details>
  <summary>Details</summary>
Motivation: 随机数在模拟、密码学等任务中至关重要，需要高质量随机数源。利用卫星任务中的连续变量有效载荷实现量子随机数生成，可提供安全的随机数来源

Method: 使用SPOQC任务的CV有效载荷，通过零差测量真空态实现QRNG。使用12位ADC采集数据，通过零差测量设置，利用有效载荷中的激光源，在卫星过境期间采集约1Mb原始数据

Result: 从约1Mb原始数据中提取约19.5Kb认证随机数。通过NIST测试套件验证随机性，并正式上界最小熵，确保随机数的安全性

Conclusion: 成功演示了基于卫星任务的CV-QRNG，能够从真空态测量中提取认证的随机数，为空间量子随机数生成提供了可行方案

Abstract: The necessity of random numbers for various tasks, from simulation to cryptography, is crucial and immense. Here we demonstrate CV-QRNG using the CV payload of the SPOQC mission. The homodyne setup for QRNG uses the laser from the payload, in addition to potentially being used as detector in the case of an uplink scenario. Here we quantify the extractable secure randomness from the QRNG setup, that involves homodyne measurement of the vacuum states. The extracted randomness is tested against NIST test suite in addition to formally upper bounding the min-entropy. With the raw key length being $\approx1$ Mb in a given satellite pass, we get a total length of $\approx19.5$ Kb of certified random numbers from the 12-bit ADC.

</details>


### [117] [Quantumness certification via non-demolition measurements](https://arxiv.org/abs/2512.09734)
*Paolo Solinas,Stefano Gherardini*

Main category: quant-ph

TL;DR: QNDM作为认证量子特征的工具，通过检测准概率密度函数的负项来违反宏观实在性，为量子资源认证提供了直接方法。


<details>
  <summary>Details</summary>
Motivation: 需要建立严格标准来判断系统何时具有内在量子性，这超越了经典可模拟性或计算复杂性问题，关键在于实时认证量子纠缠和叠加等真正量子特征的出现和持续。

Method: 使用量子非破坏测量（QNDM）作为理论实验工具，将其实现与违反宏观实在性的充要条件直接关联，建立与Leggett-Garg不等式的概念平行，通过检测QNDM产生的准概率密度函数中的负项来认证量子特征。

Result: QNDM方法能够追踪环境相互作用导致的量子-经典转变，在噪声存在下具有鲁棒性，相比Leggett-Garg不等式具有优势，为量子资源认证提供了直接相关的工具。

Conclusion: QNDM方法因其直接实现性，对量子力学基础和量子信息理论都具有直接相关性，其中受控生成和认证真正量子资源是核心关注点。

Abstract: The fundamental question of when a static or dynamic system should be deemed intrinsically quantum remains a challenge to address in absolute terms. A rigorous criterion, however, can be established by focusing on the measurable or reconstructible features of the system. This determination transcends mere issues of a system's classical simulability or computational complexity. Instead, the critical requirement lies in the certification (ideally, in real-time) of the emergence and persistence of genuine quantum features, principally entanglement and quantum superposition. Quantum Non-Demolition Measurements (QNDM) serve as the appropriate instrument for this certification, both from a theoretical and experimental standpoint. In this review paper, we demonstrate, with accessible clarity, how the implementation of QNDM can be directly linked to a necessary and sufficient condition for the violation of macrorealism in finite-dimensional systems, establishing a conceptual parallel with Leggett-Garg inequalities. Using concrete examples that detail the detection of negative terms in the quasi-probability density function resulting from QNDM, we introduce the core concepts for certifying genuinely quantum features. As specific examples, we discuss an application where the quantum-to-classical transition due to the interaction with an environment can be tracked by QNDM. Moreover, we argue about the robustness of QNDM protocols in the presence of noise sources and their advantages with respect to the Leggett-Garg inequalities. Because of its straightforward implementation, the QNDM approach can be of direct relevance to both the foundations of quantum mechanics and quantum information theory, where a controlled generation and certification of genuinely quantum resources is a central concern.

</details>


### [118] [Quantum error correction via purification using a single auxiliary](https://arxiv.org/abs/2512.09745)
*Chandrima B. Pushpan,Tanoy Kanti Konar,Aditi Sen De,Amit Kumar Pal*

Main category: quant-ph

TL;DR: 提出一种基于纯化的单辅助量子纠错框架，通过特殊设计的哈密顿量进行系统-辅助联合演化，然后测量辅助并后选择，能纠正将系统从基态子空间激发到激发态的错误。


<details>
  <summary>Details</summary>
Motivation: 现有量子纠错方法难以处理将系统从基态激发到激发态的错误，特别是面对振幅阻尼噪声时。需要扩展可纠正错误的类别，提高纠错成功率。

Method: 设计系统-辅助联合演化哈密顿量，进行时间演化后测量辅助的能量本征态，通过后选择特定测量结果实现纯化。该方法能处理比特翻转、相位翻转和振幅阻尼噪声。

Result: 纯化后的态总能达到单位保真度，成功率为辅助测量到非基态能量的概率。该方法扩展了给定编码的可纠正错误类别，特别是在振幅阻尼噪声下表现优异。

Conclusion: 该单辅助纯化框架为量子纠错提供了新方法，能有效处理激发态错误，扩展了纠错能力，对实际量子计算应用有重要意义。

Abstract: We propose a single auxiliary-assisted purification-based framework for quantum error correction, capable of correcting errors that drive a system from its ground-state subspace into excited-state sectors. The protocol consists of a joint time evolution of the system-auxiliary duo under a specially engineered interaction Hamiltonian, followed by a single measurement of the auxiliary in its energy eigenbasis and a subsequent post-selection of one of the measurement outcomes. We show that the resulting purified state always achieves unit fidelity, while the probability of obtaining any energy of the auxiliary other than its ground state energy yields the success rate of the protocol. We demonstrate the power of this proposed method for several low-distance quantum codes, including the three-, four-, and five-qubit codes, and for the one-dimensional isotropic Heisenberg model, subjected to bit-flip, phase-flip, and amplitude-damping noises acting on all qubits. Notably, the protocol expands the class of correctable errors for a given code, particularly in the presence of amplitude-damping noise. We further analyze the impact of replacing the auxiliary qudit with a single auxiliary qubit, and the changes in the performance of the protocol under the realistic scenario where noise remains active during the correction cycle.

</details>


### [119] [Optimal certification of constant-local Hamiltonians](https://arxiv.org/abs/2512.09778)
*Junseo Lee,Myeongjin Shin*

Main category: quant-ph

TL;DR: 提出首个对任意常数局域性哈密顿量实现最优容错认证的协议，仅需正向实时演化，无需逆演化或受控操作，达到海森堡极限标度。


<details>
  <summary>Details</summary>
Motivation: 现有哈密顿量认证方法存在局限：要么需要实现逆演化，要么需要受控访问演化算子，要么只能在受限设置（如Ising模型）中达到近最优保证。需要开发一种仅使用正向实时动力学就能对所有常数局域性哈密顿量实现最优容错认证的通用方法。

Method: 通过oracle访问未知k-局域哈密顿量H的演化算子e^{-itH}，与完全指定的目标哈密顿量H_0进行比较。算法仅使用正向实时动力学，无需逆演化或受控操作，通过优化总演化时间实现认证。

Result: 对于一般的n-量子比特、k-局域、无迹哈密顿量，协议使用O(c^k/ε)总演化时间（c为通用常数），以高概率成功。特别地，对于O(1)-局域哈密顿量，总演化时间为Θ(1/ε)，匹配已知的Ω(1/ε)下界，达到海森堡极限标度。

Conclusion: 该工作首次实现了对所有常数局域性哈密顿量的最优容错认证，仅需正向实时演化，无需逆演化或受控操作，在哈密顿量认证领域取得了重要进展。

Abstract: We study the problem of certifying local Hamiltonians from real-time access to their dynamics. Given oracle access to $e^{-itH}$ for an unknown $k$-local Hamiltonian $H$ and a fully specified target Hamiltonian $H_0$, the goal is to decide whether $H$ is exactly equal to $H_0$ or differs from $H_0$ by at least $\varepsilon$ in normalized Frobenius norm, while minimizing the total evolution time. We introduce the first intolerant Hamiltonian certification protocol that achieves optimal performance for all constant-locality Hamiltonians. For general $n$-qubit, $k$-local, traceless Hamiltonians, our procedure uses $O(c^k/\varepsilon)$ total evolution time for a universal constant $c$, and succeeds with high probability. In particular, for $O(1)$-local Hamiltonians, the total evolution time becomes $Θ(1/\varepsilon)$, matching the known $Ω(1/\varepsilon)$ lower bounds and achieving the gold-standard Heisenberg-limit scaling. Prior certification methods either relied on implementing inverse evolution of $H$, required controlled access to $e^{-itH}$, or achieved near-optimal guarantees only in restricted settings such as the Ising case ($k=2$). In contrast, our algorithm requires neither inverse evolution nor controlled operations: it uses only forward real-time dynamics and achieves optimal intolerant certification for all constant-locality Hamiltonians.

</details>


### [120] [Pinball: A Cryogenic Predecoder for Quantum Error Correction Decoding Under Circuit-Level Noise](https://arxiv.org/abs/2512.09807)
*Alexander Knapen,Guanchen Tao,Jacob Mack,Tomas Bruno,Mehdi Saligane,Dennis Sylvester,Qirui Zhang,Gokul Subramanian Ravi*

Main category: quant-ph

TL;DR: Pinball：一种针对实际电路级噪声优化的低温CMOS QEC预解码器，相比现有方案在逻辑错误率、功耗和带宽方面均有显著提升


<details>
  <summary>Details</summary>
Motivation: 扩展容错量子计算机面临数据处理和功耗挑战，特别是实时量子纠错解码器的高数据率需求。现有低温预解码方案仅考虑部分误差源且精度有限，依赖SFQ逻辑限制了架构技术协同优化。

Method: 采用低温CMOS技术设计QEC预解码器Pinball，考虑电路级噪声中的误差生成和传播，与22nm FDSOI技术协同设计，利用电压/频率缩放和体偏置技术优化功耗。

Result: 相比现有最佳低温预解码器，逻辑错误率降低近6个数量级；相比室温解码器，逻辑错误率分别降低32.58倍和5倍；带宽减少最高3780.72倍；峰值功耗低于0.56mW，典型功耗降低22.2倍，总能耗节省67.4倍。

Conclusion: Pinball通过高精度低温预解码设计，显著提升量子纠错性能，降低功耗和带宽需求，支持在4K功率预算下实现多达2,668个逻辑量子比特，为大规模量子计算系统提供可行解决方案。

Abstract: Scaling fault tolerant quantum computers, especially cryogenic systems, to millions of qubits is challenging due to poorly-scaling data processing and power consumption overheads. One key challenge is the design of decoders for real-time quantum error correction (QEC), which demands high data rates for error processing; this is particularly apparent in systems with cryogenic qubits and room temperature (RT) decoders. In response, cryogenic predecoding using lightweight logic has been proposed to handle common, sparse errors in the cryogenic domain. However, prior work only accounts for a subset of error sources present in real-world quantum systems with limited accuracy, often degrading performance below a useful level in practical scenarios. Furthermore, prior reliance on SFQ logic precludes detailed architecture-technology co-optimization.
  To address these shortcomings, this paper introduces Pinball, a comprehensive design in cryogenic CMOS of a QEC predecoder tailored to realistic, circuit-level noise. By accounting for error generation and propagation through QEC circuits, our design achieves higher predecoding accuracy, outperforming logical error rates (LER) of the current state-of-the-art cryogenic predecoder by nearly six orders of magnitude. Remarkably, despite operating under much stricter power and area constraints, Pinball also reduces LER by 32.58x and 5x, respectively, compared to the state-of-the-art RT predecoder and RT ensemble configurations. By increasing cryogenic coverage, we also reduce syndrome bandwidth up to 3780.72x. Through co-design with 4 K-characterized 22 nm FDSOI technology, we achieve a peak power consumption under 0.56 mW. Voltage/frequency scaling and body biasing enable 22.2x lower typical power consumption, yielding up to 67.4x total energy savings. Assuming a 4 K power budget of 1.5 W, our predecoder supports up to 2,668 logical qubits at d=21.

</details>


### [121] [Quantum Algorithm for Estimating Ollivier-Ricci Curvature](https://arxiv.org/abs/2512.09822)
*Nhat A. Nghiem,Linh Nguyen,Tuan K. Do,Tzu-Chieh Wei,Trung V. Phan*

Main category: quant-ph

TL;DR: 提出了一种计算Ollivier Ricci曲率的量子算法，该算法在特定问题类别上相比经典方法可实现指数级加速


<details>
  <summary>Details</summary>
Motivation: Ollivier Ricci曲率作为离散Ricci曲率的模拟，在金融网络脆弱性分析和组合量子引力等领域有重要应用。现有经典计算方法效率有限，需要更高效的算法

Method: 开发了基于最优传输理论的量子算法，用于在图和一般度量空间上计算Ollivier Ricci曲率。算法针对点云数据和成对距离作为输入进行优化

Result: 对于特定问题类别，该量子算法相比已知最佳经典方法可实现指数级加速。这是几何问题量子算法领域的重要进展

Conclusion: 该工作推动了几何问题量子算法的发展，既能提供实用价值，又能为基本理论提供信息，是量子计算在几何问题应用中的重要一步

Abstract: We introduce a quantum algorithm for computing the Ollivier Ricci curvature, a discrete analogue of the Ricci curvature defined via optimal transport on graphs and general metric spaces. This curvature has seen applications ranging from signaling fragility in financial networks to serving as basic quantities in combinatorial quantum gravity. For inputs given as a point cloud with pairwise distances, we show that our algorithm can achieve an exponential speedup over the best-known classical methods for two particular classes of problem. Our work is another step toward quantum algorithms for geometrical problems that are capable of delivering practical value while also informing fundamental theory.

</details>


### [122] [Transpiling quantum circuits by a transformers-based algorithm](https://arxiv.org/abs/2512.09834)
*Michele Banfi,Paolo Zentilini,Sebastiano Corli,Enrico Prati*

Main category: quant-ph

TL;DR: 开发了一个基于Transformer的量子电路转译模型，能够将QASM标准量子电路转换为IonQ离子阱量子计算机的原生门集，在5量子比特范围内实现了99.98%以上的正确转译率。


<details>
  <summary>Details</summary>
Motivation: Transformer在自然语言处理中表现出色，而门级量子计算可以看作低级文本编程语言。利用Transformer处理量子电路转译问题，将标准QASM电路转换为特定量子硬件（如IonQ离子阱计算机）的原生门集。

Method: 开发基于Transformer的模型，将量子电路从QASM标准转译到目标量子硬件的原生门集。模型复杂度在最坏情况下随寄存器深度和电路长度呈多项式增长趋势。

Result: 在5量子比特范围内，正确转译目标电路的比例达到99.98%以上。证明了模型复杂度随寄存器深度和电路长度呈多项式增长，允许在高性能计算基础设施上高效训练更多参数的模型。

Conclusion: Transformer模型能够有效处理量子电路转译任务，在保持高准确率的同时，模型复杂度可控，为在HPC基础设施上训练更大规模模型提供了可行性。

Abstract: Transformers have gained popularity in machine learning due to their application in the field of natural language processing. They manipulate and process text efficiently, capturing long-range dependencies among data and performing the next word prediction. On the other hand, gate-based quantum computing is based on controlling the register of qubits in the quantum hardware by applying a sequence of gates, a process which can be interpreted as a low level text programming language. We develop a transformer model capable of transpiling quantum circuits from the qasm standard to other sets of gates native suited for a specific target quantum hardware, in our case the set for the trapped-ion quantum computers of IonQ. The feasibility of a translation up to five qubits is demonstrated with a percentage of correctly transpiled target circuits equal or superior to 99.98%. Regardless the depth of the register and the number of gates applied, we prove that the complexity of the transformer model scales, in the worst case scenario, with a polynomial trend by increasing the depth of the register and the length of the circuit, allowing models with a higher number of parameters to be efficiently trained on HPC infrastructures.

</details>


### [123] [Practical and Efficient Verification of Entanglement with Incomplete Measurement Settings](https://arxiv.org/abs/2512.09856)
*Jiheon Seong,Jin-Woo Kim,Seungchan Seo,Seung-Hyun Nam,Anindita Bera,Dariusz Chruściński,June-Koo Kevin Rhee,Heonoh Kim,Joonwoo Bae*

Main category: quant-ph

TL;DR: 提出一个实用框架，在测量设置不完备（仅能访问有限可观测量）的情况下验证纠缠态，通过少量可观测量构造大量纠缠见证，并优化选择最有效的见证。


<details>
  <summary>Details</summary>
Motivation: 在实际实验中，通常只能进行不完备的测量（即只能访问有限的可观测量），这使得纠缠验证变得困难。需要开发在测量资源受限情况下仍能有效验证纠缠的方法。

Method: 1) 利用少量实验可观测量直接构造大量纠缠见证；2) 提出基于半正定规划的优化方法，系统搜索在给定测量约束下最能揭示纠缠的见证；3) 在光子偏振量子比特实验中验证方法的实用性。

Result: 在原理验证实验中，仅使用部分完整测量数据即可成功验证纠缠，证明了不完备测量设置在现实场景中用于纠缠验证的最大效用。

Conclusion: 该框架为测量资源受限情况下的纠缠验证提供了实用高效的解决方案，展示了不完备测量设置在纠缠检测中的最大潜力，具有重要的实际应用价值。

Abstract: In this work, we present a practical and efficient framework for verifying entangled states when only a tomographically incomplete measurement setting is available-specifically, when access to observables is severely limited. We show how the experimental estimation of a small number of observables can be directly exploited to construct a large family of entanglement witnesses, enabling the efficient identification of entangled states. Moreover, we introduce an optimization approach, formulated as a semidefinite program, that systematically searches for those witnesses best suited to reveal entanglement under the given measurement constraints. We demonstrate the practicality of the approach in a proof-of-principle experiment with photon-polarization qubits, where entanglement is certified using only a fraction of the full measurement data. These results reveal the maximal usefulness of incomplete measurement settings for entanglement verification in realistic scenarios.

</details>


### [124] [True Random Number Generators on IQM Spark](https://arxiv.org/abs/2512.09862)
*Andrzej Gnatowski,Jarosław Rudy,Teodor Niżyński,Krzysztof Święcicki*

Main category: quant-ph

TL;DR: 该研究在Odra 5量子计算机上评估了5种TRNG电路（共105个子变体）的随机数生成质量，使用NIST测试套件进行分析，填补了现有研究主要依赖IBM量子计算机和模拟的空白。


<details>
  <summary>Details</summary>
Motivation: 传统伪随机数生成器是确定性的，而量子计算机能提供真正的随机性。现有研究大多局限于IBM量子计算机、模拟环境，且只测试少量TRNG电路。本研究旨在填补这些空白，在真实量子硬件上全面评估多种TRNG电路。

Method: 在Wrocław科技大学的Odra 5量子计算机（采用IQM超导架构）上测试5种TRNG电路类型，共105个电路子变体。每个电路生成100万比特，然后使用NIST SP 800-22和NIST SP 800-90B测试套件分析随机序列质量。

Result: 在真实量子硬件上进行了全面的TRNG电路评估，提供了105个不同电路变体的性能数据。这是首次在IQM超导架构上进行的TRNG研究，也是首次在本地部署的量子计算机上进行如此大规模测试。

Conclusion: 本研究填补了量子计算机TRNG研究的空白，提供了在真实量子硬件上的全面评估。结果表明在非IBM量子架构上也能实现高质量的随机数生成，为量子随机数生成的实用化提供了重要参考。

Abstract: Random number generation is fundamental for many modern applications including cryptography, simulations and machine learning. Traditional pseudo-random numbers may offer statistical unpredictability, but are ultimately deterministic. On the other hand, True Random Number Generation (TRNG) offers true randomness. One way of obtaining such randomness are quantum systems, including quantum computers. As such the use of quantum computers for TRNG has received considerable attention in recent years. However, existing studies almost exclusively consider IBM quantum computers, often stop at using simulations and usually test only a handful of different TRNG quantum circuits. In this paper, we address those issues by presenting a study of TRNG circuits on Odra 5 a real-life quantum computer installed at Wrocław University of Science and Technology. It is also the first study to utilize the IQM superconducting architecture. Since Odra 5 is available on-premises it allows for much more comprehensive study of various TRNG circuits. In particular, we consider 5 types of TRNG circuits with 105 circuit subvariants in total. Each circuit is used to generate 1 million bits. We then perform an analysis of the quality of the obtained random sequences using the NIST SP 800-22 and NIST SP 800-90B test suites. We also provide a comprehensive review of existing literature on quantum computer-based TRNGs.

</details>


### [125] [Error Mitigation of Fault-Tolerant Quantum Circuits with Soft Information](https://arxiv.org/abs/2512.09863)
*Zeyuan Zhou,Shaun Pexton,Aleksander Kubica,Yongshan Ding*

Main category: quant-ph

TL;DR: 量子错误缓解(QEM)在量子纠错(QEC)时代仍能提供显著效益，通过利用QEC解码器产生的软信息实现逻辑级QEM，无需额外数据或硬件修改，可减少100倍以上逻辑错误率。


<details>
  <summary>Details</summary>
Motivation: 挑战传统观点：量子错误缓解通常被视为当前嘈杂中等规模量子设备的实用技术，被认为在容错量子计算机可用后相关性有限。本文证明QEM在量子纠错时代仍能提供实质性效益。

Method: 提出逻辑级QEM框架，利用QEC解码器自然产生的软信息，无需额外数据、硬件修改或运行时开销。开发三种逻辑级QEM技术：后选择与运行时中止策略、概率错误消除和零噪声外推。

Result: 逻辑错误率减少超过100倍，同时丢弃少于0.1%的测量次数；相比仅依赖QEC或QEC结合QEM的先前方法，可节省高达87.4%的时空开销。在表面码架构和两种先进解码器上验证了有效性。

Conclusion: 逻辑级QEM结合QEC解码器软信息能够可靠提升逻辑性能，证明QEM技术在容错量子计算机时代仍然高效有用，挑战了QEM仅适用于当前嘈杂设备的传统观点。

Abstract: Quantum error mitigation (QEM) is typically viewed as a suite of practical techniques for today's noisy intermediate-scale quantum devices, with limited relevance once fault-tolerant quantum computers become available. In this work, we challenge this conventional wisdom by showing that QEM can continue to provide substantial benefits in the era of quantum error correction (QEC), and in an even more efficient manner than it does on current devices. We introduce a framework for logical-level QEM that leverages soft information naturally produced by QEC decoders, requiring no additional data, hardware modifications, or runtime overhead beyond what QEC protocols already provide. Within this framework, we develop and analyze three logical-level QEM techniques: post-selection and runtime abort policies, probabilistic error cancellation, and zero-noise extrapolation. Our techniques reduce logical error rates by more than 100x while discarding fewer than 0.1% of shots; they also provide in situ characterization of logical channels for QEM protocols. As a proof of principle, we benchmark our approach using a surface-code architecture and two state-of-the-art decoders based on tensor-network contraction and minimum-weight perfect matching. We evaluate logical-level QEM on random Clifford circuits and molecular simulation algorithms and find that, compared to previous approaches relying on QEC only or QEC combined with QEM, we can achieve up to 87.4% spacetime overhead savings. Our results demonstrate that logical-level QEM with QEC decoder soft information can reliably improve logical performance, underscoring the efficiency and usefulness of QEM techniques for fault-tolerant quantum computers.

</details>


### [126] [Tomographic characterization of non-Hermitian Hamiltonians in reciprocal space](https://arxiv.org/abs/2512.09870)
*Francesco Di Colandrea,Fabrizio Pavan,Sarvesh Bansal,Paola Savarese,Grazia Di Bello,Giulio De Filippis,Carmine Antonio Perroni,Donato Farina,Filippo Cardano*

Main category: quant-ph

TL;DR: 实验光子平台实现非厄米量子行走，通过倒空间直接扫描重构哈密顿量，揭示动量空间中的奇异点和宇称-时间对称破缺。


<details>
  <summary>Details</summary>
Motivation: 非厄米哈密顿量扩展了传统相图，实现了新的拓扑现象和奇异点，在量子传感中有潜在应用。但目前对特定类型非厄米哈密顿量的实验研究还很有限。

Method: 开发实验光子平台模拟非厄米量子行走，通过直接访问倒空间扫描整个布里渊区的准动量，实现哈密顿量的精确层析重建。

Result: 成功重构非厄米哈密顿量，提取复数值能带结构，解析动量空间中的奇异点，通过本征矢合并检测宇称-时间对称破缺。

Conclusion: 该工作在准动量空间呈现结果，代表了研究非厄米现象视角的重大转变，为探索非厄米量子物理提供了新平台。

Abstract: Non-Hermitian Hamiltonians enrich quantum physics by extending conventional phase diagrams, enabling novel topological phenomena, and realizing exceptional points with potential applications in quantum sensing. Here, we present an experimental photonic platform capable of simulating a non-unitary quantum walk generated by a peculiar type of non-Hermitian Hamiltonian, largely unexplored in the literature. The novelty of this platform lies in its direct access to the reciprocal space, which enables us to scan the quasi-momentum across the entire Brillouin zone and thus achieve a precise tomographic reconstruction of the underlying non-Hermitian Hamiltonian, indicated by the comparison between theoretical predictions and experimental measurements. From the inferred Hamiltonian, it is possible to retrieve complex-valued band structures, resolve exceptional points in momentum space, and detect the associated parity-time symmetry breaking through eigenvector coalescence. Our results, presented entirely in quasi-momentum space, represent a substantial shift in perspective in the study of non-Hermitian phenomena.

</details>


### [127] [A 0.8395-approximation algorithm for the EPR problem](https://arxiv.org/abs/2512.09896)
*Anuj Apte,Eunou Lee,Kunal Marwaha,Ojas Parekh,Lennart Sinjorgo,James Sud*

Main category: quant-ph

TL;DR: 提出了一种高效的0.8395近似算法用于EPR哈密顿量问题，改进了现有方法，并证明了当前技术难以获得更大提升


<details>
  <summary>Details</summary>
Motivation: 改进EPR哈密顿量问题的近似算法，探索量子计算中纠缠约束的边界，为量子优化问题提供更好的解决方案

Method: 基于星图上的新型非线性纠缠单配性边界，以及对先前工作中浅层量子电路的精细化参数化

Result: 实现了0.8395的近似比，显著优于先前结果，并证明了当前方法难以获得实质性更好的近似比

Conclusion: 该工作显著推进了EPR哈密顿量问题的近似算法，但进一步改进需要全新的技术方法

Abstract: We give an efficient 0.8395-approximation algorithm for the EPR Hamiltonian. Our improvement comes from a new nonlinear monogamy-of-entanglement bound on star graphs and a refined parameterization of a shallow quantum circuit from previous works. We also prove limitations showing that current methods cannot achieve substantially better approximation ratios, indicating that further progress will require fundamentally new techniques.

</details>


### [128] [Two simple models derived from a quantum-mechanical particle on an elliptical path](https://arxiv.org/abs/2512.09905)
*Francisco M. Fernández*

Main category: quant-ph

TL;DR: 分析椭圆路径上量子粒子的两个简单模型：第一个非厄米哈密顿算符与厄米算符同构，展现与圆路径相同的二重简并；第二个厄米哈密顿算符无此简并，激发能级在微扰论n阶分裂。


<details>
  <summary>Details</summary>
Motivation: 研究椭圆路径上量子粒子的对称性特性，比较非厄米与厄米哈密顿算符在相同点群对称性下的不同能级结构，探索几何形状对量子系统简并性的影响。

Method: 从椭圆路径上的量子力学粒子推导出两个简单模型：第一个是非厄米但同构于厄米算符的哈密顿量；第二个是厄米哈密顿量。使用点群对称性分析两个模型，对第二个模型采用微扰理论分析能级分裂。

Result: 第一个模型展现与圆路径相同的二重简并：$E_n=n^2E_1$（n=1,2,...），外加精确本征值$E_0=0$。第二个模型无此简并，第n个激发能级在第n阶微扰理论中分裂。两个模型可用相同点群对称性描述。

Conclusion: 椭圆路径上量子粒子的对称性分析表明，非厄米但同构于厄米的哈密顿量保持圆路径的简并特性，而纯厄米哈密顿量则破坏这种简并，激发能级在微扰论高阶分裂，两者共享相同的点群对称性描述。

Abstract: We analyze two simple models derived from a quantum-mechanical particle on an elliptical path. The first Hamiltonian operator is non-Hermitian but isomorphic to an Hermitian operator. It appears to exhibit the same two-fold degeneracy as the particle on a circular path. More precisely, $E_n=n^2E_1,\ n=1,2,\ldots$ (in addition to an exact eigenvalue $E_0=0$). The second Hamiltonian operator is Hermitian and does not exhibit such degeneracy. In this case the nth excited energy level splits at the nth order of perturbation theory. Both models can be described in terms of the same point-group symmetry.

</details>
