<div id=toc></div>

# Table of Contents

- [physics.comp-ph](#physics.comp-ph) [Total: 2]
- [quant-ph](#quant-ph) [Total: 52]
- [gr-qc](#gr-qc) [Total: 20]
- [cs.LG](#cs.LG) [Total: 82]


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [1] [Generative Monte Carlo Sampling for Constant-Cost Particle Transport](https://arxiv.org/abs/2512.13965)
*Joseph A. Farmer,Aidan Murray,Johannes Krotz,Ryan G. McClarren*

Main category: physics.comp-ph

TL;DR: 提出Generative Monte Carlo (GMC)新范式，将生成式AI直接集成到线性玻尔兹曼方程的随机求解中，通过条件流匹配训练神经网络采样粒子出口状态，在光学厚区域实现数量级加速。


<details>
  <summary>Details</summary>
Motivation: 传统蒙特卡洛方法在光学厚区域计算成本随光学厚度线性增长，而现代计算架构更优化神经网络推理。需要将粒子输运与AI硬件进展对齐，提高计算效率。

Method: 将单元传输问题重新表述为条件生成任务，使用条件流匹配训练神经网络直接采样粒子出口状态（位置、方向、路径长度），无需模拟散射历史。采用光学坐标缩放技术，使单个训练模型能泛化到任何材料。

Result: GMC在核反应堆堆芯特征的异质晶格问题和高温高密度辐射传输的线性化空腔几何两个基准测试中验证。保持标准蒙特卡洛的统计保真度，显示预期的1/√N收敛率，同时保持准确的标量通量分布。在光学厚区域实现数量级加速。

Conclusion: GMC框架将粒子输运与优化神经网络推理的现代计算架构战略对齐，使输运代码能够利用AI硬件和算法的持续进展，在光学厚区域实现恒定O(1)成本，显著提升计算效率。

Abstract: We present Generative Monte Carlo (GMC), a novel paradigm for particle transport simulation that integrates generative artificial intelligence directly into the stochastic solution of the linear Boltzmann equation. By reformulating the cell-transmission problem as a conditional generation task, we train neural networks using conditional flow matching to sample particle exit states, including position, direction, and path length, without simulating scattering histories. The method employs optical coordinate scaling, enabling a single trained model to generalize across any material. We validate GMC on two canonical benchmarks, namely a heterogeneous lattice problem characteristic of nuclear reactor cores and a linearized hohlraum geometry representative of high-energy density radiative transfer. Results demonstrate that GMC preserves the statistical fidelity of standard Monte Carlo, exhibiting the expected $1/\sqrt{N}$ convergence rate while maintaining accurate scalar flux profiles. While standard Monte Carlo computational cost scales linearly with optical thickness in the diffusive limit, GMC achieves constant $O(1)$ cost per cell transmission, yielding order-of-magnitude speedups in optically thick regimes. This framework strategically aligns particle transport with modern computing architectures optimized for neural network inference, positioning transport codes to leverage ongoing advances in AI hardware and algorithms.

</details>


### [2] [Physics-Informed Machine Learning for Two-Phase Moving-Interface and Stefan Problems](https://arxiv.org/abs/2512.14010)
*Che-Chia Chang,Te-Sheng Lin,Ming-Chih Lai*

Main category: physics.comp-ph

TL;DR: 提出基于物理信息神经网络的两相Stefan问题求解框架，通过两个神经网络分别追踪界面运动和温度场，能准确捕捉界面处温度梯度不连续性


<details>
  <summary>Details</summary>
Motivation: Stefan问题是经典的相变自由边界问题，传统数值方法面临移动界面和非线性温度-相耦合的计算挑战，需要更灵活鲁棒的求解方法

Method: 使用两个神经网络：一个表示移动界面，另一个表示温度场。界面网络快速分类空间域热扩散率，温度网络输入通过修改的零水平集函数增强以准确捕捉界面处法向导数跳跃

Result: 数值实验表明该方法相比其他神经网络方法具有更高的精度和有效性，能捕捉与Mullins-Sekerka不稳定性相关的不稳定界面演化

Conclusion: 该框架为相变移动边界问题提供了传统数值方法的鲁棒灵活替代方案，能有效处理界面不连续性

Abstract: The Stefan problem is a classical free-boundary problem that models phase-change processes and poses computational challenges due to its moving interface and nonlinear temperature-phase coupling. In this work, we develop a physics-informed neural network framework for solving two-phase Stefan problems. The proposed method explicitly tracks the interface motion and enforces the discontinuity in the temperature gradient across the interface while maintaining global consistency of the temperature field. Our approach employs two neural networks: one representing the moving interface and the other for the temperature field. The interface network allows rapid categorization of thermal diffusivity in the spatial domain, which is a crucial step for selecting training points for the temperature network. The temperature network's input is augmented with a modified zero-level set function to accurately capture the jump in its normal derivative across the interface. Numerical experiments on two-phase dynamical Stefan problems demonstrate the superior accuracy and effectiveness of our proposed method compared with the ones obtained by other neural network methodology in literature. The results indicate that the proposed framework offers a robust and flexible alternative to traditional numerical methods for solving phase-change problems governed by moving boundaries. In addition, the proposed method can capture an unstable interface evolution associated with the Mullins-Sekerka instability.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [3] [Electron-positron pair creation induced by multi-pulse train of electric fields: effect of randomness in time-delay](https://arxiv.org/abs/2512.13722)
*Deepak Sah,Manoranjan P. Singh*

Main category: quant-ph

TL;DR: 研究随机时间延迟对Sauter型脉冲序列中电子-正电子对产生的影响，发现特定随机延迟能显著增强中心动量峰值


<details>
  <summary>Details</summary>
Motivation: 探索多脉冲电场配置中随机时间延迟对电子-正电子对产生的影响，寻找优化粒子对产生的新方法

Method: 通过求解量子Vlasov方程，研究具有随机时间延迟的Sauter型脉冲序列，时间延迟服从高斯分布，标准差σ_T控制波动程度

Result: 增加σ_T显著改变纵向动量谱，多缝干涉条纹模式被修改；特定随机延迟能极大增强中心峰值（如N=20脉冲时，σ_T≈31 m⁻¹使中心峰值增加近10倍，σ_T≈50 m⁻¹时增加10³倍）

Conclusion: 随机时间延迟能显著优化多脉冲场配置，为最大化电子-正电子对产生提供新的实验设计指导

Abstract: We investigate the creation of electron-positron pairs (EPPs) in a sequence of alternating-sign, time-dependent electric field pulse trains by solving the quantum Vlasov equations. Specifically, we focus on Sauter-like pulse trains with random time delays between successive pulses, drawn from a Gaussian distribution wherein the extent of fluctuations is controlled by the standard deviation $σ_T$ of the distribution. We find that increasing $σ_T$ leads to a dramatic transformation in the longitudinal momentum spectrum. The well-known fringe pattern, akin to that in the multi-slit interference, gets significantly modified. The averaged spectra exhibit a robust Gaussian-like envelope with residual oscillations, which are much more prominent in the central momentum region. Notably, we find that in certain cases, stochastic time delays lead to a pronounced enhancement in the central peak of the distribution function for pulse train containing $N$ pulses. For example, for $N=20$ pulses, $σ_T \approx 31$ $[m^{-1}]$(about $17\%$ of the mean time delay) yields nearly a tenfold increase in the central peak, which for $σ_T \approx 50$ $[m^{-1}]$ (about $27\%$ of the mean time delay), scales up to $10^3.$ This may open up new possibilities for optimizing multi-pulse field configurations and guide future experimental designs aimed at maximizing EPPs creation.

</details>


### [4] [A Spatio-Temporal Hybrid Quantum-Classical Graph Convolutional Neural Network Approach for Urban Taxi Destination Prediction](https://arxiv.org/abs/2512.13745)
*Xiuying Zhang,Qinsheng Zhu,Xiaodong Xing*

Main category: quant-ph

TL;DR: 提出混合时空量子图卷积网络(H-STQGCN)，结合量子计算与经典深度学习预测出租车目的地，在准确率和稳定性上优于现有方法


<details>
  <summary>Details</summary>
Motivation: 利用量子计算的优势来增强对城市道路网络中高维空间依赖关系的捕捉能力，提高出租车目的地预测的准确性和稳定性

Method: 采用双分支结构：空间处理分支（经典GCN编码道路网络拓扑特征 + 量子模块通过可微分池化层将图特征映射到参数化量子电路）和时间演化分支（基于经典TCN理论整合多源上下文信息并捕捉动态行程依赖）

Result: 实验结果表明，所提算法在预测准确率和稳定性方面优于现有方法，验证了量子增强机制在捕捉高维空间依赖关系方面的独特优势

Conclusion: 成功开发了结合量子计算与经典深度学习的混合时空量子图卷积网络，为城市道路网络中的出租车目的地预测提供了更有效的解决方案，展示了量子增强机制在空间依赖建模中的潜力

Abstract: We propose a Hybrid Spatio-Temporal Quantum Graph Convolutional Network (H-STQGCN) algorithm by combining the strengths of quantum computing and classical deep learning to predict the taxi destination within urban road networks. Our algorithm consists of two branches: spatial processing and time evolution. Regarding the spatial processing, the classical module encodes the local topological features of the road network based on the GCN method, and the quantum module is designed to map graph features onto parameterized quantum circuits through a differentiable pooling layer. The time evolution is solved by integrating multi-source contextual information and capturing dynamic trip dependencies on the classical TCN theory. Finally, our experimental results demonstrate that the proposed algorithm outperforms the current methods in terms of prediction accuracy and stability, validating the unique advantages of the quantum-enhanced mechanism in capturing high-dimensional spatial dependencies.

</details>


### [5] [Optical Downlink Modeling for LEO and MEO Satellites under Atmospheric Turbulence with a Quantum State Tomography Use Case](https://arxiv.org/abs/2512.13828)
*Artur Czerwinski,Jakub J. Borkowski,Saeed Haddadi*

Main category: quant-ph

TL;DR: 该论文对LEO和MEO卫星的自由空间光通信链路预算进行了全面分析，建立了包含大气吸收/散射、自由空间衍射和湍流效应的卫星-地面信道模型，并提出了量子态层析的卫星应用方案。


<details>
  <summary>Details</summary>
Motivation: 为支持空间光通信系统的设计和评估，需要建立准确的卫星-地面信道模型，特别是针对LEO和MEO卫星的链路预算分析，这对量子信息网络等应用至关重要。

Method: 开发了包含大气吸收/散射、自由空间衍射和湍流效应的详细信道模型，提出了计算卫星与地面站之间斜路径透射率的通用方法，考虑了天顶角、斜距和高度相关衰减。

Result: 提供了典型操作条件下的数值损失估计，包括孔径平均效应的影响，展示了链路预算分析的实际应用价值。

Conclusion: 该框架为空间光通信链路设计和评估提供了关键工具，同时提出的卫星量子态层析方案能够持续验证量子资源质量，支持量子信息网络的发展。

Abstract: This paper presents a comprehensive analysis of the link budget for free-space optical systems involving Low Earth Orbit (LEO) and Medium Earth Orbit (MEO) satellites. We develop a detailed model of the satellite-to-ground channel that accounts for the primary physical processes affecting transmittance: atmospheric absorption and scattering, free-space diffraction, and turbulence-induced fluctuations. The study introduces a general method for computing transmittance along a slant path between a satellite and an optical ground station, incorporating zenith angle, slant range, and altitude-dependent attenuation. The proposed framework is intended to support the design and evaluation of space-based optical links and serves as a critical tool for defining technical specifications in satellite communication demonstrators and simulations. Numerical estimates are provided to illustrate the magnitude of losses under typical operational conditions, including the role of aperture averaging. In addition to the link budget analysis, we introduce a satellite-based quantum use case. We propose a scheme for quantum state tomography performed on states generated by an onboard photon source on an LEO or MEO satellite and transmitted to the optical ground station. This approach enables continuous verification of the quality of quantum resources that can be used to perform quantum protocols within quantum information networks.

</details>


### [6] [Quantum simulation using Trotterized disorder Hamiltonians in a single-mode optical cavity](https://arxiv.org/abs/2512.13774)
*Rahel Lea Baumgartner,Pietro Pelliconi,Soumik Bandyopadhyay,Francesca Orsi,Philipp Hauke,Jean-Philippe Brantut,Julian Sonner*

Main category: quant-ph

TL;DR: 提出利用Trotter化方案来增加全对全相互作用无序多体系统的无序密度，并在腔QED平台上实现复杂Sachdev-Ye-Kitaev模型


<details>
  <summary>Details</summary>
Motivation: 全对全相互作用和无序多体系统在量子平台上难以模拟，因为相互作用通常通过辅助自由度介导，这会降低无序度并引入不希望的关联

Method: 使用Trotter化方案来增加模型的无序密度，研究所得模型的统计特性以及影响时间演化和动力学可观测量模拟的Trotter化误差，通过单模腔QED平台实现复杂Sachdev-Ye-Kitaev模型

Result: 分析了有效模型的特征，包括有效耦合的分布、相互作用位点数量、状态准备以及量子混沌探针的行为，并通过解析和数值方法详细研究了结果对耗散的鲁棒性

Conclusion: Trotter化方案可以有效增加无序多体系统的无序密度，为在腔QED平台上模拟复杂Sachdev-Ye-Kitaev模型提供了可行方案，且结果对耗散具有鲁棒性

Abstract: All-to-all interacting and disordered many-body systems are notoriously hard to simulate on quantum platforms, as interactions are commonly mediated by auxiliary degrees of freedom that lower the amount of disorder, introducing undesired correlations. In this work, we show how a Trotterization scheme can be effectively utilized to densify the disorder of the model. In particular, we study the statistical properties of the resulting model, as well as Trotterization errors in the simulation that affect the time evolution and dynamical observables. As a concrete example, we propose an implementation via a single-mode cavity QED platform of the complex Sachdev-Ye-Kitaev model. We analyze several features of the effective model, such as the distribution of the effective couplings, the number of interacting sites, state preparation, and the behavior of quantum chaos probes. We conclude this work with a detailed investigation of the robustness of our findings against dissipation, both analytically and numerically.

</details>


### [7] [Transversal Clifford-Hierarchy Gates via Non-Abelian Surface Codes](https://arxiv.org/abs/2512.13777)
*Alison Warman,Sakura Schafer-Nameki*

Main category: quant-ph

TL;DR: 本文提出了一种在二维非阿贝尔表面码中实现任意级别Clifford层级相位门的纯横向构造方法，突破了Bravyi-König定理的限制。


<details>
  <summary>Details</summary>
Motivation: Bravyi-König定理限制了在D维Pauli稳定子码中通过恒定深度量子电路可实现的幺正门只能达到第D级Clifford层级。本文旨在突破这一限制，在保持局域性和容错性的前提下，在纯二维系统中实现任意级别的Clifford层级门。

Method: 使用非阿贝尔群G的量子双D(G)在三角形空间区域编码逻辑量子比特。通过在空间区域上堆叠由群2-上循环指定的对称保护拓扑(SPT)相来实现横向逻辑门。特别地，对于G = D_{4N}(8N阶二面体群)，在逻辑Z基中实现了相位门T^{1/N} = diag(1, e^{iπ/(4N)})。

Result: 成功在纯二维系统中实现了任意级别的Clifford层级相位门，突破了Bravyi-König定理的限制。对于8N = 2^n的情况，该门位于第n级Clifford层级，并且具有纯量子比特实现：可以在晶格每条边上使用n个物理量子比特的代码中通过Clifford层级稳定子构造。

Conclusion: 通过使用非阿贝尔表面码，可以在纯二维系统中实现任意级别的Clifford层级门，同时保持局域性和容错性。该方法还讨论了到Z_2 × Z_2和Z_2环面码的代码切换，可用于量子纠错设置。

Abstract: We present a purely 2D transversal realization of phase gates at any level of the Clifford hierarchy, and beyond, using non-Abelian surface codes. Our construction encodes a logical qubit in the quantum double $D(G)$ of a non-Abelian group $G$ on a triangular spatial patch. The logical gate is implemented transversally by stacking on the spatial region a symmetry-protected topological (SPT) phase specified by a group 2-cocycle. The Bravyi--König theorem limits the unitary gates implementable by constant-depth quantum circuits on Pauli stabilizer codes in $D$ dimensions to the $D$-th level of the Clifford hierarchy. We bypass this, by constructing transversal unitary gates at arbitrary levels of the Clifford hierarchy purely in 2D, without sacrificing locality or fault tolerance, however at the cost of using the quantum double of a non-Abelian group $G$. Specifically, for $G = D_{4N}$, the dihedral group of order $8N$, we realize the phase gate $T^{1/N} = \mathrm{diag}(1, e^{iπ/(4N)})$ in the logical $\overline{Z}$ basis. For $8N = 2^n$, this gate lies at the $n$-th level of the Clifford hierarchy and, importantly, has a qubit-only realization: we show that it can be constructed in terms of Clifford-hierarchy stabilizers for a code with $n$ physical qubits on each edge of the lattice. We also discuss code-switching to the $\mathbb{Z}_2 \times \mathbb{Z}_2$ and $\mathbb{Z}_2$ toric codes, which can be utilized for the quantum error correction in this setup.

</details>


### [8] [Search Smarter, Not Harder: A Scalable, High-Quality Zoned Neutral Atom Compiler](https://arxiv.org/abs/2512.13790)
*Yannick Stade,Lukas Burgholzer,Robert Wille*

Main category: quant-ph

TL;DR: 提出了一种用于中性原子量子计算架构的可扩展编译策略，通过迭代潜水搜索和松弛路由优化，能够处理数千量子比特的电路编译问题。


<details>
  <summary>Details</summary>
Motivation: 分区中性原子架构作为大规模量子计算平台正在兴起，但现有编译方法无法扩展到这些设备承诺的数千量子比特规模，特别是最先进的编译器存在巨大的内存需求限制。

Method: 提出了"搜索更智能，而非更困难"的可扩展编译策略，包括迭代潜水搜索（IDS）算法避免先前方法的内存问题，以及松弛路由优化来减少原子重排开销。

Result: 该方法能够编译数千量子比特的电路，并且平均减少28.1%的重排开销，完整代码已在MQT开源工具包中公开。

Conclusion: 该工作为中性原子量子计算架构提供了一种可扩展的编译解决方案，解决了大规模量子电路编译的内存和效率问题。

Abstract: Zoned neutral atom architectures are emerging as a promising platform for large-scale quantum computing. Their growing scale, however, creates a critical need for efficient and automated compilation solutions. Yet, existing methods fail to scale to the thousands of qubits these devices promise. State-of-the-art compilers, in particular, suffer from immense memory requirements that limit them to small-scale problems. This work proposes a scalable compilation strategy that "searches smarter, not harder". We introduce Iterative Diving Search (IDS), a goal-directed search algorithm that avoids the memory issues of previous methods, and relaxed routing, an optimization to mitigate atom rearrangement overhead. Our evaluation confirms that this approach compiles circuits with thousands of qubits and, in addition, even reduces rearrangement overhead by 28.1% on average. The complete code is publicly available in open-source as part of the Munich Quantum Toolkit (MQT) at https://github.com/munich-quantum-toolkit/qmap.

</details>


### [9] [Freeness Reined in by a Single Qubit](https://arxiv.org/abs/2512.13803)
*Alexander Altland,Francisco Divi,Tobias Micklitz,Maedeh Rezaei*

Main category: quant-ph

TL;DR: 研究探讨了自由概率理论在量子系统中的鲁棒性，发现即使系统与单个辅助量子比特耦合，自由概率预测的相关函数也会出现O(1)量级的修正，这些修正源于非均匀分布的稳态量子态。


<details>
  <summary>Details</summary>
Motivation: 自由概率理论为描述复杂量子系统中非对易可观测量之间的相关性提供了框架，但需要检验该框架在偏离自由条件时的鲁棒性。研究关注系统与单个辅助量子比特耦合这一最小偏离情况。

Method: 通过分析高维(D0 ≫ 1)Haar分布量子电路与单个辅助量子比特耦合的系统，研究自由概率预测的相关函数修正。采用解析分析和数值模拟相结合的方法，特别关注非均匀分布的稳态量子态。

Result: 发现即使在这种最小偏离自由条件的情况下，自由概率理论预测的相关函数也会出现O(1)量级的修正。这些修正在系统动力学已经达到遍历状态的长时极限下仍然存在。

Conclusion: 自由概率框架在量子系统中对偏离自由条件的扰动相当敏感，即使是最小的扰动也会导致显著修正。这些修正源于非均匀分布的稳态量子态，对理解复杂量子系统的相关性有重要意义。

Abstract: Free probability provides a framework for describing correlations between non-commuting observables in complex quantum systems whose Hilbert-space states follow maximum-entropy distributions. We examine the robustness of this framework under a minimal deviation from freeness: the coupling of a single ancilla qubit to a Haar-distributed quantum circuit of dimension $D0 \gg 1$. We find that, even in this setting, the correlation functions predicted by free probability theory receive corrections of order $O(1)$. These modifications persist at long times, when the dynamics of the coupled system is already ergodic. We trace their origin to non-uniformly distributed stationary quantum states, which we characterize analytically and confirm numerically.

</details>


### [10] [Universal Statistics of Measurement-Induced Entanglement in Tomonaga-Luttinger liquids](https://arxiv.org/abs/2512.13809)
*Kabir Khanna,Romain Vasseur*

Main category: quant-ph

TL;DR: 研究一维量子临界态（Tomonaga-Luttinger液体）在部分测量后测量诱导纠缠的统计特性，利用CFT工具推导MIE累积量的闭式表达式，发现Born平均等价于对共形边界条件的平均，揭示所有累积量的临界行为及双峰分布特征。


<details>
  <summary>Details</summary>
Motivation: 研究量子临界态在部分测量后的纠缠统计特性，理解测量如何影响量子多体系统的纠缠结构，特别是测量诱导纠缠的统计分布和临界行为。

Method: 使用副本技巧对电荷基测量结果进行平均，结合共形场论工具，推导测量诱导纠缠累积量的解析表达式。通过数值计算验证理论预测。

Result: 得到测量诱导纠缠累积量的闭式表达式，发现Born平均在低能下等价于对共形边界条件的加权平均。所有累积量在未测量部分最大分离时表现出独特的临界行为，后测量纠缠熵分布呈双峰且具有厚尾特征。

Conclusion: 测量诱导纠缠在一维量子临界态中展现出丰富的统计特性，包括所有累积量的临界标度行为和双峰分布，为理解测量对量子多体系统的影响提供了新视角。

Abstract: We study the statistics of measurement-induced entanglement (MIE) after partial measurement on a class of one-dimensional quantum critical states described by Tomonaga-Luttinger liquids at low energies. Using a replica trick to average over measurement outcomes in the charge basis and tools from conformal field theory (CFT), we derive closed-form expressions for the cumulants of MIE. We show that exact Born-averaging over microscopic measurement outcomes becomes equivalent at low energy to averaging over conformal boundary conditions weighted by their corresponding partition functions. Our results yield distinctive critical behavior across all cumulants in the regime where the unmeasured parts of the system are maximally separated. We also obtain the full distribution of the post-measurement entanglement entropy, finding that it is generically bimodal and exhibits fat-tails. We corroborate our analytical predictions by numerical calculations and find good agreement between them.

</details>


### [11] [Fractional decay in the spontaneous emission of a two-level system](https://arxiv.org/abs/2512.13817)
*Hiroki Nakabayashi,Hayato Kinkawa,Takano Taira,Naomichi Hatano*

Main category: quant-ph

TL;DR: 研究具有下界无上界能谱环境中的两能级系统自发辐射，发现存活概率在短时和长时分别呈现不同的分数幂律标度行为，导致量子芝诺效应具有不同的芝诺时间标度。


<details>
  <summary>Details</summary>
Motivation: 探索环境能谱特性（有下界无上界）对两能级系统自发辐射动力学的影响，特别是对存活概率时间演化和量子芝诺效应标度行为的影响。

Method: 分析具有特定能谱结构（能量色散关系为|k|^n）的环境与两能级系统的相互作用，推导存活概率的时间演化公式，研究短时和长时极限下的渐近行为。

Result: 发现存活概率在短时标度为1-αt^{2-D/n}，在长时标度为αt^{D/n-2}，其中D为空间维度，n为能量色散指数。这种分数幂律标度导致量子芝诺效应具有不同的芝诺时间标度。

Conclusion: 环境能谱的边界条件（有下界无上界）显著影响两能级系统自发辐射的动力学行为，导致存活概率呈现独特的分数幂律标度，进而影响量子芝诺效应的标度特性。

Abstract: We find that when the environment of a two-level system has an energy spectrum with a lower bound but without an upper one, the survival probability of the spontaneous emission of the two-level system scales with the spatial dimension $D$ and the exponent $n$ of the energy dispersion $|\vec{k}|^n$ of the environment in the form $1-αt^{2-D/n}$ in the short-time and in the form $αt^{D/n-2}$ in the long-time regime. The former fractional scaling of the survival probability leads to a quantum Zeno effect with a different scaling of the Zeno time.

</details>


### [12] [Microwave-free vector magnetometry and crystal orientation determination with Nitrogen-Vacancy centers using Bayesian inference](https://arxiv.org/abs/2512.13835)
*Hilario Espinós,Omkar Dhungel,Arne Wickenbrock,Dmitry Budker,Ricardo Puebla,Erik Torrontegui*

Main category: quant-ph

TL;DR: 提出基于贝叶斯推断的微波自由矢量磁强计框架，利用NV中心交叉弛豫实现近零场下的矢量磁场测量，无需微波和严格晶体对准。


<details>
  <summary>Details</summary>
Motivation: 传统NV中心磁强计依赖微波，会产生热效应和杂散电磁场干扰样品；现有光学方法需要严格对准晶体轴，实用性受限。

Method: 开发贝叶斯推断框架，通过光致发光图谱直接提取磁场矢量和NV方向；建立交叉弛豫共振解析模型，处理任意场和方向配置，并纳入NV对称性的离散简并性。

Result: 实验证明能够稳健确定NV方向和重建矢量磁场，为紧凑、无需对准的实用NV磁强计提供通用途径。

Conclusion: 该框架为实用NV磁强计提供通用解决方案，消除微波需求和对准限制，推动紧凑型量子传感设备的实际应用。

Abstract: Nitrogen-vacancy (NV) centers in diamond provide a solid-state platform for quantum sensing. While optically detected magnetic resonance techniques offer high sensitivity, their reliance on microwaves introduces heating and stray electromagnetic fields that can perturb nearby samples. Optical approaches based on cross-relaxation between differently oriented NV centers remove this constraint but have so far required stringent alignment of the external field with crystallographic axes, restricting their practicality. Here we introduce a general framework for microwave-free vector magnetometry at near-zero field that leverages Bayesian inference to extract both the magnetic field vector and the NV orientation directly from photoluminescence maps. An analytical model of cross-relaxation resonances enables efficient inference under arbitrary field and orientation configurations, while naturally incorporating the discrete degeneracies of the NV symmetry. We experimentally demonstrate robust orientation determination and vector-field reconstruction, establishing a general route toward compact and alignment-free NV magnetometers for practical sensing applications.

</details>


### [13] [Achieving $10^{-5}$ level relative intensity crosstalk in optical holographic qubit addressing via a double-pass digital micromirror device](https://arxiv.org/abs/2512.13882)
*Shilpa Mahato,Rajibul Islam*

Main category: quant-ph

TL;DR: 使用双通道数字微镜器件实现低串扰全息光束整形，用于量子比特寻址


<details>
  <summary>Details</summary>
Motivation: 传统全息光束整形在量子比特控制中存在两个主要问题：相邻位点的残余强度串扰和远场背景噪声，这会导致量子比特控制中的累积误差

Method: 采用单数字微镜器件的双通道配置方案：第一通道在傅里叶平面实现二进制振幅全息图用于个体寻址；第二通道作为可编程中间像平面孔径进行空间滤波；通过多路复用全息图生成辅助场进行相消干涉

Result: 在整个量子比特寻址视场内，相对强度串扰保持在10⁻⁵（-50dB）以下；远场背景噪声降至约10⁻⁶，接近检测极限

Conclusion: 该方案为捕获离子和其他空间有序量子系统提供了一种紧凑、基于DMD的低串扰光学全息量子比特寻址解决方案

Abstract: Holographic beam shaping is a powerful approach for generating individually addressable optical spots for controlling atomic qubits, such as those in trapped-ion quantum processors. However, its application in qubit control is limited by residual intensity crosstalk at neighboring sites and by a nonzero background floor in the far wings of the addressing beam, leading to accumulated errors from many exposed qubits. Here, we present an all-optical scheme that mitigates both effects using a single digital micromirror device (DMD) operated in a double-pass configuration, in which light interacts with two separate regions of the same device. In the first pass, one region of the DMD is placed in a Fourier plane and implements a binary-amplitude hologram for individual addressing, while in the second pass a different region serves as a programmable intermediate image-plane aperture for spatial filtering. By multiplexing the Fourier-plane hologram to include secondary holograms, we generate weak auxiliary fields that interfere destructively with unwanted light at selected sites, while image-plane filtering suppresses the residual tail at larger distances. Together, these techniques maintain relative intensity crosstalk at or below $10^{-5}$ ($-50\,\mathrm{dB}$) across the full field of view relevant for qubit addressing, and further reduce the far-wing background to approximately $10^{-6}$ at large distances from the addressed qubit, approaching the detection limit. These results provide a compact, DMD-based solution for low-crosstalk optical holographic qubit addressing that is directly applicable to trapped ions and other spatially ordered quantum systems.

</details>


### [14] [Implementing the Koopman-von Neumann approach on continuous-variable photonic quantum computers](https://arxiv.org/abs/2512.13887)
*Xinfeng Gao,Olivier Pfister,Stefan Bekiranov*

Main category: quant-ph

TL;DR: 论文探索在连续变量光量子计算架构上实现Koopman-von Neumann形式，用于模拟经典动力系统，特别是谐振子和非线性偏微分方程。


<details>
  <summary>Details</summary>
Motivation: KvN形式将经典力学重新表述为类似量子力学的希尔伯特空间框架，为在量子计算机上模拟经典动力系统提供了有前景的途径。特别是在连续变量光量子计算架构上实现KvN，可以利用量子模拟工具处理传统难以计算的非线性动力学问题。

Method: 采用Koopman-von Neumann形式，将经典力学映射到量子计算框架，利用薛定谔类方程描述经典波函数。在连续变量光量子计算架构上实现该方法，通过量子线性代数工具和酉演化来模拟经典动力系统。

Result: 论文将展示该方法在谐振子和一维非线性偏微分方程两个问题上的实现和可行性，证明KvN方法在量子计算架构上模拟经典动力系统的有效性。

Conclusion: KvN形式为在量子计算机上模拟经典动力系统提供了有效途径，特别是在连续变量光量子计算架构上实现该方法，能够利用量子模拟工具处理传统难以计算的非线性动力学问题，为经典-量子映射开辟了新方向。

Abstract: The Koopman-von Neumann (KvN) formalism recasts classical mechanics in a Hilbert space framework using complex wavefunctions and linear operators, akin to quantum mechanics. Instead of evolving probability densities in phase space (as in Liouville's equation), KvN uses a Schrödinger-like equation for a classical wavefunction, with commuting position and momentum operators. Mapped to quantum computing, KvN offers a promising route to simulate classical dynamical systems using quantum algorithms by leveraging unitary evolution and quantum linear algebra tools, potentially enabling efficient classical-to-quantum mappings without invoking full quantum uncertainty. In this work, we specifically explore the implementation of the KvN approach on continuous-variable photonic quantum computing architectures, with the goals of leveraging quantum simulation for both sampling and computing intractable nonlinear dynamics. We will demonstrate its implementation and feasibility with two problems: the harmonic oscillator and a 1D partial differential equation governing nonlinear dynamics.

</details>


### [15] [Group-Theoretic Reinforcement Learning of Dynamical Decoupling Sequences](https://arxiv.org/abs/2512.13890)
*Charles Marrder,Shuo Sun,Murray J. Holland*

Main category: quant-ph

TL;DR: 使用强化学习设计量子比特的动态解耦脉冲序列，无需先验噪声谱知识


<details>
  <summary>Details</summary>
Motivation: 动态解耦技术通过电磁脉冲序列来减轻量子比特的相位退相干，但现有方法需要特定噪声条件下的解析解，难以应对实际复杂的噪声谱

Method: 提出基于强化学习的方法，使用源自Thompson群F的动作集，使智能体能在非凸优化空间中高效搜索最优脉冲时序

Result: 强化学习智能体能够学习到最小化退相干的脉冲序列，无需底层噪声谱的显式知识

Conclusion: 该方法为实时学习量子比特的最优动态解耦序列开辟了可能性，其无模型特性使其能应对脉冲误差和非高斯噪声等未建模物理效应

Abstract: Dynamical decoupling seeks to mitigate phase decoherence in qubits by applying a carefully designed sequence of effectively instantaneous electromagnetic pulses. Although analytic solutions exist for pulse timings that are optimal under specific noise regimes, identifying the optimal timings for a realistic noise spectrum remains challenging. We propose a reinforcement learning (RL)-based method for designing pulse sequences on qubits. Our novel action set enables the RL agent to efficiently navigate this inherently non-convex optimization landscape. The action set, derived from Thompson's group $F$, is applicable to a broad class of sequential decision problems whose states can be represented as bounded sequences. We demonstrate that our RL agent can learn pulse sequences that minimize dephasing without requiring explicit knowledge of the underlying noise spectrum. This work opens the possibility for real-time learning of optimal dynamical decoupling sequences on qubits which are dephasing-limited. The model-free nature of our algorithm suggests that the agent may ultimately learn optimal pulse sequences even in the presence of unmodeled physical effects, such as pulse errors or non-Gaussian noise.

</details>


### [16] [Quantum Anticodes](https://arxiv.org/abs/2512.13891)
*ChunJun Cao,Giuseppe Cotardo,Brad Lackey*

Main category: quant-ph

TL;DR: 提出了一种量子纠错码的辛框架，通过反码视角分析局部结构，将码视为辛空间，反码作为在指定分量上消失的最大辛子空间


<details>
  <summary>Details</summary>
Motivation: 为量子纠错码建立统一的辛几何框架，将经典纠错码中的反码概念自然地推广到量子领域，以更好地分析量子码的局部结构特性

Method: 将量子码视为辛空间，定义反码为在指定分量上消失的最大辛子空间，建立辛框架下的量子码理论，包含稳定子码和子系统码等家族

Result: 该框架自然地扩展了量子码的广义距离概念，产生了捕捉局部代数和组合特征的新不变量，并自然地导出了辛码的穿孔和缩短操作

Conclusion: 反码概念为量子纠错中的关键现象（如清理引理和互补恢复）提供了代数解释，并为重量枚举器提供了新的描述，建立了量子码的辛几何理论

Abstract: This work introduces a symplectic framework for quantum error correcting codes in which local structure is analyzed through an anticode perspective. In this setting, a code is treated as a symplectic space, and anticodes arise as maximal symplectic subspaces whose elements vanish on a prescribed set of components, providing a natural quantum analogue of their classical counterparts. This framework encompasses several families of quantum codes, including stabilizer and subsystem codes, provides a natural extension of generalized distances in quantum codes, and yields new invariants that capture local algebraic and combinatorial features. The notion of anticodes also naturally leads to operations such as puncturing and shortening for symplectic codes, which in turn provide algebraic interpretations of key phenomena in quantum error correction, such as the cleaning lemma and complementary recovery and yield new descriptions of weight enumerators.

</details>


### [17] [Regulated reconstruction of long-time spin--boson dynamics and emergent zero-bias transverse measurement primitive](https://arxiv.org/abs/2512.13900)
*Dragomir Davidovic*

Main category: quant-ph

TL;DR: 提出一种调控的时间卷积无主方程方法，通过重构动力学映射来避免长期时间下的发散问题，并在自旋-玻色子模型中发现了横向测量基元的涌现现象。


<details>
  <summary>Details</summary>
Motivation: 传统时间卷积无主方程在长时间尺度下会失效，特别是在相关主导区域，其时间局域微扰生成元会出现长期增长问题。需要一种方法来克服这一限制。

Method: 采用调控的部分重求和重构动力学映射，围绕Davies参考半群展开，通过非马尔可夫密度矩阵关联函数C(t)来保持长时间有界性。在旋转波基准模型上验证方法，并应用于无偏自旋-玻色子模型。

Result: 方法成功调控了动力学映射的发散问题。在自旋-玻色子模型中发现了横向测量基元的涌现：浴记忆和反旋转项诱导相位锁定，在有限时间尺度t_P内不可逆地擦除σ_x本征空间之间的相对相位，形成有效的零偏置横向测量通道。

Conclusion: 提出的调控重构方法有效解决了TCL主方程的长期发散问题，揭示了非马尔可夫干涉效应在量子动力学中的重要作用，特别是在自旋-玻色子模型中涌现的横向测量现象，这在旋转波近似和Davies弱耦合极限中不会出现。

Abstract: Time--convolutionless (TCL) master equations can break down at long times: time-local perturbative generators develop secular growth in correlation-dominated regimes. We mitigate this by a regulated, partially resummed reconstruction of the dynamical map around a Davies reference semigroup, expressed through a non--Markovian density-matrix correlator C(t) that remains bounded at late times. An exactly solvable rotating-wave benchmark links generator growth to interference-induced near-zeros of the coherence and shows how the reconstruction regulates the map. Applying the method to the unbiased spin--boson model reveals an emergent transverse measurement primitive: bath memory and counter--rotating terms induce phase lock-in that irreversibly erases the relative phase between $σ_x$ eigenspaces on a finite timescale $t_P$, yielding an effective zero-bias transverse ($σ_x$) measurement channel. The selected transverse basis is not assumed a priori; it follows from the reconstructed reduced dynamics. The effect disappears in the rotating-wave approximation and in the Davies weak-coupling limit, demonstrating its non--Markovian interference origin.

</details>


### [18] [Magic state cultivation on a superconducting quantum processor](https://arxiv.org/abs/2512.13908)
*Emma Rosenfeld,Craig Gidney,Gabrielle Roberts,Alexis Morvan,Nathan Lacroix,Dvir Kafri,Jeffrey Marshall,Ming Li,Volodymyr Sivak,Dmitry Abanin,Amira Abbas,Rajeev Acharya,Laleh Aghababaie Beni,Georg Aigeldinger,Ross Alcaraz,Sayra Alcaraz,Trond I. Andersen,Markus Ansmann,Frank Arute,Kunal Arya,Walt Askew,Nikita Astrakhantsev,Juan Atalaya,Ryan Babbush,Brian Ballard,Joseph C. Bardin,Hector Bates,Andreas Bengtsson,Majid Bigdeli Karimi,Alexander Bilmes,Simon Bilodeau,Felix Borjans,Jenna Bovaird,Dylan Bowers,Leon Brill,Peter Brooks,Michael Broughton,David A. Browne,Brett Buchea,Bob B. Buckley,Tim Burger,Brian Burkett,Nicholas Bushnell,Jamal Busnaina,Anthony Cabrera,Juan Campero,Hung-Shen Chang,Silas Chen,Zijun Chen,Ben Chiaro,Liang-Ying Chih,Agnetta Y. Cleland,Bryan Cochrane,Matt Cockrell,Josh Cogan,Paul Conner,Harold Cook,Rodrigo G. Cortiñas,William Courtney,Alexander L. Crook,Ben Curtin,Martin Damyanov,Sayan Das,Dripto M. Debroy,Sean Demura,Paul Donohoe,Ilya Drozdov,Andrew Dunsworth,Valerie Ehimhen,Alec Eickbusch,Aviv Moshe Elbag,Lior Ella,Mahmoud Elzouka,David Enriquez,Catherine Erickson,Lara Faoro,Vinicius S. Ferreira,Marcos Flores,Leslie Flores Burgos,Sam Fontes,Ebrahim Forati,Jeremiah Ford,Brooks Foxen,Masaya Fukami,Alan Wing Lun Fung,Lenny Fuste,Suhas Ganjam,Gonzalo Garcia,Christopher Garrick,Robert Gasca,Helge Gehring,Robert Geiger,Élie Genois,William Giang,Dar Gilboa,James E. Goeders,Edward C. Gonzales,Raja Gosula,Stijn J. de Graaf,Alejandro Grajales Dau,Dietrich Graumann,Joel Grebel,Alex Greene,Jonathan A. Gross,Jose Guerrero,Loïck Le Guevel,Tan Ha,Steve Habegger,Tanner Hadick,Ali Hadjikhani,Michael C. Hamilton,Monica Hansen,Matthew P. Harrigan,Sean D. Harrington,Jeanne Hartshorn,Stephen Heslin,Paula Heu,Oscar Higgott,Reno Hiltermann,Jeremy Hilton,Hsin-Yuan Huang,Mike Hucka,Christopher Hudspeth,Ashley Huff,William J. Huggins,Lev B. Ioffe,Evan Jeffrey,Shaun Jevons,Zhang Jiang,Xiaoxuan Jin,Chaitali Joshi,Pavol Juhas,Andreas Kabel,Hui Kang,Kiseo Kang,Amir H. Karamlou,Ryan Kaufman,Kostyantyn Kechedzhi,Tanuj Khattar,Mostafa Khezri,Seon Kim,Paul V. Klimov,Can M. Knaut,Bryce Kobrin,Alexander N. Korotkov,Fedor Kostritsa,John Mark Kreikebaum,Ryuho Kudo,Ben Kueffler,Arun Kumar,Vladislav D. Kurilovich,Vitali Kutsko,Tiano Lange-Dei,Brandon W. Langley,Pavel Laptev,Kim-Ming Lau,Emma Leavell,Justin Ledford,Joy Lee,Kenny Lee,Brian J. Lester,Wendy Leung,Lily Li,Wing Yan Li,Alexander T. Lill,William P. Livingston,Matthew T. Lloyd,Aditya Locharla,Laura De Lorenzo,Erik Lucero,Daniel Lundahl,Aaron Lunt,Sid Madhuk,Aniket Maiti,Ashley Maloney,Salvatore Mandrà,Leigh S. Martin,Orion Martin,Eric Mascot,Paul Masih Das,Dmitri Maslov,Melvin Mathews,Cameron Maxfield,Jarrod R. McClean,Matt McEwen,Seneca Meeks,Anthony Megrant,Kevin C. Miao,Zlatko K. Minev,Reza Molavi,Sebastian Molina,Shirin Montazeri,Charles Neill,Michael Newman,Anthony Nguyen,Murray Nguyen,Chia-Hung Ni,Murphy Yuezhen Niu,Nicholas Noll,Logan Oas,William D. Oliver,Raymond Orosco,Kristoffer Ottosson,Alice Pagano,Agustin Di Paolo,Sherman Peek,David Peterson,Alex Pizzuto,Elias Portoles,Rebecca Potter,Orion Pritchard,Michael Qian,Chris Quintana,Ganesh Ramachandran,Arpit Ranadive,Matthew J. Reagor,Rachel Resnick,David M. Rhodes,Daniel Riley,Roberto Rodriguez,Emma Ropes,Lucia B. De Rose,Eliott Rosenberg,Dario Rosenstock,Elizabeth Rossi,Pedram Roushan,David A. Rower,Robert Salazar,Kannan Sankaragomathi,Murat Can Sarihan,Max Schaefer,Sebastian Schroeder,Henry F. Schurkus,Aria Shahingohar,Michael J. Shearn,Aaron Shorter,Noah Shutty,Vladimir Shvarts,Spencer Small,W. Clarke Smith,David A. Sobel,Barrett Spells,Sofia Springer,George Sterling,Jordan Suchard,Aaron Szasz,Alexander Sztein,Madeline Taylor,Jothi Priyanka Thiruraman,Douglas Thor,Dogan Timucin,Eifu Tomita,Alfredo Torres,M. Mert Torunbalci,Hao Tran,Abeer Vaishnav,Justin Vargas,Sergey Vdovichev,Guifre Vidal,Benjamin Villalonga,Catherine Vollgraff Heidweiller,Meghan Voorhees,Steven Waltman,Jonathan Waltz,Shannon X. Wang,Danni Wang,Brayden Ware,James D. Watson,Yonghua Wei,Travis Weidel,Theodore White,Kristi Wong,Bryan W. K. Woo,Christopher J. Wood,Maddy Woodson,Cheng Xing,Z. Jamie Yao,Ping Yeh,Bicheng Ying,Juhwan Yoo,Noureldin Yosri,Elliot Young,Grayson Young,Adam Zalcman,Ran Zhang,Yaxing Zhang,Ningfeng Zhu,Nicholas Zobrist,Zhenjie Zou,Hartmut Neven,Sergio Boixo,Cody Jones,Julian Kelly,Alexandre Bourassa,Kevin J. Satzinger*

Main category: quant-ph

TL;DR: 实验展示了在超导量子处理器上实现魔法态培育，将误差降低40倍，达到0.9999(1)的保真度，为量子计算中的非克利福德门问题提供了可行解决方案。


<details>
  <summary>Details</summary>
Motivation: 容错量子计算需要通用门集，但非克利福德门在大多数量子纠错架构中代表显著资源成本。魔法态培育提供了比资源密集型蒸馏协议更高效的替代方案，但需要实验验证其假设。

Method: 在超导量子处理器上实现魔法态培育，包括切换到表面码的代码切换，并开发了容错测量协议来限定魔法态保真度。

Result: 培育将误差降低了40倍，获得0.9999(1)的态保真度（保留8%的尝试）。实验建立了魔法态培育作为量子计算重大挑战的可行解决方案。

Conclusion: 魔法态培育是解决量子计算中非克利福德门资源成本问题的有效方法，实验验证了其在超导量子处理器上的可行性。

Abstract: Fault-tolerant quantum computing requires a universal gate set, but the necessary non-Clifford gates represent a significant resource cost for most quantum error correction architectures. Magic state cultivation offers an efficient alternative to resource-intensive distillation protocols; however, testing the proposal's assumptions represents a challenging departure from quantum memory experiments. We present an experimental study of magic state cultivation on a superconducting quantum processor. We implement cultivation, including code-switching into a surface code, and develop a fault-tolerant measurement protocol to bound the magic state fidelity. Cultivation reduces the error by a factor of 40, with a state fidelity of 0.9999(1) (retaining 8% of attempts). Our results experimentally establish magic state cultivation as a viable solution to one of quantum computing's most significant challenges.

</details>


### [19] [Q-IRIS: The Evolution of the IRIS Task-Based Runtime to Enable Classical-Quantum Workflows](https://arxiv.org/abs/2512.13931)
*Narasinga Rao Miniskar,Mohammad Alaul Haque Monil,Elaine Wong,Vicente Leyton-Ortega,Jeffrey S. Vetter,Seth R. Johnson,Travis S. Humble*

Main category: quant-ph

TL;DR: 提出一个混合执行框架，集成IRIS异步任务运行时与XACC量子编程框架，通过QIR-EE在异构系统上协调经典与量子工作负载，展示了量子电路切割等技术的实际应用。


<details>
  <summary>Details</summary>
Motivation: 新兴HPC系统的极端异构性开始包含量子加速器，需要能够协调经典和量子工作负载的运行时系统。

Method: 提出概念验证的混合执行框架，集成IRIS异步任务运行时与XACC量子编程框架，通过Quantum Intermediate Representation Execution Engine (QIR-EE)在异构后端（包括多个量子模拟器）上编排多个QIR程序。

Result: 成功实现了多个量子工作负载的异步调度和执行，通过量子电路切割技术将四量子比特电路分解为更小的子电路，减少了每个任务的量子模拟负载，展示了任务粒度如何改善模拟器吞吐量和减少排队行为。

Conclusion: 概述了扩展混合运行时的关键挑战，包括协调调度、经典-量子交互管理以及在异构系统中支持多样化后端资源。

Abstract: Extreme heterogeneity in emerging HPC systems are starting to include quantum accelerators, motivating runtimes that can coordinate between classical and quantum workloads. We present a proof-of-concept hybrid execution framework integrating the IRIS asynchronous task-based runtime with the XACC quantum programming framework via the Quantum Intermediate Representation Execution Engine (QIR-EE). IRIS orchestrates multiple programs written in the quantum intermediate representation (QIR) across heterogeneous backends (including multiple quantum simulators), enabling concurrent execution of classical and quantum tasks. Although not a performance study, we report measurable outcomes through the successful asynchronous scheduling and execution of multiple quantum workloads. To illustrate practical runtime implications, we decompose a four-qubit circuit into smaller subcircuits through a process known as quantum circuit cutting, reducing per-task quantum simulation load and demonstrating how task granularity can improve simulator throughput and reduce queueing behavior -- effects directly relevant to early quantum hardware environments. We conclude by outlining key challenges for scaling hybrid runtimes, including coordinated scheduling, classical-quantum interaction management, and support for diverse backend resources in heterogeneous systems.

</details>


### [20] [Coherence-Sensitive Readout Models for Quantum Devices: Beyond the Classical Assignment Matrix](https://arxiv.org/abs/2512.13949)
*Zachariah Malik,Zain Saleem*

Main category: quant-ph

TL;DR: 该论文提出了一个超越经典读取误差模型的通用框架，考虑了量子相干性对测量统计的影响，通过引入相干响应矩阵C来捕捉计算基态之间的干涉效应。


<details>
  <summary>Details</summary>
Motivation: 现有量子设备读取误差模型普遍假设测量噪声是经典的，即测量统计仅由理想计算基态布居通过列随机分配矩阵A得到。这种描述忽略了量子相干性对测量的影响，假设有效POVM在测量基上是对角的，因此对量子相干完全不敏感。

Method: 作者放松了经典假设，推导了在任意完全正定保迹噪声后接计算基测量下观测测量概率的通用表达式。将理想后电路态表示为布居x和相干y，证明观测概率向量z满足z = A x + C y，其中A是经典分配矩阵，C是从有效POVM在计算基中的非对角矩阵元构造的相干响应矩阵。

Result: 经典模型z = A x仅在所有POVM元都是对角的情况下成立。相干响应矩阵C量化了关于相干读取失真和计算基态之间干涉的可访问信息，这些信息在仅保留A的模型中是不可见的。

Conclusion: 该工作为当前和未来量子设备上的相干敏感读取建模提供了一个自然、完全通用的框架，能够捕捉经典模型无法描述的量子相干效应。

Abstract: Readout error models for noisy quantum devices almost universally assume that measurement noise is classical: the measurement statistics are obtained from the ideal computational-basis populations by a column-stochastic assignment matrix $A$. This description is equivalent to assuming that the effective positive-operator-valued measurement (POVM) is diagonal in the measurement basis, and therefore completely insensitive to quantum coherences. We relax this assumption and derive a fully general expression for the observed measurement probabilities under arbitrary completely positive trace-preserving (CPTP) noise preceding a computational-basis measurement. Writing the ideal post-circuit stat $\tildeρ$ in terms of its populations $x$ and coherences $y$, we show that the observed probability vector $z$ satisfies $z = A x + C y$, where $A$ is the familiar classical assignment matrix and $C$ is a coherence-response matrix constructed from the off-diagonal matrix elements of the effective POVM in the computational basis. The classical model $z = A x$ arises if and only if all POVM elements are diagonal; in this sense $C$ quantifies accessible information about coherent readout distortions and interference between computational-basis states, all of which are invisible to models that retain only $A$. This work therefore provides a natural, fully general framework for coherence-sensitive readout modeling on current and future quantum devices.

</details>


### [21] [A non-linear quantum neural network framework for entanglement engineering](https://arxiv.org/abs/2512.13971)
*Adriano Macarone-Palmieri,Alberto Ferrara,Rosario Lo Franco*

Main category: quant-ph

TL;DR: 提出一种基于量子神经网络的低深度变分纠缠工程框架，通过非线性激活函数和电路拓扑优化，在噪声量子设备中可扩展地生成多体纠缠态。


<details>
  <summary>Details</summary>
Motivation: 多体纠缠是量子技术的核心资源，但在噪声量子设备中可扩展地生成多体纠缠仍然具有挑战性。现有线性变分电路表达能力有限，需要探索新的架构来克服这些限制。

Method: 提出受记忆型光子组件启发的量子神经网络架构，具有线性缩放特性。引入物理动机的非线性激活函数增强表达能力，通过蒙特卡洛采样优化电路拓扑结构。在噪声场景下使用Meyer-Wallach全局纠缠作为优化代价，并用二分负性验证纠缠。

Result: 网络能高效生成接近GHz极限的高度纠缠纯态，在20量子比特内非线性网络表现出明显优势。对于混合态，优化电路在对称和非对称二分下都能产生显著纠缠，在10量子比特内验证有效。

Conclusion: 建立了一个实验可行且可扩展的变分框架，用于在近期量子设备上工程化多体纠缠，突出了非线性和电路拓扑结构的协同作用。

Abstract: Multipartite entanglement is a key resource for quantum technologies, yet its scalable generation in noisy quantum devices remains challenging. Here, we propose a low-depth quantum neural network architecture with linear scaling, inspired by memory-enabled photonic components, for variational entanglement engineering. The network incorporates physically motivated non-linear activation functions, enhancing expressivity beyond linear variational circuits at fixed depth. By Monte Carlo sampling over circuit topologies, we identify architectures that efficiently generate highly entangled pure states, approaching the GHz limit, and demonstrate a clear advantage of non-linear networks up to 20 qubits. For the noisy scenario, we employ the experimentally accessible Meyer-Wallach global entanglement as a surrogate optimization cost and certify entanglement using bipartite negativity. For mixed states of up to ten qubits, the optimized circuits generate substantial entanglement across both symmetric and asymmetric bipartitions. These results establish an experimentally motivated and scalable variational framework for engineering multipartite entanglement on near-term quantum devices, highlighting the combined role of non-linearity and circuit topology.

</details>


### [22] [Quantifying electron-nuclear spin entanglement dynamics in central-spin systems using one-tangles](https://arxiv.org/abs/2512.14004)
*Isabela Gnasso,Khadija Sarguroh,Dorian Gangloff,Sophia E. Economou,Edwin Barnes*

Main category: quant-ph

TL;DR: 该研究将一纠缠功率度量推广到更广泛的电子-核中心自旋系统，包括自旋>1/2的核系统，并应用于量子点等系统，提出了最大化纠缠和计算退相干时间的方法。


<details>
  <summary>Details</summary>
Motivation: 固态量子系统（如量子点、稀土离子、金刚石色心）中的核自旋通常会导致电子自旋退相干，但如果可控，它们可以作为长寿命量子存储器。需要量化这些系统中电子与核自旋之间的纠缠动力学。

Method: 将一纠缠功率度量从自旋-1/2核系统推广到自旋>1/2的核系统，应用于(In)GaAs量子点等系统。通过识别物理可实现参数区域来最大化纠缠，利用自然简并性和系统可调性在动态解耦下生成目标自旋子集的最大纠缠。

Result: 建立了适用于广泛电子-核中心自旋系统的一纠缠功率框架，能够精确计算量子点电子自旋退相干时间（包括使用自旋回波序列的情况），并识别出维持相干性的系统条件。

Conclusion: 该研究为量子点、稀土离子和色心等固态量子系统提供了一种通用方法来量化电子-核纠缠动力学，优化纠缠生成，并计算退相干时间，有助于量子网络、计算和传感应用的发展。

Abstract: Optically-active solid-state systems such as self-assembled quantum dots, rare-earth ions, and color centers in diamond and SiC are promising candidates for quantum network, computing, and sensing applications. Although the nuclei in these systems naturally lead to electron spin decoherence, they can be repurposed, if they are controllable, as long-lived quantum memories. Prior work showed that a metric known as the one-tangling power can be used to quantify the entanglement dynamics of sparse systems of spin-1/2 nuclei coupled to color centers in diamond and SiC. Here, we generalize these findings to a wide range of electron-nuclear central-spin systems, including those with spin > 1/2 nuclei, such as in III-V quantum dots (QDs), rare-earth ions, and some color centers. Focusing on the example of an (In)GaAs QD, we offer a procedure for pinpointing physically realistic parameter regimes that yield maximal entanglement between the central electron and surrounding nuclei. We further harness knowledge of naturally-occurring degeneracies and the tunability of the system to generate maximal entanglement between target subsets of spins when the QD electron is subject to dynamical decoupling. We also leverage the one-tangling power as an exact and immediate method for computing QD electron spin dephasing times with and without the application of spin echo sequences, and use our analysis to identify coherence-sustaining conditions within the system.

</details>


### [23] [Frozen Gaussian sampling algorithms for simulating Markovian open quantum systems in the semiclassical regime](https://arxiv.org/abs/2512.14015)
*Limin Xu,Zhen Huang,Zhennan Zhou*

Main category: quant-ph

TL;DR: 提出基于Wigner-Fokker-Planck相空间表述的Frozen Gaussian Sampling算法，用于模拟半经典区域中的马尔可夫开放量子系统，解决了传统网格方法在振荡动力学中的计算瓶颈。


<details>
  <summary>Details</summary>
Motivation: 模拟半经典区域中的马尔可夫开放量子系统面临重大计算挑战，因为动力学的高度振荡特性对传统网格方法提出了极高的分辨率要求，导致计算成本过高。

Method: 基于Wigner-Fokker-Planck相空间表述，开发了Frozen Gaussian Sampling（FGS）算法。这是一种无网格的采样方法，避免了传统网格方法的边界限制。

Result: FGS算法具有两大优势：1) 物理可观测量计算中的采样误差与半经典参数ε无关，从根本上打破了网格方法在半经典极限下的计算瓶颈；2) 无网格特性完全消除了边界引起的不稳定性，支持长时间模拟。

Conclusion: FGS算法成为研究开放量子系统长时间行为的强大工具，为强非谐势中稳态存在的数值证据提供了支持，填补了当前缺乏严格分析结果的空白。

Abstract: Simulating Markovian open quantum systems in the semiclassical regime poses a grand challenge for computational physics, as the highly oscillatory nature of the dynamics imposes prohibitive resolution requirements on traditional grid-based methods. To overcome this barrier, this paper introduces an efficient Frozen Gaussian Sampling (FGS) algorithm based on the Wigner-Fokker-Planck phase-space formulation. The proposed algorithm exhibits two transformative advantages. First, for the computation of physical observables, its sampling error is independent of the semiclassical parameter $\varepsilon$, thus fundamentally breaking the prohibitive computational scaling faced by grid methods in the semiclassical limit. Second, its mesh-free nature entirely eliminates the boundary-induced instabilities that constrain long-time grid-based simulations. Leveraging these capabilities, the FGS algorithm serves as a powerful investigatory tool for exploring the long-time behavior of open quantum systems. Specifically, we provide compelling numerical evidence for the existence of steady states in strongly non-harmonic potentials-a regime where rigorous analytical results are currently lacking.

</details>


### [24] [Integrability Breaking and Coherent Dynamics in Hermitian and Non-Hermitian Spin Chains with Long-Range Coupling](https://arxiv.org/abs/2512.14065)
*Y. S. Liu,X. Z. Zhang*

Main category: quant-ph

TL;DR: 该论文研究了一维自旋模型中可调长程跳跃项H_n如何驱动从可积性到量子混沌的转变，并发现了即使在全局混沌下仍存在的精确非热本征态（量子多体疤痕）。


<details>
  <summary>Details</summary>
Motivation: 理解复杂量子系统中遍历性破缺的机制是非平衡物理学的核心问题。作者旨在探索长程和非厄米效应如何重塑量子遍历性，为在复杂多体系统中保持量子相干性提供新途径。

Method: 通过系统分析能级间距统计、Krylov复杂度和纠缠熵，研究一维自旋模型中可调长程跳跃项H_n的作用。H_n作为通用控制参数，连接厄米和非厄米区域。

Result: 增加H_n强度在厄米极限下诱导从泊松统计到高斯正交系综统计的交叉，在非厄米情况下同样触发混沌动力学。尽管出现全局混沌，但仍发现了一系列精确的非热本征态，这些态作为稳健的量子多体疤痕存在，即使在强非厄米扰动下仍保持低纠缠和相干动力学。

Conclusion: 长程和非厄米效应通过通用机制重塑量子遍历性，为在复杂多体系统中保持量子相干性提供了新途径。发现的量子多体疤痕态即使在混沌环境中也能抵抗热化。

Abstract: Unraveling the mechanisms of ergodicity breaking in complex quantum systems is a central pursuit in nonequilibrium physics. In this work, we investigate a one-dimensional spin model featuring a tunable long-range hopping term, $H_{n}$, which introduces nonlocal interactions and bridges the gap between Hermitian and non-Hermitian regimes. Through a systematic analysis of level-spacing statistics, Krylov complexity, and entanglement entropy, we demonstrate that $H_{n}$ acts as a universal control parameter driving the transition from integrability to quantum chaos. Specifically, increasing the strength of $H_{n}$ induces a crossover from Poissonian to Gaussian Orthogonal Ensemble statistics in the Hermitian limit, and similarly triggers chaotic dynamics in the non-Hermitian case. Most remarkably, despite the onset of global chaos, we identify a tower of exact nonthermal eigenstates that evade thermalization. These states survive as robust quantum many-body scars, retaining low entanglement and coherent dynamics even under strong non-Hermitian perturbations. Our findings reveal a universal mechanism by which long-range and non-Hermitian effects reshape quantum ergodicity, offering new pathways for preserving quantum coherence in complex many-body systems.

</details>


### [25] [Group Theory and Representation Theory for Identical Particles](https://arxiv.org/abs/2512.14091)
*James Daniel Whitfield*

Main category: quant-ph

TL;DR: 本章节从量子信息科学教材中独立出来，系统介绍量子模拟所需的群论和表示论数学基础，重点阐述全同粒子的数学描述及其在量子力学中的处理方式。


<details>
  <summary>Details</summary>
Motivation: 量子模拟作为量子技术中最广为人知的应用之一，激发了凝聚态物理、量子化学和量子计算交叉领域的众多有趣问题。这些领域共享数学基础，需要系统梳理群论和表示论知识来支持相关研究。

Method: 通过全面开发全同粒子的数学理论，包括第一量子化和第二量子化方案中描述全同粒子系统的力学方法。从群论和表示论的基本原理出发，构建完整的数学框架。

Result: 提供了一个关于全同粒子对称性和表示论的完整数学发展，涵盖了量子模拟所需的数学工具，可作为相关领域研究者的参考资源。

Conclusion: 本章节虽然源自量子信息科学教材，但因其内容不专门聚焦于量子信息而单独发布，为研究全同粒子对称性和表示论提供了系统性的数学基础，适合相关领域研究者参考。

Abstract: Few, if any, applications of quantum technology are as widely known as the quantum simulation of quantum matter. Consequently, many interesting questions have been sparked at the intersection of condensed matter, quantum chemistry, and quantum computing. Given the common mathematical foundation of these subjects, we walk through the necessary group theory and representation theory serving as background in all of these fields. Our discussion will include a full development of the mathematics of identical particles and the mechanics of describing systems of identical particles in both first and second quantization schemes. This chapter is an offshoot of a larger work that provides a graduate-level introduction to quantum information science. This chapter is being released separately because it is not explicitly focused on quantum information. It has grown beyond a short digression into a full-fledged journey into the symmetries and representations of identical particles that we invite you, the reader, to join.

</details>


### [26] [QBism, Polishing Some Points](https://arxiv.org/abs/2512.14122)
*Christopher A. Fuchs,Blake C. Stacey*

Main category: quant-ph

TL;DR: QBism将量子理论视为主观决策框架而非客观描述，强调波恩规则是规范性而非描述性，所有概率包括量子概率都是主观的，测量结果是个人经验，从而提供对量子基础问题的新视角。


<details>
  <summary>Details</summary>
Motivation: QBism旨在通过消除量子理论中过于脆弱无法作为本体论的元素，从剩余部分寻找"本体论教训"，为量子理论提供更一致的主观解释框架。

Method: 通过阐述QBism的三个核心原则：1)波恩规则是规范性陈述而非自然法则；2)所有概率都是主观的，量子态对世界没有"本体论控制"；3)量子测量结果只是代理人的个人经验。

Result: 基于这些原则，QBism能够更好地解释：1)与玻尔明确语言关切的对比；2)与埃弗雷特解释的对比；3)贝尔不等式违反的意义；4)对维格纳"暂停动画"论证的回应。

Conclusion: QBism的本体论教训指向量子理论的主观主义解释，这可能对未来一百年的量子理论发展以及人类对现实的理解产生深远影响。

Abstract: QBism pursues the real by first eliminating the elements of quantum theory too fragile to be ontologies on their own. Thereafter, it seeks an "ontological lesson" from whatever remains. Here, we explore this program by highlighting three tenets of QBism. First, the Born Rule is a normative statement. It is about the decision-making behavior any individual agent should strive for, not a descriptive "law of nature." Second, all probabilities, including all quantum probabilities, are so subjective they never tell nature what to do. This includes probability-1 assignments. Quantum states thus have no "ontic hold" on the world, which implies a more radical kind of indeterminism in quantum theory than other interpretations understand. Third, quantum measurement outcomes just are personal experiences for the agent gambling upon them. Thus all quantum measurement outcomes are local in the sense of the agent enacting them. Through these tenets, we explain four points better than previously: 1) how QBism contrasts with Bohr's concern over unambiguous language, 2) how QBism contrasts with the Everett interpretation, 3) how QBism understands the meaning of Bell inequality violations, and 4) how QBism responds to Wigner's "suspended animation" argument. Finally, we consider the ontological lesson of the tenets and ask what it might mean for the next one hundred years of quantum theory and humankind more generally.

</details>


### [27] [Quantum Fisher Information Measure in a Strongly Confined Harmonic Paul Trap Lattice System](https://arxiv.org/abs/2512.14155)
*Precious Ogbonda Amadi,Paphon Pewkhom,Pruet Kalasuwan,Norshamsuri Ali,Syed Alwee Aljunid,Rosdisham Endut*

Main category: quant-ph

TL;DR: 该研究通过控制离子阱中有效势能的变化，分析单个离子的信息与结构特性，发现Fisher信息、Shannon熵和Fisher-Shannon复杂度能追踪有效势能曲率，为精密量子控制提供信息论框架。


<details>
  <summary>Details</summary>
Motivation: 研究离子阱平台中如何通过调控有效势能来探索量子系统的信息特性，为精密量子控制提供理论基础。

Method: 在Paul阱中引入光学晶格修改有效势能，将阱频率ω和晶格参数κ作为独立调谐参数，分析系统基态下Fisher信息、Shannon熵和Fisher-Shannon复杂度随有效势能曲率的变化。

Result: 信息度量（Fisher信息、Shannon熵、Fisher-Shannon复杂度）能准确追踪有效势能曲率ω_eff=ω²√(1-κ)，且系统行为由曲率而非具体控制参数决定，证明离子阱平台可在保持谐波特性不变的情况下工程化曲率。

Conclusion: ω和κ的相互作用为精密量子控制提供了实用途径，并为探测约束、量子化尺度和信息流提供了信息论框架，突显了离子阱平台在量子信息处理中的优势。

Abstract: In this work, we examine how the informational and structural properties of a single ion respond to controlled changes of the effective potential in a Paul trap modified by an optical lattice. We consider the ground state of the system where confinement is strongest. And by treating the trap frequency $ω$ and lattice $κ$ as independent tunning parameters, we show that Fisher information, Shannon entropy, and Fisher-Shannon complexity track the curvature of the effective potential $ω_{\mathrm{eff}}=ω^2\,\sqrt{1-κ}$. The $ω$ and $κ$ sweeps confirm that curvature and not the choice of control parameter determines the behaviour of the system. This gives the trapped-ion platform a clear advantage that the curvature can be engineered without altering the harmonic characteristics of the system. The interplay between $ω$ and $κ$ thus provides a practical route for precision quantum control and offers Information-theoretic framework for experiments that probe confinement, quantization scale, and information flow in engineered ion traps.

</details>


### [28] [High-Order Harmonic Generation with Beyond-Semiclassical Emitter Dynamics: A Strong-Field Quantum Optical Heisenberg Picture Approach](https://arxiv.org/abs/2512.14174)
*Christian Saugbjerg Lange,Ella Elisabeth Lassen,Rasmus Vesterager Gothelf,Lars Bojer Madsen*

Main category: quant-ph

TL;DR: 本文提出了一种在Heisenberg绘景中描述强场过程的新框架，特别针对高次谐波生成，能够准确捕捉量子涨落效应并简化计算。


<details>
  <summary>Details</summary>
Motivation: 当前强场过程的量子光学描述主要在Schrödinger绘景中进行，存在计算限制和近似要求，而Heisenberg绘景相对未被充分探索，需要开发更准确、可控的理论框架。

Method: 在Heisenberg绘景中开发了时间演化算符的精确可控微扰展开，推导了超越半经典的修正项，考虑了量子电磁场的量子涨落对发射体动力学的影响。

Result: 该框架在当前感兴趣的参数范围内准确，给出了关键观测量的闭式表达式；发现压缩程度随发射体数量增加而增加，而光子统计在大发射体极限下趋近于经典泊松分布；超越半经典的发射体动力学显著增强了发射光的压缩程度。

Conclusion: 这项工作推进了对量子光学高次谐波生成的理论理解，并引入了一个可访问且良好控制的框架来描述现实实验，特别适用于大发射体集合的典型实验条件。

Abstract: Quantum-optical descriptions of strong-field processes have attracted significant attention in recent years. Typically, the theoretical modeling has been conducted in the Schrödinger picture, where results are only obtainable under certain approximations, while, in contrast, the Heisenberg picture has remained relatively unexplored. In this work, we develop an accurately controlled perturbative expansion of the time-evolution operator in the Heisenberg picture and derive beyond-semiclassical corrections to the emitter dynamics due to the coupling to the quantized electromagnetic field, capturing effects of the quantum fluctuations present in the latter. We focus on high-order harmonic generation (HHG), where the approach is accurate in parameter regimes of current interest and it gives closed-form expressions for key observables. This formulation not only simplifies numerical calculations compared to the Schrödinger-picture approach but also provides a clear correspondence between nonclassical features of the emitted light and the underlying induced dynamics of the generating medium including quantum fluctuations. Moreover, the Heisenberg framework naturally yields scaling relations with the number of independent emitters, enabling us to assess whether nonclassical behavior should persist under typical experimental conditions involving large emitter ensembles. Interestingly, we find that the degree of squeezing increases with the number of emitters, whereas the photon statistics approaches a classical Poissonian distribution in the many-emitter limit. We also find that the beyond-semiclassical emitter dynamics significantly enhances the degree of squeezing of the emitted light. Our work advances the theoretical understanding of quantum-optical HHG and introduces an accessible and well-controlled framework to describe realistic experiments.

</details>


### [29] [Towards Explainable Quantum AI: Informing the Encoder Selection of Quantum Neural Networks via Visualization](https://arxiv.org/abs/2512.14181)
*Shaolun Ruan,Feng Liang,Rohan Ramakrishna,Chao Ren,Rudai Yan,Qiang Guan,Jiannan Li,Yong Wang*

Main category: quant-ph

TL;DR: XQAI-Eyes：一种可视化工具，帮助量子神经网络开发者比较经典数据特征与编码量子态，分析不同类别间的混合量子态，以优化量子编码器选择。


<details>
  <summary>Details</summary>
Motivation: 量子神经网络中编码器的选择缺乏系统指导，当前方法依赖试错，且面临两大挑战：1) 训练前难以评估编码量子态；2) 缺乏直观方法分析编码器区分数据特征的能力。

Method: 提出XQAI-Eyes可视化工具，通过桥接经典与量子视角，让开发者能够比较经典数据特征与对应编码量子态，并检查不同类别间的混合量子状态。

Result: 在不同数据集和编码器设计上的评估表明，XQAI-Eyes能够支持探索编码器设计与QNN有效性之间的关系，领域专家使用该工具得出了基于模式保持和特征映射原则的量子编码器选择实践。

Conclusion: XQAI-Eyes提供了一种整体且透明的量子编码器优化方法，通过可视化分析帮助理解编码器如何影响QNN性能，为量子编码器选择提供了系统指导。

Abstract: Quantum Neural Networks (QNNs) represent a promising fusion of quantum computing and neural network architectures, offering speed-ups and efficient processing of high-dimensional, entangled data. A crucial component of QNNs is the encoder, which maps classical input data into quantum states. However, choosing suitable encoders remains a significant challenge, largely due to the lack of systematic guidance and the trial-and-error nature of current approaches. This process is further impeded by two key challenges: (1) the difficulty in evaluating encoded quantum states prior to training, and (2) the lack of intuitive methods for analyzing an encoder's ability to effectively distinguish data features. To address these issues, we introduce a novel visualization tool, XQAI-Eyes, which enables QNN developers to compare classical data features with their corresponding encoded quantum states and to examine the mixed quantum states across different classes. By bridging classical and quantum perspectives, XQAI-Eyes facilitates a deeper understanding of how encoders influence QNN performance. Evaluations across diverse datasets and encoder designs demonstrate XQAI-Eyes's potential to support the exploration of the relationship between encoder design and QNN effectiveness, offering a holistic and transparent approach to optimizing quantum encoders. Moreover, domain experts used XQAI-Eyes to derive two key practices for quantum encoder selection, grounded in the principles of pattern preservation and feature mapping.

</details>


### [30] [Discrete time crystals enabled by Floquet strong Hilbert space fragmentation](https://arxiv.org/abs/2512.14182)
*Ling-Zhi Tang,Xiao Li,Z. D. Wang,Dan-Wei Zhang*

Main category: quant-ph

TL;DR: 该论文研究了无无序、周期性驱动的XXZ自旋链中的离散时间晶体，发现其由Floquet强希尔伯特空间碎片化稳定，展现出倍周期响应和多重周期响应，寿命随系统尺寸指数增长。


<details>
  <summary>Details</summary>
Motivation: 探索无无序系统中离散时间晶体的稳定机制，研究Floquet希尔伯特空间碎片化如何作为维持非平衡量子多体系统中非平凡时间序的机制。

Method: 使用周期性驱动的XXZ自旋链模型，通过数值模拟分析Floquet谱，研究磁化和畴壁数的近似守恒，采用有限尺寸标度分析Floquet谱平均互信息。

Result: 发现了由Floquet强碎片化稳定的离散时间晶体，展现出倍周期响应和多重周期响应，寿命与驱动频率无关，与ZZ相互作用强度呈幂律关系，随系统尺寸指数增长。

Conclusion: Floquet希尔伯特空间碎片化可作为无无序机制维持非平衡量子多体系统中的非平凡时间序，为离散时间晶体的研究提供了新视角。

Abstract: Discrete time crystals (DTCs) are non-equilibrium phases of matter that break the discrete time-translation symmetry and is characterized by a robust subharmonic response in periodically driven quantum systems. Here, we explore the DTC in a disorder-free, periodically kicked XXZ spin chain, which is stabilized by the Floquet strong Hilbert space fragmentation. We numerically show the period-doubling response of the conventional DTC order, and uncover a multiple-period response with beating dynamics due to the coherent interplay of multiple $π$-pairs in the Floquet spectrum of small-size systems. The lifetime of the DTC order exhibits independence of the driving frequency and a power-law dependence on the ZZ interaction strength. It also grows exponentially with the system size, as a hallmark of the strong fragmentation inherent to the Floquet model. We analytically reveal the approximate conservation of the magnetization and domain-wall number in the Floquet operator for the emergent strong fragmentation, which is consistent with numerical results of the dimensionality ratio of symmetry subspaces. The rigidity and phase regime of the DTC order are identified through finite-size scaling of the Floquet-spectrum-averaged mutual information, as well as via dynamical probes. Our work establishes the Floquet Hilbert space fragmentation as a disorder-free mechanism for sustaining nontrivial temporal orders in out-of-equilibrium quantum many-body systems.

</details>


### [31] [Quantum Machine Learning for Climate Modelling](https://arxiv.org/abs/2512.14208)
*Mierk Schwabe,Lorenzo Pastori,Valentina Sarandrea,Veronika Eyring*

Main category: quant-ph

TL;DR: 量子神经网络在气候模型中预测云覆盖，性能与传统方案相当，学习关系更一致


<details>
  <summary>Details</summary>
Motivation: 量子机器学习有望提供量子优势，如更高的表达能力和泛化能力。地球系统模型需要改进以预测气候变化，可以通过结合传统物理组件和机器学习模型来实现。

Method: 使用量子神经网络开发地球系统模型中云覆盖的参数化方案，并与具有相同自由参数数量的经典神经网络进行比较。

Result: 量子神经网络预测云覆盖的性能与相同参数量的经典神经网络相当，且显著优于传统方案。分析显示量子神经网络学习的关系比经典神经网络更一致。

Conclusion: 量子神经网络在地球系统模型中具有应用潜力，至少在云覆盖预测任务中表现出比经典神经网络更一致的学习能力。

Abstract: Quantum machine learning (QML) is making rapid progress, and QML-based models hold the promise of quantum advantages such as potentially higher expressivity and generalizability than their classical counterparts. Here, we present work on using a quantum neural net (QNN) to develop a parameterization of cloud cover for an Earth system model (ESM). ESMs are needed for predicting and projecting climate change, and can be improved in hybrid models incorporating both traditional physics-based components as well as machine learning (ML) models. We show that a QNN can predict cloud cover with a performance similar to a classical NN with the same number of free parameters and significantly better than the traditional scheme. We also analyse the learning capability of the QNN in comparison to the classical NN and show that, at least for our example, QNNs learn more consistent relationships than classical NNs.

</details>


### [32] [Information-efficient decoding of surface codes](https://arxiv.org/abs/2512.14255)
*Long D. H. My,Shao-Hen Chiew,Jing Hao Chai,Hui Khoon Ng*

Main category: quant-ph

TL;DR: 提出了两种基于简化综合征信息的表面码解码器，将通信需求从面积缩放降低到宽度缩放


<details>
  <summary>Details</summary>
Motivation: 表面码中的实时解码需要量子处理单元与经典处理器之间的高速通信，这在保持量子处理器质量的同时难以实现

Method: 开发了两种解码器，仅使用与表面码补丁宽度（而非面积）成比例的综合征比特数量

Result: 显著降低了实时解码所需的通信要求，缓解了量子处理单元与经典处理器之间的通信瓶颈

Conclusion: 通过减少综合征信息量，提出的解码器解决了表面码中实时解码的通信难题，为实现容错量子计算提供了更可行的方案

Abstract: Surface codes are a popular error-correction route to fault-tolerant quantum computation. The so-called exponential backlog problem that can arise when one has to do logical $T$-gates within the surface code demands real-time decoding of the syndrome information to diagnose the appropriate Pauli frame in which to do the gate. This in turn puts a minimum requirement on the communication rate between the quantum processing unit, where the syndrome information is collected, and the classical processor, where the decoding algorithm is run. This minimum communication rate can be difficult to achieve while preserving the quality of the quantum processor. Here, we present two decoders that make use of a reduced syndrome information volume, relying on a number of syndrome bits that scale only as the width -- and not the usual area -- of the surface-code patch. This eases the communication requirements necessary for real-time decoding.

</details>


### [33] [Engineering Anisotropic Rabi Model in Circuit QED](https://arxiv.org/abs/2512.14276)
*S. Mojtaba Tabatabaei,Babak Zare Rameshti,Mohsen Akbari*

Main category: quant-ph

TL;DR: 该研究实现了各向异性拉比模型的电路QED实现，通过同时耦合量子比特到谐振器的电压和电流波腹，实现了从纯Jaynes-Cummings到纯anti-Jaynes-Cummings相互作用的几何调谐。


<details>
  <summary>Details</summary>
Motivation: 各向异性拉比模型具有可调的Jaynes-Cummings和anti-Jaynes-Cummings相互作用，但一直难以完全实现。需要建立一个能够完全控制模型参数并探索其完整参数空间的平台。

Method: 采用电路QED实现，通过同时耦合量子比特到谐振器的电压和电流波腹，实现对各向异性拉比模型参数的静态控制。这种几何调谐方法允许从纯JC到纯AJC相互作用的连续调节。

Result: 成功实现了对各向异性拉比模型参数的完全控制，展示了新型量子测量能力，包括色散位移消除和Purcell抑制读取。建立了探索模型完整参数空间的直接平台。

Conclusion: 该工作为探索各向异性拉比模型的完整参数空间及其在量子信息处理中的应用建立了直接平台，提供了新颖的量子测量能力。

Abstract: The anisotropic Rabi model (ARM), which features tunable Jaynes-Cummings (JC) and anti-Jaynes-Cummings (AJC) interactions, has remained challenging to realize fully. We present a circuit QED implementation that provides static control over the ARM parameters. By simultaneously coupling a qubit to a resonator's voltage and current antinodes, we geometrically tune the interaction from pure JC to pure AJC. This control enables novel quantum measurement capabilities, including dispersive shift cancellation and Purcell-suppressed readout. Our work establishes a direct platform for exploring the ARM's full parameter space and its applications in quantum information processing.

</details>


### [34] [General Quantum Instruction for Communication via Maximally Entangled $n$-Qubit States](https://arxiv.org/abs/2512.14280)
*Saba Arife Bozpolat*

Main category: quant-ph

TL;DR: 提出了一个广义的n比特超密编码协议，使用n量子比特纠缠系统和传输n-1个量子比特来传输n个经典比特信息，通过简单电路设计减少错误，并在真实量子硬件上测试。


<details>
  <summary>Details</summary>
Motivation: 开发一个可扩展的n比特超密编码协议，提供明确的量子电路构建方法，解决现有超密编码方案缺乏可扩展性和明确实现指导的问题。

Method: 创建最大纠缠的n量子比特态，使用Pauli-Z和Pauli-X门编码经典信息，通过量子通信、量子操作和测量进行传输和解码，提出了首个明确且可扩展的n比特编码电路构建方法。

Result: 在IBM-Torino量子计算机上测试4、6、8、10比特消息，结果显示成功率随消息长度、电路深度和门数量增加而下降，主要原因是更多"1"比特需要更多Pauli-X门操作。

Conclusion: 该工作提供了一个实用且易于扩展的量子通信方案，通过分段发送消息和提高量子比特相干性及门保真度可改善性能，在量子网络和通信系统中具有应用潜力。

Abstract: This study presents a generalized $n$-bit superdense coding protocol that enables the transmission of n classical bits of information using an entangled n--qubit quantum system and the transmission of $n-1$ qubits. The protocol involves creating a maximally entangled n--qubit state, encoding the classical message with Pauli--Z and Pauli--X gates, and then transmitting and decoding the message via quantum communication, quantum operations, and measurements. The key novelty of this work lies in the proposed n--bit encoding routine, which, to the best of our knowledge, is the first explicit and scalable recipe for constructing quantum circuits for n--bit Superdense Coding, minimizing errors through a simple circuit design. The protocol was tested on real quantum hardware using Qiskit 2.0 and the IBM--Torino quantum computer for message lengths of 4, 6, 8, and 10 bits. Results show that success rates decrease as message length, circuit depth, and gate count increase, largely due to increased Pauli--X gate usage for messages with more ``1" bits. Strategies to improve performance include sending messages in shorter segments and advances in qubit coherence and gate fidelity. This work offers a practical and easily scalable quantum communication instruction with potential applications in quantum networks and communication systems.

</details>


### [35] [Universal Structure of Nonlocal Operators for Deterministic Navigation and Geometric Locking](https://arxiv.org/abs/2512.14302)
*Jia Bao,Bin Guo,Shu Qu,Fanqin Xu,Zhaoyu Sun*

Main category: quant-ph

TL;DR: 提出几何框架将非局域算符优化从组合黑箱转为确定性预测-验证操作，发现主特征值由二维角变量参数化，揭示量子临界性中几何临界性与几何锁定的二分结构


<details>
  <summary>Details</summary>
Motivation: 传统寻找最优非局域算符的方法通常基于组合搜索，效率低下且缺乏理论指导。需要建立系统框架将这一过程转化为确定性操作，并深入理解量子临界性中的几何结构

Method: 建立通用几何框架，发现非局域性主特征值由低维流形参数化，仅需两个基本角变量θ和φ。通过对称性简化分析，建立外部控制参数与最优测量配置的精确映射

Result: 发现量子临界性存在基本二分结构：对称扇区旋转的转变表现为几何临界性（算符剧烈重定向），而强各向异性主导的转变表现为几何锁定（最优基保持稳健）。这提供了量子相变的结构分类和贝尔实验的精确导航图

Conclusion: 该几何框架将非局域算符优化从黑箱搜索转变为确定性操作，揭示的几何临界性与几何锁定二分结构为量子相变提供了新颖的结构分类，并为贝尔实验提供了精确指导

Abstract: We establish a universal geometric framework that transforms the search for optimal nonlocal operators from a combinatorial black box into a deterministic predict-verify operation. We discover that the principal eigenvalue governing nonlocality is rigorously dictated by a low-dimensional manifold parameterized by merely two fundamental angular variables, $θ$ and $φ$, whose symmetry leads to further simplification. This geometric distillation establishes a precise mapping connecting external control parameters directly to optimal measurement configurations. Crucially, a comparative analysis of the geometric angles against the principal eigenvalue spectrum, including its magnitude, susceptibility, and nonlocal gap, reveals a fundamental dichotomy in quantum criticality. While transitions involving symmetry sector rotation manifest as geometric criticality with drastic operator reorientation, transitions dominated by strong anisotropy exhibit geometric locking, where the optimal basis remains robust despite clear signatures of phase transitions in the spectral indicators. This distinction offers a novel structural classification of quantum phase transitions and provides a precision navigation chart for Bell experiments.

</details>


### [36] [Steering Alternative Realities through Local Quantum Memory Operations](https://arxiv.org/abs/2512.14377)
*Xiongfeng Ma*

Main category: quant-ph

TL;DR: 量子测量通过将叠加态与观察者记忆关联来产生确定结果。本文提出"现实转向"协议，允许观察者概率性访问量子态支持的另一个现实，无需逆转环境退相干，但面临内在约束且无法内部验证。


<details>
  <summary>Details</summary>
Motivation: 探索量子测量后观察者如何可能访问量子态支持的其他现实分支，将多现实探索从哲学思辨转向具体的量子信息框架。

Method: 提出"现实转向"协议，通过在观察者记忆中进行局部擦除操作（不涉及环境），消除存储的"哪个结果"信息，从而概率性地导航到不同现实分支。

Result: 现实转向面临内在约束：成功导航需要相关分支中观察者对应体的相干参与；任何转向在操作上无法与未转向区分；转向后所有记忆记录与新现实完美一致，无法内部确认转向发生。

Conclusion: 在标准量子力学框架内，有意识的转向确认不可能；非线性操作原则上可实现可验证的导航。研究将多现实探索从哲学思辨转向具体但受基本约束的量子信息框架。

Abstract: Quantum measurement resolves a superposition into a definite outcome by correlating it with an observer's memory -- a reality register. While the global quantum state remains coherent, the observer's local reality becomes singular and definite. This work introduces reality steering, a protocol that allows an observer to probabilistically access a different reality already supported by the initial quantum state, without reversing decoherence on the environment. The mechanism relies on locally erasing the 'which-outcome' information stored in the observer's brain. Here, 'local' means operations confined to the observer's memory, excluding the environment, which may be cosmically large. Reality steering nevertheless faces intrinsic constraints: successful navigation requires coherent participation from the observer's counterparts across the relevant branches, and any transition is operationally indistinguishable from non-transition. After arriving in a new reality, all memory records are perfectly consistent with that reality, leaving no internal evidence that a switch occurred. This makes conscious confirmation impossible within standard quantum mechanics. We show that nonlinear operations beyond the standard theory could, in principle, enable verifiable and deliberate navigation. Our results shift multi-reality exploration from philosophical speculation toward a concrete -- though fundamentally constrained -- quantum-informational framework.

</details>


### [37] [Geometric quantum thermodynamics: A fibre bundle approach](https://arxiv.org/abs/2512.14383)
*T. Pernambuco,L. C. Céleri*

Main category: quant-ph

TL;DR: 该论文探讨量子热力学的几何结构，通过构造主纤维丛来建立热力学与基础物理理论的统一数学框架。


<details>
  <summary>Details</summary>
Motivation: 经典热力学基于粗粒化，而量子力学中对微观系统的高度控制使信息理论在描述量子系统热性质中起重要作用。最近提出的量子热力学规范理论通过热力学群的规范变换引入了冗余信息概念，需要探索其几何结构。

Method: 通过显式构造相关的主纤维丛来探索量子热力学的几何结构，展示热力学规范理论中两种不同但相关的几何结构。

Result: 成功建立了量子热力学的几何框架，将热力学表达为与基础物理理论相同的数学（几何）语言，揭示了热力学规范理论中的两种几何结构。

Conclusion: 这些几何和拓扑结构的性质可能有助于解释热力学的基本性质，为理解量子热力学提供了新的几何视角。

Abstract: Classical thermodynamics is a theory based on coarse-graining, meaning that the thermodynamic variables arise from discarding information related to the microscopic features of the system at hand. In quantum mechanics, however, where one has a high degree of control over microscopic systems, information theory plays an important role in describing the thermal properties of quantum systems. Recently, a new approach has been proposed in the form of a quantum thermodynamic gauge theory, where the notion of redundant information arises from a group of physically motivated gauge transformations called the thermodynamic group. In this work, we explore the geometrical structure of quantum thermodynamics. Particularly, we do so by explicitly constructing the relevant principal fibre bundle. We then show that there are two distinct (albeit related) geometric structures associated with the gauge theory of quantum thermodynamics. In this way, we express thermodynamics in the same mathematical (geometric) language as the fundamental theories of physics. Finally, we discuss how the geometric and topological properties of these structures may help explain fundamental properties of thermodynamics.

</details>


### [38] [Capacity and SKR tradeoff in coexisting classical and CV-QKD metropolitan-reach optical links](https://arxiv.org/abs/2512.14408)
*Cagla Ozkan,Lucas Alves Zischler,Kadir Gumus,Joao dos Reis Frazao,Cristian Antonelli,Chigo Okonkwo*

Main category: quant-ph

TL;DR: 针对城域DWDM中量子-经典共存场景，提出功率机制相关的保护带优化方法，通过在频带边缘设置量子信道并采用100-150 GHz保护带，在-1.5 dBm/ch功率下实现108%的密钥率提升，容量损失仅3.4%（相比频带中心的6.8%）


<details>
  <summary>Details</summary>
Motivation: 在城域密集波分复用系统中实现量子密钥分发与经典通信的共存面临挑战，传统方法在频带中心放置量子信道会导致较大的容量损失，需要优化保护带配置以平衡量子密钥率和经典通信容量

Method: 采用功率机制相关的保护带优化策略，将量子信道放置在频带边缘而非中心，并配置100-150 GHz的保护带，通过实验验证不同功率机制下的性能表现

Result: 在-1.5 dBm/ch功率下，频带边缘配置实现了108%的密钥率提升，同时容量损失仅为3.4%，相比频带中心配置的6.8%容量损失有显著改善

Conclusion: 频带边缘放置量子信道配合优化的保护带配置是城域DWDM中实现量子-经典共存的有效策略，能在提升量子密钥率的同时最小化经典通信容量损失

Abstract: We demonstrate power-regime-dependent guardband optimization for quantum-classical coexistence in metropolitan DWDM. Quantum channel at band-edge with 100-150 GHz guardbands achieves 108% SKR improvement at -1.5 dBm/ch, incurring 3.4% capacity loss versus 6.8% for band-center.

</details>


### [39] [Ground State Energy via Adiabatic Evolution and Phase Measurement for a Molecular Hamiltonian on an Ion-Trap Quantum Computer](https://arxiv.org/abs/2512.14415)
*Ludwig Nützel,Michael J. Hartmann,Henrik Dreyer,Etienne Granet*

Main category: quant-ph

TL;DR: 该论文在离子阱量子计算机上运行了分子基态能量估计协议，发现泄漏误差是实现化学精度的主要障碍，而非相干或非相干噪声。


<details>
  <summary>Details</summary>
Motivation: 量子计算在分子基态能量估计中具有重要应用，但硬件噪声对实验结果的影响需要深入理解，以区分不同影响的误差类型并指导硬件和算法改进。

Method: 使用离子阱量子计算机，通过绝热态制备准备H3+分子的六量子比特编码基态，并采用抗噪声的迭代量子相位估计变体来提取能量，完全在量子硬件上执行，未将计算任务卸载到经典计算机。

Result: 实验结果超越了经典Hartree-Fock能量。噪声分析表明，相干和非相干噪声影响较小，而泄漏误差是主要障碍。模拟显示，若无泄漏误差，即使包含散粒噪声，也能接近化学精度。

Conclusion: 泄漏误差是实现化学精度的关键障碍，未来算法和硬件开发应重点针对泄漏抑制进行优化。

Abstract: Estimating molecular ground-state energies is a central application of quantum computing, requiring both the preparation of accurate quantum states and efficient energy readout. Understanding the effect of hardware noise on these experiments is crucial to distinguish errors that have low impact, errors that can be mitigated, and errors that must be reduced at the hardware level. We ran a state preparation and energy measurement protocol on an ion-trap quantum computer, without any non-scalable off-loading of computational tasks to classical computers, and show that leakage errors are the main obstacle to chemical accuracy. More specifically, we apply adiabatic state preparation to prepare the ground state of a six-qubit encoding of the H3+ molecule and extract its energy using a noise-resilient variant of iterative quantum phase estimation. Our results improve upon the classical Hartree-Fock energy. Analyzing the effect of hardware noise on the result, we find that while coherent and incoherent noise have little influence, the hardware results are mainly impacted by leakage errors. Absent leakage errors, noisy numerical simulations show that with our experimental settings we would have achieved close to chemical accuracy, even shot noise included. These insights highlight the importance of targeting leakage suppression in future algorithm and hardware development.

</details>


### [40] [Adiabatic-Inspired Hybrid Quantum-Classical Methods for Molecular Ground State Preparation](https://arxiv.org/abs/2512.14449)
*Sean Thrasher,Ioannis Kolotouros,Julien Michel,Petros Wallden*

Main category: quant-ph

TL;DR: 论文提出并比较了多种绝热启发的量子算法，包括新提出的G-AQC-PQC方法，用于解决量子化学中的基态问题，并在BeH₂分子上展示了优于传统VQE的性能。


<details>
  <summary>Details</summary>
Motivation: 传统VQE算法存在收敛困难（非凸能量景观和贫瘠高原问题），而AQC需要深电路超出当前量子设备能力。需要开发介于两者之间的绝热启发算法来填补这一空白。

Method: 1) 建立统一框架并基准测试AAVQE、VAQC和AQC-PQC算法；2) 提出新的G-AQC-PQC方法，结合绝热启发初始化和低内存BFGS优化器；3) 在BeH₂分子上比较各种方法，考虑不同参数化电路、深度、离散化步骤、初始哈密顿量、绝热调度等选择。

Result: G-AQC-PQC方法在量子化学应用中优于传统VQE。研究还讨论了零梯度问题等限制，并确定了绝热启发方法在近期量子化学应用中具有实际优势的机制。

Conclusion: 绝热启发的量子算法，特别是新提出的G-AQC-PQC方法，为解决量子化学基态问题提供了有前景的途径，在近期量子设备上具有实际应用潜力。

Abstract: Quantum computing promises to efficiently and accurately solve many important problems in quantum chemistry which elude classical solvers, such as the electronic structure problem of highly correlated materials. Two leading methods in solving the ground state problem are the Variational Quantum Eigensolver (VQE) and Adiabatic Quantum Computing (AQC) algorithms. VQE often struggles with convergence due to the energy landscape being highly non-convex and the existence of barren plateaux, and implementing AQC is beyond the capabilities of current quantum devices as it requires deep circuits. Adiabatically-inspired algorithms aim to fill this gap. In this paper, we first present a unifying framework for these algorithms and then benchmark the following methods: the Adiabatically Assisted VQE (AAVQE) (Garcia-Saez and Latorre (2018)), the Variational Adiabatic Quantum Computing (VAQC) (Harwood et al (2022)), and the Adiabatic Quantum Computing with Parametrized Quantum Circuits (AQC-PQC) (Kolotouros et al (2025)) algorithms. Second, we introduce a novel hybrid approach termed G-AQC-PQC, which generalizes the AQC-PQC method, and combines adiabatic-inspired initialization with the low-memory BFGS optimizer, reducing the quantum computational cost of the method. Third, we compare the accuracy of the methods for chemistry applications using the beryllium hydride molecule (BeH$_2$). We compare the approaches across a number of different choices (ansätze types, depth, discretization steps, initial Hamiltonian, adiabatic schedules and method used). Our results show that the G-AQC-PQC outperforms conventional VQE. We further discuss limitations such as the zero-gradient problem and identify regimes where adiabatically-inspired methods offer a tangible advantage for near-term quantum chemistry applications.

</details>


### [41] [Super-Heisenberg-limited Sensing via Collective Subradiance in Waveguide QED](https://arxiv.org/abs/2512.14463)
*Xin Wang,Zeyang Liao*

Main category: quant-ph

TL;DR: 该论文研究亚波长间距发射体阵列与一维纳米光子波导耦合系统的量子计量潜力，发现偶极-偶极相互作用导致超窄亚辐射共振，其衰减率呈现N^{-3}标度律，量子Fisher信息可达N^6标度，为集成纳米光子平台上的可扩展量子传感器开辟新途径。


<details>
  <summary>Details</summary>
Motivation: 探索亚波长间距发射体阵列与一维纳米光子波导耦合系统的量子计量潜力，将多体波导量子电动力学与高精度传感相结合，为集成纳米光子平台上的可扩展量子传感器开发新路径。

Method: 通过有效非厄米哈密顿量的本征模分析，推导最亚辐射态衰减率的普适标度律；分析单光子散射谱以检测原子间距的微小变化；计算量子Fisher信息并研究其在最亚辐射共振最陡斜率附近谱移测量中的可实现性。

Result: 在深亚波长区域，最亚辐射态的衰减率呈现N^{-3}标度律并具有奇偶振荡行为；品质因数标度为N^3；量子Fisher信息标度可达N^6；这些增强效应在实际位置无序下保持鲁棒性。

Conclusion: 偶极-偶极工程化的亚辐射为量子计量学提供了可行资源，该工作桥接了多体波导量子电动力学与高精度传感，为集成纳米光子平台上的可扩展量子传感器开辟了道路。

Abstract: We explore the quantum-metrological potential of subwavelength-spaced emitter arrays coupled to a one-dimensional nanophotonic waveguide. In this system, strong dipole--dipole interactions profoundly modify the collective optical response, leading to the emergence of ultranarrow subradiant resonances. Through an eigenmode analysis of the effective non-Hermitian Hamiltonian, we derive a universal scaling law for the decay rate of the most subradiant state, which exhibits an $ N^{-3} $ scaling with even-odd oscillatory behavior in the deep-subwavelength regime. This scaling is directly observable in the single-photon scattering spectrum, enabling the detection of minute changes in atomic separation with a figure of merit that scales as $ N^3 $. The quantum Fisher information (QFI) scales as $N^6$ and can be closely approached by measuring spectral shifts near the steepest slope of the most subradiant resonance. These enhancements remain robust under realistic positional disorder, confirming that dipole--dipole-engineered subradiance provides a viable resource for quantum metrology. Our work bridges many-body waveguide quantum electrodynamics and high-precision sensing, opening a route toward scalable quantum sensors on integrated nanophotonic platforms.

</details>


### [42] [Nonlocal contributions to ergotropy: A thermodynamic perspective](https://arxiv.org/abs/2512.14497)
*B. Vigneshwar,R. Sankaranarayanan*

Main category: quant-ph

TL;DR: 提出了一种量化非局域性对可提取功贡献的方法，建立了非局域资源与可提取功之间的直接关系


<details>
  <summary>Details</summary>
Motivation: 非局域性是量子力学的核心特征，但非局域性对可提取功的具体贡献一直不清楚，这是量子热力学中的关键问题

Method: 引入了一个量化二分系统中非局域性对可提取功贡献的量，并给出了用施密特系数计算的闭式表达式。对于严格非相互作用哈密顿量，建立了ergotropy与关联之间的直接关系

Result: 在非相互作用哈密顿量下，非局域资源总是增强可提取功；而在存在相互作用时，非局域性的贡献可能增加或减少，取决于量子态和哈密顿量的结构

Conclusion: 该研究揭示了非局域性在量子热力学中的复杂作用，为非局域资源在能量提取中的应用提供了理论框架

Abstract: Nonlocality is a defining feature of quantum mechanics and has long served as a key indicator of quantum resources since the formulation of Bell's inequalities. Identifying the contribution of nonlocality to extractable work remains a central problem in quantum thermodynamics. We address this by introducing a quantifier of nonlocal contributions to extractable work in bipartite systems. It is shown that closed form expressions can be calculated for our quantity in terms of the Schmidt coefficients. Further for strictly non-interacting Hamiltonian, the direct relationship between ergotropy and correlations is established. Our results reveal that nonlocal resources invariably enhance extractable work under non-interacting Hamiltonians, while in the presence of interactions, their contribution can either increase or diminish depending on the structure of the state and the Hamiltonian.

</details>


### [43] [Large circuit execution for NMR spectroscopy simulation on NISQ quantum hardware](https://arxiv.org/abs/2512.14513)
*Artemiy Burov,Julien Baglio,Clément Javerzac-Galy*

Main category: quant-ph

TL;DR: 使用量子计算模拟一维核磁共振谱，通过误差抑制技术处理34自旋系统，超越经典模拟极限


<details>
  <summary>Details</summary>
Motivation: 量子计算正从NISQ时代迈向量子实用时代，核磁共振谱模拟是经典方法难以处理的难题，对分子结构研究和新材料药物设计至关重要

Method: 结合Q-CTRL的误差抑制技术、IBM超导量子计算机和IonQ离子阱量子计算机，开发量子哈密顿模拟管道，处理高达34自旋系统

Result: 误差抑制使均方误差降低22倍，成功执行深度量子电路，获得16、22和34自旋系统的核磁共振谱特征，突破32自旋的Liouville极限

Conclusion: 该工作推动了核磁共振光谱学向近期量子实用化迈进，展示了量子计算在复杂化学系统模拟中的潜力

Abstract: With the latest advances in quantum computing technology, we are gradually moving from the noisy intermediate-scale quantum (NISQ) era characterized by hardware limited in the number of qubits and plagued with quantum noise, to the age of quantum utility where both the newest hardware and software methods allow for tackling problems which have been deemed difficult or intractable with conventional classical methods. One of these difficult problems is the simulation of one-dimensional (1D) nuclear magnetic resonance (NMR) spectra, a major tool to learn about the structure of molecules, helping the design of new materials or drugs. Using advanced error mitigation and error suppression techniques from Q-CTRL together with the latest commercially available superconducting-qubit quantum computer from IBM and trapped-ion quantum computer from IonQ, we present the quantum Hamiltonian simulation of liquid-state 1D NMR spectra in the high-field regime for spin systems up to 34 spins. Our pipeline has a major impact on the ability to execute deep quantum circuits with the reduction of quantum noise, improving mean square error by a factor of 22. It allows for the execution of deep quantum circuits and obtaining salient features of the 1D NMR spectra for both 16-spin and 22-spin systems, as well as a 34-spin system, which lies beyond the regime where unrestricted full Liouvillespace simulations are practical (32 spins, the Liouville limit). Our work is a step toward near-term quantum utility in NMR spectroscopy.

</details>


### [44] [Finite-Time Protocols Stabilize Charging in Noisy Ising Quantum Batteries](https://arxiv.org/abs/2512.14521)
*Riccardo Grazi,Henrik Johannesson,Dario Ferraro,Niccolò Traverso Ziani*

Main category: quant-ph

TL;DR: 研究横向场伊辛链量子电池，发现有限充电时间和量子比特相互作用能产生更平滑可控的充电过程，噪声对充电性能的影响取决于具体协议类型。


<details>
  <summary>Details</summary>
Motivation: 可靠的充电协议对量子电池的实际应用至关重要。研究量子比特相互作用与有限充电时间的结合效应，探索噪声对量子电池性能的影响。

Method: 使用横向场伊辛链作为量子电池模型，分析量子比特相互作用与有限充电时间的相互作用，引入随机噪声研究不同充电轨迹下的性能变化。

Result: 相互作用和有限充电时间产生比突然充电协议或非相互作用电池更平滑可控的充电过程。噪声影响取决于协议类型：弱激发协议在噪声下获得能量但损失可提取功；强激发多模式协议则相反，噪声减少存储能量但提高效率。

Conclusion: 有限时间斜坡充电能稳定充电过程，噪声对量子电池性能的影响具有双重性：既可阻碍也可增强性能，具体取决于所采用的充电协议。

Abstract: Reliable charging protocols are crucial for advancing quantum batteries toward practical use. We investigate a transverse-field Ising chain as a quantum battery, focusing on the combined role of qubit interactions in the battery model and finite charging time. This interplay yields smoother and more controllable charging compared to sudden protocols or non-interacting batteries. Introducing stochastic noise reveals a strong dependence on the charging trajectory. Protocols that weakly excite the system gain energy under noise but lose extractable work. In contrast, protocols that strongly excite many modes show the opposite trend: noise reduces stored energy yet improves efficiency, defined as the ratio of ergotropy to stored energy. These findings demonstrate that finite-time ramps stabilize charging and highlight that noise can either hinder or enhance quantum-battery performance depending on the protocol.

</details>


### [45] [Continuous Accumulation of Cold Atoms in an Optical Cavity](https://arxiv.org/abs/2512.14528)
*Edward Gheorghita,Sebastian Wald,Andrea Pupić,Onur Hosten*

Main category: quant-ph

TL;DR: 该论文展示了一种在浅层腔内偶极阱中连续积累亚多普勒冷却原子的方法，实现了稳态量子传感器和量子处理器所需的关键原子-光接口。


<details>
  <summary>Details</summary>
Motivation: 连续运行的原子-光接口是稳态量子传感器和高效量子处理器的关键前提。目前需要实现能够在连续模式下工作的系统，而不是时间序列操作。

Method: 通过光移操纵创建空间变化的冷却参数，使原子能够高效捕获并积累在腔模内。使用铷原子，从源池连续通量通过磁光阱进入腔模，在腔内冷却并维持在10μK以下，无需时间序列操作。

Result: 成功实现了数百万原子的连续维持集合体，这些原子与腔场具有集体耦合。系统在稳态下运行，原子温度保持在10μK以下，建立了连续运行腔QED系统的途径。

Conclusion: 该方法为连续运行的腔QED系统和长持续时间原子及混合量子传感器开辟了道路，实现了关键的稳态原子-光接口技术。

Abstract: Continuously operating atom-light interfaces represent a key prerequisite for steady-state quantum sensors and efficient quantum processors. Here, we demonstrate continuous accumulation of sub-Doppler-cooled atoms in a shallow intracavity dipole trap, realizing this regime. The key ingredient is a light-shift manipulation that creates spatially varying cooling parameters, enabling efficient capture and accumulation of atoms within a cavity mode. Demonstrated with rubidium atoms, a continuous flux from a source cell is funneled through the magneto-optical trap into the cavity mode, where the atoms are cooled and maintained below $10~μ\text{K}$ in steady state without time-sequenced operation. We characterize the resulting continuously maintained ensemble of millions of atoms and its collective coupling to the cavity field, establishing a route toward continuously operated cavity-QED systems and long-duration atomic and hybrid quantum sensors.

</details>


### [46] [A Graph-Based Forensic Framework for Inferring Hardware Noise of Cloud Quantum Backend](https://arxiv.org/abs/2512.14541)
*Subrata Das,Archisman Ghosh,Swaroop Ghosh*

Main category: quant-ph

TL;DR: 提出基于图神经网络的量子计算后端错误率预测框架，仅使用拓扑信息和电路特征即可重建完整错误映射，无需目标后端校准数据


<details>
  <summary>Details</summary>
Motivation: 量子云平台存在透明度问题：用户无法验证电路是否在收费的硬件上执行，提供商可能将作业重定向到错误率更高的区域，而校准数据可能过时或平均化，导致安全漏洞

Method: 使用图神经网络回归器，结合拓扑信息和从转译电路中提取的聚合特征，分别训练单量子比特和双量子比特链路错误率预测模型，构建数据集并合并静态校准特征与动态转译特征

Result: 模型能准确恢复后端错误率，单量子比特错误平均不匹配约22%，量子比特链路错误约18%，具有强排序一致性（高Spearman相关性），能稳定识别弱链路和高噪声量子比特，对时间噪声漂移具有鲁棒性

Conclusion: 该GNN框架为量子计算提供了有效的法证分析工具，使用户能够验证后端行为并重建错误映射，填补了量子云平台的安全透明度缺口

Abstract: Cloud quantum platforms give users access to many backends with different qubit technologies, coupling layouts, and noise levels. The execution of a circuit, however, depends on internal allocation and routing policies that are not observable to the user. A provider may redirect jobs to more error-prone regions to conserve resources, balance load or for other opaque reasons, causing degradation in fidelity while still presenting stale or averaged calibration data. This lack of transparency creates a security gap: users cannot verify whether their circuits were executed on the hardware for which they were charged. Forensic methods that infer backend behavior from user-visible artifacts are therefore becoming essential. In this work, we introduce a Graph Neural Network (GNN)-based forensic framework that predicts per-qubit and per-qubit link error rates of an unseen backend using only topology information and aggregated features extracted from transpiled circuits. We construct a dataset from several IBM 27-qubit devices, merge static calibration features with dynamic transpilation features and train separate GNN regressors for one- and two-qubit errors. At inference time, the model operates without access to calibration data from the target backend and reconstructs a complete error map from the features available to the user. Our results on the target backend show accurate recovery of backend error rate, with an average mismatch of approximately 22% for single-qubit errors and 18% for qubit-link errors. The model also exhibits strong ranking agreement, with the ordering induced by predicted error values closely matching that of the actual calibration errors, as reflected by high Spearman correlation. The framework consistently identifies weak links and high-noise qubits and remains robust under realistic temporal noise drift.

</details>


### [47] [Physics-Informed Neural Networks with Adaptive Constraints for Multi-Qubit Quantum Tomography](https://arxiv.org/abs/2512.14543)
*Changchun Feng,Laifa Tao,Lin Chen*

Main category: quant-ph

TL;DR: 提出了一种物理信息神经网络(PINN)框架用于量子态层析，通过整合量子力学约束显著减少测量需求，从O(4^n)降至O(2^n)，并在2-5量子比特系统中表现出优越的保真度、噪声鲁棒性和维度鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统量子态层析(QST)在多量子比特系统中面临指数级测量需求和噪声敏感性问题，这限制了实用量子技术的发展。需要一种能够减少测量需求、提高噪声鲁棒性的新方法。

Method: 提出物理信息神经网络(PINN)框架，通过自适应加权整合量子力学约束，采用残差和注意力增强架构，以及可微分的Cholesky参数化确保物理有效性。

Result: 在2-5量子比特系统和任意维度状态评估中，PINN始终优于传统神经网络(TNNs)，在所有维度上实现最高保真度，表现出优越的噪声鲁棒性(性能下降更慢)和一致的维度鲁棒性。

Conclusion: 物理约束降低了Rademacher复杂度并通过约束诱导的维度减少缓解了维度诅咒，理论框架证明PINN的优势将在更大系统(6+量子比特)中持续增强，为量子纠错和门校准提供了实用解决方案。

Abstract: Quantum state tomography (QST) faces exponential measurement requirements and noise sensitivity in multi-qubit systems, bottlenecking practical quantum technologies. We present a physics-informed neural network (PINN) framework integrating quantum mechanical constraints via adaptive weighting, a residual-and-attention-enhanced architecture, and differentiable Cholesky parameterization for physical validity. Evaluations on 2--5 qubit systems and arbitrary-dimensional states show PINN consistently outperforms traditional neural networks (TNNs), achieving highest fidelity across all dimensions. PINN outperforms baselines, with marked improvements in moderately high-dimensional systems, superior noise robustness (slower performance degradation), and consistent dimensional robustness. Theoretical analysis shows physical constraints reduce Rademacher complexity and mitigate the curse of dimensionality via constraint-induced dimension and sample complexity reduction, effective regardless of qubit number. While experiments are limited to 5-qubit systems due to computational constraints, our theoretical framework (convergence guarantees, generalization bounds, scalability theorems) justifies PINN's advantages will persist and strengthen in larger systems (6+ qubits), where constraint-induced dimension reduction benefits grow with system size. Practically, this advances quantum error correction and gate calibration by reducing measurement requirements from O(4^n) to O(2^n) while maintaining high fidelity, enabling faster error correction cycles and accelerated calibration critical for scalable quantum computing.

</details>


### [48] [Fair sampling of ground-state configurations using hybrid quantum-classical MCMC algorithms](https://arxiv.org/abs/2512.14552)
*Yuichiro Nakano,Keisuke Fujii*

Main category: quant-ph

TL;DR: 混合量子-经典MCMC算法通过量子动力学作为提议转移，经典接受步骤保证细致平衡，能够纠正量子优化算法的采样偏差，在组合优化问题的简并基态上实现公平采样。


<details>
  <summary>Details</summary>
Motivation: 量子优化启发式算法（如量子退火和QAOA）已知会产生采样偏差，而组合优化问题通常具有简并基态，需要公平采样方法。研究混合量子-经典MCMC算法能否纠正量子动力学的采样偏差，实现公平采样。

Method: 提出混合量子-经典MCMC算法，将量子动力学仅作为提议转移，通过经典接受步骤强制细致平衡。在小伊辛模型上验证，然后应用于随机k-SAT问题（特别是2-SAT和3-SAT），结合QAOA辅助的神经提议和单自旋翻转更新。

Result: MCMC后处理纠正了量子动力学的采样偏差，在简并基态上恢复近均匀采样。对于随机2-SAT，混合MCMC的公平性与PT-ICM相当；对于随机3-SAT（经典方法不再适用），仍能实现近似均匀采样。解计数所需的转移次数与WalkSAT相当。

Conclusion: 混合量子-经典MCMC为公平采样和解枚举提供了一个可行的框架，能够纠正量子优化算法的采样偏差，在组合优化问题中实现有效的公平采样。

Abstract: We study the fair sampling properties of hybrid quantum-classical Markov chain Monte Carlo (MCMC) algorithms for combinatorial optimization problems with degenerate ground states. While quantum optimization heuristics such as quantum annealing and the quantum approximate optimization algorithm (QAOA) are known to induce biased sampling, hybrid quantum-classical MCMC incorporates quantum dynamics only as a proposal transition and enforces detailed balance through classical acceptance steps. Using small Ising models, we show that MCMC post-processing corrects the sampling bias of quantum dynamics and restores near-uniform sampling over degenerate ground states. We then apply the method to random $k$-SAT problems near the satisfiability threshold. For random 2-SAT, a hybrid MCMC combining QAOA-assisted neural proposals with single spin-flip updates achieves fairness comparable to that of PT-ICM. For random 3-SAT, where such classical methods are no longer applicable, the hybrid MCMC still attains approximately uniform sampling. We also examine solution counting and find that the required number of transitions is comparable to that of WalkSAT. These results indicate that hybrid quantum-classical MCMC provides a viable framework for fair sampling and solution enumeration.

</details>


### [49] [Entanglement measure for the W-class states](https://arxiv.org/abs/2512.14566)
*Reza Hamzehofi*

Main category: quant-ph

TL;DR: 该论文研究了W类态在物理变换下的纠缠结构和量化，建立了全局可分性与两体纠缠行为的联系，提出了新的纠缠度量条件，并改进了π-tangle度量以适用于大n极限下的最大纠缠W态。


<details>
  <summary>Details</summary>
Motivation: 研究W类态在物理变换下的纠缠结构和量化问题，特别是现有纠缠度量（如π-tangle）在大系统尺寸下对最大纠缠W态失效的问题，需要发展更有效的纠缠量化方法。

Method: 通过建立全局可分性与两体纠缠行为的严格条件，将两体纠缠之和作为W类态的自然纠缠度量；针对π-tangle在大n极限下失效的问题，提出了π-tangle之和的新度量；引入新的纠缠度量条件来构建物理意义明确的纠缠度量。

Result: 建立了全局可分性与两体纠缠缺失的充分条件；证明了两体纠缠之和是W类态的有效纠缠度量；发现π-tangle对大n极限下的最大纠缠W态失效；提出的π-tangle之和能够成功量化大n极限下的最大纠缠W态纠缠。

Conclusion: 该研究为W类态的纠缠量化提供了新的理论框架，通过两体纠缠之和与π-tangle之和两种方法有效解决了大系统尺寸下的纠缠量化问题，并建立了更严格的纠缠度量条件，对量子信息处理具有重要意义。

Abstract: The structure and quantification of entanglement in the W-class states are investigated under physically motivated transformations that induce mixed-state dynamics. A rigorous condition is established linking global separability to the behavior of pairwise entanglement, showing that the absence of pairwise entanglement is sufficient to guarantee complete separability of the system, provided the Hilbert-space basis is preserved. This result motivates the identification of the sum of two-tangles as a natural and effective entanglement quantifier for the W-class states. Furthermore, the commonly used $π$-tangle becomes ineffective for the maximally entangled $n$-qubit W state as the system size increases, vanishing in the large-$n$ limit. To address this limitation, the sum of $π$-tangles is introduced, which, like the sum of two-tangles, successfully quantifies the entanglement of the maximally entangled $n$-qubit W state in the large-$n$ limit. In addition, a new condition for entanglement measures is introduced, which facilitates the formulation of a well-behaved and physically meaningful entanglement measure.

</details>


### [50] [Exploiting Reset Operations in Cloud-based Quantum Computers to Run Quantum Circuits for Free](https://arxiv.org/abs/2512.14582)
*Jakub Szefer*

Main category: quant-ph

TL;DR: 量子计算云服务中，用户可利用重置操作将多个量子电路打包在单个shot中执行，从而规避按shot计费，造成服务商经济损失。


<details>
  <summary>Details</summary>
Motivation: 当前量子计算云服务普遍采用按shot计费模式，但用户可能滥用量子比特测量和重置操作，将多个电路打包执行，导致服务商收入损失。

Method: 通过在实际云量子计算机上评估，展示如何利用重置操作将多个用户电路分隔并打包成一个更大的电路，在单个shot中执行多个电路。

Result: 该方法可将某些电路的每shot运行成本降低高达900%，对量子计算公司造成重大财务损失。

Conclusion: 需要制定新的计费策略来应对这种攻击，同时保持量子比特测量和重置操作的灵活性和可用性。

Abstract: This work presents the first thorough exploration of how reset operations in cloud-based quantum computers could be exploited to run quantum circuits for free. This forms a new type of attack on the economics of cloud-based quantum computers. All major quantum computing companies today offer access to their hardware through some type of cloud-based service. Due to the noisy nature of quantum computers, a quantum circuit is run many times to collect the output statistics, and each run is called a shot. The fees users pay for access to the machines typically depend on the number of these shots of a quantum circuit that are executed. Per-shot pricing is a clean and straightforward approach as users are charged a small fee for each shot of their circuit. This work demonstrates that per-shot pricing can be exploited to get circuits to run for free when users abuse recently implemented mid-circuit qubit measurement and reset operations. Through evaluation on real, cloud-based quantum computers this work shows how multiple circuits can be executed together within a shot, by separating each user circuit by set of reset operations and submitting all the circuits, and reset operations, as one larger circuit. As a result, the user is charged per-shot pricing, even though inside each shot are multiple circuits. Total per-shot cost to run certain circuits could be reduced by up to $900$\% using methods proposed in this work, leading to significant financial losses to quantum computing companies. To address this novel finding, this work proposes a clear approach for how users should be charged for their execution, while maintaining the flexibility and usability of the mid-circuit measurement and reset~operations.

</details>


### [51] [Reading Qubits with Sequential Weak Measurements: Limits of Information Extraction](https://arxiv.org/abs/2512.14583)
*Cesar Lema,Aleix Bou-Comas,Atithi Acharya,Vadim Oganesyan,Anirvan Sengupta*

Main category: quant-ph

TL;DR: 研究弱测量下量子比特初始态读取的信息物理，分析两种模型的信息提取极限和最优测量时长


<details>
  <summary>Details</summary>
Motivation: 量子信息处理需要高精度量子比特状态读取，但测量方案和内在动力学可能使初始态信息丢失，需要研究弱测量下信息提取的极限性能

Method: 使用互信息量化初始态信息在测量记录中的编码，分析两种模型：信息完备无内在动力学模型，和信息不完备弱测量有内在动力学模型。采用固定离散时间步长计算互信息，并利用连续极限和随机主方程的渐近展开

Result: 发现了互信息平台现象，确定了信息提取的界限，获得了达到这些界限所需的最优测量时长。渐近展开能捕捉数值数据的定性和定量特征

Conclusion: 该研究结果对量子设备操作优化和当前NISQ实验中机器学习方法改进量子比特配置读取性能有实用价值

Abstract: Quantum information processing and computation requires high accuracy qubit configuration readout. In many practical schemes, the initial qubit configuration has to be inferred from readout that is a time-dependent weak measurement record. However, a combination of the measurement scheme and intrinsic dynamics can end up scrambling the initial state and lose information irretrievably. Here, we study the information physics of quantum trajectories based on weak measurements in order to address the optimal achievable performance in qubit configuration readout for two realistic models of single qubit readout: (i) Model I is informationally complete, but without intrinsic dynamics; (ii) Model II is informationally incomplete weak measurements with intrinsic dynamics. We first use mutual information to characterize how much intrinsic information about the initial state is encoded in the measurement record. Using a fixed discrete time-step formulation, we compute the mutual information while varying the measurement strength, duration of measurement record, and the relative strength of intrinsic dynamics in our measurement schemes. We also exploit the emergence of continuum scaling and the Stochastic Master Equation in the weak measurement limit. We develop an asymptotic expansion in the measurement efficiency parameter to calculate mutual information, which captures qualitative and quantitative features of the numerical data. The bounds on information extraction are manifested as plateaux in mutual information, our analysis obtains these bounds and also optimal duration of measurement required to saturate them. Our results should be useful both for quantum device operation and optimization and also, possibly, for improving the performance of recent machine learning approaches for qubit and multiqubit configuration readout in current Noisy Intermediate-Scale Quantum (NISQ) experiment regimes.

</details>


### [52] [Sequential realization of Quantum Instruments](https://arxiv.org/abs/2512.14588)
*Soham Sau,Michal Sedlák*

Main category: quant-ph

TL;DR: 该论文研究自适应量子电路中通过中电路测量实现量子仪器的分解与实现，提出了自适应仪器序列（ASI）框架，并分析了实现量子仪器所需步数N和辅助量子比特数n_A之间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 研究自适应量子电路中如何通过经典测量结果控制后续门操作，从而用更少的量子比特实现量子仪器（POVM、量子通道等）的序列实现，探索实现效率的优化。

Method: 提出自适应仪器序列（ASI）的数学框架，分析量子仪器在ASI中的分解方法，研究实现所需步数N和辅助量子比特数n_A之间的权衡关系，推导出N·n_A的下界。

Result: 发现对于将n个量子比特转换为m(>n)个量子比特的量子仪器，存在N步ASI实现，仅需(m-n)个辅助量子比特，这些辅助比特被重复测量(N-1)次后最终作为输出比特使用。

Conclusion: 自适应量子电路中的ASI框架为量子仪器的实现提供了高效方法，揭示了步数与辅助量子比特数之间的优化权衡，并展示了与传统直觉相悖的高效实现方案。

Abstract: In adaptive quantum circuits classical results of mid-circuit measurements determine the upcoming gates. This allows POVMs, quantum channels or more generally quantum instruments to be implemented sequentially, so that fewer qubits need to be used at each of the $N$ measurement steps. In this paper, we mathematically describe these problems via adaptive sequence of instruments (ASI) and show how any instrument can be decomposed into it. Number of steps $N$ and number of ancillary qubits $n_A$ needed for actual implementation are crucial parameters of any such ASI. We show an achievable lower bound on the product $N.n_A$ and we determine in which situations this tradeoff is likely to be optimal. Contrary to common intuition we show that for quantum instruments which transform $n$ to $m(>n)$ qubits, there exist $N$-step ASI implementing them just with $(m-n)$ ancillary qubits, which are remeasured $(N-1)$ times and finally used as output qubits.

</details>


### [53] [Improved Lower Bounds for QAC0](https://arxiv.org/abs/2512.14643)
*Malvika Raj Joshi,Avishay Tal,Francisca Vasconcelos,John Wright*

Main category: quant-ph

TL;DR: 该论文建立了针对QAC⁰电路的最强下界，证明了深度3 QAC⁰无法计算奇偶校验，深度2电路无法近似高影响布尔函数，且深度2 QAC⁰无法精确合成nekomata态。


<details>
  <summary>Details</summary>
Motivation: 研究量子电路相对于经典电路的计算优势，特别是探讨常数深度量子电路QAC⁰是否比经典AC⁰电路更强大，尤其是在计算奇偶校验等基本布尔函数方面。

Method: 提出新技术将某些QAC⁰电路在经典AC⁰中模拟，从而获得深度3下界；放松量子电路输出要求为单比特（无输入保持/可逆计算限制）；分析深度2电路近似能力和精确合成能力。

Result: 1) 深度3 QAC⁰无法计算奇偶校验，计算多数函数需要Ω(exp(√n))门数；2) 深度2电路无法以非可忽略优势近似高影响布尔函数；3) 深度2 QAC⁰无法精确合成n-target nekomata态。

Conclusion: 对于本质经典的决策问题，常数深度量子电路不一定比经典对应物更强大，深度2经典AC⁰可用指数规模精确计算奇偶校验，而深度2 QAC⁰甚至无法近似。

Abstract: In this work, we establish the strongest known lower bounds against QAC$^0$, while allowing its full power of polynomially many ancillae and gates. Our two main results show that:
  (1) Depth 3 QAC$^0$ circuits cannot compute PARITY regardless of size, and require at least $Ω(\exp(\sqrt{n}))$ many gates to compute MAJORITY.
  (2) Depth 2 circuits cannot approximate high-influence Boolean functions (e.g., PARITY) with non-negligible advantage in depth $2$, regardless of size.
  We present new techniques for simulating certain QAC$^0$ circuits classically in AC$^0$ to obtain our depth $3$ lower bounds. In these results, we relax the output requirement of the quantum circuit to a single bit (i.e., no restrictions on input preservation/reversible computation), making our depth $2$ approximation bound stronger than the previous best bound of Rosenthal (2021). This also enables us to draw natural comparisons with classical AC$^0$ circuits, which can compute PARITY exactly in depth $2$ using exponential size. Our proof techniques further suggest that, for inherently classical decision problems, constant-depth quantum circuits do not necessarily provide more power than their classical counterparts. Our third result shows that depth $2$ QAC$^0$ circuits, regardless of size, cannot exactly synthesize an $n$-target nekomata state (a state whose synthesis is directly related to the computation of PARITY). This complements the depth $2$ exponential size upper bound of Rosenthal (2021) for approximating nekomatas (which is used as a sub-circuit in the only known constant depth PARITY upper bound).

</details>


### [54] [Testing electron-photon exchange-correlation functional performance for many-electron systems under weak and strong light-matter coupling](https://arxiv.org/abs/2512.14655)
*Iman Ahmadabadi,I-Te Lu,Leonardo A. Cunha,Michael Ruggenthaler,Johannes Flick,Angel Rubio*

Main category: quant-ph

TL;DR: 提出了一种用于量子电动力学密度泛函理论(QEDFT)的无光子交换关联泛函pxcLDA，该泛函能在弱到强光-物质耦合范围内高效描述多电子系统的电子密度。


<details>
  <summary>Details</summary>
Motivation: 需要开发适用于实际多电子系统的QEDFT泛函，以描述光-物质耦合对电子密度的影响。先前工作主要针对单电子系统，需要扩展到多电子系统。

Method: 基于局域密度近似(LDA)构建无光子交换关联泛函(pxcLDA)，通过简单程序计算描述电子-光子关联和弱耦合区域非均匀性的重整化因子，并与量子电动力学耦合簇方法及先前QEDFT优化有效势方法进行比较。

Result: 在各种原子和分子系统中，pxcLDA能精确再现腔修饰的电子密度，与参考方法结果高度一致。重整化因子随系统尺寸或集体耦合增加而趋近于1，表明电子-光子交换主导行为，对大系统有更高精度。

Conclusion: 该方法为基于电子密度的QEDFT泛函应用于实际电子系统提供了实用途径，能有效描述从弱到强光-物质耦合范围内的电子密度变化。

Abstract: We present results of a photon-free exchange-correlation functional within the local density approximation (pxcLDA) for quantum electrodynamics density functional theory (QEDFT) that efficiently describes the electron density of many-electron systems across weak to strong light-matter coupling. Building on previous work [I-Te. Lu et al., Phys. Rev. A 109, 052823 (2024)] that captured electron-photon correlations via an exchange-correlation functional derived from the nonrelativistic Pauli-Fierz Hamiltonian and tested on one-electron systems, we use a simple procedure to compute a renormalization factor describing electron-photon correlations and inhomogeneity in the weak-coupling regime by comparing it with quantum electrodynamics coupled-cluster, and previous QEDFT optimized effective potential methods. Across various atoms and molecules, pxcLDA reproduces cavity-modified densities in close agreement with these references. The renormalization factor approaches unity as the system size or collective coupling increases, reflecting an electron-photon exchange-dominated behavior and improved accuracy for larger systems. This approach now offers a practical route to applying QEDFT functionals based on electron density to realistic electron systems.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [55] [Topological and optical signatures of modified black-hole entropies](https://arxiv.org/abs/2512.13769)
*Ankit Anand,Kimet Jusufi,Spyros Basilakos,Emmanuel N. Saridakis*

Main category: gr-qc

TL;DR: 研究四种修正熵（Barrow、Rényi、Kaniadakis、对数）如何通过熵-几何对应改变黑洞时空，分析热力学拓扑分类和光子球/阴影效应，并用EHT观测数据约束熵修正参数。


<details>
  <summary>Details</summary>
Motivation: 探索偏离Bekenstein-Hawking熵的黑洞如何影响时空几何，利用热力学拓扑和光学观测来测试广义熵框架并探测对面积律的偏离。

Method: 通过熵-几何对应推导四种修正熵对应的有效度规，使用离壳自由能和绕数进行热力学拓扑分类，计算光子球半径和阴影大小，并与事件视界望远镜对Sgr A*的观测数据比较。

Result: Barrow和Rényi熵产生单个不稳定扇区（全局电荷W=-1），而对数和Kaniadakis修正产生相消缺陷（W=0），显示不同于Schwarzschild黑洞的拓扑结构。每种修正熵都引起特征性光学偏移，通过与EHT观测比较得到了所有熵变形参数的新界限。

Conclusion: 热力学拓扑结合光子球现象学为测试广义熵框架和探测Bekenstein-Hawking面积律的偏离提供了可行途径，修正熵参数可通过黑洞阴影观测进行约束。

Abstract: We investigate how deviations from the Bekenstein-Hawking entropy modify black-hole spacetimes through the recently proposed entropy-geometry correspondence. For four representative modified entropies, namely Barrow, Rényi, Kaniadakis, and logarithmic, we derive the corresponding effective metrics and analyze their thermodynamic and topological classification using the off-shell free energy and winding numbers. We show that Barrow and Rényi entropies yield a single unstable sector with global charge $W=-1$, while logarithmic and Kaniadakis corrections produce canceling defects with $W=0$, revealing topological structures absent in the Schwarzschild case. Using the modified metrics, we further calculate the photon-sphere radius and shadow size, showing that each modified entropy relation induces characteristic optical shifts. Thus, by comparing with Event Horizon Telescope observations of Sgr A$^\ast$, we extract new bounds on all entropy-deformation parameters. Our results demonstrate that thermodynamic topology, together with photon-sphere phenomenology, offers a viable way to test generalized entropy frameworks and probe departures from the Bekenstein-Hawking area law.

</details>


### [56] [A cyclic scale-invariance universe with negative variable cosmological constant](https://arxiv.org/abs/2512.13906)
*Nasr Ahmed*

Main category: gr-qc

TL;DR: 论文提出一个负的随时间变化的宇宙学常数Λ(H)作为哈勃参数的函数，用于构建无未来奇点的周期性宇宙模型，该模型显示Quintom行为并在每个周期中宇宙压力符号翻转。


<details>
  <summary>Details</summary>
Motivation: AdS真空对应负宇宙学常数Λ，虽然理论上动机充分，但其实际存在性一直存在争议。AdS-dS转换对应Λ符号切换，需要探索负Λ在宇宙学中的作用。

Method: 提出一个负的随时间变化的宇宙学常数Λ(H)作为哈勃参数H的函数的ansatz，在尺度不变引力理论中构建周期性无未来奇点的宇宙模型。

Result: 负Λ模型得到物理上可接受的宇宙描述，而正Λ和零Λ得到非物理参数。模型显示Quintom行为，每个周期中宇宙压力符号翻转，为晚期加速膨胀提供非传统机制。

Conclusion: 负的随时间变化的宇宙学常数Λ(H)能够构建合理的周期性宇宙模型，揭示Quintom行为，为AdS-dS转换和晚期加速膨胀提供新视角。

Abstract: The AdS vacuum corresponds to a negative cosmological constant $Λ$. While it is well-motivated theoretically, There has always been controversy over its actual existence. The AdS-dS transition is corresponding to a sign switching $Λ$. We have proposed an ansatz for a negative time-varying cosmological constant $Λ(H)$ as a function of Hubble parameter $H$, and used it in constructing a periodic model with no future singularity in a scale-invariance gravity. With the proposed Ansatz for negative $Λ$, The model leads to a physically acceptable cosmic description, while we get unphysical parameters with the positive and zero values of $Λ$. The model reveals a Quintom behavior with a sign flipping of cosmic pressure during each period. The non-conventional mechanism of negative $Λ$ that are expected to address the late-time acceleration has been revisited.

</details>


### [57] [On non-equatorial embeddings into $\mathbb{R}^3$ of spherically symmetric wormholes with topological defects](https://arxiv.org/abs/2512.13942)
*Mauricio Cataldo,Daniel Cuevas*

Main category: gr-qc

TL;DR: 论文提出了一种广义的等距嵌入方法，将传统局限于赤道平面的球对称时空嵌入扩展到任意极角切片，解决了某些几何无法嵌入三维欧氏空间的问题。


<details>
  <summary>Details</summary>
Motivation: 传统球对称时空的嵌入方法仅限于赤道平面（θ=π/2），但许多球对称几何的赤道切片无法等距嵌入三维欧氏空间，导致标准几何直观失效。需要扩展嵌入方法以可视化和分析这些传统方法无法处理的时空。

Method: 将嵌入程序推广到任意极角θ≠π/2的切片，建立广义嵌入形式体系。该方法允许选择不同的极角切片进行嵌入，突破了传统赤道平面的限制。

Result: 将形式体系应用于类史瓦西虫洞和具有角亏缺或角盈余的广义闵可夫斯基时空。对于这些赤道切片无法一致嵌入ℝ³的情况，确定了径向坐标、极角和几何参数的具体约束条件，以保证能够一致地嵌入三维欧氏空间。

Conclusion: 通过推广到任意极角切片，扩展了球对称时空的可视化和分析能力，为传统方法无法处理的几何提供了新的嵌入可能性，增强了我们对这些时空结构的几何直观理解。

Abstract: Traditionally, the embedding procedure for spherically symmetric spacetimes has been restricted to the equatorial plane $θ= π/2$. This conventional approach, however, encounters a fundamental limitation: not every spherically symmetric geometry admits an isometric embedding of its equatorial slice into three-dimensional Euclidean space. When such embeddings are not possible, the standard geometric intuition becomes inapplicable. In this work, we generalize the embedding procedure to slices with arbitrary polar angles $θ\neq π/2$, thereby extending the visualization and analysis of spacetimes beyond the reach of traditional methods.
  The formalism is applied to Schwarzschild-like wormholes and to a generalized Minkowski spacetime with angular deficit or excess, which are particularly relevant since their equatorial slices cannot be consistently embedded in $\mathbb{R}^3$. In these cases, we identify the explicit constraints on the radial coordinate, polar angle, and geometric parameters required to guarantee consistent embeddings into three-dimensional Euclidean space.

</details>


### [58] [Graviton Condensate Stars and Its Gravitational Echoes](https://arxiv.org/abs/2512.13976)
*Muhammad Fitrah Alfian Rangga Sakti*

Main category: gr-qc

TL;DR: 该论文构建了包含普通完美流体物质与引力子凝聚体相互作用的精确恒星结构，提出了两种表面压力条件不同的引力子凝聚体类型，并研究了其对致密性和引力回波的影响。


<details>
  <summary>Details</summary>
Motivation: 研究引力子凝聚体与普通物质相互作用的恒星结构，探索引力子凝聚体如何影响恒星的致密性和引力波回波特性，为通过致密天体观测研究引力子提供理论基础。

Method: 构建包含普通完美流体物质与引力子凝聚体相互作用的精确恒星解，提出两种表面压力条件：类型1（表面横向压力为零）和类型2（表面径向压力为零）。分析压力不连续性条件，计算Buchdahl不等式、回波时间和频率，并研究质量标量波的引力扰动。

Result: 发现恒星结构的Buchdahl不等式依赖于引力子凝聚体参数，可实现超致密恒星模型。在相同致密性下，类型2的引力子凝聚体会延迟引力回波，而类型1会加速回波（τ_echo2 > τ_CDS > τ_echo1）。质量标量波的引力扰动分析支持这些结果。

Conclusion: 引力子凝聚体的存在显著影响恒星的致密性和引力波回波特性，为通过致密天体观测探测引力子提供了新的可能性，有望推动引力子的实验研究。

Abstract: We construct the exact stellar configurations that contain an ordinary perfect-fluid matter that interacts minimally with a condensate of gravitons with distinct pressure conditions on the surface. We propose vanishing transverse pressure on the surface for, namely graviton condensate type 1 and vanishing radial pressure on the surface for type 2. The condition for the radial pressure of type 1 requires the existence of a thin shell that will balance the pressure discontinuity while for type 2, the discontinuity on transverse pressure does not require the additional thin shell. It is found that the Buchdahl inequality of the resulting stellar configurations depends on the parameter related to the graviton condensate, such that we can find the ultra-compact regime of the stellar models. Moreover, the echo time and echo frequency within the ultra-compact regime are computed. At the same compactness, it is found that the presence of the graviton condensate will delay the gravitational echoes for type 2 and will expedite the gravitational echoes for type 1 compared to constant density star, $τ_{echo2}>τ_{CDS}>τ_{echo1}$. Furthermore, the gravitational perturbation of a massless scalar wave is also investigated to support these results. These results could open more opportunities for the observational study of graviton in the near future, mostly from the compact astrophysical objects.

</details>


### [59] [First-order general constitutive equations for relativistic fluids using the projection method in the Chapman-Enskog expansion of the Boltzmann equation](https://arxiv.org/abs/2512.14060)
*A. L. García-Perciante,A. R. Méndez,O. Sarbach*

Main category: gr-qc

TL;DR: 将投影方法与Chapman-Enskog方法结合，推广了相对论Boltzmann方程的一阶非平衡修正分布函数，使其明确包含热力学框架和表示的选择自由度


<details>
  <summary>Details</summary>
Motivation: 现有的相对论流体理论在处理非平衡修正时，未能充分体现热力学框架和表示的选择自由度，这限制了理论的一般性和应用范围

Method: 结合投影方法和Chapman-Enskog方法，推广相对论Boltzmann方程的一阶非平衡修正分布函数，使其包含热力学框架和表示的选择自由度

Result: 得到了广义的本构方程，将热力学通量与所有力（包括弱外电磁场）耦合起来，特殊情况下可导出物理上合理的相对论流体理论

Conclusion: 通过明确包含热力学框架和表示的选择自由度，建立了一般化的力-通量关系，为相对论流体理论提供了更一般的基础

Abstract: The first-order out of equilibrium correction to the distribution function, obtained by implementing the projection method for the perturbed relativistic Boltzmann equation using the Chapman-Enskog method, is generalized in order to explicitly include the freedom of choice for thermodynamic frame and representation. It is shown how this procedure leads to general constitutive equations that couple the thermodynamic fluxes to all forces including a weak external electromagnetic field. Special cases of the resulting force-flux relations have been shown to lead to physically sound theories for relativistic fluids.

</details>


### [60] [Chiral gravitational waves from domain walls in Nieh-Yan gravity](https://arxiv.org/abs/2512.14063)
*Jiro Soda,Maki Takeuchi*

Main category: gr-qc

TL;DR: 研究在带有Nieh-Yan项的teleparallel引力中，引力波被轴子畴壁散射的现象，发现畴壁导致宇称破坏，使透射引力波呈现手性特征


<details>
  <summary>Details</summary>
Motivation: 探索在teleparallel引力框架下，轴子畴壁对引力波传播的影响，特别是宇称破坏效应如何导致引力波的手性特征

Method: 在带有Nieh-Yan项的teleparallel引力理论中，计算引力波被轴子畴壁散射的过程，分析透射引力波的圆偏振度

Result: 畴壁导致宇称破坏，使透射引力波呈现手性；引力波通过畴壁后可能变得手性；圆偏振度不依赖于畴壁的张力

Conclusion: 在teleparallel引力中，轴子畴壁可以导致引力波的手性特征，这一效应与畴壁张力无关，为探测轴子畴壁和引力波手性提供了新途径

Abstract: We study the scattering of gravitational waves by axion domain walls in teleparallel gravity with the Nieh-Yan term. Since a domain wall causes the parity violation, the transmitted gravitational waves also exhibit the parity violation. We calculate the degree of circular polarization of gravitational waves. It turns out that gravitational waves after going through the domain wall could be chiral. Remarkably, the degree of circular polarization does not depend on the tension of the domain wall.

</details>


### [61] [Spherically symmetric solutions in quasi-local Einstein-Weyl gravity](https://arxiv.org/abs/2512.14148)
*Johanna Borissova,Breno L. Giacchini,Aaron Held*

Main category: gr-qc

TL;DR: 研究准局域爱因斯坦-外尔引力中的静态球对称解，发现该理论在径向核心处只允许正则解，并给出大距离处的1/r^6修正


<details>
  <summary>Details</summary>
Motivation: 量子引力有效作用量中的高阶导数和非局域算符有望正则化广义相对论的奇点，本文研究准局域爱因斯坦-外尔引力中的解分类

Method: 在静态球对称条件下，对准局域爱因斯坦-外尔引力进行Frobenius解分类分析

Result: 发现准局域理论在径向核心处只允许正则解，大距离处有1/r^6修正，还发现了类史瓦西视界、对称/非对称虫洞喉等解类型

Conclusion: 准局域爱因斯坦-外尔引力能够避免奇点问题，为量子引力正则化提供了具体实现途径

Abstract: Quantum-gravitational effective actions with higher-derivative and non-local operators are expected to regularize the singularities of general relativity. Here we focus on quasi-local Einstein-Weyl gravity and obtain a classification of Frobenius solutions in static spherical symmetry. In contrast to local Einstein-Weyl gravity, and more generally quadratic gravity, we find that the quasi-local theory admits only regular solutions at the radial core. In addition, we find asymptotic $1/r^{6}$-corrections to the Schwarzschild geometry at large radial distances. Other solution classes around generic expansion points describe Schwarzschild-like and other types of horizons, as well as symmetric and non-symmetric wormhole throats.

</details>


### [62] [Inspiral-Transition-Plunge Gravitational Waveforms Beyond Kerr: A Kerr-Newman Case Study](https://arxiv.org/abs/2512.14156)
*Daiki Watarai,Kent Yagi,Shammi Tahura*

Main category: gr-qc

TL;DR: 该论文构建了Kerr-Newman背景下的双黑洞并合波形，用于探测超越Kerr时空的特征，发现后螺旋阶段动力学能显著提高对黑洞电荷的约束精度。


<details>
  <summary>Details</summary>
Motivation: 非对称质量双黑洞并合是第三代地面和未来空间引力波探测器的关键目标，但现有波形构建主要局限于Schwarzschild或Kerr背景时空。需要扩展到超越Kerr的时空（如Kerr-Newman）来探测非Kerr特征。

Method: 在Kerr-Newman背景下构建螺旋-过渡-俯冲波形，假设主黑洞带自旋和电荷，次级天体中性无自旋。采用小电荷质量比近似和Dudley-Finley近似，使引力与电磁扰动解耦，引力部分满足类Teukolsky方程。

Result: 对于爱因斯坦望远镜观测的中等质量比并合，显式建模后螺旋动力学能显著收紧电荷质量比约束。在主导后螺旋信号的区域，电荷质量比约束可达O(10^{-3})，比仅使用螺旋阶段或GW150914当前约束严格数个量级。

Conclusion: 该研究为超越Kerr时空的螺旋-过渡-俯冲波形建模奠定了基础，并为未来引力波观测中探测非Kerr特征提供了方法，显示后螺旋阶段对约束黑洞电荷至关重要。

Abstract: Binary black hole mergers with asymmetric component masses are key targets for both third-generation ground-based and future space-based gravitational-wave (GW) detectors, offering unique access to the strong-field dynamics of gravity. The evolution is commonly divided into three stages: the adiabatic inspiral, the transition, and the plunge. To date, constructions of inspiral-transition-plunge waveforms have largely focused on Schwarzschild or Kerr background spacetimes. In this paper, we extend these efforts to spacetimes beyond Kerr by constructing such waveforms in a Kerr-Newman background. For simplicity, we allow the primary black hole to carry spin and charge while keeping the secondary object neutral and non-spinning. We work in the small charge-to-mass ratio regime and adopt the Dudley-Finley approximation, in which the gravitational and electromagnetic perturbations decouple. In particular, the gravitational sector satisfies a Teukolsky-like equation, enabling only minimal modifications relative to the Kerr case when constructing the waveform. Having the inspiral-transtion-plunge waveforms in hand, we studied observational prospects for constraining the charge of the central black hole. We find that, for intermediate-mass-ratio mergers observed with the Einstein Telescope, explicitly modeling the post-inspiral dynamics significantly tightens charge-to-mass ratio constraints. In particular, the bounds on the charge-to-mass ratio can reach $O(10^{-3})$ in the region of primary masses and spins where the post-inspiral signal dominates, yielding charge bounds that can be orders of magnitude tighter than those obtained from the inspiral alone or from the current bound with GW150914. These results lay the groundwork for inspiral-transition-plunge waveform modeling in beyond-Kerr spacetimes and for probing non-Kerr signatures in future GW observations.

</details>


### [63] [Acoustic horizons and the Hawking effect in polariton fluids of light](https://arxiv.org/abs/2512.14194)
*Elisabeth Giacobino,Maxime J. Jacquet*

Main category: gr-qc

TL;DR: 该论文提出利用极化激元光流体作为可编程模拟器，研究定制弯曲时空上的量子场论，重点关注声学视界和霍金效应。


<details>
  <summary>Details</summary>
Motivation: 开发一个实验平台来研究弯曲时空中的量子场论现象，特别是霍金效应、声学视界等难以在真实黑洞中观测的量子引力效应。

Method: 利用半导体微腔中的激子-极化激元系统，通过理论工具（平均场、量子流体动力学）将其映射到相对论场论，建立视界物理的伪幺正散射问题，并开发实验工具包（相位印刻流、相干泵浦-探测光谱、平衡和零差探测）。

Result: 建立了从极化激元系统到弯曲时空量子场论的完整映射框架，提供了提取放大、正交压缩和纠缠关联的实验工作流程，为研究旋转几何中的超辐射、动力学不稳定性等现象提供了平台。

Conclusion: 极化激元光流体为研究弯曲时空量子场论中的开放问题提供了强大的可编程模拟平台，特别适用于研究霍金效应、旋转超辐射及其相互作用，为实现"哑洞光谱学"和弯曲时空中纠缠动力学研究提供了路线图。

Abstract: These lecture notes develop polariton fluids of light as programmable simulators of quantum fields on tailored curved spacetimes, with emphasis on acoustic horizons and the Hawking effect. After introducing exciton-polariton physics in semiconductor microcavities, we detail the theoretical tools to study the mean field and the quantum hydrodynamics of this driven-dissipative quantum system. We derive the mapping to relativistic field theories and cast horizon physics as a pseudounitary stationary scattering problem. We present the Gaussian optics circuit that describes observables and fixes detection weights for the horizon modes in near- and far-field measurements. We provide a practical experimental toolkit (phase-imprinted flows, coherent pump-probe spectroscopy, balanced and homodyne detection) and a step-by-step workflow to extract amplification, quadrature squeezing, and entanglement among correlations. Finally, we discuss the potential of this platform to investigate open questions in quantum field theory in curved spacetime, such as near horizon effects and quasinormal modes, as well as other phenomena universal to rotating geometries, from rotational superradiance to dynamical instabilities. We further outline the interplay between rotational superradiance and the Hawking effect, proposing to spatially resolve measurements as a roadmap for `dumb hole spectroscopy' and the study of entanglement dynamics in curved spacetimes.

</details>


### [64] [Analogue gravity with Bose-Einstein condensates](https://arxiv.org/abs/2512.14209)
*Adrià Delhom,Luca Giacomelli*

Main category: gr-qc

TL;DR: 这篇论文是关于模拟引力的教程性综述，重点介绍原子玻色-爱因斯坦凝聚体作为模拟黑洞的平台，涵盖声学黑洞、超辐射和霍金辐射等概念。


<details>
  <summary>Details</summary>
Motivation: 模拟引力研究凝聚态系统中集体激发如何再现弯曲时空中的场行为，原子BEC因其精确理论描述、卓越实验控制和超低温特性成为理想的模拟平台。

Method: 提供模拟黑洞和BEC理论描述的入门教程，包括BEC基本激发（表现为弯曲时空中的量子场），并应用这些工具研究黑洞超辐射和模拟霍金辐射。

Result: 论文系统综述了当前对黑洞超辐射和模拟霍金辐射的理解，包含具体示例和数值方法，展示了BEC作为模拟引力平台的潜力。

Conclusion: 原子BEC为模拟引力研究提供了独特平台，能够探索量子声学在弯曲时空中的行为，特别是黑洞超辐射和霍金辐射等量子引力效应。

Abstract: Analogue gravity explores how collective excitations in condensed matter systems can reproduce the behavior of fields in curved spacetimes. An important example is the acoustic black holes that can occur for sound in a moving fluid. In these lecture notes, we focus on atomic Bose-Einstein condensates (BECs), quantum fluids that provide an interesting platform for analogue gravity studies thanks to their accurate theoretical description, remarkable experimental control, and ultralow temperatures that allow the quantum nature of sound to emerge. We give a pedagogical introduction to analogue black holes and the theoretical description of BECs and their elementary excitations, which behave as quantum fields in curved spacetimes. We then apply these tools to survey the current understanding of black-hole superradiance and analogue Hawking radiation, including explicit examples and numerical methods.

</details>


### [65] [Comment on "Thermodynamic properties of Schwarzschild black hole in non-commutative gauge theory of gravity"](https://arxiv.org/abs/2512.14310)
*A. A. Araújo Filho,Iarley P. Lobo*

Main category: gr-qc

TL;DR: 该论文指出先前一篇关于非对易框架下轴对称黑洞热力学的研究存在计算错误，包括事件视界计算错误和表面引力定义不当，导致所有热力学结果无效。


<details>
  <summary>Details</summary>
Motivation: 指出先前研究[Annals Phys. 455 (2023) 169394]中关于非对易框架下轴对称黑洞热力学分析存在严重计算错误，需要重新审视这些结果。

Method: 通过分析指出原论文的两个主要错误：1）事件视界计算错误；2）在轴对称时空错误地使用了球对称情况的表面引力定义。

Result: 原论文的所有热力学结果都因计算错误而无效，需要彻底重新检验。

Conclusion: 先前关于非对易框架下轴对称黑洞热力学的研究存在根本性错误，其所有结果都需要重新计算和验证。

Abstract: A recent study [Annals Phys. 455 (2023) 169394, e-Print: 2204.01901 [gr-qc]] examined the thermodynamic behavior of an axially symmetric black hole within a non-commutative framework that mimics the effect of an angular momentum. However, the analysis presents notable computational inconsistencies. In that analysis, the event horizon was miscalculated, and this error propagated through and compromised all subsequent results. In addition, an incorrect definition of surface gravity was used -- the spherically symmetric case was invoked for an axially symmetric spacetime -- rendering the thermodynamic results invalid. In other words, all the results presented in the paper require a thorough reexamination.

</details>


### [66] [Covariance, relativity, and the proper mass of the universe in the no-boundary wave function](https://arxiv.org/abs/2512.14339)
*Natalia Gorobey,Alexander Lukyanenk,A. V. Goltsev*

Main category: gr-qc

TL;DR: 在闭合宇宙中发现了特权参考系的离散类，物理自由度运动方程相同。获得了特权参考系下宇宙量子态的欧几里得泛函积分表示，具有无边界条件。极点处的边界条件包括哈勃参数的无限渐近行为，这使得通过改变宇宙膨胀能量的符号来正则化泛函积分成为可能。该构造还允许添加非零的宇宙固有质量。


<details>
  <summary>Details</summary>
Motivation: 研究闭合宇宙中的特权参考系问题，探索量子宇宙学中的泛函积分表示，解决宇宙量子态的正则化问题，并考虑宇宙固有质量的影响。

Method: 在闭合宇宙中发现离散的特权参考系类，建立物理自由度运动方程相同的框架。采用欧几里得泛函积分方法表示宇宙量子态，应用无边界条件。在极点处引入哈勃参数无限渐近行为的边界条件，通过改变宇宙膨胀能量的符号实现泛函积分的正则化。

Result: 成功获得了特权参考系下宇宙量子态的泛函积分表示，实现了泛函积分的正则化，并扩展了构造以包含非零宇宙固有质量的可能性。

Conclusion: 该研究为闭合宇宙中的特权参考系问题提供了新的理论框架，通过泛函积分正则化方法解决了量子宇宙学中的技术难题，并为考虑宇宙固有质量效应开辟了途径。

Abstract: A discrete class of privileged reference frames in a closed universe with identical equations of motion for physical degrees of freedom was found. A representation of the quantum state of the universe in a privileged reference frame was obtained as a Euclidean functional integral with no-boundary conditions. The boundary condition at the Pole, in addition to the smoothness conditions, is the infinite asymptotic behavior of the Hubble parameter. This makes it possible to regularize the functional integral by changing the sign of the expansion energy of the universe. The proposed construction also allows for the addition of a non-zero proper mass of the universe.

</details>


### [67] [Probing Hairy Kerr Black Holes through Quasi-Periodic Oscillations I: A study based on the kinematic models](https://arxiv.org/abs/2512.14456)
*Anirban Dasgupta,Supragyan Priyadarshinee,Indrani Banerjee,Subhash Mahapatra*

Main category: gr-qc

TL;DR: 本文研究了受引力解耦方法启发的旋转毛状黑洞，探索其视界结构和基本频率，并通过与六个黑洞源的高频准周期振荡观测比较，约束毛状参数空间。


<details>
  <summary>Details</summary>
Motivation: 毛状黑洞具有超越质量、电荷和角动量的额外参数，导致更丰富的现象学。在电磁和引力波观测数据可用的背景下，表征其允许的参数空间至关重要。

Method: 使用受引力解耦方法启发的旋转毛状黑洞解，满足爱因斯坦场方程并遵守强能量条件。详细探索视界结构，研究毛状参数对基本频率的敏感性，并通过与六个黑洞源的HFQPO观测比较来约束参数空间。

Result: 首次报告了毛状黑洞独特的视界特征，确定了每个黑洞源最有利的参数空间。分析表明，对于GRO J1655-40和XTE J1859+226源，相对论进动模型比潮汐瓦解模型更不合适。

Conclusion: 研究为区分不同黑洞源的最合适模型提供了框架，并讨论了当前数据精度下相对论进动模型与潮汐瓦解模型的适用性差异，为通过观测约束毛状黑洞参数空间提供了方法。

Abstract: Black hole (BH) solutions endowed with nontrivial scalar or matter fields - commonly known as hairy black holes - have attracted significant interest in recent years. They admit extra parameters beyond mass, charge, and angular momentum, leading to a richer phenomenology. Characterizing their allowed parameter space is therefore crucial, especially in light of the available data from electromagnetic and gravitational-wave observations. The rotating hairy black hole solutions studied here are inspired by the gravitational decoupling method and satisfy the Einstein field equations with a conserved energy-momentum tensor that respects the strong energy conditions (SECs). We explore in detail the horizon structure of such black holes and report for the first time certain unique features, not observed in Kerr BHs. We investigate the sensitivity of the hairy parameters on the fundamental frequencies associated with the motion of matter in the hairy Kerr spacetime, and compare them with the Kerr scenario. The theoretical models aimed to explain the observed high-frequency observations (HFQPOs) in BHs are associated with the fundamental frequencies. Hence, such a study enables us to constrain the parameter space of the hairy Kerr spacetime by comparing the model-dependent HFQPO frequencies with the available observations. By comparing the kinematic models of HFQPOs with the observations of six BH sources, we report the most favored parameter space for each of these BHs. Our analysis also provides a framework to discern the most suitable model for each of these sources. Interestingly, even with the present precision of the data, the Relativistic Precession Model seems to be less suitable compared to the Tidal Disruption Model for the sources GRO J1655-40 and XTE J1859+226. The implications are discussed.

</details>


### [68] [Pfaffian Systems, Cartan Connections, and the Null Surface Formulation of General Relativity](https://arxiv.org/abs/2512.14501)
*Emanuel Gallo,Carlos N. Kozameh*

Main category: gr-qc

TL;DR: 本文回顾了微分形式、普法夫系统和超曲面在广义相对论中的作用，重点介绍了零曲面表述这一将光锥结构而非度规本身作为基本引力变量的激进框架。


<details>
  <summary>Details</summary>
Motivation: 探讨微分形式、普法夫系统和超曲面等数学工具如何为广义相对论提供优雅的表述方式，特别是如何通过这些工具发展出零曲面表述这一替代框架。

Method: 使用Cartan微分形式微积分来表述爱因斯坦场方程，引入Élie Cartan的正则共形联络来描述共形几何的不变量，并基于普法夫系统构建零曲面表述框架。

Result: 建立了零曲面表述框架，该框架允许从单个标量函数Z（其等值面为类光面）重构整个时空几何，将光锥结构而非度规作为基本引力变量。

Conclusion: 微分形式、普法夫系统和超曲面为广义相对论提供了强大的数学表述工具，特别是零曲面表述为理解引力理论提供了全新的视角，将光锥结构提升为基本物理变量。

Abstract: This review examines the role of differential forms, Pfaffian systems, and hypersurfaces in general relativity. These mathematical constructions provide the essential tools for general relativity, in which the curvature of spacetime;described by the Einstein field equations;is most elegantly formulated using the Cartan calculus of differential forms. Another important subject in this discussion is the notion of conformal geometry, where the relevant invariants of a metric are characterized by Elie Cartan's normal conformal connection. The previous analysis is then used to develop the null surface formulation (NSF) of general relativity, a radical framework that postulates the structure of light cones rather than the metric itself as the fundamental gravitational variable. Defined by a central Pfaffian system, this formulation allows the entire spacetime geometry to be reconstructed from a single scalar function, $Z$, whose level surfaces are null.

</details>


### [69] [Causal character of imaginary Killing spinors and spinorial slicings](https://arxiv.org/abs/2512.14569)
*Sven Hirsch,Yiyue Zhang*

Main category: gr-qc

TL;DR: 该论文研究了渐近AdS时空中满足BPS界限的自旋初始数据集，包括引力波和高维旋转黑洞，并建立了尖锐的维度阈值。


<details>
  <summary>Details</summary>
Motivation: 研究渐近AdS时空中满足BPS界限的自旋初始数据集，理解引力波和旋转黑洞在更高维度中的性质，建立维度阈值以区分不同物理行为。

Method: 使用自旋几何方法，通过虚Killing旋量分析，建立混合因果类型旋量可替换为严格类时或类光旋量的判据，并类比最小曲面方法构造余维2切片。

Result: 建立了渐近AdS时空中BPS界限饱和的精确特征，发现了引力波和旋转黑洞的尖锐维度阈值，证明了虚Killing旋量替换定理，并成功构造了余维2切片。

Conclusion: 自旋几何方法为研究渐近AdS时空中的BPS界限提供了有力工具，建立的维度阈值和旋量替换定理对理解高维引力理论具有重要意义，余维2切片构造扩展了最小曲面方法的应用范围。

Abstract: We characterize spin initial data sets that saturate the BPS bound in the asymptotically AdS setting. This includes both gravitational waves and rotating black holes in higher dimensions, and we establish a sharp dimension threshold in each case. A key ingredient in our argument is a theorem providing a general criterion for when an imaginary Killing spinor of mixed causal type can be replaced by one that is strictly timelike or null. Moreover, in analogy with the minimal surface method, we demonstrate that spinors can be used to construct a codimension-$2$ slicing.

</details>


### [70] [Stochastic Inflation in Numerical Relativity](https://arxiv.org/abs/2512.14649)
*Yoann L. Launay,Gerasimos I. Rigopoulos,E. Paul S. Shellard*

Main category: gr-qc

TL;DR: 本文重新推导了包含所有度规和标量物质自由度的3+1维随机暴胀方程，并以规范不变的方式呈现。通过BSSN数值相对论公式实现数值模拟，在慢滚和超慢滚场景中验证了方程的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统随机暴胀方法通常忽略梯度项，而数值相对论和晶格宇宙学则处理非线性动力学但缺乏随机性。本文旨在结合两者的优势，开发一个包含所有自由度、保留梯度信息且能处理非微扰现象的随机暴胀框架。

Method: 1. 以规范不变的方式重新推导包含所有度规和标量物质自由度的3+1维随机暴胀方程；2. 将方程转换为BSSN数值相对论公式；3. 在慢滚和超慢滚两种暴胀场景中实现数值模拟；4. 验证能量和动量约束条件的满足情况。

Result: 1. 所有动力学变量的演化被正确再现；2. 能量和动量约束条件得到良好满足；3. 获得了保留梯度信息的完全非线性随机动力学的实空间实现；4. 证明了随机方程在理论和数值上的鲁棒性。

Conclusion: 该工作为标准随机暴胀、暴胀数值相对论和晶格宇宙学提供了推广，为可靠预测非微扰现象和后续宇宙学时期的精确初始条件开辟了可能性，使随机方程能够应用于更广泛的暴胀场景。

Abstract: A set of 3+1 equations for stochastic inflation incorporating all metric and scalar matter degrees of freedom, first presented in previous work, are re-derived in a gauge invariant manner. We then present numerical implementations of these stochastic equations, cast in the BSSN formulation of Numerical Relativity, demonstrating their efficacy in both a slow-roll and an ultra slow-roll scenario. We find the evolution is correctly reproduced for all the dynamical variables, and the energy and momentum constraints are well-satisfied. This demonstrates that the stochastic equations are theoretically and numerically robust and ready to be applied to a wider inflationary landscape. Our simulations result in real space realizations of the fully non-linear stochastic dynamics with gradient information retained. As a generalisation of standard stochastic inflation, inflationary numerical relativity and lattice cosmology, this work opens up the possibility for reliable predictions of non-perturbative phenomena and provides precise initial conditions for subsequent cosmological eras.

</details>


### [71] [Search for Gravitational Wave Memory in PPTA and EPTA Data: A Complete Signal Model](https://arxiv.org/abs/2512.14650)
*Sharon Mary Tomson,Boris Goncharov,Rutger van Haasteren,Rahul Srinivasan,Enrico Barausse,Yirong Wen,Jingbo Wang,John Antoniadis,N. D. Ramesh Bhat,Zu-Cheng Chen,Ismael Cognard,Valentina Di Marco,Huanchen Hu,Gemma H. Janssen,Michael Kramer,Wenhua Ling,Kuo Liu,Saurav Mishra,Delphine Perrodin,Andrea Possenti,Christopher J. Russell,Ryan M. Shannon,Gilles Theureau,Shuangqiang Wang*

Main category: gr-qc

TL;DR: 首次在脉冲星计时阵列数据中搜索引力波记忆效应，使用完整数值相对论波形，排除了特定质量超大质量黑洞双星合并，并探索了降低计算成本的方法。


<details>
  <summary>Details</summary>
Motivation: 超大质量黑洞双星是脉冲星计时阵列实验中引力波的主要来源，但之前的研究未充分探索其晚期旋进和合并阶段的引力波记忆效应。需要开发基于完整数值相对论波形的搜索方法，并探索降低计算成本的途径。

Method: 开发了首个基于完整数值相对论波形的搜索方法，包含非线性引力波记忆效应。同时搜索通用的位移记忆爆发，探索使用核密度估计和归一化流近似来降低后验分布计算成本。

Result: 在95%置信水平下，排除了在700 Mpc范围内、18年观测时间内、啁啾质量为10^10太阳质量的超大质量黑洞双星合并。同时排除了在特定观测时间段内全天空、或在整个观测时间内特定天区位置、应变振幅大于10^-14的通用位移记忆爆发。

Conclusion: 成功开发并实施了首个基于完整数值相对论波形的引力波记忆搜索，为脉冲星计时阵列实验提供了新的探测工具，并展示了降低计算成本方法的可行性。

Abstract: We perform searches for gravitational wave memory in the data of two major Pulsar Timing Array (PTA) experiments located in Europe and Australia. Supermassive black hole binaries (SMBHBs) are the primary sources of gravitational waves in PTA experiments. We develop and carry out the first search for late inspirals and mergers of these sources based on full numerical relativity waveforms with null (nonlinear) gravitational wave memory. Additionally, we search for generic bursts of null gravitational wave memory, exploring possibilities of reducing the computational cost of these searches through kernel density and normalizing flow approximation of the posteriors. We rule out the mergers of SMBHBs with a chirp mass of 10^10 Solar Mass up to 700 Mpc over 18 years of observation at 95% credibility. We rule out the observation of generic displacement memory bursts with strain amplitudes > 10^-14 in brief periods of the observation time but across the sky, or over the whole observation time but for certain preferred sky positions, at 95%$credibility.

</details>


### [72] [Nonlinear Relativistic Tidal Response of Neutron Stars](https://arxiv.org/abs/2512.14663)
*Paolo Pani,Massimiliano Maria Riva,Luca Santoni,Nikola Savić,Filippo Vernizzi*

Main category: gr-qc

TL;DR: 该研究首次计算了相对论中子星的完全相对论性静态二次Love数，揭示了非线性潮汐效应在双星系统引力波信号中的重要性，二次Love数在晚期旋近阶段可达线性Love数的10%。


<details>
  <summary>Details</summary>
Motivation: 研究非线性潮汐响应的动机在于提高双星系统引力波建模的精度。传统线性潮汐效应已得到较好研究，但非线性效应（特别是二次Love数）对高精度引力波信号建模至关重要，尤其是在中子星合并的晚期旋近阶段。

Method: 采用两种方法：1）扩展引力体的世界线有效场理论；2）相对论恒星模型的二阶微扰理论。通过匹配程序，首次推导出由外部引力-电潮汐场诱导的非线性潮汐变形到二次阶。

Result: 二次Love数在小致密度极限下比线性Love数增强更多。尽管在8PN阶进入引力波相位，但主导的二次Love数可与7PN阶的次次主导线性潮汐修正相当，甚至大于4PN阶的次主导点粒子贡献。在晚期旋近阶段，二次Love数可达线性Love数的约10%。

Conclusion: 该研究首次提供了双星系统保守动力学和引力波信号的主导非线性潮汐修正，为高精度引力波建模中纳入非线性潮汐效应奠定了基础，并为计算磁潮汐场和高阶多极矩的（次主导）非线性效应提供了框架。

Abstract: We investigate the nonlinear tidal response of relativistic neutron stars by computing the fully relativistic, static, quadratic Love numbers. Using both the worldline effective field theory for extended gravitating bodies and second-order perturbations of relativistic stellar models, we derive the nonlinear tidal deformation induced by an external gravito-electric tidal field to quadratic order. Through a suitable matching procedure, we provide for the first time the leading nonlinear tidal corrections to the conservative dynamics and gravitational-wave signal of binary systems. Quadratic Love numbers are enhanced more than the linear ones in the small-compactness limit. Because of this, despite entering the gravitational-wave phase at 8th post-Newtonian (PN) order, the leading quadratic Love number can be as important as the next-to-next-to-leading order linear tidal correction, which enters at 7th PN order, and is larger than the subleading point-particle contribution entering at 4th PN order. In particular, quadratic Love numbers can be as large as ~10% of the linear Love numbers in the late inspiral phase. Our approach provides a framework to also compute the (subleading) nonlinear effects induced by magnetic tidal fields and higher multipole moments, and sets the foundations for incorporating nonlinear tidal effects in high-precision gravitational-wave modeling.

</details>


### [73] [Quasitopological gravity and double-copy formalism](https://arxiv.org/abs/2512.14674)
*Valeri P. Frolov*

Main category: gr-qc

TL;DR: 提出基于修正经典双拷贝构造的拟拓扑引力新方法，将D维拟拓扑引力真空解映射到(D+1)维平坦时空中的非线性电动力学


<details>
  <summary>Details</summary>
Motivation: 扩展双拷贝范式到爱因斯坦引力之外，为高阶曲率理论提供统一框架，通过非线性规范动力学解释高阶曲率引力相互作用

Method: 使用修正经典双拷贝构造，将静态球对称的D维拟拓扑引力真空解映射到(D+1)维平坦时空中的非线性电动力学，引力场方程简化为曲率不变量与电场强度之间的代数关系

Result: 所有D维拟拓扑引力真空解都可以从辅助非线性电动力学获得，引力场方程简化为代数关系，剩余动力学由高斯定律约束控制，应用于Born-Infeld和Hayward模型得到具有de Sitter核心的高维规则黑洞解

Conclusion: 该方法扩展了双拷贝范式的适用范围，为高阶曲率理论提供了统一框架，通过非线性规范动力学透明地解释了高阶曲率引力相互作用

Abstract: We propose a new approach to the quasitopological theory of gravity based on a modified classical double--copy construction. Focusing on static, spherically symmetric configurations, we show that all vacuum solutions of $D$--dimensional quasitopological gravity can be obtained from an auxiliary non--linear electrodynamics defined in a flat $(D+1)$--dimensional spacetime. The gravitational field equations reduce to an algebraic relation between a primary curvature invariant and the electric field strength, while the remaining dynamics is governed by a Gauss--law constraint for a point--like charge in the auxiliary space. This correspondence provides a transparent interpretation of higher--curvature gravitational interactions in terms of non--linear gauge dynamics and explains the absence of higher--derivative terms in the reduced equations. As illustrative examples, we apply the formalism to Born--Infeld and Hayward--type models, obtaining higher--dimensional regular black--hole solutions with a de~Sitter--like core. Our results extend the scope of the double--copy paradigm beyond Einstein gravity and suggest a unifying framework for a broad class of higher--curvature theories.

</details>


### [74] [Computing spectral shifts for Johannsen-Psaltis Black Holes](https://arxiv.org/abs/2512.14679)
*David G. Wu,Asad Hussain,Aaron Zimmerman*

Main category: gr-qc

TL;DR: 该论文开发了修改的Teukolsky形式主义和特征值扰动方法，计算了Johannsen-Psaltis黑洞的准正规模谱移，发现了奇偶宇称模的等谱性破缺，并推导了支持确定宇称模的广义宇称条件。


<details>
  <summary>Details</summary>
Motivation: 随着引力波探测数量和灵敏度的增加，需要在强场区对广义相对论进行精确检验。GW250114中多个准正规模的观测标志着黑洞光谱学的重大进展，这凸显了在超越广义相对论理论中准确预测准正规模谱的必要性，以便进行新物理的精确搜索。

Method: 采用修改的Teukolsky形式主义结合特征值扰动方法，计算了缓慢旋转的Johannsen-Psaltis黑洞的谱移，覆盖了角量子数2≤ℓ≤10、所有磁量子数m和泛音n=0,1,2，并通过与WKB近似比较验证了大ℓ极限下的模式行为。

Result: 发现这些黑洞允许确定宇称模式，但在所有自旋下打破了偶宇称和奇宇称准正规模之间的等谱性；谱移在慢自旋下线性依赖于m；推导了任何超越广义相对论的度规修改必须满足的支持确定宇称模的广义宇称条件。

Conclusion: 该工作为超越广义相对论理论中的准正规模谱预测奠定了基础，提供了关于引力扰动中等谱性破缺和宇称结构的新见解，为利用引力波观测进行新物理搜索提供了理论工具。

Abstract: The growing number of gravitational wave (GW) detections and the increasing sensitivity of GW detectors have enabled precision tests of General Relativity (GR) in the strong-field regime. The recent observation of multiple quasinormal modes (QNMs) in GW250114 marks a major advance for observational black hole spectroscopy. This clear signal, together with the growing number of GW detections, highlights the need for accurate predictions of QNM spectra in beyond-GR theories in order to carry out precision searches for new physics. In this work, we continue to lay the foundation for such predictions using a modified Teukolsky formalism in conjunction with the eigenvalue perturbation method. We compute the spectral shifts of slowly rotating Johannsen-Psaltis black holes for $2 \leq \ell \leq 10$, all $m$, and overtones $n = 0, 1, 2$, and confirm the large-$\ell$ behavior of the modes by comparing with the WKB approximation. We find that these black holes admit definite-parity modes but break the isospectrality between even- and odd-parity QNMs at all spins, and that the shifts depend linearly on $m$ for slow spins. We further derive a general parity condition that any beyond-GR modification to the metric must satisfy to support definite-parity modes, providing new insights into isospectrality breaking and parity structure in gravitational perturbations.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [75] [Physics-Guided Deep Learning for Heat Pump Stress Detection: A Comprehensive Analysis on When2Heat Dataset](https://arxiv.org/abs/2512.13696)
*Md Shahabub Alam,Md Asifuzzaman Jishan,Ayan Kumar Ghosh*

Main category: cs.LG

TL;DR: 本文提出了一种物理引导的深度神经网络方法，用于热泵系统应力分类，在When2Heat数据集上实现了78.1%的测试准确率，相比基线方法有显著提升。


<details>
  <summary>Details</summary>
Motivation: 热泵系统在现代节能建筑中至关重要，但由于复杂的热力学相互作用和有限的真实世界数据，其运行应力检测仍然具有挑战性。需要开发更有效的应力分类方法来提高系统可靠性和能效。

Method: 提出物理引导的深度神经网络方法，结合物理引导的特征选择和类别定义，采用5层隐藏层的深度神经网络架构，并应用双重正则化策略。使用When2Heat数据集（131,483个样本，656个特征，覆盖26个欧洲国家）。

Result: 模型在测试集上达到78.1%准确率，验证集上达到78.5%准确率。相比基线方法有显著改进：比浅层网络高5.0%，比有限特征集高4.0%，比单一正则化策略高2.0%。消融研究验证了物理引导特征选择、可变阈值设定和跨国能源模式分析的有效性。

Conclusion: 提出的系统为热泵应力检测提供了一个生产就绪的解决方案，具有181,348个参数和720秒的训练时间（在AMD Ryzen 9 7950X和RTX 4080硬件上）。该方法在准确性和实用性方面均表现出色。

Abstract: Heat pump systems are critical components in modern energy-efficient buildings, yet their operational stress detection remains challenging due to complex thermodynamic interactions and limited real-world data. This paper presents a novel Physics-Guided Deep Neural Network (PG-DNN) approach for heat pump stress classification using the When2Heat dataset, containing 131,483 samples with 656 features across 26 European countries. The methodology integrates physics-guided feature selection and class definition with a deep neural network architecture featuring 5 hidden layers and dual regularization strategies. The model achieves 78.1\% test accuracy and 78.5% validation accuracy, demonstrating significant improvements over baseline approaches: +5.0% over shallow networks, +4.0% over limited feature sets, and +2.0% over single regularization strategies. Comprehensive ablation studies validate the effectiveness of physics-guided feature selection, variable thresholding for realistic class distribution, and cross-country energy pattern analysis. The proposed system provides a production-ready solution for heat pump stress detection with 181,348 parameters and 720 seconds training time on AMD Ryzen 9 7950X with RTX 4080 hardware.

</details>


### [76] [Scaling and Transferability of Annealing Strategies in Large Language Model Training](https://arxiv.org/abs/2512.13705)
*Siqi Wang,Zhengyu Chen,Teng Xiao,Zheqi Lv,Jinluan Yang,Xunliang Cai,Jingang Wang,Xiaomeng Li*

Main category: cs.LG

TL;DR: 该研究提出了一个改进的预测框架，用于优化大语言模型训练中的学习率退火策略，发现小模型可以作为大模型训练动态的可靠代理，无需进行耗尽的超参数搜索。


<details>
  <summary>Details</summary>
Motivation: 学习率调度对训练大语言模型至关重要，但不同模型配置下的最优退火策略理解仍然不足。需要研究退火动态的可迁移性，并开发更有效的优化框架。

Method: 提出了改进的预测框架，纳入训练步数、最大学习率和退火行为等参数，在Warmup-Steady-Decay调度器下优化退火策略。使用密集模型和混合专家模型进行广泛实验验证。

Result: 研究发现最优退火比率遵循一致的模式，可以在不同训练配置间迁移。小模型可以作为优化大模型训练动态的可靠代理，显著减少超参数搜索成本。

Conclusion: 该工作为选择最优退火策略提供了实用指导，证明了训练动态的可迁移性，使研究人员能够更高效地优化大语言模型的学习率调度，而无需进行耗尽的超参数搜索。

Abstract: Learning rate scheduling is crucial for training large language models, yet understanding the optimal annealing strategies across different model configurations remains challenging. In this work, we investigate the transferability of annealing dynamics in large language model training and refine a generalized predictive framework for optimizing annealing strategies under the Warmup-Steady-Decay (WSD) scheduler. Our improved framework incorporates training steps, maximum learning rate, and annealing behavior, enabling more efficient optimization of learning rate schedules. Our work provides a practical guidance for selecting optimal annealing strategies without exhaustive hyperparameter searches, demonstrating that smaller models can serve as reliable proxies for optimizing the training dynamics of larger models. We validate our findings on extensive experiments using both Dense and Mixture-of-Experts (MoE) models, demonstrating that optimal annealing ratios follow consistent patterns and can be transferred across different training configurations.

</details>


### [77] [Mitigating Catastrophic Forgetting in Mathematical Reasoning Finetuning through Mixed Training](https://arxiv.org/abs/2512.13706)
*John Graham Reynolds*

Main category: cs.LG

TL;DR: 研究微调大语言模型时发现数学推理训练会导致灾难性遗忘，提出混合训练策略可完全消除遗忘同时保持数学性能


<details>
  <summary>Details</summary>
Motivation: 当微调大语言模型进行数学推理等专门任务时，模型会出现灾难性遗忘，丧失先前学习的能力。研究者希望探索如何在保持专业能力的同时避免遗忘通用能力。

Method: 在Flan-T5-Base模型上进行实验，首先进行纯数学训练（DeepMind Mathematics数据集），然后提出混合训练策略，在训练中交错使用数学和NLI（MultiNLI）示例，系统探索从1:1到15:1的不同混合比例。

Result: 纯数学训练将数学准确率从3.1%提升到12.0%，但NLI准确率从81.0%暴跌至16.5%（下降64.5个百分点）。混合训练完全消除了灾难性遗忘：1:1比例达到12.0%数学准确率（与纯数学训练相当），同时保持86.2%的NLI准确率。即使少量NLI示例（6.2%）也能提供有效的正则化效果。

Conclusion: 专业化训练不一定需要遗忘通用能力，混合训练策略可以完全消除灾难性遗忘同时保持专业性能。这一发现对扩展到更大模型具有重要意义，混合训练可能带来超越遗忘预防的额外好处。

Abstract: When finetuning large language models for specialized tasks such as mathematical reasoning, models exhibit catastrophic forgetting, losing previously learned capabilities. We investigate this by finetuning Flan-T5-Base (250M parameters) on the DeepMind Mathematics dataset and measuring forgetting on MultiNLI. Math-only training improves mathematical accuracy from 3.1\% to 12.0\% but causes NLI accuracy to collapse from 81.0\% to 16.5\%--a 64.5 percentage point drop occurring within the first 1,000 training steps. We propose mixed training strategies that interleave mathematical and NLI examples during training. Our results demonstrate that mixed training completely eliminates catastrophic forgetting while maintaining equivalent mathematical performance: the balanced 1:1 ratio achieves 12.0\% math accuracy (matching math-only) while preserving 86.2\% NLI accuracy. We systematically explore mixing ratios from 1:1 to 15:1, finding that even minimal NLI exposure (6.2\%) provides effective regularization. These findings demonstrate that specialization need not require forgetting general capabilities, with implications for scaling to larger models where mixed training may confer additional benefits beyond forgetting prevention.

</details>


### [78] [Variational Physics-Informed Ansatz for Reconstructing Hidden Interaction Networks from Steady States](https://arxiv.org/abs/2512.13708)
*Kaiming Luo*

Main category: cs.LG

TL;DR: VPIA方法从异构稳态数据中推断复杂系统的相互作用结构，无需时间轨迹或导数估计，能准确恢复有向、加权和多体网络结构。


<details>
  <summary>Details</summary>
Motivation: 现有重构方法难以处理非线性、异构和高阶耦合的系统，特别是在只能观测到稳态数据的情况下。需要一种能从稳态数据直接推断一般相互作用算子的方法。

Method: 提出变分物理信息基函数（VPIA），将动力学的稳态约束嵌入到可微分的变分表示中，通过最小化物理导出的稳态残差来重构底层耦合，无需时间轨迹、导数估计或监督。结合残差采样和自然梯度优化实现大规模高阶网络的可扩展学习。

Result: 在多种非线性系统中，VPIA能够准确恢复有向、加权和多体结构，即使在存在显著噪声的情况下也能稳健工作，为仅能获得快照观测的复杂相互作用网络推断提供了统一框架。

Conclusion: VPIA为仅能获得稳态观测的复杂系统相互作用结构推断提供了一个统一且稳健的物理约束框架，能够处理非线性、异构和高阶耦合的挑战性问题。

Abstract: The interaction structure of a complex dynamical system governs its collective behavior, yet existing reconstruction methods struggle with nonlinear, heterogeneous, and higher-order couplings, especially when only steady states are observable. We propose a Variational Physics-Informed Ansatz (VPIA) that infers general interaction operators directly from heterogeneous steady-state data. VPIA embeds the steady-state constraints of the dynamics into a differentiable variational representation and reconstructs the underlying couplings by minimizing a physics-derived steady-state residual, without requiring temporal trajectories, derivative estimation, or supervision. Residual sampling combined with natural-gradient optimization enables scalable learning of large and higher-order networks. Across diverse nonlinear systems, VPIA accurately recovers directed, weighted, and multi-body structures under substantial noise, providing a unified and robust framework for physics-constrained inference of complex interaction networks in settings where only snapshot observations are available.

</details>


### [79] [Predictive Modeling of Flood-Prone Areas Using SAR and Environmental Variables](https://arxiv.org/abs/2512.13710)
*Edwin Oluoch Awino,Denis Machanda*

Main category: cs.LG

TL;DR: 该研究结合SAR影像与环境水文数据，使用机器学习模型评估肯尼亚Nyando河流域洪水易发性，发现随机森林模型表现最佳，识别出维多利亚湖附近低洼地区为高风险区。


<details>
  <summary>Details</summary>
Motivation: 洪水是全球最具破坏性的自然灾害之一，对生态系统、基础设施和人类生计构成严重威胁。在数据有限的地区，需要开发有效的洪水易发性评估方法，以支持灾害风险管理和土地利用规划。

Method: 研究结合Sentinel-1双极化SAR影像（2024年5月洪水事件）与环境水文数据，生成二元洪水清单作为训练数据。整合六个条件因子（坡度、高程、坡向、土地利用/土地覆盖、土壤类型、距河流距离），使用四种监督分类器（逻辑回归、分类回归树、支持向量机、随机森林）进行建模，并通过准确性、Cohen's Kappa和ROC分析评估模型性能。

Result: 随机森林模型表现最佳（准确性=0.762；Kappa=0.480），优于其他三种模型。基于随机森林的易发性地图显示，维多利亚湖附近的Kano平原低洼地区洪水易发性最高，这与历史洪水记录和2024年5月洪水事件的影响一致。

Conclusion: 研究表明，在数据有限的地区，结合SAR数据和集成机器学习方法进行洪水易发性制图具有重要价值。生成的易发性地图为灾害风险减少、土地利用规划和早期预警系统开发提供了重要见解。

Abstract: Flooding is one of the most destructive natural hazards worldwide, posing serious risks to ecosystems, infrastructure, and human livelihoods. This study combines Synthetic Aperture Radar (SAR) imagery with environmental and hydrological data to model flood susceptibility in the River Nyando watershed, western Kenya. Sentinel-1 dual-polarization SAR data from the May 2024 flood event were processed to produce a binary flood inventory, which served as training data for machine learning (ML) models. Six conditioning factors -- slope, elevation, aspect, land use/land cover, soil type, and distance from streams -- were integrated with the SAR-derived flood inventory to train four supervised classifiers: Logistic Regression (LR), Classification and Regression Trees (CART), Support Vector Machines (SVM), and Random Forest (RF). Model performance was assessed using accuracy, Cohen's Kappa, and Receiver Operating Characteristic (ROC) analysis. Results indicate that RF achieved the highest predictive performance (accuracy = 0.762; Kappa = 0.480), outperforming LR, CART, and SVM. The RF-based susceptibility map showed that low-lying Kano Plains near Lake Victoria have the highest flood vulnerability, consistent with historical flood records and the impacts of the May 2024 event. These findings demonstrate the value of combining SAR data and ensemble ML methods for flood susceptibility mapping in regions with limited data. The resulting maps offer important insights for disaster risk reduction, land-use planning, and early warning system development.

</details>


### [80] [Delete and Retain: Efficient Unlearning for Document Classification](https://arxiv.org/abs/2512.13711)
*Aadya Goel,Mayuri Sridhar*

Main category: cs.LG

TL;DR: 本文提出Hessian Reassignment方法，用于文档分类器的类别级遗忘，通过两步法高效移除目标类别的影响，同时保持其他类别准确性。


<details>
  <summary>Details</summary>
Motivation: 机器学习遗忘旨在高效移除特定训练数据对模型的影响而无需完全重新训练。虽然LLMs的遗忘研究已有进展，但文档分类模型的遗忘研究相对不足。本文研究文档分类器的类别级遗忘问题。

Method: 提出Hessian Reassignment方法：1）通过求解Hessian-向量系统进行单次影响式更新，减去目标类别所有训练点的影响；2）通过Top-1分类强制执行决策空间保证，而非随机重新分类已删除类别样本。

Result: 在标准文本基准测试中，Hessian Reassignment在保持接近完整重新训练（不含目标类别）的准确性的同时，运行速度快数个数量级。同时，通过池化多影子攻击测量，该方法持续降低移除类别的成员推理优势。

Conclusion: 这些结果表明了在文档分类中实现高效类别遗忘的实用且有原则的路径，为文档分类模型提供了有效的遗忘解决方案。

Abstract: Machine unlearning aims to efficiently remove the influence of specific training data from a model without full retraining. While much progress has been made in unlearning for LLMs, document classification models remain relatively understudied. In this paper, we study class-level unlearning for document classifiers and present Hessian Reassignment, a two-step, model-agnostic solution. First, we perform a single influence-style update that subtracts the contribution of all training points from the target class by solving a Hessian-vector system with conjugate gradients, requiring only gradient and Hessian-vector products. Second, in contrast to common unlearning baselines that randomly reclassify deleted-class samples, we enforce a decision-space guarantee via Top-1 classification. On standard text benchmarks, Hessian Reassignment achieves retained-class accuracy close to full retrain-without-class while running orders of magnitude faster. Additionally, it consistently lowers membership-inference advantage on the removed class, measured with pooled multi-shadow attacks. These results demonstrate a practical, principled path to efficient class unlearning in document classification.

</details>


### [81] [Prediction of Respiratory Syncytial Virus-Associated Hospitalizations Using Machine Learning Models Based on Environmental Data](https://arxiv.org/abs/2512.13712)
*Eric Guo*

Main category: cs.LG

TL;DR: 开发机器学习框架，整合废水监测、气象和空气质量数据预测美国RSV相关住院率，识别废水RSV水平为最强预测因子，发现原住民和阿拉斯加原住民住院率显著更高，高海拔地区住院率更高，并开发交互式仪表板用于公共卫生干预。


<details>
  <summary>Details</summary>
Motivation: RSV是导致幼儿住院的主要原因，其暴发受环境条件强烈影响。需要开发预测工具来改善公共卫生干预和资源分配，特别是考虑到不同人群的RSV相关住院率存在显著差异。

Method: 整合每周住院率、废水RSV水平、每日气象测量和空气污染物浓度数据，使用CART、随机森林和提升等分类模型，预测RSV相关住院率（分为低风险、警报和流行三个等级）。

Result: 废水RSV水平被确定为最强预测因子，其次是温度、臭氧水平和比湿度等气象和空气质量变量。发现原住民和阿拉斯加原住民RSV相关住院率显著更高，高海拔地区（表面压力较低）住院率持续较高。

Conclusion: 结合环境和社区监测数据对预测RSV暴发具有重要价值，有助于更及时的公共卫生干预和资源分配。开发了交互式R Shiny仪表板，使模型可访问且实用，支持用户探索不同州的RSV风险水平并生成预测。

Abstract: Respiratory syncytial virus (RSV) is a leading cause of hospitalization among young children, with outbreaks strongly influenced by environmental conditions. This study developed a machine learning framework to predict RSV-associated hospitalizations in the United States (U.S.) by integrating wastewater surveillance, meteorological, and air quality data. The dataset combined weekly hospitalization rates, wastewater RSV levels, daily meteorological measurements, and air pollutant concentrations. Classification models, including CART, Random Forest, and Boosting, were trained to predict weekly RSV-associated hospitalization rates classified as \textit{Low risk}, \textit{Alert}, and \textit{Epidemic} levels. The wastewater RSV level was identified as the strongest predictor, followed by meteorological and air quality variables such as temperature, ozone levels, and specific humidity. Notably, the analysis also revealed significantly higher RSV-associated hospitalization rates among Native Americans and Alaska Natives. Further research is needed to better understand the drivers of RSV disparity in these communities to improve prevention strategies. Furthermore, states at high altitudes, characterized by lower surface pressure, showed consistently higher RSV-associated hospitalization rates. These findings highlight the value of combining environmental and community surveillance data to forecast RSV outbreaks, enabling more timely public health interventions and resource allocation. In order to provide accessibility and practical use of the models, we have developed an interactive R Shiny dashboard (https://f6yxlu-eric-guo.shinyapps.io/rsv_app/), which allows users to explore RSV-associated hospitalization risk levels across different states, visualize the impact of key predictors, and interactively generate RSV outbreak forecasts.

</details>


### [82] [Federated Few-Shot Learning for Epileptic Seizure Detection Under Privacy Constraints](https://arxiv.org/abs/2512.13717)
*Ekaterina Sysoykova,Bernhard Anzengruber-Tanase,Michael Haslgrubler,Philipp Seidl,Alois Ferscha*

Main category: cs.LG

TL;DR: 提出两阶段联邦少样本学习框架，用于个性化EEG癫痫检测，解决临床数据稀缺、分布不均和隐私限制问题。


<details>
  <summary>Details</summary>
Motivation: 临床实践中EEG数据稀缺、分散在不同机构、受隐私法规限制无法集中，导致基于AI的癫痫检测模型难以在实际医疗环境中应用。

Method: 两阶段框架：第一阶段使用联邦学习在非IID模拟医院站点上微调预训练的BIOT模型；第二阶段通过联邦少样本个性化，仅用5个标记EEG片段为每个患者适配分类器。

Result: 联邦微调获得平衡准确率0.43（集中式0.52）；FFSL阶段客户端特定模型平均平衡准确率达0.77，Cohen's kappa 0.62，加权F1 0.73，在异质事件分布的四个站点表现良好。

Conclusion: FFSL框架能够在现实数据可用性和隐私约束下支持有效的患者自适应癫痫检测，为临床实践提供可行解决方案。

Abstract: Many deep learning approaches have been developed for EEG-based seizure detection; however, most rely on access to large centralized annotated datasets. In clinical practice, EEG data are often scarce, patient-specific distributed across institutions, and governed by strict privacy regulations that prohibit data pooling. As a result, creating usable AI-based seizure detection models remains challenging in real-world medical settings. To address these constraints, we propose a two-stage federated few-shot learning (FFSL) framework for personalized EEG-based seizure detection. The method is trained and evaluated on the TUH Event Corpus, which includes six EEG event classes. In Stage 1, a pretrained biosignal transformer (BIOT) is fine-tuned across non-IID simulated hospital sites using federated learning, enabling shared representation learning without centralizing EEG recordings. In Stage 2, federated few-shot personalization adapts the classifier to each patient using only five labeled EEG segments, retaining seizure-specific information while still benefiting from cross-site knowledge. Federated fine-tuning achieved a balanced accuracy of 0.43 (centralized: 0.52), Cohen's kappa of 0.42 (0.49), and weighted F1 of 0.69 (0.74). In the FFSL stage, client-specific models reached an average balanced accuracy of 0.77, Cohen's kappa of 0.62, and weighted F1 of 0.73 across four sites with heterogeneous event distributions. These results suggest that FFSL can support effective patient-adaptive seizure detection under realistic data-availability and privacy constraints.

</details>


### [83] [Time-Constrained Recommendations: Reinforcement Learning Strategies for E-Commerce](https://arxiv.org/abs/2512.13726)
*Sayak Chakrabarty,Souradip Pal*

Main category: cs.LG

TL;DR: 论文提出在有限时间预算约束下的推荐系统问题，使用强化学习同时学习用户偏好和时间预算模式，在电商场景中优化推荐列表以提升用户参与度。


<details>
  <summary>Details</summary>
Motivation: 传统推荐任务忽略了用户时间预算这一关键资源约束。在移动购物等场景中，用户评估每个推荐项目都需要时间成本，高相关性的项目可能因评估成本过高而无法在有限时间内被用户接受，从而影响用户参与度。

Method: 1) 将时间约束的推荐列表问题建模为具有预算感知效用的马尔可夫决策过程；2) 开发模拟框架研究重排序数据上的策略行为；3) 在阿里巴巴个性化重排序数据集上实验，比较在线策略和离线策略强化学习方法与传统上下文多臂老虎机方法。

Result: 实验表明，在严格时间预算约束下，在线策略和离线策略强化学习方法相比传统的上下文多臂老虎机方法能够显著提升推荐性能，更好地平衡项目相关性和评估成本。

Conclusion: 强化学习能够有效处理时间约束的推荐列表优化问题，通过学习用户偏好和时间预算的联合模式，在资源受限条件下生成具有更高参与潜力的推荐，为实际电商应用提供了有前景的解决方案。

Abstract: Unlike traditional recommendation tasks, finite user time budgets introduce a critical resource constraint, requiring the recommender system to balance item relevance and evaluation cost. For example, in a mobile shopping interface, users interact with recommendations by scrolling, where each scroll triggers a list of items called slate. Users incur an evaluation cost - time spent assessing item features before deciding to click. Highly relevant items having higher evaluation costs may not fit within the user's time budget, affecting engagement. In this position paper, our objective is to evaluate reinforcement learning algorithms that learn patterns in user preferences and time budgets simultaneously, crafting recommendations with higher engagement potential under resource constraints. Our experiments explore the use of reinforcement learning to recommend items for users using Alibaba's Personalized Re-ranking dataset supporting slate optimization in e-commerce contexts. Our contributions include (i) a unified formulation of time-constrained slate recommendation modeled as Markov Decision Processes (MDPs) with budget-aware utilities; (ii) a simulation framework to study policy behavior on re-ranking data; and (iii) empirical evidence that on-policy and off-policy control can improve performance under tight time budgets than traditional contextual bandit-based methods.

</details>


### [84] [RAST-MoE-RL: A Regime-Aware Spatio-Temporal MoE Framework for Deep Reinforcement Learning in Ride-Hailing](https://arxiv.org/abs/2512.13727)
*Yuhan Tang,Kangxin Cui,Jung Ho Park,Yibo Zhao,Xuan Jiang,Haoze He,Dingyi Zhuang,Shenhao Wang,Jiangbo Yu,Haris Koutsopoulos,Jinhua Zhao*

Main category: cs.LG

TL;DR: 提出RAST-MoE框架，使用专家混合自注意力编码器解决网约车平台的动态延迟匹配问题，在真实Uber数据上显著降低匹配和接驾延迟。


<details>
  <summary>Details</summary>
Motivation: 网约车平台需要在高度不确定的供需条件下平衡乘客等待时间和系统效率。现有强化学习方法往往过度简化交通动态或使用浅层编码器，无法捕捉复杂的时空模式。

Method: 提出Regime-Aware Spatio-Temporal Mixture-of-Experts (RAST-MoE)框架，将自适应延迟匹配形式化为制度感知MDP，使用自注意力专家混合编码器。专家自动专业化，提高表示能力同时保持计算效率。引入物理信息拥堵代理模型实现高效仿真，自适应奖励方案防止病态策略。

Result: 仅用1200万参数，在真实Uber轨迹数据（旧金山）上，总奖励提升超过13%，平均匹配延迟降低10%，接驾延迟降低15%。在不同需求制度下表现出鲁棒性和稳定训练。

Conclusion: RAST-MoE框架展示了专家混合增强的强化学习在处理复杂时空动态的大规模决策问题中的潜力，为网约车平台的动态匹配提供了有效解决方案。

Abstract: Ride-hailing platforms face the challenge of balancing passenger waiting times with overall system efficiency under highly uncertain supply-demand conditions. Adaptive delayed matching creates a trade-off between matching and pickup delays by deciding whether to assign drivers immediately or batch requests. Since outcomes accumulate over long horizons with stochastic dynamics, reinforcement learning (RL) is a suitable framework. However, existing approaches often oversimplify traffic dynamics or use shallow encoders that miss complex spatiotemporal patterns.
  We introduce the Regime-Aware Spatio-Temporal Mixture-of-Experts (RAST-MoE), which formalizes adaptive delayed matching as a regime-aware MDP equipped with a self-attention MoE encoder. Unlike monolithic networks, our experts specialize automatically, improving representation capacity while maintaining computational efficiency. A physics-informed congestion surrogate preserves realistic density-speed feedback, enabling millions of efficient rollouts, while an adaptive reward scheme guards against pathological strategies.
  With only 12M parameters, our framework outperforms strong baselines. On real-world Uber trajectory data (San Francisco), it improves total reward by over 13%, reducing average matching and pickup delays by 10% and 15% respectively. It demonstrates robustness across unseen demand regimes and stable training. These findings highlight the potential of MoE-enhanced RL for large-scale decision-making with complex spatiotemporal dynamics.

</details>


### [85] [CurvaDion: Curvature-Adaptive Distributed Orthonormalization](https://arxiv.org/abs/2512.13728)
*Bhavesh Kumar,Roger Jin,Jeffrey Quesnelle*

Main category: cs.LG

TL;DR: CurvaDion通过检测高曲率区域来动态调整梯度同步频率，在保持收敛性的同时减少99%的通信开销


<details>
  <summary>Details</summary>
Motivation: 随着语言模型参数规模达到万亿级别，分布式训练中的梯度同步成为关键瓶颈。现有方法如Dion虽然通过低秩更新减少通信，但每步都同步，忽略了优化过程中不同区域对同步需求的变化：平坦区域梯度相似，频繁同步冗余；高曲率区域则需要协调防止发散。

Method: 提出CurvaDion方法，使用相对最大动量变化(RMMC)来检测需要同步的高曲率区域。RMMC利用优化过程中已计算的动量动态作为方向曲率的计算可行代理，每层仅增加O(d)操作。建立了RMMC与损失曲率的理论联系。

Result: 在160M到1.3B参数的模型上，CurvaDion实现了99%的通信减少，同时匹配基线收敛性能。

Conclusion: 通过动态检测高曲率区域来调整同步频率，CurvaDion显著减少了分布式训练的通信开销，同时保持了模型收敛性，为大规模语言模型训练提供了高效的通信优化方案。

Abstract: As language models scale to trillions of parameters, distributed training across many GPUs becomes essential, yet gradient synchronization over high-bandwidth, low-latency networks remains a critical bottleneck. While recent methods like Dion reduce per-step communication through low-rank updates, they synchronize at every step regardless of the optimization landscape. We observe that synchronization requirements vary dramatically throughout training: workers naturally compute similar gradients in flat regions, making frequent synchronization redundant, while high-curvature regions require coordination to prevent divergence. We introduce CurvaDion, which uses Relative Maximum Momentum Change (RMMC) to detect high-curvature regions requiring synchronization. RMMC leverages momentum dynamics which are already computed during optimization as a computationally tractable proxy for directional curvature, adding only $\mathcal{O}(d)$ operations per layer. We establish theoretical connections between RMMC and loss curvature and demonstrate that CurvaDion achieves 99\% communication reduction while matching baseline convergence across models from 160M to 1.3B parameters.

</details>


### [86] [Composite Classifier-Free Guidance for Multi-Modal Conditioning in Wind Dynamics Super-Resolution](https://arxiv.org/abs/2512.13729)
*Jacob Schnell,Aditya Makkar,Gunadi Gani,Aniket Srinivasan Ashok,Darren Lo,Mike Optis,Alexander Wong,Yuhao Chen*

Main category: cs.LG

TL;DR: 提出CCFG（复合分类器自由引导）方法改进多条件输入的风数据超分辨率扩散模型，开发WindDM模型实现高保真、低成本的风数据重建


<details>
  <summary>Details</summary>
Motivation: 高分辨率风数据获取成本高且困难，传统方法无法同时实现成本效益和准确性，现有深度学习方法在处理多通道风数据时效果有限

Method: 提出CCFG（复合分类器自由引导）方法，扩展标准CFG以处理多个条件输入，开发WindDM扩散模型用于工业级风动力学重建

Result: CCFG比标准CFG产生更高保真度的输出，WindDM在深度学习模型中达到最先进的重建质量，成本比传统方法低1000倍

Conclusion: CCFG方法有效解决了多条件输入扩散模型的引导问题，WindDM为工业规模风数据重建提供了高效且经济的解决方案

Abstract: Various weather modelling problems (e.g., weather forecasting, optimizing turbine placements, etc.) require ample access to high-resolution, highly accurate wind data. Acquiring such high-resolution wind data, however, remains a challenging and expensive endeavour. Traditional reconstruction approaches are typically either cost-effective or accurate, but not both. Deep learning methods, including diffusion models, have been proposed to resolve this trade-off by leveraging advances in natural image super-resolution. Wind data, however, is distinct from natural images, and wind super-resolvers often use upwards of 10 input channels, significantly more than the usual 3-channel RGB inputs in natural images. To better leverage a large number of conditioning variables in diffusion models, we present a generalization of classifier-free guidance (CFG) to multiple conditioning inputs. Our novel composite classifier-free guidance (CCFG) can be dropped into any pre-trained diffusion model trained with standard CFG dropout. We demonstrate that CCFG outputs are higher-fidelity than those from CFG on wind super-resolution tasks. We present WindDM, a diffusion model trained for industrial-scale wind dynamics reconstruction and leveraging CCFG. WindDM achieves state-of-the-art reconstruction quality among deep learning models and costs up to $1000\times$ less than classical methods.

</details>


### [87] [PIS: A Generalized Physical Inversion Solver for Arbitrary Sparse Observations via Set-Conditioned Diffusion](https://arxiv.org/abs/2512.13732)
*Weijie Yang,Xun Zhang*

Main category: cs.LG

TL;DR: PIS是一个基于集合条件扩散的物理反演框架，能够在任意稀疏观测下稳定求解PDE约束参数反问题，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: PDE约束的物理参数反演在稀疏、不规则观测下本质上是病态的，现有深度学习和算子学习方法在极端稀疏条件下失效，缺乏鲁棒性和不确定性量化能力。

Method: 提出物理反演求解器(PIS)：1) 使用基于Set Transformer的编码器处理任意数量和几何的观测；2) 采用余弦退火稀疏课程实现卓越鲁棒性；3) 基于信息论分析揭示极端稀疏下的反演极限。

Result: 在Darcy流、Helmholtz波场反演和结构健康监测三个PDE反问题上，PIS在包括0.29%观测率的极端稀疏条件下保持稳定准确，反演误差降低12.28%-88.73%，并能生成校准的后验样本。

Conclusion: PIS是一个强大、通用且对稀疏性具有独特韧性的物理反演解决方案，能够在任意严重欠采样观测下可靠工作，为实际应用提供了实用工具。

Abstract: Estimation of PDE-constrained physical parameters from limited indirect measurements is inherently ill-posed, particularly when observations are sparse, irregular, and constrained by real-world sensor placement. This challenge is ubiquitous in fields such as fluid mechanics, seismic inversion, and structural health monitoring. Existing deep and operator-learning models collapse under these conditions: fixed-grid assumptions fail, reconstruction deteriorates sharply, and inversion becomes unreliable with limited robustness and no uncertainty quantification (UQ).We propose the Physical Inversion Solver (PIS), a set-conditioned diffusion framework enabling inversion from truly arbitrary observation sets. PIS employs a Set Transformer-based encoder to handle measurements of any number or geometry, and a cosine-annealed sparsity curriculum for exceptional robustness. An accompanying information-theoretic analysis provides insight into the limits of inversion under extreme sparsity by revealing how observation entropy varies across physical systems.PIS is evaluated on three challenging PDE inverse problems: Darcy flow, wavefield inversion (Helmholtz), and structural health monitoring (Hooke's Law). Across all tasks and sparsity regimes -- including extreme cases with an observation rate of only $0.29\%$ -- existing operator-learning baselines fail to reconstruct meaningful fields, often diverging or collapsing entirely.In stark contrast, PIS remains stable and accurate, reducing inversion error by $12.28\%$--$88.73\%$ and reliably producing calibrated posterior samples. These samples accurately reflect both data scarcity and intrinsic physical ambiguity. These results position PIS as a powerful, general-purpose, and uniquely sparsity-resilient solution for physical inversion under arbitrary and severely undersampled observations.

</details>


### [88] [Low-Rank Compression of Language Models via Differentiable Rank Selection](https://arxiv.org/abs/2512.13733)
*Sidhant Sundrani,Francesco Tudisco,Pasquale Minervini*

Main category: cs.LG

TL;DR: 提出LLRC方法，通过梯度学习掩码权重来选择奇异值，在无需微调的情况下优化大语言模型低秩压缩的秩选择问题


<details>
  <summary>Details</summary>
Motivation: 现有低秩压缩方法在秩选择上存在局限：启发式方法搜索空间有限导致次优结果，梯度方法在无微调时性能不如启发式方法。需要一种无需微调就能联合优化压缩率和下游任务准确率的秩选择方法

Method: 提出LLRC（Learning to Low-Rank Compress），基于梯度的方法，直接学习选择奇异值的掩码权重。使用校准数据集仅训练掩码权重，在减少奇异值的同时最小化中间激活与原始模型的差异

Result: 在无需微调的情况下，LLRC在常识推理和开放域问答任务上优于其他秩选择方法。在Llama-2-13B 20%压缩率下，在MMLU、BoolQ和OpenbookQA上分别比STRS高出12%、3.5%和4.4%。与SVD-LLM和LLM-Pruner的无微调变体相比，在各种数据集和压缩率下表现更优，且与LLM-Pruner的微调变体性能相当

Conclusion: LLRC提供了一种有效的无需微调的低秩压缩方法，通过梯度学习掩码权重优化秩选择，在保持性能的同时实现更好的压缩效果

Abstract: Approaches for compressing large-language models using low-rank decomposition have made strides, particularly with the introduction of activation and loss-aware SVD, which improves the trade-off between decomposition rank and downstream task performance. Despite these advancements, a persistent challenge remains--selecting the optimal ranks for each layer to jointly optimise compression rate and downstream task accuracy. Current methods either rely on heuristics that can yield sub-optimal results due to their limited discrete search space or are gradient-based but are not as performant as heuristic approaches without post-compression fine-tuning. To address these issues, we propose Learning to Low-Rank Compress (LLRC), a gradient-based approach which directly learns the weights of masks that select singular values in a fine-tuning-free setting. Using a calibration dataset, we train only the mask weights to select fewer and fewer singular values while minimising the divergence of intermediate activations from the original model. Our approach outperforms competing ranking selection methods that similarly require no post-compression fine-tuning across various compression rates on common-sense reasoning and open-domain question-answering tasks. For instance, with a compression rate of 20% on Llama-2-13B, LLRC outperforms the competitive Sensitivity-based Truncation Rank Searching (STRS) on MMLU, BoolQ, and OpenbookQA by 12%, 3.5%, and 4.4%, respectively. Compared to other compression techniques, our approach consistently outperforms fine-tuning-free variants of SVD-LLM and LLM-Pruner across datasets and compression rates. Our fine-tuning-free approach also performs competitively with the fine-tuning variant of LLM-Pruner.

</details>


### [89] [Plug-and-Play Parameter-Efficient Tuning of Embeddings for Federated Recommendation](https://arxiv.org/abs/2512.13734)
*Haochen Yuan,Yang Zhang,Xiang He,Quan Z. Sheng,Zhongjie Wang*

Main category: cs.LG

TL;DR: 提出一个基于参数高效微调（PEFT）的联邦推荐框架，通过减少嵌入参数传输量来提升通信效率，同时保持推荐准确性。


<details>
  <summary>Details</summary>
Motivation: 联邦推荐系统在分布式环境中训练时，由于大规模物品嵌入参数导致通信效率低下，现有研究主要关注模型效率而忽视了嵌入参数开销问题。

Method: 提出一个基于PEFT的联邦推荐训练框架，采用LoRA、哈希编码等常见PEFT技术，并探索使用残差量化变分自编码器（RQ-VAE）作为新的PEFT策略，提供轻量级插件式解决方案。

Result: 在不同联邦推荐模型和数据集上的实验表明，该框架显著降低了通信开销，同时提高了推荐准确性。

Conclusion: 提出的基于PEFT的联邦推荐框架有效解决了嵌入参数传输效率问题，为现有联邦推荐方法提供了可无缝集成的轻量级解决方案。

Abstract: With the rise of cloud-edge collaboration, recommendation services are increasingly trained in distributed environments. Federated Recommendation (FR) enables such multi-end collaborative training while preserving privacy by sharing model parameters instead of raw data. However, the large number of parameters, primarily due to the massive item embeddings, significantly hampers communication efficiency. While existing studies mainly focus on improving the efficiency of FR models, they largely overlook the issue of embedding parameter overhead. To address this gap, we propose a FR training framework with Parameter-Efficient Fine-Tuning (PEFT) based embedding designed to reduce the volume of embedding parameters that need to be transmitted. Our approach offers a lightweight, plugin-style solution that can be seamlessly integrated into existing FR methods. In addition to incorporating common PEFT techniques such as LoRA and Hash-based encoding, we explore the use of Residual Quantized Variational Autoencoders (RQ-VAE) as a novel PEFT strategy within our framework. Extensive experiments across various FR model backbones and datasets demonstrate that our framework significantly reduces communication overhead while improving accuracy. The source code is available at https://github.com/young1010/FedPEFT.

</details>


### [90] [DARTs: A Dual-Path Robust Framework for Anomaly Detection in High-Dimensional Multivariate Time Series](https://arxiv.org/abs/2512.13735)
*Xuechun Liu,Heli Sun,Xuecheng Wu,Ruichen Cao,Yunyun Shi,Dingkang Yang,Haoran Li*

Main category: cs.LG

TL;DR: DARTs是一个用于高维多变量时间序列异常检测的鲁棒性长短时双路径框架，通过窗口感知的时空软融合机制有效处理噪声并捕获长距离时空依赖关系。


<details>
  <summary>Details</summary>
Motivation: 现有方法在低维场景下能识别明显异常模式，但在处理高维噪声时间序列时难以鲁棒地捕获长距离时空依赖关系，这限制了工业控制系统中的异常检测性能。

Method: 提出DARTs框架，包含三个互补组件：1) 短时路径中的多视图稀疏图学习器和扩散多关系图单元，用于自适应捕获高噪声时间序列中的分层判别性短时时空模式；2) 长时路径中的多尺度时空图构造器，用于建模高维表示空间中的显著长时动态；3) 窗口感知时空软融合机制，用于过滤残留噪声并无缝整合异常模式。

Result: 在主流数据集上的大量定性和定量实验结果表明，DARTs具有优越性和鲁棒性。消融研究也验证了所提出组件关键设计因素的重要性。

Conclusion: DARTs通过长短时双路径框架和窗口感知软融合机制，有效解决了高维噪声时间序列中长距离时空依赖关系的建模问题，在多变量时间序列异常检测任务中表现出色。

Abstract: Multivariate time series anomaly detection (MTSAD) aims to accurately identify and localize complex abnormal patterns in the large-scale industrial control systems. While existing approaches excel in recognizing the distinct patterns under the low-dimensional scenarios, they often fail to robustly capture long-range spatiotemporal dependencies when learning representations from the high-dimensional noisy time series. To address these limitations, we propose DARTs, a robust long short-term dual-path framework with window-aware spatiotemporal soft fusion mechanism, which can be primarily decomposed into three complementary components. Specifically, in the short-term path, we introduce a Multi-View Sparse Graph Learner and a Diffusion Multi-Relation Graph Unit that collaborate to adaptively capture hierarchical discriminative short-term spatiotemporal patterns in the high-noise time series. While in the long-term path, we design a Multi-Scale Spatiotemporal Graph Constructor to model salient long-term dynamics within the high-dimensional representation space. Finally, a window-aware spatiotemporal soft-fusion mechanism is introduced to filter the residual noise while seamlessly integrating anomalous patterns. Extensive qualitative and quantitative experimental results across mainstream datasets demonstrate the superiority and robustness of our proposed DARTs. A series of ablation studies are also conducted to explore the crucial design factors of our proposed components. Our code and model will be made publicly open soon.

</details>


### [91] [TF-MCL: Time-frequency Fusion and Multi-domain Cross-Loss for Self-supervised Depression Detection](https://arxiv.org/abs/2512.13736)
*Li-Xuan Zhao,Chen-Yang Xu,Wen-Qiang Li,Bo Wang,Rong-Xing Wei,Qing-Hao Menga*

Main category: cs.LG

TL;DR: 提出TF-MCL模型，通过时间-频率融合和多域交叉损失改进抑郁症脑电检测，在两个公开数据集上显著超越现有最佳方法。


<details>
  <summary>Details</summary>
Motivation: 现有抑郁症脑电检测方法依赖标注数据，而标注困难；对比学习虽能缓解标注依赖，但现有方法未能有效表征脑电信号的时频特性，低语义数据表示能力不足。

Method: 提出时间-频率融合和多域交叉损失模型：1) 使用融合映射头生成时频混合表示，将时频域信息重映射到融合域；2) 优化多域交叉损失函数，重构时频域和融合域的表示分布。

Result: 在MODMA和PRED+CT数据集上，准确率分别比现有最佳方法提升5.87%和9.96%，显著改进抑郁症检测性能。

Conclusion: TF-MCL模型通过时频融合和多域交叉损失，有效增强了脑电信号的时频信息综合能力，提升了抑郁症检测的准确率，为无监督/自监督抑郁症检测提供了有效解决方案。

Abstract: In recent years, there has been a notable increase in the use of supervised detection methods of major depressive disorder (MDD) based on electroencephalogram (EEG) signals. However, the process of labeling MDD remains challenging. As a self-supervised learning method, contrastive learning could address the shortcomings of supervised learning methods, which are unduly reliant on labels in the context of MDD detection. However, existing contrastive learning methods are not specifically designed to characterize the time-frequency distribution of EEG signals, and their capacity to acquire low-semantic data representations is still inadequate for MDD detection tasks. To address the problem of contrastive learning method, we propose a time-frequency fusion and multi-domain cross-loss (TF-MCL) model for MDD detection. TF-MCL generates time-frequency hybrid representations through the use of a fusion mapping head (FMH), which efficiently remaps time-frequency domain information to the fusion domain, and thus can effectively enhance the model's capacity to synthesize time-frequency information. Moreover, by optimizing the multi-domain cross-loss function, the distribution of the representations in the time-frequency domain and the fusion domain is reconstructed, thereby improving the model's capacity to acquire fusion representations. We evaluated the performance of our model on the publicly available datasets MODMA and PRED+CT and show a significant improvement in accuracy, outperforming the existing state-of-the-art (SOTA) method by 5.87% and 9.96%, respectively.

</details>


### [92] [The Laminar Flow Hypothesis: Detecting Jailbreaks via Semantic Turbulence in Large Language Models](https://arxiv.org/abs/2512.13741)
*Md. Hasib Ur Rahman*

Main category: cs.LG

TL;DR: 论文提出"层流假说"，认为良性输入在LLM潜在空间中产生平滑过渡，而对抗性提示会引发"语义湍流"（内部安全对齐与指令跟随目标冲突），并通过层间余弦速度方差这一零样本指标检测，实验证明其可作为轻量级越狱检测器及黑盒模型安全架构诊断工具。


<details>
  <summary>Details</summary>
Motivation: 当前LLM防御策略依赖计算昂贵的外部分类器或脆弱的词汇过滤器，忽略了模型推理过程的内在动态。需要一种更本质、轻量级的检测方法来应对日益严重的"越狱"攻击威胁。

Method: 提出"层流假说"，认为良性输入在LLM高维潜在空间中产生平滑渐变过渡，而对抗性提示会引发混沌、高方差的"语义湍流"。通过计算层间余弦速度方差作为零样本度量指标，量化这种内部冲突现象。

Result: 实验表明：RLHF对齐的Qwen2-1.5B在攻击下湍流增加75.4%（p<0.001），验证了内部冲突假说；而Gemma-2B的湍流减少22.0%，显示出不同的"反射式"拒绝机制。该指标能有效区分良性输入与对抗性提示。

Conclusion: 语义湍流不仅可作为轻量级、实时的越狱检测器，还能作为非侵入式诊断工具，用于分类黑盒模型的安全架构类型，为LLM安全防御提供了新视角。

Abstract: As Large Language Models (LLMs) become ubiquitous, the challenge of securing them against adversarial "jailbreaking" attacks has intensified. Current defense strategies often rely on computationally expensive external classifiers or brittle lexical filters, overlooking the intrinsic dynamics of the model's reasoning process. In this work, the Laminar Flow Hypothesis is introduced, which posits that benign inputs induce smooth, gradual transitions in an LLM's high-dimensional latent space, whereas adversarial prompts trigger chaotic, high-variance trajectories - termed Semantic Turbulence - resulting from the internal conflict between safety alignment and instruction-following objectives. This phenomenon is formalized through a novel, zero-shot metric: the variance of layer-wise cosine velocity. Experimental evaluation across diverse small language models reveals a striking diagnostic capability. The RLHF-aligned Qwen2-1.5B exhibits a statistically significant 75.4% increase in turbulence under attack (p less than 0.001), validating the hypothesis of internal conflict. Conversely, Gemma-2B displays a 22.0% decrease in turbulence, characterizing a distinct, low-entropy "reflex-based" refusal mechanism. These findings demonstrate that Semantic Turbulence serves not only as a lightweight, real-time jailbreak detector but also as a non-invasive diagnostic tool for categorizing the underlying safety architecture of black-box models.

</details>


### [93] [Comparative Evaluation of Embedding Representations for Financial News Sentiment Analysis](https://arxiv.org/abs/2512.13749)
*Joyjit Roy,Samaresh Kumar Singh*

Main category: cs.LG

TL;DR: 该研究比较了在数据稀缺环境下基于嵌入的金融新闻情感分析方法，发现预训练嵌入在小数据集上效果有限，验证集过小导致过拟合，模型表现甚至不如简单基线。


<details>
  <summary>Details</summary>
Motivation: 金融情感分析对市场理解很重要，但标准NLP方法在小数据集上遇到显著挑战。研究旨在评估在资源受限环境下，基于嵌入的方法在金融新闻情感分类中的表现。

Method: 使用Word2Vec、GloVe和句子转换器表示，结合梯度提升算法，在手动标注的新闻标题上进行评估。通过验证集和测试集性能比较，分析数据充足性阈值和验证集大小的影响。

Result: 实验结果显示验证集和测试集性能存在显著差距，模型表现甚至不如简单基线，尽管验证指标良好。预训练嵌入在低于关键数据充足阈值时收益递减，小验证集导致模型选择时过拟合。

Conclusion: 嵌入质量本身无法解决情感分类中的数据稀缺问题。对于资源有限的实践者，当标注样本稀缺时，需要考虑替代方法如少样本学习、数据增强或词典增强的混合方法。

Abstract: Financial sentiment analysis enhances market understanding; however, standard natural language processing approaches encounter significant challenges when applied to small datasets. This study provides a comparative evaluation of embedding-based methods for financial news sentiment classification in resource-constrained environments. Word2Vec, GloVe, and sentence transformer representations are evaluated in combination with gradient boosting on manually labeled headlines. Experimental results identify a substantial gap between validation and test performance, with models performing worse than trivial baselines despite strong validation metrics. The analysis demonstrates that pretrained embeddings yield diminishing returns below a critical data sufficiency threshold, and that small validation sets contribute to overfitting during model selection. Practical application is illustrated through weekly sentiment aggregation and narrative summarization for market monitoring workflows. The findings offer empirical evidence that embedding quality alone cannot address fundamental data scarcity in sentiment classification. For practitioners operating with limited resources, the results indicate the need to consider alternative approaches such as few-shot learning, data augmentation, or lexicon-enhanced hybrid methods when labeled samples are scarce.

</details>


### [94] [MIDUS: Memory-Infused Depth Up-Scaling](https://arxiv.org/abs/2512.13751)
*Taero Kim,Hoyoon Byun,Youngjun Choi,Sungrae Park,Kyungwoo Song*

Main category: cs.LG

TL;DR: MIDUS是一种新的深度扩展方法，用头级记忆层替代传统的前馈网络，通过为每个注意力头分配独立记忆库实现高效参数扩展，在保持高效参数足迹的同时获得性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统深度扩展方法通过复制层并使用前馈网络进行持续预训练，但这种方法效率有限且性能提升受限。需要一种既能增加模型容量又不会导致参数过度增长或推理成本过高的方法。

Method: 提出MIDUS方法，在复制的块中用头级记忆层替代前馈网络。为每个注意力头分配独立记忆库，支持头级检索并将信息注入后续层，同时保持头级功能结构。结合稀疏内存访问和头级表示，并包含高效的每头值分解模块。

Result: 在持续预训练实验中，MIDUS相比强大的深度扩展基线表现出稳健的性能提升，同时保持高效的参数足迹。有效缓解了效率与性能之间的权衡。

Conclusion: MIDUS通过其头级记忆设计，成为传统前馈网络复制进行深度扩展的有力且资源高效的替代方案，为大型语言模型扩展提供了新方向。

Abstract: Scaling large language models (LLMs) demands approaches that increase capacity without incurring excessive parameter growth or inference cost. Depth Up-Scaling (DUS) has emerged as a promising strategy by duplicating layers and applying Continual Pre-training (CPT), but its reliance on feed-forward networks (FFNs) limits efficiency and attainable gains. We introduce Memory-Infused Depth Up-Scaling (MIDUS), which replaces FFNs in duplicated blocks with a head-wise memory (HML) layer. Motivated by observations that attention heads have distinct roles both across and within layers, MIDUS assigns an independent memory bank to each head, enabling head-wise retrieval and injecting information into subsequent layers while preserving head-wise functional structure. This design combines sparse memory access with head-wise representations and incorporates an efficient per-head value factorization module, thereby relaxing the usual efficiency-performance trade-off. Across our CPT experiments, MIDUS exhibits robust performance improvements over strong DUS baselines while maintaining a highly efficient parameter footprint. Our findings establish MIDUS as a compelling and resource-efficient alternative to conventional FFN replication for depth up-scaling by leveraging its head-wise memory design.

</details>


### [95] [Network-Wide Traffic Volume Estimation from Speed Profiles using a Spatio-Temporal Graph Neural Network with Directed Spatial Attention](https://arxiv.org/abs/2512.13758)
*Léo Hein,Giovanni de Nunzio,Giovanni Chierchia,Aurélie Pirayre,Laurent Najman*

Main category: cs.LG

TL;DR: 提出HDA-STGNN模型，利用车速数据和道路属性进行全网交通流量估计，无需依赖流量传感器数据


<details>
  <summary>Details</summary>
Motivation: 现有交通流量估计方法要么依赖传感器数据进行预测，要么需要邻近传感器数据进行空间插值。在传感器稀缺的城市中，这些方法难以实现全网覆盖。相比之下，车速数据和静态道路属性更易获取，能够覆盖大多数城市路网的所有路段。

Method: 提出混合定向注意力时空图神经网络(HDA-STGNN)，这是一个归纳式深度学习框架。模型利用车速数据、静态道路属性和路网拓扑结构，预测全网所有路段的日交通流量分布。

Result: 通过广泛的消融实验验证了模型的有效性，证明模型能够捕捉复杂的时空依赖关系，并强调了拓扑信息对于在不依赖流量数据的情况下进行准确全网交通流量估计的重要性。

Conclusion: HDA-STGNN框架能够利用易获取的车速数据和道路属性，实现全网交通流量估计，解决了传感器稀缺城市的交通监测问题，为城市交通管理提供了新的解决方案。

Abstract: Existing traffic volume estimation methods typically address either forecasting traffic on sensor-equipped roads or spatially imputing missing volumes using nearby sensors. While forecasting models generally disregard unmonitored roads by design, spatial imputation methods explicitly address network-wide estimation; yet this approach relies on volume data at inference time, limiting its applicability in sensor-scarce cities. Unlike traffic volume data, probe vehicle speeds and static road attributes are more broadly accessible and support full coverage of road segments in most urban networks. In this work, we present the Hybrid Directed-Attention Spatio-Temporal Graph Neural Network (HDA-STGNN), an inductive deep learning framework designed to tackle the network-wide volume estimation problem. Our approach leverages speed profiles, static road attributes, and road network topology to predict daily traffic volume profiles across all road segments in the network. To evaluate the effectiveness of our approach, we perform extensive ablation studies that demonstrate the model's capacity to capture complex spatio-temporal dependencies and highlight the value of topological information for accurate network-wide traffic volume estimation without relying on volume data at inference time.

</details>


### [96] [Enhancing Semi-Supervised Multi-View Graph Convolutional Networks via Supervised Contrastive Learning and Self-Training](https://arxiv.org/abs/2512.13770)
*Huaiyuan Xiao,Fadi Dornaika,Jingjun Bi*

Main category: cs.LG

TL;DR: MV-SupGCN：一个半监督图卷积网络模型，通过联合损失函数、多图构建方法和对比学习与伪标签的统一框架，有效整合多视图互补信息，提升特征表示和性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于GCN的多视图学习方法未能充分利用不同视图间的互补信息，导致特征表示次优和性能受限。需要设计更有效的方法来整合多视图结构信息，提升模型泛化能力。

Method: 1) 设计联合损失函数：交叉熵损失+监督对比损失，减少类内方差并增大类间可分性；2) 结合KNN和半监督图构建方法增强数据结构表示的鲁棒性；3) 提出统一框架整合对比学习和伪标签，利用未标记数据并增强多视图语义对齐。

Result: 在多个基准测试中，MV-SupGCN始终超越最先进方法，验证了集成方法的有效性。

Conclusion: MV-SupGCN通过整合互补组件，有效提升了多视图学习的性能，为复杂多视图数据的建模提供了强大框架。

Abstract: The advent of graph convolutional network (GCN)-based multi-view learning provides a powerful framework for integrating structural information from heterogeneous views, enabling effective modeling of complex multi-view data. However, existing methods often fail to fully exploit the complementary information across views, leading to suboptimal feature representations and limited performance. To address this, we propose MV-SupGCN, a semi-supervised GCN model that integrates several complementary components with clear motivations and mutual reinforcement. First, to better capture discriminative features and improve model generalization, we design a joint loss function that combines Cross-Entropy loss with Supervised Contrastive loss, encouraging the model to simultaneously minimize intra-class variance and maximize inter-class separability in the latent space. Second, recognizing the instability and incompleteness of single graph construction methods, we combine both KNN-based and semi-supervised graph construction approaches on each view, thereby enhancing the robustness of the data structure representation and reducing generalization error. Third, to effectively utilize abundant unlabeled data and enhance semantic alignment across multiple views, we propose a unified framework that integrates contrastive learning in order to enforce consistency among multi-view embeddings and capture meaningful inter-view relationships, together with pseudo-labeling, which provides additional supervision applied to both the cross-entropy and contrastive loss functions to enhance model generalization. Extensive experiments demonstrate that MV-SupGCN consistently surpasses state-of-the-art methods across multiple benchmarks, validating the effectiveness of our integrated approach. The source code is available at https://github.com/HuaiyuanXiao/MVSupGCN

</details>


### [97] [Constrained Policy Optimization via Sampling-Based Weight-Space Projection](https://arxiv.org/abs/2512.13788)
*Shengfan Cao,Francesco Borrelli*

Main category: cs.LG

TL;DR: SCPO是一种基于采样的权重空间投影方法，用于约束策略学习，通过轨迹采样和光滑性边界构建局部安全区域，使用凸SOCP进行投影更新，确保从安全初始化开始的所有中间策略都保持安全。


<details>
  <summary>Details</summary>
Motivation: 安全关键学习需要在安全操作范围内改进性能，但模型参数必须满足未知的、基于滚动的安全约束。传统方法需要约束函数的梯度信息，这在复杂系统中难以获取。

Method: 提出SCPO方法：1) 通过轨迹采样评估安全约束；2) 利用光滑性边界建立参数变化与安全指标变化的关系；3) 构建局部安全区域；4) 使用凸二阶锥规划(SOCP)进行梯度投影；5) 在具有稳定备份策略的约束控制设置中确保闭环稳定性。

Result: 在有害监督的回归任务和恶意专家约束的双积分器任务中，SCPO能持续拒绝不安全更新，在整个训练过程中保持可行性，并实现有意义的原始目标改进。

Conclusion: SCPO提供了一种无需约束函数梯度信息的参数空间安全投影方法，具有安全归纳保证，在约束控制设置中能确保闭环稳定性，并实现超越保守备份的安全适应。

Abstract: Safety-critical learning requires policies that improve performance without leaving the safe operating regime. We study constrained policy learning where model parameters must satisfy unknown, rollout-based safety constraints. We propose SCPO, a sampling-based weight-space projection method that enforces safety directly in parameter space without requiring gradient access to the constraint functions. Our approach constructs a local safe region by combining trajectory rollouts with smoothness bounds that relate parameter changes to shifts in safety metrics. Each gradient update is then projected via a convex SOCP, producing a safe first-order step. We establish a safe-by-induction guarantee: starting from any safe initialization, all intermediate policies remain safe given feasible projections. In constrained control settings with a stabilizing backup policy, our approach further ensures closed-loop stability and enables safe adaptation beyond the conservative backup. On regression with harmful supervision and a constrained double-integrator task with malicious expert, our approach consistently rejects unsafe updates, maintains feasibility throughout training, and achieves meaningful primal objective improvement.

</details>


### [98] [EEG-D3: A Solution to the Hidden Overfitting Problem of Deep Learning Models](https://arxiv.org/abs/2512.13806)
*Siegfried Ludwig,Stylianos Bakas,Konstantinos Barmpas,Georgios Zoumpourlis,Dimitrios A. Adamos,Nikolaos Laskaris,Yannis Panagakis,Stefanos Zafeiriou*

Main category: cs.LG

TL;DR: 提出D3方法，通过弱监督训练分离EEG信号中的潜在脑活动成分，防止隐藏过拟合，提高模型泛化能力


<details>
  <summary>Details</summary>
Motivation: 当前深度学习在EEG解码中虽然基准性能良好，但实际应用转化有限，存在隐藏过拟合问题，需要能分离真实脑活动成分与伪迹的方法

Method: 提出解耦解码分解(D3)方法，通过预测输入窗口在试验序列中的位置来分离EEG潜在成分；使用完全独立的子网络架构确保可解释性；建立特征解释范式对比不同数据集上的成分激活模式

Result: D3能可靠分离运动想象数据的脑活动潜在成分；在下游分类器中使用适当成分子集可防止任务相关伪迹导致的隐藏过拟合；在线性可分离的潜在空间中实现有效的少样本睡眠分期学习

Conclusion: D3方法能区分真实脑活动成分与虚假特征，避免隐藏过拟合问题，在真实应用中泛化良好且仅需少量标注数据，为神经科学研究提供了分离个体脑过程的新工具

Abstract: Deep learning for decoding EEG signals has gained traction, with many claims to state-of-the-art accuracy. However, despite the convincing benchmark performance, successful translation to real applications is limited. The frequent disconnect between performance on controlled BCI benchmarks and its lack of generalisation to practical settings indicates hidden overfitting problems. We introduce Disentangled Decoding Decomposition (D3), a weakly supervised method for training deep learning models across EEG datasets. By predicting the place in the respective trial sequence from which the input window was sampled, EEG-D3 separates latent components of brain activity, akin to non-linear ICA. We utilise a novel model architecture with fully independent sub-networks for strict interpretability. We outline a feature interpretation paradigm to contrast the component activation profiles on different datasets and inspect the associated temporal and spatial filters. The proposed method reliably separates latent components of brain activity on motor imagery data. Training downstream classifiers on an appropriate subset of these components prevents hidden overfitting caused by task-correlated artefacts, which severely affects end-to-end classifiers. We further exploit the linearly separable latent space for effective few-shot learning on sleep stage classification. The ability to distinguish genuine components of brain activity from spurious features results in models that avoid the hidden overfitting problem and generalise well to real-world applications, while requiring only minimal labelled data. With interest to the neuroscience community, the proposed method gives researchers a tool to separate individual brain processes and potentially even uncover heretofore unknown dynamics.

</details>


### [99] [The Double Life of Code World Models: Provably Unmasking Malicious Behavior Through Execution Traces](https://arxiv.org/abs/2512.13821)
*Subramanyam Sahoo,Jared Junkin*

Main category: cs.LG

TL;DR: 提出Cross-Trace Verification Protocol (CTVP)框架，通过语义轨道分析验证不可信代码生成模型，检测后门注入，无需直接执行潜在恶意代码。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型越来越多地生成代码且人工监督减少，后门注入和恶意行为成为关键问题。需要一种方法来验证不可信的代码生成模型，确保其安全性。

Method: 提出CTVP框架，通过分析模型在语义等价程序变换上的执行轨迹预测一致性来检测行为异常。引入Adversarial Robustness Quotient (ARQ)量化验证计算成本，理论分析证明其不可博弈性。

Result: 该方法能够检测后门行为异常，ARQ显示验证成本随轨道大小呈指数增长。理论分析建立了信息论边界，证明对手无法通过训练改进，受基本空间复杂度约束。

Conclusion: 语义轨道分析为代码生成任务提供了一种可扩展、理论基础的AI控制方法，能够有效验证不可信模型并检测后门注入。

Abstract: Large language models (LLMs) increasingly generate code with minimal human oversight, raising critical concerns about backdoor injection and malicious behavior. We present Cross-Trace Verification Protocol (CTVP), a novel AI control framework that verifies untrusted code-generating models through semantic orbit analysis. Rather than directly executing potentially malicious code, CTVP leverages the model's own predictions of execution traces across semantically equivalent program transformations. By analyzing consistency patterns in these predicted traces, we detect behavioral anomalies indicative of backdoors. Our approach introduces the Adversarial Robustness Quotient (ARQ), which quantifies the computational cost of verification relative to baseline generation, demonstrating exponential growth with orbit size. Theoretical analysis establishes information-theoretic bounds showing non-gamifiability -- adversaries cannot improve through training due to fundamental space complexity constraints. This work demonstrates that semantic orbit analysis provides a scalable, theoretically grounded approach to AI control for code generation tasks.

</details>


### [100] [Explainable reinforcement learning from human feedback to improve alignment](https://arxiv.org/abs/2512.13837)
*Shicheng Liu,Siyuan Xu,Wenjie Qiu,Hangfan Zhang,Minghui Zhu*

Main category: cs.LG

TL;DR: 提出一种通过识别并修正导致不满意响应的训练数据来改进RLHF的方法，包括事后解释和反学习两部分


<details>
  <summary>Details</summary>
Motivation: 受人类改进策略启发，针对RLHF调优的语言模型仍可能输出不满意响应的问题，希望通过识别并修正导致这些响应的训练数据来改进模型

Method: 1) 事后解释方法：将问题形式化为约束组合优化，寻找最接近提示-响应对的训练数据集合，提出高效迭代数据选择算法；2) 反学习方法：通过反学习导致不满意响应的训练数据来改进模型，同时不显著降低其他提示的满意响应

Result: 实验结果表明，该方法能够有效改进RLHF

Conclusion: 将人类改进策略应用于RLHF改进是可行的，通过识别并修正导致不满意响应的训练数据可以提升语言模型的对齐效果

Abstract: A common and effective strategy for humans to improve an unsatisfactory outcome in daily life is to find a cause of this outcome and correct the cause. In this paper, we investigate whether this human improvement strategy can be applied to improving reinforcement learning from human feedback (RLHF) for alignment of language models (LMs). In particular, it is observed in the literature that LMs tuned by RLHF can still output unsatisfactory responses. This paper proposes a method to improve the unsatisfactory responses by correcting their causes. Our method has two parts. The first part proposes a post-hoc explanation method to explain why an unsatisfactory response is generated to a prompt by identifying the training data that lead to this response. We formulate this problem as a constrained combinatorial optimization problem where the objective is to find a set of training data closest to this prompt-response pair in a feature representation space, and the constraint is that the prompt-response pair can be decomposed as a convex combination of this set of training data in the feature space. We propose an efficient iterative data selection algorithm to solve this problem. The second part proposes an unlearning method that improves unsatisfactory responses to some prompts by unlearning the training data that lead to these unsatisfactory responses and, meanwhile, does not significantly degrade satisfactory responses to other prompts. Experimental results demonstrate that our algorithm can improve RLHF.

</details>


### [101] [Topologically-Stabilized Graph Neural Networks: Empirical Robustness Across Domains](https://arxiv.org/abs/2512.13852)
*Jelena Losic*

Main category: cs.LG

TL;DR: 提出结合持续同调特征与稳定性正则化的图神经网络框架，增强对结构扰动的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 图神经网络已成为图表示学习的标准方法，但对结构扰动仍然脆弱，需要提高鲁棒性

Method: 集成持续同调特征与稳定性正则化，基于Cohen-Steiner稳定性定理，将GIN架构与从持续图像提取的多尺度拓扑特征结合，并施加Hiraoka-Kusano启发的稳定性约束

Result: 在六个涵盖生化、社交和协作网络的数据集上，该方法对边扰动表现出卓越的鲁棒性，同时保持竞争力精度；在扰动下性能下降最小（大多数数据集0-4%），显著优于基线稳定性方法

Conclusion: 这项工作提供了一个理论上有基础、经验上验证的鲁棒图学习方法，与拓扑正则化的最新进展保持一致

Abstract: Graph Neural Networks (GNNs) have become the standard for graph representation learning but remain vulnerable to structural perturbations. We propose a novel framework that integrates persistent homology features with stability regularization to enhance robustness. Building on the stability theorems of persistent homology \cite{cohen2007stability}, our method combines GIN architectures with multi-scale topological features extracted from persistence images, enforced by Hiraoka-Kusano-inspired stability constraints. Across six diverse datasets spanning biochemical, social, and collaboration networks , our approach demonstrates exceptional robustness to edge perturbations while maintaining competitive accuracy. Notably, we observe minimal performance degradation (0-4\% on most datasets) under perturbation, significantly outperforming baseline stability. Our work provides both a theoretically-grounded and empirically-validated approach to robust graph learning that aligns with recent advances in topological regularization

</details>


### [102] [Dropout Neural Network Training Viewed from a Percolation Perspective](https://arxiv.org/abs/2512.13853)
*Finley Devlin,Jaron Sanders*

Main category: cs.LG

TL;DR: 研究深度神经网络dropout训练中的渗流现象及其影响，发现dropout可能切断输入输出路径导致训练崩溃


<details>
  <summary>Details</summary>
Motivation: 探究dropout正则化方法中随机移除连接的过程与统计物理中渗流模型的相似性，研究当dropout移除足够多连接导致输入输出路径中断时对神经网络训练的影响

Method: 建立模拟dropout的渗流模型，分析网络拓扑结构与路径问题的关系，研究无偏置神经网络的dropout训练，并启发式地扩展到有偏置网络

Result: 理论证明了dropout中存在渗流效应，这种效应会导致无偏置神经网络在dropout训练时崩溃，并启发式地论证这种崩溃会扩展到有偏置网络

Conclusion: dropout训练中存在渗流效应，当移除的连接足够多时会切断输入输出路径，导致神经网络无法基于数据做出预测，这在无偏置网络中会导致训练崩溃，有偏置网络也可能存在类似问题

Abstract: In this work, we investigate the existence and effect of percolation in training deep Neural Networks (NNs) with dropout. Dropout methods are regularisation techniques for training NNs, first introduced by G. Hinton et al. (2012). These methods temporarily remove connections in the NN, randomly at each stage of training, and update the remaining subnetwork with Stochastic Gradient Descent (SGD). The process of removing connections from a network at random is similar to percolation, a paradigm model of statistical physics.
  If dropout were to remove enough connections such that there is no path between the input and output of the NN, then the NN could not make predictions informed by the data. We study new percolation models that mimic dropout in NNs and characterise the relationship between network topology and this path problem. The theory shows the existence of a percolative effect in dropout. We also show that this percolative effect can cause a breakdown when training NNs without biases with dropout; and we argue heuristically that this breakdown extends to NNs with biases.

</details>


### [103] [Measuring Uncertainty Calibration](https://arxiv.org/abs/2512.13872)
*Kamil Ciosek,Nicolò Felicioni,Sina Ghiassian,Juan Elenter Litwin,Francesco Tonolini,David Gustaffson,Eva Garcia Martin,Carmen Barcena Gonzales,Raphaëlle Bertrand-Lalo*

Main category: cs.LG

TL;DR: 提出两种估计二元分类器L1校准误差的方法：1）对有界变差校准函数的分类器提供上界；2）通过修改分类器使其校准误差能被高效上界估计而不显著影响性能


<details>
  <summary>Details</summary>
Motivation: 在有限数据集上准确估计二元分类器的L1校准误差是一个重要但具有挑战性的问题，需要非渐近、分布无关的实用方法

Method: 1）对有界变差校准函数的分类器提供理论上的上界；2）提出一种修改分类器的方法，使其校准误差能被高效上界估计，而不需要严格假设且不显著影响分类器性能

Result: 提供了非渐近、分布无关的校准误差估计方法，这些方法能在真实数据集上以适度开销运行，为实际测量校准误差提供实用建议

Conclusion: 提出的方法为二元分类器的L1校准误差测量提供了实用、高效的解决方案，能够在实际应用中帮助评估和改进分类器的校准性能

Abstract: We make two contributions to the problem of estimating the $L_1$ calibration error of a binary classifier from a finite dataset. First, we provide an upper bound for any classifier where the calibration function has bounded variation. Second, we provide a method of modifying any classifier so that its calibration error can be upper bounded efficiently without significantly impacting classifier performance and without any restrictive assumptions. All our results are non-asymptotic and distribution-free. We conclude by providing advice on how to measure calibration error in practice. Our methods yield practical procedures that can be run on real-world datasets with modest overhead.

</details>


### [104] [Privacy-Enhancing Infant Cry Classification with Federated Transformers and Denoising Regularization](https://arxiv.org/abs/2512.13880)
*Geofrey Owino,Bernard Shibwabo*

Main category: cs.LG

TL;DR: 提出一个结合去噪自编码器、卷积分词器和Transformer编码器的婴儿哭声分类系统，采用联邦学习训练，实现隐私保护、抗噪声和通信高效的边缘部署。


<details>
  <summary>Details</summary>
Motivation: 婴儿哭声分类有助于早期评估婴儿需求，但现有解决方案面临隐私问题（音频数据）、背景噪声敏感性和跨记录环境的领域偏移等部署限制。

Method: 端到端婴儿哭声分析流程：集成去噪自编码器（DAE）、卷积分词器和Transformer编码器，采用通信高效的联邦学习训练。系统执行设备端去噪、自适应分割、事后校准和基于能量的分布外（OOD）弃权。联邦训练采用正则化控制变量更新和8位适配器增量，在安全聚合下进行。

Result: 在Baby Chillanto和Donate-a-Cry数据集（带ESC-50噪声叠加）上，模型获得宏观F1分数0.938、AUC 0.962、预期校准误差（ECE）0.032，每轮客户端上传从约36-42 MB减少到3.3 MB。在NVIDIA Jetson Nano（4 GB，TensorRT FP16）上实时边缘推理达到每1秒频谱图帧96毫秒。

Conclusion: 该系统展示了实现隐私保护、抗噪声和通信高效的婴儿哭声分类的实用路径，适合联邦部署。

Abstract: Infant cry classification can aid early assessment of infant needs. However, deployment of such solutions is limited by privacy concerns around audio data, sensitivity to background noise, and domain shift across recording environments. We present an end-to-end infant cry analysis pipeline that integrates a denoising autoencoder (DAE), a convolutional tokenizer, and a Transformer encoder trained using communication-efficient federated learning (FL). The system performs on-device denoising, adaptive segmentation, post hoc calibration, and energy-based out-of-distribution (OOD) abstention. Federated training employs a regularized control variate update with 8-bit adapter deltas under secure aggregation. Using the Baby Chillanto and Donate-a-Cry datasets with ESC-50 noise overlays, the model achieves a macro F1 score of 0.938, an AUC of 0.962, and an Expected Calibration Error (ECE) of 0.032, while reducing per-round client upload from approximately 36 to 42 MB to 3.3 MB. Real-time edge inference on an NVIDIA Jetson Nano (4 GB, TensorRT FP16) achieves 96 ms per one-second spectrogram frame. These results demonstrate a practical path toward privacy-preserving, noise-robust, and communication-efficient infant cry classification suitable for federated deployment.

</details>


### [105] [OPTIMA: Optimal One-shot Pruning for LLMs via Quadratic Programming Reconstruction](https://arxiv.org/abs/2512.13886)
*Mohammad Mozaffari,Samuel Kushnir,Maryam Mehri Dehnavi,Amir Yazdanbakhsh*

Main category: cs.LG

TL;DR: OPTIMA是一种实用的后训练剪枝方法，通过将层权重重构转化为独立行式二次规划问题，在保持准确性的同时实现大规模剪枝，无需微调。


<details>
  <summary>Details</summary>
Motivation: 后训练剪枝面临权衡：简单启发式方法速度快但准确性下降，而联合优化方法能恢复准确性但计算不可行。需要一种既准确又可扩展的实用方法。

Method: 将掩码选择后的层权重重构转化为独立的行式二次规划问题，这些QP共享层Hessian矩阵。实现加速器友好的QP求解器，每层累积一个Hessian并并行求解多个小QP。

Result: 在多个LLM家族和稀疏度下一致改进零样本性能，最高提升3.97%绝对准确率。在NVIDIA H100上，40小时内完成80亿参数transformer的端到端剪枝，峰值内存60GB。

Conclusion: OPTIMA为一次性后训练剪枝设定了新的准确率-效率权衡标准，平衡了准确性和可扩展性，无需微调即可实现大规模模型剪枝。

Abstract: Post-training model pruning is a promising solution, yet it faces a trade-off: simple heuristics that zero weights are fast but degrade accuracy, while principled joint optimization methods recover accuracy but are computationally infeasible at modern scale. One-shot methods such as SparseGPT offer a practical trade-off in optimality by applying efficient, approximate heuristic weight updates. To close this gap, we introduce OPTIMA, a practical one-shot post-training pruning method that balances accuracy and scalability. OPTIMA casts layer-wise weight reconstruction after mask selection as independent, row-wise Quadratic Programs (QPs) that share a common layer Hessian. Solving these QPs yields the per-row globally optimal update with respect to the reconstruction objective given the estimated Hessian. The shared-Hessian structure makes the problem highly amenable to batching on accelerators. We implement an accelerator-friendly QP solver that accumulates one Hessian per layer and solves many small QPs in parallel, enabling one-shot post-training pruning at scale on a single accelerator without fine-tuning. OPTIMA integrates with existing mask selectors and consistently improves zero-shot performance across multiple LLM families and sparsity regimes, yielding up to 3.97% absolute accuracy improvement. On an NVIDIA H100, OPTIMA prunes a 8B-parameter transformer end-to-end in 40 hours with 60GB peak memory. Together, these results set a new state-of-the-art accuracy-efficiency trade-offs for one-shot post-training pruning.

</details>


### [106] [Let's (not) just put things in Context: Test-Time Training for Long-Context LLMs](https://arxiv.org/abs/2512.13898)
*Rachit Bansal,Aston Zhang,Rishabh Tiwari,Lovish Madaan,Sai Surya Duvvuri,Devvrit Khatri,David Brandfonbrener,David Alvarez-Melis,Prajjwal Bhargava,Mihir Sanjay Kale,Samy Jelassi*

Main category: cs.LG

TL;DR: 论文发现长上下文LLM存在"分数稀释"问题，传统推理时计算策略效果有限，提出通过上下文特定梯度更新来显著提升长上下文性能


<details>
  <summary>Details</summary>
Motivation: 当前长上下文LLM虽然能处理数百万token，但实际使用可靠性不足。传统推理时计算策略（如生成更多思考token）在长上下文任务中效果有限，存在根本性限制

Method: 提出简单方法：通过对给定上下文进行针对性梯度更新，克服静态自注意力的限制。这种方法将推理时计算从生成更多思考token转向上下文特定训练

Result: 方法在模型和长上下文基准测试中带来一致的大幅性能提升。Qwen3-4B在LongBench-v2和ZeroScrolls基准子集上平均提升12.6和14.1个百分点

Conclusion: 对于长上下文任务，少量上下文特定训练比传统推理时扩展策略（如生成更多思考token）是更好的推理计算利用方式。这提供了实用的长上下文处理新思路

Abstract: Progress on training and architecture strategies has enabled LLMs with millions of tokens in context length. However, empirical evidence suggests that such long-context LLMs can consume far more text than they can reliably use. On the other hand, it has been shown that inference-time compute can be used to scale performance of LLMs, often by generating thinking tokens, on challenging tasks involving multi-step reasoning. Through controlled experiments on sandbox long-context tasks, we find that such inference-time strategies show rapidly diminishing returns and fail at long context. We attribute these failures to score dilution, a phenomenon inherent to static self-attention. Further, we show that current inference-time strategies cannot retrieve relevant long-context signals under certain conditions. We propose a simple method that, through targeted gradient updates on the given context, provably overcomes limitations of static self-attention. We find that this shift in how inference-time compute is spent leads to consistently large performance improvements across models and long-context benchmarks. Our method leads to large 12.6 and 14.1 percentage point improvements for Qwen3-4B on average across subsets of LongBench-v2 and ZeroScrolls benchmarks. The takeaway is practical: for long context, a small amount of context-specific training is a better use of inference compute than current inference-time scaling strategies like producing more thinking tokens.

</details>


### [107] [Exploring Machine Learning, Deep Learning, and Explainable AI Methods for Seasonal Precipitation Prediction in South America](https://arxiv.org/abs/2512.13910)
*Matheus Corrêa Domingos,Valdivino Alexandre de Santiago Júnior,Juliana Aparecida Anochi,Elcio Hideiti Shiguemori,Luísa Mirelle Costa dos Santos,Hércules Carlos dos Santos Pereira,André Estevam Costa Oliveira*

Main category: cs.LG

TL;DR: 该研究比较了传统机器学习、深度学习和动态建模方法在南美洲降水预报中的表现，发现LSTM模型在预报精度上表现最佳，而传统动态模型BAM表现最差，证实了深度学习在气候预报中的可行性。


<details>
  <summary>Details</summary>
Motivation: 降水预报对社会至关重要，但传统动态建模复杂且计算成本高。虽然AI技术已被用作替代或补充，但缺乏对纯数据驱动方法在降水预报中可行性的广泛研究。本研究旨在填补这一空白，系统评估不同机器学习方法在南美洲降水预报中的表现。

Method: 研究比较了传统机器学习方法（随机森林和XGBoost）、深度学习方法（1D CNN、LSTM和GRU）以及传统动态建模方法（巴西全球大气模型BAM）。使用2019年全季节数据，并采用可解释人工智能（XAI）分析模型行为。

Result: LSTM模型表现出最强的预测性能，特别是在强降水预报方面最准确。传统动态模型BAM表现最差。XGBoost在成本敏感场景下提供了较低的延迟和轻微精度损失。深度学习模型在气候预报中表现出可行性。

Conclusion: 深度学习模型（特别是LSTM）在降水预报中优于传统动态建模方法，证实了数据驱动方法在气候预报中的可行性。这符合全球主要气象和气候预报中心的发展趋势，为降水预报提供了有效的替代方案。

Abstract: Forecasting meteorological variables is challenging due to the complexity of their processes, requiring advanced models for accuracy. Accurate precipitation forecasts are vital for society. Reliable predictions help communities mitigate climatic impacts. Based on the current relevance of artificial intelligence (AI), classical machine learning (ML) and deep learning (DL) techniques have been used as an alternative or complement to dynamic modeling. However, there is still a lack of broad investigations into the feasibility of purely data-driven approaches for precipitation forecasting. This study aims at addressing this issue where different classical ML and DL approaches for forecasting precipitation in South America, taking into account all 2019 seasons, are considered in a detailed investigation. The selected classical ML techniques were Random Forests and extreme gradient boosting (XGBoost), while the DL counterparts were a 1D convolutional neural network (CNN 1D), a long short-term memory (LSTM) model, and a gated recurrent unit (GRU) model. Additionally, the Brazilian Global Atmospheric Model (BAM) was used as a representative of the traditional dynamic modeling approach. We also relied on explainable artificial intelligence (XAI) to provide some explanations for the models behaviors. LSTM showed strong predictive performance while BAM, the traditional dynamic model representative, had the worst results. Despite presented the higher latency, LSTM was most accurate for heavy precipitation. If cost is a concern, XGBoost offers lower latency with slightly accuracy loss. The results of this research confirm the viability of DL models for climate forecasting, solidifying a global trend in major meteorological and climate forecasting centers.

</details>


### [108] [Capturing reduced-order quantum many-body dynamics out of equilibrium via neural ordinary differential equations](https://arxiv.org/abs/2512.13913)
*Patrick Egenlauf,Iva Březinová,Sabine Andergassen,Miriam Klopotek*

Main category: cs.LG

TL;DR: 使用神经ODE学习2RDM动力学，发现仅在两粒子和三粒子关联度高的参数区域有效，揭示了时间局域重建泛函的局限性，为开发非局域闭包方案提供指导。


<details>
  <summary>Details</summary>
Motivation: 研究非平衡量子多体系统中快速关联建立的描述方法，探索时间局域重建泛函在TD2RDM方法中的有效性和局限性。

Method: 使用神经ODE模型在精确2RDM数据上训练，无需三维粒子信息，通过分析两粒子和三粒子累积量之间的Pearson相关性来评估模型性能。

Result: 神经ODE仅在两粒子和三粒子累积量高度相关的参数区域能准确重现动力学；在反相关或不相关区域失败，表明简单的时间局域泛函无法捕捉演化。时间平均的三粒子关联建立幅度是成功的主要预测指标。

Conclusion: 神经ODE可作为模型无关的诊断工具，映射累积量展开方法的适用范围，指导开发依赖记忆的非局域闭包方案，为快速数据驱动的相关量子物质模拟开辟新途径。

Abstract: Out-of-equilibrium quantum many-body systems exhibit rapid correlation buildup that underlies many emerging phenomena. Exact wave-function methods to describe this scale exponentially with particle number; simpler mean-field approaches neglect essential two-particle correlations. The time-dependent two-particle reduced density matrix (TD2RDM) formalism offers a middle ground by propagating the two-particle reduced density matrix (2RDM) and closing the BBGKY hierarchy with a reconstruction of the three-particle cumulant. But the validity and existence of time-local reconstruction functionals ignoring memory effects remain unclear across different dynamical regimes. We show that a neural ODE model trained on exact 2RDM data (no dimensionality reduction) can reproduce its dynamics without any explicit three-particle information -- but only in parameter regions where the Pearson correlation between the two- and three-particle cumulants is large. In the anti-correlated or uncorrelated regime, the neural ODE fails, indicating that no simple time-local functional of the instantaneous two-particle cumulant can capture the evolution. The magnitude of the time-averaged three-particle-correlation buildup appears to be the primary predictor of success: For a moderate correlation buildup, both neural ODE predictions and existing TD2RDM reconstructions are accurate, whereas stronger values lead to systematic breakdowns. These findings pinpoint the need for memory-dependent kernels in the three-particle cumulant reconstruction for the latter regime. Our results place the neural ODE as a model-agnostic diagnostic tool that maps the regime of applicability of cumulant expansion methods and guides the development of non-local closure schemes. More broadly, the ability to learn high-dimensional RDM dynamics from limited data opens a pathway to fast, data-driven simulation of correlated quantum matter.

</details>


### [109] [Adaptive digital twins for predictive decision-making: Online Bayesian learning of transition dynamics](https://arxiv.org/abs/2512.13919)
*Eugenio Varetti,Matteo Torzoni,Marco Tezzele,Andrea Manzoni*

Main category: cs.LG

TL;DR: 本文提出了一种自适应数字孪生框架，通过贝叶斯更新在线学习状态转移概率，使用强化学习求解参数化马尔可夫决策过程，应用于土木工程中的结构健康监测和维护规划。


<details>
  <summary>Details</summary>
Motivation: 当前数字孪生在土木工程中的价值实现有限，需要增强自适应性来提升个性化、鲁棒性和成本效益。特别是状态转移模型需要能够在线学习和适应物理系统的变化。

Method: 1. 使用概率图模型（动态贝叶斯网络）表示数字孪生，建模物理与虚拟域的双向交互；2. 将状态转移概率视为具有共轭先验的随机变量，实现层次化在线学习；3. 提供更广泛分布类别的数学框架；4. 通过强化学习求解参数化马尔可夫决策过程，计算动态策略。

Result: 提出的自适应数字孪生框架具有增强的个性化、增加的鲁棒性和改进的成本效益。在铁路桥梁结构健康监测和维护规划的案例研究中验证了方法的有效性。

Conclusion: 自适应性能够显著提升数字孪生在土木工程中的价值实现。通过贝叶斯在线学习和强化学习，数字孪生能够更好地适应系统变化，为结构健康监测和维护规划提供更优的决策支持。

Abstract: This work shows how adaptivity can enhance value realization of digital twins in civil engineering. We focus on adapting the state transition models within digital twins represented through probabilistic graphical models. The bi-directional interaction between the physical and virtual domains is modeled using dynamic Bayesian networks. By treating state transition probabilities as random variables endowed with conjugate priors, we enable hierarchical online learning of transition dynamics from a state to another through effortless Bayesian updates. We provide the mathematical framework to account for a larger class of distributions with respect to the current literature. To compute dynamic policies with precision updates we solve parametric Markov decision processes through reinforcement learning. The proposed adaptive digital twin framework enjoys enhanced personalization, increased robustness, and improved cost-effectiveness. We assess our approach on a case study involving structural health monitoring and maintenance planning of a railway bridge.

</details>


### [110] [Sliding Window Recurrences for Sequence Models](https://arxiv.org/abs/2512.13921)
*Dragos Secrieru,Garyk Brixi,Yoshua Bengio,Taiji Suzuki,Michael Poli,Stefano Massaroli*

Main category: cs.LG

TL;DR: Phalanx层通过滑动窗口循环实现多混合架构，在保持困惑度不变的同时，相比优化Transformer获得10-40%的速度提升


<details>
  <summary>Details</summary>
Motivation: 多混合架构在语言建模中展现出更好的质量和性能潜力，但需要与GPU内存层次结构对齐的高效算法

Method: 提出分层分解框架用于线性循环，开发滑动窗口循环算法，创建Phalanx层作为窗口注意力或线性循环的替代方案

Result: 在10亿参数多混合模型中，Phalanx在4K到32K上下文长度上比优化Transformer快10-40%，同时保持相同的困惑度

Conclusion: 滑动窗口循环和Phalanx层为多混合架构提供了高效实现，显著提升了语言建模的性能

Abstract: Multi-hybrid architectures are poised to take over language modeling due to better quality and performance. We introduce a hierarchical decomposition framework for linear recurrences that allows us to develop algorithms aligned with GPU memory hierarchies, yielding Sliding Window Recurrences. We focus specifically on truncating recurrences to hardware-aligned windows which are naturally jagged, limiting costly inter-warp communication. Using SWR, we develop Phalanx layers that serve as drop-in replacements for windowed attention or linear recurrences. In 1B parameter multi-hybrid models, Phalanx achieves over 10-40% speedup across 4K to 32K context length over optimized Transformers while matching perplexity.

</details>


### [111] [A Complete Guide to Spherical Equivariant Graph Transformers](https://arxiv.org/abs/2512.13927)
*Sophia Tang*

Main category: cs.LG

TL;DR: 球形等变图神经网络（EGNNs）为三维分子和生物分子系统学习提供理论框架，确保预测符合物理旋转对称性，通过球张量表示特征并构建SO(3)-等变核。


<details>
  <summary>Details</summary>
Motivation: 在三维分子和生物分子系统中，预测必须尊重物理固有的旋转对称性。传统GNNs和Transformers需要扩展以表示这些对称性，确保预测在输入旋转时以物理有意义的方式变化。

Method: 将节点和边特征表示为在旋转群SO(3)不可约表示下变换的球张量，构建SO(3)-等变核，开发Tensor Field Network和SE(3)-Transformer架构，实现等变消息传递和注意力机制。

Result: 提供了完整的球形等变建模理论基础，包括群表示、球谐函数、张量积、Clebsch-Gordan分解和SO(3)-等变核构建，并展示了具体架构实现。

Conclusion: 该指南为研究人员和学习者提供了自包含的球形EGNNs介绍，适用于化学、分子性质预测、蛋白质结构建模和生成建模等应用。

Abstract: Spherical equivariant graph neural networks (EGNNs) provide a principled framework for learning on three-dimensional molecular and biomolecular systems, where predictions must respect the rotational symmetries inherent in physics. These models extend traditional message-passing GNNs and Transformers by representing node and edge features as spherical tensors that transform under irreducible representations of the rotation group SO(3), ensuring that predictions change in physically meaningful ways under rotations of the input. This guide develops a complete, intuitive foundation for spherical equivariant modeling - from group representations and spherical harmonics, to tensor products, Clebsch-Gordan decomposition, and the construction of SO(3)-equivariant kernels. Building on this foundation, we construct the Tensor Field Network and SE(3)-Transformer architectures and explain how they perform equivariant message-passing and attention on geometric graphs. Through clear mathematical derivations and annotated code excerpts, this guide serves as a self-contained introduction for researchers and learners seeking to understand or implement spherical EGNNs for applications in chemistry, molecular property prediction, protein structure modeling, and generative modeling.

</details>


### [112] [Informing Acquisition Functions via Foundation Models for Molecular Discovery](https://arxiv.org/abs/2512.13935)
*Qi Chen,Fabio Ramos,Alán Aspuru-Guzik,Florian Shkurti*

Main category: cs.LG

TL;DR: 提出一种免似然的贝叶斯优化方法，直接利用LLM和化学基础模型的先验知识，通过树状空间划分和蒙特卡洛树搜索提升分子发现的效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 传统贝叶斯优化在低数据、先验知识不足和大候选空间下性能受限，而LLM和化学基础模型虽然提供丰富先验，但高维特征、上下文学习成本高以及深度贝叶斯代理模型的计算负担阻碍了它们的充分利用。

Method: 1) 免似然贝叶斯优化，绕过显式代理建模，直接利用LLM和化学基础模型的先验知识指导采集函数；2) 学习分子搜索空间的树状划分，结合局部采集函数；3) 使用蒙特卡洛树搜索进行高效候选选择；4) 引入粗粒度LLM聚类，将采集函数评估限制在具有更高属性值的聚类中。

Result: 通过大量实验和消融研究表明，该方法显著提升了LLM引导的贝叶斯优化在分子发现中的可扩展性、鲁棒性和样本效率。

Conclusion: 提出的方法通过整合LLM先验、树状空间划分和聚类策略，有效解决了传统贝叶斯优化在分子发现中的局限性，为大规模分子搜索提供了高效解决方案。

Abstract: Bayesian Optimization (BO) is a key methodology for accelerating molecular discovery by estimating the mapping from molecules to their properties while seeking the optimal candidate. Typically, BO iteratively updates a probabilistic surrogate model of this mapping and optimizes acquisition functions derived from the model to guide molecule selection. However, its performance is limited in low-data regimes with insufficient prior knowledge and vast candidate spaces. Large language models (LLMs) and chemistry foundation models offer rich priors to enhance BO, but high-dimensional features, costly in-context learning, and the computational burden of deep Bayesian surrogates hinder their full utilization. To address these challenges, we propose a likelihood-free BO method that bypasses explicit surrogate modeling and directly leverages priors from general LLMs and chemistry-specific foundation models to inform acquisition functions. Our method also learns a tree-structured partition of the molecular search space with local acquisition functions, enabling efficient candidate selection via Monte Carlo Tree Search. By further incorporating coarse-grained LLM-based clustering, it substantially improves scalability to large candidate sets by restricting acquisition function evaluations to clusters with statistically higher property values. We show through extensive experiments and ablations that the proposed method substantially improves scalability, robustness, and sample efficiency in LLM-guided BO for molecular discovery.

</details>


### [113] [Pattern-Guided Diffusion Models](https://arxiv.org/abs/2512.13945)
*Vivian Lin,Kuk Jin Jang,Wenwen Si,Insup Lee*

Main category: cs.LG

TL;DR: PGDM利用模式引导的扩散模型进行时间序列预测，通过原型分析提取数据中的重复模式，并基于模式估计指导预测，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在多元时间序列预测中很少考虑数据中的重复结构或模式，这限制了预测的准确性和现实性。

Method: PGDM首先使用原型分析提取时间数据中的固有模式，估计序列中最可能的下一个模式，然后用这个模式估计来指导预测。还引入了基于原型分析的不确定性量化技术，并根据模式估计的不确定性动态调整引导水平。

Result: 在两个应用（视野测量和动作捕捉帧预测）中，模式引导使PGDM性能提升分别达40.67%/56.26%和14.12%/14.10%。PGDM比基线方法表现更好，提升分别达65.58%/84.83%和93.64%/92.55%。

Conclusion: PGDM通过利用时间数据中的固有模式进行引导预测，显著提高了扩散模型在时间序列预测中的性能，并提供了有效的不确定性量化方法。

Abstract: Diffusion models have shown promise in forecasting future data from multivariate time series. However, few existing methods account for recurring structures, or patterns, that appear within the data. We present Pattern-Guided Diffusion Models (PGDM), which leverage inherent patterns within temporal data for forecasting future time steps. PGDM first extracts patterns using archetypal analysis and estimates the most likely next pattern in the sequence. By guiding predictions with this pattern estimate, PGDM makes more realistic predictions that fit within the set of known patterns. We additionally introduce a novel uncertainty quantification technique based on archetypal analysis, and we dynamically scale the guidance level based on the pattern estimate uncertainty. We apply our method to two well-motivated forecasting applications, predicting visual field measurements and motion capture frames. On both, we show that pattern guidance improves PGDM's performance (MAE / CRPS) by up to 40.67% / 56.26% and 14.12% / 14.10%, respectively. PGDM also outperforms baselines by up to 65.58% / 84.83% and 93.64% / 92.55%.

</details>


### [114] [A Single Architecture for Representing Invariance Under Any Space Group](https://arxiv.org/abs/2512.13989)
*Cindy Y. Zhang,Elif Ertekin,Peter Orbanz,Ryan P. Adams*

Main category: cs.LG

TL;DR: 提出一种能自动适应任意空间群的机器学习架构，通过对称性约束的傅里叶基实现权重共享，解决晶体对称性建模的扩展性问题


<details>
  <summary>Details</summary>
Motivation: 传统方法需要为每个对称群设计专门架构，限制了可扩展性，特别是对于材料科学中230个三维空间群。需要一种能自动适应任意空间群的通用架构。

Method: 通过群操作对傅里叶系数的约束构建对称性适应的傅里叶基，将这些约束编码到神经网络层中，实现不同空间群间的权重共享。

Result: 在材料性质预测任务中达到竞争性性能，并能进行零样本学习，泛化到未见过的空间群。

Conclusion: 提出的方法通过对称性约束的傅里叶基实现单一架构适应任意空间群，解决了传统方法的扩展性问题，并能利用群间结构相似性克服数据稀疏问题。

Abstract: Incorporating known symmetries in data into machine learning models has consistently improved predictive accuracy, robustness, and generalization. However, achieving exact invariance to specific symmetries typically requires designing bespoke architectures for each group of symmetries, limiting scalability and preventing knowledge transfer across related symmetries. In the case of the space groups, symmetries critical to modeling crystalline solids in materials science and condensed matter physics, this challenge is particularly salient as there are 230 such groups in three dimensions. In this work we present a new approach to such crystallographic symmetries by developing a single machine learning architecture that is capable of adapting its weights automatically to enforce invariance to any input space group. Our approach is based on constructing symmetry-adapted Fourier bases through an explicit characterization of constraints that group operations impose on Fourier coefficients. Encoding these constraints into a neural network layer enables weight sharing across different space groups, allowing the model to leverage structural similarities between groups and overcome data sparsity when limited measurements are available for specific groups. We demonstrate the effectiveness of this approach in achieving competitive performance on material property prediction tasks and performing zero-shot learning to generalize to unseen groups.

</details>


### [115] [Accelerating MHC-II Epitope Discovery via Multi-Scale Prediction in Antigen Presentation](https://arxiv.org/abs/2512.14011)
*Yue Wan,Jiayi Yuan,Zhiwei Feng,Xiaowei Jia*

Main category: cs.LG

TL;DR: 该论文构建了一个精心策划的MHC-II抗原表位数据集，提出了三个机器学习任务，并建立了多尺度评估框架，为计算免疫治疗提供资源。


<details>
  <summary>Details</summary>
Motivation: MHC-II抗原表位在免疫治疗中至关重要，但相比MHC-I研究面临更多挑战：结合特异性复杂、基序模式模糊、数据集较小且标准化程度低。

Method: 1. 从IEDB等公共来源构建精心策划的MHC-II数据集；2. 提出肽结合、肽呈递和抗原呈递三个ML任务；3. 建立多尺度评估框架和模块化框架来基准测试现有模型。

Result: 创建了扩展和标准化的肽-MHC-II数据集，并引入了具有更丰富生物学背景的新型抗原-MHC-II数据集，为MHC-II抗原呈递途径的ML研究提供了基础资源。

Conclusion: 这项工作为推进计算免疫治疗提供了宝贵资源，为未来ML指导的表位发现和免疫反应预测建模研究奠定了基础。

Abstract: Antigenic epitope presented by major histocompatibility complex II (MHC-II) proteins plays an essential role in immunotherapy. However, compared to the more widely studied MHC-I in computational immunotherapy, the study of MHC-II antigenic epitope poses significantly more challenges due to its complex binding specificity and ambiguous motif patterns. Consequently, existing datasets for MHC-II interactions are smaller and less standardized than those available for MHC-I. To address these challenges, we present a well-curated dataset derived from the Immune Epitope Database (IEDB) and other public sources. It not only extends and standardizes existing peptide-MHC-II datasets, but also introduces a novel antigen-MHC-II dataset with richer biological context. Leveraging this dataset, we formulate three major machine learning (ML) tasks of peptide binding, peptide presentation, and antigen presentation, which progressively capture the broader biological processes within the MHC-II antigen presentation pathway. We further employ a multi-scale evaluation framework to benchmark existing models, along with a comprehensive analysis over various modeling designs to this problem with a modular framework. Overall, this work serves as a valuable resource for advancing computational immunotherapy, providing a foundation for future research in ML guided epitope discovery and predictive modeling of immune responses.

</details>


### [116] [EXAONE Path 2.5: Pathology Foundation Model with Multi-Omics Alignment](https://arxiv.org/abs/2512.14019)
*Juseung Yun,Sunwoo Yu,Sumin Ha,Jonghyun Kim,Janghyeon Lee,Jongseong Jang,Soonyoung Lee*

Main category: cs.LG

TL;DR: EXAONE Path 2.5是一个病理学基础模型，通过联合建模组织学、基因组学、表观遗传学和转录组学等多模态数据，创建更全面的患者表征，在临床和基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 癌症进展涉及多个生物层面的相互作用，特别是分子层面（基因组、表观遗传、转录组）的相互作用对仅基于图像的模型是不可见的。需要更全面地捕捉肿瘤生物学特征，超越单纯的形态学分析。

Method: 1. 多模态SigLIP损失函数，实现跨异质模态的全配对对比学习
2. 片段感知旋转位置编码（F-RoPE）模块，保持WSI中的空间结构和组织片段拓扑
3. 针对WSI和RNA-seq的领域专业化内部基础模型，提供生物学基础嵌入以实现稳健的多模态对齐

Result: 在Patho-Bench基准测试（80个任务）和内部真实世界临床数据集上评估，与六个领先的病理学基础模型相比，EXAONE Path 2.5表现出高数据和参数效率，在Patho-Bench上达到最先进水平，在临床环境中表现出最高的适应性。

Conclusion: 生物学信息驱动的多模态设计具有重要价值，整合基因型到表型的建模为下一代精准肿瘤学提供了潜力。

Abstract: Cancer progression arises from interactions across multiple biological layers, especially beyond morphological and across molecular layers that remain invisible to image-only models. To capture this broader biological landscape, we present EXAONE Path 2.5, a pathology foundation model that jointly models histologic, genomic, epigenetic and transcriptomic modalities, producing an integrated patient representation that reflects tumor biology more comprehensively. Our approach incorporates three key components: (1) multimodal SigLIP loss enabling all-pairwise contrastive learning across heterogeneous modalities, (2) a fragment-aware rotary positional encoding (F-RoPE) module that preserves spatial structure and tissue-fragment topology in WSI, and (3) domain-specialized internal foundation models for both WSI and RNA-seq to provide biologically grounded embeddings for robust multimodal alignment. We evaluate EXAONE Path 2.5 against six leading pathology foundation models across two complementary benchmarks: an internal real-world clinical dataset and the Patho-Bench benchmark covering 80 tasks. Our framework demonstrates high data and parameter efficiency, achieving on-par performance with state-of-the-art foundation models on Patho-Bench while exhibiting the highest adaptability in the internal clinical setting. These results highlight the value of biologically informed multimodal design and underscore the potential of integrated genotype-to-phenotype modeling for next-generation precision oncology.

</details>


### [117] [Multivariate Time Series Forecasting with Hybrid Euclidean-SPD Manifold Graph Neural Networks](https://arxiv.org/abs/2512.14023)
*Yong Fang,Na Li,Hangguan Shan,Eryun Liu,Xinyu Li,Wei Ni,Er-Ping Li*

Main category: cs.LG

TL;DR: HSMGNN是一种新颖的图神经网络模型，首次将混合欧几里得-黎曼几何表示用于多元时间序列预测，通过双空间建模显著提升了预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有多元时间序列预测方法通常在欧几里得空间或黎曼空间中建模，难以捕捉真实数据中多样的几何结构和复杂的时空依赖关系。需要一种能够同时利用两种几何空间优势的混合表示方法。

Method: 提出HSMGNN模型：1) SCS嵌入将输入数据投影到欧几里得和黎曼双空间；2) ADB层通过可训练记忆机制降低黎曼距离计算成本；3) FGCN通过可学习融合算子集成双空间特征进行预测。

Result: 在三个基准数据集上的实验表明，HSMGNN相比最先进的基线方法，预测精度提升最高达13.8%。

Conclusion: HSMGNN首次将混合几何表示引入多元时间序列预测，通过双空间建模有效捕捉数据几何特性，显著提升了预测性能，为复杂时空依赖建模提供了新思路。

Abstract: Multivariate Time Series (MTS) forecasting plays a vital role in various real-world applications, such as traffic management and predictive maintenance. Existing approaches typically model MTS data in either Euclidean or Riemannian space, limiting their ability to capture the diverse geometric structures and complex spatio-temporal dependencies inherent in real-world data. To overcome this limitation, we propose the Hybrid Symmetric Positive-Definite Manifold Graph Neural Network (HSMGNN), a novel graph neural network-based model that captures data geometry within a hybrid Euclidean-Riemannian framework. To the best of our knowledge, this is the first work to leverage hybrid geometric representations for MTS forecasting, enabling expressive and comprehensive modeling of geometric properties. Specifically, we introduce a Submanifold-Cross-Segment (SCS) embedding to project input MTS into both Euclidean and Riemannian spaces, thereby capturing spatio-temporal variations across distinct geometric domains. To alleviate the high computational cost of Riemannian distance, we further design an Adaptive-Distance-Bank (ADB) layer with a trainable memory mechanism. Finally, a Fusion Graph Convolutional Network (FGCN) is devised to integrate features from the dual spaces via a learnable fusion operator for accurate prediction. Experiments on three benchmark datasets demonstrate that HSMGNN achieves up to a 13.8 percent improvement over state-of-the-art baselines in forecasting accuracy.

</details>


### [118] [FusAD: Time-Frequency Fusion with Adaptive Denoising for General Time Series Analysis](https://arxiv.org/abs/2512.14078)
*Da Zhang,Bingyu Li,Zhiyuan Zhao,Feiping Nie,Junyu Gao,Xuelong Li*

Main category: cs.LG

TL;DR: FusAD是一个统一的时间序列分析框架，通过自适应时频融合和去噪机制，在分类、预测和异常检测任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前时间序列分析面临三大挑战：1）缺乏高效、多任务兼容的统一框架；2）现有方法通常针对单一任务或特定数据类型；3）现实数据常受噪声、复杂频率成分和多尺度动态模式影响，难以进行鲁棒特征提取。

Method: FusAD采用自适应时频融合机制，结合傅里叶和小波变换捕获全局-局部和多尺度动态特征；包含自适应去噪机制自动感知和过滤各类噪声；集成通用信息融合和解码结构，结合掩码预训练促进多粒度表示学习。

Result: 在主流时间序列基准测试中，FusAD在分类、预测和异常检测任务上始终优于最先进模型，同时保持高效率和可扩展性。

Conclusion: FusAD提供了一个统一、高效、多任务兼容的时间序列分析框架，通过创新的时频融合和自适应去噪机制，能够有效处理复杂现实数据中的各种挑战。

Abstract: Time series analysis plays a vital role in fields such as finance, healthcare, industry, and meteorology, underpinning key tasks including classification, forecasting, and anomaly detection. Although deep learning models have achieved remarkable progress in these areas in recent years, constructing an efficient, multi-task compatible, and generalizable unified framework for time series analysis remains a significant challenge. Existing approaches are often tailored to single tasks or specific data types, making it difficult to simultaneously handle multi-task modeling and effectively integrate information across diverse time series types. Moreover, real-world data are often affected by noise, complex frequency components, and multi-scale dynamic patterns, which further complicate robust feature extraction and analysis. To ameliorate these challenges, we propose FusAD, a unified analysis framework designed for diverse time series tasks. FusAD features an adaptive time-frequency fusion mechanism, integrating both Fourier and Wavelet transforms to efficiently capture global-local and multi-scale dynamic features. With an adaptive denoising mechanism, FusAD automatically senses and filters various types of noise, highlighting crucial sequence variations and enabling robust feature extraction in complex environments. In addition, the framework integrates a general information fusion and decoding structure, combined with masked pre-training, to promote efficient learning and transfer of multi-granularity representations. Extensive experiments demonstrate that FusAD consistently outperforms state-of-the-art models on mainstream time series benchmarks for classification, forecasting, and anomaly detection tasks, while maintaining high efficiency and scalability. Code is available at https://github.com/zhangda1018/FusAD.

</details>


### [119] [SonicMoE: Accelerating MoE with IO and Tile-aware Optimizations](https://arxiv.org/abs/2512.14080)
*Wentao Guo,Mayank Mishra,Xinle Cheng,Ion Stoica,Tri Dao*

Main category: cs.LG

TL;DR: SonicMoE：一种内存高效的MoE训练方法，通过减少激活内存缓存、重叠IO计算和token rounding技术，显著提升训练效率。


<details>
  <summary>Details</summary>
Motivation: 当前细粒度MoE模型面临激活内存占用高、硬件效率低的问题，而稀疏MoE在Grouped GEMM内核中存在padding导致的计算浪费。需要解决这些效率瓶颈。

Method: 提出三方面改进：1) 内存高效的前向/反向传播算法，最小化激活缓存；2) 重叠内存IO与计算的GPU内核；3) "token rounding"方法减少Grouped GEMM中的padding浪费。

Result: SonicMoE减少激活内存45%，在Hopper GPU上计算吞吐量提升1.86倍。在64个H100上达到2130亿token/天的训练吞吐量，接近ScatterMoE在96个H100上的性能。token rounding算法在高稀疏设置下带来额外1.16倍加速。

Conclusion: SonicMoE通过系统级优化解决了MoE训练的内存和计算效率问题，显著提升训练速度同时保持模型性能，为大规模MoE模型训练提供了高效解决方案。

Abstract: Mixture of Experts (MoE) models have emerged as the de facto architecture for scaling up language models without significantly increasing the computational cost. Recent MoE models demonstrate a clear trend towards high expert granularity (smaller expert intermediate dimension) and higher sparsity (constant number of activated experts with higher number of total experts), which improve model quality per FLOP. However, fine-grained MoEs suffer from increased activation memory footprint and reduced hardware efficiency due to higher IO costs, while sparser MoEs suffer from wasted computations due to padding in Grouped GEMM kernels. In response, we propose a memory-efficient algorithm to compute the forward and backward passes of MoEs with minimal activation caching for the backward pass. We also design GPU kernels that overlap memory IO with computation benefiting all MoE architectures. Finally, we propose a novel "token rounding" method that minimizes the wasted compute due to padding in Grouped GEMM kernels. As a result, our method SonicMoE reduces activation memory by 45% and achieves a 1.86x compute throughput improvement on Hopper GPUs compared to ScatterMoE's BF16 MoE kernel for a fine-grained 7B MoE. Concretely, SonicMoE on 64 H100s achieves a training throughput of 213 billion tokens per day comparable to ScatterMoE's 225 billion tokens per day on 96 H100s for a 7B MoE model training with FSDP-2 using the lm-engine codebase. Under high MoE sparsity settings, our tile-aware token rounding algorithm yields an additional 1.16x speedup on kernel execution time compared to vanilla top-$K$ routing while maintaining similar downstream performance. We open-source all our kernels to enable faster MoE model training.

</details>


### [120] [Derivative-Informed Fourier Neural Operator: Universal Approximation and Applications to PDE-Constrained Optimization](https://arxiv.org/abs/2512.14086)
*Boyuan Yao,Dingcheng Luo,Lianghao Cao,Nikola Kovachki,Thomas O'Leary-Roseberry,Omar Ghattas*

Main category: cs.LG

TL;DR: 提出了导数信息傅里叶神经算子(DIFNOs)的逼近理论和高效训练方法，用于PDE约束优化。DIFNO通过同时最小化输出和Fréchet导数的预测误差来学习高保真算子，在样本复杂度上优于传统FNO。


<details>
  <summary>Details</summary>
Motivation: 传统FNO作为代理模型在PDE约束优化中需要准确的Fréchet导数，而DIFNO能够同时准确模拟算子的响应和灵敏度，从而更有效地解决无限维PDE约束逆问题。

Method: 提出了DIFNO架构，通过最小化输出和Fréchet导数样本的联合预测误差来训练。开发了使用维度约简和多分辨率技术的高效训练方案，显著降低了Fréchet导数学习的内存和计算成本。

Result: 建立了FNO及其Fréchet导数在紧集上的同时通用逼近理论，以及在具有无界支持的输入测度的加权Sobolev空间中的通用逼近理论。数值实验表明DIFNO在非线性扩散-反应、Helmholtz和Navier-Stokes方程上具有优越的样本复杂度。

Conclusion: DIFNOs在算子学习和解决无限维PDE约束逆问题方面具有显著优势，能够在低训练样本量下实现高精度，为PDE约束优化提供了有效的代理模型。

Abstract: We present approximation theories and efficient training methods for derivative-informed Fourier neural operators (DIFNOs) with applications to PDE-constrained optimization. A DIFNO is an FNO trained by minimizing its prediction error jointly on output and Fréchet derivative samples of a high-fidelity operator (e.g., a parametric PDE solution operator). As a result, a DIFNO can closely emulate not only the high-fidelity operator's response but also its sensitivities. To motivate the use of DIFNOs instead of conventional FNOs as surrogate models, we show that accurate surrogate-driven PDE-constrained optimization requires accurate surrogate Fréchet derivatives. Then, for continuously differentiable operators, we establish (i) simultaneous universal approximation of FNOs and their Fréchet derivatives on compact sets, and (ii) universal approximation of FNOs in weighted Sobolev spaces with input measures that have unbounded supports. Our theoretical results certify the capability of FNOs for accurate derivative-informed operator learning and accurate solution of PDE-constrained optimization. Furthermore, we develop efficient training schemes using dimension reduction and multi-resolution techniques that significantly reduce memory and computational costs for Fréchet derivative learning. Numerical examples on nonlinear diffusion--reaction, Helmholtz, and Navier--Stokes equations demonstrate that DIFNOs are superior in sample complexity for operator learning and solving infinite-dimensional PDE-constrained inverse problems, achieving high accuracy at low training sample sizes.

</details>


### [121] [Arithmetic-Intensity-Aware Quantization](https://arxiv.org/abs/2512.14090)
*Taig Singh,Shreshth Rajan,Nikhil Iyer*

Main category: cs.LG

TL;DR: AIQ是一种混合精度量化框架，通过搜索每层比特宽度来最大化算术强度，同时最小化精度损失，从而提升内存受限神经网络推理吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现代神经网络越来越受内存限制，推理吞吐量受DRAM带宽而非计算能力限制。需要一种方法来优化内存使用，提高算术强度。

Method: AIQ是一种后训练量化方法，使用搜索算法在每层量化方案上搜索，最小化算术强度和精度的加权损失。通过混合精度量化选择每层比特宽度。

Result: 在ResNet-20/CIFAR-10上，AIQ将算术强度提高约50%，测试精度损失在1个百分点内，优于全局统一量化。在MobileNetV2上，AIQ配置提供1.66倍吞吐量提升，精度损失在1个百分点内。

Conclusion: AIQ能有效提升内存受限神经网络的推理吞吐量，通过混合精度量化优化算术强度，且自然地更激进地量化较大层。

Abstract: As modern neural networks become increasingly memory-bound, inference throughput is limited by DRAM bandwidth rather than compute. We present Arithmetic-Intensity-Aware Quantization (AIQ), a mixed precision quantization framework that chooses per-layer bit-widths to maximize arithmetic intensity (AI) while minimizing accuracy loss. AIQ is a post-training quantization method that uses search algorithms over per-layer quantization schemes to minimize a weighted loss over AI and accuracy. On ResNet-20/CIFAR-10, AIQ increases AI by ~50% over an FP32 baseline while keeping test accuracy within ~1 percentage point, and outperforming global uniform quantization schemes. On a memory-bound MobileNetV2 architecture, AIQ configurations give a 1.66x higher throughput than the FP32 baseline while keeping test accuracy within 1 percentage point. We also find that AIQ naturally quantizes larger layers more aggressively.

</details>


### [122] [Cornserve: Efficiently Serving Any-to-Any Multimodal Models](https://arxiv.org/abs/2512.14098)
*Jeff J. Ma,Jae-Won Chung,Jisang Ahn,Yizhuo Liang,Akshay Jajoo,Myungjin Lee,Mosharaf Chowdhury*

Main category: cs.LG

TL;DR: Cornserve是一个针对Any-to-Any多模态模型的高效在线服务系统，通过自动规划模型部署和分布式执行，显著提升吞吐量并降低延迟。


<details>
  <summary>Details</summary>
Motivation: Any-to-Any多模态模型（接受文本和多模态数据输入，生成文本和多模态数据输出）在服务时面临请求类型、计算路径和计算规模异构性的挑战，现有服务系统难以高效处理。

Method: 1) 允许开发者描述通用Any-to-Any模型的计算图；2) 规划器根据模型和工作负载特征自动优化部署计划，包括是否及如何将模型分解为更小组件；3) 分布式运行时按照计划高效执行模型。

Result: Cornserve能够高效服务多样化的Any-to-Any模型和工作负载，相比现有解决方案，吞吐量提升最高达3.81倍，尾部延迟降低最高达5.79倍。

Conclusion: Cornserve通过自动化的部署规划和分布式执行，有效解决了Any-to-Any多模态模型在线服务中的异构性挑战，为这类新兴模型提供了高效的服务解决方案。

Abstract: We present Cornserve, an efficient online serving system for an emerging class of multimodal models called Any-to-Any models. Any-to-Any models accept combinations of text and multimodal data (e.g., image, video, audio) as input and also generate combinations of text and multimodal data as output, introducing request type, computation path, and computation scaling heterogeneity in model serving.
  Cornserve allows model developers to describe the computation graph of generic Any-to-Any models, which consists of heterogeneous components such as multimodal encoders, autoregressive models like Large Language Models (LLMs), and multimodal generators like Diffusion Transformers (DiTs). Given this, Cornserve's planner automatically finds an optimized deployment plan for the model, including whether and how to disaggregate the model into smaller components based on model and workload characteristics. Cornserve's distributed runtime then executes the model per the plan, efficiently handling Any-to-Any model heterogeneity during online serving. Evaluations show that Cornserve can efficiently serve diverse Any-to-Any models and workloads, delivering up to 3.81$\times$ throughput improvement and up to 5.79$\times$ tail latency reduction over existing solutions.

</details>


### [123] [A First-Order Logic-Based Alternative to Reward Models in RLHF](https://arxiv.org/abs/2512.14100)
*Chunjin Jian,Xinhua Zhu*

Main category: cs.LG

TL;DR: 提出S-GRPO方法，用逻辑相似性奖励机制替代传统奖励建模，通过形式逻辑一致性引导大语言模型与人类偏好对齐，避免模型崩溃。


<details>
  <summary>Details</summary>
Motivation: 现有RLHF方法依赖奖励模型的质量和稳定性，但传统奖励建模存在启发式估计的局限性。需要一种更稳定、基于逻辑一致性的方法来引导模型对齐人类偏好。

Method: 提出逻辑相似性奖励机制，利用形式逻辑一致性替代传统奖励估计。为防止逻辑强化学习导致模型崩溃，引入S-GRPO（GRPO的监督变体），结合监督组件，联合优化生成项、KL散度正则化和基于标签的目标。

Result: S-GRPO在性能和鲁棒性上均优于标准监督微调（SFT），并能扩展现有偏好学习框架（如GRPO和DPO），提供更灵活、任务自适应的对齐训练方法。

Conclusion: 逻辑相似性奖励机制和S-GRPO框架为RLHF提供了更稳定、逻辑一致的对齐方法，优于传统监督微调，并能增强现有偏好学习框架的适应性。

Abstract: Reinforcement Learning from Human Feedback (RLHF) plays a crucial role in aligning large language models (LLMs) with human values and preferences. However, the quality and stability of the trained reward model largely determine the final alignment performance. Existing approaches such as Proximal Policy Optimization (PPO) rely heavily on reward models to guide LLMs toward human-aligned behaviors.
  In this work, we propose a logic-similarity-based reward mechanism as an alternative to conventional reward modeling. Instead of relying on heuristic reward estimation, our method leverages formal logical consistency to steer model alignment with human preferences. Since real-world questions can be interpreted from multiple perspectives, to ensure that logic-based reinforcement learning does not cause model collapse, we introduce S-GRPO, a supervised variant of the GRPO framework. S-GRPO incorporates an additional supervised component and jointly optimizes the generation term, KL-divergence regularization, and label-based objective during training.
  Experimental results demonstrate that S-GRPO consistently outperforms standard supervised fine-tuning (SFT) in both performance and robustness. Furthermore, it extends existing preference-learning frameworks such as GRPO and DPO, offering a more flexible and task-adaptive approach to alignment training. Our code is available at https://github.com/ChunjinJiang/sgrpo.

</details>


### [124] [PathFinder: Advancing Path Loss Prediction for Single-to-Multi-Transmitter Scenario](https://arxiv.org/abs/2512.14150)
*Zhijie Zhong,Zhiwen Yu,Pengyu Li,Jianming Lv,C. L. Philip Chen,Min Chen*

Main category: cs.LG

TL;DR: PathFinder提出了一种主动建模建筑物和发射器的无线电路径损耗预测架构，通过解耦特征编码和掩码引导低秩注意力机制，解决了现有方法在多发射器场景和分布偏移下的泛化问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的无线电路径损耗预测方法存在三个关键问题：1）被动环境建模，忽略了发射器和关键环境特征；2）过度关注单发射器场景，而现实世界多为多发射器场景；3）过度关注分布内性能，忽略了分布偏移挑战，特别是在训练/测试环境建筑物密度或发射器配置不同时。

Method: 提出PathFinder架构：1）通过解耦特征编码主动建模建筑物和发射器；2）集成掩码引导低秩注意力机制，独立关注接收器和建筑物区域；3）引入发射器导向混合策略进行鲁棒训练；4）创建新的单到多发射器RPP基准（S2MT-RPP）来评估外推性能。

Result: 实验结果表明PathFinder显著优于现有最先进方法，特别是在具有挑战性的多发射器场景中。

Conclusion: PathFinder通过主动环境建模和专门设计的训练策略，有效解决了多发射器场景和分布偏移下的无线电路径损耗预测问题，为5G网络优化和物联网应用提供了更可靠的解决方案。

Abstract: Radio path loss prediction (RPP) is critical for optimizing 5G networks and enabling IoT, smart city, and similar applications. However, current deep learning-based RPP methods lack proactive environmental modeling, struggle with realistic multi-transmitter scenarios, and generalize poorly under distribution shifts, particularly when training/testing environments differ in building density or transmitter configurations. This paper identifies three key issues: (1) passive environmental modeling that overlooks transmitters and key environmental features; (2) overemphasis on single-transmitter scenarios despite real-world multi-transmitter prevalence; (3) excessive focus on in-distribution performance while neglecting distribution shift challenges. To address these, we propose PathFinder, a novel architecture that actively models buildings and transmitters via disentangled feature encoding and integrates Mask-Guided Low-rank Attention to independently focus on receiver and building regions. We also introduce a Transmitter-Oriented Mixup strategy for robust training and a new benchmark, single-to-multi-transmitter RPP (S2MT-RPP), tailored to evaluate extrapolation performance (multi-transmitter testing after single-transmitter training). Experimental results show PathFinder outperforms state-of-the-art methods significantly, especially in challenging multi-transmitter scenarios. Our code and project site are available at: https://emorzz1g.github.io/PathFinder/.

</details>


### [125] [On Improving Deep Active Learning with Formal Verification](https://arxiv.org/abs/2512.14170)
*Jonathan Spiegelman,Guy Amir,Guy Katz*

Main category: cs.LG

TL;DR: 本文研究如何通过添加违反鲁棒性约束的对抗样本来提升深度主动学习性能，发现形式验证生成的对抗样本比梯度攻击更有效，能显著提高模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 深度主动学习旨在减少神经网络训练中的标注成本，但现有方法主要关注选择哪些样本进行标注。本文探索通过添加无需人工标注的对抗样本来进一步提升数据效率，特别是研究违反鲁棒性约束的对抗样本如何改善主动学习性能。

Method: 提出在深度主动学习中通过形式验证生成对抗样本来增强训练数据，将这种方法扩展到多种现代DAL技术中，并提出了一个新的技术方案。使用形式验证生成的对抗样本比传统梯度攻击方法更有效。

Result: 实验表明，形式验证生成的对抗样本相比标准梯度攻击方法能显著提升模型性能。该方法在多个现代DAL技术和提出的新技术中都取得了显著改进，在标准基准测试中提高了模型的泛化能力。

Conclusion: 通过形式验证生成对抗样本来增强训练数据是提升深度主动学习性能的有效方法，这种方法比传统梯度攻击更有效，能显著提高模型在标准基准测试中的泛化表现。

Abstract: Deep Active Learning (DAL) aims to reduce labeling costs in neural-network training by prioritizing the most informative unlabeled samples for annotation. Beyond selecting which samples to label, several DAL approaches further enhance data efficiency by augmenting the training set with synthetic inputs that do not require additional manual labeling. In this work, we investigate how augmenting the training data with adversarial inputs that violate robustness constraints can improve DAL performance. We show that adversarial examples generated via formal verification contribute substantially more than those produced by standard, gradient-based attacks. We apply this extension to multiple modern DAL techniques, as well as to a new technique that we propose, and show that it yields significant improvements in model generalization across standard benchmarks.

</details>


### [126] [Optimizing the Adversarial Perturbation with a Momentum-based Adaptive Matrix](https://arxiv.org/abs/2512.14188)
*Wei Tao,Sheng Long,Xin Liu,Wei Li,Qing Tao*

Main category: cs.LG

TL;DR: 提出AdaMI攻击方法，使用动量自适应矩阵优化对抗扰动，解决MI-FGSM不收敛问题，提升对抗样本可迁移性


<details>
  <summary>Details</summary>
Motivation: 现有基于优化的对抗攻击（如PGD、MI-FGSM）使用符号函数缩放扰动，从优化理论角度存在收敛性问题。研究发现PGD实际上是特定形式的投影梯度法，而使用自适应矩阵可将其转化为AdaGrad，这启发了新的攻击方法设计。

Method: 提出AdaMI攻击方法，使用动量自适应矩阵优化对抗扰动。该方法将PGD重新表述为仅使用当前梯度确定步长的投影梯度法，并引入基于累积梯度的自适应矩阵，证明在凸问题上能达到最优收敛。

Result: 实验表明AdaMI在保持更好稳定性和不可感知性的同时，能有效提升对抗样本在不同网络间的可迁移性，优于现有最先进方法。

Conclusion: 动量自适应矩阵可作为通用有效技术提升对抗攻击性能，AdaMI解决了MI-FGSM的不收敛问题，确保了优化过程的稳定性。

Abstract: Generating adversarial examples (AEs) can be formulated as an optimization problem. Among various optimization-based attacks, the gradient-based PGD and the momentum-based MI-FGSM have garnered considerable interest. However, all these attacks use the sign function to scale their perturbations, which raises several theoretical concerns from the point of view of optimization. In this paper, we first reveal that PGD is actually a specific reformulation of the projected gradient method using only the current gradient to determine its step-size. Further, we show that when we utilize a conventional adaptive matrix with the accumulated gradients to scale the perturbation, PGD becomes AdaGrad. Motivated by this analysis, we present a novel momentum-based attack AdaMI, in which the perturbation is optimized with an interesting momentum-based adaptive matrix. AdaMI is proved to attain optimal convergence for convex problems, indicating that it addresses the non-convergence issue of MI-FGSM, thereby ensuring stability of the optimization process. The experiments demonstrate that the proposed momentum-based adaptive matrix can serve as a general and effective technique to boost adversarial transferability over the state-of-the-art methods across different networks while maintaining better stability and imperceptibility.

</details>


### [127] [Random-Bridges as Stochastic Transports for Generative Models](https://arxiv.org/abs/2512.14190)
*Stefano Goria,Levent A. Mengütürk,Murat C. Mengütürk,Berkan Sesen*

Main category: cs.LG

TL;DR: 提出使用随机桥（random-bridges）作为生成模型中的随机传输方法，能在较少步骤内生成高质量样本，计算成本低且适合高速生成任务。


<details>
  <summary>Details</summary>
Motivation: 在生成建模领域引入随机桥的概念，作为两个概率分布之间的随机传输方法。随机桥可以根据驱动过程表现出马尔可夫或非马尔可夫特性，以及连续、不连续或混合模式，为生成模型提供更灵活的框架。

Method: 从一般概率陈述出发，推导出具体的学习和模拟算法表示。基于高斯随机桥构建方法，通过信息处理的角度实现随机桥的表示和计算。

Result: 基于高斯随机桥的实证结果能够在显著减少步骤的情况下生成高质量样本，同时获得有竞争力的Frechet inception distance分数。证明该框架计算成本低，适合高速生成任务。

Conclusion: 随机桥框架为生成建模提供了有效的随机传输方法，在保持生成质量的同时大幅减少计算步骤，具有实际应用价值，特别适合需要高速生成的任务场景。

Abstract: This paper motivates the use of random-bridges -- stochastic processes conditioned to take target distributions at fixed timepoints -- in the realm of generative modelling. Herein, random-bridges can act as stochastic transports between two probability distributions when appropriately initialized, and can display either Markovian or non-Markovian, and either continuous, discontinuous or hybrid patterns depending on the driving process. We show how one can start from general probabilistic statements and then branch out into specific representations for learning and simulation algorithms in terms of information processing. Our empirical results, built on Gaussian random bridges, produce high-quality samples in significantly fewer steps compared to traditional approaches, while achieving competitive Frechet inception distance scores. Our analysis provides evidence that the proposed framework is computationally cheap and suitable for high-speed generation tasks.

</details>


### [128] [Understanding and Improving Hyperbolic Deep Reinforcement Learning](https://arxiv.org/abs/2512.14202)
*Timo Klein,Thomas Lang,Andrii Shkabrii,Alexander Sturm,Kevin Sidak,Lukas Miklautz,Claudia Plant,Yllka Velaj,Sebastian Tschiatschek*

Main category: cs.LG

TL;DR: 提出Hyper++，一种改进的双曲强化学习智能体，通过稳定批评家训练、特征正则化和优化友好的双曲层，解决双曲特征空间在RL中的优化不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 双曲特征空间能自然捕捉复杂RL环境中的层次和关系结构，但由于RL的非平稳性，在双曲空间中训练面临优化挑战，特别是大范数嵌入会导致梯度训练不稳定。

Method: 分析Poincaré Ball和Hyperboloid模型中核心操作的梯度，识别训练失败因素。提出Hyper++：1) 使用分类值损失而非回归的稳定批评家训练；2) 保证有界范数同时避免裁剪维度诅咒的特征正则化；3) 优化友好的双曲网络层公式。

Result: 在ProcGen上，Hyper++保证稳定学习，优于先前双曲智能体，减少约30%的挂钟时间。在Atari-5的Double DQN中，显著优于欧几里得和双曲基线。

Conclusion: 通过系统分析双曲RL的优化挑战并引入Hyper++，成功解决了双曲特征空间在强化学习中的训练稳定性问题，实现了更好的性能和效率。

Abstract: The performance of reinforcement learning (RL) agents depends critically on the quality of the underlying feature representations. Hyperbolic feature spaces are well-suited for this purpose, as they naturally capture hierarchical and relational structure often present in complex RL environments. However, leveraging these spaces commonly faces optimization challenges due to the nonstationarity of RL. In this work, we identify key factors that determine the success and failure of training hyperbolic deep RL agents. By analyzing the gradients of core operations in the Poincaré Ball and Hyperboloid models of hyperbolic geometry, we show that large-norm embeddings destabilize gradient-based training, leading to trust-region violations in proximal policy optimization (PPO). Based on these insights, we introduce Hyper++, a new hyperbolic PPO agent that consists of three components: (i) stable critic training through a categorical value loss instead of regression; (ii) feature regularization guaranteeing bounded norms while avoiding the curse of dimensionality from clipping; and (iii) using a more optimization-friendly formulation of hyperbolic network layers. In experiments on ProcGen, we show that Hyper++ guarantees stable learning, outperforms prior hyperbolic agents, and reduces wall-clock time by approximately 30%. On Atari-5 with Double DQN, Hyper++ strongly outperforms Euclidean and hyperbolic baselines. We release our code at https://github.com/Probabilistic-and-Interactive-ML/hyper-rl .

</details>


### [129] [Estimating problem difficulty without ground truth using Large Language Model comparisons](https://arxiv.org/abs/2512.14220)
*Marthe Ballon,Andres Algaba,Brecht Verbeken,Vincent Ginis*

Main category: cs.LG

TL;DR: 提出LLM compare方法，通过大语言模型进行成对难度比较，使用Bradley-Terry评分估计问题难度，解决现有方法无法评估超出分布问题的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有难度评估方法（如人工校准或基于性能的评分）无法泛化到超出分布的问题（人类和LLM目前无法解决的问题），因为这些方法不可扩展、耗时且依赖真实标签。

Method: LLM compare方法：让大语言模型进行成对难度比较，然后基于比较结果计算Bradley-Terry评分。该方法连续动态、模型无关且不依赖真实标签信息。

Result: 1) 概念框架验证显示LLM compare占据所有理想象限；2) 与人类标注高度一致（Pearson r ≥ 0.80，n=1876）；3) 对幻觉具有鲁棒性（10%噪声注入下Pearson相关性下降小于6%）。

Conclusion: LLM compare是首个连续动态、模型无关且不依赖真实标签的难度评估方法，可替代耗时的人工标注和合成数据生成，对课程设计、模型评估和AI辅助研究构思有重要推动作用。

Abstract: Recent advances in the finetuning of large language models (LLMs) have significantly improved their performance on established benchmarks, emphasizing the need for increasingly difficult, synthetic data. A key step in this data generation pipeline is a method for estimating problem difficulty. Current approaches, such as human calibration or performance-based scoring, fail to generalize to out-of-distribution problems, i.e. problems currently unsolvable by humans and LLMs, because they are not scalable, time-consuming, and ground truth dependent. Therefore, we propose a new method for estimating problem difficulty, LLM compare, that addresses these limitations. An LLM performs pairwise difficulty comparisons, and then Bradley-Terry scores are computed based on the outcomes. To validate our method, we first propose a conceptual framework that positions existing approaches on three orthogonal planes--construction, scale and dependence--identifying which quadrants a measure needs to occupy to score out-of-distribution problems. LLM compare naturally occupies all desirable quadrants as the first measure that is continuous and dynamic, model-agnostic and independent of ground truth information. As a second validation, we show that LLM compare demonstrates strong alignment with human annotations: Pearson $r \geq 0.80$ for $n=1876$. Thirdly, we show that LLM compare is robust to hallucinations, with less than $6\%$ degradation in Pearson correlation for $10\%$ noise injection. Our work represents a significant step towards replacing time-consuming human annotations and synthetic data generation, and will be an important driver for curriculum design, model evaluation, and AI-assisted research ideation.

</details>


### [130] [Understanding the Gain from Data Filtering in Multimodal Contrastive Learning](https://arxiv.org/abs/2512.14230)
*Divyansh Pareek,Sewoong Oh,Simon S. Du*

Main category: cs.LG

TL;DR: 论文通过理论分析证明了教师模型过滤在多模态对比学习中的有效性，量化了过滤前后误差的上下界，显示过滤能显著提升学习效果。


<details>
  <summary>Details</summary>
Motivation: 现代多模态表示学习依赖互联网规模数据集，但原始网络数据质量参差不齐，数据筛选成为关键步骤。教师模型过滤方法在实践中表现出色，但缺乏理论解释其成功原因。

Method: 采用标准双模态数据生成模型，在线性对比学习框架下，分析教师模型过滤的理论性能。通过数学推导量化过滤前后误差的上下界，特别关注正确匹配数据比例η的影响。

Result: 理论分析显示：未过滤时误差上下界为1/(η√n)；教师模型过滤后，大η区域误差上界为1/√(ηn)，小η区域误差上界为1/√n，证明过滤能显著降低误差。

Conclusion: 教师模型过滤在多模态对比学习中具有理论保证的有效性，能够显著提升学习性能，特别是在数据匹配质量较低的情况下效果更为明显。

Abstract: The success of modern multimodal representation learning relies on internet-scale datasets. Due to the low quality of a large fraction of raw web data, data curation has become a critical step in the training pipeline. Filtering using a trained model (i.e., teacher-based filtering) has emerged as a successful solution, leveraging a pre-trained model to compute quality scores. To explain the empirical success of teacher-based filtering, we characterize the performance of filtered contrastive learning under the standard bimodal data generation model. Denoting $η\in(0,1]$ as the fraction of data with correctly matched modalities among $n$ paired samples, we utilize a linear contrastive learning setup to show a provable benefit of data filtering: $(i)$ the error without filtering is upper and lower bounded by $\frac{1}{η\sqrt{n}}$, and $(ii)$ the error with teacher-based filtering is upper bounded by $\frac{1}{\sqrt{ηn}}$ in the large $η$ regime, and by $\frac{1}{\sqrt{n}}$ in the small $η$ regime.

</details>


### [131] [Physically consistent model learning for reaction-diffusion systems](https://arxiv.org/abs/2512.14240)
*Erion Morina,Martin Holler*

Main category: cs.LG

TL;DR: 提出了一种从数据中学习反应-扩散系统的方法，确保物理一致性和适定性，通过修改参数化反应项来保证质量守恒和拟正性。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动模型学习反应-扩散系统时，往往无法保证物理一致性（如质量守恒、非负性）和适定性，这限制了模型的可靠性和可解释性。

Method: 基于正则化框架，提出系统修改参数化反应项的技术，使其固有地满足质量守恒和拟正性，并扩展理论结果到物理一致的反应-扩散系统。

Result: 证明了学习问题的解收敛到唯一正则化最小化解，即使强制守恒定律和拟正性；提供了拟正函数的逼近结果，支持物理一致参数化构造。

Conclusion: 该方法推进了可解释且可靠的数据驱动反应-扩散模型的发展，确保模型符合基本物理定律，为物理一致的系统辨识提供了理论保证。

Abstract: This paper addresses the problem of learning reaction-diffusion (RD) systems from data while ensuring physical consistency and well-posedness of the learned models. Building on a regularization-based framework for structured model learning, we focus on learning parameterized reaction terms and investigate how to incorporate key physical properties, such as mass conservation and quasipositivity, directly into the learning process. Our main contributions are twofold: First, we propose techniques to systematically modify a given class of parameterized reaction terms such that the resulting terms inherently satisfy mass conservation and quasipositivity, ensuring that the learned RD systems preserve non-negativity and adhere to physical principles. These modifications also guarantee well-posedness of the resulting PDEs under additional regularity and growth conditions. Second, we extend existing theoretical results on regularization-based model learning to RD systems using these physically consistent reaction terms. Specifically, we prove that solutions to the learning problem converge to a unique, regularization-minimizing solution of a limit system even when conservation laws and quasipositivity are enforced. In addition, we provide approximation results for quasipositive functions, essential for constructing physically consistent parameterizations. These results advance the development of interpretable and reliable data-driven models for RD systems that align with fundamental physical laws.

</details>


### [132] [Beyond MMD: Evaluating Graph Generative Models with Geometric Deep Learning](https://arxiv.org/abs/2512.14241)
*Salvatore Romano,Marco Grassia,Giuseppe Mangioni*

Main category: cs.LG

TL;DR: 本文提出了一种名为RGM的新方法，用于评估图生成模型，克服了传统最大均值差异(MMD)的局限性，并对GRAN和EDGE两种先进模型进行了全面评估。


<details>
  <summary>Details</summary>
Motivation: 图生成在许多领域至关重要，但现有评估方法主要依赖最大均值差异(MMD)来衡量生成图的性质分布，这种方法存在局限性，需要更有效的评估方法。

Method: 提出了RGM（Representation-aware Graph-generation Model evaluation）评估方法，使用几何深度学习模型在专门设计的合成和真实图数据集上进行图分类任务，以评估生成模型。

Result: 对GRAN和EDGE两种先进图生成模型的评估显示，虽然两者都能生成具有某些拓扑性质的图，但在保持区分不同图域的结构特征方面存在显著局限性。

Conclusion: 最大均值差异(MMD)作为图生成模型的评估指标存在不足，需要采用替代方法，RGM方法为未来研究提供了新的评估框架。

Abstract: Graph generation is a crucial task in many fields, including network science and bioinformatics, as it enables the creation of synthetic graphs that mimic the properties of real-world networks for various applications. Graph Generative Models (GGMs) have emerged as a promising solution to this problem, leveraging deep learning techniques to learn the underlying distribution of real-world graphs and generate new samples that closely resemble them. Examples include approaches based on Variational Auto-Encoders, Recurrent Neural Networks, and more recently, diffusion-based models. However, the main limitation often lies in the evaluation process, which typically relies on Maximum Mean Discrepancy (MMD) as a metric to assess the distribution of graph properties in the generated ensemble. This paper introduces a novel methodology for evaluating GGMs that overcomes the limitations of MMD, which we call RGM (Representation-aware Graph-generation Model evaluation). As a practical demonstration of our methodology, we present a comprehensive evaluation of two state-of-the-art Graph Generative Models: Graph Recurrent Attention Networks (GRAN) and Efficient and Degree-guided graph GEnerative model (EDGE). We investigate their performance in generating realistic graphs and compare them using a Geometric Deep Learning model trained on a custom dataset of synthetic and real-world graphs, specifically designed for graph classification tasks. Our findings reveal that while both models can generate graphs with certain topological properties, they exhibit significant limitations in preserving the structural characteristics that distinguish different graph domains. We also highlight the inadequacy of Maximum Mean Discrepancy as an evaluation metric for GGMs and suggest alternative approaches for future research.

</details>


### [133] [FLAME: Flow Enhanced Legendre Memory Models for General Time Series Forecasting](https://arxiv.org/abs/2512.14253)
*Xingjian Wu,Hanyin Cheng,Xiangfei Qiu,Zhengyu Li,Jilin Hu,Chenjuan Guo,Bin Yang*

Main category: cs.LG

TL;DR: FLAME是一个极轻量级的时间序列基础模型家族，通过生成式概率建模同时支持确定性和概率性预测，结合Legendre Memory实现强泛化能力，在零样本预测任务中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测模型通常需要在效率和鲁棒性之间权衡，难以同时支持确定性和概率性预测。需要开发一个既能高效处理长序列又能准确建模复杂分布的轻量级基础模型。

Method: 1) 采用Legendre Memory增强泛化能力，通过LegT和LegS变体在编码和解码阶段捕获数据内在归纳偏置；2) 使用归一化流(Normalization Flow)作为预测头，以生成方式建模预测范围内的任意复杂分布；3) 整体架构支持高效的长程推理。

Result: 在TSFM-Bench和ProbTS等权威基准测试中，FLAME在确定性和概率性预测任务上都取得了最先进的零样本性能，证明了其优越的泛化能力和预测准确性。

Conclusion: FLAME成功构建了一个极轻量级的时间序列基础模型，通过Legendre Memory和归一化流技术的结合，实现了高效、鲁棒且能同时处理确定性和概率性预测的统一框架，为零样本时间序列预测提供了有力工具。

Abstract: In this work, we introduce FLAME, a family of extremely lightweight and capable Time Series Foundation Models, which support both deterministic and probabilistic forecasting via generative probabilistic modeling, thus ensuring both efficiency and robustness. FLAME utilizes the Legendre Memory for strong generalization capabilities. Through adapting variants of Legendre Memory, i.e., translated Legendre (LegT) and scaled Legendre (LegS), in the Encoding and Decoding phases, FLAME can effectively capture the inherent inductive bias within data and make efficient long-range inferences. To enhance the accuracy of probabilistic forecasting while keeping efficient, FLAME adopts a Normalization Flow based forecasting head, which can model the arbitrarily intricate distributions over the forecasting horizon in a generative manner. Comprehensive experiments on well-recognized benchmarks, including TSFM-Bench and ProbTS, demonstrate the consistent state-of-the-art zero-shot performance of FLAME on both deterministic and probabilistic forecasting tasks.

</details>


### [134] [Explainable Preference Learning: a Decision Tree-based Surrogate Model for Preferential Bayesian Optimization](https://arxiv.org/abs/2512.14263)
*Nick Leenders,Thomas Quadt,Boris Cule,Roy Lindelauf,Herman Monsuur,Joost van Oijen,Mark Voskuijl*

Main category: cs.LG

TL;DR: 提出基于决策树的解释性贝叶斯优化模型，解决高斯过程模型在解释性、分类数据处理和计算复杂度方面的限制，在尖峰函数上表现更优，并应用于寿司偏好学习。


<details>
  <summary>Details</summary>
Motivation: 当前基于高斯过程的偏好贝叶斯优化方法存在三个主要问题：模型难以解释、处理分类数据困难、计算复杂度高，限制了实际应用。

Method: 引入基于决策树的解释性代理模型，能够同时处理分类和连续数据，并扩展到大型数据集。

Result: 在八个逐渐尖峰的优化函数上，新模型在尖峰函数上优于基于高斯过程的替代方法，在非尖峰函数上性能仅略低。在真实寿司数据集上成功学习个体偏好，并初步探索利用历史偏好数据加速新用户优化。

Conclusion: 决策树基代理模型为偏好贝叶斯优化提供了更可解释、更灵活且计算效率更高的替代方案，特别适用于尖峰函数和包含分类数据的实际应用场景。

Abstract: Current Preferential Bayesian Optimization methods rely on Gaussian Processes (GPs) as surrogate models. These models are hard to interpret, struggle with handling categorical data, and are computationally complex, limiting their real-world usability. In this paper, we introduce an inherently interpretable decision tree-based surrogate model capable of handling both categorical and continuous data, and scalable to large datasets. Extensive numerical experiments on eight increasingly spiky optimization functions show that our model outperforms GP-based alternatives on spiky functions and has only marginally lower performance for non-spiky functions. Moreover, we apply our model to the real-world Sushi dataset and show its ability to learn an individual's sushi preferences. Finally, we show some initial work on using historical preference data to speed up the optimization process for new unseen users.

</details>


### [135] [Implicit Bias and Invariance: How Hopfield Networks Efficiently Learn Graph Orbits](https://arxiv.org/abs/2512.14338)
*Michael Murray,Tenzin Chan,Kedar Karhadker,Christopher J. Hillar*

Main category: cs.LG

TL;DR: Hopfield网络能从少量随机样本中推断图的同构类，其学习过程具有向范数效率解的隐式偏置，这驱动了群结构数据下近似不变性的涌现。


<details>
  <summary>Details</summary>
Motivation: 研究神经网络在群结构数据训练中不变性的涌现现象，特别是Hopfield网络如何从少量样本学习图的同构类。

Method: 使用经典Hopfield网络，通过最小化能量流（MEF）的梯度下降方法，分析网络对图同构类的学习能力。

Result: 发现图同构类可在三维不变子空间中表示；梯度下降的范数效率偏置支持多项式样本复杂度；多种学习规则下参数都收敛到不变子空间。

Conclusion: Hopfield网络中的泛化机制统一解释为：学习过程中的范数效率偏置驱动了群结构数据下近似不变性的涌现。

Abstract: Many learning problems involve symmetries, and while invariance can be built into neural architectures, it can also emerge implicitly when training on group-structured data. We study this phenomenon in classical Hopfield networks and show they can infer the full isomorphism class of a graph from a small random sample. Our results reveal that: (i) graph isomorphism classes can be represented within a three-dimensional invariant subspace, (ii) using gradient descent to minimize energy flow (MEF) has an implicit bias toward norm-efficient solutions, which underpins a polynomial sample complexity bound for learning isomorphism classes, and (iii) across multiple learning rules, parameters converge toward the invariant subspace as sample sizes grow. Together, these findings highlight a unifying mechanism for generalization in Hopfield networks: a bias toward norm efficiency in learning drives the emergence of approximate invariance under group-structured data.

</details>


### [136] [Causal Structure Learning for Dynamical Systems with Theoretical Score Analysis](https://arxiv.org/abs/2512.14361)
*Nicholas Tagliapietra,Katharina Ensinger,Christoph Zimmer,Osman Mian*

Main category: cs.LG

TL;DR: CaDyT：一种基于差分因果模型和高斯过程推理的连续时间因果发现方法，在规则和不规则采样数据上优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现实世界系统按照其潜在因果关系在连续时间中演化，但现有方法要么离散化时间导致不规则采样数据性能差，要么忽略底层因果关系。需要一种能同时解决这两个挑战的方法。

Method: 提出CaDyT方法，基于差分因果模型（允许更温和的假设来建模系统的连续性质），利用精确高斯过程推理建模连续时间动态，通过算法马尔可夫条件和最小描述长度原则指导的贪婪搜索来识别因果结构。

Result: CaDyT在规则和不规则采样数据上都优于现有最先进方法，发现的因果网络更接近真实底层动态。

Conclusion: CaDyT通过结合差分因果模型和连续时间高斯过程推理，有效解决了动态系统中因果发现的挑战，在保持连续时间建模的同时准确识别因果关系。

Abstract: Real world systems evolve in continuous-time according to their underlying causal relationships, yet their dynamics are often unknown. Existing approaches to learning such dynamics typically either discretize time -- leading to poor performance on irregularly sampled data -- or ignore the underlying causality. We propose CaDyT, a novel method for causal discovery on dynamical systems addressing both these challenges. In contrast to state-of-the-art causal discovery methods that model the problem using discrete-time Dynamic Bayesian networks, our formulation is grounded in Difference-based causal models, which allow milder assumptions for modeling the continuous nature of the system. CaDyT leverages exact Gaussian Process inference for modeling the continuous-time dynamics which is more aligned with the underlying dynamical process. We propose a practical instantiation that identifies the causal structure via a greedy search guided by the Algorithmic Markov Condition and Minimum Description Length principle. Our experiments show that CaDyT outperforms state-of-the-art methods on both regularly and irregularly-sampled data, discovering causal networks closer to the true underlying dynamics.

</details>


### [137] [Black-Box Auditing of Quantum Model: Lifted Differential Privacy with Quantum Canaries](https://arxiv.org/abs/2512.14388)
*Baobao Song,Shiva Raj Pokhrel,Athanasios V. Vasilakos,Tianqing Zhu,Gang Li*

Main category: cs.LG

TL;DR: 首个针对量子机器学习的黑盒隐私审计框架，基于提升量子差分隐私，使用量子金丝雀检测记忆化并量化隐私泄露，填补理论保证与实际验证之间的关键空白。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习在处理敏感数据时存在记忆化个体记录的风险，带来严重隐私漏洞。现有的量子差分隐私机制虽然提供理论最坏情况保证，但缺乏对已部署模型进行实证验证的工具。

Method: 提出基于提升量子差分隐私的黑盒隐私审计框架，利用量子金丝雀（战略偏移编码的量子态）检测记忆化，通过建立金丝雀偏移与迹距离界限之间的数学联系，推导隐私预算消耗的经验下界。

Result: 在模拟和物理量子硬件上的全面评估表明，该框架能有效测量QML模型的实际隐私损失，实现量子机器学习系统中稳健的隐私验证。

Conclusion: 该研究填补了量子差分隐私理论保证与实际隐私验证之间的关键空白，为量子机器学习系统提供了首个实用的黑盒隐私审计框架，能够精确量化训练过程中的隐私泄露。

Abstract: Quantum machine learning (QML) promises significant computational advantages, yet models trained on sensitive data risk memorizing individual records, creating serious privacy vulnerabilities. While Quantum Differential Privacy (QDP) mechanisms provide theoretical worst-case guarantees, they critically lack empirical verification tools for deployed models. We introduce the first black-box privacy auditing framework for QML based on Lifted Quantum Differential Privacy, leveraging quantum canaries (strategically offset-encoded quantum states) to detect memorization and precisely quantify privacy leakage during training. Our framework establishes a rigorous mathematical connection between canary offset and trace distance bounds, deriving empirical lower bounds on privacy budget consumption that bridge the critical gap between theoretical guarantees and practical privacy verification. Comprehensive evaluations across both simulated and physical quantum hardware demonstrate our framework's effectiveness in measuring actual privacy loss in QML models, enabling robust privacy verification in QML systems.

</details>


### [138] [RePo: Language Models with Context Re-Positioning](https://arxiv.org/abs/2512.14391)
*Huayang Li,Tianyu Zhao,Richard Sproat*

Main category: cs.LG

TL;DR: RePo提出了一种新的上下文重新定位机制，通过可微分模块动态分配token位置来捕获上下文依赖关系，减少额外认知负荷，提升长上下文、噪声上下文和结构化数据任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM架构使用固定线性或常数位置索引，这种无信息结构增加了额外认知负荷，消耗了本应用于深度推理和注意力分配的有限工作记忆容量。基于认知负荷理论，需要减少这种额外负荷。

Method: 提出RePo机制，使用可微分模块f_φ动态分配token位置来捕获上下文依赖关系，而不是依赖预定义的整数范围。通过在OLMo-2 1B骨干网络上持续预训练实现。

Result: RePo在涉及噪声上下文、结构化数据和较长上下文长度的任务上显著提升性能，同时在一般短上下文任务上保持竞争力。分析显示RePo能更好地关注远距离相关信息，在密集非线性空间中分配位置，并捕获输入上下文的内在结构。

Conclusion: RePo通过动态上下文重新定位有效减少额外认知负荷，提升LLM在复杂上下文任务中的性能，为更灵活的上下文建模提供了新方向。

Abstract: In-context learning is fundamental to modern Large Language Models (LLMs); however, prevailing architectures impose a rigid and fixed contextual structure by assigning linear or constant positional indices. Drawing on Cognitive Load Theory (CLT), we argue that this uninformative structure increases extraneous cognitive load, consuming finite working memory capacity that should be allocated to deep reasoning and attention allocation. To address this, we propose RePo, a novel mechanism that reduces extraneous load via context re-positioning. Unlike standard approaches, RePo utilizes a differentiable module, $f_φ$, to assign token positions that capture contextual dependencies, rather than replying on pre-defined integer range. By continually pre-training on the OLMo-2 1B backbone, we demonstrate that RePo significantly enhances performance on tasks involving noisy contexts, structured data, and longer context length, while maintaining competitive performance on general short-context tasks. Detailed analysis reveals that RePo successfully allocate higher attention to distant but relevant information, assign positions in dense and non-linear space, and capture the intrinsic structure of the input context. Our code is available at https://github.com/SakanaAI/repo.

</details>


### [139] [SuperWing: a comprehensive transonic wing dataset for data-driven aerodynamic design](https://arxiv.org/abs/2512.14397)
*Yunjia Yang,Weishao Tang,Mengxin Liu,Nils Thuerey,Yufei Zhang,Haixin Chen*

Main category: cs.LG

TL;DR: SuperWing是一个包含4,239个参数化机翼几何和28,856个RANS流场解的开源数据集，用于训练可推广的三维机翼气动预测机器学习模型。


<details>
  <summary>Details</summary>
Motivation: 现有三维机翼数据集稀缺且多样性有限，限制了机器学习代理模型在气动设计中的通用性发展。

Method: 使用简化的几何参数化方法生成机翼形状，包含翼展方向的翼型变化、扭转和上反角，在典型飞行包线范围内进行广泛的马赫数和攻角模拟。

Result: 基于SuperWing训练的最先进Transformer模型能够准确预测表面流动，在保留样本上达到2.5阻力计数误差，并在DLR-F6和NASA CRM等复杂基准机翼上表现出强大的零样本泛化能力。

Conclusion: SuperWing数据集具有足够的多样性和实用性，能够支持开发可推广的三维机翼气动预测模型，促进气动设计加速。

Abstract: Machine-learning surrogate models have shown promise in accelerating aerodynamic design, yet progress toward generalizable predictors for three-dimensional wings has been limited by the scarcity and restricted diversity of existing datasets. Here, we present SuperWing, a comprehensive open dataset of transonic swept-wing aerodynamics comprising 4,239 parameterized wing geometries and 28,856 Reynolds-averaged Navier-Stokes flow field solutions. The wing shapes in the dataset are generated using a simplified yet expressive geometry parameterization that incorporates spanwise variations in airfoil shape, twist, and dihedral, allowing for an enhanced diversity without relying on perturbations of a baseline wing. All shapes are simulated under a broad range of Mach numbers and angles of attack covering the typical flight envelope. To demonstrate the dataset's utility, we benchmark two state-of-the-art Transformers that accurately predict surface flow and achieve a 2.5 drag-count error on held-out samples. Models pretrained on SuperWing further exhibit strong zero-shot generalization to complex benchmark wings such as DLR-F6 and NASA CRM, underscoring the dataset's diversity and potential for practical usage.

</details>


### [140] [GRAFT: Grid-Aware Load Forecasting with Multi-Source Textual Alignment and Fusion](https://arxiv.org/abs/2512.14400)
*Fangzhou Lin,Guoshun He,Zhenyu Guo,Zhe Huang,Jinsong Tao*

Main category: cs.LG

TL;DR: GRAFT是一个用于电力负荷预测的模型，通过文本引导融合和多源信息处理，在澳大利亚五个州的数据集上显著优于基线方法


<details>
  <summary>Details</summary>
Motivation: 电力负荷同时受到天气、日历节奏、突发事件和政策等多种外生因素的影响，需要能够整合多源文本信息并支持电网感知预测的模型

Method: 改进STanHOP模型，严格对齐每日汇总的新闻、社交媒体和政策文本与半小时负荷数据，通过交叉注意力实现文本引导融合，并提供即插即用的外部记忆接口

Result: 在澳大利亚五个州2019-2021年的统一基准测试中，GRAFT在小时、日、月三个时间尺度上显著优于强基线方法，达到或超过最先进水平，在事件驱动场景中表现稳健

Conclusion: GRAFT通过文本引导融合和多源信息处理，在电力负荷预测中实现了优异性能，同时支持时间定位和源级解释，发布的基准和代码有助于标准化评估和可复现性

Abstract: Electric load is simultaneously affected across multiple time scales by exogenous factors such as weather and calendar rhythms, sudden events, and policies. Therefore, this paper proposes GRAFT (GRid-Aware Forecasting with Text), which modifies and improves STanHOP to better support grid-aware forecasting and multi-source textual interventions. Specifically, GRAFT strictly aligns daily-aggregated news, social media, and policy texts with half-hour load, and realizes text-guided fusion to specific time positions via cross-attention during both training and rolling forecasting. In addition, GRAFT provides a plug-and-play external-memory interface to accommodate different information sources in real-world deployment. We construct and release a unified aligned benchmark covering 2019--2021 for five Australian states (half-hour load, daily-aligned weather/calendar variables, and three categories of external texts), and conduct systematic, reproducible evaluations at three scales -- hourly, daily, and monthly -- under a unified protocol for comparison across regions, external sources, and time scales. Experimental results show that GRAFT significantly outperforms strong baselines and reaches or surpasses the state of the art across multiple regions and forecasting horizons. Moreover, the model is robust in event-driven scenarios and enables temporal localization and source-level interpretation of text-to-load effects through attention read-out. We release the benchmark, preprocessing scripts, and forecasting results to facilitate standardized empirical evaluation and reproducibility in power grid load forecasting.

</details>


### [141] [Dual-Axis RCCL: Representation-Complete Convergent Learning for Organic Chemical Space](https://arxiv.org/abs/2512.14418)
*Dejun Hu,Zhiming Li,Jia-Rui Shen,Jia-Ning Tu,Zi-Hao Ye,Junliang Zhang*

Main category: cs.LG

TL;DR: 提出双轴表示-完全收敛学习(RCCL)策略，通过FD25数据集实现有机分子化学空间的近完全覆盖，使图神经网络达到表示完全收敛学习和强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 机器学习正在重塑分子和材料建模，但化学空间极其庞大(10^30-10^60)，模型能否在整个化学空间实现收敛学习仍是一个开放的科学问题。

Method: 引入双轴表示-完全收敛学习(RCCL)策略：1) 基于现代价键理论的图卷积网络编码局部价环境；2) 无桥图编码环/笼拓扑结构。开发FD25数据集，系统覆盖13,302个局部价单元和165,726个环/笼拓扑。

Result: 在FD25上训练的图神经网络表现出表示完全收敛学习和强分布外泛化能力，在外部基准测试中整体预测误差约为1.0 kcal/mol MAE。

Conclusion: 建立了分子表示、结构完整性和模型泛化之间的定量联系，为可解释、可迁移和数据高效的分子智能奠定了基础。

Abstract: Machine learning is profoundly reshaping molecular and materials modeling; however, given the vast scale of chemical space (10^30-10^60), it remains an open scientific question whether models can achieve convergent learning across this space. We introduce a Dual-Axis Representation-Complete Convergent Learning (RCCL) strategy, enabled by a molecular representation that integrates graph convolutional network (GCN) encoding of local valence environments, grounded in modern valence bond theory, together with no-bridge graph (NBG) encoding of ring/cage topologies, providing a quantitative measure of chemical-space coverage. This framework formalizes representation completeness, establishing a principled basis for constructing datasets that support convergent learning for large models. Guided by this RCCL framework, we develop the FD25 dataset, systematically covering 13,302 local valence units and 165,726 ring/cage topologies, achieving near-complete combinatorial coverage of organic molecules with H/C/N/O/F elements. Graph neural networks trained on FD25 exhibit representation-complete convergent learning and strong out-of-distribution generalization, with an overall prediction error of approximately 1.0 kcal/mol MAE across external benchmarks. Our results establish a quantitative link between molecular representation, structural completeness, and model generalization, providing a foundation for interpretable, transferable, and data-efficient molecular intelligence.

</details>


### [142] [Bridging Artificial Intelligence and Data Assimilation: The Data-driven Ensemble Forecasting System ClimaX-LETKF](https://arxiv.org/abs/2512.14444)
*Akira Takeshima,Kenta Shiraishi,Atsushi Okazaki,Tadashi Tsuyuki,Shunji Kotsuki*

Main category: cs.LG

TL;DR: ClimaX-LETKF是首个纯数据驱动的机器学习集合天气预报系统，通过同化NCEP观测数据实现多年稳定运行，发现RTPP比RTPS对MLWP模型更稳定准确，而NWP模型则相反。


<details>
  <summary>Details</summary>
Motivation: 机器学习天气预报已取得显著进展，但在MLWP模型中同化真实观测数据或集合预报的研究仍然有限，需要开发独立于数值天气预报模型的纯数据驱动集合预报系统。

Method: 提出ClimaX-LETKF系统，基于机器学习同化NCEP ADP全球高空和地面天气观测数据，比较了松弛到先验扰动(RTPP)和松弛到先验扩展(RTPS)两种方法的效果。

Result: 系统能稳定运行多年，RTPP比RTPS对MLWP模型更稳定准确，而NWP模型则相反；发现MLWP模型恢复大气场到吸引子的能力弱于NWP模型。

Conclusion: 这项工作为增强MLWP集合预报系统提供了宝贵见解，代表了向实际应用迈出的重要一步，揭示了MLWP与NWP在集合预报中的不同特性。

Abstract: While machine learning-based weather prediction (MLWP) has achieved significant advancements, research on assimilating real observations or ensemble forecasts within MLWP models remains limited. We introduce ClimaX-LETKF, the first purely data-driven ML-based ensemble weather forecasting system. It operates stably over multiple years, independently of numerical weather prediction (NWP) models, by assimilating the NCEP ADP Global Upper Air and Surface Weather Observations. The system demonstrates greater stability and accuracy with relaxation to prior perturbation (RTPP) than with relaxation to prior spread (RTPS), while NWP models tend to be more stable with RTPS. RTPP replaces an analysis perturbation with a weighted blend of analysis and background perturbations, whereas RTPS simply rescales the analysis perturbation. Our experiments reveal that MLWP models are less capable of restoring the atmospheric field to its attractor than NWP models. This work provides valuable insights for enhancing MLWP ensemble forecasting systems and represents a substantial step toward their practical applications.

</details>


### [143] [AnySleep: a channel-agnostic deep learning system for high-resolution sleep staging in multi-center cohorts](https://arxiv.org/abs/2512.14461)
*Niklas Grieger,Jannik Raskob,Siamak Mehrkanoon,Stephan Bialonski*

Main category: cs.LG

TL;DR: AnySleep是一个深度神经网络模型，能够使用任何EEG或EOG数据以可调时间分辨率进行睡眠分期，在跨21个数据集的19,000多个夜间记录上训练，达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 传统睡眠分期需要人工评分，劳动密集且受限于30秒固定时间分辨率，不同中心的PSG记录在电极数量、导联方式和受试者特征上差异很大，这给多中心研究和短时标生物标志物发现带来挑战。

Method: 开发了AnySleep深度神经网络模型，使用任何EEG或EOG数据进行睡眠分期，支持可调时间分辨率。模型在21个数据集的19,000多个夜间记录（近200,000小时EEG和EOG数据）上训练和验证，确保跨站点的鲁棒泛化能力。

Result: 模型达到最先进性能，在30秒时段上超越或等于现有基线。提供更多通道时性能提升，但在EOG缺失或仅使用EOG或单个EEG导联（额、中央或枕部）时仍保持良好性能。在30秒以下时间尺度上，模型能捕捉与觉醒一致的短暂清醒入侵，并改善生理特征（年龄、性别）和病理状况（睡眠呼吸暂停）的预测。

Conclusion: AnySleep模型公开可用，有助于促进具有异质电极设置的大规模研究，并加速睡眠中新生物标志物的发现，解决了传统睡眠分期方法的局限性。

Abstract: Sleep is essential for good health throughout our lives, yet studying its dynamics requires manual sleep staging, a labor-intensive step in sleep research and clinical care. Across centers, polysomnography (PSG) recordings are traditionally scored in 30-s epochs for pragmatic, not physiological, reasons and can vary considerably in electrode count, montage, and subject characteristics. These constraints present challenges in conducting harmonized multi-center sleep studies and discovering novel, robust biomarkers on shorter timescales. Here, we present AnySleep, a deep neural network model that uses any electroencephalography (EEG) or electrooculography (EOG) data to score sleep at adjustable temporal resolutions. We trained and validated the model on over 19,000 overnight recordings from 21 datasets collected across multiple clinics, spanning nearly 200,000 hours of EEG and EOG data, to promote robust generalization across sites. The model attains state-of-the-art performance and surpasses or equals established baselines at 30-s epochs. Performance improves as more channels are provided, yet remains strong when EOG is absent or when only EOG or single EEG derivations (frontal, central, or occipital) are available. On sub-30-s timescales, the model captures short wake intrusions consistent with arousals and improves prediction of physiological characteristics (age, sex) and pathophysiological conditions (sleep apnea), relative to standard 30-s scoring. We make the model publicly available to facilitate large-scale studies with heterogeneous electrode setups and to accelerate the discovery of novel biomarkers in sleep.

</details>


### [144] [Kinetic-Mamba: Mamba-Assisted Predictions of Stiff Chemical Kinetics](https://arxiv.org/abs/2512.14471)
*Additi Pandey,Liang Wei,Hessam Babaee,George Em Karniadakis*

Main category: cs.LG

TL;DR: Kinetic-Mamba：基于Mamba的神经算子框架，用于燃烧模拟中的化学动力学建模，通过三种互补模型预测热化学状态变量的时间演化。


<details>
  <summary>Details</summary>
Motivation: 准确的化学动力学建模对燃烧模拟至关重要，但传统方法计算成本高且难以捕捉复杂反应路径。需要开发高效且准确的替代方案来预测热化学状态的时间演化。

Method: 提出Kinetic-Mamba框架，包含三种模型：(1)独立Mamba模型预测状态变量时间演化；(2)约束Mamba模型在保持质量守恒的同时学习状态动力学；(3)基于温度区间的双Mamba模型架构。还开发了潜在空间变体，在降维空间演化动力学并重构完整状态。

Result: 在Syngas和GRI-Mech 3.0反应机制上的计算实验表明，该框架仅使用状态变量初始条件就能高保真地预测复杂动力学行为，在时间分解和递归预测策略下均表现出良好的准确性和鲁棒性。

Conclusion: Kinetic-Mamba框架成功地将神经算子的表达能力与Mamba架构的高效时间建模能力相结合，为燃烧模拟中的化学动力学建模提供了准确且高效的解决方案，具有良好的外推能力。

Abstract: Accurate chemical kinetics modeling is essential for combustion simulations, as it governs the evolution of complex reaction pathways and thermochemical states. In this work, we introduce Kinetic-Mamba, a Mamba-based neural operator framework that integrates the expressive power of neural operators with the efficient temporal modeling capabilities of Mamba architectures. The framework comprises three complementary models: (i) a standalone Mamba model that predicts the time evolution of thermochemical state variables from given initial conditions; (ii) a constrained Mamba model that enforces mass conservation while learning the state dynamics; and (iii) a regime-informed architecture employing two standalone Mamba models to capture dynamics across temperature-dependent regimes. We additionally develop a latent Kinetic-Mamba variant that evolves dynamics in a reduced latent space and reconstructs the full state on the physical manifold. We evaluate the accuracy and robustness of Kinetic-Mamba using both time-decomposition and recursive-prediction strategies. We further assess the extrapolation capabilities of the model on varied out-of-distribution datasets. Computational experiments on Syngas and GRI-Mech 3.0 reaction mechanisms demonstrate that our framework achieves high fidelity in predicting complex kinetic behavior using only the initial conditions of the state variables.

</details>


### [145] [Improving Slow Transfer Predictions: Generative Methods Compared](https://arxiv.org/abs/2512.14522)
*Jacob Taegon Kim,Alex Sim,Kesheng Wu,Jinoh Kim*

Main category: cs.LG

TL;DR: 该研究针对科学计算网络中数据传输性能预测的类别不平衡问题，比较了多种数据增强策略，发现即使使用先进的CTGAN等生成技术，在高度不平衡情况下性能提升有限，简单分层采样已足够有效。


<details>
  <summary>Details</summary>
Motivation: 科学计算网络中需要早期预测数据传输性能以识别潜在缓慢传输，但机器学习模型面临类别不平衡问题，这限制了预测能力的提升。

Method: 分析比较了多种数据增强策略，包括传统过采样方法和生成技术（如CTGAN），并调整训练数据集中的类别不平衡比例来评估对模型性能的影响。

Result: 虽然数据增强可能改善性能，但随着不平衡比例增加，性能提升并不显著。最先进的技术如CTGAN相比简单的分层采样方法并没有显著优势。

Conclusion: 在处理科学计算网络性能预测的类别不平衡问题时，简单的分层采样方法已经足够有效，即使使用先进的生成技术也无法显著超越这一基线方法。

Abstract: Monitoring data transfer performance is a crucial task in scientific computing networks. By predicting performance early in the communication phase, potentially sluggish transfers can be identified and selectively monitored, optimizing network usage and overall performance. A key bottleneck to improving the predictive power of machine learning (ML) models in this context is the issue of class imbalance. This project focuses on addressing the class imbalance problem to enhance the accuracy of performance predictions. In this study, we analyze and compare various augmentation strategies, including traditional oversampling methods and generative techniques. Additionally, we adjust the class imbalance ratios in training datasets to evaluate their impact on model performance. While augmentation may improve performance, as the imbalance ratio increases, the performance does not significantly improve. We conclude that even the most advanced technique, such as CTGAN, does not significantly improve over simple stratified sampling.

</details>


### [146] [Synthetic Electrogram Generation with Variational Autoencoders for ECGI](https://arxiv.org/abs/2512.14537)
*Miriam Gutiérrez Fernández,Karen López-Linares,Carlos Fambuena Santos,María S. Guillem,Andreu M. Climent,Óscar Barquero Pérez*

Main category: cs.LG

TL;DR: 使用变分自编码器生成合成心房电图以解决配对体表-心内信号数据稀缺问题，提升非侵入性电生理成像性能


<details>
  <summary>Details</summary>
Motivation: 心房颤动是最常见的心律失常，需要准确表征心房电活动。非侵入性心电图成像结合深度学习估计心内电图有前景，但进展受限于配对的体表电位-心内电图数据集稀缺。

Method: 提出两种变分自编码器模型：窦性心律特异性VAE（VAE-S）和类别条件VAE（VAE-C），用于生成合成多通道心房电图。使用形态学、频谱和分布相似性指标评估生成质量。

Result: VAE-S在模拟心内电图方面达到更高保真度，VAE-C支持节律特异性生成但窦性重建质量降低。数据增强实验表明适度增强可改善下游非侵入性心内电图重建任务性能。

Conclusion: 基于VAE的生成模型有潜力缓解数据稀缺问题，增强基于深度学习的非侵入性心电图成像流程，为心房颤动临床评估提供支持。

Abstract: Atrial fibrillation (AF) is the most prevalent sustained cardiac arrhythmia, and its clinical assessment requires accurate characterization of atrial electrical activity. Noninvasive electrocardiographic imaging (ECGI) combined with deep learning (DL) approaches for estimating intracardiac electrograms (EGMs) from body surface potentials (BSPMs) has shown promise, but progress is hindered by the limited availability of paired BSPM-EGM datasets. To address this limitation, we investigate variational autoencoders (VAEs) for the generation of synthetic multichannel atrial EGMs. Two models are proposed: a sinus rhythm-specific VAE (VAE-S) and a class-conditioned VAE (VAE-C) trained on both sinus rhythm and AF signals. Generated EGMs are evaluated using morphological, spectral, and distributional similarity metrics. VAE-S achieves higher fidelity with respect to in silico EGMs, while VAE-C enables rhythm-specific generation at the expense of reduced sinus reconstruction quality. As a proof of concept, the generated EGMs are used for data augmentation in a downstream noninvasive EGM reconstruction task, where moderate augmentation improves estimation performance. These results demonstrate the potential of VAE-based generative modeling to alleviate data scarcity and enhance deep learning-based ECGI pipelines.

</details>


### [147] [Counterfactual Explanations for Time Series Should be Human-Centered and Temporally Coherent in Interventions](https://arxiv.org/abs/2512.14559)
*Emmanuel C. Chukwu,Rianne M. Schouten,Monique Tabak,Mykola Pechenizkiy*

Main category: cs.LG

TL;DR: 本文批评当前时间序列反事实解释方法在临床推荐场景中的不足，指出其过于关注最小输入扰动而忽视因果合理性和时间连贯性，呼吁开发更实用、用户中心的反事实干预方法。


<details>
  <summary>Details</summary>
Motivation: 当前时间序列分类的反事实解释方法主要基于静态数据假设，仅关注通过最小输入扰动来翻转模型预测，这在临床推荐场景中是不够的。临床干预需要随时间展开，必须具有因果合理性和时间连贯性，现有方法存在时间盲点和缺乏用户中心考虑的问题。

Method: 本文采用批判性分析和实证验证相结合的方法。首先论证现有方法的理论缺陷，然后对多种最先进的时间序列反事实方法进行鲁棒性分析，展示这些方法对随机噪声的高度敏感性。

Result: 分析显示，现有时间序列反事实方法生成的解释对随机噪声高度敏感，在现实临床环境中可靠性有限。这些方法忽略了可行性、可操作性和用户特定动态等关键因素。

Conclusion: 需要开发超越单纯预测变化的新方法和评估框架，强调在现实环境中可行、有目的导向的干预措施。反事实解释应反映持续的、目标导向的干预，符合临床推理和患者特定动态，确保在实际应用中具有可操作性。

Abstract: Counterfactual explanations are increasingly proposed as interpretable mechanisms to achieve algorithmic recourse. However, current counterfactual techniques for time series classification are predominantly designed with static data assumptions and focus on generating minimal input perturbations to flip model predictions. This paper argues that such approaches are fundamentally insufficient in clinical recommendation settings, where interventions unfold over time and must be causally plausible and temporally coherent. We advocate for a shift towards counterfactuals that reflect sustained, goal-directed interventions aligned with clinical reasoning and patient-specific dynamics. We identify critical gaps in existing methods that limit their practical applicability, specifically, temporal blind spots and the lack of user-centered considerations in both method design and evaluation metrics. To support our position, we conduct a robustness analysis of several state-of-the-art methods for time series and show that the generated counterfactuals are highly sensitive to stochastic noise. This finding highlights their limited reliability in real-world clinical settings, where minor measurement variations are inevitable. We conclude by calling for methods and evaluation frameworks that go beyond mere prediction changes without considering feasibility or actionability. We emphasize the need for actionable, purpose-driven interventions that are feasible in real-world contexts for the users of such applications.

</details>


### [148] [Residual GRU+MHSA: A Lightweight Hybrid Recurrent Attention Model for Cardiovascular Disease Detection](https://arxiv.org/abs/2512.14563)
*Tejaswani Dash,Gautam Datla,Anudeep Vurity,Tazeem Ahmad,Mohd Adnan,Saima Rafi,Saisha Patro,Saina Patro*

Main category: cs.LG

TL;DR: 提出Residual GRU with Multi-Head Self-Attention架构，用于临床表格数据的心血管疾病预测，在UCI数据集上优于传统和深度学习基线方法。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病是全球主要死因，需要可靠高效的预测工具。传统方法依赖手工特征和临床经验，机器学习方法可提高可重复性但难以在噪声和异质临床数据上泛化。

Method: 提出紧凑深度学习架构：集成残差双向门控循环单元用于特征列的序列建模、通道重加权块、多头部自注意力池化及可学习分类标记以捕获全局上下文。

Result: 在UCI心脏病数据集上，模型准确率0.861，宏F1 0.860，ROC-AUC 0.908，PR-AUC 0.904，优于所有基线方法。消融研究确认各组件贡献，t-SNE可视化显示学习嵌入有更清晰的类别分离。

Conclusion: 轻量级混合循环和注意力架构在临床风险预测中提供了准确性和效率的良好平衡，支持在资源受限的医疗环境中部署。

Abstract: Cardiovascular disease (CVD) remains the leading cause of mortality worldwide, underscoring the need for reliable and efficient predictive tools that support early intervention. Traditional diagnostic approaches rely on handcrafted features and clinician expertise, while machine learning methods improve reproducibility but often struggle to generalize across noisy and heterogeneous clinical data. In this work, we propose Residual GRU with Multi-Head Self-Attention, a compact deep learning architecture designed for tabular clinical records. The model integrates residual bidirectional gated recurrent units for sequential modeling of feature columns, a channel reweighting block, and multi-head self-attention pooling with a learnable classification token to capture global context. We evaluate the model on the UCI Heart Disease dataset using 5-fold stratified cross-validation and compare it against classical methods such as Logistic Regression, Random Forest, and Support Vector Machines, as well as modern deep learning baselines including DeepMLP, convolutional networks, recurrent networks, and Transformers. The proposed model achieves an accuracy of 0.861, macro-F1 of 0.860, ROC-AUC of 0.908, and PR-AUC of 0.904, outperforming all baselines. Ablation studies confirm the individual contributions of residual recurrence, channel gating, and attention pooling. t-SNE visualizations further indicate that the learned embeddings exhibit clearer separation between disease and non-disease classes compared to raw features. These results demonstrate that lightweight hybrid recurrent and attention-based architectures provide a strong balance between accuracy and efficiency for clinical risk prediction, supporting deployment in resource-constrained healthcare settings.

</details>


### [149] [Hybrid Iterative Solvers with Geometry-Aware Neural Preconditioners for Parametric PDEs](https://arxiv.org/abs/2512.14596)
*Youngkyu Lee,Francesc Levrero Florencio,Jay Pathak,George Em Karniadakis*

Main category: cs.LG

TL;DR: Geo-DeepONet：一种几何感知的深度算子网络，结合有限元离散化提取的域信息，可在任意非结构化网格上进行算子学习而无需重新训练，并用于构建几何感知的混合预条件迭代求解器。


<details>
  <summary>Details</summary>
Motivation: 传统迭代求解器对参数偏微分方程（PDEs）的收敛行为高度依赖于几何域和具体离散化。先前提出的混合求解器（结合经典求解器和神经算子）在训练未见的几何域中表现不佳，需要解决几何泛化问题。

Method: 提出Geo-DeepONet，一种几何感知的深度算子网络，从有限元离散化中提取域信息。基于此开发几何感知的混合预条件迭代求解器，将Geo-DeepONet与传统方法（如松弛方案和Krylov子空间算法）结合。

Result: 通过在不同非结构化域上的参数PDE数值实验，证明了所提出的混合求解器在多个实际应用中具有增强的鲁棒性和效率。

Conclusion: Geo-DeepONet能够实现跨任意非结构化网格的准确算子学习而无需重新训练，基于此构建的几何感知混合求解器显著提升了传统迭代方法在复杂几何域中的性能。

Abstract: The convergence behavior of classical iterative solvers for parametric partial differential equations (PDEs) is often highly sensitive to the domain and specific discretization of PDEs. Previously, we introduced hybrid solvers by combining the classical solvers with neural operators for a specific geometry 1, but they tend to under-perform in geometries not encountered during training. To address this challenge, we introduce Geo-DeepONet, a geometry-aware deep operator network that incorporates domain information extracted from finite element discretizations. Geo-DeepONet enables accurate operator learning across arbitrary unstructured meshes without requiring retraining. Building on this, we develop a class of geometry-aware hybrid preconditioned iterative solvers by coupling Geo-DeepONet with traditional methods such as relaxation schemes and Krylov subspace algorithms. Through numerical experiments on parametric PDEs posed over diverse unstructured domains, we demonstrate the enhanced robustness and efficiency of the proposed hybrid solvers for multiple real-world applications.

</details>


### [150] [Hierarchical Persistence Velocity for Network Anomaly Detection: Theory and Applications to Cryptocurrency Markets](https://arxiv.org/abs/2512.14615)
*Omid Khormali*

Main category: cs.LG

TL;DR: 提出OW-HNPV方法，基于拓扑速度检测时变网络异常，在以太坊交易网络中表现优于基线模型


<details>
  <summary>Details</summary>
Motivation: 现有方法主要测量累积拓扑存在性，缺乏对拓扑特征出现和消失速度的考量，需要一种能自动降噪的拓扑速度分析方法来检测动态网络中的结构异常

Method: 提出重叠加权分层归一化持久性速度(OW-HNPV)，首次引入持久性图的速度视角，通过重叠加权自动降低噪声影响，并证明其数学稳定性

Result: 在以太坊交易网络(2017年5月-2018年5月)的加密货币异常检测中，OW-HNPV相比基线模型在7天价格预测上获得最高10.4%的AUC提升，在中长期预测(4-7天)中表现最优且最稳定

Conclusion: 建模拓扑速度对于检测动态网络中的结构异常至关重要，OW-HNPV为拓扑数据分析提供了新的速度视角，在金融网络异常检测中具有实际应用价值

Abstract: We introduce the Overlap-Weighted Hierarchical Normalized Persistence Velocity (OW-HNPV), a novel topological data analysis method for detecting anomalies in time-varying networks. Unlike existing methods that measure cumulative topological presence, we introduce the first velocity-based perspective on persistence diagrams, measuring the rate at which features appear and disappear, automatically downweighting noise through overlap-based weighting. We also prove that OW-HNPV is mathematically stable. It behaves in a controlled, predictable way, even when comparing persistence diagrams from networks with different feature types. Applied to Ethereum transaction networks (May 2017-May 2018), OW-HNPV demonstrates superior performance for cryptocurrency anomaly detection, achieving up to 10.4% AUC gain over baseline models for 7-day price movement predictions. Compared with established methods, including Vector of Averaged Bettis (VAB), persistence landscapes, and persistence images, velocity-based summaries excel at medium- to long-range forecasting (4-7 days), with OW-HNPV providing the most consistent and stable performance across prediction horizons. Our results show that modeling topological velocity is crucial for detecting structural anomalies in dynamic networks.

</details>


### [151] [Model-Based Reinforcement Learning in Discrete-Action Non-Markovian Reward Decision Processes](https://arxiv.org/abs/2512.14617)
*Alessandro Trapasso,Luca Iocchi,Fabio Patrizi*

Main category: cs.LG

TL;DR: QR-MAX：首个基于模型的NMRDP算法，通过奖励机分解马尔可夫转移与非马尔可夫奖励，实现多项式样本复杂度的PAC收敛，并扩展到连续状态空间。


<details>
  <summary>Details</summary>
Motivation: 许多实际决策问题涉及依赖于整个系统历史的任务，而非仅达到具有特定属性的状态。马尔可夫强化学习方法不适用于此类任务，而非马尔可夫奖励决策过程（NMRDPs）虽然能处理时间依赖任务，但长期以来缺乏（近）最优性和样本效率的形式保证。

Method: 提出QR-MAX算法：1）基于模型的离散NMRDP算法，通过奖励机将马尔可夫转移学习与非马尔可夫奖励处理分解；2）扩展至连续状态空间的Bucket-QR-MAX，使用SimHash离散化器保持相同的分解结构，无需手动网格化或函数逼近。

Result: QR-MAX是首个利用这种分解实现ε最优策略PAC收敛且具有多项式样本复杂度的基于模型NMRDP算法。实验表明，在复杂度递增的环境中，相比现代最先进的基于模型RL方法，样本效率显著提升，寻找最优策略的鲁棒性增强。

Conclusion: 该研究解决了NMRDP中长期缺乏形式保证的问题，通过创新的分解方法实现了高效、鲁棒的非马尔可夫任务学习，为处理时间依赖决策问题提供了理论保证和实践有效的解决方案。

Abstract: Many practical decision-making problems involve tasks whose success depends on the entire system history, rather than on achieving a state with desired properties. Markovian Reinforcement Learning (RL) approaches are not suitable for such tasks, while RL with non-Markovian reward decision processes (NMRDPs) enables agents to tackle temporal-dependency tasks. This approach has long been known to lack formal guarantees on both (near-)optimality and sample efficiency. We contribute to solving both issues with QR-MAX, a novel model-based algorithm for discrete NMRDPs that factorizes Markovian transition learning from non-Markovian reward handling via reward machines. To the best of our knowledge, this is the first model-based RL algorithm for discrete-action NMRDPs that exploits this factorization to obtain PAC convergence to $\varepsilon$-optimal policies with polynomial sample complexity. We then extend QR-MAX to continuous state spaces with Bucket-QR-MAX, a SimHash-based discretiser that preserves the same factorized structure and achieves fast and stable learning without manual gridding or function approximation. We experimentally compare our method with modern state-of-the-art model-based RL approaches on environments of increasing complexity, showing a significant improvement in sample efficiency and increased robustness in finding optimal policies.

</details>


### [152] [ParaFormer: A Generalized PageRank Graph Transformer for Graph Representation Learning](https://arxiv.org/abs/2512.14619)
*Chaohao Yuan,Zhenjie Song,Ercan Engin Kuruoglu,Kangfei Zhao,Yang Liu,Deli Zhao,Hong Cheng,Yu Rong*

Main category: cs.LG

TL;DR: ParaFormer通过PageRank增强注意力模块解决图Transformer中的过平滑问题，在节点和图分类任务上表现优异


<details>
  <summary>Details</summary>
Motivation: 研究发现图Transformer中的全局注意力机制存在严重的过平滑问题，导致节点表示变得难以区分，这种效应甚至比GNNs中的过平滑更严重

Method: 提出PageRank Transformer (ParaFormer)，采用PageRank增强的注意力模块来模拟深层Transformer的行为，作为自适应滤波器缓解过平滑

Result: 在11个从数千到数百万节点的数据集上，ParaFormer在节点分类和图分类任务上均取得一致的性能提升

Conclusion: ParaFormer通过PageRank增强注意力有效缓解了图Transformer中的过平滑问题，证明了自适应滤波器设计的有效性

Abstract: Graph Transformers (GTs) have emerged as a promising graph learning tool, leveraging their all-pair connected property to effectively capture global information. To address the over-smoothing problem in deep GNNs, global attention was initially introduced, eliminating the necessity for using deep GNNs. However, through empirical and theoretical analysis, we verify that the introduced global attention exhibits severe over-smoothing, causing node representations to become indistinguishable due to its inherent low-pass filtering. This effect is even stronger than that observed in GNNs. To mitigate this, we propose PageRank Transformer (ParaFormer), which features a PageRank-enhanced attention module designed to mimic the behavior of deep Transformers. We theoretically and empirically demonstrate that ParaFormer mitigates over-smoothing by functioning as an adaptive-pass filter. Experiments show that ParaFormer achieves consistent performance improvements across both node classification and graph classification tasks on 11 datasets ranging from thousands to millions of nodes, validating its efficacy. The supplementary material, including code and appendix, can be found in https://github.com/chaohaoyuan/ParaFormer.

</details>


### [153] [gridfm-datakit-v1: A Python Library for Scalable and Realistic Power Flow and Optimal Power Flow Data Generation](https://arxiv.org/abs/2512.14658)
*Alban Puech,Matteo Mazzonelli,Celia Cintas,Tamara R. Govindasamy,Mangaliso Mngomezulu,Jonas Weiss,Matteo Baù,Anna Varbella,François Mirallès,Kibaek Kim,Le Xie,Hendrik F. Hamann,Etienne Vos,Thomas Brunschwiler*

Main category: cs.LG

TL;DR: gridfm-datakit-v1是一个Python库，用于生成真实多样的电力潮流和最优潮流数据集，解决现有数据集缺乏随机性、多样性不足、泛化能力有限等问题。


<details>
  <summary>Details</summary>
Motivation: 现有电力系统数据集面临三个主要挑战：1）缺乏真实的随机负荷和拓扑扰动，限制了场景多样性；2）潮流数据集仅限于最优潮流可行点，阻碍了机器学习求解器对违反运行限制情况的泛化；3）最优潮流数据集使用固定的发电机成本函数，限制了成本变化的泛化能力。

Method: 通过结合真实世界负荷曲线的全局负荷缩放与局部噪声，支持任意N-k拓扑扰动来创建多样且真实的数据集；生成超出运行限制的潮流样本；生成具有变化发电机成本的最优潮流数据；并能高效扩展到大型电网（最多10,000个节点）。

Result: 开发了gridfm-datakit-v1库，与OPFData、OPF-Learn、PGLearn和PFΔ等现有工具进行了比较，可在GitHub上获取并通过pip安装。

Conclusion: gridfm-datakit-v1解决了现有电力系统数据集的关键限制，为训练机器学习求解器提供了更真实、多样和可扩展的数据生成能力。

Abstract: We introduce gridfm-datakit-v1, a Python library for generating realistic and diverse Power Flow (PF) and Optimal Power Flow (OPF) datasets for training Machine Learning (ML) solvers. Existing datasets and libraries face three main challenges: (1) lack of realistic stochastic load and topology perturbations, limiting scenario diversity; (2) PF datasets are restricted to OPF-feasible points, hindering generalization of ML solvers to cases that violate operating limits (e.g., branch overloads or voltage violations); and (3) OPF datasets use fixed generator cost functions, limiting generalization across varying costs. gridfm-datakit addresses these challenges by: (1) combining global load scaling from real-world profiles with localized noise and supporting arbitrary N-k topology perturbations to create diverse yet realistic datasets; (2) generating PF samples beyond operating limits; and (3) producing OPF data with varying generator costs. It also scales efficiently to large grids (up to 10,000 buses). Comparisons with OPFData, OPF-Learn, PGLearn, and PF$Δ$ are provided. Available on GitHub at https://github.com/gridfm/gridfm-datakit under Apache 2.0 and via `pip install gridfm-datakit`.

</details>


### [154] [Beyond Lipschitz Continuity and Monotonicity: Fractal and Chaotic Activation Functions in Echo State Networks](https://arxiv.org/abs/2512.14675)
*Rae Chipera,Jenny Du,Irene Tsapara*

Main category: cs.LG

TL;DR: 该论文研究了非光滑激活函数（包括混沌、随机和分形变体）在回声状态网络中的表现，发现某些非光滑函数不仅保持回声状态特性，还在收敛速度和谱半径容限方面优于传统光滑激活函数。


<details>
  <summary>Details</summary>
Motivation: 当前储层计算严重依赖光滑、全局Lipschitz连续的激活函数，限制了在需要极端条件下稳健操作的防御、灾难响应和药物建模等领域的应用。需要研究非光滑激活函数的潜力。

Method: 系统研究非光滑激活函数在回声状态网络中的应用，通过36,610个储层配置的全面参数扫描，引入量化激活函数的理论框架，定义退化回声状态特性(d-ESP)，并证明d-ESP蕴含传统ESP。

Result: 康托函数（处处连续但几乎处处平坦）在谱半径高达ρ~10时仍保持ESP一致行为，比光滑函数的典型界限高一个数量级，收敛速度比tanh和ReLU快2.6倍。发现预处理拓扑而非连续性本身决定稳定性。

Conclusion: 研究挑战了储层计算中激活函数设计的传统假设，某些分形函数的优异性能机制仍无法解释，表明我们对激活函数几何性质如何影响储层动态的理解存在根本性空白。

Abstract: Contemporary reservoir computing relies heavily on smooth, globally Lipschitz continuous activation functions, limiting applications in defense, disaster response, and pharmaceutical modeling where robust operation under extreme conditions is critical. We systematically investigate non-smooth activation functions, including chaotic, stochastic, and fractal variants, in echo state networks. Through comprehensive parameter sweeps across 36,610 reservoir configurations, we demonstrate that several non-smooth functions not only maintain the Echo State Property (ESP) but outperform traditional smooth activations in convergence speed and spectral radius tolerance. Notably, the Cantor function (continuous everywhere and flat almost everywhere) maintains ESP-consistent behavior up to spectral radii of rho ~ 10, an order of magnitude beyond typical bounds for smooth functions, while achieving 2.6x faster convergence than tanh and ReLU. We introduce a theoretical framework for quantized activation functions, defining a Degenerate Echo State Property (d-ESP) that captures stability for discrete-output functions and proving that d-ESP implies traditional ESP. We identify a critical crowding ratio Q=N/k (reservoir size / quantization levels) that predicts failure thresholds for discrete activations. Our analysis reveals that preprocessing topology, rather than continuity per se, determines stability: monotone, compressive preprocessing maintains ESP across scales, while dispersive or discontinuous preprocessing triggers sharp failures. While our findings challenge assumptions about activation function design in reservoir computing, the mechanism underlying the exceptional performance of certain fractal functions remains unexplained, suggesting fundamental gaps in our understanding of how geometric properties of activation functions influence reservoir dynamics.

</details>


### [155] [Early Warning Index for Patient Deteriorations in Hospitals](https://arxiv.org/abs/2512.14683)
*Dimitris Bertsimas,Yu Ma,Kimberly Villalobos Carballo,Gagan Singh,Michal Laskowski,Jeff Mather,Dan Kombert,Howard Haronian*

Main category: cs.LG

TL;DR: 开发了一个多模态机器学习框架EWI，通过整合临床和运营数据预测ICU入院、急救团队派遣和死亡风险，在大型医院部署并实现0.796的C统计量


<details>
  <summary>Details</summary>
Motivation: 医院缺乏自动化系统来利用日益增长的异构临床和运营数据有效预测关键事件。早期识别有恶化风险的患者对患者护理质量监测和医生护理管理都至关重要，但将不同数据流转化为准确且可解释的风险评估面临数据格式不一致的挑战。

Method: 开发了多模态机器学习框架EWI（早期预警指数），采用人机协作流程：临床医生帮助确定警报阈值和解释模型输出。使用SHAP（Shapley Additive exPlanations）提供可解释输出，突出显示驱动每个患者风险的临床和运营因素（如预定手术、病房普查）。从结构化和非结构化电子健康记录数据中自动提取特征。

Result: 在美国一家大型医院的18,633名独特患者数据集上，EWI实现了0.796的C统计量。目前已部署在医院仪表板中，将患者分为三个风险层级，作为主动管理风险患者的分类工具。

Conclusion: 该方法通过自动对不同风险水平的患者进行分类，为医生节省了宝贵时间，使他们能够专注于患者护理而不是筛选复杂的EHR数据。通过进一步确定具体的风险驱动因素，该模型为护理人员调度和关键资源分配提供了数据驱动的调整依据，从而帮助临床医生和管理人员避免下游并发症，改善整体患者流程。

Abstract: Hospitals lack automated systems to harness the growing volume of heterogeneous clinical and operational data to effectively forecast critical events. Early identification of patients at risk for deterioration is essential not only for patient care quality monitoring but also for physician care management. However, translating varied data streams into accurate and interpretable risk assessments poses significant challenges due to inconsistent data formats. We develop a multimodal machine learning framework, the Early Warning Index (EWI), to predict the aggregate risk of ICU admission, emergency response team dispatch, and mortality. Key to EWI's design is a human-in-the-loop process: clinicians help determine alert thresholds and interpret model outputs, which are enhanced by explainable outputs using Shapley Additive exPlanations (SHAP) to highlight clinical and operational factors (e.g., scheduled surgeries, ward census) driving each patient's risk. We deploy EWI in a hospital dashboard that stratifies patients into three risk tiers. Using a dataset of 18,633 unique patients at a large U.S. hospital, our approach automatically extracts features from both structured and unstructured electronic health record (EHR) data and achieves C-statistics of 0.796. It is currently used as a triage tool for proactively managing at-risk patients. The proposed approach saves physicians valuable time by automatically sorting patients of varying risk levels, allowing them to concentrate on patient care rather than sifting through complex EHR data. By further pinpointing specific risk drivers, the proposed model provides data-informed adjustments to caregiver scheduling and allocation of critical resources. As a result, clinicians and administrators can avert downstream complications, including costly procedures or high readmission rates and improve overall patient flow.

</details>


### [156] [Bias-Variance Trade-off for Clipped Stochastic First-Order Methods: From Bounded Variance to Infinite Mean](https://arxiv.org/abs/2512.14686)
*Chuan He*

Main category: cs.LG

TL;DR: 该论文研究了在重尾噪声（尾指数α∈(0,2]）下随机一阶方法的优化复杂度，通过梯度裁剪技术解决了现有方法在α接近1时复杂度趋于无穷的问题。


<details>
  <summary>Details</summary>
Motivation: 现有随机优化方法主要针对轻尾噪声或有限均值（α∈(1,2]）的重尾噪声，当噪声尾指数α接近1时复杂度趋于无穷，而实际应用中常出现无限均值的重尾噪声（α∈(0,1]），这一问题尚未得到充分研究。

Method: 通过分析梯度裁剪中的偏差-方差权衡，提出了一种新颖的分析框架，在控制噪声尾部对称性的条件下，为裁剪后的随机一阶方法建立了统一的复杂度保证。

Result: 证明了裁剪随机一阶方法在完整尾指数范围α∈(0,2]内都能获得改进的复杂度保证，包括无限均值的重尾噪声情况，数值实验验证了理论结果。

Conclusion: 该研究填补了重尾噪声优化理论的重要空白，为处理从有界方差到无限均值的各种噪声类型提供了统一的理论框架和实用方法。

Abstract: Stochastic optimization is fundamental to modern machine learning. Recent research has extended the study of stochastic first-order methods (SFOMs) from light-tailed to heavy-tailed noise, which frequently arises in practice, with clipping emerging as a key technique for controlling heavy-tailed gradients. Extensive theoretical advances have further shown that the oracle complexity of SFOMs depends on the tail index $α$ of the noise. Nonetheless, existing complexity results often cover only the case $α\in (1,2]$, that is, the regime where the noise has a finite mean, while the complexity bounds tend to infinity as $α$ approaches $1$. This paper tackles the general case of noise with tail index $α\in(0,2]$, covering regimes ranging from noise with bounded variance to noise with an infinite mean, where the latter case has been scarcely studied. Through a novel analysis of the bias-variance trade-off in gradient clipping, we show that when a symmetry measure of the noise tail is controlled, clipped SFOMs achieve improved complexity guarantees in the presence of heavy-tailed noise for any tail index $α\in (0,2]$. Our analysis of the bias-variance trade-off not only yields new unified complexity guarantees for clipped SFOMs across this full range of tail indices, but is also straightforward to apply and can be combined with classical analyses under light-tailed noise to establish oracle complexity guarantees under heavy-tailed noise. Finally, numerical experiments validate our theoretical findings.

</details>
