<div id=toc></div>

# Table of Contents

- [quant-ph](#quant-ph) [Total: 35]
- [cs.LG](#cs.LG) [Total: 72]
- [gr-qc](#gr-qc) [Total: 13]


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [1] [Universal Quantum Simulation of 50 Qubits on Europe`s First Exascale Supercomputer Harnessing Its Heterogeneous CPU-GPU Architecture](https://arxiv.org/abs/2511.03359)
*Hans De Raedt,Jiri Kraus,Andreas Herten,Vrinda Mehta,Mathis Bode,Markus Hrywniak,Kristel Michielsen,Thomas Lippert*

Main category: quant-ph

TL;DR: 开发了JUQCS-50量子计算机模拟器，首次实现50量子位通用量子计算机模拟，相比之前的48量子位记录获得11.4倍加速


<details>
  <summary>Details</summary>
Motivation: 突破现有量子计算机模拟的量子位限制，利用GH200超级芯片特性实现更高性能的量子计算模拟

Method: 采用三项关键技术：1) 通过高速CPU-GPU互连和LPDDR5内存扩展可用内存；2) 自适应数据编码减少内存占用；3) 实时网络流量优化

Result: 成功模拟50量子位通用量子计算机，相比K计算机上的48量子位记录实现11.4倍加速

Conclusion: JUQCS-50通过创新技术突破了量子计算机模拟的量子位限制，为更大规模量子计算研究提供了有力工具

Abstract: We have developed a new version of the high-performance J\"ulich universal
quantum computer simulator (JUQCS-50) that leverages key features of the GH200
superchips as used in the JUPITER supercomputer, enabling simulations of a
50-qubit universal quantum computer for the first time. JUQCS-50 achieves this
through three key innovations: (1) extending usable memory beyond GPU limits
via high-bandwidth CPU-GPU interconnects and LPDDR5 memory; (2) adaptive data
encoding to reduce memory footprint with acceptable trade-offs in precision and
compute effort; and (3) an on-the-fly network traffic optimizer. These advances
result in an 11.4-fold speedup over the previous 48-qubit record on the K
computer.

</details>


### [2] [Quantum error mitigation using energy sampling and extrapolation enhanced Clifford data regression](https://arxiv.org/abs/2511.03556)
*Zhongqi Zhao,Erik Rosendahl Kjellgren,Sonia Coriani,Jacob Kongsted,Stephan P. A. Sauer,Karl Michael Ziems*

Main category: quant-ph

TL;DR: 本文探索并扩展了Clifford数据回归(CDR)方法，用于在变分量子本征求解器(VQE)中缓解量子化学模拟的噪声。提出了两种改进：能量采样(ES)和非Clifford外推(NCE)，在H4分子模拟中均优于原始CDR。


<details>
  <summary>Details</summary>
Motivation: 在噪声中等规模量子(NISQ)设备上实现量子算法需要有效的误差缓解技术，特别是对于量子化学模拟中的VQE方法。

Method: 使用H4分子和tiled Unitary Product State (tUPS) ansatz进行噪声模拟，详细研究CDR超参数对误差缓解质量的影响。提出两种改进：能量采样(ES)选择最低能量训练电路进行回归，非Clifford外推(NCE)将非Clifford参数数量作为回归模型额外输入。

Result: 数值结果表明，两种改进策略均优于原始CDR方法，能够更有效地缓解量子化学模拟中的噪声。

Conclusion: 通过能量采样和非Clifford外推的改进，CDR框架在量子化学模拟中的误差缓解性能得到显著提升，为NISQ设备上的实际应用提供了更有效的解决方案。

Abstract: Error mitigation is essential for the practical implementation of quantum
algorithms on noisy intermediate-scale quantum (NISQ) devices. This work
explores and extends Clifford Data Regression (CDR) to mitigate noise in
quantum chemistry simulations using the Variational Quantum Eigensolver (VQE).
Using the H$_4$ molecule with the tiled Unitary Product State (tUPS) ansatz, we
perform noisy simulations with the ibm torino noise model to investigate in
detail the effect of various hyperparameters in CDR on the error mitigation
quality. Building on these insights, two improvements to the CDR framework are
proposed. The first, Energy Sampling (ES), improves performance by selecting
only the lowest-energy training circuits for regression, thereby further
biasing the sample energies toward the target state. The second, Non-Clifford
Extrapolation (NCE), enhances the regression model by including the number of
non-Clifford parameters as an additional input, enabling the model to learn how
the noisy-ideal mapping evolves as the circuit approaches the optimal one. Our
numerical results demonstrate that both strategies outperform the original CDR.

</details>


### [3] [Atom-Field Non-Markovian Dynamics in Open and Dissipative Systems: An Efficient Memory-Kernel Approach Linked to Dyadic Greens Function and CEM Treatments](https://arxiv.org/abs/2511.03561)
*Hyunwoo Choi,Jisang Seo,Weng C. Chew,Dong-Yeop Na*

Main category: quant-ph

TL;DR: 提出了一个非马尔可夫近似下开放耗散系统中二能级系统单光子发射的数值框架，可直接集成到FDTD和FEM等标准计算电磁求解器中。


<details>
  <summary>Details</summary>
Motivation: 需要开发一个能够描述开放耗散系统中量子发射器动力学的方法，将经典电磁求解器扩展到量子光-物质相互作用领域。

Method: 基于修改的Langevin噪声形式，通过模态展开重构格林函数的虚部，利用多模Jaynes-Cummings模型描述原子-场相互作用，在FDTD和FEM框架中实现具体策略。

Result: 验证了边界和介质辅助模式的完备性，证明了二能级系统的记忆核由格林函数的虚部决定，辐射模式主导相关动力学，并在有损Lorentz-Drude型镜子和Fabry-Perot腔中验证了数值结果。

Conclusion: 建立了一个严格的格林函数基础方法，用于将量子发射器动力学纳入计算电磁学，从而扩展经典求解器到量子光-物质相互作用领域。

Abstract: In this work, we present a numerical framework for modeling single photon
emission from a two level system in open and dissipative systems beyond the
Markovian approximation. The method can be readily integrated into standard
computational electromagnetic (CEM) solvers such as finite difference time
domain (FDTD) and finite element method (FEM). We numerically verify the
completeness of boundary and medium assisted modes in the modified Langevin
noise formalism by reconstructing the imaginary part of the dyadic Greens
function through modal expansion in three dimensions. This reconstruction
enables a first principles description of atom field interaction via the multi
mode Jaynes Cummings model in open and dissipative environments. Within the
single excitation manifold, we show that the memory kernel of a two level
system is determined by the imaginary part of the Greens function, implying
that radiative modes alone govern the relevant dynamics. The proposed framework
thus provides a Greens function based approach for describing atomic population
and single photon dynamics, directly compatible with Maxwell solvers. We then
present concrete strategies for implementing our method in both FDTD and FEM
frameworks, demonstrating its practical applicability. We further verify
numerical results for a lossy Lorentz Drude type mirror, including both the
case of a TLS near a finite sized metallic mirror and that of a TLS centered in
a Fabry Perot cavity. This work establishes a rigorous foundation for
incorporating quantum emitter dynamics into computational electromagnetics,
thereby extending classical solvers toward quantum light matter interactions.

</details>


### [4] [The electron double-slit experiment from an ISP perspective](https://arxiv.org/abs/2511.02863)
*David LeBlond*

Main category: quant-ph

TL;DR: 提出基于不可分随机过程的电子双缝实验教学模型和R代码，提供量子概率和相干现象的统计解释视角


<details>
  <summary>Details</summary>
Motivation: 为量子概率和相干现象提供统计而非纯波动力学的替代解释视角

Method: 使用不可分随机过程构建电子双缝实验的教学模型，并开发配套的R代码实现

Result: 建立了一个能够解释量子概率和相干现象的教学框架

Conclusion: 该方法为理解量子现象提供了统计学的替代视角，有助于教学和概念理解

Abstract: This paper presents a pedagogical model, and accompanying R code, of the
electron double-slit experiment using the perspective of indivisible stochastic
processes. The approach offers an alternative lens on quantum probability and
coherence phenomena, emphasizing a statistical rather than purely
wave-mechanical interpretation.

</details>


### [5] [Clifford Hierarchy Stabilizer Codes: Transversal Non-Clifford Gates and Magic](https://arxiv.org/abs/2511.02900)
*Ryohei Kobayashi,Guanyu Zhu,Po-Shen Hsin*

Main category: quant-ph

TL;DR: 本文扩展了拓扑Pauli稳定子码到n维Clifford层次稳定子码，构造了横向非Clifford逻辑门，在2D和3D中分别实现了T门和√T门，并提出了关于Clifford层次稳定子码的Bravyi-König边界猜想。


<details>
  <summary>Details</summary>
Motivation: 解决容错量子计算中普遍性与维度之间的权衡问题，突破Bravyi-König边界对拓扑稳定子码的限制。

Method: 将拓扑Pauli稳定子码扩展到n维Clifford层次稳定子码，对应(n+1)D Dijkgraaf-Witten规范理论，通过杯积表示的自动同构对称性构造横向非Clifford门。

Result: 在2D中首次为Clifford稳定子码实现了横向T和CS逻辑门；在3D中构造了第三Clifford层次的横向√T门；通过码切换实现了O(d)轮次的逻辑T魔法态容错制备。

Conclusion: 提出的构造为第N层Clifford层次的逻辑门提供了空间维度(N-1)的上界，避免了2D中的权衡问题，有望实现第四Clifford层次且仅需O(d³)时空开销。

Abstract: A fundamental problem in fault-tolerant quantum computation is the tradeoff
between universality and dimensionality, exemplified by the the Bravyi-K\"onig
bound for $n$-dimensional topological stabilizer codes. In this work, we extend
topological Pauli stabilizer codes to a broad class of $n$-dimensional Clifford
hierarchy stabilizer codes. These codes correspond to the $(n+1)$D
Dijkgraaf-Witten gauge theories with non-Abelian topological order. We
construct transversal non-Clifford gates through automorphism symmetries
represented by cup products. In 2D, we obtain the first transversal
non-Clifford logical gates including T and CS for Clifford stabilizer codes,
using the automorphism of the twisted $\mathbb{Z}_2^3$ gauge theory (equivalent
to $\mathbb{D}_4$ topological order). We also combine it with the just-in-time
decoder to fault-tolerantly prepare the logical T magic state in $O(d)$ rounds
via code switching. In 3D, we construct a transversal logical $\sqrt{\text{T}}$
gate in a non-Clifford stabilizer code at the third level of the Clifford
hierarchy, located on a tetrahedron corresponding to a twisted $\mathbb{Z}_2^4$
gauge theory. Due to the potential single-shot code-switching properties of
these codes, one could achieve the 4th level of Clifford hierarchy with an
$O(d^3)$ space-time overhead, avoiding the tradeoff observed in 2D. We propose
a conjecture extending the Bravyi-K\"onig bound to Clifford hierarchy
stabilizer codes, with our explicit constructions providing an upper bound of
spatial dimension $(N-1)$ for achieving the logical gates in the
$N^\text{th}$-level of Clifford hierarchy.

</details>


### [6] [Zero-Noise Extrapolation via Cyclic Permutations of Quantum Circuit Layouts](https://arxiv.org/abs/2511.02901)
*Zahar Sayapin,Daniil Rabinovich,Nikita Korolev,Kirill Lakhmanskiy*

Main category: quant-ph

TL;DR: 提出了一种基于循环布局置换的零噪声外推协议(CLP-ZNE)，用于缓解NISQ设备的硬件误差，仅需测量O(n)个不同电路布局即可重建无噪声期望值。


<details>
  <summary>Details</summary>
Motivation: 提高当前NISQ设备的实用性需要开发有效的硬件误差缓解方法，考虑这些设备的约束条件，如中等数量量子比特和有限连接性。

Method: 利用NISQ硬件中门误差的固有非均匀性，并利用具有一维连接性的量子电路的对称性，通过对循环电路布局置换的平均期望值进行零噪声外推。

Result: 在模拟IBM Torino量子计算机的噪声通道上进行基准测试，该方法将典型期望值误差降低了一个数量级，具体取决于协议规范。

Conclusion: 通过使用源自真实硬件规格的噪声模型，这些结果为CLP-ZNE在当前NISQ处理器上的适用性提供了证据。

Abstract: Increasing the utility of currently available Noisy Intermediate-Scale
Quantum (NISQ) devices requires developing efficient methods to mitigate
hardware errors, taking into account the constraints of these devices such as
medium number of qubits and limited connectivity between them. In this work we
propose a novel Cyclic Layout Permutations based Zero Noise Extrapolation
(CLP-ZNE) protocol for such a task. The method leverages the inherent
non-uniformity of gate errors in NISQ hardware and exploits symmetries of
quantum circuits with one-dimensional connectivity to extrapolate the
expectation value, averaged over cyclic circuit layout permutations, to the
level of zero noise. In contrast to the previous layout permutation based
approaches, for $n$ qubit circuit CLP-ZNE requires measurements of only $O(n)$
different circuit layouts to reconstruct the noiseless expected value. When
benchmarked against noise channels modeling the IBM Torino quantum computer,
the method reduces a typical expectation value error by an order of magnitude,
depending on the protocol specifications. By employing a noise model derived
from real hardware specifications, including both depolarizing and $T_1/T_2$
relaxation processes, these results give evidence for the applicability of
CLP-ZNE to present-day NISQ processors.

</details>


### [7] [Classical shadows for sample-efficient measurements of gauge-invariant observables](https://arxiv.org/abs/2511.02904)
*Jacob Bringewatt,Henry Froland,Andreas Elben,Niklas Mueller*

Main category: quant-ph

TL;DR: 本文开发了三种针对具有局域对称性的系统的经典阴影协议，用于高效预测晶格规范理论中的规范不变量，相比无对称性方法可实现指数级样本复杂度改进。


<details>
  <summary>Details</summary>
Motivation: 经典阴影框架可从重复随机测量中估计量子态性质，但当存在先验信息（如态和算符的对称性）时，可显著提高样本效率。晶格规范理论模型是量子模拟的前沿领域，需要高效预测规范不变量。

Method: 开发了三种针对局域对称性系统的经典阴影协议，利用对偶表述进行严格资源需求分析，包括电路深度和样本复杂度。

Result: 在Z2晶格规范理论中验证了协议效果，相比对称性无关方法可实现指数级样本复杂度改进，但代价是电路复杂度增加。

Conclusion: 所提出的经典阴影协议为具有局域对称性的系统提供了高效的观测值预测方法，在样本复杂度和电路复杂度之间存在权衡关系。

Abstract: Classical shadows provide a versatile framework for estimating many
properties of quantum states from repeated, randomly chosen measurements
without requiring full quantum state tomography. When prior information is
available, such as knowledge of symmetries of states and operators, this
knowledge can be exploited to significantly improve sample efficiency. In this
work, we develop three classical shadow protocols tailored to systems with
local (or gauge) symmetries to enable efficient prediction of gauge-invariant
observables in lattice gauge theory models which are currently at the forefront
of quantum simulation efforts. For such models, our approaches can offer
exponential improvements in sample complexity over symmetry-agnostic methods,
albeit at the cost of increased circuit complexity. We demonstrate these
trade-offs using a $\mathbb{Z}_2$ lattice gauge theory, where a dual
formulation enables a rigorous analysis of resource requirements, including
both circuit depth and sample complexity.

</details>


### [8] [Analytically Continuing the Randomized Measurement Toolbox](https://arxiv.org/abs/2511.02912)
*Akash Vijay,Ayush Raj,Jonah Kudler-Flam,Benoît Vermersch,Andreas Elben,Laimei Nie*

Main category: quant-ph

TL;DR: 提出了一种通过解析延拓从随机测量实验中提取密度矩阵非多项式解析函数的框架SAC，该方法对统计噪声具有鲁棒性，适用于实际量子硬件。


<details>
  <summary>Details</summary>
Motivation: 解决在有限重复量子实验中由统计噪声引起的非多项式函数估计问题，为实际量子硬件提供稳健的分析工具。

Method: 使用稳定化解析延拓(SAC)方法，从随机测量实验中通过Rényi熵估计来提取冯·诺依曼纠缠熵等非线性诊断量。

Result: 成功应用于数值模拟的淬灭Néel态和实验离子阱量子模拟器的Rényi数据，提取了不同演化时间的子系统冯·诺依曼熵。

Conclusion: SAC框架具有对统计噪声的鲁棒性，可推广到其他非线性诊断量如对数负性和Rényi相对熵的提取。

Abstract: We develop a framework for extracting non-polynomial analytic functions of
density matrices in randomized measurement experiments by a method of
analytical continuation. A central advantage of this approach, dubbed
stabilized analytic continuation (SAC), is its robustness to statistical noise
arising from finite repetitions of a quantum experiment, making it well-suited
to realistic quantum hardware. As a demonstration, we use SAC to estimate the
von Neumann entanglement entropy of a numerically simulated quenched N\'eel
state from R\'enyi entropies estimated via the randomized measurement protocol.
We then apply the method to experimental R\'enyi data from a trapped-ion
quantum simulator, extracting subsystem von Neumann entropies at different
evolution times. Finally, we briefly note that the SAC framework is readily
generalizable to obtain other nonlinear diagnostics, such as the logarithmic
negativity and R\'enyi relative entropies.

</details>


### [9] [Correlation Self-Testing of Quantum Theory against Generalised Probabilistic Theories with Restricted Relabelling Symmetry](https://arxiv.org/abs/2511.02914)
*Kuntal Sengupta,Mirjam Weilenmann,Roger Colbeck*

Main category: quant-ph

TL;DR: 该论文研究量子理论的自测试，通过构建缺乏旋转对称性的广义概率理论，引入组合一致性标准，证明量子理论在自适应CHSH游戏中表现更优，可实验排除这些理论。


<details>
  <summary>Details</summary>
Motivation: 研究量子理论的自测试，探索缺乏正则性的广义概率理论，引入组合一致性标准来加强无限制假设。

Method: 构建缺乏旋转对称性的广义概率理论，通过取局部状态和有限非局部状态的凸包形成理论，引入组合一致性标准。

Result: 量子理论在自适应CHSH游戏中表现优于这些理论，可实验排除它们；组合一致性与Tsirelson界限存在联系。

Conclusion: 组合一致性是必要的理论约束，量子理论在特定任务中表现更优，可通过实验排除缺乏正则性的广义概率理论。

Abstract: Correlation self-testing of quantum theory involves identifying a task or set
of tasks whose optimal performance can be achieved only by theories that can
realise the same set of correlations as quantum theory in every causal
structure. Following this approach, previous work has ruled out various classes
of generalised probabilistic theories whose joint state spaces have a certain
regularity in the sense of a (discrete) rotation symmetry of the bipartite
state spaces. Here we consider theories whose bipartite state spaces lack this
regularity. We form them by taking the convex hull of all the local states and
a finite number of non-local states. We show that a criterion of compositional
consistency is needed in such theories: for a measurement effect to be valid,
there must exist at least one measurement that it is part of. This goes beyond
previous consistency criteria and corresponds to a strengthening of the
no-restriction hypothesis. We show that quantum theory outperforms these
theories in a task called the adaptive CHSH game, which shows that they can be
ruled out experimentally. We further show a connection between compositional
consistency and Tsirelson's bound.

</details>


### [10] [Motional entanglement in low-energy collisions near shape resonances](https://arxiv.org/abs/2511.02925)
*Yimeng Wang,Christiane P. Koch*

Main category: quant-ph

TL;DR: 该论文研究了三维空间中双粒子散射过程中产生的纠缠，发现平面波描述无法准确捕捉纠缠特性，需要量子不确定性的初始状态。在窄动量色散的散射设置中，纠缠与散射截面呈线性关系，在形状共振附近显著增强。


<details>
  <summary>Details</summary>
Motivation: 爱因斯坦-波多尔斯基-罗森悖论讨论了测量两个粒子的位置或动量，这些粒子在散射过程中会纠缠。但问题是：在这个过程中能产生多少纠缠？

Method: 使用完全相干计算分析三维空间中的双粒子散射，通过单粒子纯度的倒数来量化纠缠。比较了标准平面波描述和考虑量子不确定性的更现实描述。

Result: 标准平面波描述无法捕捉纠缠特性。在窄初始动量色散的更现实散射设置中，纠缠与散射截面呈线性关系，在形状共振附近有显著增强。

Conclusion: 研究结果为探测和最终在量子碰撞中使用纠缠开辟了道路，讨论了如何在实验中检测运动纠缠的生成。

Abstract: Einstein, Podolsky, and Rosen discussed their paradox in terms of measuring
the positions or momenta of two particles. These can become entangled upon
scattering, but how much entanglement can be created in this process? Here we
address this question with fully coherent calculations of bipartite scattering
in three-dimensional space, quantifying entanglement by the inverse of the
single particle purity. We show that the standard plane-wave description of
scattering fails to capture the entanglement properties, due to the essential
role of quantum uncertainty in the initial state. For a more realistic
description of a scattering setup and narrow initial momentum dispersion, we
find the entanglement to scale linearly with the scattering cross section,
including strong enhancement close to shape resonances. We discuss how the
generation of motional entanglement can be detected in experiments. Our results
open the way to probing and eventually using entanglement in quantum
collisions.

</details>


### [11] [SWAP-Network Routing and Spectral Qubit Ordering for MPS Imaginary-Time Optimization](https://arxiv.org/abs/2511.02980)
*Erik M. Åsgrim,Stefano Markidis*

Main category: quant-ph

TL;DR: 提出了一种量子启发的组合求解器，通过矩阵乘积态上的虚时间演化，结合结构化SWAP网络和谱量子比特映射来处理非局域耦合问题。


<details>
  <summary>Details</summary>
Motivation: 旨在提高基于张量网络的优化算法性能，通过利用问题结构（谱映射和高效路由网络）来增强非局域量子比特相互作用的处理能力。

Method: 使用矩阵乘积态进行虚时间演化，采用结构化SWAP网络（基于矩形和三角形网格）和谱量子比特映射方法，将逻辑量子比特根据连接图的拉普拉斯矩阵映射到MPS位点。

Result: 在特定问题配置下，结合谱排序和三角形SWAP网络相比随机排序优化，误差减少了20倍以上；在180量子比特的投资组合优化问题中，谱排序不仅提高了解质量，还增强了MPS中的纠缠熵。

Conclusion: 通过谱映射和高效路由网络利用问题结构，可以显著提升基于张量网络的优化算法性能。

Abstract: We propose a quantum-inspired combinatorial solver that performs
imaginary-time evolution (ITE) on a matrix product state (MPS), incorporating
non-local couplings through structured SWAP networks and spectral qubit mapping
of logical qubits. The SWAP networks, composed exclusively of local two-qubit
gates, effectively mediate non-local qubit interactions. We investigate two
distinct network architectures based on rectangular and triangular meshes of
SWAP gates and analyze their performance in combination with spectral qubit
ordering, which maps logical qubits to MPS sites based on the Laplacian of the
logical qubit connectivity graph. The proposed framework is evaluated on
synthetic MaxCut instances with varying graph connectivity, as well as on a
dynamic portfolio optimization problem based on real historical asset data
involving 180 qubits. On certain problem configurations, we observe an over
20$\times$ reduction in error when combining spectral ordering and triangular
SWAP networks compared to optimization with shuffled qubit ordering.
Furthermore, an analysis of the entanglement entropy during portfolio
optimization reveals that spectral qubit ordering not only improves solution
quality but also enhances the total and spatially distributed entanglement
within the MPS. These findings demonstrate that exploiting problem structure
through spectral mapping and efficient routing networks can substantially
enhance the performance of tensor-network-based optimization algorithms.

</details>


### [12] [D2-UC: A Distributed-Distributed Quantum-Classical Framework for Unit Commitment](https://arxiv.org/abs/2511.03104)
*Milad Hasanzadeh,Amin Kargarian*

Main category: quant-ph

TL;DR: D2-UC是一个量子就绪的机组组合框架，通过结合分布式经典分解和分布式量子执行，将机组组合问题转化为三块ADMM形式，其中二进制子问题表示为QUBO，适合近期的混合量子-经典求解器。


<details>
  <summary>Details</summary>
Motivation: 为机组组合问题开发量子就绪的解决方案，利用量子计算的优势来解决传统方法难以处理的大规模优化问题，同时适应当前和近期量子硬件的限制。

Method: 将确定性和随机机组组合问题重新表述为三块ADMM：凸二次子问题、二进制QUBO子问题和近端松弛更新。通过分解为类型特定的QUBO、微QUBO和批量处理，使问题更易处理且与分布式变分量子本征求解器兼容。

Result: 案例研究证实所提方法能够生成可行调度方案，实现更快的收敛速度，且QUBO大小与当前和近期量子硬件能力相匹配。

Conclusion: D2-UC框架成功地将机组组合问题转化为适合量子求解器的形式，通过创新的分解和批处理策略，为混合量子-经典求解器提供了可行的解决方案路径。

Abstract: This paper introduces D2-UC, a quantum-ready framework for the unit
commitment (UC) problem that prepares UC for near-term hybrid quantum-classical
solvers by combining distributed classical decomposition with distributed
quantum execution. We reformulate deterministic and stochastic UC into a
three-block alternating direction method of multipliers (ADMM): (i) a convex
quadratic subproblem for dispatch and reserves, (ii) a binary subproblem
expressed as a quadratic unconstrained binary optimization (QUBO), and (iii) a
proximal slack update for consensus. The core contributions are fivefold.
First, we demonstrate how the full UC problem can be expressed as a single
monolithic QUBO, establishing a direct interface to quantum solvers. Second, we
decompose this large binary block into three type-specific QUBOs for
commitment, startup, and shutdown, making the problem more tractable but
revealing slower ADMM convergence. Third, we restore local logical couplings
through per-unit-time micro-QUBOs, which accelerate convergence. Fourth, we
batch micro-QUBOs into K non-overlapping block-diagonal problems, reducing many
subproblems to a fixed number of solver-ready QUBOs per iteration, compatible
with distributed variational quantum eigensolvers (DVQE). Fifth, we integrate
an accept-if-better safeguard with DVQE to stabilize hybrid updates and prevent
oscillations. Case studies confirm that the proposed methods deliver feasible
schedules, faster convergence, and QUBO sizes aligned with current and
near-term quantum hardware capabilities. All detailed data, codes, and
parameter values are available at
https://github.com/LSU-RAISE-LAB/3B-ADMM-UC-DVQE .

</details>


### [13] [Frequency- and Amplitude-Modulated Gates for Universal Quantum Control](https://arxiv.org/abs/2511.03164)
*Qi Ding,Shoumik Chowdhury,Agustin Di Paolo,Réouven Assouly,Alan V. Oppenheim,Jeffrey A. Grover,William D. Oliver*

Main category: quant-ph

TL;DR: 提出了一种使用频率和幅度调制微波控制实现量子门的理论框架，在固定频率量子比特上实现高保真度单比特和双比特门操作。


<details>
  <summary>Details</summary>
Motivation: 实现高保真度的单比特和双比特门对于执行任意数字量子算法和构建容错量子计算机至关重要，传统方法需要量子比特频率可调性，而本方法通过驱动频率调制来替代这一需求。

Method: 使用Floquet理论分析和设计频率和幅度调制的微波控制驱动，将量子比特频率可调性需求转化为驱动频率调制，涵盖从绝热到非绝热门的广泛门类型。

Result: 数值模拟显示，使用典型transmon量子比特参数，实现了包括X、Hadamard、相位和CZ门的通用门集合，单比特门控制误差低于0.1%，门时间为25-40ns，双比特门为125-135ns，还展示了针对驱动量子比特的常开CZ门，门时间为80-90ns。

Conclusion: 该框架提供了一种在固定频率量子比特上实现高保真度量子门的有效方法，通过频率调制替代了传统对量子比特频率可调性的需求，具有广泛的应用前景。

Abstract: Achieving high-fidelity single- and two-qubit gates is essential for
executing arbitrary digital quantum algorithms and for building error-corrected
quantum computers. We propose a theoretical framework for implementing quantum
gates using frequency- and amplitude-modulated microwave control, which extends
conventional amplitude modulation by introducing frequency modulation as an
additional degree of control. Our approach operates on fixed-frequency qubits,
converting the need for qubit frequency tunability into drive frequency
modulation. Using Floquet theory, we analyze and design these drives for
optimal fidelity within specified criteria. Our framework spans adiabatic to
nonadiabatic gates within the Floquet framework, ensuring broad applicability
across gate types and control schemes. Using typical transmon qubit parameters
in numerical simulations, we demonstrate a universal gate set-including the X,
Hadamard, phase, and CZ gates-with control error well below 0.1% and gate times
of 25-40 ns for single-qubit operations and 125-135 ns for two-qubit
operations. Furthermore, we show an always-on CZ gate tailored for driven
qubits, which has gate times of 80-90 ns.

</details>


### [14] [Heralded Induced-Coherence Interferometry in a Noisy Environment](https://arxiv.org/abs/2511.03176)
*L. Theerthagiri,Balakrishnan Viswanathan,C. M. Chandrashekar*

Main category: quant-ph

TL;DR: 分析热背景噪声对ZWM诱导相干干涉仪的影响，提出通过优化衰减、三SPDC配置或引入预示检测来恢复干涉可见度。


<details>
  <summary>Details</summary>
Motivation: 研究热背景噪声对ZWM干涉仪性能的影响，特别是在低增益和高增益状态下如何降低干涉对比度。

Method: 在ZWM干涉仪中显式包含背景噪声，分析低增益和高增益状态下的干涉可见度，并测试三种恢复方法：优化衰减、三SPDC配置和预示检测。

Result: 热光子引入非相干偏移降低干涉对比度，但通过优化衰减、三SPDC配置或预示检测可以恢复高对比度干涉条纹。

Conclusion: 热背景噪声确实会降低ZWM干涉仪的干涉可见度，但通过适当的工程方法可以有效恢复高对比度干涉。

Abstract: Induced-coherence interferometry, first introduced in the Zou-Wang-Mandel
(ZWM) setup, enables retrieval of object information from the interference
pattern of light that never interacted with the object. This scheme relies on
two identically correlated photon pairs and the absence of "which-way"
information about the photons illuminating the object to induce coherence in
their companions. In previous studies, the effect of thermal background on the
ZWM interferometer was considered; here we explicitly include background noise
and analyze the interference visibility in both low- and high-gain regimes,
revealing how thermal photons introduce an incoherent offset that lowers the
observed interference contrast. We show that the visibility can be restored
either by optimal attenuation or by extending the geometry to a three-SPDC
configuration. Furthermore, we demonstrate that introducing heralded detection
removes the detrimental effect of thermal background noise, restoring
high-contrast interference fringes.

</details>


### [15] [Quantum Sensing of Copper-Phthalocyanine Electron Spins via NV Relaxometry](https://arxiv.org/abs/2511.03200)
*Boning Li,Xufan Li,Yifan Quan,Avetik R Harutyunyan,Paola Cappellaro*

Main category: quant-ph

TL;DR: 使用金刚石中浅层氮空位中心的T1弛豫测量技术探测铜酞菁薄膜的电子自旋系综，识别了NV-CuPc相互作用，提取了CuPc的关键参数，并证明了该方法可用于精确估计NV深度。


<details>
  <summary>Details</summary>
Motivation: 分子自旋系统在量子信息处理和纳米尺度传感方面具有潜力，但在室温下由于快速自旋退相干而难以表征。

Method: 利用浅层氮空位中心的T1弛豫测量技术探测铜酞菁薄膜的电子自旋系综，通过超精细光谱识别相互作用。

Result: 成功识别了NV-CuPc相互作用，提取了CuPc的相关时间和局部晶格取向等关键参数，证实电子-电子相互作用主导室温下的退相干动力学。

Conclusion: 氮空位中心可作为分子自旋系统的强大探针，为分子量子比特、自旋浴工程和混合量子材料提供见解，并有望应用于分子尺度量子处理器和自旋基量子网络。

Abstract: Molecular spin systems are promising candidates for quantum information
processing and nanoscale sensing, yet their characterization at room
temperature remains challenging due to fast spin decoherence. In this work, we
use $T_1$ relaxometry of shallow nitrogen-vacancy (NV) centers in diamond to
probe the electron spin ensemble of a polycrystalline copper phthalocyanine
(CuPc) thin film. In addition to unequivocally identifying the NV-CuPc
interaction thanks to its hyperfine spectrum, we further extract key parameters
of the CuPc spin ensemble, including its correlation time and local lattice
orientation, that cannot be measured in bulk electron resonance experiments.
The analysis of our experimental results confirms that electron-electron
interactions dominate the decoherence dynamics of CuPc at room temperature.
Additionally, we demonstrate that the CuPc-enhanced NV relaxometry can serve as
a robust method to estimate the NV depth with $\sim1$~nm precision. Our results
establish NV centers as powerful probes for molecular spin systems, providing
insights into molecular qubits, spin bath engineering, and hybrid quantum
materials, and offering a potential pathway toward their applications such as
molecular-scale quantum processors and spin-based quantum networks.

</details>


### [16] [Quantum properties of superpositions of oppositely squeezed states](https://arxiv.org/abs/2511.03204)
*Hiroo Azuma,William J. Munro,Kae Nemoto*

Main category: quant-ph

TL;DR: 该论文研究了相反压缩态叠加的量子特性，这种态可视为薛定谔猫态，相比传统相干态猫态具有不同的光子数结构和增强的非经典特性。


<details>
  <summary>Details</summary>
Motivation: 研究相反压缩态叠加的量子特性，探索其在连续变量量子信息处理中的潜力，特别是在需要高非高斯性和强纠缠的领域。

Method: 分析Wigner函数，量化注入50:50分束器产生的纠缠，提出无需强Kerr非线性的线性光学预示方案来近似这种叠加态。

Result: 对于小压缩参数，产生的双模态比纯双模压缩真空态具有更高的纠缠度。

Conclusion: 相反压缩态叠加态是连续变量量子信息处理的有前景资源，特别适用于需要高非高斯性和强纠缠的场景。

Abstract: We investigate the quantum properties of superpositions of oppositely
squeezed states, which can be regarded as Schrodinger cat states. Compared with
conventional coherent-state cat states, these states exhibit distinct
photon-number structures and enhanced nonclassical features. We analyze their
Wigner function and quantify the entanglement generated when they are injected
into a 50:50 beam splitter. For small squeezing parameters, the resulting
two-mode states possess higher entanglement than pure two-mode squeezed vacuum
states. We also propose a linear-optical heralding scheme that approximates
this superposition of oppositely squeezed states without requiring strong Kerr
nonlinearities. Our results indicate that such states are promising resources
for continuous-variable quantum information processing, particularly in regimes
where high non-Gaussianity and strong entanglement are desirable.

</details>


### [17] [Quantum phase transition in the anisotropic Rabi model induced by parametric amplification](https://arxiv.org/abs/2511.03207)
*Yuan Qiu,Ke-Xiong Yan,Jun-Hao Lin,Jie Song,Ye-Hong Chen,Yan-Xia*

Main category: quant-ph

TL;DR: 本文通过模式图像分析各向异性Rabi模型在经典振子极限下的超辐射相变机制，发现相变源于模式间的竞争。由于经典振子极限难以实现，作者转而研究参数驱动Jaynes-Cummings模型中的量子相变，该模型可在压缩光框架中重现超强耦合各向异性Rabi模型的动力学。


<details>
  <summary>Details</summary>
Motivation: 研究各向异性Rabi模型中超辐射相变的机制，特别是经典振子极限下的相变行为，但由于经典振子极限难以实现，转而探索参数驱动Jaynes-Cummings模型中的等效相变。

Method: 1. 在经典振子极限下，通过模式图像分析各向异性Rabi模型哈密顿量，得到三个竞争模式；2. 使用参数驱动Jaynes-Cummings模型，在压缩光框架中重现超强耦合各向异性Rabi模型的动力学；3. 分析等效模型的能量本征值和本征态。

Result: 1. 相变源于模式间的竞争；2. 正常相和超辐射相的激发能在临界点消失；3. 超过临界点时光子数趋于无穷大；4. 系统在临界点发生超辐射相变。

Conclusion: 各向异性Rabi模型在经典振子极限下存在超辐射相变，相变机制为模式竞争，参数驱动Jaynes-Cummings模型可有效模拟该相变行为，临界点处激发能消失和光子数发散是相变的特征表现。

Abstract: In this manuscript, we analyze the mechanism of the superradiant phase
transition in the anisotropic Rabi model under the classical oscillator limit
using the pattern picture. By expanding the anisotropic Rabi model Hamiltonian
in operator space, we obtained three patterns, and we find that the phase
transition arises from the competition between patterns. The difficulty in
achieving the classical oscillator limit motivates our investigation into the
quantum phase transition within a parametrically-driven Jaynes-Cummings model.
This parametrically-driven Jaynes-Cummings model can reproduce the dynamics of
a ultrastrong-coupling anisotropic Rabi model in a squeezed-light frame.
According to the eigenenergies and eigenstates of the normal and superradiant
phases of this equivalent anisotropic Rabi model, we find that the excitation
energy of the normal phase and the superradiant phase vanishes at the critical
point. The photon number becomes infinite beyond the critical point. These
results indicate that the system undergoes a superradiant phase transition at
the critical point.

</details>


### [18] [Quantum-classical hybrid algorithm using quantum annealing for multi-objective job shop scheduling](https://arxiv.org/abs/2511.03257)
*Kenta Sawamura,Kensuke Araki,Naoki Maruyama,Renichiro Haba,Masayuki Ohzeki*

Main category: quant-ph

TL;DR: 提出了一种量子-经典混合算法，将生产规划问题分解为资源分配和任务调度两个子问题，在铸造生产场景中验证了方法的优越性。


<details>
  <summary>Details</summary>
Motivation: 传统数学优化方法在大规模生产规划问题中计算成本高，且多目标场景下传统标量化技术难以找到多样化的帕累托最优解。

Method: 将问题分解为资源分配（QUBO问题，使用退火方法求解）和任务调度（MILP问题，使用传统求解器求解）两个子问题。

Result: 实验结果表明，该混合方法在解决方案质量和计算效率方面优于传统的整体方法。

Conclusion: 这项工作为工业应用中的高速多目标调度提供了一个有前景的方向。

Abstract: Efficient production planning is essential in modern manufacturing to improve
performance indicators such as lead time and to reduce reliance on human
intuition. While mathematical optimization approaches, formulated as job shop
scheduling problems, have been applied to automate this process, solving
large-scale production planning problems remains computationally demanding.
Moreover, many practical scenarios involve conflicting objectives, making
traditional scalarization techniques ineffective in finding diverse and useful
Pareto-optimal solutions. To address these challenges, we developed a
quantum-classical hybrid algorithm that decomposes the problem into two
subproblems: resource allocation and task scheduling. Resource allocation is
formulated as a quadratic unconstrained binary optimization problem and solved
using annealing-based methods that efficiently explore complex solutions. Task
scheduling is modeled as a mixed-integer linear programming problem and solved
using conventional solvers to satisfy detailed scheduling constraints. We
validated the proposed method using benchmark instances based on foundry
production scenarios. Experimental results demonstrate that our hybrid approach
achieves superior solution quality and computational efficiency compared to
traditional monolithic methods. This work offers a promising direction for
high-speed, multi-objective scheduling in industrial applications.

</details>


### [19] [Thermodynamic Probes of Multipartite Entanglement in Strongly Interacting Quantum Systems](https://arxiv.org/abs/2511.03266)
*Harsh Sharma,Sampriti Saha,A. S. Majumdar,Manik Banik,Himadri Shekhar Dhar*

Main category: quant-ph

TL;DR: 提出了一种通过评估全局和局域功容量来量化多体量子系统中真正多体纠缠的新框架，该方法通过控制相互作用淬灭或测量局域可观测量实现，适用于强相互作用系统。


<details>
  <summary>Details</summary>
Motivation: 传统基于热力学量的纠缠度量方法在强集体或粒子间相互作用系统中存在限制，需要开发更通用的纠缠表征工具以适应量子模拟器的发展。

Method: 通过控制相互作用淬灭或测量合适的局域可观测量来评估全局和局域功容量，从而估计真正多体纠缠。

Result: 该框架能够正确估计强相互作用系统中静态和演化态的真正多体纠缠，包括在量子电路中模拟的参数化量子态，并适用于Tavis-Cummings模型、三能级Dicke模型和横场Ising模型等物理模型。

Conclusion: 该框架为近量子模拟器中的纠缠表征提供了一个通用工具，能够克服传统方法在强相互作用系统中的限制。

Abstract: Quantifying multipartite entanglement in quantum many-body systems and hybrid
quantum computing architectures is a fundamental yet challenging task. In
recent years, thermodynamic quantities such as the maximum extractable work
from an isolated system (the ergotropy) have allowed for entanglement measures
that are operationally more accessible. However, these measures can be
restrictive when applied to systems governed by Hamiltonians with strong
collective or interparticle interactions. Motivated by advances in quantum
simulators, we propose a framework that circumvents these restrictions by
evaluating global and local ergotropy either through controlled quenching of
interactions or by measuring suitable local observables only. We show that this
formalism allows us to correctly estimate genuine multipartite entanglement in
both stationary and time-evolved states of systems with strong interactions,
including parametrized quantum states simulated on a quantum circuit with
varying circuit depth and noise. We demonstrate its applicability to realistic
physical models, namely, the Tavis-Cummings model, the three-level Dicke model,
and the transverse-field Ising model, highlighting its potential as a versatile
tool for characterizing entanglement in near-term quantum simulators.

</details>


### [20] [Influence of Data Dimensionality Reduction Methods on the Effectiveness of Quantum Machine Learning Models](https://arxiv.org/abs/2511.03320)
*Aakash Ravindra Shinde,Jukka K. Nurminen*

Main category: quant-ph

TL;DR: 本文分析了数据降维方法对量子机器学习模型性能的影响，发现在使用和不使用数据降维时，模型准确率存在14%到48%的差异，导致对量子机器学习模型实际性能的错误估计。


<details>
  <summary>Details</summary>
Motivation: 解决NISQ量子设备（噪声大、量子比特有限）和经典设备模拟大量量子比特的约束，同时关注数据降维方法在大数据集上的可扩展性问题。

Method: 在多个生成数据集上，使用不同的量子机器学习算法、量子数据编码方法和数据降维方法进行实验，评估准确率、精确率、召回率和F1分数等性能指标。

Result: 数据降维方法导致性能指标值偏斜，错误估计量子机器学习模型的真实性能。某些数据降维方法对特定的数据嵌入方法和ansatz结构表现更好。

Conclusion: 数据降维方法的使用会扭曲量子机器学习模型的性能评估，需要谨慎考虑数据集特性、量子信息嵌入方法、特征减少比例、经典组件和模型结构等因素。

Abstract: Data dimensionality reduction techniques are often utilized in the
implementation of Quantum Machine Learning models to address two significant
issues: the constraints of NISQ quantum devices, which are characterized by
noise and a limited number of qubits, and the challenge of simulating a large
number of qubits on classical devices. It also raises concerns over the
scalability of these approaches, as dimensionality reduction methods are slow
to adapt to large datasets. In this article, we analyze how data reduction
methods affect different QML models. We conduct this experiment over several
generated datasets, quantum machine algorithms, quantum data encoding methods,
and data reduction methods. All these models were evaluated on the performance
metrics like accuracy, precision, recall, and F1 score. Our findings have led
us to conclude that the usage of data dimensionality reduction methods results
in skewed performance metric values, which results in wrongly estimating the
actual performance of quantum machine learning models. There are several
factors, along with data dimensionality reduction methods, that worsen this
problem, such as characteristics of the datasets, classical to quantum
information embedding methods, percentage of feature reduction, classical
components associated with quantum models, and structure of quantum machine
learning models. We consistently observed the difference in the accuracy range
of 14% to 48% amongst these models, using data reduction and not using it.
Apart from this, our observations have shown that some data reduction methods
tend to perform better for some specific data embedding methodologies and
ansatz constructions.

</details>


### [21] [Exploring Topologies in Quantum Annealing: A Hardware-Aware Perspective](https://arxiv.org/abs/2511.03327)
*Mario Bifulco,Luca Roversi*

Main category: quant-ph

TL;DR: 本文研究了量子退火硬件拓扑结构对优化问题嵌入效率的影响，比较了Zephyr图和Havel-Hakimi图两种拓扑在minor embedding中的表现。


<details>
  <summary>Details</summary>
Motivation: 量子退火硬件中硬连线的静态拓扑结构可能导致低效的编译，因为硬件连接图不能是完全图。需要评估硬件拓扑如何负面地影响嵌入问题，使量子优化对噪声更敏感。

Method: 提出了一种方法和一组标准来评估硬件拓扑对嵌入问题的影响，在两种QPU拓扑（Zephyr图和Havel-Hakimi图）上执行minor embedding，研究节点数/节点度比率对嵌入成功率的影响。

Result: 基于Havel-Hakimi的拓扑平均需要更短的量子比特链，在QPU尺寸增加时展现出更平滑的最大可嵌入图缩放特性。

Conclusion: Havel-Hakimi拓扑作为量子退火QPU的替代设计具有潜力，能够提供更好的嵌入效率和可扩展性。

Abstract: Quantum Annealing (QA) offers a promising framework for solving NP-hard
optimization problems, but its effectiveness is constrained by the topology of
the underlying quantum hardware. Solving an optimization problem $P$ via QA
involves a hardware-aware circuit compilation which requires representing $P$
as a graph $G_P$ and embedding it into the hardware connectivity graph $G_Q$
that defines how qubits connect to each other in a QA-based quantum processing
unit (QPU).
  Minor Embedding (ME) is a possible operational form of this hardware-aware
compilation. ME heuristically builds a map that associates each node of $G_P$
-- the logical variables of $P$ -- to a chain of adjacent nodes in $G_Q$ by
means of one of its minors, so that the arcs of $G_P$ are preserved as physical
connections among qubits in $G_Q$.
  The static topology of hardwired qubits can clearly lead to inefficient
compilations because $G_Q$ cannot be a clique, currently. We propose a
methodology and a set of criteria to evaluate how the hardware topology $G_Q$
can negatively affect the embedded problem, thus making the quantum
optimization more sensible to noise.
  We evaluate the result of ME across two QPU topologies: Zephyr graphs (used
in current D-Wave systems) and Havel-Hakimi graphs, which allow controlled
variation of the average node degree. This enables us to study how the ratio
`number of nodes/number of incident arcs per node' affects ME success rates to
map $G_P$ into a minor of $G_Q$.
  Our findings, obtained through ME executed on classical, i.e. non-quantum,
architectures, suggest that Havel-Hakimi-based topologies, on average, require
shorter qubit chains in the minor of $G_P$, exhibiting smoother scaling of the
largest embeddable $G_P$ as the QPU size increases. These characteristics
indicate their potential as alternative designs for QA-based QPUs.

</details>


### [22] [Dynamical discontinuities in repeated weak measurements revealed by complex weak values](https://arxiv.org/abs/2511.03352)
*Lorena Ballesteros Ferraz*

Main category: quant-ph

TL;DR: 该论文研究了在弱测量后选择协议中，当后选择极角作为控制参数时出现的动力学不连续性现象，揭示了这些不连续性与弱值虚部的关系以及相关的临界行为。


<details>
  <summary>Details</summary>
Motivation: 探索量子弱测量协议中测量反作用如何塑造量子动力学，特别是在后选择条件下出现的临界现象和普遍行为。

Method: 系统在重复应用弱测量后选择协议下演化，每次迭代后保留仪表状态但重置系统状态，分析弱值结构和Kraus算子的本征结构。

Result: 当弱值具有非零虚部时，在弱值虚部消失的后选择极角处会出现仪表可观测量期望值的不连续性；当弱值始终为实数时则无此现象。临界指数为1，与系统参数无关。

Conclusion: 这些结果为在基于测量的量子控制中设计非解析行为以及使用弱值弱测量探测后选择量子动力学中的临界性开辟了新视角。

Abstract: Critical phenomena reveal universal behavior in complex systems, and
uncovering analogous effects in quantum weak measurement protocols with
post-selection provides new insight into how measurement backaction can shape
quantum dynamics. This work investigates dynamical discontinuities that arise
when the post-selected polar angle is used as a control parameter. The system
evolves under repeated applications of a weak measurement protocol with
post-selection, in which the meter state is retained after each iteration while
the system is renewed. The emergence of these discontinuities is shown to be
determined by the structure of the weak value: when the weak value has a
nonzero imaginary component, a discontinuity appears in the expectation value
of meter observables precisely at the point where the imaginary part of the
weak value vanishes as a function of the post-selection polar angle. In
contrast, no discontinuities occur when the weak value remains real for all
post-selection angles. The phenomenon originates from the eigenstructure of the
protocol's Kraus operator, with the stability of fixed points changing at the
critical point where the discontinuity arises. Remarkably, the associated
critical exponent is 1, independent of system parameters. These results open
new perspectives for engineering non-analytic behavior in measurement-based
quantum control and for probing criticality in post-selected quantum dynamics
using weak measurements with weak values.

</details>


### [23] [Integration of quantum dots at the tips of single plasmonic bipyramid nanoantennas for strong coupling at room temperature](https://arxiv.org/abs/2511.03409)
*Kseniia Mamaeva,Hodjat Haijan,Carolyn Elliott,Hannah Killeen,Teodora Faraone,Larisa Florea,Colm Delaney,A. Louise Bradley*

Main category: quant-ph

TL;DR: 该论文展示了在室温下实现胶体量子点与单个金纳米双锥之间的强耦合，通过等离子体触发双光子聚合技术精确定位量子点到等离子体热点，观测到349.3 meV的拉比分裂和175.68 meV的耦合强度。


<details>
  <summary>Details</summary>
Motivation: 实现胶体半导体量子点与局域表面等离子体极化激元的强耦合对于室温量子发射器和传感应用至关重要，但关键挑战在于精确控制发射器相对于单个等离子体纳米结构的位置。

Method: 选择双锥等离子体纳米腔提供单个热点，利用等离子体触发双光子聚合技术，通过BP尖端增强电场选择性聚合含量子点的光敏配方，实现量子点在单个热点的定位。

Result: 3-QD-BP系统的室温散射光谱显示349.3 meV的拉比分裂和175.68 meV的耦合强度，模拟确认了明显的反交叉行为。

Conclusion: 该方法相比先前方法简化了量子点集成，为胶体量子点的固态量子技术提供了一个可扩展平台，能够在环境条件下探索激子-等离子体相互作用并推进量子光学和量子传感应用。

Abstract: Achieving strong coupling between excitons of colloidal semiconductor quantum
dots (QDs) and localized surface plasmon polaritons (LSPs) is critical for
advanced room-temperature quantum emitter and sensing applications. A key
challenge is to have precise control of the emitters position with respect to
an individual plasmonic nanostructure. Here, we present room temperature strong
coupling between QDs and a single gold nano-bipyramid (BPs). The selection of
the bipyramid plasmonic nanocavity offers access to a single hotspot with a
very small mode volume. The localization of QDs at a single hotspot is achieved
via plasmon-triggered two-photon polymerization. This technique exploits the
enhanced electric field at the BP tip to selectively polymerize a
photosensitive QD-containing formulation. Room-temperature scattering spectra
of a 3-QD-BP system reveal Rabi splitting of 349.3 meV and a coupling strength
of 175.68 meV. The with distinct anti-crossing behavior is confirmed by
simulations. This approach simplifies QD integration for strong coupling
systems compared to previous methods. These results indicate a scalable
platform for solid-state quantum technologies with colloidal QDs, enabling
explora-tion of exciton-plasmon interactions and further advance-ment of
applications in quantum optics and quantum sensing under ambient conditions.

</details>


### [24] [Quantum-elevated Chiral Discrimination for Bio-molecules](https://arxiv.org/abs/2511.03412)
*Yiquan Yang,Xiaolong Hu,Wei Du,Shuhe Wu,Peiyu Yang,Guzhi Bao,Weiping Zhang*

Main category: quant-ph

TL;DR: 本文提出了一种基于连续变量偏振纠缠态的量子增强手性识别方法，在区分L型和D型氨基酸时实现了比经典散粒噪声极限高5dB的灵敏度提升。


<details>
  <summary>Details</summary>
Motivation: 传统手性识别方法依赖圆偏振光，存在手性光学信号弱和潜在光损伤问题，且受限于量子涨落导致的散粒噪声极限。

Method: 使用连续变量偏振纠缠态作为中等光子通量、高灵敏度的量子噪声压缩手性探针。

Result: 在液相中区分L型和D型氨基酸时实现了5dB的灵敏度提升，超越了散粒噪声极限。

Conclusion: 这种非破坏性、生物相容的协议为高灵敏度手性分析提供了新途径，在药物开发、生化研究、环境监测和不对称合成等领域具有广泛应用前景。

Abstract: Chiral discrimination of enantiomeric biomolecules is vital in chemistry,
biology, and medicine. Conventional methods, relying on circularly polarized
light, face weak chiroptical signals and potential photodamage. Despite
extensive efforts to improve sensitivity under low-photon exposure, classical
chiral probes remain fundamentally bounded by the shot-noise limit due to
quantum fluctuations. To beat these limitations, we demonstrate
quantum-elevated chiral discrimination using continuous-variable
polarization-entangled states as moderate-photon-flux, high-sensitivity,
quantum-noise-squeezed chiral probes. We achieve a 5 dB improvement beyond the
SNL in distinguishing L- and D-amino acids in liquid phase. This
non-destructive, biocompatible protocol enables high-sensitivity chiral
analysis, with broad implications for drug development, biochemical research,
environmental monitoring, and asymmetric synthesis.

</details>


### [25] [Universal first-passage time statistics for quantum diffusion](https://arxiv.org/abs/2511.03455)
*Guido Ladenburger,Finn Schmolke,Eric Lutz*

Main category: quant-ph

TL;DR: 该论文解决了量子扩散过程中的首次通过时间问题，发现这种时间分布具有普遍性，不依赖于系统哈密顿量或测量算子。


<details>
  <summary>Details</summary>
Motivation: 首次通过现象在经典随机过程中具有基础地位，但在量子系统中研究较少。连续监测可能将量子系统困在退相干自由子空间中，这在量子信息科学中很重要。

Method: 通过解析方法求解由测量噪声驱动的量子扩散问题，这是经典布朗运动的量子推广。

Result: 解析确定了首次通过时间分布，该分布形式具有普遍性，不依赖于系统哈密顿量或测量算子。

Conclusion: 这些结果为研究扩散量子轨迹的首次通过统计提供了一个通用框架。

Abstract: First-passage phenomena play a fundamental role in classical stochastic
processes. We here exactly solve a quantum first-passage time problem for
quantum diffusion driven by measurement noise, a generalization of classical
Brownian motion. Such continuous monitoring may trap the measured quantum
system in a decoherence-free subspace, a fraction of the available state space
that is isolated from the surroundings, and thus plays an important role in
quantum information science. We analytically determine the first-passage time
distribution, whose form neither depends on the system Hamiltonian nor on the
measurement operator, and is therefore universal. These results provide a
general framework to investigate the first-passage statistics of diffusive
quantum trajectories.

</details>


### [26] [Mutually Unbiased Bases and Orthogonal Latin Squares](https://arxiv.org/abs/2511.03537)
*Stefan Joka*

Main category: quant-ph

TL;DR: 证明了在N维希尔伯特空间中，完全相互无偏基(MUBs)的存在意味着相同阶数的完全相互正交拉丁方(MOLSs)的存在，并特别证明了在维度六（第一个非素数幂维度）中不存在完全MUBs。


<details>
  <summary>Details</summary>
Motivation: 研究相互无偏基(MUBs)在量子信息理论中的重要性，特别是在非素数幂维度中的存在性问题，维度六是第一个非素数幂维度，其MUBs的存在性一直是一个开放问题。

Method: 通过数学证明建立MUBs与MOLSs之间的等价关系，利用组合数学和量子信息理论的工具来分析维度六的情况。

Result: 证明了完全MUBs的存在等价于完全MOLSs的存在，并确认在维度六中不存在完全MUBs。

Conclusion: 该研究解决了维度六中MUBs存在性的长期开放问题，并为更高维度的类似研究提供了方法论基础。

Abstract: In this paper, we prove that the existence of a complete set of mutually
unbiased bases (MUBs) in N-dimensional Hilbert space implies the existence of a
complete set of mutually orthogonal Latin squares (MOLSs) of order N. In
particular, we prove that a complete set of MUBs does not exist in dimension
six (the first dimension which is not a power of prime).

</details>


### [27] [The Converse Madelung Question](https://arxiv.org/abs/2511.03552)
*Jonathan R Dunkley*

Main category: quant-ph

TL;DR: 该论文证明了在满足特定物理公理的局部哈密顿场理论中，Fisher信息是量子力学出现的必要条件，且该框架下薛定谔方程是唯一的可逆固定点。


<details>
  <summary>Details</summary>
Motivation: 研究Fisher信息在量子力学中的必要性，而非其充分性，旨在从信息论角度理解量子力学的本质。

Method: 采用最小物理公理（局域性、概率守恒、欧几里得不变性等），通过局部复变量变换和变分方法分析密度和相位的动力学。

Result: 在满足公理的局部场理论中，只有Fisher泛函能产生可逆的完全投影线性动力学，且当系数为普朗克常数平方除以两倍质量时，动力学简化为线性薛定谔方程。

Conclusion: 量子力学作为Fisher正则化信息流体动力学的可逆固定点出现，普朗克常数在多体系统中由局部复结构统一确定。

Abstract: We pose the converse Madelung question: not whether Fisher information can
reproduce quantum mechanics, but whether it is necessary. We work with minimal,
physically motivated axioms on density and phase: locality, probability
conservation, Euclidean invariance with a global phase symmetry, reversibility,
and convex regularity. Within the resulting class of first order local
Hamiltonian field theories, these axioms single out the canonical Poisson
bracket on density and phase under the Dubrovin and Novikov assumptions for
local hydrodynamic brackets. Using a pointwise, gauge covariant complex change
of variables that maps density and phase to a single complex field, we show
that the only convex, rotationally invariant, first derivative local functional
of the density whose Euler Lagrange term yields a reversible completion that is
exactly projectively linear is the Fisher functional. When its coefficient
equals Planck constant squared divided by twice the mass, the dynamics reduce
to the linear Schrodinger equation. For many body systems, a single local
complex structure across sectors enforces the same relation species by species,
fixing a single Planck constant. Galilean covariance appears through the
Bargmann central extension, with the usual superselection consequences.
Comparison with the Doebner and Goldin family identifies the reversible zero
diffusion corner with linear Schrodinger dynamics. We provide operational
falsifiers via residual diagnostics for the continuity and Hamilton Jacobi
equations and report numerical minima at the Fisher scale that are invariant
under Galilean boosts. In this setting, quantum mechanics emerges as a
reversible fixed point of Fisher regularised information hydrodynamics. A code
archive enables direct numerical checks, including a superposition stress test
that preserves exact projective linearity within our axioms.

</details>


### [28] [Spontaneous symmetry breaking in nonlinear superradiance](https://arxiv.org/abs/2511.03590)
*Nikolai D. Klimkin,Misha Ivanov*

Main category: quant-ph

TL;DR: 本文通过修改Dicke超辐射问题，利用对称性选择规则抑制单原子单光子发射，展示了非经典光态的形成和操控。


<details>
  <summary>Details</summary>
Motivation: 现代阿秒科学关注非经典光态的创建和操控，本文旨在探索如何通过原子系综产生这类量子态。

Method: 采用新颖的非马尔可夫、非微扰方法，研究不可区分原子系综的光子发射，利用对称性选择规则抑制单原子发射。

Result: 观察到系统经历对称性破缺转变后，形成大型量子光态并表现出显著的非经典统计特性。

Conclusion: 通过对称性破缺转变可以实现非经典光态的产生，为量子光学和量子信息处理提供了新途径。

Abstract: Creation and manipulation of non-classical states of light is rapidly
becoming the focus of modern attosecond science. Here, we demonstrate
numerically how such states can arise by considering a modification of the
well-known problem of superradiance encountered already by Dicke. Similarly to
him, we investigate photon emission by ensembles of indistinguishable atoms. In
contrast to him, however, we leverage symmetry-based selection rules to
suppress emission of single photons by single atoms. A steady state is
therefore only reached following a spontaneous transition into a collective
symmetry-broken state of atoms and photonic modes. The novel non-Markovian,
non-perturbative method applied allows us to observe a large quantum state of
light form and exhibit drastically non-classical statistics once the system
undergoes a symmetry-breaking transition.

</details>


### [29] [Directional quantum walks of two bosons on the Hatano-Nelson lattice](https://arxiv.org/abs/2511.03613)
*Sk Anisur,Kartik Singh,Sayan Choudhury*

Main category: quant-ph

TL;DR: 研究了非厄米性对一维Hatano-Nelson晶格上两个玻色子动力学的影响，发现非互易隧穿导致不对称密度锥形成，强相互作用产生内密度结构，系统可作为量子增强传感器检测弱力。


<details>
  <summary>Details</summary>
Motivation: 探索非厄米系统中相互作用和非厄米性的相互作用如何影响多体量子动力学，特别是在非互易隧穿条件下玻色子对的动力学行为。

Method: 理论分析一维Hatano-Nelson晶格上两个玻色子的动力学，考虑非互易隧穿参数δ和静态外力的影响，研究密度分布、空间关联和量子Fisher信息的演化。

Result: 非互易性导致不对称密度锥形成；强相互作用产生内密度锥或沙漏结构；系统表现出非互易聚束/反聚束行为；量子Fisher信息以F_Q ∝ t^α增长，α∼3，表明量子增强传感能力。

Conclusion: 非厄米性显著影响多体量子动力学，产生不对称结构和非互易关联，系统具有量子增强传感潜力，可用于弱力检测。

Abstract: We theoretically investigate the interplay of interactions and
non-Hermiticity in the dynamics of two bosons on the one-dimensional
Hatano-Nelson lattice with non-reciprocal tunneling. We find that the
non-reciprocity in the tunneling leads to the formation of an asymmetric
density cone during the time-evolution of the system; the degree of asymmetry
can be tuned by tuning the non-reciprocity parameter, $\delta$. Next, we
analyze the dynamics of this system in the presence of a static external force
and demonstrate that non-Hermiticity leads to asymmetric two-particle Bloch
oscillations. Interestingly, when $F=0$ ($F \ne 0$), strong interactions leads
to the formation of an inner density-cone (density-hourglass) structure; this
inner structure also becomes asymmetric in the presence of non-Hermiticity. We
further analyze the spatial correlations and establish that the system exhibits
non-reciprocal bunching (anti-bunching) in the presence of weak (strong)
interactions. Finally, we examine the growth of the Quantum Fisher Information,
$F_Q$, with time, and demonstrate that $F_Q \propto t^{\alpha}$ where $\alpha
\sim 3$. This feature persists for both one- and two-particle walks, thereby
demonstrating that this system can be employed as a quantum-enhanced sensor for
detecting weak forces.

</details>


### [30] [Annual-modulation fingerprint of the axion wind induced sideband triplet in quantum dot spin qubit sensors](https://arxiv.org/abs/2511.03630)
*Xiangjun Tan,Zhanning Wang*

Main category: quant-ph

TL;DR: 提出了一种基于硅量子点自旋量子位的相位相干窄带磁强计，用于探测轴子或类轴子粒子与电子自旋的耦合，通过分析日调制和年调制信号增强灵敏度。


<details>
  <summary>Details</summary>
Motivation: 开发实验室方法来探测轴子与电子自旋的耦合，补充天体物理观测，利用量子传感器的优势实现高精度测量。

Method: 使用门定义硅量子点自旋量子位，通过重复Ramsey回波序列和色散读出，结合滤波协议处理传感噪声，分析日调制和年调制信号。

Result: 在1-10 μeV轴子质量范围内，可探测的轴子-电子耦合强度范围为10^-14到10^-10，能够清晰观测到地球自转引起的日调制信号。

Conclusion: 自旋量子位磁强计可以达到接近天体物理建议的灵敏度，为轴子-电子相互作用提供了互补的实验室探测方法，该方法可广泛应用于自旋基量子传感器。

Abstract: We propose a phase-coherent, narrowband magnetometer for searching couplings
between axions or axion-like particles (ALPs) and electron spins, using
gate-defined silicon quantum-dot spin qubits. With repeated Ramsey echo
sequences and dispersive readout, the qubit precession response can be tracked
with sub-Hz spectral resolution. The accessible axion mass window is determined
using a series of filtering protocols that take into account sensing noise,
including readout errors and $1/f$ noise. We demonstrate clear evidence of
sidereal modulation of the signal due to Earth's rotation, while Earth's
orbital motion produces an annual amplitude envelope that generates sidebands
at fixed frequency spacing $\pm \Omega_\oplus$ around the sidereal component.
For axion masses between $1$-$10~\mu{\rm eV}$, the proposed method covers
axion-electron coupling strengths $g_{ae}$ ranging from $10^{-14}$ to
$10^{-10}$. Including both daily and annual modulation patterns in the
likelihood analysis enhances the rejection of stationary or instrumental noise.
Our results indicate that spin-qubit magnetometry can achieve sensitivities
approaching those suggested by astrophysical considerations, providing a
complementary, laboratory-based probe of axion-electron interactions. Although
we focus on silicon spin-qubit architectures, the approach is broadly
applicable to spin-based quantum sensors.

</details>


### [31] [Correlation-Powered Work: Equivalence in Peak Yield, Differences in Robustness](https://arxiv.org/abs/2511.03679)
*Karl Svozil*

Main category: quant-ph

TL;DR: 本文比较了经典、量子及超量子关联在测量不对齐情况下的功提取能力，发现虽然三者都能达到最大功提取值k_B T ln 2，但作为热力学燃料的操作鲁棒性存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 研究初始系统-环境关联作为热力学资源的价值，特别关注不同关联类型在测量不对齐情况下的功提取鲁棒性差异。

Method: 通过比较经典、量子和假设的超量子关联模型，分析它们在测量不对齐参数变化下的功提取能力衰减特性。

Result: 所有模型都能达到最大功提取值k_B T ln 2（对应互信息ln 2），但经典关联的功提取能力随不对齐线性衰减，量子关联仅二次衰减，超量子关联表现更优。

Conclusion: 非定域性程度不决定关联的最大能量价值，而是决定其作为热力学燃料的操作鲁棒性，量子关联在测量不对齐时表现出更强的鲁棒性。

Abstract: Initial system-environment correlations are a thermodynamic resource,
enabling work extraction via their erasure. We compare the work potential of
classical, quantum, and hypothetical stronger-than-quantum correlations as a
function of measurement misalignment. While all models can yield a peak
extractable work of k_B T ln 2, corresponding to a mutual information of ln 2,
their value as a resource differs critically in its robustness. The classical
resource is fragile, decaying linearly with misalignment, whereas the quantum
resource is robust, decaying only quadratically. Thus, the degree of
nonlocality maps not to the maximum energetic value of a correlation, but to
its operational robustness as a thermodynamic fuel.

</details>


### [32] [Certified randomness amplification by dynamically probing remote random quantum states](https://arxiv.org/abs/2511.03686)
*Minzhao Liu,Pradeep Niroula,Matthew DeCross,Cameron Foreman,Wen Yu Kon,Ignatius William Primaatmaja,M. S. Allman,J. P. Campora III,Akhil Isanaka,Kartik Singhal,Omar Amer,Shouvanik Chakrabarti,Kaushik Chakraborty,Samuel F. Cooper,Robert D. Delaney,Joan M. Dreiling,Brian Estey,Caroline Figgatt,Cameron Foltz,John P. Gaebler,Alex Hall,Zichang He,Craig A. Holliman,Travis S. Humble,Shih-Han Hung,Ali A. Husain,Yuwei Jin,Fatih Kaleoglu,Colin J. Kennedy,Nikhil Kotibhaskar,Nathan K. Lysne,Ivaylo S. Madjarov,Michael Mills,Alistair R. Milne,Kevin Milner,Louis Narmour,Sivaprasad Omanakuttan,Annie J. Park,Michael A. Perlin,Adam P. Reed,Chris N. Self,Matthew Steinberg,David T. Stephen,Joseph Sullivan,Alex Chernoguzov,Florian J. Curchod,Anthony Ransford,Justin G. Bohnet,Brian Neyenhuis,Michael Foss-Feig,Rob Otter,Ruslan Shaydulin*

Main category: quant-ph

TL;DR: 在量子处理器上实现跨网络的认证随机性放大，通过实时流式传输量子门并限制经典欺骗时间，将不完美的随机性转化为近乎完美的随机性


<details>
  <summary>Details</summary>
Motivation: 物理随机源产生的比特存在偏差或相关性，而传统的量子随机性放大需要物理共置的无漏洞贝尔测试，限制了远程操作的可行性

Method: 在Quantinuum的98量子比特离子阱量子处理器上动态探测大型纠缠量子态，实时流式传输量子门，在测量前毫秒级时间才揭示测量基，限制经典欺骗时间为30毫秒

Result: 在64量子比特和276个双量子比特门的随机电路中实现了0.586的保真度，将低熵率的不完美随机性放大为近乎完美的随机性

Conclusion: 该方法即使在远程设备恶意或被截获的情况下也是安全的，为网络环境下的认证随机性放大提供了可行方案

Abstract: Cryptography depends on truly unpredictable numbers, but physical sources
emit biased or correlated bits. Quantum mechanics enables the amplification of
imperfect randomness into nearly perfect randomness, but prior demonstrations
have required physically co-located, loophole-free Bell tests, constraining the
feasibility of remote operation. Here we realize certified randomness
amplification across a network by dynamically probing large, entangled quantum
states on Quantinuum's 98-qubit Helios trapped-ion quantum processor. Our
protocol is secure even if the remote device acts maliciously or is compromised
by an intercepting adversary, provided the samples are generated quickly enough
to preclude classical simulation of the quantum circuits. We stream quantum
gates in real time to the quantum processor, maintain quantum state coherence
for $\approx 0.9$ seconds, and then reveal the measurement bases to the quantum
processor only milliseconds before measurement. This limits the time for
classical spoofing to 30 ms and constrains the location of hypothetical
adversaries to a $4{,}500$ km radius. We achieve a fidelity of 0.586 on random
circuits with 64 qubits and 276 two-qubit gates, enabling the amplification of
realistic imperfect randomness with a low entropy rate into nearly perfect
randomness.

</details>


### [33] [Frequency shifts as a reflection of ground state squeezing and entanglement in two coupled harmonic oscillators](https://arxiv.org/abs/2511.03687)
*Safoura Mirkhalaf,Helmut Ritsch,Karol Gietka*

Main category: quant-ph

TL;DR: 耦合量子谐振子即使在基态也能通过频率偏移显示量子特征，这些偏移可作为纠缠见证并用于增强精密频率测量的信噪比。


<details>
  <summary>Details</summary>
Motivation: 挑战传统观点，证明耦合量子谐振子系统的经典可观测量也能编码真正的量子特征，揭示量子性在量子-经典边界上的持续存在。

Method: 分析耦合量子谐振子系统的频率偏移与两模压缩纠缠之间的关系，证明这两种现象在不同模式基下是同一基础现象的不同表达。

Result: 发现频率偏移可作为基态纠缠的见证，并且这种潜在的压缩纠缠可用于增强单个振荡器精密频率测量的信噪比。

Conclusion: 在传统上被视为经典的系统中发现了一条量子增强传感的新途径，为量子性在量子-经典边界上的持续存在提供了新的见解。

Abstract: It is often argued that two coupled quantum harmonic oscillators, even when
cooled to their ground state, display no inherently quantum features beyond
quantized energy levels. Here, we challenge this view by showing that their
classical observables can encode genuinely quantum features. In particular, we
demonstrate that the characteristic frequency shifts observed in such systems
act as a signature of non-classical correlations and ground-state entanglement
at zero temperature, specifically two-mode squeezing between the uncoupled
modes. From a complementary perspective, these two effects -- frequency shifts
and squeezing -- represent the same underlying phenomenon expressed in
different mode bases. What appears as a spectral renormalization in one
description manifests as entanglement in another. These shifts therefore can
serve as an entanglement witness accessible via standard frequency
measurements. Furthermore, we show that this underlying squeezing, although not
directly measurable, can be exploited to enhance the signal-to-noise ratio in
precision frequency measurements of individual oscillators without requiring
squeezed quantum noise. Our results uncover a new route to quantum-enhanced
sensing within systems traditionally regarded as classical, offering fresh
insight into how signatures of quantumness persist across the
quantum-to-classical boundary.

</details>


### [34] [Realization of a Quantum Streaming Algorithm on Long-lived Trapped-ion Qubits](https://arxiv.org/abs/2511.03689)
*Pradeep Niroula,Shouvanik Chakrabarti,Steven Kordonowy,Niraj Kumar,Sivaprasad Omanakuttan,Michael A. Perlin,M. S. Allman,J. P. Campora III,Alex Chernoguzov,Samuel F. Cooper,Robert D. Delaney,Joan M. Dreiling,Brian Estey,Caroline Figgatt,Cameron Foltz,John P. Gaebler,Alex Hall,Ali A. Husain,Akhil Isanaka,Colin J. Kennedy,Nikhil Kotibhaskar,Ivaylo S. Madjarov,Michael Mills,Alistair R. Milne,Louis Narmour,Annie J. Park,Adam P. Reed,Kartik Singhal,Anthony Ransford,Justin G. Bohnet,Brian Neyenhuis,Rob Otter,Ruslan Shaydulin*

Main category: quant-ph

TL;DR: 本文在Quantinuum Helios离子阱量子计算机上实现了量子流式算法，解决了Hidden Matching问题，并证明了即使在容错架构下量子空间优势仍然存在。


<details>
  <summary>Details</summary>
Motivation: 经典数据集通常在流式模型中处理，量子算法在该模型中已被证明在空间上具有无条件指数优势，但实验实现需要与环境数据流交互时保持相干性的量子比特。

Method: 使用Quantinuum Helios离子阱量子计算机，实现量子对草图（quantum pair sketch）作为量子流式算法的基本原语，并将其编译到基于表面码和双变量自行车码的容错量子架构。

Result: 成功实现了量子流式模型，解决了Hidden Matching问题，该问题已知在理论上具有指数级量子空间优势。

Conclusion: 即使在考虑容错开销的情况下，量子空间优势仍然持续存在，这为量子流式算法的实际应用提供了实验支持。

Abstract: Large classical datasets are often processed in the streaming model, with
data arriving one item at a time. In this model, quantum algorithms have been
shown to offer an unconditional exponential advantage in space. However,
experimentally implementing such streaming algorithms requires qubits that
remain coherent while interacting with an external data stream. In this work,
we realize such a data-streaming model using Quantinuum Helios trapped-ion
quantum computer with long-lived qubits that communicate with an external
server. We implement a quantum pair sketch, which is the primitive underlying
many quantum streaming algorithms, and use it to solve Hidden Matching, a
problem known to exhibit a theoretical exponential quantum advantage in space.
Furthermore, we compile the quantum streaming algorithm to fault-tolerant
quantum architectures based on surface and bivariate bicycle codes and show
that the quantum space advantage persists even with the overheads of
fault-tolerance.

</details>


### [35] [A Transferable Machine Learning Approach to Predict Quantum Circuit Parameters for Electronic Structure Problems](https://arxiv.org/abs/2511.03726)
*Davide Bincoletto,Korbinian Stein,Jonas Motyl,Jakob S. Kottmann*

Main category: quant-ph

TL;DR: 本文探索了基于机器学习的参数预测方法，旨在实现量子电路参数在不同分子间的可迁移性，解决了变分量子本征求解器中参数优化的瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 当前变分量子本征求解器中量子电路参数的个体优化是主要实践瓶颈，现有机器学习方法主要针对单个分子进行参数训练和预测，缺乏不同分子间的参数迁移能力。

Method: 使用经过充分研究的量子电路设计，应用于氢原子系统建模，开发机器学习建模策略以实现参数在不同分子间的系统迁移。

Result: 展示了参数预测能够系统性地迁移到比训练实例显著更大的实例上，证明了跨分子参数迁移的可行性。

Conclusion: 机器学习方法可以实现量子电路参数在不同分子间的有效迁移，为解决变分量子算法中的参数优化瓶颈提供了新途径。

Abstract: The individual optimization of quantum circuit parameters is currently one of
the main practical bottlenecks in variational quantum eigensolvers for
electronic systems. To this end, several machine learning approaches have been
proposed to mitigate the problem. However, such method predominantly aims at
training and predicting parameters tailored to individual molecules: either a
specific structure, or several structures of the same molecule with varying
bond lengths. This work explores machine learning based modeling strategies to
include transferability between different molecules. We use a well investigated
quantum circuit design and apply it to model properties of hydrogenic systems
where we show parameter prediction that is systematically transferable to
instances significantly larger than the training instances.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [36] [FATE: A Formal Benchmark Series for Frontier Algebra of Multiple Difficulty Levels](https://arxiv.org/abs/2511.02872)
*Jiedong Jiang,Wanyi He,Yuefeng Wang,Guoxiong Gao,Yongle Hu,Jingting Wang,Nailing Guan,Peihao Wu,Chunbo Dai,Liang Xiao,Bin Dong*

Main category: cs.LG

TL;DR: FATE是一个新的形式代数定理评估基准系列，包含FATE-H和FATE-X各100个问题，难度从本科练习到超过博士资格考试水平，填补了现有数学基准与真实数学研究之间的差距。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在IMO等竞赛数学基准上表现优异，但这些基准无法反映现代数学研究的深度、广度和抽象性。需要建立更贴近真实数学研究难度的评估基准。

Method: 开发了FATE基准系列，包含两个组件：FATE-H和FATE-X，各包含100个抽象代数和交换代数问题。进行了两阶段评估：自然语言推理和形式化推理，并系统分类了形式化过程中的常见错误。

Result: 最先进的大语言模型在FATE基准上表现显著下降：最佳模型在FATE-H上仅达到3%（pass@64）准确率，在FATE-X上为0%。模型在自然语言推理阶段的准确性明显高于形式化推理阶段。

Conclusion: FATE基准为研究级形式数学推理提供了稳健且具有挑战性的评估标准，揭示了当前模型在高级数学推理方面的局限性，并建立了通往研究级数学推理的重要检查点。

Abstract: Recent advances in large language models (LLMs) have demonstrated impressive
capabilities in formal theorem proving, particularly on contest-based
mathematical benchmarks like the IMO. However, these contests do not reflect
the depth, breadth, and abstraction of modern mathematical research. To bridge
this gap, we introduce FATE (Formal Algebra Theorem Evaluation), a new
benchmark series in formal algebra designed to chart a course toward advanced
mathematical reasoning. We present two new components, FATE-H and FATE-X, each
with 100 problems in abstract and commutative algebra. The FATE series spans a
difficulty spectrum from undergraduate exercises to problems exceeding PhD
qualifying exams. Notably, FATE-X is the first formal benchmark to surpass both
PhD-level exam difficulty and the coverage of the Mathlib library. Our
evaluations of state-of-the-art LLM provers on this new benchmark reveal a
stark performance gap compared to contest math: the best model achieves only 3%
(pass@64) accuracy on FATE-H and 0% on FATE-X. Our two-stage evaluation reveals
that models' natural-language reasoning is notably more accurate than their
ability to formalize this reasoning. We systematically classify the common
errors that arise during this formalization process. Furthermore, a comparative
study shows that a specialized prover can exhibit less effective reflection
than general-purpose models, reducing its accuracy at the natural-language
stage. We believe FATE provides a robust and challenging benchmark that
establishes essential checkpoints on the path toward research-level formal
mathematical reasoning.

</details>


### [37] [Stochastic Deep Graph Clustering for Practical Group Formation](https://arxiv.org/abs/2511.02879)
*Junhyung Park,Hyungjin Kim,Seokho Ahn,Young-Duk Seo*

Main category: cs.LG

TL;DR: DeepForm是一个用于动态群组形成的推荐系统框架，通过轻量级图卷积网络捕捉高阶用户信息，支持实时群组形成和动态调整群组数量。


<details>
  <summary>Details</summary>
Motivation: 现有群组推荐系统主要关注推荐准确性，但假设群组是静态或预定义的，不适合现实世界中动态变化的场景。

Method: 采用轻量级GCN架构捕捉高阶结构信号，使用随机聚类学习实现无需重新训练的自适应群组重构，通过对比学习在动态条件下优化群组。

Result: 在多个数据集上的实验表明，DeepForm在群组形成质量、效率和推荐准确性方面均优于各种基线方法。

Conclusion: DeepForm成功解决了动态群组形成的核心挑战，满足了现实世界群组推荐系统的操作需求。

Abstract: While prior work on group recommender systems (GRSs) has primarily focused on
improving recommendation accuracy, most approaches assume static or predefined
groups, making them unsuitable for dynamic, real-world scenarios. We reframe
group formation as a core challenge in GRSs and propose DeepForm (Stochastic
Deep Graph Clustering for Practical Group Formation), a framework designed to
meet three key operational requirements: (1) the incorporation of high-order
user information, (2) real-time group formation, and (3) dynamic adjustment of
the number of groups. DeepForm employs a lightweight GCN architecture that
effectively captures high-order structural signals. Stochastic cluster learning
enables adaptive group reconfiguration without retraining, while contrastive
learning refines groups under dynamic conditions. Experiments on multiple
datasets demonstrate that DeepForm achieves superior group formation quality,
efficiency, and recommendation accuracy compared with various baselines.

</details>


### [38] [Test-time Adaptation of Tiny Recursive Models](https://arxiv.org/abs/2511.02886)
*Ronan Killian McGovern*

Main category: cs.LG

TL;DR: 通过从在公开ARC任务上预训练的微小递归模型出发，可以在允许的计算限制内高效地对竞赛任务进行微调，最终在半私有评估任务上获得6.67%的分数。


<details>
  <summary>Details</summary>
Motivation: 解决TRM方法在ARC竞赛中计算资源超限的问题，探索在有限计算预算下实现有效微调的方法。

Method: 首先在1280个公开任务上预训练7M参数的递归神经网络，然后在竞赛期间仅用12,500梯度步进行完整微调（非LoRA或仅任务嵌入微调）。

Result: 预训练模型在公开评估集上获得约10%的分数，后训练模型在半私有评估任务上达到6.67%的分数。

Conclusion: 从预训练的微小递归模型出发进行完整微调，可以在竞赛计算限制内实现有效的性能提升。

Abstract: Prior to the close of the 2025 ARC Prize competition, the leading open source
approach - known as TRM, or Tiny Recursive Models - involved training a 7M
parameter recursive neural network on augmented variants of ARC tasks. That
approach scored approximately 7.8% on the public ARC AGI II evaluation set, but
required a level of compute far in excess of what is allowed during the
competition. This paper shows that, by starting from a tiny recursive model
that has been pre-trained on public ARC tasks, one can efficiently fine-tune on
competition tasks within the allowed compute limits. Specifically, a model was
pre-trained on 1,280 public tasks for 700k+ optimizer steps over 48 hours on
4xH100 SXM GPUs to obtain a ~10% score on the public evaluation set. That model
was then post-trained in just 12,500 gradient steps during the competition to
reach a score of 6.67% on semi-private evaluation tasks. Notably, such
post-training performance is achieved by full-fine tuning of the tiny model,
not LoRA fine-tuning or fine-tuning of task embeddings alone.

</details>


### [39] [Predicting Weekly Fishing Concentration Zones through Deep Learning Integration of Heterogeneous Environmental Spatial Datasets](https://arxiv.org/abs/2511.02887)
*Chaitanya Rele,Aditya Rathod,Kaustubh Natu,Saurabh Kulkarni,Ajay Koli,Swapnali Makdey*

Main category: cs.LG

TL;DR: 提出了一个AI辅助框架，利用海面温度和叶绿素浓度等海洋参数来预测北印度洋的潜在渔区，旨在提高渔区识别准确性并为可持续捕捞提供区域特定见解。


<details>
  <summary>Details</summary>
Motivation: 北印度洋（包括阿拉伯海和孟加拉湾）是沿海社区重要的生计来源，但渔民在寻找高产渔区时经常面临不确定性。

Method: 使用AI辅助框架，结合海面温度和叶绿素浓度等海洋学参数来预测潜在渔区。

Result: 初步结果表明，该框架能够通过减少搜索时间、降低燃料消耗和促进资源高效利用来支持渔民。

Conclusion: 该AI辅助框架能够有效提高渔区预测准确性，为可持续渔业实践提供技术支持。

Abstract: The North Indian Ocean, including the Arabian Sea and the Bay of Bengal,
represents a vital source of livelihood for coastal communities, yet fishermen
often face uncertainty in locating productive fishing grounds. To address this
challenge, we present an AI-assisted framework for predicting Potential Fishing
Zones (PFZs) using oceanographic parameters such as sea surface temperature and
chlorophyll concentration. The approach is designed to enhance the accuracy of
PFZ identification and provide region-specific insights for sustainable fishing
practices. Preliminary results indicate that the framework can support
fishermen by reducing search time, lowering fuel consumption, and promoting
efficient resource utilization.

</details>


### [40] [Adaptive and Robust Data Poisoning Detection and Sanitization in Wearable IoT Systems using Large Language Models](https://arxiv.org/abs/2511.02894)
*W. K. M Mithsara,Ning Yang,Ahmed Imteaj,Hussein Zangoti,Abdur R. Shahid*

Main category: cs.LG

TL;DR: 提出使用大语言模型进行零样本、单样本和少样本学习，通过角色扮演和逐步思考策略来检测和清理可穿戴物联网系统中的人类活动识别数据中毒攻击。


<details>
  <summary>Details</summary>
Motivation: 随着可穿戴设备在物联网中的广泛应用，人类活动识别系统面临数据中毒攻击的威胁。传统防御方法需要大量标记数据集，限制了在动态物联网环境中的适应性。

Method: 利用大语言模型进行中毒检测和清理，采用角色扮演提示（LLM扮演专家角色评估传感器异常）和逐步思考推理（引导LLM推断中毒指标和清洁替代方案）。

Result: 通过广泛评估框架，量化了检测准确率、清理质量、延迟和通信成本，证明了大语言模型在提高可穿戴物联网系统安全性和可靠性方面的实用性。

Conclusion: 该方法减少了对大量数据集的依赖，实现了在实时环境中鲁棒且适应性强的防御机制，为可穿戴物联网系统安全提供了有效解决方案。

Abstract: The widespread integration of wearable sensing devices in Internet of Things
(IoT) ecosystems, particularly in healthcare, smart homes, and industrial
applications, has required robust human activity recognition (HAR) techniques
to improve functionality and user experience. Although machine learning models
have advanced HAR, they are increasingly susceptible to data poisoning attacks
that compromise the data integrity and reliability of these systems.
Conventional approaches to defending against such attacks often require
extensive task-specific training with large, labeled datasets, which limits
adaptability in dynamic IoT environments. This work proposes a novel framework
that uses large language models (LLMs) to perform poisoning detection and
sanitization in HAR systems, utilizing zero-shot, one-shot, and few-shot
learning paradigms. Our approach incorporates \textit{role play} prompting,
whereby the LLM assumes the role of expert to contextualize and evaluate sensor
anomalies, and \textit{think step-by-step} reasoning, guiding the LLM to infer
poisoning indicators in the raw sensor data and plausible clean alternatives.
These strategies minimize reliance on curation of extensive datasets and enable
robust, adaptable defense mechanisms in real-time. We perform an extensive
evaluation of the framework, quantifying detection accuracy, sanitization
quality, latency, and communication cost, thus demonstrating the practicality
and effectiveness of LLMs in improving the security and reliability of wearable
IoT systems.

</details>


### [41] [Zero-shot data citation function classification using transformer-based large language models (LLMs)](https://arxiv.org/abs/2511.02936)
*Neil Byers,Ali Zaidi,Valerie Skye,Chris Beecroft,Kjiersten Fagnan*

Main category: cs.LG

TL;DR: 使用Llama 3.1-405B大语言模型对引用特定基因组数据集的科学文献进行零样本数据使用案例分类，无需人工标注即可生成结构化标签。


<details>
  <summary>Details</summary>
Motivation: 近年来需要识别数据集与引用它们的科学文献之间的关联，了解数据如何被使用。传统方法需要昂贵的人工标注和训练数据集开发，而预训练大语言模型提供了规模化描述数据使用案例的潜在途径。

Method: 应用开源LLM Llama 3.1-405B对已知引用特定基因组数据集的文献生成结构化数据使用案例标签，并引入新颖的评估框架来验证方法效果。

Result: 在零样本数据引用分类任务中，基础模型取得了0.674的F1分数，且无需预定义类别。

Conclusion: 结果有前景，但受到数据可用性、提示过拟合、计算基础设施以及负责任性能评估所需成本等障碍的限制。

Abstract: Efforts have increased in recent years to identify associations between
specific datasets and the scientific literature that incorporates them. Knowing
that a given publication cites a given dataset, the next logical step is to
explore how or why that data was used. Advances in recent years with
pretrained, transformer-based large language models (LLMs) offer potential
means for scaling the description of data use cases in the published
literature. This avoids expensive manual labeling and the development of
training datasets for classical machine-learning (ML) systems. In this work we
apply an open-source LLM, Llama 3.1-405B, to generate structured data use case
labels for publications known to incorporate specific genomic datasets. We also
introduce a novel evaluation framework for determining the efficacy of our
methods. Our results demonstrate that the stock model can achieve an F1 score
of .674 on a zero-shot data citation classification task with no previously
defined categories. While promising, our results are qualified by barriers
related to data availability, prompt overfitting, computational infrastructure,
and the expense required to conduct responsible performance evaluation.

</details>


### [42] [Power Constrained Nonstationary Bandits with Habituation and Recovery Dynamics](https://arxiv.org/abs/2511.02944)
*Fengxu Li,Stephanie M. Carpenter,Matthew P. Buman,Yonatan Mintz*

Main category: cs.LG

TL;DR: 本文针对ROGUE多臂老虎机框架，开发了ROGUE-TS算法和概率裁剪程序，在个性化推荐和群体层面学习之间取得平衡，在MRT数据集上实现了更低遗憾并保持高统计功效。


<details>
  <summary>Details</summary>
Motivation: 现有算法在ROGUE框架下可能因过度强调利用而探索不足，限制了群体层面效应的估计能力，这在微随机化试验中尤为重要。

Method: 开发了ROGUE-TS（Thompson Sampling算法），并引入概率裁剪程序来平衡个性化和群体学习，量化了遗憾和最小探索概率之间的权衡。

Result: 在两个MRT数据集上的验证表明，该方法比现有方法获得更低遗憾，并通过裁剪程序保持高统计功效而不显著增加遗憾。

Conclusion: 该框架为设计MRT的研究人员提供了平衡个性化和统计有效性的实用指导，能够可靠检测治疗效果同时考虑个体行为动态。

Abstract: A common challenge for decision makers is selecting actions whose rewards are
unknown and evolve over time based on prior policies. For instance, repeated
use may reduce an action's effectiveness (habituation), while inactivity may
restore it (recovery). These nonstationarities are captured by the Reducing or
Gaining Unknown Efficacy (ROGUE) bandit framework, which models real-world
settings such as behavioral health interventions. While existing algorithms can
compute sublinear regret policies to optimize these settings, they may not
provide sufficient exploration due to overemphasis on exploitation, limiting
the ability to estimate population-level effects. This is a challenge of
particular interest in micro-randomized trials (MRTs) that aid researchers in
developing just-in-time adaptive interventions that have population-level
effects while still providing personalized recommendations to individuals. In
this paper, we first develop ROGUE-TS, a Thompson Sampling algorithm tailored
to the ROGUE framework, and provide theoretical guarantees of sublinear regret.
We then introduce a probability clipping procedure to balance personalization
and population-level learning, with quantified trade-off that balances regret
and minimum exploration probability. Validation on two MRT datasets concerning
physical activity promotion and bipolar disorder treatment shows that our
methods both achieve lower regret than existing approaches and maintain high
statistical power through the clipping procedure without significantly
increasing regret. This enables reliable detection of treatment effects while
accounting for individual behavioral dynamics. For researchers designing MRTs,
our framework offers practical guidance on balancing personalization with
statistical validity.

</details>


### [43] [Digital Twin-Driven Pavement Health Monitoring and Maintenance Optimization Using Graph Neural Networks](https://arxiv.org/abs/2511.02957)
*Mohsin Mahmud Topu,Mahfuz Ahmed Anik,Azmine Toushik Wasi,Md Manjurul Ahsan*

Main category: cs.LG

TL;DR: 提出了一种结合数字孪生和图神经网络的道路健康监测框架，通过图结构建模道路段和空间关系，实现预测性维护和主动干预。


<details>
  <summary>Details</summary>
Motivation: 传统道路管理系统多为被动响应，缺乏实时智能来预防故障和优化维护规划，难以应对复杂的空间依赖性和非线性退化问题。

Method: 将道路段和空间关系建模为图节点和边，利用无人机、传感器和激光雷达实时数据流，采用归纳式图神经网络学习退化模式来预测道路损坏。

Result: 在真实世界数据集上训练，模型R2达到0.3798，优于基线回归器，能有效捕捉非线性退化模式。

Conclusion: 数字孪生与图神经网络的集成提高了预测精度，建立了持续改进的闭环反馈系统，为主动、智能和可持续的道路管理奠定了基础。

Abstract: Pavement infrastructure monitoring is challenged by complex spatial
dependencies, changing environmental conditions, and non-linear deterioration
across road networks. Traditional Pavement Management Systems (PMS) remain
largely reactive, lacking real-time intelligence for failure prevention and
optimal maintenance planning. To address this, we propose a unified Digital
Twin (DT) and Graph Neural Network (GNN) framework for scalable, data-driven
pavement health monitoring and predictive maintenance. Pavement segments and
spatial relations are modeled as graph nodes and edges, while real-time UAV,
sensor, and LiDAR data stream into the DT. The inductive GNN learns
deterioration patterns from graph-structured inputs to forecast distress and
enable proactive interventions. Trained on a real-world-inspired dataset with
segment attributes and dynamic connectivity, our model achieves an R2 of
0.3798, outperforming baseline regressors and effectively capturing non-linear
degradation. We also develop an interactive dashboard and reinforcement
learning module for simulation, visualization, and adaptive maintenance
planning. This DT-GNN integration enhances forecasting precision and
establishes a closed feedback loop for continuous improvement, positioning the
approach as a foundation for proactive, intelligent, and sustainable pavement
management, with future extensions toward real-world deployment, multi-agent
coordination, and smart-city integration.

</details>


### [44] [Inference-Time Personalized Alignment with a Few User Preference Queries](https://arxiv.org/abs/2511.02966)
*Victor-Alexandru Pădurean,Parameswaran Kamalaruban,Nachiket Kotalwar,Alkis Gotovos,Adish Singla*

Main category: cs.LG

TL;DR: UserAlign是一种新颖的推理时个性化对齐方法，通过少量成对响应比较来获取用户偏好，基于逻辑赌博机中的最佳臂识别理论框架，从固定响应池中选择个性化响应。


<details>
  <summary>Details</summary>
Motivation: 现有个性化对齐方法要么需要大量用户偏好查询，要么要求偏好作为文本输入明确指定，存在效率和使用便利性问题。

Method: 基于逻辑赌博机中的最佳臂识别理论框架，将用户反馈视为一致且无噪声的，通过少量成对响应比较快速识别最佳响应。

Result: 在个性化文本和图像生成等多个任务上的实验结果表明，UserAlign在实现个性化对齐方面具有有效性。

Conclusion: UserAlign能够以少量用户查询实现有效的个性化对齐，为生成模型与用户偏好的对齐提供了高效解决方案。

Abstract: We study the problem of aligning a generative model's response with a user's
preferences. Recent works have proposed several different formulations for
personalized alignment; however, they either require a large amount of user
preference queries or require that the preference be explicitly specified as a
text input. In this paper, we propose a novel inference-time personalized
alignment method, UserAlign, that elicits the user's preferences with a few
queries as pairwise response comparisons. In particular, UserAlign builds on
the theoretical framework of best-arm identification in logistic bandits and
selects a personalized response from a fixed pool of the model's generated
responses. The key idea is to consider the user's feedback consistent and
noise-free, and incorporate it into the theoretical framework to identify the
best response quickly. Experimental results across several tasks, involving
personalized text and image generation, showcase the effectiveness of UserAlign
in achieving personalized alignment.

</details>


### [45] [Value of Information-Enhanced Exploration in Bootstrapped DQN](https://arxiv.org/abs/2511.02969)
*Stergios Plataniotis,Charilaos Akasiadis,Georgios Chalkiadakis*

Main category: cs.LG

TL;DR: 将期望信息价值(EVOI)整合到Bootstrapped DQN框架中，通过测量不同网络头之间的意见差异来指导探索，在稀疏奖励的复杂环境中提升深度强化学习的探索效率。


<details>
  <summary>Details</summary>
Motivation: 传统基于随机局部策略噪声的探索策略（如ε-greedy和Boltzmann方法）在高维状态和稀疏奖励环境中难以有效平衡探索与利用，需要更智能的探索机制。

Method: 开发了两种新算法，将期望信息价值整合到Bootstrapped DQN中，利用信息价值估计来测量不同网络头之间的意见差异，并驱动探索朝向最有潜力的区域。

Result: 在复杂稀疏奖励的Atari游戏中实验表明，算法性能得到提升，能更好地利用随机网络初始化产生的不确定性，且无需引入额外超参数。

Conclusion: 基于期望信息价值的探索策略能有效增强深度强化学习在稀疏奖励环境中的探索能力，提供了一种无需额外超参数的智能探索方法。

Abstract: Efficient exploration in deep reinforcement learning remains a fundamental
challenge, especially in environments characterized by high-dimensional states
and sparse rewards. Traditional exploration strategies that rely on random
local policy noise, such as $\epsilon$-greedy and Boltzmann exploration
methods, often struggle to efficiently balance exploration and exploitation. In
this paper, we integrate the notion of (expected) value of information (EVOI)
within the well-known Bootstrapped DQN algorithmic framework, to enhance the
algorithm's deep exploration ability. Specifically, we develop two novel
algorithms that incorporate the expected gain from learning the value of
information into Bootstrapped DQN. Our methods use value of information
estimates to measure the discrepancies of opinions among distinct network
heads, and drive exploration towards areas with the most potential. We evaluate
our algorithms with respect to performance and their ability to exploit
inherent uncertainty arising from random network initialization. Our
experiments in complex, sparse-reward Atari games demonstrate increased
performance, all the while making better use of uncertainty, and, importantly,
without introducing extra hyperparameters.

</details>


### [46] [Heterogeneous Metamaterials Design via Multiscale Neural Implicit Representation](https://arxiv.org/abs/2511.03012)
*Hongrui Chen,Liwei Wang,Levent Burak Kara*

Main category: cs.LG

TL;DR: 提出基于神经网络的双尺度超材料设计框架，通过多尺度神经表示学习连续结构表示，解决异质超材料设计中的兼容性问题。


<details>
  <summary>Details</summary>
Motivation: 传统异质超材料设计方法面临设计空间巨大和相邻单元兼容性要求严格的挑战，现有方法存在边界不连续或依赖固定数据集的问题。

Method: 使用多尺度神经表示网络，输入全局和局部坐标，输出表示多尺度结构的隐式场，通过兼容性损失项确保相邻单元连接性。

Result: 框架能够产生任意高分辨率的超材料设计，实现无限上采样，在力学超材料设计、负泊松比和力学隐身问题上展示有效性。

Conclusion: 该神经网络框架成功解决了异质超材料设计中的兼容性问题，无需预定义数据集，在机器人、生物工程和航空航天领域具有应用潜力。

Abstract: Metamaterials are engineered materials composed of specially designed unit
cells that exhibit extraordinary properties beyond those of natural materials.
Complex engineering tasks often require heterogeneous unit cells to accommodate
spatially varying property requirements. However, designing heterogeneous
metamaterials poses significant challenges due to the enormous design space and
strict compatibility requirements between neighboring cells. Traditional
concurrent multiscale design methods require solving an expensive optimization
problem for each unit cell and often suffer from discontinuities at cell
boundaries. On the other hand, data-driven approaches that assemble structures
from a fixed library of microstructures are limited by the dataset and require
additional post-processing to ensure seamless connections. In this work, we
propose a neural network-based metamaterial design framework that learns a
continuous two-scale representation of the structure, thereby jointly
addressing these challenges. Central to our framework is a multiscale neural
representation in which the neural network takes both global (macroscale) and
local (microscale) coordinates as inputs, outputting an implicit field that
represents multiscale structures with compatible unit cell geometries across
the domain, without the need for a predefined dataset. We use a compatibility
loss term during training to enforce connectivity between adjacent unit cells.
Once trained, the network can produce metamaterial designs at arbitrarily high
resolution, hence enabling infinite upsampling for fabrication or simulation.
We demonstrate the effectiveness of the proposed approach on mechanical
metamaterial design, negative Poisson's ratio, and mechanical cloaking problems
with potential applications in robotics, bioengineering, and aerospace.

</details>


### [47] [Discrete Bayesian Sample Inference for Graph Generation](https://arxiv.org/abs/2511.03015)
*Ole Petersen,Marcel Kollovieh,Marten Lienen,Stephan Günnemann*

Main category: cs.LG

TL;DR: GraphBSI是一种基于贝叶斯样本推理(BSI)的单次图生成模型，通过在分布参数的连续空间中迭代优化图结构的信念来处理离散图数据，在分子和合成图生成任务上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 图结构数据的生成在分子生成、知识图谱和网络分析中很重要，但其离散、无序的特性使得传统生成模型难以处理，因此需要开发新的离散扩散和流匹配模型。

Method: GraphBSI基于贝叶斯样本推理(BSI)，在分布参数的连续空间中迭代优化图结构的信念，而不是直接演化样本。该方法被表述为随机微分方程(SDE)，并推导出通过分数函数近似保持边缘分布的噪声控制SDE族。

Result: 在经验评估中，GraphBSI在分子和合成图生成任务上表现出最先进的性能，在标准基准测试Moses和GuacaMol上优于现有的单次图生成模型。

Conclusion: GraphBSI提供了一种有效处理离散图结构生成的新方法，通过贝叶斯推理框架在连续参数空间中操作，实现了优异的生成性能，并与贝叶斯流网络和扩散模型建立了理论联系。

Abstract: Generating graph-structured data is crucial in applications such as molecular
generation, knowledge graphs, and network analysis. However, their discrete,
unordered nature makes them difficult for traditional generative models,
leading to the rise of discrete diffusion and flow matching models. In this
work, we introduce GraphBSI, a novel one-shot graph generative model based on
Bayesian Sample Inference (BSI). Instead of evolving samples directly, GraphBSI
iteratively refines a belief over graphs in the continuous space of
distribution parameters, naturally handling discrete structures. Further, we
state BSI as a stochastic differential equation (SDE) and derive a
noise-controlled family of SDEs that preserves the marginal distributions via
an approximation of the score function. Our theoretical analysis further
reveals the connection to Bayesian Flow Networks and Diffusion models. Finally,
in our empirical evaluation, we demonstrate state-of-the-art performance on
molecular and synthetic graph generation, outperforming existing one-shot graph
generative models on the standard benchmarks Moses and GuacaMol.

</details>


### [48] [Adaptive-Sensorless Monitoring of Shipping Containers](https://arxiv.org/abs/2511.03022)
*Lingqing Shen,Chi Heem Wong,Misaki Mito,Arnab Chakrabarti*

Main category: cs.LG

TL;DR: 提出了一种自适应无传感器监测方法，通过残差校正框架修正无传感器模型中的系统性偏差，在温度预测上MAE从2.43°C提升到2.24-2.31°C，湿度预测MAE从7.99%提升到5.72-7.09%。


<details>
  <summary>Details</summary>
Motivation: 传统无传感器监测方法不包含遥测信息且无法校正系统性误差，导致预测结果与实时数据差异显著，给用户带来困惑。

Method: 引入残差校正方法，这是一个通用框架，在观察到实时遥测数据后校正无传感器模型中的系统性偏差，称为自适应无传感器监测。

Result: 在348万数据点上训练和评估，相比基线无传感器模型，温度MAE从2.43°C提升到2.24-2.31°C，湿度MAE从7.99%提升到5.72-7.09%；温度RMSE从3.38°C提升到3.19-3.26°C，湿度RMSE从10.0%提升到7.70-9.12%。

Conclusion: 自适应无传感器模型能够实现更准确的货物监测、早期风险检测，并减少全球航运中对完全连接的依赖。

Abstract: Monitoring the internal temperature and humidity of shipping containers is
essential to preventing quality degradation during cargo transportation.
Sensorless monitoring -- machine learning models that predict the internal
conditions of the containers using exogenous factors -- shows promise as an
alternative to monitoring using sensors. However, it does not incorporate
telemetry information and correct for systematic errors, causing the
predictions to differ significantly from the live data and confusing the users.
In this paper, we introduce the residual correction method, a general framework
for correcting for systematic biases in sensorless models after observing live
telemetry data. We call this class of models ``adaptive-sensorless''
monitoring. We train and evaluate adaptive-sensorless models on the 3.48
million data points -- the largest dataset of container sensor readings ever
used in academic research -- and show that they produce consistent improvements
over the baseline sensorless models. When evaluated on the holdout set of the
simulated data, they achieve average mean absolute errors (MAEs) of 2.24 $\sim$
2.31$^\circ$C (vs 2.43$^\circ$C by sensorless) for temperature and 5.72 $\sim$
7.09% for relative humidity (vs 7.99% by sensorless) and average root
mean-squared errors (RMSEs) of 3.19 $\sim$ 3.26$^\circ$C for temperature (vs
3.38$^\circ$C by sensorless) and 7.70 $\sim$ 9.12% for relative humidity (vs
10.0% by sensorless). Adaptive-sensorless models enable more accurate cargo
monitoring, early risk detection, and less dependence on full connectivity in
global shipping.

</details>


### [49] [Leveraging Discrete Function Decomposability for Scientific Design](https://arxiv.org/abs/2511.03032)
*James C. Bowden,Sergey Levine,Jennifer Listgarten*

Main category: cs.LG

TL;DR: 提出了一种新的分布优化算法DADO，能够利用设计变量的可分解性结构，通过图消息传递在因子间协调优化，提高离散设计空间的搜索效率。


<details>
  <summary>Details</summary>
Motivation: 在AI驱动的科学工程中，需要在离散设计空间（如蛋白质序列）中根据用户指定属性进行设计。现有分布优化算法无法利用属性预测器的可分解性结构，导致组合优化困难。

Method: 使用软因子化的"搜索分布"作为学习生成模型，通过图消息传递在连接因子间协调优化，利用设计变量的junction tree定义的任何可分解性。

Result: DADO算法能够更有效地在离散设计空间中进行优化，特别是在属性预测器可分解的情况下。

Conclusion: DADO算法通过利用设计变量的可分解性结构，为离散设计空间的分布优化提供了更高效的解决方案。

Abstract: In the era of AI-driven science and engineering, we often want to design
discrete objects in silico according to user-specified properties. For example,
we may wish to design a protein to bind its target, arrange components within a
circuit to minimize latency, or find materials with certain properties. Given a
property predictive model, in silico design typically involves training a
generative model over the design space (e.g., protein sequence space) to
concentrate on designs with the desired properties. Distributional optimization
-- which can be formalized as an estimation of distribution algorithm or as
reinforcement learning policy optimization -- finds the generative model that
maximizes an objective function in expectation. Optimizing a distribution over
discrete-valued designs is in general challenging because of the combinatorial
nature of the design space. However, many property predictors in scientific
applications are decomposable in the sense that they can be factorized over
design variables in a way that could in principle enable more effective
optimization. For example, amino acids at a catalytic site of a protein may
only loosely interact with amino acids of the rest of the protein to achieve
maximal catalytic activity. Current distributional optimization algorithms are
unable to make use of such decomposability structure. Herein, we propose and
demonstrate use of a new distributional optimization algorithm,
Decomposition-Aware Distributional Optimization (DADO), that can leverage any
decomposability defined by a junction tree on the design variables, to make
optimization more efficient. At its core, DADO employs a soft-factorized
"search distribution" -- a learned generative model -- for efficient navigation
of the search space, invoking graph message-passing to coordinate optimization
across linked factors.

</details>


### [50] [Data-Efficient Realized Volatility Forecasting with Vision Transformers](https://arxiv.org/abs/2511.03046)
*Emi Soroka,Artem Arzyn*

Main category: cs.LG

TL;DR: 使用Vision Transformer (ViT)架构预测资产未来30天的已实现波动率，探索将图像识别中的transformer模型应用于期权数据。


<details>
  <summary>Details</summary>
Motivation: 金融机器学习研究表明深度学习能够学习高度非线性关系，在金融预测中表现优于简单方法。虽然transformer架构在金融时间序列预测中显示出潜力，但在期权数据中的应用仍较少探索。

Method: 训练Vision Transformer (ViT)架构，从单日的隐含波动率表面（增强日期信息）预测资产未来30天的已实现波动率。

Result: ViT能够从隐含波动率表面学习季节性模式和非线性特征，表明这是一个有前景的模型开发方向。

Conclusion: 将ViT应用于期权数据是可行的，能够有效学习复杂的金融模式，为期权数据建模提供了新的研究方向。

Abstract: Recent work in financial machine learning has shown the virtue of complexity:
the phenomenon by which deep learning methods capable of learning highly
nonlinear relationships outperform simpler approaches in financial forecasting.
While transformer architectures like Informer have shown promise for financial
time series forecasting, the application of transformer models for options data
remains largely unexplored. We conduct preliminary studies towards the
development of a transformer model for options data by training the Vision
Transformer (ViT) architecture, typically used in modern image recognition and
classification systems, to predict the realized volatility of an asset over the
next 30 days from its implied volatility surface (augmented with date
information) for a single day. We show that the ViT can learn seasonal patterns
and nonlinear features from the IV surface, suggesting a promising direction
for model development.

</details>


### [51] [Unsupervised Evaluation of Multi-Turn Objective-Driven Interactions](https://arxiv.org/abs/2511.03047)
*Emi Soroka,Tanmay Chopra,Krish Desai,Sanjay Lall*

Main category: cs.LG

TL;DR: 提出了首个用于目标驱动交互的无监督评估指标，利用未标注交互数据的统计特性和微调LLM来适应分布变化，无需人工标注即可评估用户目标、目标完成度和LLM不确定性。


<details>
  <summary>Details</summary>
Motivation: 企业应用中LLM代理与人类的目标驱动交互系统难以评估：数据复杂且无标注、人工标注不具可扩展性、自定义指标无法检测未知错误、LLM评估结果不可靠。

Method: 利用未标注交互数据的统计特性，通过微调LLM适应分布变化，开发了用户目标标注、目标完成度测量和LLM不确定性量化的无监督指标。

Result: 在开放领域和任务特定的交互数据上验证了方法的有效性，能够在不依赖人工生成理想响应的情况下进行可靠评估。

Conclusion: 提出的无监督评估指标为LLM在目标驱动交互系统中的性能评估提供了可行的解决方案，解决了传统评估方法的局限性。

Abstract: Large language models (LLMs) have seen increasing popularity in enterprise
applications where AI agents and humans engage in objective-driven
interactions. However, these systems are difficult to evaluate: data may be
complex and unlabeled; human annotation is often impractical at scale; custom
metrics can monitor for specific errors, but not previously-undetected ones;
and LLM judges can produce unreliable results. We introduce the first set of
unsupervised metrics for objective-driven interactions, leveraging statistical
properties of unlabeled interaction data and using fine-tuned LLMs to adapt to
distributional shifts. We develop metrics for labeling user goals, measuring
goal completion, and quantifying LLM uncertainty without grounding evaluations
in human-generated ideal responses. Our approach is validated on open-domain
and task-specific interaction data.

</details>


### [52] [The Curved Spacetime of Transformer Architectures](https://arxiv.org/abs/2511.03060)
*Riccardo Di Sipio,Jairo Diaz-Rodriguez,Luis Serrano*

Main category: cs.LG

TL;DR: 该论文提出了一个将Transformer语言模型与广义相对论类比的几何框架，将注意力机制视为离散连接，在表示空间中实现并行传输，并通过实验验证了嵌入空间曲率的存在和影响。


<details>
  <summary>Details</summary>
Motivation: 旨在从几何角度理解Transformer语言模型的工作原理，特别是注意力机制如何通过表示空间的曲率影响token嵌入的演化轨迹。

Method: 设计了三类实验：(1)可视化整个段落的曲率景观；(2)通过模拟验证尖锐/平坦角度和长度-弦长比异常；(3)受爱因斯坦日食实验启发，通过控制上下文编辑探测嵌入轨迹的偏转。

Result: 实验证实了注意力诱导的曲率存在：局部转向角度在token和层间变化，尖锐/平坦角度和长度-弦长比的异常无法用维度或偶然性解释，上下文编辑导致可测量的、意义一致的嵌入轨迹弯曲。

Conclusion: Transformer语言模型确实在弯曲的表示空间中运行，注意力机制通过离散连接实现并行传输，token嵌入的演化轨迹受到嵌入空间曲率的影响而弯曲和重新定向。

Abstract: We present a geometric framework for understanding Transformer-based language
models, drawing an explicit analogy to General Relativity. Queries and keys
induce an effective metric on representation space, and attention acts as a
discrete connection that implements parallel transport of value vectors across
tokens. Stacked layers provide discrete time-slices through which token
representations evolve on this curved manifold, while backpropagation plays the
role of a least-action principle that shapes loss-minimizing trajectories in
parameter space. If this analogy is correct, token embeddings should not
traverse straight paths in feature space; instead, their layer-wise steps
should bend and reorient as interactions mediated by embedding space curvature.
To test this prediction, we design experiments that expose both the presence
and the consequences of curvature: (i) we visualize a curvature landscape for a
full paragraph, revealing how local turning angles vary across tokens and
layers; (ii) we show through simulations that excess counts of sharp/flat
angles and longer length-to-chord ratios are not explainable by dimensionality
or chance; and (iii) inspired by Einstein's eclipse experiment, we probe
deflection under controlled context edits, demonstrating measurable,
meaning-consistent bends in embedding trajectories that confirm
attention-induced curvature.

</details>


### [53] [Homomorphism distortion: A metric to distinguish them all and in the latent space bind them](https://arxiv.org/abs/2511.03068)
*Martin Carrasco,Olga Zaghen,Erik Bekkers,Bastian Rieck*

Main category: cs.LG

TL;DR: 本文提出了一种新的图相似性度量方法——图同态失真，能够完全表征图结构并作为完整的图嵌入方法，通过采样高效计算，并在实验中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 长期以来，图神经网络的表达能力仅通过组合性质来衡量，本文旨在提供一种基于原则的方法来度量带顶点属性图之间的相似性。

Method: 提出图同态失真度量方法，通过采样来高效计算该度量，以避免图规范化问题，并证明该度量可以转化为度量空间。

Result: 图同态失真能够完全区分BREC数据集中4-WL无法区分的图，在ZINC-12k数据集上优于先前基于同态的方法。

Conclusion: 这些理论和实证结果为未来图表征研究开辟了新途径，将图论传统扩展到新领域。

Abstract: For far too long, expressivity of graph neural networks has been measured
\emph{only} in terms of combinatorial properties. In this work we stray away
from this tradition and provide a principled way to measure similarity between
vertex attributed graphs. We denote this measure as the \emph{graph
homomorphism distortion}. We show it can \emph{completely characterize} graphs
and thus is also a \emph{complete graph embedding}. However, somewhere along
the road, we run into the graph canonization problem. To circumvent this
obstacle, we devise to efficiently compute this measure via sampling, which in
expectation ensures \emph{completeness}. Additionally, we also discovered that
we can obtain a metric from this measure. We validate our claims empirically
and find that the \emph{graph homomorphism distortion}: (1.) fully
distinguishes the \texttt{BREC} dataset with up to $4$-WL non-distinguishable
graphs, and (2.) \emph{outperforms} previous methods inspired in homomorphisms
under the \texttt{ZINC-12k} dataset.
  These theoretical results, (and their empirical validation), pave the way for
future characterization of graphs, extending the graph theoretic tradition to
new frontiers.

</details>


### [54] [Online Learning to Rank under Corruption: A Robust Cascading Bandits Approach](https://arxiv.org/abs/2511.03074)
*Fatemeh Ghaffari,Siddarth Sitaraman,Xutong Liu,Xuchuang Wang,Mohammad Hajiesmaili*

Main category: cs.LG

TL;DR: MSUCB算法通过中位数均值估计器实现鲁棒的在线学习排序，在无污染时保持最优对数遗憾，在存在点击欺诈等污染时仅增加与总污染量相关的附加遗憾项。


<details>
  <summary>Details</summary>
Motivation: 在线学习排序系统易受点击欺诈等污染攻击，导致学习过程被误导和用户体验下降，需要开发鲁棒算法来应对这种挑战。

Method: 提出MSUCB算法，首次在带污染的bandit设置中应用新颖的中位数均值估计器，该估计器在无污染时表现如标准均值，在污染时通过中位数步骤过滤异常值和污染样本。

Result: 在真实数据集上的综合实验表明，该方法始终优于先前方法，对两种最先进方法的遗憾改进分别达到97.35%和91.60%。

Conclusion: MSUCB算法在无污染时实现最优对数遗憾，在污染情况下仅以与总污染量相关的附加项为代价，展现出强大的鲁棒性和优越性能。

Abstract: Online learning to rank (OLTR) studies how to recommend a short ranked list
of items from a large pool and improves future rankings based on user clicks.
This setting is commonly modeled as cascading bandits, where the objective is
to maximize the likelihood that the user clicks on at least one of the
presented items across as many timesteps as possible. However, such systems are
vulnerable to click fraud and other manipulations (i.e., corruption), where
bots or paid click farms inject corrupted feedback that misleads the learning
process and degrades user experience. In this paper, we propose MSUCB, a robust
algorithm that incorporates a novel mean-of-medians estimator, which to our
knowledge is applied to bandits with corruption setting for the first time.
This estimator behaves like a standard mean in the absence of corruption, so no
cost is paid for robustness. Under corruption, the median step filters out
outliers and corrupted samples, keeping the estimate close to its true value.
Updating this estimate at every round further accelerates empirical convergence
in experiments. Hence, MSUCB achieves optimal logarithmic regret in the absence
of corruption and degrades gracefully under corruptions, with regret increasing
only by an additive term tied to the total corruption. Comprehensive and
extensive experiments on real-world datasets further demonstrate that our
approach consistently outperforms prior methods while maintaining strong
robustness. In particular, it achieves a \(97.35\%\) and a \(91.60\%\) regret
improvement over two state-of-the-art methods.

</details>


### [55] [Sparse, self-organizing ensembles of local kernels detect rare statistical anomalies](https://arxiv.org/abs/2511.03095)
*Gaia Grosso,Sai Sumedh R. Hindupur,Thomas Fel,Samuel Bright-Thonney,Philip Harris,Demba Ba*

Main category: cs.LG

TL;DR: 提出了SparKer方法，使用稀疏高斯核集合在Neyman-Pearson框架下建模异常检测的似然比，实现了高效、可解释的异常检测。


<details>
  <summary>Details</summary>
Motivation: 现代AI提取的数据表示缺乏统计特性控制，导致异常检测方法失效，弱信号或罕见信号难以在正常数据的规律性中被发现。

Method: 基于稀疏性、局部性和竞争性原则，提出自组织局部核方法SparKer，使用稀疏高斯核集合在半监督Neyman-Pearson框架下建模似然比。

Result: 仅需少量核就能在数千维表示空间中识别统计显著的异常位置，证明了方法的可解释性、效率和可扩展性。

Conclusion: SparKer方法通过结构化的核设计原则，有效解决了高维表示空间中的异常检测问题，在科学发现和实际应用中表现出色。

Abstract: Modern artificial intelligence has revolutionized our ability to extract rich
and versatile data representations across scientific disciplines. Yet, the
statistical properties of these representations remain poorly controlled,
causing misspecified anomaly detection (AD) methods to falter. Weak or rare
signals can remain hidden within the apparent regularity of normal data,
creating a gap in our ability to detect and interpret anomalies. We examine
this gap and identify a set of structural desiderata for detection methods
operating under minimal prior information: sparsity, to enforce parsimony;
locality, to preserve geometric sensitivity; and competition, to promote
efficient allocation of model capacity. These principles define a class of
self-organizing local kernels that adaptively partition the representation
space around regions of statistical imbalance. As an instantiation of these
principles, we introduce SparKer, a sparse ensemble of Gaussian kernels trained
within a semi-supervised Neyman--Pearson framework to locally model the
likelihood ratio between a sample that may contain anomalies and a nominal,
anomaly-free reference. We provide theoretical insights into the mechanisms
that drive detection and self-organization in the proposed model, and
demonstrate the effectiveness of this approach on realistic high-dimensional
problems of scientific discovery, open-world novelty detection, intrusion
detection, and generative-model validation. Our applications span both the
natural- and computer-science domains. We demonstrate that ensembles containing
only a handful of kernels can identify statistically significant anomalous
locations within representation spaces of thousands of dimensions, underscoring
both the interpretability, efficiency and scalability of the proposed approach.

</details>


### [56] [Scaling Multi-Agent Environment Co-Design with Diffusion Models](https://arxiv.org/abs/2511.03100)
*Hao Xiang Li,Michael Amir,Amanda Prorok*

Main category: cs.LG

TL;DR: 提出了DiCoDe框架，通过Projected Universal Guidance和critic蒸馏机制，解决了agent-environment协同设计中的可扩展性和样本效率问题，在多个基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的协同设计方法难以扩展到高维环境设计空间，且在联合优化中面临样本效率低下的问题，限制了在实际场景中的应用。

Method: DiCoDe框架包含两个核心创新：Projected Universal Guidance采样技术，用于探索满足硬约束的奖励最大化环境分布；critic蒸馏机制，确保扩散模型能够适应不断演化的agent策略。

Result: 在仓库自动化、多智能体路径规划和风电场优化等基准测试中，DiCoDe方法始终优于现有技术，例如在仓库设置中实现了39%的奖励提升，同时减少了66%的模拟样本需求。

Conclusion: DiCoDe为agent-environment协同设计设立了新标准，是实现现实世界协同设计收益的重要一步。

Abstract: The agent-environment co-design paradigm jointly optimises agent policies and
environment configurations in search of improved system performance. With
application domains ranging from warehouse logistics to windfarm management,
co-design promises to fundamentally change how we deploy multi-agent systems.
However, current co-design methods struggle to scale. They collapse under
high-dimensional environment design spaces and suffer from sample inefficiency
when addressing moving targets inherent to joint optimisation. We address these
challenges by developing Diffusion Co-Design (DiCoDe), a scalable and
sample-efficient co-design framework pushing co-design towards practically
relevant settings. DiCoDe incorporates two core innovations. First, we
introduce Projected Universal Guidance (PUG), a sampling technique that enables
DiCoDe to explore a distribution of reward-maximising environments while
satisfying hard constraints such as spatial separation between obstacles.
Second, we devise a critic distillation mechanism to share knowledge from the
reinforcement learning critic, ensuring that the guided diffusion model adapts
to evolving agent policies using a dense and up-to-date learning signal.
Together, these improvements lead to superior environment-policy pairs when
validated on challenging multi-agent environment co-design benchmarks including
warehouse automation, multi-agent pathfinding and wind farm optimisation. Our
method consistently exceeds the state-of-the-art, achieving, for example, 39%
higher rewards in the warehouse setting with 66% fewer simulation samples. This
sets a new standard in agent-environment co-design, and is a stepping stone
towards reaping the rewards of co-design in real world domains.

</details>


### [57] [An Efficient Classification Model for Cyber Text](https://arxiv.org/abs/2511.03107)
*Md Sakhawat Hossen,Md. Zashid Iqbal Borshon,A. S. M. Badrudduza*

Main category: cs.LG

TL;DR: 提出CTF-IDF算法和改进的IRLBA降维方法，结合传统机器学习技术，在文本分析中实现比深度学习方法更高效、更快速且计算资源消耗更少的解决方案，同时保持可接受的准确率。


<details>
  <summary>Details</summary>
Motivation: 深度学习在文本分析领域的广泛应用导致计算资源和能耗急剧增加，产生严重的碳足迹问题。需要寻找更环保高效的替代方案。

Method: 改进传统的TF-IDF算法为CTF-IDF，结合IRLBA算法进行降维处理，构建基于传统机器学习技术的文本分析流程。

Result: 实验结果显示，与传统深度学习方法相比，该方法在时间复杂度和模型准确率方面都有显著提升，同时大幅降低了计算资源消耗和碳足迹。

Conclusion: 传统机器学习方法结合CTF-IDF和IRLBA算法可以在文本分析中提供比深度学习方法更环保高效的解决方案，仅需在准确率上做出微小妥协。

Abstract: The uprising of deep learning methodology and practice in recent years has
brought about a severe consequence of increasing carbon footprint due to the
insatiable demand for computational resources and power. The field of text
analytics also experienced a massive transformation in this trend of
monopolizing methodology. In this paper, the original TF-IDF algorithm has been
modified, and Clement Term Frequency-Inverse Document Frequency (CTF-IDF) has
been proposed for data preprocessing. This paper primarily discusses the
effectiveness of classical machine learning techniques in text analytics with
CTF-IDF and a faster IRLBA algorithm for dimensionality reduction. The
introduction of both of these techniques in the conventional text analytics
pipeline ensures a more efficient, faster, and less computationally intensive
application when compared with deep learning methodology regarding carbon
footprint, with minor compromise in accuracy. The experimental results also
exhibit a manifold of reduction in time complexity and improvement of model
accuracy for the classical machine learning methods discussed further in this
paper.

</details>


### [58] [Towards Scalable Backpropagation-Free Gradient Estimation](https://arxiv.org/abs/2511.03110)
*Daniel Wang,Evan Markou,Dylan Campbell*

Main category: cs.LG

TL;DR: 提出了一种新的梯度估计方法，通过操纵上游雅可比矩阵来减少偏差和方差，在更宽的网络中表现更好


<details>
  <summary>Details</summary>
Motivation: 反向传播需要两次前向传播和存储中间激活值，现有前向模式自动微分方法由于高方差难以扩展到大型网络，且缓解方法会引入显著偏差

Method: 通过操纵上游雅可比矩阵计算猜测方向，减少梯度估计的偏差和方差

Result: 该方法显示出有希望的结果，随着网络宽度增加性能更好

Conclusion: 该方法通过分析偏差和方差及其与神经网络梯度低维结构的联系来理解，具有扩展到更大网络的潜力

Abstract: While backpropagation--reverse-mode automatic differentiation--has been
extraordinarily successful in deep learning, it requires two passes (forward
and backward) through the neural network and the storage of intermediate
activations. Existing gradient estimation methods that instead use forward-mode
automatic differentiation struggle to scale beyond small networks due to the
high variance of the estimates. Efforts to mitigate this have so far introduced
significant bias to the estimates, reducing their utility. We introduce a
gradient estimation approach that reduces both bias and variance by
manipulating upstream Jacobian matrices when computing guess directions. It
shows promising results and has the potential to scale to larger networks,
indeed performing better as the network width is increased. Our understanding
of this method is facilitated by analyses of bias and variance, and their
connection to the low-dimensional structure of neural network gradients.

</details>


### [59] [FP-AbDiff: Improving Score-based Antibody Design by Capturing Nonequilibrium Dynamics through the Underlying Fokker-Planck Equation](https://arxiv.org/abs/2511.03113)
*Jiameng Chen,Yida Xiong,Kun Li,Hongzhi Zhang,Xiantao Cai,Wenbin Hu,Jia Wu*

Main category: cs.LG

TL;DR: FP-AbDiff是首个在整个生成轨迹中强制执行Fokker-Planck方程物理学的抗体生成器，通过FPE残差损失确保物理一致性，在RAbD基准测试中创下新纪录。


<details>
  <summary>Details</summary>
Motivation: 现有抗体生成模型存在两个核心挑战：缺乏动力学一致性导致物理上不可行的结构，以及由于数据稀缺和结构偏差导致的泛化能力差。

Method: 在SE(3)-等变扩散框架中，在CDR几何的混合流形上最小化新颖的FPE残差损失，将局部学习的去噪分数组合成全局一致的概率流，并与深度生物先验协同整合。

Result: 在从头CDR-H3设计中，可变区叠加的均方根偏差为0.99Å，比先前最佳模型AbX提高25%；在更具挑战性的六-CDR协同设计中，全链均方根偏差降低约15%，CDR-H3环的氨基酸回收率达到45.67%。

Conclusion: 通过将生成动力学与物理定律对齐，FP-AbDiff增强了鲁棒性和泛化能力，为物理忠实且功能可行的抗体设计建立了原则性方法。

Abstract: Computational antibody design holds immense promise for therapeutic
discovery, yet existing generative models are fundamentally limited by two core
challenges: (i) a lack of dynamical consistency, which yields physically
implausible structures, and (ii) poor generalization due to data scarcity and
structural bias. We introduce FP-AbDiff, the first antibody generator to
enforce Fokker-Planck Equation (FPE) physics along the entire generative
trajectory. Our method minimizes a novel FPE residual loss over the mixed
manifold of CDR geometries (R^3 x SO(3)), compelling locally-learned denoising
scores to assemble into a globally coherent probability flow. This
physics-informed regularizer is synergistically integrated with deep biological
priors within a state-of-the-art SE(3)-equivariant diffusion framework.
Rigorous evaluation on the RAbD benchmark confirms that FP-AbDiff establishes a
new state-of-the-art. In de novo CDR-H3 design, it achieves a mean Root Mean
Square Deviation of 0.99 {\AA} when superposing on the variable region, a 25%
improvement over the previous state-of-the-art model, AbX, and the highest
reported Contact Amino Acid Recovery of 39.91%. This superiority is underscored
in the more challenging six-CDR co-design task, where our model delivers
consistently superior geometric precision, cutting the average full-chain Root
Mean Square Deviation by ~15%, and crucially, achieves the highest full-chain
Amino Acid Recovery on the functionally dominant CDR-H3 loop (45.67%). By
aligning generative dynamics with physical laws, FP-AbDiff enhances robustness
and generalizability, establishing a principled approach for physically
faithful and functionally viable antibody design.

</details>


### [60] [An Augmentation Overlap Theory of Contrastive Learning](https://arxiv.org/abs/2511.03114)
*Qi Zhang,Yifei Wang,Yisen Wang*

Main category: cs.LG

TL;DR: 本文提出了基于增强重叠理论的对比学习分析框架，推导了更紧致的性能边界，并开发了无需额外模块的无监督表示评估指标。


<details>
  <summary>Details</summary>
Motivation: 自监督对比学习虽然取得了显著成功，但其工作机制仍不清晰，特别是基于条件独立性假设的理论分析存在局限性。

Method: 首先在条件独立性假设下提供最紧致的性能边界，然后放松该假设，提出更实用的增强重叠假设，并推导出渐近闭合的下游性能边界。

Result: 提出的增强重叠理论表明，在激进数据增强下，类内样本的支持集会更重叠，仅对齐正样本就能使对比学习将类内样本聚类在一起。

Conclusion: 从增强重叠角度开发的无监督表示评估指标与下游性能高度一致，几乎不需要额外模块，为对比学习提供了新的理论视角和实用工具。

Abstract: Recently, self-supervised contrastive learning has achieved great success on
various tasks. However, its underlying working mechanism is yet unclear. In
this paper, we first provide the tightest bounds based on the widely adopted
assumption of conditional independence. Further, we relax the conditional
independence assumption to a more practical assumption of augmentation overlap
and derive the asymptotically closed bounds for the downstream performance. Our
proposed augmentation overlap theory hinges on the insight that the support of
different intra-class samples will become more overlapped under aggressive data
augmentations, thus simply aligning the positive samples (augmented views of
the same sample) could make contrastive learning cluster intra-class samples
together. Moreover, from the newly derived augmentation overlap perspective, we
develop an unsupervised metric for the representation evaluation of contrastive
learning, which aligns well with the downstream performance almost without
relying on additional modules. Code is available at
https://github.com/PKU-ML/GARC.

</details>


### [61] [From Insight to Exploit: Leveraging LLM Collaboration for Adaptive Adversarial Text Generation](https://arxiv.org/abs/2511.03128)
*Najrin Sultana,Md Rafi Ur Rashid,Kang Gu,Shagufta Mehnaz*

Main category: cs.LG

TL;DR: 提出了Static Deceptor (StaDec)和Dynamic Deceptor (DyDec)两种攻击框架，通过利用LLM的理解能力生成动态自适应对抗样本，用于系统评估LLM的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当将LLMs应用于敏感任务时，需要全面评估其对对抗性输入的鲁棒性。现有方法依赖外部启发式规则，需要更系统化的评估方法。

Method: 使用自动化的LLM驱动管道生成微妙且自然的对抗样本，保持与原始文本的语义相似性同时有效欺骗目标LLM。攻击框架能够随LLM发展而演进。

Result: 生成的对抗样本在保持语义相似性的同时能有效欺骗LLM，并展现出对攻击者未知模型的强迁移性。

Conclusion: 这项工作为LLM的鲁棒性自我评估提供了系统化方法，代码和数据已开源。

Abstract: LLMs can provide substantial zero-shot performance on diverse tasks using a
simple task prompt, eliminating the need for training or fine-tuning. However,
when applying these models to sensitive tasks, it is crucial to thoroughly
assess their robustness against adversarial inputs. In this work, we introduce
Static Deceptor (StaDec) and Dynamic Deceptor (DyDec), two innovative attack
frameworks designed to systematically generate dynamic and adaptive adversarial
examples by leveraging the understanding of the LLMs. We produce subtle and
natural-looking adversarial inputs that preserve semantic similarity to the
original text while effectively deceiving the target LLM. By utilizing an
automated, LLM-driven pipeline, we eliminate the dependence on external
heuristics. Our attacks evolve with the advancements in LLMs and demonstrate
strong transferability across models unknown to the attacker. Overall, this
work provides a systematic approach for the self-assessment of an LLM's
robustness. We release our code and data at
https://github.com/Shukti042/AdversarialExample.

</details>


### [62] [Test Time Adaptation Using Adaptive Quantile Recalibration](https://arxiv.org/abs/2511.03148)
*Paria Mehrbod,Pedro Vianna,Geraldin Nanfack,Guy Wolf,Eugene Belilovsky*

Main category: cs.LG

TL;DR: 提出了一种名为自适应分位数重校准（AQR）的测试时适应方法，通过通道级分位数对齐来修改预激活分布，无需目标域先验知识或模型重训练，在各种架构和数据集上优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统领域适应方法依赖目标域先验知识或需要模型重训练，在动态或资源受限环境中实用性有限。现有的基于批量归一化统计更新的测试时适应方法无法捕捉复杂的激活分布且受限于特定归一化层。

Method: AQR通过通道级分位数对齐来修改预激活分布，捕捉激活分布的完整形状，适用于BatchNorm、GroupNorm和LayerNorm架构。采用鲁棒的尾部校准策略解决不同批次大小下的分布尾部估计问题，利用训练时计算的源域统计量实现无监督适应。

Result: 在CIFAR-10-C、CIFAR-100-C和ImageNet-C数据集上的实验表明，AQR在各种架构和设置下实现了鲁棒的适应性能，优于现有的测试时适应基线方法。

Conclusion: AQR在动态和不可预测数据分布的实际部署场景中具有重要应用潜力，能够实现无需重训练的无监督领域适应。

Abstract: Domain adaptation is a key strategy for enhancing the generalizability of
deep learning models in real-world scenarios, where test distributions often
diverge significantly from the training domain. However, conventional
approaches typically rely on prior knowledge of the target domain or require
model retraining, limiting their practicality in dynamic or
resource-constrained environments. Recent test-time adaptation methods based on
batch normalization statistic updates allow for unsupervised adaptation, but
they often fail to capture complex activation distributions and are constrained
to specific normalization layers. We propose Adaptive Quantile Recalibration
(AQR), a test-time adaptation technique that modifies pre-activation
distributions by aligning quantiles on a channel-wise basis. AQR captures the
full shape of activation distributions and generalizes across architectures
employing BatchNorm, GroupNorm, or LayerNorm. To address the challenge of
estimating distribution tails under varying batch sizes, AQR incorporates a
robust tail calibration strategy that improves stability and precision. Our
method leverages source-domain statistics computed at training time, enabling
unsupervised adaptation without retraining models. Experiments on CIFAR-10-C,
CIFAR-100-C, and ImageNet-C across multiple architectures demonstrate that AQR
achieves robust adaptation across diverse settings, outperforming existing
test-time adaptation baselines. These results highlight AQR's potential for
deployment in real-world scenarios with dynamic and unpredictable data
distributions.

</details>


### [63] [Forecast2Anomaly (F2A): Adapting Multivariate Time Series Foundation Models for Anomaly Prediction](https://arxiv.org/abs/2511.03149)
*Atif Hassan,Tarun Kumar,Ashish Mishra,Sergey Serebryakov,Satish Kumar Mopur,Phanidhar Koganti,Murthy Chelankuri,Ramanagopal Vogety,Suparna Bhattacharya,Martin Foltin*

Main category: cs.LG

TL;DR: F2A是一个新颖的框架，通过联合预测-异常损失和检索增强生成模块，使时间序列基础模型具备异常预测能力，在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有异常预测方法局限于特定系统，无法适应随时间演变的异常模式。虽然预训练的时间序列基础模型表现出强大的泛化能力，但尚未用于异常预测任务。

Method: 1. 联合预测-异常损失：微调TSFM以准确预测异常时间点的未来信号；2. 检索增强生成模块：检索历史相关时段并基于这些条件进行预测，动态适应推理时的分布变化。

Result: 在16个不同数据集和多个TSFM骨干网络上的广泛实验表明，F2A始终优于最先进的方法。

Conclusion: F2A通过目标微调和动态检索的结合，弥合了稳健TSFM零样本预测与零样本异常预测之间的差距，为实际应用提供了可扩展的零样本异常预测解决方案。

Abstract: Forecasting anomalies (anomaly prediction) in multivariate time series from
different real-world, dynamic, and complex systems is vital for preempting
critical failures, leading to a substantial minimization in operational costs
and human labor. Yet, existing methods are limited to specific systems while
failing to generalize to evolving anomaly patterns over time. In contrast,
pretrained Time Series Foundation Models (TSFMs) have recently demonstrated
strong generalization and zero-shot forecasting capabilities. However, their
potential remains untapped for anomaly prediction, a task fundamentally
different from forecasting normal behavior. Thus, we present Forecast2Anomaly
(F2A), a novel framework that empowers TSFMs with anomaly prediction abilities
through two key innovations. First, we propose a joint forecast-anomaly loss
that fine-tunes TSFMs to accurately forecast future signals even at anomalous
time points. Second, we introduce a Retrieval-Augmented Generation (RAG) module
that retrieves historically relevant horizons and conditions predictions on
them. This component dynamically adapts to distributional shifts at inference
time, enabling F2A to track evolving anomalies without requiring model updates.
By combining targeted fine-tuning with dynamic retrieval, F2A bridges the gap
between robust TSFM zero-shot forecasting and zero-shot anomaly prediction.
Extensive experiments across 16 diverse datasets and multiple TSFM backbones
show that F2A consistently outperforms state-of-the-art methods, offering a
scalable, zero-shot anomaly prediction solution for real-world applications.

</details>


### [64] [UnCLe: Towards Scalable Dynamic Causal Discovery in Non-linear Temporal Systems](https://arxiv.org/abs/2511.03168)
*Tingzhu Bi,Yicheng Pan,Xinrui Jiang,Huize Sun,Meng Ma,Ping Wang*

Main category: cs.LG

TL;DR: 提出UnCLe方法，使用解耦器和重耦合器网络从观测时间序列中发现动态因果关系，能够捕捉随时间演化的因果图。


<details>
  <summary>Details</summary>
Motivation: 现实世界系统常表现出动态因果关系，现有方法主要推断静态因果图，无法准确捕捉随时间演化的关系。

Method: 使用解耦器和重耦合器网络将时间序列解耦为语义表示，通过自回归依赖矩阵学习变量间依赖关系，通过时间扰动引起的预测误差估计动态因果影响。

Result: 在静态因果发现基准测试中超越现有方法，更重要的是能够准确捕捉合成和真实动态系统中的演化时间因果关系。

Conclusion: UnCLe为揭示复杂现象中潜在的时间变化机制提供了一种有前景的方法。

Abstract: Uncovering cause-effect relationships from observational time series is
fundamental to understanding complex systems. While many methods infer static
causal graphs, real-world systems often exhibit dynamic causality-where
relationships evolve over time. Accurately capturing these temporal dynamics
requires time-resolved causal graphs. We propose UnCLe, a novel deep learning
method for scalable dynamic causal discovery. UnCLe employs a pair of Uncoupler
and Recoupler networks to disentangle input time series into semantic
representations and learns inter-variable dependencies via auto-regressive
Dependency Matrices. It estimates dynamic causal influences by analyzing
datapoint-wise prediction errors induced by temporal perturbations. Extensive
experiments demonstrate that UnCLe not only outperforms state-of-the-art
baselines on static causal discovery benchmarks but, more importantly, exhibits
a unique capability to accurately capture and represent evolving temporal
causality in both synthetic and real-world dynamic systems (e.g., human
motion). UnCLe offers a promising approach for revealing the underlying,
time-varying mechanisms of complex phenomena.

</details>


### [65] [Periodic Skill Discovery](https://arxiv.org/abs/2511.03187)
*Jonghae Park,Daesol Cho,Jusuk Lee,Dongseok Shim,Inkyu Jang,H. Jin Kim*

Main category: cs.LG

TL;DR: 提出了PSD框架，通过将状态映射到圆形潜在空间来无监督发现周期性技能，特别适用于机器人运动任务。


<details>
  <summary>Details</summary>
Motivation: 当前无监督技能发现方法忽视了技能的周期性特征，而许多机器人任务（特别是运动任务）需要在不同时间尺度上执行周期性行为。

Method: 训练编码器将状态映射到圆形潜在空间，在潜在表示中自然编码周期性，通过捕捉时间距离来学习具有不同周期的技能。

Result: PSD能够在复杂机器人任务中有效学习具有多样周期的技能，即使基于像素观测也能工作，并在跨栏等下游任务中取得高性能。

Conclusion: PSD框架成功发现了周期性行为，与现有技能发现方法结合可提供更多样化的行为，扩展了智能体的技能库。

Abstract: Unsupervised skill discovery in reinforcement learning (RL) aims to learn
diverse behaviors without relying on external rewards. However, current methods
often overlook the periodic nature of learned skills, focusing instead on
increasing the mutual dependence between states and skills or maximizing the
distance traveled in latent space. Considering that many robotic tasks --
particularly those involving locomotion -- require periodic behaviors across
varying timescales, the ability to discover diverse periodic skills is
essential. Motivated by this, we propose Periodic Skill Discovery (PSD), a
framework that discovers periodic behaviors in an unsupervised manner. The key
idea of PSD is to train an encoder that maps states to a circular latent space,
thereby naturally encoding periodicity in the latent representation. By
capturing temporal distance, PSD can effectively learn skills with diverse
periods in complex robotic tasks, even with pixel-based observations. We
further show that these learned skills achieve high performance on downstream
tasks such as hurdling. Moreover, integrating PSD with an existing skill
discovery method offers more diverse behaviors, thus broadening the agent's
repertoire. Our code and demos are available at
https://jonghaepark.github.io/psd/

</details>


### [66] [Efficient Linear Attention for Multivariate Time Series Modeling via Entropy Equality](https://arxiv.org/abs/2511.03190)
*Mingtao Zhang,Guoli Yang,Zhanxing Zhu,Mengzhu Wang,Xiaoying Bai*

Main category: cs.LG

TL;DR: 提出了一种基于熵的线性注意力机制，通过理论证明熵值与分布结构相似性的关系，实现了线性复杂度的注意力计算，在时空时间序列建模中取得了竞争性或更优的性能。


<details>
  <summary>Details</summary>
Motivation: 传统注意力机制因二次计算复杂度而难以扩展到长序列，限制了其在时间序列建模等应用中的实用性。

Method: 基于熵理论开发线性注意力机制，利用熵作为严格凹函数的性质，通过线性复杂度算法近似计算点积分布熵值，实现基于熵相等的注意力计算。

Result: 在四个时空数据集上的实验表明，该方法在保持竞争性或更优预测性能的同时，显著减少了内存使用和计算时间。

Conclusion: 注意力机制在时空时间序列建模中的有效性可能主要源于获得适度且平衡的权重分布，而非softmax的非线性特性，线性注意力机制为此提供了高效实现方案。

Abstract: Attention mechanisms have been extensively employed in various applications,
including time series modeling, owing to their capacity to capture intricate
dependencies; however, their utility is often constrained by quadratic
computational complexity, which impedes scalability for long sequences. In this
work, we propose a novel linear attention mechanism designed to overcome these
limitations. Our approach is grounded in a theoretical demonstration that
entropy, as a strictly concave function on the probability simplex, implies
that distributions with aligned probability rankings and similar entropy values
exhibit structural resemblance. Building on this insight, we develop an
efficient approximation algorithm that computes the entropy of
dot-product-derived distributions with only linear complexity, enabling the
implementation of a linear attention mechanism based on entropy equality.
Through rigorous analysis, we reveal that the effectiveness of attention in
spatio-temporal time series modeling may not primarily stem from the
non-linearity of softmax but rather from the attainment of a moderate and
well-balanced weight distribution. Extensive experiments on four
spatio-temporal datasets validate our method, demonstrating competitive or
superior forecasting performance while achieving substantial reductions in both
memory usage and computational time.

</details>


### [67] [Cross-Modal Alignment via Variational Copula Modelling](https://arxiv.org/abs/2511.03196)
*Feng Wu,Tsai Hor Chan,Fuying Wang,Guosheng Yin,Lequan Yu*

Main category: cs.LG

TL;DR: 提出了一种基于copula的多模态学习框架，通过建模不同模态的联合分布来捕捉复杂交互，能够为缺失模态生成准确表示。


<details>
  <summary>Details</summary>
Motivation: 现实应用中存在多种数据模态，需要开发多模态学习方法。现有方法主要依赖拼接或Kronecker积，过于简化模态间交互结构，需要建模更复杂的交互。

Method: 提出copula驱动的多模态学习框架，假设每个模态服从高斯混合分布，在联合分布上应用copula模型，将copula解释为有效对齐模态边际分布的工具。

Result: 在公开MIMIC数据集上的广泛实验表明，该模型优于其他竞争方法。

Conclusion: copula框架能够有效学习多模态的联合分布，捕捉复杂交互，并为缺失模态生成准确表示。

Abstract: Various data modalities are common in real-world applications (e.g.,
electronic health records, medical images and clinical notes in healthcare). It
is essential to develop multimodal learning methods to aggregate various
information from multiple modalities. The main challenge is how to
appropriately align and fuse the representations of different modalities into a
joint distribution. Existing methods mainly rely on concatenation or the
Kronecker product, oversimplifying the interaction structure between modalities
and indicating a need to model more complex interactions. Additionally, the
joint distribution of latent representations with higher-order interactions is
underexplored. Copula is a powerful statistical structure for modelling the
interactions among variables, as it naturally bridges the joint distribution
and marginal distributions of multiple variables. We propose a novel
copula-driven multimodal learning framework, which focuses on learning the
joint distribution of various modalities to capture the complex interactions
among them. The key idea is to interpret the copula model as a tool to align
the marginal distributions of the modalities efficiently. By assuming a
Gaussian mixture distribution for each modality and a copula model on the joint
distribution, our model can generate accurate representations for missing
modalities. Extensive experiments on public MIMIC datasets demonstrate the
superior performance of our model over other competitors. The code is available
at https://github.com/HKU-MedAI/CMCM.

</details>


### [68] [A Probabilistic U-Net Approach to Downscaling Climate Simulations](https://arxiv.org/abs/2511.03197)
*Maryam Alipourhajiagha,Pierre-Louis Lemaire,Youssef Diouane,Julie Carreau*

Main category: cs.LG

TL;DR: 本文采用概率U-Net进行统计降尺度，结合确定性U-Net主干和变分潜在空间来捕捉随机不确定性，评估了四种训练目标在降尺度降水和温度数据中的表现。


<details>
  <summary>Details</summary>
Motivation: 气候模型受限于计算成本，通常产生粗空间分辨率的输出，而许多气候变化影响研究需要更精细的尺度，统计降尺度方法可以弥补这一差距。

Method: 使用概率U-Net架构，结合确定性U-Net主干和变分潜在空间，评估了afCRPS和WMSE-MS-SSIM两种训练目标在三种设置下的表现，用于从16倍粗分辨率降尺度降水和温度数据。

Result: WMSE-MS-SSIM在某些设置下对极端值表现良好，而afCRPS在跨尺度的空间变异性捕捉方面表现更优。

Conclusion: 不同的训练目标在统计降尺度任务中各有优势，需要根据具体应用需求选择合适的损失函数。

Abstract: Climate models are limited by heavy computational costs, often producing
outputs at coarse spatial resolutions, while many climate change impact studies
require finer scales. Statistical downscaling bridges this gap, and we adapt
the probabilistic U-Net for this task, combining a deterministic U-Net backbone
with a variational latent space to capture aleatoric uncertainty. We evaluate
four training objectives, afCRPS and WMSE-MS-SSIM with three settings for
downscaling precipitation and temperature from $16\times$ coarser resolution.
Our main finding is that WMSE-MS-SSIM performs well for extremes under certain
settings, whereas afCRPS better captures spatial variability across scales.

</details>


### [69] [A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies](https://arxiv.org/abs/2511.03201)
*Hassan Wasswa,Hussein Abbass,Timothy Lynar*

Main category: cs.LG

TL;DR: 本研究提出了一种基于VAE-MLP的轻量级物联网僵尸网络检测框架，通过变分自编码器提取8维潜在向量，并系统评估了两种量化策略(QAT和PTQ)在检测性能、存储效率和推理延迟方面的影响。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习检测方法计算量大，难以部署在资源受限的物联网设备上，需要开发轻量级检测模型。

Method: 使用预训练VAE编码器从高维训练数据中提取8维潜在向量，训练MLP分类器，然后系统评估QAT和PTQ两种量化策略。

Result: PTQ在检测精度上只有轻微下降，实现了6倍加速和21倍压缩；QAT精度下降更明显，但实现了3倍加速和24倍压缩。

Conclusion: 量化技术为设备级物联网僵尸网络检测提供了实用解决方案，特别是PTQ策略在保持检测性能的同时显著提升了效率。

Abstract: In an effort to counter the increasing IoT botnet-based attacks,
state-of-the-art deep learning methods have been proposed and have achieved
impressive detection accuracy. However, their computational intensity restricts
deployment on resource-constrained IoT devices, creating a critical need for
lightweight detection models. A common solution to this challenge is model
compression via quantization. This study proposes a VAE-MLP model framework
where an MLP-based classifier is trained on 8-dimensional latent vectors
derived from the high-dimensional train data using the encoder component of a
pretrained variational autoencoder (VAE). Two widely used quantization
strategies--Quantization-Aware Training (QAT) and Post-Training Quantization
(PTQ)--are then systematically evaluated in terms of their impact on detection
performance, storage efficiency, and inference latency using two benchmark IoT
botnet datasets--N-BaIoT and CICIoT2022. The results revealed that, with
respect to detection accuracy, the QAT strategy experienced a more noticeable
decline,whereas PTQ incurred only a marginal reduction compared to the original
unquantized model. Furthermore, PTQ yielded a 6x speedup and 21x reduction in
size, while QAT achieved a 3x speedup and 24x compression, demonstrating the
practicality of quantization for device-level IoT botnet detection.

</details>


### [70] [Incorporating Quality of Life in Climate Adaptation Planning via Reinforcement Learning](https://arxiv.org/abs/2511.03238)
*Miguel Costa,Arthur Vandervoort,Martin Drews,Karyn Morrissey,Francisco C. Pereira*

Main category: cs.LG

TL;DR: 使用强化学习识别气候适应路径，以提升城市长期生活质量。结合降雨预测、洪水、交通可达性和生活质量指数的综合评估模型，结果表明该方法优于现实规划策略。


<details>
  <summary>Details</summary>
Motivation: 气候变化导致城市洪水频发，影响生活质量。政策制定者需要应对气候变化不确定性和城市洪水复杂性，强化学习有望解决这类复杂动态问题。

Method: 使用强化学习结合综合评估模型，整合降雨预测模型、洪水模型、交通可达性模型和生活质量指数，识别最优气候适应措施。

Result: 初步结果表明该方法能够学习最优适应措施，并且优于其他现实和真实世界的规划策略。

Conclusion: 该框架为气候适应规划提供了有效工具，能够识别提升长期生活质量的适应路径，框架已公开可用。

Abstract: Urban flooding is expected to increase in frequency and severity as a
consequence of climate change, causing wide-ranging impacts that include a
decrease in urban Quality of Life (QoL). Meanwhile, policymakers must devise
adaptation strategies that can cope with the uncertain nature of climate change
and the complex and dynamic nature of urban flooding. Reinforcement Learning
(RL) holds significant promise in tackling such complex, dynamic, and uncertain
problems. Because of this, we use RL to identify which climate adaptation
pathways lead to a higher QoL in the long term. We do this using an Integrated
Assessment Model (IAM) which combines a rainfall projection model, a flood
model, a transport accessibility model, and a quality of life index. Our
preliminary results suggest that this approach can be used to learn optimal
adaptation measures and it outperforms other realistic and real-world planning
strategies. Our framework is publicly available:
https://github.com/MLSM-at-DTU/maat_qol_framework.

</details>


### [71] [A Feedback-Control Framework for Efficient Dataset Collection from In-Vehicle Data Streams](https://arxiv.org/abs/2511.03239)
*Philipp Reis,Philipp Rigoll,Christian Steinhauser,Jacob Langner,Eric Sax*

Main category: cs.LG

TL;DR: FCDC将数据收集建模为闭环控制问题，通过在线概率模型和反馈机制动态调节样本保留，在减少39.8%存储的同时提升数据集平衡性25.9%


<details>
  <summary>Details</summary>
Motivation: 现代AI系统主要受限于数据质量和多样性而非模型容量，传统开环数据收集方式积累冗余样本，导致存储低效、标注成本高和泛化能力有限

Method: FCDC使用在线概率模型持续估计已收集数据分布状态，基于似然和马氏距离等反馈信号自适应调节样本保留，动态平衡探索与利用

Result: 在真实数据流实验中，FCDC减少39.8%数据存储的同时提升数据集平衡性25.9%，合成数据集实验展示了系统的可控性

Conclusion: 数据收集本身可以主动控制，将收集从被动管道阶段转变为以数据为中心AI核心的自调节、反馈驱动过程

Abstract: Modern AI systems are increasingly constrained not by model capacity but by
the quality and diversity of their data. Despite growing emphasis on
data-centric AI, most datasets are still gathered in an open-loop manner which
accumulates redundant samples without feedback from the current coverage. This
results in inefficient storage, costly labeling, and limited generalization. To
address this, this paper introduces \ac{FCDC}, a paradigm that formulates data
collection as a closed-loop control problem. \ac{FCDC} continuously
approximates the state of the collected data distribution using an online
probabilistic model and adaptively regulates sample retention using based on
feedback signals such as likelihood and Mahalanobis distance. Through this
feedback mechanism, the system dynamically balances exploration and
exploitation, maintains dataset diversity, and prevents redundancy from
accumulating over time. Besides showcasing the controllability of \ac{FCDC} on
a synthetic dataset, experiments on a real data stream show that \ac{FCDC}
produces more balanced datasets by $\SI{25.9}{\percent}$ while reducing data
storage by $\SI{39.8}{\percent}$. These results demonstrate that data
collection itself can be actively controlled, transforming collection from a
passive pipeline stage into a self-regulating, feedback-driven process at the
core of data-centric AI.

</details>


### [72] [A unified physics-informed generative operator framework for general inverse problems](https://arxiv.org/abs/2511.03241)
*Gang Bao,Yaohua Zang*

Main category: cs.LG

TL;DR: IGNO是一种新颖的生成神经算子框架，用于解决由偏微分方程控制的逆问题，无需标记训练数据，通过物理约束和潜在空间优化实现稳定、可扩展的逆问题求解。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法需要大量标记数据或局限于特定测量类型，在稀疏、噪声或高维不连续系数情况下容易失败，限制了实际应用。

Method: IGNO将高维系数场编码到低维潜在空间，通过神经算子解码器重建系数和PDE解，仅依赖物理约束进行训练，在潜在空间进行高效梯度优化。

Result: 在多种挑战性逆问题中，包括从解测量恢复不连续系数和EIT问题，IGNO实现了准确、稳定和可扩展的逆问题求解，在不同噪声水平下均优于现有最优方法。

Conclusion: IGNO为计算科学领域的挑战性逆问题提供了一个统一而强大的框架。

Abstract: Solving inverse problems governed by partial differential equations (PDEs) is
central to science and engineering, yet remains challenging when measurements
are sparse, noisy, or when the underlying coefficients are high-dimensional or
discontinuous. Existing deep learning approaches either require extensive
labeled datasets or are limited to specific measurement types, often leading to
failure in such regimes and restricting their practical applicability. Here, a
novel generative neural operator framework, IGNO, is introduced to overcome
these limitations. IGNO unifies the solution of inverse problems from both
point measurements and operator-valued data without labeled training pairs.
This framework encodes high-dimensional, potentially discontinuous coefficient
fields into a low-dimensional latent space, which drives neural operator
decoders to reconstruct both coefficients and PDE solutions. Training relies
purely on physics constraints through PDE residuals, while inversion proceeds
via efficient gradient-based optimization in latent space, accelerated by an a
priori normalizing flow model. Across a diverse set of challenging inverse
problems, including recovery of discontinuous coefficients from solution-based
measurements and the EIT problem with operator-based measurements, IGNO
consistently achieves accurate, stable, and scalable inversion even under
severe noise. It consistently outperforms the state-of-the-art method under
varying noise levels and demonstrates strong generalization to
out-of-distribution targets. These results establish IGNO as a unified and
powerful framework for tackling challenging inverse problems across
computational science domains.

</details>


### [73] [Climate Adaptation with Reinforcement Learning: Economic vs. Quality of Life Adaptation Pathways](https://arxiv.org/abs/2511.03243)
*Miguel Costa,Arthur Vandervoort,Martin Drews,Karyn Morrissey,Francisco C. Pereira*

Main category: cs.LG

TL;DR: 本文提出使用强化学习来识别气候变化下的适应路径，并明确建模不同的适应优先级（经济vs福祉），通过综合评估模型分析洪水影响。


<details>
  <summary>Details</summary>
Motivation: 气候变化将增加洪水事件的频率和严重性，需要有效的适应政策制定，但长期气候影响的不确定性和政策中的规范性选择往往未明确考虑。

Method: 使用强化学习结合综合评估模型，将降雨和洪水模型连接起来，计算洪水对生活质量、交通和基础设施损坏的影响。

Result: 优先考虑生活质量而非经济影响的模型会导致更多的适应支出，并在研究区域内更均匀地分配支出，表明规范性假设会显著改变适应政策。

Conclusion: 强化学习是识别不确定条件下适应路径和明确建模不同适应优先级的有效工具，框架已公开可用。

Abstract: Climate change will cause an increase in the frequency and severity of flood
events, prompting the need for cohesive adaptation policymaking. Designing
effective adaptation policies, however, depends on managing the uncertainty of
long-term climate impacts. Meanwhile, such policies can feature important
normative choices that are not always made explicit. We propose that
Reinforcement Learning (RL) can be a useful tool to both identify adaptation
pathways under uncertain conditions while it also allows for the explicit
modelling (and consequent comparison) of different adaptation priorities (e.g.
economic vs. wellbeing). We use an Integrated Assessment Model (IAM) to link
together a rainfall and flood model, and compute the impacts of flooding in
terms of quality of life (QoL), transportation, and infrastructure damage. Our
results show that models prioritising QoL over economic impacts results in more
adaptation spending as well as a more even distribution of spending over the
study area, highlighting the extent to which such normative assumptions can
alter adaptation policy. Our framework is publicly available:
https://github.com/MLSM-at-DTU/maat_qol_framework.

</details>


### [74] [GMoPE:A Prompt-Expert Mixture Framework for Graph Foundation Models](https://arxiv.org/abs/2511.03251)
*Zhibin Wang,Zhixing Zhang,Shuqi Wang,Xuanting Xie,Zhao Kang*

Main category: cs.LG

TL;DR: 提出了GMoPE框架，将混合专家架构与基于提示的图学习相结合，通过专家特定的提示向量和结构感知路由实现跨领域泛化，显著降低适应成本。


<details>
  <summary>Details</summary>
Motivation: 解决图神经网络在跨领域和任务泛化能力有限、存在负迁移、可扩展性问题和适应成本高等挑战。

Method: 结合混合专家架构与提示学习，使用专家特定提示向量和结构感知路由，引入软正交约束促进专家多样性，采用仅提示微调策略。

Result: 在各种预训练策略和下游任务中持续优于现有方法，性能接近全参数微调但只需少量适应开销。

Conclusion: GMoPE为推进通用且高效的图基础模型提供了一个原则性和可扩展的框架。

Abstract: Graph Neural Networks (GNNs) have demonstrated impressive performance on
task-specific benchmarks, yet their ability to generalize across diverse
domains and tasks remains limited. Existing approaches often struggle with
negative transfer, scalability issues, and high adaptation costs. To address
these challenges, we propose GMoPE (Graph Mixture of Prompt-Experts), a novel
framework that seamlessly integrates the Mixture-of-Experts (MoE) architecture
with prompt-based learning for graphs. GMoPE leverages expert-specific prompt
vectors and structure-aware MoE routing to enable each expert to specialize in
distinct subdomains and dynamically contribute to predictions. To promote
diversity and prevent expert collapse, we introduce a soft orthogonality
constraint across prompt vectors, encouraging expert specialization and
facilitating a more balanced expert utilization. Additionally, we adopt a
prompt-only fine-tuning strategy that significantly reduces spatiotemporal
complexity during transfer. We validate GMoPE through extensive experiments
under various pretraining strategies and multiple downstream tasks. Results
show that GMoPE consistently outperforms state-of-the-art baselines and
achieves performance comparable to full parameter fine-tuning-while requiring
only a fraction of the adaptation overhead. Our work provides a principled and
scalable framework for advancing generalizable and efficient graph foundation
models.

</details>


### [75] [Decoupled Entropy Minimization](https://arxiv.org/abs/2511.03256)
*Jing Ma,Hanlin Li,Xiang Xiang*

Main category: cs.LG

TL;DR: 本文分析了经典熵最小化(EM)的内在机制，将其解耦为两个相反作用的部分，揭示了其局限性，并提出了自适应解耦熵最小化(AdaDEM)方法来解决这些问题。


<details>
  <summary>Details</summary>
Motivation: 经典熵最小化在机器学习中虽然有益于减少类别重叠、弥合领域差距和限制不确定性，但其潜力有限。需要研究其内部机制并解决其局限性。

Method: 将经典EM解耦为集群聚合驱动因子(CADF)和梯度缓解校准器(GMC)，然后提出AdaDEM方法，通过标准化CADF带来的奖励并使用边际熵校准器(MEC)替代GMC。

Result: AdaDEM在噪声和动态环境中的各种不完美监督学习任务中表现出色，超越了经典EM的上界变体DEM*。

Conclusion: 通过解耦分析和自适应设计，AdaDEM有效解决了经典EM的局限性，在多个任务中实现了优越性能。

Abstract: Entropy Minimization (EM) is beneficial to reducing class overlap, bridging
domain gap, and restricting uncertainty for various tasks in machine learning,
yet its potential is limited. To study the internal mechanism of EM, we
reformulate and decouple the classical EM into two parts with opposite effects:
cluster aggregation driving factor (CADF) rewards dominant classes and prompts
a peaked output distribution, while gradient mitigation calibrator (GMC)
penalizes high-confidence classes based on predicted probabilities.
Furthermore, we reveal the limitations of classical EM caused by its coupled
formulation: 1) reward collapse impedes the contribution of high-certainty
samples in the learning process, and 2) easy-class bias induces misalignment
between output distribution and label distribution. To address these issues, we
propose Adaptive Decoupled Entropy Minimization (AdaDEM), which normalizes the
reward brought from CADF and employs a marginal entropy calibrator (MEC) to
replace GMC. AdaDEM outperforms DEM*, an upper-bound variant of classical EM,
and achieves superior performance across various imperfectly supervised
learning tasks in noisy and dynamic environments.

</details>


### [76] [Diffusion Language Models are Super Data Learners](https://arxiv.org/abs/2511.03276)
*Jinjie Ni,Qian Liu,Longxu Dou,Chao Du,Zili Wang,Hang Yan,Tianyu Pang,Michael Qizhe Shieh*

Main category: cs.LG

TL;DR: 在严格控制的预训练设置下，当独特数据有限时，扩散语言模型通过更多轮训练持续超越自回归模型。这种交叉现象随着数据量增加而推迟，随着模型规模增大而提前，并在密集和稀疏架构中持续存在。


<details>
  <summary>Details</summary>
Motivation: 探索在数据受限情况下，扩散语言模型相对于自回归模型的优势，特别是在重复使用有限数据时的表现。

Method: 在严格匹配的设置下训练扩散语言模型和自回归模型，比较它们在数据受限情况下的性能，分析扩散模型的三个优势因素：任意顺序建模、迭代双向去噪的超密集计算、内置蒙特卡洛增强。

Result: 1.7B参数的扩散语言模型在约1.5T令牌计算预算下，使用10B独特Python令牌训练后超越了匹配设置的自回归编码器。1B参数的扩散模型仅使用1B令牌就实现了HellaSwag >56%和MMLU >33%的准确率。验证交叉熵上升并不表示下游性能下降。

Conclusion: 扩散语言模型在数据受限情况下具有显著优势，通过更多轮训练可以超越自回归模型，这为有限数据环境下的语言模型训练提供了新思路。

Abstract: Under strictly controlled pre-training settings, we observe a Crossover: when
unique data is limited, diffusion language models (DLMs) consistently surpass
autoregressive (AR) models by training for more epochs. The crossover shifts
later with more or higher-quality data, earlier with larger models, and
persists across dense and sparse architectures. We attribute the gains to three
compounding factors: (1) any-order modeling, (2) super-dense compute from
iterative bidirectional denoising, and (3) built-in Monte Carlo augmentation;
input or parameter noise improves AR under data constraint but cannot close the
gap. At scale, a 1.7B DLM trained with a ~1.5T-token compute budget on 10B
unique Python tokens overtakes an AR coder trained with strictly matched
settings. In addition, a 1B-parameter DLM achieves > 56% accuracy on HellaSwag
and > 33% on MMLU using only 1B tokens, without any special tricks, just by
repeating standard pre-training data. We also show that rising validation
cross-entropy does not imply degraded downstream performance in this regime.

</details>


### [77] [Multi-Objective Adaptive Rate Limiting in Microservices Using Deep Reinforcement Learning](https://arxiv.org/abs/2511.03279)
*Ning Lyu,Yuxi Wang,Ziyu Cheng,Qingyuan Zhang,Feng Chen*

Main category: cs.LG

TL;DR: 提出基于深度强化学习的自适应限流策略，在Kubernetes集群环境中相比传统固定阈值策略实现了23.7%吞吐量提升和31.4% P99延迟降低。


<details>
  <summary>Details</summary>
Motivation: 传统限流算法难以适应动态流量模式和变化的系统负载，需要更智能的自适应限流机制来确保系统稳定性和服务质量。

Method: 设计结合DQN和A3C算法的混合架构，将限流决策过程建模为马尔可夫决策过程，通过环境交互学习最优限流策略。

Result: 在高负载场景下，吞吐量提升23.7%，P99延迟降低31.4%；90天生产部署处理5亿日请求，服务降级事件减少82%，人工干预减少68%。

Conclusion: 基于深度强化学习的自适应限流策略能有效平衡系统吞吐量和服务延迟，在云原生环境中具有显著优势。

Abstract: As cloud computing and microservice architectures become increasingly
prevalent, API rate limiting has emerged as a critical mechanism for ensuring
system stability and service quality. Traditional rate limiting algorithms,
such as token bucket and sliding window, while widely adopted, struggle to
adapt to dynamic traffic patterns and varying system loads. This paper proposes
an adaptive rate limiting strategy based on deep reinforcement learning that
dynamically balances system throughput and service latency. We design a hybrid
architecture combining Deep Q-Network (DQN) and Asynchronous Advantage
Actor-Critic (A3C) algorithms, modeling the rate limiting decision process as a
Markov Decision Process. The system continuously monitors microservice states
and learns optimal rate limiting policies through environmental interaction.
Extensive experiments conducted in a Kubernetes cluster environment demonstrate
that our approach achieves 23.7% throughput improvement and 31.4% P99 latency
reduction compared to traditional fixed-threshold strategies under high-load
scenarios. Results from a 90-day production deployment handling 500 million
daily requests validate the practical effectiveness of the proposed method,
with 82% reduction in service degradation incidents and 68% decrease in manual
interventions.

</details>


### [78] [A Probabilistic Approach to Pose Synchronization for Multi-Reference Alignment with Applications to MIMO Wireless Communication Systems](https://arxiv.org/abs/2511.03280)
*Rob Romijnders,Gabriele Cesa,Christos Louizos,Kumar Pratik,Arash Behboodi*

Main category: cs.LG

TL;DR: 提出了一种新的多参考对齐算法，通过概率建模和相对位姿作为干扰变量来消除全局对称性，实现更直接的求解和更好的收敛性。


<details>
  <summary>Details</summary>
Motivation: 从分子成像到无线通信，从多个未对齐观测中重建信号对系统性能至关重要。MRA问题出现在许多实际应用中，如冷冻电镜、计算机视觉和无线通信系统。

Method: 使用概率方法建模MRA问题，将相对位姿作为干扰变量进行边缘化处理，消除问题的全局对称性。通过循环一致性避免集中式方法的立方复杂度。

Result: 所提出的算法在实验设置中实现了更低的重建误差，通过去中心化方法显著节省计算成本。

Conclusion: 新算法通过消除全局对称性和利用循环一致性，在多参考对齐问题上实现了更好的性能和计算效率。

Abstract: From molecular imaging to wireless communications, the ability to align and
reconstruct signals from multiple misaligned observations is crucial for system
performance. We study the problem of multi-reference alignment (MRA), which
arises in many real-world problems, such as cryo-EM, computer vision, and, in
particular, wireless communication systems. Using a probabilistic approach to
model MRA, we find a new algorithm that uses relative poses as nuisance
variables to marginalize out -- thereby removing the global symmetries of the
problem and allowing for more direct solutions and improved convergence. The
decentralization of this approach enables significant computational savings by
avoiding the cubic scaling of centralized methods through cycle consistency.
Both proposed algorithms achieve lower reconstruction error across experimental
settings.

</details>


### [79] [Graph Neural AI with Temporal Dynamics for Comprehensive Anomaly Detection in Microservices](https://arxiv.org/abs/2511.03285)
*Qingyuan Zhang,Ning Lyu,Le Liu,Yuxi Wang,Ziyu Cheng,Cancan Hua*

Main category: cs.LG

TL;DR: 提出了一个结合图神经网络和时间建模的统一框架，用于微服务架构中的异常检测和根因追踪。


<details>
  <summary>Details</summary>
Motivation: 解决微服务架构中异常检测和根因追踪的问题，应对动态拓扑和复杂环境下的挑战。

Method: 将微服务调用链抽象为有向图，使用图卷积聚合节点特征建模结构依赖关系，引入门控循环单元建模时间演化，定义节点和路径级别的异常评分函数。

Result: 在AUC、ACC、Recall和F1-Score等关键指标上优于基线方法，在动态拓扑和复杂环境下保持高准确性和稳定性。

Conclusion: 为微服务异常检测提供了新的技术路径，为分布式系统智能运维奠定了方法论基础。

Abstract: This study addresses the problem of anomaly detection and root cause tracing
in microservice architectures and proposes a unified framework that combines
graph neural networks with temporal modeling. The microservice call chain is
abstracted as a directed graph, where multidimensional features of nodes and
edges are used to construct a service topology representation, and graph
convolution is applied to aggregate features across nodes and model
dependencies, capturing complex structural relationships among services. On
this basis, gated recurrent units are introduced to model the temporal
evolution of call chains, and multi-layer stacking and concatenation operations
are used to jointly obtain structural and temporal representations, improving
the ability to identify anomaly patterns. Furthermore, anomaly scoring
functions at both the node and path levels are defined to achieve unified
modeling from local anomaly detection to global call chain tracing, which
enables the identification of abnormal service nodes and the reconstruction of
potential anomaly propagation paths. Sensitivity experiments are then designed
from multiple dimensions, including hyperparameters, environmental
disturbances, and data distribution, to evaluate the framework, and results
show that it outperforms baseline methods in key metrics such as AUC, ACC,
Recall, and F1-Score, maintaining high accuracy and stability under dynamic
topologies and complex environments. This research not only provides a new
technical path for anomaly detection in microservices but also lays a
methodological foundation for intelligent operations in distributed systems.

</details>


### [80] [Extending Fair Null-Space Projections for Continuous Attributes to Kernel Methods](https://arxiv.org/abs/2511.03304)
*Felix Störck,Fabian Hinder,Barbara Hammer*

Main category: cs.LG

TL;DR: 本文提出了一种用于连续公平性的核方法，通过将零空间投影推广到核方法，显著扩展了适用范围，并在支持向量回归中表现出色。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习系统在日常社会生活中的广泛应用，公平性成为重要考量。现有研究主要关注离散属性，而连续属性（特别是回归问题中的连续公平性）研究稀缺。

Method: 将迭代零空间投影方法推广到核方法，提出模型和公平性评分无关的核嵌入方法，适用于连续保护属性。

Result: 与支持向量回归结合使用时，该方法在多个数据集上表现出竞争性或改进的性能。

Conclusion: 该方法成功将零空间投影扩展到核方法，为连续公平性提供了有效的解决方案。

Abstract: With the on-going integration of machine learning systems into the everyday
social life of millions the notion of fairness becomes an ever increasing
priority in their development. Fairness notions commonly rely on protected
attributes to assess potential biases. Here, the majority of literature focuses
on discrete setups regarding both target and protected attributes. The
literature on continuous attributes especially in conjunction with regression
-- we refer to this as \emph{continuous fairness} -- is scarce. A common
strategy is iterative null-space projection which as of now has only been
explored for linear models or embeddings such as obtained by a non-linear
encoder. We improve on this by generalizing to kernel methods, significantly
extending the scope. This yields a model and fairness-score agnostic method for
kernel embeddings applicable to continuous protected attributes. We demonstrate
that our novel approach in conjunction with Support Vector Regression (SVR)
provides competitive or improved performance across multiple datasets in
comparisons to other contemporary methods.

</details>


### [81] [SORTeD Rashomon Sets of Sparse Decision Trees: Anytime Enumeration](https://arxiv.org/abs/2511.03344)
*Elif Arslan,Jacobus G. M. van der Linden,Serge Hoogendoorn,Marco Rinaldi,Emir Demirović*

Main category: cs.LG

TL;DR: SORTD是一个新颖框架，用于高效枚举Rashomon集合中的决策树（性能相似但结构不同的树），相比现有方法将运行时间减少两个数量级，支持可分离和全序目标函数。


<details>
  <summary>Details</summary>
Motivation: 稀疏决策树学习提供准确且可解释的预测模型，但单一"最佳"树限制了分析灵活性。Rashomon集合（性能相似但结构不同的树集合）可以增强变量重要性分析、丰富解释性，并允许用户根据偏好选择更简单或满足特定标准（如公平性）的树。

Method: 提出SORTD框架，按目标值顺序枚举Rashomon集合中的树，提供随时可用的行为。支持任何可分离和全序的目标函数，并支持使用其他可分离（部分有序）目标函数进行后评估。

Result: 实验表明，SORTD相比现有技术将运行时间减少高达两个数量级，能够更高效地计算Rashomon集合。

Conclusion: SORTD使探索Rashomon集合在现实应用中更加实用，为高风险应用中的决策树分析提供了更强大的工具。

Abstract: Sparse decision tree learning provides accurate and interpretable predictive
models that are ideal for high-stakes applications by finding the single most
accurate tree within a (soft) size limit. Rather than relying on a single
"best" tree, Rashomon sets-trees with similar performance but varying
structures-can be used to enhance variable importance analysis, enrich
explanations, and enable users to choose simpler trees or those that satisfy
stakeholder preferences (e.g., fairness) without hard-coding such criteria into
the objective function. However, because finding the optimal tree is NP-hard,
enumerating the Rashomon set is inherently challenging. Therefore, we introduce
SORTD, a novel framework that improves scalability and enumerates trees in the
Rashomon set in order of the objective value, thus offering anytime behavior.
Our experiments show that SORTD reduces runtime by up to two orders of
magnitude compared with the state of the art. Moreover, SORTD can compute
Rashomon sets for any separable and totally ordered objective and supports
post-evaluating the set using other separable (and partially ordered)
objectives. Together, these advances make exploring Rashomon sets more
practical in real-world applications.

</details>


### [82] [A Modular, Data-Free Pipeline for Multi-Label Intention Recognition in Transportation Agentic AI Applications](https://arxiv.org/abs/2511.03363)
*Xiaocai Zhang,Hur Lim,Ke Wang,Zhe Xiao,Jing Wang,Kelvin Lee,Xiuju Fu,Zheng Qin*

Main category: cs.LG

TL;DR: 提出了一种无需数据的模块化多标签意图识别管道DMTC，通过LLM生成合成查询、Sentence-T5编码和在线焦点对比损失训练，在交通领域实现高精度意图理解，无需昂贵数据标注。


<details>
  <summary>Details</summary>
Motivation: 传统意图识别系统依赖大量标注数据且难以进行细粒度多标签区分，需要消除数据收集成本同时提升多标签意图理解准确性。

Method: 三步骤管道：1) 使用提示工程引导LLM生成多样化合成查询；2) 用Sentence-T5模型编码文本查询获得语义嵌入；3) 使用新颖的在线焦点对比损失训练轻量级分类器，强调困难样本并最大化类间可分性。

Result: 在海上交通应用中，DMTC实现5.35%的汉明损失和95.92%的AUC，优于最先进的多标签分类器和LLM基线。Sentence-T5嵌入比替代编码器提升至少3.29%子集准确率，OFC损失相比标准对比目标额外提升0.98%。

Conclusion: 该系统无缝地将用户查询路由到特定任务模块，为完全自主的意图感知代理奠定了基础，无需昂贵的人工标注。

Abstract: In this study, a modular, data-free pipeline for multi-label intention
recognition is proposed for agentic AI applications in transportation. Unlike
traditional intent recognition systems that depend on large, annotated corpora
and often struggle with fine-grained, multi-label discrimination, our approach
eliminates the need for costly data collection while enhancing the accuracy of
multi-label intention understanding. Specifically, the overall pipeline, named
DMTC, consists of three steps: 1) using prompt engineering to guide large
language models (LLMs) to generate diverse synthetic queries in different
transport scenarios; 2) encoding each textual query with a Sentence-T5 model to
obtain compact semantic embeddings; 3) training a lightweight classifier using
a novel online focal-contrastive (OFC) loss that emphasizes hard samples and
maximizes inter-class separability. The applicability of the proposed pipeline
is demonstrated in an agentic AI application in the maritime transportation
context. Extensive experiments show that DMTC achieves a Hamming loss of 5.35%
and an AUC of 95.92%, outperforming state-of-the-art multi-label classifiers
and recent end-to-end SOTA LLM-based baselines. Further analysis reveals that
Sentence-T5 embeddings improve subset accuracy by at least 3.29% over
alternative encoders, and integrating the OFC loss yields an additional 0.98%
gain compared to standard contrastive objectives. In conclusion, our system
seamlessly routes user queries to task-specific modules (e.g., ETA information,
traffic risk evaluation, and other typical scenarios in the transportation
domain), laying the groundwork for fully autonomous, intention-aware agents
without costly manual labelling.

</details>


### [83] [TripleWin: Fixed-Point Equilibrium Pricing for Data-Model Coupled Markets](https://arxiv.org/abs/2511.03368)
*Hongrun Ren,Yun Xiong,Lei You,Yingying Wang,Haixu Xiong,Yangyong Zhu*

Main category: cs.LG

TL;DR: 提出了一个统一的数据-模型耦合市场，将数据集和模型交易作为一个单一系统处理，通过供需映射形成闭环定价机制，保证均衡价格的存在性、唯一性和全局收敛性。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型经济的兴起使得训练数据集和预训练模型市场相互交织，但现有定价方法仍将数据和模型交易分离，或依赖偏向一方的代理中心管道，缺乏同时覆盖数据卖家、模型生产者和模型买家的对称机制。

Method: 构建统一的数据-模型耦合市场，包含供给端映射（将数据集支付转化为买家可见的模型报价）和需求端映射（通过基于Shapley值的分配将买家价格传播回数据集），形成连接四个交互的闭环系统。

Result: 证明了联合算子是一个标准干扰函数，确保均衡价格的存在性、唯一性和全局收敛性。实验表明该方法能高效收敛，相比代理中心和单边基准方法提高了公平性。

Conclusion: 该研究提出的统一数据-模型耦合市场机制能够有效解决现有定价方法的局限性，为机器学习模型经济中的多方参与者提供公平高效的定价解决方案。

Abstract: The rise of the machine learning (ML) model economy has intertwined markets
for training datasets and pre-trained models. However, most pricing approaches
still separate data and model transactions or rely on broker-centric pipelines
that favor one side. Recent studies of data markets with externalities capture
buyer interactions but do not yield a simultaneous and symmetric mechanism
across data sellers, model producers, and model buyers. We propose a unified
data-model coupled market that treats dataset and model trading as a single
system. A supply-side mapping transforms dataset payments into buyer-visible
model quotations, while a demand-side mapping propagates buyer prices back to
datasets through Shapley-based allocation. Together, they form a closed loop
that links four interactions: supply-demand propagation in both directions and
mutual coupling among buyers and among sellers. We prove that the joint
operator is a standard interference function (SIF), guaranteeing existence,
uniqueness, and global convergence of equilibrium prices. Experiments
demonstrate efficient convergence and improved fairness compared with
broker-centric and one-sided baselines. The code is available on
https://github.com/HongrunRen1109/Triple-Win-Pricing.

</details>


### [84] [Adaptable Hindsight Experience Replay for Search-Based Learning](https://arxiv.org/abs/2511.03405)
*Alexandros Vazaios,Jannis Brugger,Cedric Derstroff,Kristian Kersting,Mira Mezini*

Main category: cs.LG

TL;DR: 提出了Adaptable HER框架，将后见经验回放与AlphaZero结合，通过重新标记搜索树中的失败轨迹来改进稀疏奖励环境下的训练效果。


<details>
  <summary>Details</summary>
Motivation: 原始AlphaZero方法在稀疏奖励环境下训练神经网络存在局限性，特别是在早期阶段网络无法提供有效指导时。

Method: 开发了Adaptable HER框架，灵活整合HER与AlphaZero，允许调整重新标记的目标、策略目标和轨迹选择等属性。

Result: 实验（包括方程发现）表明，修改HER的可能性是有益的，并且超越了纯监督学习或强化学习的性能。

Conclusion: Adaptable HER框架有效解决了稀疏奖励环境下的训练问题，通过重新标记失败轨迹提升了AlphaZero系统的性能。

Abstract: AlphaZero-like Monte Carlo Tree Search systems, originally introduced for
two-player games, dynamically balance exploration and exploitation using neural
network guidance. This combination makes them also suitable for classical
search problems. However, the original method of training the network with
simulation results is limited in sparse reward settings, especially in the
early stages, where the network cannot yet give guidance. Hindsight Experience
Replay (HER) addresses this issue by relabeling unsuccessful trajectories from
the search tree as supervised learning signals. We introduce Adaptable HER
(\ours{}), a flexible framework that integrates HER with AlphaZero, allowing
easy adjustments to HER properties such as relabeled goals, policy targets, and
trajectory selection. Our experiments, including equation discovery, show that
the possibility of modifying HER is beneficial and surpasses the performance of
pure supervised or reinforcement learning.

</details>


### [85] [POEMS: Product of Experts for Interpretable Multi-omic Integration using Sparse Decoding](https://arxiv.org/abs/2511.03464)
*Mihriban Kocak Balik,Pekka Marttinen,Negar Safinianaini*

Main category: cs.LG

TL;DR: POEMS是一个可解释的多组学集成框架，通过稀疏解码保持预测性能的同时提供可解释性，无需线性化网络部分。


<details>
  <summary>Details</summary>
Motivation: 解决深度生成模型在预测性能和可解释性之间的权衡问题，大多数模型要么牺牲可解释性追求性能，要么通过线性化解码器削弱非线性表达能力。

Method: 使用专家乘积模型构建共享潜在空间，通过稀疏连接将特征映射到潜在因子，采用自适应门控网络计算各组学贡献，并提出了高效的稀疏解码器。

Result: 在癌症亚型分析案例中，POEMS实现了具有竞争力的聚类和分类性能，同时提供了新颖的可解释性分析。

Conclusion: 基于生物标志物的洞察力和预测准确性可以在多组学表示学习中并存，POEMS成功克服了性能与可解释性之间的权衡。

Abstract: Integrating different molecular layers, i.e., multiomics data, is crucial for
unraveling the complexity of diseases; yet, most deep generative models either
prioritize predictive performance at the expense of interpretability or enforce
interpretability by linearizing the decoder, thereby weakening the network's
nonlinear expressiveness. To overcome this tradeoff, we introduce POEMS:
Product Of Experts for Interpretable Multiomics Integration using Sparse
Decoding, an unsupervised probabilistic framework that preserves predictive
performance while providing interpretability. POEMS provides interpretability
without linearizing any part of the network by 1) mapping features to latent
factors using sparse connections, which directly translates to biomarker
discovery, 2) allowing for cross-omic associations through a shared latent
space using product of experts model, and 3) reporting contributions of each
omic by a gating network that adaptively computes their influence in the
representation learning. Additionally, we present an efficient sparse decoder.
In a cancer subtyping case study, POEMS achieves competitive clustering and
classification performance while offering our novel set of interpretations,
demonstrating that biomarker based insight and predictive accuracy can coexist
in multiomics representation learning.

</details>


### [86] [Reinforcement Learning Using known Invariances](https://arxiv.org/abs/2511.03473)
*Alexandru Cioba,Aya Kayal,Laura Toni,Sattar Vakili,Alberto Bernacchia*

Main category: cs.LG

TL;DR: 本文提出了一个将已知群对称性融入基于核的强化学习的理论算法框架，开发了对称感知的乐观最小二乘值迭代方法，通过不变核编码奖励和转移动态的不变性，显著提升了样本效率。


<details>
  <summary>Details</summary>
Motivation: 许多现实世界强化学习问题中的环境存在固有对称性，可以利用这些对称性来提高学习效率。

Method: 提出了对称感知的乐观最小二乘值迭代方法，使用不变核来编码奖励和转移动态的不变性。

Result: 理论分析建立了不变RKHS中最大信息增益和覆盖数的新界限，实证结果在定制Frozen Lake环境和2D布局设计问题上证实了对称感知RL相比标准核方法有显著更好的性能。

Conclusion: 这些发现凸显了结构先验在设计更样本高效的强化学习算法中的价值。

Abstract: In many real-world reinforcement learning (RL) problems, the environment
exhibits inherent symmetries that can be exploited to improve learning
efficiency. This paper develops a theoretical and algorithmic framework for
incorporating known group symmetries into kernel-based RL. We propose a
symmetry-aware variant of optimistic least-squares value iteration (LSVI),
which leverages invariant kernels to encode invariance in both rewards and
transition dynamics. Our analysis establishes new bounds on the maximum
information gain and covering numbers for invariant RKHSs, explicitly
quantifying the sample efficiency gains from symmetry. Empirical results on a
customized Frozen Lake environment and a 2D placement design problem confirm
the theoretical improvements, demonstrating that symmetry-aware RL achieves
significantly better performance than their standard kernel counterparts. These
findings highlight the value of structural priors in designing more
sample-efficient reinforcement learning algorithms.

</details>


### [87] [RAGBoost: Efficient Retrieval-Augmented Generation with Accuracy-Preserving Context Reuse](https://arxiv.org/abs/2511.03475)
*Yinsicheng Jiang,Yeqi Huang,Liang Cheng,Cheng Deng,Xuan Sun,Luo Mai*

Main category: cs.LG

TL;DR: RAGBoost是一个高效的检索增强生成系统，通过准确保持的上下文重用实现高缓存复用率而不牺牲准确性，相比现有方法将预填充性能提升1.5-3倍。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG缓存技术要么保持准确性但缓存复用率低，要么提高复用率但牺牲推理质量，需要在保持准确性的同时提高缓存效率。

Method: 通过检测并发会话和多轮交互中的重叠检索项，使用高效的上下文索引、排序和去重来最大化复用，同时通过轻量级上下文提示保持推理保真度。

Result: 在多样化RAG和智能AI工作负载中，预填充性能比最先进方法提升1.5-3倍，同时保持甚至提升了推理准确性。

Conclusion: RAGBoost实现了高缓存复用而不牺牲准确性，可无缝集成到现有LLM推理引擎中，显著提升RAG系统性能。

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs)
with retrieved context but often suffers from downgraded prefill performance as
modern applications demand longer and more complex inputs. Existing caching
techniques either preserve accuracy with low cache reuse or improve reuse at
the cost of degraded reasoning quality. We present RAGBoost, an efficient RAG
system that achieves high cache reuse without sacrificing accuracy through
accuracy-preserving context reuse. RAGBoost detects overlapping retrieved items
across concurrent sessions and multi-turn interactions, using efficient context
indexing, ordering, and de-duplication to maximize reuse, while lightweight
contextual hints maintain reasoning fidelity. It integrates seamlessly with
existing LLM inference engines and improves their prefill performance by 1.5-3X
over state-of-the-art methods, while preserving or even enhancing reasoning
accuracy across diverse RAG and agentic AI workloads. Our code is released at:
https://github.com/Edinburgh-AgenticAI/RAGBoost.

</details>


### [88] [NAP: Attention-Based Late Fusion for Automatic Sleep Staging](https://arxiv.org/abs/2511.03488)
*Alvise Dei Rossi,Julia van der Meer,Markus H. Schmidt,Claudio L. A. Bassetti,Luigi Fiorillo,Francesca Faraci*

Main category: cs.LG

TL;DR: NAP是一个基于注意力的模型，通过三轴注意力机制整合多通道预测，在睡眠分期任务中实现零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 解决多导睡眠图信号在不同数据集和临床中心存在模态组成、通道可用性和采集协议差异的问题，现有模型无法充分利用其多模态特性。

Method: 提出NAP模型，使用三轴注意力机制（时间、空间、预测器级）来组合多个预测流，通过聚合预训练单通道模型的输出来适应不同输入维度。

Result: NAP在多个数据集上持续优于单个预测器和简单集成方法，实现了最先进的零样本泛化性能。

Conclusion: 该方法不仅适用于睡眠分期，还可扩展到其他多模态生理应用。

Abstract: Polysomnography signals are highly heterogeneous, varying in modality
composition (e.g., EEG, EOG, ECG), channel availability (e.g., frontal,
occipital EEG), and acquisition protocols across datasets and clinical sites.
Most existing models that process polysomnography data rely on a fixed subset
of modalities or channels and therefore neglect to fully exploit its inherently
multimodal nature. We address this limitation by introducing NAP (Neural
Aggregator of Predictions), an attention-based model which learns to combine
multiple prediction streams using a tri-axial attention mechanism that captures
temporal, spatial, and predictor-level dependencies. NAP is trained to adapt to
different input dimensions. By aggregating outputs from frozen, pretrained
single-channel models, NAP consistently outperforms individual predictors and
simple ensembles, achieving state-of-the-art zero-shot generalization across
multiple datasets. While demonstrated in the context of automated sleep staging
from polysomnography, the proposed approach could be extended to other
multimodal physiological applications.

</details>


### [89] [Why Less is More (Sometimes): A Theory of Data Curation](https://arxiv.org/abs/2511.03492)
*Elvis Dohmatob,Mohammad Pezeshki,Reyhane Askari-Hemmat*

Main category: cs.LG

TL;DR: 本文提出了一个理论框架来解决机器学习中的核心悖论：何时使用更少数据反而更好。研究发现，在某些条件下，精心筛选的小数据集可以超越完整数据集，并提供了数据大小和质量相关的相变曲线。


<details>
  <summary>Details</summary>
Motivation: 解决现代机器学习中的核心矛盾：当经典缩放定律认为'越多越好'时，为什么像LIMO和s1这样的方法通过小规模、精心筛选的数据集反而能获得更好的性能？

Method: 研究数据筛选策略，其中不完美的预言机根据样本的难度和正确性来选择训练样本。推导了在标签无关和标签感知筛选规则下测试误差的精确缩放定律曲线。

Result: 理论分析显示，在某些条件下，小规模筛选数据集可以超越完整数据集。在ImageNet上的实证结果验证了理论预测，确认了筛选何时能提高准确性甚至缓解模型崩溃。

Conclusion: 该框架为最近在LLM数学推理中观察到的矛盾筛选策略提供了原则性解释，揭示了数据筛选改善泛化的条件和机制。

Abstract: This paper introduces a theoretical framework to resolve a central paradox in
modern machine learning: When is it better to use less data? This question has
become critical as classical scaling laws suggesting ``more is more'' (Sun et
al., 2025) are challenged by methods like LIMO (``less is more'') and s1 (Ye et
al., 2025; Muenighoff et al., 2025), which achieve superior performance with
small, aggressively curated datasets. Here, we study data curation strategies
where an imperfect oracle selects the training examples according to their
difficulty and correctness. Our results provide exact scaling law curves for
test error under both label-agnostic and label-aware curation rules, revealing
when and why keeping only a subset of data can improve generalization. In
contrast to classical scaling laws, we show that under certain conditions,
small curated datasets can outperform full datasets, and we provide analytical
conditions for this by deriving precise phase transition curves tied to data
size and quality. We validate these theoretical claims with empirical results
on ImageNet, confirming our predictions about when curation improves accuracy
and can even mitigate model collapse. Furthermore, our framework provides a
principled explanation for the contradictory curation strategies recently
observed in LLM mathematical reasoning.

</details>


### [90] [Learning Without Critics? Revisiting GRPO in Classical Reinforcement Learning Environments](https://arxiv.org/abs/2511.03527)
*Bryan L. M. de Oliveira,Felipe V. Frujeri,Marcos P. C. M. Queiroz,Luana G. B. Martins,Telma W. de L. Soares,Luckeciano C. Melo*

Main category: cs.LG

TL;DR: GRPO作为PPO的可扩展替代方案，通过组间轨迹比较消除学习评论家，但在经典单任务RL环境中系统研究表明：学习评论家在长时域任务中仍然必要，GRPO仅适用于短时域环境如CartPole；高折扣因子通常有益，但需根据环境调整；小规模组优于大规模组。


<details>
  <summary>Details</summary>
Motivation: 研究GRPO作为消除学习评论家的PPO替代方案，探索在策略梯度方法中学习基线的必要性，通过系统分析揭示无评论家方法的局限性。

Method: 在经典单任务强化学习环境中进行受控消融实验，隔离基线、折扣和组采样因素，涵盖离散和连续控制任务。

Result: 发现三个关键结果：1) 学习评论家对长时域任务仍然必要，无评论家基线仅在短时域环境中表现良好；2) GRPO受益于高折扣因子，但需根据环境特性调整；3) 小规模组表现优于大规模组。

Conclusion: 揭示了无评论家方法在经典控制任务中的局限性，以及它们在特定条件下作为学习价值函数替代方案的可行性范围。

Abstract: Group Relative Policy Optimization (GRPO) has emerged as a scalable
alternative to Proximal Policy Optimization (PPO) by eliminating the learned
critic and instead estimating advantages through group-relative comparisons of
trajectories. This simplification raises fundamental questions about the
necessity of learned baselines in policy-gradient methods. We present the first
systematic study of GRPO in classical single-task reinforcement learning
environments, spanning discrete and continuous control tasks. Through
controlled ablations isolating baselines, discounting, and group sampling, we
reveal three key findings: (1) learned critics remain essential for
long-horizon tasks: all critic-free baselines underperform PPO except in
short-horizon environments like CartPole where episodic returns can be
effective; (2) GRPO benefits from high discount factors (gamma = 0.99) except
in HalfCheetah, where lack of early termination favors moderate discounting
(gamma = 0.9); (3) smaller group sizes outperform larger ones, suggesting
limitations in batch-based grouping strategies that mix unrelated episodes.
These results reveal both the limitations of critic-free methods in classical
control and the specific conditions where they remain viable alternatives to
learned value functions.

</details>


### [91] [Byzantine-Robust Federated Learning with Learnable Aggregation Weights](https://arxiv.org/abs/2511.03529)
*Javad Parsa,Amir Hossein Daghestani,André M. H. Teixeira,Mikael Johansson*

Main category: cs.LG

TL;DR: 提出了一种新的拜占庭鲁棒联邦学习优化方法，通过将聚合权重作为可学习参数与全局模型参数联合优化，在异构数据和恶意客户端攻击下显著提升性能


<details>
  <summary>Details</summary>
Motivation: 联邦学习中恶意客户端的存在对系统鲁棒性构成严重威胁，特别是在数据分布异构的情况下，传统方法难以有效应对

Method: 提出拜占庭鲁棒FL优化问题，将聚合权重作为可学习参数，开发具有强收敛保证的交替最小化算法

Result: 在多种数据集和攻击场景下，该方法始终优于现有最先进的拜占庭鲁棒FL方法，特别在高度异构数据和大量恶意客户端情况下表现更佳

Conclusion: 所提出的自适应权重聚合方法能有效提升联邦学习在拜占庭攻击下的鲁棒性，特别是在数据异构的挑战性环境中

Abstract: Federated Learning (FL) enables clients to collaboratively train a global
model without sharing their private data. However, the presence of malicious
(Byzantine) clients poses significant challenges to the robustness of FL,
particularly when data distributions across clients are heterogeneous. In this
paper, we propose a novel Byzantine-robust FL optimization problem that
incorporates adaptive weighting into the aggregation process. Unlike
conventional approaches, our formulation treats aggregation weights as
learnable parameters, jointly optimizing them alongside the global model
parameters. To solve this optimization problem, we develop an alternating
minimization algorithm with strong convergence guarantees under adversarial
attack. We analyze the Byzantine resilience of the proposed objective. We
evaluate the performance of our algorithm against state-of-the-art
Byzantine-robust FL approaches across various datasets and attack scenarios.
Experimental results demonstrate that our method consistently outperforms
existing approaches, particularly in settings with highly heterogeneous data
and a large proportion of malicious clients.

</details>


### [92] [Efficient Neural Networks with Discrete Cosine Transform Activations](https://arxiv.org/abs/2511.03531)
*Marc Martinez-Gost,Sara Pepe,Ana Pérez-Neira,Miguel Ángel Lagunas*

Main category: cs.LG

TL;DR: 本文扩展了表达性神经网络(ENN)的研究，这是一种使用离散余弦变换(DCT)参数化自适应激活函数的多层感知机。论文重点展示了ENN在效率、可解释性和剪枝能力方面的优势。


<details>
  <summary>Details</summary>
Motivation: 基于先前工作证明ENN在紧凑架构下具有强大表达能力，现在需要强调其效率、可解释性和剪枝能力，将信号处理概念系统性地整合到神经网络设计中。

Method: 使用DCT参数化提供结构化和去相关的表示，揭示每个神经元的功能角色，并允许直接识别冗余组件。提出高效的剪枝策略，移除不必要的DCT系数。

Result: 在分类和隐式神经表示任务中的实验结果表明，ENN在保持参数数量较少的同时达到最先进的准确率。由于DCT基的正交性和有界性，可以安全剪枝高达40%的激活系数。

Conclusion: ENN框架将信号处理概念与神经网络设计原则性整合，在表达能力、紧凑性和可解释性之间实现了平衡的权衡。

Abstract: In this paper, we extend our previous work on the Expressive Neural Network
(ENN), a multilayer perceptron with adaptive activation functions parametrized
using the Discrete Cosine Transform (DCT). Building upon previous work that
demonstrated the strong expressiveness of ENNs with compact architectures, we
now emphasize their efficiency, interpretability and pruning capabilities. The
DCT-based parameterization provides a structured and decorrelated
representation that reveals the functional role of each neuron and allows
direct identification of redundant components. Leveraging this property, we
propose an efficient pruning strategy that removes unnecessary DCT coefficients
with negligible or no loss in performance. Experimental results across
classification and implicit neural representation tasks confirm that ENNs
achieve state-of-the-art accuracy while maintaining a low number of parameters.
Furthermore, up to 40% of the activation coefficients can be safely pruned,
thanks to the orthogonality and bounded nature of the DCT basis. Overall, these
findings demonstrate that the ENN framework offers a principled integration of
signal processing concepts into neural network design, achieving a balanced
trade-off between expressiveness, compactness, and interpretability.

</details>


### [93] [Flat Minima and Generalization: Insights from Stochastic Convex Optimization](https://arxiv.org/abs/2511.03548)
*Matan Schliserman,Shira Vansover-Hager,Tomer Koren*

Main category: cs.LG

TL;DR: 该论文研究了凸优化中平坦最小值与泛化性能的关系，发现平坦最小值可能泛化很差，而尖锐最小值反而泛化良好。同时分析了两种锐度感知算法的泛化表现。


<details>
  <summary>Details</summary>
Motivation: 理解学习算法的泛化行为是学习理论的核心目标。最近的研究表明，学习算法在实践中成功是因为收敛到平坦最小值，这与改进的泛化性能相关。本研究旨在探索在随机凸优化设置中平坦最小值与泛化之间的确切联系。

Method: 在非负β-平滑目标的随机凸优化标准设置中，分析平坦最小值与泛化的关系。研究两种锐度感知算法：锐度感知梯度下降(SA-GD)和锐度感知最小化(SAM)，前者在预定义邻域内对最大损失执行梯度步骤，后者是基于归一化上升步骤的计算高效近似。

Result: 发现平坦经验最小值可能产生Ω(1)的总体风险，而尖锐最小值反而泛化最优。SA-GD虽然快速收敛到平坦最小值，但总体风险仍可能高达Ω(1)。SAM虽然最小化经验损失，但可能收敛到尖锐最小值并产生Ω(1)总体风险。

Conclusion: 在凸优化设置中，平坦最小值与良好泛化之间没有必然联系，平坦最小值可能泛化很差。锐度感知算法不能保证找到泛化良好的解，需要重新审视平坦最小值与泛化的关系。

Abstract: Understanding the generalization behavior of learning algorithms is a central
goal of learning theory. A recently emerging explanation is that learning
algorithms are successful in practice because they converge to flat minima,
which have been consistently associated with improved generalization
performance. In this work, we study the link between flat minima and
generalization in the canonical setting of stochastic convex optimization with
a non-negative, $\beta$-smooth objective. Our first finding is that, even in
this fundamental and well-studied setting, flat empirical minima may incur
trivial $\Omega(1)$ population risk while sharp minima generalizes optimally.
Then, we show that this poor generalization behavior extends to two natural
''sharpness-aware'' algorithms originally proposed by Foret et al. (2021),
designed to bias optimization toward flat solutions: Sharpness-Aware Gradient
Descent (SA-GD) and Sharpness-Aware Minimization (SAM). For SA-GD, which
performs gradient steps on the maximal loss in a predefined neighborhood, we
prove that while it successfully converges to a flat minimum at a fast rate,
the population risk of the solution can still be as large as $\Omega(1)$,
indicating that even flat minima found algorithmically using a sharpness-aware
gradient method might generalize poorly. For SAM, a computationally efficient
approximation of SA-GD based on normalized ascent steps, we show that although
it minimizes the empirical loss, it may converge to a sharp minimum and also
incur population risk $\Omega(1)$. Finally, we establish population risk upper
bounds for both SA-GD and SAM using algorithmic stability techniques.

</details>


### [94] [Imitation Learning in the Deep Learning Era: A Novel Taxonomy and Recent Advances](https://arxiv.org/abs/2511.03565)
*Iason Chrysomallis,Georgios Chalkiadakis*

Main category: cs.LG

TL;DR: 本调查论文回顾了模仿学习的最新进展，提出了新的分类法来反映当前研究现状和趋势，并分析了代表性工作的优缺点、评估实践以及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习的发展，模仿学习的能力和可扩展性显著提升，出现了许多新方法来应对泛化、协变量偏移和演示质量等长期挑战，需要系统梳理最新研究进展。

Method: 提出了一种新颖的分类法来更好地反映当前模仿学习研究现状和趋势，对代表性工作进行了批判性分析。

Result: 系统回顾了模仿学习的最新进展，包括方法创新、实际应用和评估实践，突出了当前研究趋势。

Conclusion: 模仿学习在多个领域取得了显著进展，但仍面临关键挑战，需要进一步研究解决泛化、协变量偏移等问题，并提出了未来的研究方向。

Abstract: Imitation learning (IL) enables agents to acquire skills by observing and
replicating the behavior of one or multiple experts. In recent years, advances
in deep learning have significantly expanded the capabilities and scalability
of imitation learning across a range of domains, where expert data can range
from full state-action trajectories to partial observations or unlabeled
sequences. Alongside this growth, novel approaches have emerged, with new
methodologies being developed to address longstanding challenges such as
generalization, covariate shift, and demonstration quality. In this survey, we
review the latest advances in imitation learning research, highlighting recent
trends, methodological innovations, and practical applications. We propose a
novel taxonomy that is distinct from existing categorizations to better reflect
the current state of the IL research stratum and its trends. Throughout the
survey, we critically examine the strengths, limitations, and evaluation
practices of representative works, and we outline key challenges and open
directions for future research.

</details>


### [95] [TabGemma: Text-Based Tabular ICL via LLM using Continued Pretraining and Retrieval](https://arxiv.org/abs/2511.03570)
*Günther Schindler,Maximilian Schambach,Michael Medek,Sam Thelin*

Main category: cs.LG

TL;DR: TabGemma是一个用于表格预测的LLM模型，通过科学记数法处理数值、目标插补预训练和n-gram检索选择示例，在语义丰富的分类任务上达到SOTA，但在回归任务中数据量大时表现不如传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决将预训练LLM应用于表格预测时的两个实际障碍：不稳定的数值标记化和有限的上下文大小。

Method: 1. 使用带符号科学记数法规范化数值；2. 在大型真实数据集上对12B Gemma 3模型进行目标插补预训练；3. 使用紧凑的n-gram检索选择信息丰富的示例以适应128k令牌窗口。

Result: 在语义丰富的基准测试中，TabGemma在分类任务（低数据和高数据场景）上达到新的SOTA，性能随上下文行数增加而单调提升；在回归任务中，小样本时具有竞争力，但数据增长时落后于传统方法。

Conclusion: LLMs在配备专用数值处理和上下文检索时，可以成为有效的表格上下文学习器，特别是在高度语义任务上，同时需要在数值建模和长上下文扩展方面进一步改进。

Abstract: We study LLMs for tabular prediction with mixed text, numeric, and
categorical fields. We introduce TabGemma, a schema-agnostic in-context learner
that treats rows as sequences and tackles two practical hurdles when adapting
pretrained LLMs for tabular predictions: unstable numeric tokenization and
limited context size. We propose to canonicalize numbers via signed scientific
notation and continue pretraining of a 12B Gemma 3 model with a target
imputation objective using a large-scale real world dataset. For inference, we
use a compact n-gram-based retrieval to select informative exemplars that fit
within a 128k-token window.
  On semantically rich benchmarks, TabGemma establishes a new state of the art
on classification across low- and high-data regimes and improves monotonically
with more context rows. For regression, it is competitive at small sample sizes
but trails conventional approaches as data grows. Our results show that LLMs
can be effective tabular in-context learners on highly semantic tasks when
paired with dedicated numeric handling and context retrieval, while motivating
further advances in numeric modeling and long-context scaling.

</details>


### [96] [Learning Under Laws: A Constraint-Projected Neural PDE Solver that Eliminates Hallucinations](https://arxiv.org/abs/2511.03578)
*Mainak Singha*

Main category: cs.LG

TL;DR: CPL框架通过将神经网络输出投影到物理约束集上，确保每个更新都保持物理可容许性，从而解决神经网络求解偏微分方程时违反物理定律的问题。


<details>
  <summary>Details</summary>
Motivation: 神经网络在近似偏微分方程解时经常违反其本应建模的物理定律，如质量不守恒、冲击波漂移、违反守恒律和熵增原理等。

Method: 使用约束投影学习(CPL)框架，将网络输出投影到由守恒律、Rankine-Hugoniot平衡、熵增和正定性定义的约束集交集上；结合总变差阻尼(TVD)抑制小振荡，以及滚动课程学习确保长期预测一致性。

Result: 在Burgers和Euler系统上，CPL产生了稳定且物理合法的解，没有损失精度；守恒律在机器精度下成立，总变差增长消失，熵和误差保持有界。

Conclusion: CPL使物理约束行为成为学习过程的内在属性，而不是寄希望于神经求解器会尊重物理规律。

Abstract: Neural networks can approximate solutions to partial differential equations,
but they often break the very laws they are meant to model-creating mass from
nowhere, drifting shocks, or violating conservation and entropy. We address
this by training within the laws of physics rather than beside them. Our
framework, called Constraint-Projected Learning (CPL), keeps every update
physically admissible by projecting network outputs onto the intersection of
constraint sets defined by conservation, Rankine-Hugoniot balance, entropy, and
positivity. The projection is differentiable and adds only about 10%
computational overhead, making it fully compatible with back-propagation. We
further stabilize training with total-variation damping (TVD) to suppress small
oscillations and a rollout curriculum that enforces consistency over long
prediction horizons. Together, these mechanisms eliminate both hard and soft
violations: conservation holds at machine precision, total-variation growth
vanishes, and entropy and error remain bounded. On Burgers and Euler systems,
CPL produces stable, physically lawful solutions without loss of accuracy.
Instead of hoping neural solvers will respect physics, CPL makes that behavior
an intrinsic property of the learning process.

</details>


### [97] [Tensor-Efficient High-Dimensional Q-learning](https://arxiv.org/abs/2511.03595)
*Junyi Wu,Dan Li*

Main category: cs.LG

TL;DR: 提出了Tensor-Efficient Q-Learning (TEQL)，一种基于低秩张量分解的高维强化学习方法，通过改进的块坐标下降和创新的探索机制，在样本效率和总奖励方面优于传统矩阵方法和深度RL方法。


<details>
  <summary>Details</summary>
Motivation: 高维强化学习面临复杂计算和低样本效率的挑战，特别是在大规模状态-动作空间中。现有Q学习算法受到维度诅咒的影响，而神经网络方法虽然成功但参数量大。张量方法提供了更参数高效的替代方案。

Method: TEQL通过改进的块坐标下降在离散化状态-动作空间上增强低秩张量分解，结合了基于近似误差和访问次数的上置信界探索策略，以及频率惩罚项来鼓励探索较少访问的状态-动作对。

Result: 在经典控制任务上的实证结果表明，TEQL在样本效率和总奖励方面优于传统矩阵方法和深度RL方法。

Conclusion: TEQL适用于资源受限的应用场景，如空间和医疗领域，其中采样成本很高。

Abstract: High-dimensional reinforcement learning faces challenges with complex
calculations and low sample efficiency in large state-action spaces. Q-learning
algorithms struggle particularly with the curse of dimensionality, where the
number of state-action pairs grows exponentially with problem size. While
neural network-based approaches like Deep Q-Networks have shown success, recent
tensor-based methods using low-rank decomposition offer more
parameter-efficient alternatives. Building upon existing tensor-based methods,
we propose Tensor-Efficient Q-Learning (TEQL), which enhances low-rank tensor
decomposition via improved block coordinate descent on discretized state-action
spaces, incorporating novel exploration and regularization mechanisms. The key
innovation is an exploration strategy that combines approximation error with
visit count-based upper confidence bound to prioritize actions with high
uncertainty, avoiding wasteful random exploration. Additionally, we incorporate
a frequency-based penalty term in the objective function to encourage
exploration of less-visited state-action pairs and reduce overfitting to
frequently visited regions. Empirical results on classic control tasks
demonstrate that TEQL outperforms conventional matrix-based methods and deep RL
approaches in both sample efficiency and total rewards, making it suitable for
resource-constrained applications, such as space and healthcare where sampling
costs are high.

</details>


### [98] [Going Beyond Expert Performance via Deep Implicit Imitation Reinforcement Learning](https://arxiv.org/abs/2511.03616)
*Iason Chrysomallis,Georgios Chalkiadakis*

Main category: cs.LG

TL;DR: 提出了深度隐式模仿强化学习框架，结合深度强化学习和仅观察数据集的隐式模仿学习，解决了传统模仿学习需要完整状态-动作演示和最优专家的限制。


<details>
  <summary>Details</summary>
Motivation: 传统模仿学习需要完整的状态-动作演示和最优专家，这在实际应用中限制很大，因为许多现实场景只提供状态观察而没有对应动作，且专家表现往往不是最优的。

Method: 主要算法DIIQN采用动作推断机制通过在线探索重建专家动作，并集成动态置信机制自适应平衡专家引导和自主学习。还扩展了HA-DIIQN算法处理专家和智能体具有不同动作集的情况。

Result: DIIQN相比标准DQN获得高达130%的更高回合回报，持续优于现有无法超越专家表现的隐式模仿方法。在异构动作设置中，HA-DIIQN学习速度比基线快64%。

Conclusion: 该框架能够利用专家指导加速训练，同时保持超越次优专家表现的能力，在异构动作场景中也能有效利用传统方法无法使用的专家数据集。

Abstract: Imitation learning traditionally requires complete state-action
demonstrations from optimal or near-optimal experts. These requirements
severely limit practical applicability, as many real-world scenarios provide
only state observations without corresponding actions and expert performance is
often suboptimal. In this paper we introduce a deep implicit imitation
reinforcement learning framework that addresses both limitations by combining
deep reinforcement learning with implicit imitation learning from
observation-only datasets. Our main algorithm, Deep Implicit Imitation
Q-Network (DIIQN), employs an action inference mechanism that reconstructs
expert actions through online exploration and integrates a dynamic confidence
mechanism that adaptively balances expert-guided and self-directed learning.
This enables the agent to leverage expert guidance for accelerated training
while maintaining capacity to surpass suboptimal expert performance. We further
extend our framework with a Heterogeneous Actions DIIQN (HA-DIIQN) algorithm to
tackle scenarios where expert and agent possess different action sets, a
challenge previously unaddressed in the implicit imitation learning literature.
HA-DIIQN introduces an infeasibility detection mechanism and a bridging
procedure identifying alternative pathways connecting agent capabilities to
expert guidance when direct action replication is impossible. Our experimental
results demonstrate that DIIQN achieves up to 130% higher episodic returns
compared to standard DQN, while consistently outperforming existing implicit
imitation methods that cannot exceed expert performance. In heterogeneous
action settings, HA-DIIQN learns up to 64% faster than baselines, leveraging
expert datasets unusable by conventional approaches. Extensive parameter
sensitivity analysis reveals the framework's robustness across varying dataset
sizes and hyperparameter configurations.

</details>


### [99] [Towards Formalizing Reinforcement Learning Theory](https://arxiv.org/abs/2511.03618)
*Shangtong Zhang*

Main category: cs.LG

TL;DR: 使用Lean 4定理证明器基于Mathlib库形式化验证了Q学习和线性TD学习在马尔可夫样本下的几乎必然收敛性。


<details>
  <summary>Details</summary>
Motivation: Q学习和线性TD学习是最早且最具影响力的强化学习算法，研究它们的收敛性不仅是RL领域早期发展的主要研究课题，如今也越来越受到关注。

Method: 基于Robbins-Siegmund定理的统一框架，使用Lean 4定理证明器进行形式化验证。

Result: 成功形式化验证了Q学习和线性TD学习在马尔可夫样本下的几乎必然收敛性。

Conclusion: 这项工作为完全形式化收敛RL结果迈出了重要一步，所开发的框架可以轻松扩展到收敛速率和其他收敛模式。

Abstract: In this paper, we formalize the almost sure convergence of $Q$-learning and
linear temporal difference (TD) learning with Markovian samples using the Lean
4 theorem prover based on the Mathlib library. $Q$-learning and linear TD are
among the earliest and most influential reinforcement learning (RL) algorithms.
The investigation of their convergence properties is not only a major research
topic during the early development of the RL field but also receives increasing
attention nowadays. This paper formally verifies their almost sure convergence
in a unified framework based on the Robbins-Siegmund theorem. The framework
developed in this work can be easily extended to convergence rates and other
modes of convergence. This work thus makes an important step towards fully
formalizing convergent RL results. The code is available at
https://github.com/ShangtongZhang/rl-theory-in-lean.

</details>


### [100] [Financial Management System for SMEs: Real-World Deployment of Accounts Receivable and Cash Flow Prediction](https://arxiv.org/abs/2511.03631)
*Bartłomiej Małkus,Szymon Bobek,Grzegorz J. Nalepa*

Main category: cs.LG

TL;DR: 开发了针对中小企业的集成财务预测系统，结合应收账款预测和现金流预测，解决企业级工具与小微企业实际需求之间的差距。


<details>
  <summary>Details</summary>
Motivation: 中小企业和自由职业者面临资源有限、客户基础小、数据可用性受限等独特的财务管理挑战，需要专门针对其运营约束设计的财务工具。

Method: 系统整合两个关键组件：用于预测发票付款延迟的二元分类模型，以及处理不完整和有限历史数据的多模块现金流预测模型。原型系统已作为Web应用程序部署。

Result: 系统已在Cluee平台上部署实施，这是一个为自由职业者提供财务管理工具的初创公司，证明了在实际中小企业财务管理中的可行性。

Conclusion: 该集成财务预测系统成功填补了企业级财务工具与小微企业实际需求之间的空白，为资源受限的中小企业提供了实用的财务管理解决方案。

Abstract: Small and Medium Enterprises (SMEs), particularly freelancers and early-stage
businesses, face unique financial management challenges due to limited
resources, small customer bases, and constrained data availability. This paper
presents the development and deployment of an integrated financial prediction
system that combines accounts receivable prediction and cash flow forecasting
specifically designed for SME operational constraints. Our system addresses the
gap between enterprise-focused financial tools and the practical needs of
freelancers and small businesses. The solution integrates two key components: a
binary classification model for predicting invoice payment delays, and a
multi-module cash flow forecasting model that handles incomplete and limited
historical data. A prototype system has been implemented and deployed as a web
application with integration into Cluee's platform, a startup providing
financial management tools for freelancers, demonstrating practical feasibility
for real-world SME financial management.

</details>


### [101] [nanoTabPFN: A Lightweight and Educational Reimplementation of TabPFN](https://arxiv.org/abs/2511.03634)
*Alexander Pfefferle,Johannes Hog,Lennart Purucker,Frank Hutter*

Main category: cs.LG

TL;DR: nanoTabPFN是一个简化的表格基础模型实现，相比TabPFN v2大幅减少了代码复杂度和计算需求，使表格基础模型更易于理解和教育使用。


<details>
  <summary>Details</summary>
Motivation: 现有表格基础模型如TabPFN实现复杂（超过1万行代码），缺乏架构文档和代码质量，难以理解、不友好且难以适应新实验。

Method: 开发了简化的TabPFN v2架构实现和训练循环，使用预生成的训练数据，在单GPU上1分钟内完成预训练。

Result: 在小数据设置下，性能与传统机器学习基线相当，预训练速度比TabPFN v2快160,000倍。

Conclusion: nanoTabPFN消除了对大型计算资源的需求，使表格基础模型的预训练在教育目的上变得可行。

Abstract: Tabular foundation models such as TabPFN have revolutionized predictive
machine learning for tabular data. At the same time, the driving factors of
this revolution are hard to understand. Existing open-source tabular foundation
models are implemented in complicated pipelines boasting over 10,000 lines of
code, lack architecture documentation or code quality. In short, the
implementations are hard to understand, not beginner-friendly, and complicated
to adapt for new experiments. We introduce nanoTabPFN, a simplified and
lightweight implementation of the TabPFN v2 architecture and a corresponding
training loop that uses pre-generated training data. nanoTabPFN makes tabular
foundation models more accessible to students and researchers alike. For
example, restricted to a small data setting it achieves a performance
comparable to traditional machine learning baselines within one minute of
pre-training on a single GPU (160,000x faster than TabPFN v2 pretraining). This
eliminated requirement of large computational resources makes pre-training
tabular foundation models accessible for educational purposes. Our code is
available at https://github.com/automl/nanoTabPFN.

</details>


### [102] [SHIELD: Securing Healthcare IoT with Efficient Machine Learning Techniques for Anomaly Detection](https://arxiv.org/abs/2511.03661)
*Mahek Desai,Apoorva Rumale,Marjan Asadinia*

Main category: cs.LG

TL;DR: 该研究提出一个机器学习框架，用于检测医疗物联网中的网络攻击和设备故障异常，评估了8种模型在三种学习范式下的性能。XGBoost在异常检测中表现最佳，KNN在攻击检测中效果最好。


<details>
  <summary>Details</summary>
Motivation: 医疗物联网设备面临严重的安全和可靠性挑战，容易受到网络威胁和操作异常的影响，需要有效的检测方法来保护患者安全和系统稳定运行。

Method: 使用包含20万条记录的数据集，评估了8种机器学习模型：监督学习（XGBoost、KNN）、半监督学习（GAN、VAE）和无监督学习（One-Class SVM、Isolation Forest、GNN、LSTM Autoencoders），采用F1分数、精确率、召回率、准确率、ROC-AUC和计算效率等多指标评估。

Result: XGBoost在异常检测中达到99%准确率且计算开销最小（0.04秒），Isolation Forest在精确率和召回率间取得良好平衡。KNN在攻击检测中实现近乎完美的精确率、召回率和F1分数，计算成本最低（0.05秒）。GAN计算成本最高且性能最差。

Conclusion: 该框架通过有效的异常检测策略增强了医疗物联网安全性，能够及早发现网络威胁和设备故障，预防数据泄露、减少系统停机时间，确保医疗设备持续安全运行，保护患者健康和信任。

Abstract: The integration of IoT devices in healthcare introduces significant security
and reliability challenges, increasing susceptibility to cyber threats and
operational anomalies. This study proposes a machine learning-driven framework
for (1) detecting malicious cyberattacks and (2) identifying faulty device
anomalies, leveraging a dataset of 200,000 records. Eight machine learning
models are evaluated across three learning approaches: supervised learning
(XGBoost, K-Nearest Neighbors (K- NN)), semi-supervised learning (Generative
Adversarial Networks (GAN), Variational Autoencoders (VAE)), and unsupervised
learning (One-Class Support Vector Machine (SVM), Isolation Forest, Graph
Neural Networks (GNN), and Long Short-Term Memory (LSTM) Autoencoders). The
comprehensive evaluation was conducted across multiple metrics like F1-score,
precision, recall, accuracy, ROC-AUC, computational efficiency. XGBoost
achieved 99\% accuracy with minimal computational overhead (0.04s) for anomaly
detection, while Isolation Forest balanced precision and recall effectively.
LSTM Autoencoders underperformed with lower accuracy and higher latency. For
attack detection, KNN achieved near-perfect precision, recall, and F1-score
with the lowest computational cost (0.05s), followed by VAE at 97% accuracy.
GAN showed the highest computational cost with lowest accuracy and ROC-AUC.
These findings enhance IoT-enabled healthcare security through effective
anomaly detection strategies. By improving early detection of cyber threats and
device failures, this framework has the potential to prevent data breaches,
minimize system downtime, and ensure the continuous and safe operation of
medical devices, ultimately safeguarding patient health and trust in IoT-driven
healthcare solutions.

</details>


### [103] [DQN Performance with Epsilon Greedy Policies and Prioritized Experience Replay](https://arxiv.org/abs/2511.03670)
*Daniel Perkins,Oscar J. Escobar,Luke Green*

Main category: cs.LG

TL;DR: 本文系统研究了深度Q网络在有限环境中的表现，重点分析了ε-贪婪探索策略和优先级经验回放的影响，为资源受限环境下的强化学习提供了实用建议。


<details>
  <summary>Details</summary>
Motivation: 研究深度Q网络中探索策略与经验回放机制的相互作用，特别是在有限环境下的训练效率和收敛行为，以解决资源受限环境中的强化学习优化问题。

Method: 通过系统实验评估不同ε衰减策略对学习效率的影响，比较均匀回放、无回放和优先级回放策略在多个模拟环境中的表现。

Result: 优先级经验回放能带来更快的收敛速度和更高的回报，实验揭示了探索策略与内存管理之间的权衡关系。

Conclusion: 研究阐明了DQN训练中探索策略与内存管理的相互作用，为资源受限环境下的稳健强化学习提供了实用指导。

Abstract: We present a detailed study of Deep Q-Networks in finite environments,
emphasizing the impact of epsilon-greedy exploration schedules and prioritized
experience replay. Through systematic experimentation, we evaluate how
variations in epsilon decay schedules affect learning efficiency, convergence
behavior, and reward optimization. We investigate how prioritized experience
replay leads to faster convergence and higher returns and show empirical
results comparing uniform, no replay, and prioritized strategies across
multiple simulations. Our findings illuminate the trade-offs and interactions
between exploration strategies and memory management in DQN training, offering
practical recommendations for robust reinforcement learning in
resource-constrained settings.

</details>


### [104] [Structured Matrix Scaling for Multi-Class Calibration](https://arxiv.org/abs/2511.03685)
*Eugène Berta,David Holzmüller,Michael I. Jordan,Francis Bach*

Main category: cs.LG

TL;DR: 本文提出了基于逻辑回归的参数化后验校准方法，通过结构化正则化、鲁棒预处理和高效优化来管理多类校准中的偏差-方差权衡，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 参数化校准函数可以基于简单理论设置进行推导，但多类校准面临参数过多和校准数据有限导致的过拟合问题。

Method: 使用基于逻辑回归的参数化校准方法，结合结构化正则化、鲁棒预处理和高效优化技术来管理偏差-方差权衡。

Result: 新方法在实验中显著优于现有的温度缩放、向量缩放和矩阵缩放等校准技术。

Conclusion: 提出的校准方法提供了高效易用的开源实现，是现有校准技术的有效替代方案。

Abstract: Post-hoc recalibration methods are widely used to ensure that classifiers
provide faithful probability estimates. We argue that parametric recalibration
functions based on logistic regression can be motivated from a simple
theoretical setting for both binary and multiclass classification. This insight
motivates the use of more expressive calibration methods beyond standard
temperature scaling. For multi-class calibration however, a key challenge lies
in the increasing number of parameters introduced by more complex models, often
coupled with limited calibration data, which can lead to overfitting. Through
extensive experiments, we demonstrate that the resulting bias-variance tradeoff
can be effectively managed by structured regularization, robust preprocessing
and efficient optimization. The resulting methods lead to substantial gains
over existing logistic-based calibration techniques. We provide efficient and
easy-to-use open-source implementations of our methods, making them an
attractive alternative to common temperature, vector, and matrix scaling
implementations.

</details>


### [105] [Behavior-Adaptive Q-Learning: A Unifying Framework for Offline-to-Online RL](https://arxiv.org/abs/2511.03695)
*Lipeng Zu,Hansong Zhou,Xiaonan Zhang*

Main category: cs.LG

TL;DR: BAQ框架通过行为一致性信号实现离线到在线强化学习的平滑过渡，利用离线数据中的隐式行为模型来减少分布偏移问题，提升策略部署的可靠性。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习策略在动态环境中部署时面临分布偏移和不可靠价值估计的问题，需要一种能够平滑过渡到在线学习的可靠方法。

Method: 提出行为自适应Q学习(BAQ)，采用双目标损失函数：在高不确定性时对齐离线行为，随着在线经验积累逐步放松约束，通过隐式行为模型提供行为一致性信号。

Result: 在标准基准测试中，BAQ持续优于现有离线到在线RL方法，实现更快的恢复速度、更强的鲁棒性和更高的整体性能。

Conclusion: 隐式行为适应是现实世界策略部署的原则性和实用解决方案，能够减少分布外估计的错误传播，稳定早期在线更新并加速新场景适应。

Abstract: Offline reinforcement learning (RL) enables training from fixed data without
online interaction, but policies learned offline often struggle when deployed
in dynamic environments due to distributional shift and unreliable value
estimates on unseen state-action pairs. We introduce Behavior-Adaptive
Q-Learning (BAQ), a framework designed to enable a smooth and reliable
transition from offline to online RL. The key idea is to leverage an implicit
behavioral model derived from offline data to provide a behavior-consistency
signal during online fine-tuning. BAQ incorporates a dual-objective loss that
(i) aligns the online policy toward the offline behavior when uncertainty is
high, and (ii) gradually relaxes this constraint as more confident online
experience is accumulated. This adaptive mechanism reduces error propagation
from out-of-distribution estimates, stabilizes early online updates, and
accelerates adaptation to new scenarios. Across standard benchmarks, BAQ
consistently outperforms prior offline-to-online RL approaches, achieving
faster recovery, improved robustness, and higher overall performance. Our
results demonstrate that implicit behavior adaptation is a principled and
practical solution for reliable real-world policy deployment.

</details>


### [106] [AnaFlow: Agentic LLM-based Workflow for Reasoning-Driven Explainable and Sample-Efficient Analog Circuit Sizing](https://arxiv.org/abs/2511.03697)
*Mohsen Ahmadzadeh,Kaichang Chen,Georges Gielen*

Main category: cs.LG

TL;DR: 提出了一种基于多智能体LLM的模拟电路尺寸优化框架AnaFlow，通过智能体协作实现高效、可解释的自动化电路设计


<details>
  <summary>Details</summary>
Motivation: 模拟/混合信号电路设计目前主要依赖手工，设计周期长且容易出错。现有AI方法需要大量耗时仿真且缺乏可解释性，阻碍了工具的广泛应用

Method: 采用多智能体工作流，专门的LLM智能体协作解释电路拓扑、理解设计目标，并通过人类可理解的推理迭代优化电路参数，结合自适应仿真策略提高样本效率

Result: AnaFlow框架在两个不同复杂度的电路上成功实现了全自动尺寸优化，相比纯贝叶斯优化和强化学习方法表现更优，能够从优化历史中学习避免错误并加速收敛

Conclusion: 该框架为模拟设计空间探索提供了强大工具，开创了模拟EDA新范式，AI智能体作为透明的设计助手

Abstract: Analog/mixed-signal circuits are key for interfacing electronics with the
physical world. Their design, however, remains a largely handcrafted process,
resulting in long and error-prone design cycles. While the recent rise of
AI-based reinforcement learning and generative AI has created new techniques to
automate this task, the need for many time-consuming simulations is a critical
bottleneck hindering the overall efficiency. Furthermore, the lack of
explainability of the resulting design solutions hampers widespread adoption of
the tools. To address these issues, a novel agentic AI framework for
sample-efficient and explainable analog circuit sizing is presented. It employs
a multi-agent workflow where specialized Large Language Model (LLM)-based
agents collaborate to interpret the circuit topology, to understand the design
goals, and to iteratively refine the circuit's design parameters towards the
target goals with human-interpretable reasoning. The adaptive simulation
strategy creates an intelligent control that yields a high sample efficiency.
The AnaFlow framework is demonstrated for two circuits of varying complexity
and is able to complete the sizing task fully automatically, differently from
pure Bayesian optimization and reinforcement learning approaches. The system
learns from its optimization history to avoid past mistakes and to accelerate
convergence. The inherent explainability makes this a powerful tool for analog
design space exploration and a new paradigm in analog EDA, where AI agents
serve as transparent design assistants.

</details>


### [107] [Shrinking the Variance: Shrinkage Baselines for Reinforcement Learning with Verifiable Rewards](https://arxiv.org/abs/2511.03710)
*Guanning Zeng,Zhaoyi Zhou,Daman Arora,Andrea Zanette*

Main category: cs.LG

TL;DR: 提出一种基于收缩估计的基线方法，通过结合每个提示和跨提示的均值来改进强化学习中的奖励均值估计，降低策略梯度估计的方差。


<details>
  <summary>Details</summary>
Motivation: 在强化学习可验证奖励(RLVR)中，通常使用每个提示的经验均值作为基线来稳定训练。但在低生成情况下，这种估计不够准确，需要改进均值估计方法。

Method: 受Stein悖论启发，提出收缩估计器，将每个提示的均值和跨提示均值结合起来，构建收缩基线作为现有方法的直接替代。

Result: 理论上证明了收缩基线能产生更低方差的策略梯度估计器；实证上收缩基线始终优于标准经验均值基线，导致梯度更新方差更低和训练稳定性提高。

Conclusion: 收缩基线方法无需额外超参数或计算，能有效改进RLVR训练，是现有基线方法的有效替代方案。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a
powerful paradigm for post-training large reasoning models (LRMs) using
policy-gradient methods such as GRPO. To stabilize training, these methods
typically center trajectory rewards by subtracting the empirical mean for each
prompt. Statistically, this centering acts as a control variate (or baseline),
reducing the variance of the policy-gradient estimator.
  Typically, the mean reward is estimated using per-prompt empirical averages
for each prompt in a batch. Drawing inspiration from Stein's paradox, we
propose using shrinkage estimators that combine per-prompt and across-prompt
means to improve the overall per-prompt mean estimation accuracy --
particularly in the low-generation regime typical of RLVR. Theoretically, we
construct a shrinkage-based baseline that provably yields lower-variance
policy-gradient estimators across algorithms. Our proposed baseline serves as a
drop-in replacement for existing per-prompt mean baselines, requiring no
additional hyper-parameters or computation. Empirically, shrinkage baselines
consistently outperform standard empirical-mean baselines, leading to
lower-variance gradient updates and improved training stability.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [108] [Oscillatons in Scalar-Field Dark Matter from a Full Fourier Expansion of an Exponential Potential](https://arxiv.org/abs/2511.02878)
*A. Mahmoodzadeh,K Ghaderi,P. Amiri*

Main category: gr-qc

TL;DR: 该论文开发了具有指数自相互作用的振荡子（oscillatons）的完整傅里叶处理方法，统一了二次、四次和更高阶相互作用，并数值求解了径向剖面边界值问题。


<details>
  <summary>Details</summary>
Motivation: 振荡子作为标量场暗物质（SFDM）的候选者需要更完整的理论处理，特别是统一不同阶数的自相互作用并准确计算其物理观测量。

Method: 采用傅里叶（Jacobi-Anger）展开处理度规和势的时间依赖性，通过贝塞尔级数截断数值求解无量纲边界值问题。

Result: 计算了时间分辨和时间平均的观测量（能量密度、径向能流、压力、总质量等），发现几何只包含基频的偶次谐波，径向能流主要在2倍基频振荡。

Conclusion: 该框架为SFDM振荡子的稳定性分析和观测约束提供了可重现和可扩展的基线。

Abstract: Real, time-dependent scalar fields can form oscillating, self-gravitating
configurations-oscillatonsthat are viable candidates for scalar-field dark
matter (SFDM). We revisit oscillatons with an exponential self-interaction and
develop a full Fourier (Jacobi{Anger) treatment that resums the time dependence
of both the metric and the potential, thereby unifying quadratic, quartic, and
higher-order interactions within a single framework. After fixing the
small-amplitude normalization V0 = m2 {\Phi}=({\lambda}2k0), we derive a
closed, dimensionless boundary-value problem for the radial profiles and solve
it numerically via Bessel-series truncation with controlled convergence. We
compute time-resolved and time-averaged observables energy density, radial
energy flux, radial/tangential pressures, and total mass and map their
dependence on the coupling {\lambda} and central amplitude. The geometry
exhibits only even harmonics of the fundamental frequency, while composite
observables inherit a DC part plus even harmonics; the radial flux oscillates
predominantly at 2!. Apparent negative instantaneous pressures arise from
coherent oscillations and are assessed consistently through classical
energy-condition diagnostics (WEC/NEC/SEC). Our formulation provides a
reproducible and extensible baseline for stability analyses and observational
constraints on SFDM oscillatons

</details>


### [109] [Mechanics of non-Killing horizons](https://arxiv.org/abs/2511.02911)
*Francesco Del Porro,Jacopo Mazza*

Main category: gr-qc

TL;DR: 该论文研究了非基林视界的力学性质，包括三种表面引力的定义、Smarr公式的推导、霍金辐射谱的计算，以及黑洞力学四定律在非基林视界情况下的状态。


<details>
  <summary>Details</summary>
Motivation: 研究超越广义相对论的旋转黑洞中出现的非基林视界，这些视界不满足圆对称性，需要重新理解其热力学性质。

Method: 定义并计算了三种表面引力（非亲和性、法向和剥离），推导了Smarr公式，通过隧穿方法计算霍金辐射谱，并分析了黑洞力学四定律。

Result: 发现非亲和性与法向表面引力通常不同，而法向与剥离表面引力总是一致，但都不恒定；霍金辐射温度由非恒定的剥离表面引力控制。

Conclusion: 研究结果为超越广义相对论的黑洞热力学提供了更深入的理解基础，特别是在非基林视界情况下的热力学定律适用性。

Abstract: We investigate the mechanics of stationary axisymmetric non-Killing horizons,
which emerge in spacetimes that do not enjoy the symmetry known as circularity
-- as is commonly the case for rotating black holes beyond general relativity.
Specifically, we define and compute three notions of surface gravity:
inaffinity, normal, and peeling; and find that the inaffinity and normal
definitions generically differ, while the normal and peeling definitions always
agree, although none of them is constant over the horizon. We then derive a
version of Smarr's formula, which appears to involve an average over the
horizon of the normal surface gravity. We also compute, via the tunnelling
method, the spectrum of Hawking's radiation, verifying that its temperature is
controlled by the (non-constant) peeling surface gravity. Finally, we
recapitulate the status of the four laws of black hole mechanics in situations
in which the event horizon fails to be Killing. Our results thus pave the way
to a deeper understanding of black hole thermodynamics beyond general
relativity.

</details>


### [110] [Accuracy of ringdown models calibrated to numerical relativity simulations](https://arxiv.org/abs/2511.02915)
*Francesco Crescimbeni,Gregorio Carullo,Emanuele Berti,Giada Caneva Santoro,Mark Ho-Yeuk Cheung,Paolo Pani*

Main category: gr-qc

TL;DR: 该研究系统评估了黑洞合并后引力波信号中环降模型在早期时间段的准确性，发现对于主模式(2,2)匹配度较高，但高阶模式需要改进以满足未来探测器的灵敏度要求。


<details>
  <summary>Details</summary>
Motivation: 环降模型目前只在晚期稳定阶段准确，需要了解这些模型在早期时间段的鲁棒性以及能否准确恢复更多信号部分。

Method: 通过时域计算，比较非进动准圆形环降模型与SXS数值相对论波形之间的失配度，分析不同谐波模式的性能。

Result: 最佳模型在(2,2)谐波上的失配度通常在[10^{-6}, 10^{-4}]范围内，高阶模式的失配度在[10^{-4}, 10^{-2}]范围内。

Conclusion: 研究结果为指导准正规模式的观测搜索提供了信息，并强调了改进高阶模式建模以满足未来引力波探测器灵敏度需求的必要性。

Abstract: The ''ringdown'' stage of gravitational-wave signals from binary black hole
mergers, mainly consisting of a superposition of quasinormal modes emitted by
the merger remnant, is a key tool to test fundamental physics and to probe
black hole dynamics. However, ringdown models are known to be accurate only in
the late-time, stationary regime. A key open problem in the field is to
understand if these models are robust when extrapolated to earlier times, and
if they can faithfully recover a larger portion of the signal. We address this
question through a systematic time-domain calculation of the mismatch between
non-precessing, quasi-circular ringdown models parameterised by the progenitor
binary's degrees of freedom and full numerical relativity
inspiral-merger-ringdown waveforms from the Simulating eXtreme Spacetimes (SXS)
simulation catalog. For the best-performing models, the mismatch is typically
in the range $[10^{-6}, 10^{-4}]$ for the $(\ell,|m|)= (2,2)$ harmonic, and
$[10^{-4}, 10^{-2}]$ for higher-order modes. Our findings inform ongoing
observational searches for quasinormal modes, and underscore the need for
improved modeling of higher-order modes to meet the sensitivity requirements of
future gravitational-wave detectors.

</details>


### [111] [Dark matter halo as a source of regular black-hole geometries](https://arxiv.org/abs/2511.03066)
*R. A. Konoplya,A. Zhidenko*

Main category: gr-qc

TL;DR: 构建无曲率奇点的精确黑洞解，由暗物质晕的星系密度分布描述，采用径向压力与密度的关系确保几何正则性，产生渐近平坦的无奇点黑洞解，并证明其稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决传统黑洞解中的曲率奇点问题，通过暗物质晕的密度分布构建正则的几何结构，探索黑洞与暗物质环境的相互作用。

Method: 采用径向压力与密度的关系$P_r = -\rho$，结合Einasto和Dehnen型暗物质晕密度分布，构建渐近平坦的无奇点黑洞解，分析轴向扰动稳定性、阴影半径和Lyapunov指数。

Result: 成功构建了由暗物质晕包围的无奇点黑洞解，证明其在轴向扰动下稳定，计算了光子圆轨道的阴影半径和Lyapunov指数。

Conclusion: 暗物质晕的足够密集密度分布可以产生正则的、渐近平坦的黑洞解，这些解在物理上是稳定的，为研究黑洞与暗物质的相互作用提供了新视角。

Abstract: We construct exact black-hole solutions free of curvature singularities,
sourced by dark matter halos described by galactic density profiles. Regularity
of the geometry is ensured by adopting the relation $P_{r}=-\rho$ between
radial pressure and density, which is consistent with the phenomenological
freedom of halo models. In particular, the sufficiently dense Einasto and
Dehnen-type profiles for the dark matter halo can produce asymptotically flat
solutions of singularity-free black holes embedded in the galactic environment.
The resulting regular black holes surrounded by dark matter are shown to be
stable under axial perturbations. We further compute the shadow radii and
Lyapunov exponents associated with the photon circular orbits around these
black holes.

</details>


### [112] [Fast and accurate analytical formulas for light propagation in general static, spherically symmetric spacetimes](https://arxiv.org/abs/2511.03144)
*Jonathan Claros,Emanuel Gallo*

Main category: gr-qc

TL;DR: 扩展了先前关于光线在致密天体附近传播的解析公式，使其适用于更广泛的球对称静态时空，包括Johansen-Psaltis和Rezzolla-Zhidenko度规族，保持了原方法的简洁性和准确性。


<details>
  <summary>Details</summary>
Motivation: 将先前仅适用于特定度规的光线传播解析公式推广到更一般的球对称静态时空，以处理更广泛的偏离Schwarzschild几何的情况。

Method: 开发了广义解析公式，建立了发射点与渐近观测者图像平面之间的近似映射关系，支持快速解析计算。

Result: 成功计算了多个度规族的等径向曲线，以及黑洞附近轨道热点的Stokes参数Q和U，展示了相应的偏振(QU)曲线。

Conclusion: 提出的广义公式在保持简洁准确的同时，能够处理更一般的时空度规，为吸积盘成像、辐射偏振、脉冲星光变曲线等应用提供了快速解析计算工具。

Abstract: In this article, we extend our previously presented analytical formulas
(Phys.Rev.D 109 (2024) 12, 124055) for describing light rays passing near or
emitted in the vicinity of compact objects to a broader class of spherically
symmetric, static spacetimes, including the Johansen-Psaltis and
Rezzolla-Zhidenko metric families. The generalized formulas retain the
simplicity and accuracy of the original approach while allowing for more
general deviations from Schwarzschild geometry. These expressions provide an
approximate yet accurate mapping between emission points and the image plane of
an asymptotic observer, enabling fast analytical computations of accretion disk
images, polarization of the emitted radiation, luminosity curves associated
with pulsars, and other related applications. As examples, we compute isoradial
curves for several metric families and the Stokes parameters Q and U for a hot
spot orbiting near a black hole described by one of the studied metrics,
presenting the corresponding polarization (QU) curves.

</details>


### [113] [Full Classification of Static Spherical Vacuum Solutions to Bumblebee Gravity with General VEVs](https://arxiv.org/abs/2511.03231)
*Jie Zhu,Hao Li*

Main category: gr-qc

TL;DR: 研究了bumblebee引力模型中静态球对称真空解，发现当参数ξ=κ/2时理论退化，且该引力模型允许存在非零物质分布时的精确Schwarzschild解，这可能使太阳系内的实验约束失效。


<details>
  <summary>Details</summary>
Motivation: 研究bumblebee引力模型中具有不同真空期望值的静态球对称真空解，探索该理论与广义相对论的差异。

Method: 分析bumblebee引力模型中bumblebee场Bμ具有空间类、光类和时类真空期望值bμ时的静态球对称真空解，并进行系统分类。

Result: 发现当参数ξ=κ/2时理论退化，解可由任意函数表征；且与广义相对论不同，bumblebee引力允许存在非零物质分布时的精确Schwarzschild解。

Conclusion: bumblebee引力模型在特定参数下理论定义不完善，且其允许的精确Schwarzschild解可能使太阳系内的实验约束失效。

Abstract: The static spherical vacuum solution in a bumblebee gravity model where the
bumblebee field $B_\mu$ has a two-component space-like, light-like, and
time-like vacuum expectation value $b_\mu$ is studied. Based on the results, we
present a comprehensive classification of the static spherical vacuum solutions
in bumblebee gravity with general vacuum expectation values. We find that the
model becomes degenerate for a specific set of parameter combinations, where
the solution can be characterized by an arbitrary function, which indicates
that the non-minimally coupled massless vector tensor theory is ill-defined
when $\xi=\kappa/2$. We also find that contrary to the situation in general
relativity, the bumblebee gravity admits the exact Schwarzschild solution with
non-zero matter distributions of certain forms. The implications of this result
are discussed, suggesting that the experimental constraints within the solar
system would be invalid.

</details>


### [114] [Viscous Fluid Models of Cosmic Acceleration in FRW Spacetime Using MCMC Constraints](https://arxiv.org/abs/2511.03258)
*Mohit Thakre,Praveen Kumar Dhankar,Behnam Pourhassan,Safiqul Islam*

Main category: gr-qc

TL;DR: 本研究结合理论进展和观测限制，在(3+1)维时空框架下研究具有体粘性的修正Chaplygin气体(MCG)的宇宙学意义，通过MCMC方法使用Hubble和BAO数据集进行观测分析。


<details>
  <summary>Details</summary>
Motivation: 研究体粘性修正Chaplygin气体在宇宙学中的影响，特别是解决Chaplygin气体模型在更高维度中结构形成振荡的问题。

Method: 提供粘性和非粘性情况的解析解，通过三种不同条件创建模型：无粘性、有粘性、以及忽略粘性和Chaplygin气体。使用MCMC方法结合Hubble和BAO数据集进行观测分析。

Result: 体粘性抑制了结构形成中的振荡，这是Chaplygin气体模型在更大维度中的已知缺点。通过扰动分析验证了这一结果。

Conclusion: 体粘性修正Chaplygin气体模型能够有效抑制结构形成中的振荡问题，为宇宙学模型提供了改进方案。

Abstract: This study combines theoretical advancements with observational limitations
to investigate the cosmological implications of a bulk viscous modified
Chaplygin gas (MCG) in a Friedmann--Robertson--Walker (FRW) in (3+1)
dimensional spacetime framework. We provide analytical solutions for both
viscous and non-viscous cases, pointing out variations in the energy density
evolution, the Hubble parameter dynamics, and the deceleration parameter
transitions. Bulk viscosity suppresses oscillations in structure creation, a
well-known drawback of Chaplygin gas models in larger dimensions, as shown by a
thorough perturbation analysis. Using the bulk viscosity coefficient and Hubble
expansion parameter, which are incorporated by the total pressure and the
appropriate pressure and by using energy momentum conservation law determined
time time-dependent density. With the help of three conditions ($\xi = 0$,
$\xi\neq0$, and we neglect both bulk viscosity and presence of Chaplygin gas,
i.e $A=0$ and $\xi=0$) created three different models as the Hubble parameter
is a function of redshift $z$. By applying the MCMC method to these models, we
have gone through observational analysis by using the Hubble and BAO datasets.

</details>


### [115] [Dynamic and Thermodynamic Stability of Superconducting-superfluid Stars](https://arxiv.org/abs/2511.03259)
*Delong Kong,Yu Tian,Hongbao Zhang*

Main category: gr-qc

TL;DR: 本文通过Iyer-Wald形式体系分析了中子星超导-超流体混合物的动态和热力学稳定性，建立了动态稳定性与热力学稳定性之间的等价关系。


<details>
  <summary>Details</summary>
Motivation: 研究超导-超流体混合物组成的中子星的稳定性问题，探索动态平衡与热力学平衡之间的关系。

Method: 使用Iyer-Wald形式体系构建相空间和正则能量，分析轴对称扰动下的动态稳定性，并在拉格朗日位移框架下研究固定角动量情况。

Result: 证明了动态稳定性与正则能量非负性等价，轴对称受限扰动稳定性保证所有轴对称扰动稳定性，并建立了球对称扰动下动态与热力学稳定性的等价关系。

Conclusion: 成功建立了中子星超导-超流体混合物动态稳定性与热力学稳定性之间的数学等价关系，为理解这类天体的稳定性提供了理论基础。

Abstract: We give a comprehensive analysis of the dynamic and thermodynamic stability
of neutron stars composed of superconducting-superfluid mixtures within the
Iyer-Wald formalism. We derive the first law of thermodynamics and the
necessary and sufficient condition under which dynamic equilibrium implies
thermodynamic equilibrium. By constructing the phase space and canonical
energy, we show that the dynamic stability for perturbations, restricted in
symplectic complement of trivial perturbations with the ADM 3-momentum
unchanged, is equivalent to the non-negativity of the canonical energy.
Furthermore, dynamic stability against restricted axisymmetric perturbations
guarantees the dynamic stability against all axisymmetric perturbations. We
also prove that the positivity of canonical energy on all axisymmetric
perturbations within the Lagrangian displacement framework with fixed angular
momentum is necessary for thermodynamic stability. In particular, the
equivalence of dynamic and thermodynamic stability for spherically symmetric
perturbations of static, spherically symmetric isentropic configurations is
established.

</details>


### [116] [Wormhole spacetimes in an expanding universe: energy conditions and future singularities](https://arxiv.org/abs/2511.03275)
*Taishi Katsuragawa,Shin'ichi Nojiri,Sergei D. Odintsov*

Main category: gr-qc

TL;DR: 研究在膨胀宇宙中嵌入的虫洞几何，使用四标量非线性σ模型，其中目标空间度量与时空Ricci张量等同。虫洞在违反传统能量条件时仍能保持稳定，但加入宇宙膨胀后，有效能量密度和压力被宇宙流体修正，使能量条件得以满足。


<details>
  <summary>Details</summary>
Motivation: 探索在膨胀宇宙背景下虫洞的稳定性，以及如何通过四标量非线性σ模型构造满足能量条件的虫洞解，特别是基于暗物质晕轮廓的虫洞构造。

Method: 使用四标量非线性σ模型，将目标空间度量等同于时空Ricci张量，分析虫洞在膨胀宇宙中的几何特性，并构造基于暗物质晕轮廓的虫洞解。

Result: 发现虫洞在膨胀宇宙中可以保持稳定，即使违反传统能量条件；构造出有趣的几何结构，其中有限未来奇点出现在一个宇宙但不在连接的另一个宇宙中；成功构造基于暗物质晕轮廓的虫洞解。

Conclusion: 四标量非线性σ模型为构造稳定虫洞提供了有效框架，膨胀宇宙背景可以修正能量条件，虫洞可能作为连接不同宇宙的通道，甚至在奇点事件中提供逃生路径。

Abstract: We study wormhole geometries embedded in an expanding universe within a
four-scalar non-linear $\sigma$ model, where the target-space metric is
identified with the spacetime Ricci tensor. In this framework, wormholes can
remain stable even when conventional energy conditions are violated. However,
once cosmological expansion is included, the effective energy density and
pressure are modified by the cosmological fluid, enabling the energy conditions
to be satisfied. We further present intriguing geometries in which a finite
future singularity appears in our universe but not in another universe
connected by the wormhole. Near the throat, the hypersurface becomes timelike,
allowing trajectories to traverse to the other universe before the singularity
and return afterwards. We also construct wormhole solutions motivated by
galactic dark-matter halo profiles, where the required non-vanishing pressure
arises naturally from the four-scalar non-linear $\sigma$ model.

</details>


### [117] [Deflection of Massive Spin-$\frac{1}{2}$ Particles around Kerr Black Hole](https://arxiv.org/abs/2511.03451)
*Haida Li,Xiangdong Zhang*

Main category: gr-qc

TL;DR: 通过研究极化量子自旋-1/2粒子在经典克尔黑洞周围的偏转临界半径，为测量中微子质量和其他超轻粒子质量提供新的测试方法。


<details>
  <summary>Details</summary>
Motivation: 中微子质量的精确测量是一个长期未解决的问题，目前主要通过理论和实验提供质量上限。本文旨在为测量中微子质量和其他超轻粒子质量提供额外的测试场所。

Method: 使用量子狄拉克方程推导极化自旋-1/2粒子束的MPD类方程，将有效自旋与粒子固有量子自旋等同，确认MPD方程可应用于粒子固有自旋。

Result: 对于质量为1 eV/c²的自旋-1/2粒子在太阳质量克尔黑洞周围的偏转，可获得相对幅度>10^{-12}的修正。

Conclusion: 虽然高度理论化，但基于量子自旋修正的行为，提出了提取单个中微子质量下限的新方法。

Abstract: The exact measurement of neutrino mass remains a longstanding issue. So far,
there has been much success in providing an upper bound for the neutrino rest
mass, both theoretically and experimentally. In this work, by exploring the
critical radius of a beam of polarized quantum spin-$\frac{1}{2}$ particle
deflecting around a classical Kerr black hole, we attempt to provide an
additional testing ground for neutrino mass, as well as the mass of other
proposed ultra-light particles yet to be determined. Notably, the quantum Dirac
equation is used to derive a MPD-like equation satisfied by the polarized beam
of massive spin-$\frac{1}{2}$ particles and identify the effective spin in the
spin tensor with the particle's intrinsic quantum spin, confirming the previous
theoretical result that the MPD equation can be in fact applied to particles'
intrinsic spin. The result of this work shows that corrections of relative
magnitude $>10^{-12}$ can be achieved for spin-$\frac{1}{2}$ particles with
rest mass equal to $1 eV/c^2$ deflecting around a solar mass Kerr black hole.
Although highly theoretical, a new method of extracting the lower bound for the
neutrino mass individually is also proposed due to the behavior of the quantum
spin correction.

</details>


### [118] [Wald Entropy in Extended Modified Myrzakulov Gravity Theories: \(f(R, T, Q, R_{μν}T^{μν}, R_{μν}Q^{μν}, \dots)\)](https://arxiv.org/abs/2511.03509)
*Davood Momeni,Ratbay Myrzakulov*

Main category: gr-qc

TL;DR: 本文研究了修正Myrzakulov引力理论中的黑洞熵，这些理论由广义拉格朗日量定义，包含曲率、挠率和非度量性标量。使用标架形式推导了Wald熵，分析了额外几何自由度如何修正熵表达式。


<details>
  <summary>Details</summary>
Motivation: 研究非黎曼几何背景下引力理论的黑洞熵，探索额外几何自由度对熵表达式的修正，完善扩展几何设置中的引力热力学理论框架。

Method: 使用标架形式，推导了广义拉格朗日量 \( \\mathcal{L} = \\alpha R + F(T, Q, R_{\\mu\\nu}T^{\\mu\\nu}, R_{\\mu\\nu}Q^{\\mu\\nu}, \\dots) \) 的Wald熵公式，涵盖曲率、挠率和非度量性标量。

Result: 分析表明，修正项系统地来源于作用量的扩展结构，并保持微分同胚不变性。这些结果将经典熵公式扩展到非黎曼几何设置。

Conclusion: 研究为扩展几何设置中的引力热力学提供了更完善的理论框架，揭示了额外几何自由度对黑洞熵的系统性修正。

Abstract: We investigate black hole entropy in a broad class of modified Myrzakulov
gravity theories defined by generalized Lagrangians of the form \( \mathcal{L}
= \alpha R + F(T, Q, R_{\mu\nu}T^{\mu\nu}, R_{\mu\nu}Q^{\mu\nu}, \dots) \),
where \( R \), \( T \), and \( Q \) represent curvature, torsion, and
non-metricity scalars. Using the vielbein formalism, we derive the Wald entropy
for various subclasses of these models, extending the classical entropy formula
to accommodate non-Riemannian geometry. Our focus is on how the additional
geometric degrees of freedom modify the entropy expression. The analysis shows
that such corrections arise systematically from the extended structure of the
action and preserve diffeomorphism invariance. These results refine the
theoretical framework for gravitational thermodynamics in extended geometry
settings.

</details>


### [119] [Gravitational waves in Cubic Metric-Affine Gravity](https://arxiv.org/abs/2511.03574)
*Sebastian Bahamonde,Jorge Gigante Valcarcel,José M. M. Senovilla*

Main category: gr-qc

TL;DR: 在三次度量-仿射引力框架下推导了具有动态挠率和非度量率张量的新精确引力波解，这些解代表pp波，在引力波谱中引入了标量极化模式。


<details>
  <summary>Details</summary>
Motivation: 在度量-仿射引力理论中探索包含动态挠率和非度量率的引力波解，超越广义相对论的张量极化模式，提供独特的现象学特征。

Method: 采用三次度量-仿射引力模型，考虑引力场的完整代数分类，对场强张量施加Type N条件，消除理论中矢量和轴向扇区的幽灵不稳定性。

Result: 获得了包含挠率和非度量率张量动力学贡献的pp波解，这些量在引力波谱中诱导出标量极化模式。

Conclusion: 三次度量-仿射引力模型能够产生包含标量极化模式的引力波解，这为超越广义相对论的现象学提供了独特的实验特征。

Abstract: We derive new exact gravitational wave solutions with dynamical torsion and
nonmetricity tensors in the framework of cubic Metric-Affine Gravity (MAG). For
this purpose, we consider the full algebraic classification of the
gravitational field in general metric-affine geometries and impose a set of
Type N conditions on the field strength tensors that implement the kinetics of
torsion and nonmetricity in a particular cubic MAG model, recently considered
to eliminate ghostly instabilities from the vector and axial sectors of the
theory. The new solutions represent pp-waves characterised by a metric function
that includes the dynamical contributions of the torsion and nonmetricity
tensors provided by the field equations of the model. In particular, these
quantities induce a scalar polarisation mode in the gravitational-wave
spectrum, thus offering a distinctive phenomenological signature beyond the
ordinary tensor polarisation modes of General Relativity.

</details>


### [120] [Extreme-Mass-Ratio Inspirals Embedded in Dark Matter Halo I:Existence of Homoclinic Orbit and Near-Horizon Chaos](https://arxiv.org/abs/2511.03657)
*Surajit Das,Surojit Dalui,Bum-Hoon Lee,Yi-Fu Cai*

Main category: gr-qc

TL;DR: 研究施瓦西黑洞在Dehnen型暗物质晕中的粒子动力学，发现暗物质晕会改变时空曲率，导致有效势变形，从而产生同宿轨道和混沌运动。


<details>
  <summary>Details</summary>
Motivation: 探索在暗物质晕环境中黑洞附近粒子运动的动力学稳定性变化，特别是混沌现象的出现及其对引力波信号的可能影响。

Method: 使用哈密顿公式推导不稳定圆轨道和同宿轨道条件，分析有效势和相空间结构，通过庞加莱截面和李雅普诺夫指数进行数值分析。

Result: 增加暗物质晕密度、尺度半径和能量会放大非线性效应，最终导致混沌，但不会违反混沌的普适表面引力界限。

Conclusion: 暗物质晕环境显著改变粒子运动的动力学稳定性，为探索极端质量比旋进系统中引力波信号的混沌印记提供理论基础。

Abstract: We study the existence of homoclinic orbit and the onset of chaotic motion
for a massive particle moving around a Schwarzschild-like black hole embedded
in a Dehnen-(1,4,5/2) type dark matter halo, within the extreme-mass-ratio
limit q = m/M << 1, where m and M are the masses of the particle and the
central black hole, respectively. The presence of the halo modifies the
spacetime curvature and consequently deforms the effective potential governing
the particle's motion. Using the Hamiltonian formulation, we derive the
conditions under which unstable circular orbit and the associated homoclinic
trajectory arise, marking the separatrix between bound and plunging motion. By
analyzing the effective potential and the corresponding phase-space structure,
we identify the transition from regular to chaotic dynamics in the near-horizon
region. Numerical analyses through Poincare sections and Lyapunov exponents
calculations demonstrate that increasing the halo density, scale radius along
with energy amplifies nonlinear effects which leads to chaos eventually. We
demonstrate that within a dark matter halo environment, the dynamical stability
of particle motion can be significantly altered without violating the universal
surface gravity bound on chaos. This work provides a deeper understanding of
horizon-induced chaos in astrophysically realistic environments and serves as a
theoretical basis for exploring its possible imprints on gravitational wave
signals in extreme-mass-ratio inspirals system.

</details>
