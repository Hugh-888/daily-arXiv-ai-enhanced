<div id=toc></div>

# Table of Contents

- [physics.comp-ph](#physics.comp-ph) [Total: 2]
- [quant-ph](#quant-ph) [Total: 54]
- [cs.LG](#cs.LG) [Total: 87]
- [gr-qc](#gr-qc) [Total: 15]


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [1] [Design of a specimen to train path-dependent deep learning material models from a single uniaxial test: eliciting strain diversity via automatically differentiable elastoplastic topology optimization](https://arxiv.org/abs/2512.14963)
*Shunyu Yin,Bernardo P. Ferreira,Gawel Kus,Miguel A. Bessa*

Main category: physics.comp-ph

TL;DR: 提出一种通过拓扑优化设计单试样进行简单单轴加载，即可训练神经网络材料模型的方法，大幅减少实验数据需求。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络材料模型训练需要大量多样的应力-应变数据，通常通过合成单元模拟获得。物理实验中标准试样的简单几何形状无法产生足够多样的应力-应变轨迹，导致需要大量实验或复杂多轴测试，阻碍了实际应用。

Method: 使用新型自动可微分弹塑性拓扑优化方法设计试样，使单个试样在简单单轴加载下能产生多样化的应力-应变状态；然后采用自动可微分模型更新（ADiMU）方法训练神经网络代理模型。

Result: 证明拓扑优化试样在简单加载下能够训练大型神经网络，显著减少数据驱动材料建模的实验负担。

Conclusion: 通过拓扑优化设计试样，可以在单个简单加载实验中产生足够多样的应力-应变状态，从而有效训练神经网络材料模型，大大降低了实验数据获取的难度和成本。

Abstract: Artificial neural networks accurately learn nonlinear, path-dependent material behavior. However, training them typically requires large, diverse datasets, often created via synthetic unit cell simulations. This hinders practical adoption because physical experiments on standardized specimens with simple geometries fail to generate sufficiently diverse stress-strain trajectories. Consequently, an unreasonably large number of experiments or complex multi-axial tests would be needed. This work shows that such networks can be trained from a single specimen subjected to simple uniaxial loading, by designing the specimen using a novel automatically differentiable elastoplastic topology optimization method. Our strategy diversifies the stress-strain states observed in a single test involving plastic deformation. We then employ the automatically differentiable model updating (ADiMU) method to train the neural network surrogates. This work demonstrates that topology-optimized specimens under simple loading can train large neural networks, thereby substantially reducing the experimental burden associated with data-driven material modeling.

</details>


### [2] [UGKS and UGKWP Methods for Multiscale Simulation of Electrostatic Plasma in Quasineutral and Hydrodynamic Limits](https://arxiv.org/abs/2512.15406)
*Zhigang Pu,Kun Xu*

Main category: physics.comp-ph

TL;DR: 扩展统一气体动力学格式(UGKS)和统一气体动力学波粒子方法(UGKWP)用于静电等离子体建模，确保在德拜长度和平均自由程两个尺度上都保持正确的渐近极限。


<details>
  <summary>Details</summary>
Motivation: 现有方法在等离子体建模中存在两个主要限制：1) 平均自由程相关的流体极限约束；2) 准中性区域中标准泊松方程的低效性。需要开发能够同时克服德拜长度和平均自由程分辨率约束的方法。

Method: 1) 在数值通量中耦合碰撞和输运过程，消除平均自由程相关的流体极限约束；2) 引入重新表述的泊松方程，与宏观矩方程耦合，提高准中性区域的效率；3) 扩展UGKS和UGKWP方法用于静电等离子体建模。

Result: 通过线性和非线性朗道阻尼以及"驼峰尾"不稳定性等基准测试验证了方法的准确性和渐近一致性。结果表明，该方法能够在流体和准中性区域中稳健地捕获等离子体动力学，不受德拜长度或平均自由程的分辨率约束。

Conclusion: 提出的方法成功扩展了UGKS和UGKWP用于等离子体建模，有效克服了德拜长度和平均自由程的分辨率约束，能够在从流体到准中性的广泛区域中准确模拟等离子体动力学。

Abstract: This study extends the Unified Gas-Kinetic Scheme (UGKS) and the Unified Gas-Kinetic Wave-Particle (UGKWP) method for electrostatic plasma modeling, ensuring the correct asymptotic limits with respect to both the Debye length and the mean free path. By coupling collision and transport processes within the numerical flux, the proposed approach effectively removes the hydrodynamic-limit constraint associated with the mean free path. In addition, a reformulated Poisson equation, coupled with the macroscopic moment equations, is introduced to overcome the inefficiency of the standard Poisson formulation in the quasineutral regime. The accuracy and asymptotic consistency of the proposed schemes are verified through several benchmark tests, including linear and nonlinear Landau damping and the bump-on-tail instability. The results demonstrate that the methods robustly capture plasma dynamics across hydrodynamic and quasineutral regimes, without resolution constraints imposed by either the Debye length or the mean free path.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [3] [Information-Theoretic Constraints on Variational Quantum Optimization: Efficiency Transitions and the Dynamical Lie Algebra](https://arxiv.org/abs/2512.14701)
*Jun Liang Tan*

Main category: quant-ph

TL;DR: 论文提出从信息论角度理解变分量子算法中的Barren Plateau现象，通过相干反馈控制建立功提取与互信息的经验关系，发现系统效率由动力学李代数维度决定，多项式复杂度系统保持正效率，指数复杂度系统在约6个量子比特时发生效率崩溃。


<details>
  <summary>Details</summary>
Motivation: 传统上Barren Plateau现象被归因于几何梯度消失，但作者希望从信息论角度重新理解这一限制变分量子算法可扩展性的关键问题，探索量子反馈控制与算法可训练性之间的深层联系。

Method: 使用辅助量子比特介导的相干反馈控制，建立功提取ΔE与互信息I(S:A)之间的经验本构关系ΔE ≤ ηI(S:A)。通过缩放系统规模，分析不同复杂度系统的效率转变，特别关注动力学李代数维度的影响。

Result: 发现量子纠缠相比经典Landauer界限提供2倍优势。系统效率转变由动力学李代数维度决定：多项式代数复杂度系统保持持续正效率，而指数复杂度系统在N≈6个量子比特时发生效率崩溃（η→0）。

Conclusion: 变分量子算法中的可训练性边界与量子反馈控制的信息论极限相关，效率崩溃现象为理解Barren Plateau提供了新的信息论视角，对近量子优势算法的设计有重要启示。

Abstract: Variational quantum algorithms are the leading candidates for near-term quantum advantage, yet their scalability is limited by the ``Barren Plateau'' phenomenon. While traditionally attributed to geometric vanishing gradients, we propose an information-theoretic perspective. Using ancilla-mediated coherent feedback, we demonstrate an empirical constitutive relation $ΔE \leq ηI(S:A)$ linking work extraction to mutual information, with quantum entanglement providing a factor-of-2 advantage over classical Landauer bounds. By scaling the system size, we identify a distinct efficiency transition governed by the dimension of the Dynamical Lie Algebra. Systems with polynomial algebraic complexity exhibit sustained positive efficiency, whereas systems with exponential complexity undergo an ``efficiency collapse'' ($η\to 0$) at $N \approx 6$ qubits. These results suggest that the trainability boundary in variational algorithms correlates with information-theoretic limits of quantum feedback control.

</details>


### [4] [Quantum Resource Analysis of Low-Round Keccak/SHA-3 Preimage Attack: From Classical 2^57.8 to Quantum 2^28.9 using Qiskit Modeling](https://arxiv.org/abs/2512.14759)
*Ramin Rezvani Gilkolae*

Main category: quant-ph

TL;DR: 量子计算机使用Grover算法加速Keccak-256三轮预像攻击在理论上可行，但实际硬件开销巨大，导致攻击完全不可行，SHA-3安全性不受量子计算机威胁。


<details>
  <summary>Details</summary>
Motivation: 分析Grover算法在量子计算机上加速经典Keccak-256预像攻击的实际可行性，揭示理论量子加速与实际硬件实现之间的巨大差距。

Method: 使用Qiskit进行电路合成，量化分析3轮Keccak量子预言机所需的资源：Toffoli门数量、逻辑量子比特数、总双量子比特门数、物理量子比特需求以及执行时间。

Result: 量子攻击需要：9,600个Toffoli门、3,200个逻辑量子比特、7.47×10¹³个双量子比特门、320万个物理量子比特（含纠错），执行时间从43天到2,365年以上，完全不可行。

Conclusion: SHA-3预像攻击不受量子计算机威胁，Grover算法的优雅渐近理论隐藏了工程开销，硬件感知的复杂度分析在量子密码分析中至关重要。

Abstract: This paper presents a hardware-conscious analysis of the quantum acceleration of the classical 3-round Keccak-256 preimage attack using Grover's Algorithm. While the theoretical quantum speed-up from T_cl=2^{57.8} (classical) to T_qu = 2^{28.9} (quantum) is mathematically sound, the practical implementation overhead is so extreme that attacks remain wholly infeasible in both resource and runtime dimensions. Using Qiskit-based circuit synthesis, we derive that a 3-round Keccak quantum oracle requires: 9,600 Toffoli gates (with uncomputation for reversibility); 3,200 logical qubits (1,600 state + 1,600 auxiliary); 7.47 * 10^{13} total 2-qubit gates (full Grover search); 3.2 million physical qubits (with quantum error correction)PROHIBITIVE; 0.12 years (43 days) to 2,365+ years execution time, depending on machine assumptions. These barriers -- particularly the physical qubit requirements, circuit depth, and error accumulation -- render the quantum attack infeasible for any foreseeable quantum computer. Consequently, SHA-3 security is not threatened by quantum computers for preimage attacks. We emphasize the critical importance of hardware-aware complexity analysis in quantum cryptanalysis: the elegant asymptotic theory of Grover's Algorithm hides an engineering overhead so prohibitive that the quantum approach becomes infeasible from both resource and implementation perspectives.

</details>


### [5] [Dawn and Twilight Time in Quantum Tunneling](https://arxiv.org/abs/2512.14809)
*Tinglong Feng,Jesse Moes,Tomislav Prokopec*

Main category: quant-ph

TL;DR: 该论文提出了一种基于实时通量定义的衰变率分析方法，通过核函数的极点-分支分解定义了量子衰变的两个关键时间尺度：黎明时间和黄昏时间，并给出了解析表达式。


<details>
  <summary>Details</summary>
Motivation: 研究量子衰变过程中指数衰减前后的非指数行为，特别是早期偏差和晚期幂律尾巴，为量子衰变提供更完整的理论描述。

Method: 采用基于实时通量的衰变率定义，对一维量子力学共振模型进行完整分析，提出核函数的极点-分支分解，定义黎明时间和黄昏时间两个可计算时间尺度。

Result: 获得了黎明时间和黄昏时间的解析表达式，其中黄昏时间可通过Lambert W函数闭式表达；对于方势垒、修正方势垒和Pöschl-Teller势垒得到了厚势垒公式，阐明了衰变率Γ、振荡周期T和透射概率T_trans之间的关系。

Conclusion: 该分析方法为量子衰变提供了统一的理论框架，其谱图方法可自然扩展到量子场论中的真空衰变研究。

Abstract: Metastable decay exhibits a familiar exponential regime bracketed by early-time deviations and late-time power-law tails. We adopt the real-time, flux-based definition of the decay rate in the spirit of Andreassen et al.\ direct method and present a complete analysis of one-dimensional quantum-mechanical resonance models. We show that the kernel admits a universal pole--plus--branch decomposition and use it to define two computable time scales: a dawn time, when a single resonant contribution starts dominating and exponential decay sets in, and a twilight time, when the branch-cut tail overtakes exponential decay. The latter can be expressed in closed form via the Lambert $W$ function, making its parametric dependence manifest without fitting. For square, modified square, and Pöschl--Teller barriers we obtain simple thick-barrier formulas, clarify the relation $ΓT = T_{\text{trans}}$ between the decay rate $Γ$, oscillation period $T$, and transmission probability $T_{\text{trans}}$, and indicate how our spectral picture can be naturally extended to quantum field theoretic vacuum decay.

</details>


### [6] [Energy Inference of Black-Box Quantum Computers Using Quantum Speed Limit](https://arxiv.org/abs/2512.15472)
*Nobumasa Ishida,Yoshihiko Hasegawa*

Main category: quant-ph

TL;DR: 提出一种通过量子速度极限和门时间放大技术，从用户可访问的执行时间数据推断黑盒量子处理器中门哈密顿量能标的方法，并在IBM超导量子处理器上验证。


<details>
  <summary>Details</summary>
Motivation: 云量子计算机不提供硬件级信息（如哈密顿量），阻碍了物理特性的表征。需要一种仅使用用户可访问数据来推断黑盒量子处理器能量尺度的方法。

Method: 利用量子速度极限（Margolus-Levitin和Mandelstam-Tamm界限）作为能量期望值和方差的估计器，将其与处理器正交化量子态的最短时间关联。通过门时间放大技术，从秒级作业执行时间推断纳秒级最短门时间。

Result: 在IBM超导量子处理器上应用该方法，估计了单比特、双比特和三比特门的能量尺度。估计的能量量级与超导量子比特系统中典型的驱动能量一致，表明当前门操作接近量子速度极限。

Conclusion: 通过操作时间测量可以定量访问黑盒量子计算机的基本能量特性，这反映了不确定性原理强加的时间与能量之间的共轭关系。

Abstract: Cloud-based quantum computers do not provide users with access to hardware-level information such as the underlying Hamiltonians, which obstructs the characterization of their physical properties. We propose a method to infer the energy scales of gate Hamiltonians in such black-box quantum processors using only user-accessible data, by exploiting quantum speed limits. Specifically, we reinterpret the Margolus-Levitin and Mandelstam-Tamm bounds as estimators of the energy expectation value and variance, respectively, and relate them to the shortest time for the processor to orthogonalize a quantum state. This shortest gate time, expected to lie on the nanosecond scale, is inferred from job execution times measured in seconds by employing gate-time amplification. We apply the method to IBM's superconducting quantum processor and estimate the energy scales associated with single-, two-, and three-qubit gates. The order of estimated energy is consistent with typical drive energies in superconducting qubit systems, suggesting that current gate operations approach the quantum speed limit. Our results demonstrate that fundamental energetic properties of black-box quantum computers can be quantitatively accessed through operational time measurements, reflecting the conjugate relationship between time and energy imposed by the uncertainty principle.

</details>


### [7] [Stabilizers may be poor bounds for fidelities](https://arxiv.org/abs/2512.14811)
*Aaron Z. Goldberg*

Main category: quant-ph

TL;DR: 论文指出，对于GKP态，稳定子期望值并不能保证态接近理想GKP态，这与常规假设相反。


<details>
  <summary>Details</summary>
Motivation: 研究GKP态的质量评估问题：能否用态在稳定子作用下的不变程度作为GKP态质量的代理指标？

Method: 通过理论分析，证明态对理想GKP态的保真度仅被稳定子期望值上界约束。

Result: 发现稳定子期望值好并不能保证态接近理想GKP态，这与常规假设相反。

Conclusion: 对于GKP编码的量子比特，仅凭稳定子期望值不能可靠评估态的质量，需要更全面的度量。

Abstract: The defining feature of ideal Gottesman-Kitaev-Preskill (GKP) states is that they are unchanged by stabilizers, which allow them to detect and correct for common errors without destroying the quantum information encoded in the states. Given this property, can one use the amount to which a state is unchanged by the stabilizers as a proxy for the quality of a GKP state? This is shown to hold in the opposite manner to which it is routinely assumed, because in fact the fidelity a state has to an ideal GKP state is only upper bounded by the stabilizer expectation values. This means that, for qubits encoded in harmonic oscillators via the GKP code, a good stabilizer expectation value does not guarantee proximity to an ideal GKP state in terms of any distance based on fidelity.

</details>


### [8] [QuantGraph: A Receding-Horizon Quantum Graph Solver](https://arxiv.org/abs/2512.15476)
*Pranav Vaidhyanathan,Aristotelis Papatheodorou,David R. M. Arvidsson-Shukur,Mark T. Mitchison,Natalia Ares,Ioannis Havoutis*

Main category: quant-ph

TL;DR: QuantGraph是一个两阶段量子增强框架，将图优化问题转化为量子搜索，通过局部阶段减少搜索空间，全局阶段利用Grover算法优化，并结合经典控制理论提高稳定性和精度。


<details>
  <summary>Details</summary>
Motivation: 传统动态规划在图优化问题中随着问题规模增大而难以扩展，需要更高效的解决方案来处理大规模图优化问题。

Method: 提出QuantGraph两阶段框架：1) 局部阶段寻找局部最优转移序列，积累成本作为阈值来剪枝搜索空间；2) 全局阶段基于该阈值使用Grover自适应搜索算法进行优化。框架还结合了模型预测控制方案来稳定和引导量子搜索。

Result: 搜索空间最多减少60%，在固定查询预算下控制离散化精度提高2倍，同时保持Grover搜索相对于经典方法的二次加速优势。

Conclusion: QuantGraph通过结合量子搜索和经典控制理论，为图优化问题提供了可扩展、鲁棒的解决方案，显著降低了计算复杂度并提高了精度。

Abstract: Dynamic programming is a cornerstone of graph-based optimization. While effective, it scales unfavorably with problem size. In this work, we present QuantGraph, a two-stage quantum-enhanced framework that casts local and global graph-optimization problems as quantum searches over discrete trajectory spaces. The solver is designed to operate efficiently by first finding a sequence of locally optimal transitions in the graph (local stage), without considering full trajectories. The accumulated cost of these transitions acts as a threshold that prunes the search space (up to 60% reduction for certain examples). The subsequent global stage, based on this threshold, refines the solution. Both stages utilize variants of the Grover-adaptive-search algorithm. To achieve scalability and robustness, we draw on principles from control theory and embed QuantGraph's global stage within a receding-horizon model-predictive-control scheme. This classical layer stabilizes and guides the quantum search, improving precision and reducing computational burden. In practice, the resulting closed-loop system exhibits robust behavior and lower overall complexity. Notably, for a fixed query budget, QuantGraph attains a 2x increase in control-discretization precision while still benefiting from Grover-search's inherent quadratic speedup compared to classical methods.

</details>


### [9] [The entangling power of non-entangling channels](https://arxiv.org/abs/2512.14819)
*Julien Pinske,Jan Sperling,Klaus Mølmer*

Main category: quant-ph

TL;DR: 非纠缠操作在特定条件下可概率性产生纠缠，这与LOCC操作不同，后者即使概率性也无法增加Schmidt数


<details>
  <summary>Details</summary>
Motivation: 研究那些本身不产生纠缠但能放大已有纠缠的过程，探索非纠缠操作在概率性条件下如何变得具有纠缠性

Method: 提出随机非纠缠映射的概念，设计量子通道的Schmidt数来量化通道概率性产生纠缠的能力，建立通道非纠缠性与其对偶映射保持见证性的等价关系

Result: 非纠缠操作仅当能以非零概率产生纠缠时才能增加量子态的Schmidt数；通道非纠缠当且仅当其保持纠缠见证；推导出Bell-like不等式来检测纠缠产生过程

Conclusion: 某些非纠缠操作在选择特定测量结果时会变得具有纠缠性，这揭示了纠缠产生的概率性本质，为检测纠缠产生过程提供了新的理论工具

Abstract: There are processes that cannot generate entanglement but may, nevertheless, amplify entanglement already present in a system. Here, we show that a non-entangling operation can increase the Schmidt number of a quantum state only if it can generate entanglement with some non-zero probability. This is in stark contrast to the case where the parties of a quantum network are only able to control their joint state by local operations and classical communication (LOCC). There, being able to apply operations probabilistically (stochastic LOCC) does not increase the Schmidt number. Our findings show that certain non-entangling operations become entangling when selecting on specific measurement outcomes. This naturally leads us to the class of stochastically non-entangling maps, being those that cannot generate entanglement even probabilistically. Intrigued by this finding, we devise a Schmidt number for quantum channels that quantifies whether a channel can generate entanglement probabilistically. Moreover, we show that a channel is non-entangling if and only if its dual map is witness-preserving -- it takes entanglement witnesses to witnesses. Based on this finding, we derive Bell-like inequalities whose violation signals that a process generates entanglement.

</details>


### [10] [Growth and spreading of quantum resources under random circuit dynamics](https://arxiv.org/abs/2512.14827)
*Sreemayee Aditya,Xhek Turkeshi,Piotr Sierant*

Main category: quant-ph

TL;DR: 研究追踪量子资源（魔法资源、相干性、费米子非高斯性）在一维量子比特链随机砖墙电路演化中的时空动力学，发现资源生成门产生先升后降的普适行为，而非资源生成但纠缠的门导致资源从初始区域向外弹道传播。


<details>
  <summary>Details</summary>
Motivation: 量子多体动力学自然产生非经典关联，这些关联可以用量子资源理论描述。理解量子资源（如魔法资源、相干性、费米子非高斯性）在局部电路中的时空演化，为更结构化的量子多体系统提供基准。

Method: 在一维量子比特链中，使用随机砖墙电路进行演化，追踪子系统中的量子资源。研究两种类型的电路：1）资源生成门电路；2）不生成资源但产生纠缠的门电路。分析资源随时间的演化行为。

Result: 对于资源生成门，从低资源态演化表现出普适的"上升-峰值-下降"行为，峰值时间与子系统大小呈对数标度，最终资源随子系统趋近最大混合态而衰减。对于非资源生成但纠缠的门，初始局限于区域的量子资源会弹道式向外传播。

Conclusion: 研究为局部电路中量子资源的时空动力学提供了统一图景，揭示了资源生成和非资源生成电路的普适行为，为更复杂的量子多体系统研究建立了基准。

Abstract: Quantum many-body dynamics generate nonclassical correlations naturally described by quantum resource theories. Quantum magic resources (or nonstabilizerness) capture deviation from classically simulable stabilizer states, while coherence and fermionic non-Gaussianity measure departure from the computational basis and from fermionic Gaussian states, respectively. We track these resources in a subsystem of a one-dimensional qubit chain evolved by random brickwall circuits. For resource-generating gates, evolution from low-resource states exhibits a universal rise-peak-fall behavior, with the peak time scaling logarithmically with subsystem size and the resource eventually decaying as the subsystem approaches a maximally mixed state. Circuits whose gates do not create the resource but entangle neighboring qubits, give rise to a ballistic spreading of quantum resource initially confined to a region of the initial state. Our results give a unified picture of spatiotemporal resource dynamics in local circuits and a baseline for more structured quantum many-body systems.

</details>


### [11] [Strong-to-weak symmetry breaking in monitored dipole conserving quantum circuits](https://arxiv.org/abs/2512.14830)
*Caterina Zerba,Sarang Gopalakrishnan,Michael Knap*

Main category: quant-ph

TL;DR: 研究具有电荷和偶极矩守恒的监控量子电路的信息论相，探索对称性自发破缺与局部测量学习全局电荷能力之间的关系


<details>
  <summary>Details</summary>
Motivation: 研究在电荷和偶极矩守恒约束下，监控量子电路的信息论相变，探索对称性从强对称性自发破缺为弱对称性的现象及其信息论意义

Method: 分析具有电荷和偶极矩守恒的监控量子电路，通过局部电荷密度测量，研究对称性自发破缺与从局部测量学习全局电荷能力的关系

Result: 发现丰富的相图：一维中电荷总是容易学习，偶极矩可难可易；二维中存在三相：高频测量时两者都易学，降低测量率时先偶极矩后电荷变难；低测量相是类似近晶液晶的各向异性临界相

Conclusion: 电荷和偶极矩守恒的监控量子电路展现出丰富的信息论相结构，对称性自发破缺与从局部测量学习全局电荷的能力密切相关，二维低测量相表现出各向异性的临界行为

Abstract: We explore the information-theoretic phases of monitored quantum circuits subject to dynamics that conserves both charge and dipole moment, as well as measurements of the local charge density. Explicitly, both charge and dipole-moment conservation are strong symmetries, but under the dynamics they can be spontaneously broken to weak symmetries: this spontaneous symmetry breaking has an information-theoretic interpretation in terms of whether one can learn global charges from local measurements. We find a rich phase diagram: in one spatial dimension, charge is always easy to learn, while dipole moment can be either easy or hard. In two dimensions, we find three phases: for frequent measurements, both charge and dipole moment are easy to learn; as the measurement rate is decreased, first dipole moment and then charge become hard. In two dimensions, the low-measurement phase is an exotic critical phase with anisotropic spacetime scaling, analogous to a smectic liquid crystal.

</details>


### [12] [Extreme non-negative Wigner functions](https://arxiv.org/abs/2512.14831)
*Zacharie Van Herstraeten,Jack Davis,Nuno C. Dias,João N. Prata,Nicolas J. Cerf,Ulysse Chabaud*

Main category: quant-ph

TL;DR: 该论文提出了研究Wigner正态(WPS)极端点的新方法，通过凸几何分析和Vertigo映射构造了大量极端WPS，揭示了混合态非负Wigner函数的数学结构。


<details>
  <summary>Details</summary>
Motivation: Wigner正态(WPS)的操作性表征是一个长期未解决的开放问题。纯态中只有高斯态是WPS，但混合态的情况要复杂得多。需要理解混合态WPS的结构和极端点。

Method: 采用凸几何方法：1) 表征Wigner正准态(WPQS)的相位不变极端点；2) 引入Vertigo映射，将极端WPQS映射为极端WPS；3) 识别保极端性映射，获得非相位不变的极端WPS。从beam-splitter态出发构造所有低维极端WPS。

Result: 提出了构造大量极端WPS的系统方法，生成了所有低维极端WPS。揭示了混合态非负Wigner函数的显著数学结构，基于配套论文中推导的WPS集合新数学性质。

Conclusion: 通过凸几何分析和Vertigo映射等新工具，成功构造了Wigner正态的极端点，为解决WPS操作性表征这一长期开放问题提供了重要进展，揭示了混合态非负Wigner函数的深层结构。

Abstract: Providing an operational characterization of the Wigner-positive states (WPS), i.e., the set of quantum states with non-negative Wigner function, is a longstanding open problem. For pure states, the only WPS are Gaussian states, but the situation is considerably more subtle for mixed states. Here, we approach the problem using convex geometry, reducing the question to the characterization of the extreme points of the set of WPS. We give a constructive method to generate a large class of such extreme WPS, which combines the following steps: (i) we characterize the phase-invariant extreme points of the superset of Wigner-positive quasi-states (WPQS); (ii) we introduce a new quantum map, named Vertigo map, which maps extreme WPQS to extreme WPS while preserving phase invariance; (iii) we identify families of extremality-preserving maps and use them to obtain extreme WPS while relaxing phase invariance. Our construction generates all extreme WPS of low dimension, starting from a specific kind of WPS known as beam-splitter states. Our results build upon new mathematical properties of the set of WPS derived in a companion paper and unveil the remarkable structure of mixed states with non-negative Wigner functions.

</details>


### [13] [Entanglement without Quantum Mechanics: Operational Constraints on the Quantum Signature](https://arxiv.org/abs/2512.14834)
*Samuel Schlegel,Borivoje Dakić,Flavio Del Santo*

Main category: quant-ph

TL;DR: 经典关联在受限操作下可表现出类似纠缠的非可分性，只有解除更多操作限制后才能获得真正的量子纠缠


<details>
  <summary>Details</summary>
Motivation: 探讨纠缠是否真的是量子独有的特征，研究在受限操作条件下经典关联如何表现出类似纠缠的行为

Method: 通过限制观测者的测量和变换操作集，分析经典相空间分布在量子力学形式主义中的表现，并引入希尔伯特空间算符正定性作为物理性要求

Result: 建立了操作层次结构：经典伪影、经典可再现的非可分性、真正的量子纠缠，揭示了非可分性在不同操作限制下的本质差异

Conclusion: 纠缠并非固有的量子特征，而是依赖于观测者的操作能力；只有解除足够多的操作限制后，才能获得无法用经典模型描述的真正量子纠缠

Abstract: Entanglement is often regarded as an inherently quantum feature. We show that this does not have to be the case: under restricted operational access, classical correlations can appear nonseparable when expressed in the formalism of quantum mechanics. If an observer is limited to a constrained set of measurements and transformations, certain classical phase-space distributions can mimic entanglement-like behaviours. Imposing positivity of the associated Hilbert space operator as a physicality requirement removes some of these representational artifacts, revealing a regime in which nonseparability is genuine but still reproducible by classical models. Only when the operational restrictions on the observer are lifted further--allowing operational tests of measurement incompatibility or other nonclassical signatures--does one obtain entanglement that can no longer be captured by any classical description. This operational hierarchy distinguishes classical artifacts, classically reproducible nonseparability, and genuine entanglement.

</details>


### [14] [Noise-Induced Thermalization in Quantum Systems](https://arxiv.org/abs/2512.14842)
*Sameer Dambal,Yu Zhang,Eric R Bittner,Pavan Hosur*

Main category: quant-ph

TL;DR: 噪声可以加速量子计算机中吉布斯态的制备，为噪声量子计算提供了新的实用范式


<details>
  <summary>Details</summary>
Motivation: 在NISQ时代，噪声通常被视为实现容错量子计算的主要障碍，但本研究发现量子计算流程中的某些阶段实际上可以从噪声中受益

Method: 利用本征态热化假设，通过经典和量子模拟研究噪声对吉布斯态制备的影响，使用具有局部哈密顿量的自旋1/2链模型，分别测试了Haar随机噪声和相位翻转噪声

Result: 在非可积模型中，噪声使热化速度提高约3.5倍；在可积模型中，原本不会热化的系统在噪声作用下达到了热态

Conclusion: 噪声可以加速量子计算机中吉布斯态的制备，这为在实现完全容错之前利用噪声获得实际优势提供了新的范式，而且由于在量子计算机上认证局部吉布斯态相对容易，该方法为解决量子计算中的关键问题提供了实用方案

Abstract: In the current Noisy Intermediate-Scale Quantum era, noise is widely regarded as the primary obstacle to achieving fault-tolerant quantum computation. However, certain stages of the quantum computing pipeline can, in fact, benefit from this noise. In this work, we exploit the Eigenstate Thermalization Hypothesis to show that noise generically accelerates a fundamental task in quantum computing -- the preparation of Gibbs states. We demonstrate this behavior using classical and quantum simulations with Haar-random and phase-flip noise, respectively, on a spin-1/2 chain with a local Hamiltonian. Our non-integrable model sees ~3.5x faster thermalization in the presence of noise, while our integrable model, which would not otherwise thermalize, reaches a thermal state due to noise. Since certifying a local Gibbs state is relatively easy on a quantum computer, our approach provides a new practical solution to a key problem in quantum computing. More broadly, these results establish a new paradigm in which noise can be harnessed on quantum computers, enabling practical advantages before the years of fault-tolerance.

</details>


### [15] [Quantum Fisher-information limits of resonant nanophotonic sensors: why high-Q is not optimal even at the quantum limit](https://arxiv.org/abs/2512.14899)
*J. Sumaya-Martinez*

Main category: quant-ph

TL;DR: 量子计量框架应用于基于亚波长法布里-珀罗狭缝腔的共振纳米光子传感器，发现即使达到量子极限，最优估计精度仍由参数相关相移的生成元决定，而非腔品质因子，量子资源增强灵敏度但不改变最优几何结构。


<details>
  <summary>Details</summary>
Motivation: 建立量子计量框架来分析共振纳米光子传感器，研究量子资源如何影响传感器性能，并确定量子增强传感的物理设计原则。

Method: 基于经典Fisher信息分析，将参数编码建模为马赫-曾德尔干涉仪一臂中的相位和损耗量子通道，推导相干和高斯探针态在线性损耗下的量子Fisher信息。

Result: 即使在量子极限下，最优估计精度也由参数相关相移的生成元决定，而非腔品质因子；最大化QFI的工作点通常不与最大Q共振点重合；量子资源增强灵敏度但不重新定义最优几何结构。

Conclusion: 研究结果为量子增强纳米光子传感提供了物理透明的设计原则，表明量子资源可以提升灵敏度，但传感器的最优工作条件和几何结构仍由经典物理因素主导。

Abstract: We develop a quantum metrological framework for resonant nanophotonic sensors based on subwavelength Fabry--Perot slit cavities. Building on classical Fisher-information analyses of resonant transmission sensors, we model parameter encoding as a phase-and-loss quantum channel embedded in one arm of a Mach-Zehnder interferometer. We derive the quantum Fisher information (QFI) for coherent and Gaussian probe states under linear loss and show that, even at the quantum limit, optimal estimation precision is governed by the generator of parameter-dependent phase shifts rather than by the cavity quality factor. Consequently, the operating point that maximizes the QFI does not generally coincide with the maximum-Q resonance. Quantum resources enhance sensitivity but do not redefine the optimal geometry. Our results provide physically transparent design principles for quantum-enhanced nanophotonic sensing.

</details>


### [16] [Quantum Radiometric Calibration](https://arxiv.org/abs/2512.14947)
*Leif Albers,Jan-Malte Michaelsen,Roman Schnabel*

Main category: quant-ph

TL;DR: 提出基于压缩光和量子关联的量子辐射度校准方法，首次实现原位测量光电二极管的量子效率和探测效率，发现商用光电二极管效率低于预期，无法满足未来需求。


<details>
  <summary>Details</summary>
Motivation: 光学量子计算、量子通信和传感技术需要接近完美量子效率的光电探测器（约10^16光子/秒），但现有辐射度校准方法无法满足需求，特别是无法原位测量量子效率。

Method: 基于压缩光和量子关联的量子辐射度校准方法，利用海森堡不确定性原理，通过10-dB压缩真空态校准1550nm商用光电二极管对。

Result: 测得系统探测效率为(97.20 ± 0.37)%，发现现有1550nm光电二极管效率意外地低，无法满足未来引力波探测器和光学量子计算的需求。

Conclusion: 该方法首次实现原位量子效率测量，具有更高精度潜力，但当前测量结果暴露了商用光电二极管效率不足的严重问题，对未来量子技术发展构成挑战。

Abstract: Optical quantum computing, as well as quantum communication and sensing technology based on quantum correlations are in preparation. These require photodiodes for the detection of about 10^16 photons per second with close to perfect quantum efficiency. Already the radiometric calibration is a challenge. Here, we provide the theoretical description of the quantum radiometric calibration method. Its foundation is squeezed light and Heisenberg's uncertainty principle, making it an example of quantum metrology based on quantum correlations. Unlike all existing radiometric calibration methods, ours is in situ and provides both the detection efficiency and the more stringent quantum efficiency directly for the measurement frequencies of the user application. We calibrate a pair of the most efficient commercially available photodiode at 1550 nm to a system detection efficiency of (97.20 + 0.37)% using 10-dB-squeezed vacuum states. Our method has great potential for significantly higher precision and accuracy, but even with this measurement, we can clearly say that the available photodiode efficiencies for 1550 nm are unexpectedly low, too low for future gravitational wave detectors and for optical quantum computing.

</details>


### [17] [Pulsed single-photon spectroscopy of an emitter with vibrational coupling](https://arxiv.org/abs/2512.14964)
*Sourav Das,Aiman Khan,Elnaz Darsheshdar,Francesco Albarelli,Animesh Datta*

Main category: quant-ph

TL;DR: 该论文分析了单光子脉冲与量子二能级发射体（耦合振动浴）散射后的量子态，从信息论角度研究了振动效应对量子光光谱学的影响。


<details>
  <summary>Details</summary>
Motivation: 研究振动效应对量子光光谱学的影响，特别是振动诱导退相干如何影响发射体线宽的估计精度。

Method: 解析推导单光子脉冲与量子二能级发射体（耦合振动浴）散射后的量子态，进行信息论分析，比较时域和频域分辨的光探测方法。

Result: 振动诱导退相干降低了估计发射体线宽的量子费希尔信息，这主要反映了Franck-Condon因子对光-物质耦合的抑制。在强振动耦合下，频域分辨的光探测比时域分辨更具信息量。

Conclusion: 振动效应对量子光光谱学有重要影响，频域分辨探测在强振动耦合条件下能提供更准确的发射体线宽估计。

Abstract: We analytically derive the quantum state of a single-photon pulse scattered from a single quantum two-level emitter interacting with a vibrational bath. This solution for the quadripartite system enables an information-theoretic characterization of vibrational effects in quantum light spectroscopy. We show that vibration-induced dephasing reduces the quantum Fisher information (QFI) for estimating the emitter's linewidth, largely reflecting the Franck-Condon suppression of light-matter coupling. Comparing time- and frequency-resolved photodetection, we find the latter to be more informative in estimating the emitter's linewidth for stronger vibrational coupling.

</details>


### [18] [Roadmap: 2D Materials for Quantum Technologies](https://arxiv.org/abs/2512.14973)
*Qimin Yan,Tongcang Li,Xingyu Gao,Sumukh Vaidya,Saakshi Dikshit,Yue Luo,Stefan Strauf,Reda Moukaouine,Anton Pershin,Adam Gali,Zhenyao Fang,Harvey Stanfield,Ivan J. Vera-Marun,Michael Newburger,Simranjeet Singh,Tiancong Zhu,Mauro Brotons-Gisbert,Klaus D. Jöns,Brian D. Gerardot,Brian S. Y. Kim,John R. Schaibley,Kyle L. Seyler,Jesse Balgley,James Hone,Kin Chung Fong,Lin Wang,Guido Burkard,Yihang Zeng,Tobias Heindel,Serkan Ateş,Tobias Vogl,Igor Aharonovich*

Main category: quant-ph

TL;DR: 二维材料作为量子技术平台，具有原子级控制、强量子限域和异质集成能力，可用于量子传感、计算、通信和模拟等领域。


<details>
  <summary>Details</summary>
Motivation: 二维材料为量子技术提供了独特的平台，其原子级厚度、强量子限域效应和易于异质集成的特性，能够实现从微观量子态到宏观器件的连接，为下一代量子技术奠定材料基础。

Method: 该路线图采用综合调研方法，系统回顾了二维材料在量子技术各领域的进展，包括自旋缺陷与量子传感、量子发射器与非线性光子学、计算理论与数据驱动缺陷发现、自旋电子与磁子器件、腔工程量子材料、超导与混合量子电路、量子点、莫尔量子模拟器和量子通信平台等。

Result: 识别了缺陷控制、相干性保持、界面工程和可扩展集成等共同挑战，同时指出了机器学习辅助设计和实验-理论反馈循环带来的新机遇，建立了从微观量子态到介观激发再到宏观器件架构的材料中心框架。

Conclusion: 二维材料作为基础构建模块，通过整合相干量子功能，为下一代量子技术提供了材料中心框架，有望推动量子传感、计算、通信和模拟等领域的突破性发展。

Abstract: Two-dimensional (2D) materials have emerged as a versatile and powerful platform for quantum technologies, offering atomic-scale control, strong quantum confinement, and seamless integration into heterogeneous device architectures. Their reduced dimensionality enables unique quantum phenomena, including optically addressable spin defects, tunable single-photon emitters, low-dimensional magnetism, gate-controlled superconductivity, and correlated states in Moiré superlattices. This Roadmap provides a comprehensive overview of recent progress and future directions in exploiting 2D materials for quantum sensing, computation, communication, and simulation. We survey advances spanning spin defects and quantum sensing, quantum emitters and nonlinear photonics, computational theory and data-driven discovery of quantum defects, spintronic and magnonic devices, cavity-engineered quantum materials, superconducting and hybrid quantum circuits, quantum dots, Moiré quantum simulators, and quantum communication platforms. Across these themes, we identify common challenges in defect control, coherence preservation, interfacial engineering, and scalable integration, alongside emerging opportunities driven by machine$-$learning$-$assisted design and integrated experiment$-$theory feedback loops. By connecting microscopic quantum states to mesoscopic excitations and macroscopic device architectures, this Roadmap outlines a materials-centric framework for integrating coherent quantum functionalities and positions 2D materials as foundational building blocks for next-generation quantum technologies.

</details>


### [19] [High efficiency controlled quantum secure direct communication with 4D qudits and Grover search algorithm](https://arxiv.org/abs/2512.14984)
*Ni-Shi Lu,Ping Zhou*

Main category: quant-ph

TL;DR: 提出基于协作酉序列解码范式的受控量子安全直接通信协议，通过三方解码机制打破效率、安全性和可扩展性之间的权衡，实现66.7%的高量子比特效率


<details>
  <summary>Details</summary>
Motivation: 当前量子安全直接通信的发展受到控制效率、安全性和可扩展性之间基本权衡的阻碍，需要创新方案来突破这一僵局

Method: 基于四维单粒子态，采用协作酉序列解码范式，控制器授权解锁特定酉操作序列，接收方仅通过量子操作直接解码，无需经典计算算法，并集成诱骗光子认证的多层防御机制

Result: 协议实现了66.7%的量子比特效率，显著优于现有方案，为未来量子网络提供了高效、高安全的解决方案

Conclusion: 该受控QSDC协议成功打破了效率、安全性和可扩展性之间的权衡，通过创新的三方解码机制和集成安全措施，为量子安全直接通信提供了有前景的发展方向

Abstract: Currently, the progress of quantum secure direct communication (QSDC) is impeded by a fundamental trade off among control efficiency, security, and scalability. This study proposes an innovative controlled QSDC protocol based on a collaborative unitary sequence decoding paradigm to break this deadlock.Leveraging four dimensional single particle states, the protocol's core innovation lies in its three party decoding mechanism. The controller's authorization unlocks a specific unitary operation sequence, enabling the receiver to directly decode exclusively via quantum operations, eliminating the need for classical computational algorithms in conventional protocols. This tailored sequence underpins its high efficiency.The protocol also seamlessly incorporates decoy photon authentication, creating a multi layer defense against both external and internal attacks. Consequently, it achieves a remarkable qudit efficiency of 66.7%, offering a significant performance improvement over existing schemes and an efficient, highly secure solution for future quantum networks.

</details>


### [20] [Trade-off relations and enhancement protocol of quantum battery capacities in multipartite systems](https://arxiv.org/abs/2512.14999)
*Yiding Wang,Xiaofen Huang,Shao-Ming Fei,Tinggui Zhang*

Main category: quant-ph

TL;DR: 该论文研究了量子电池容量在两量子比特系统中的权衡关系，定义了剩余电池容量，提出了增强子系统电池容量的非相干操作协议，并将理论扩展到三量子比特系统。


<details>
  <summary>Details</summary>
Motivation: 研究量子电池容量在子系统间的权衡关系，为量子电池理论和量子能量存储系统的发展提供理论基础。

Method: 首先研究两量子比特系统中量子电池容量的权衡关系，定义剩余电池容量和相干/非相干分量，提出增强子系统电池容量的非相干操作协议，然后将理论扩展到三量子比特系统。

Result: 发现子系统电池容量之和受总系统容量约束，建立了剩余电池容量理论，提出了有效的非相干操作协议，确定了增强子系统容量的最小时间要求。

Conclusion: 该研究为量子电池理论和量子能量存储系统的发展做出了贡献，提供了增强子系统电池容量的实用协议和理论基础。

Abstract: First, we investigate the trade-off relations of quantum battery capacities in two-qubit system. We find that the sum of subsystem battery capacity is governed by the total system capacity, with this trade-off relation persisting for a class of Hamiltonians, including Ising, XX, XXZ and XXX models. Then building on this relation, we define residual battery capacity for general quantum states and establish coherent/incoherent components of subsystem battery capacity. Furthermore, we introduce the protocol to guide the selection of appropriate incoherent unitary operations for enhancing subsystem battery capacity in specific scenarios, along with a sufficient condition for achieving subsystem capacity gain through unitary operation. Numerical examples validate the feasibility of the incoherent operation protocol. Additionally, for the three-qubit system, we also established a set of theories and results parallel to those for two-qubit case. Finally, we determine the minimum time required to enhance subsystem battery capacity via a single incoherent operation in our protocol. Our findings contribute to the development of quantum battery theory and quantum energy storage systems.

</details>


### [21] [Enabling Technologies for Scalable Superconducting Quantum Computing](https://arxiv.org/abs/2512.15001)
*Xanthe Croot,Kasra Nowrouzi,Christopher Spitzer,Carmen G. Almudever,Alexandre Blais,Malcolm Carroll,Jerry Chow,Daniel Friedman,Masao Tokunari,Edoardo Charbon,Vivek Chidambaram,Andrew N. Cleland,David Danovitch,Joseph Emerson,David Gunnarsson,Raymond Laflamme,John Martinis,Robert McDermott,William D. Oliver,Michel Pioro-Ladriere,Yoshiaki Sato,Hidenori Ohata,Kouichi Semba,Irfan Siddiqi*

Main category: quant-ph

TL;DR: 该论文分析了超导量子计算系统在实现大规模容错量子计算机方面的关键挑战，提出了加速超导量子计算机发展的系统与生态系统开发重点领域。


<details>
  <summary>Details</summary>
Motivation: 虽然超导量子处理器已成功演示了量子计算的基本功能，但要实现量子计算的全部潜力，关键在于构建大规模容错量子计算机。当前需要科学、工程和工业的进步来稳健地生成、维持和高效操纵指数级大的计算空间，并为这种规模系统提供足够数量和质量的组件。

Method: 论文通过分析超导量子计算系统的现状和挑战，提出了加速发展的关键领域，重点关注量子信息在低温环境内外的处理和传输问题。

Result: 识别了超导量子计算机发展的关键瓶颈，包括量子信息的处理和传输、低温环境集成、系统扩展性等，为未来研发提供了方向性指导。

Conclusion: 实现大规模容错量子计算机需要跨学科的系统性发展，特别是在量子信息处理和传输、低温系统集成等关键领域，这些进展将加速超导量子计算机的实际应用。

Abstract: Experiments with superconducting quantum processors have successfully demonstrated the basic functions needed for quantum computation and evidence of utility, albeit without a sizable array of error-corrected qubits. The realization of the full potential of quantum computing centers on achieving large scale fault-tolerant quantum computers. Science, engineering and industry advances are needed to robustly generate, sustain, and efficiently manipulate an exponentially large computational (Hilbert) space as well as supply the number and quality components needed for such a scaled system. In this article, we suggest critical areas of quantum system and ecosystem development, with respect to the handling and transmission of quantum information within and out of a cryogenic environment, that would accelerate the development of quantum computers based on superconducting circuits.

</details>


### [22] [Characterizing entanglement shareability and distribution in $N$-partite systems](https://arxiv.org/abs/2512.15018)
*Hui Li,Ting Gao,Fengli Yan*

Main category: quant-ph

TL;DR: 本文证明了Gq-并发度的平方满足层次化的一夫一妻关系，提出了两种层次化纠缠见证指标，并展示了在多层系统中Gq-并发度比并发度具有更好的纠缠分布特性。


<details>
  <summary>Details</summary>
Motivation: 探索纠缠的可共享性和分布在量子信息任务中具有基础意义。本文旨在研究Gq-并发度（并发度的推广）的平方是否满足层次化的一夫一妻关系，并比较其与并发度在纠缠分布特性上的优劣。

Method: 1. 证明Gq-并发度平方对任意N-量子比特态满足层次化一夫一妻关系
2. 基于这些不等式构建两种层次化纠缠见证指标
3. 在2⊗d系统中建立Gq-并发度与并发度的解析关系
4. 严格证明在2⊗d₂⊗d₃⊗⋯⊗d_N系统中，Gq-并发度平方的一夫一妻性质优于并发度平方
5. 提供具体示例说明多层系统中Gq-并发度平方满足一夫一妻关系而并发度平方不满足的情况

Result: 1. 成功证明了Gq-并发度平方满足层次化一夫一妻关系
2. 提出的两种层次化指标在纠缠见证能力上表现出明显优势
3. 建立了Gq-并发度与并发度在2⊗d系统中的解析关系
4. 证明了Gq-并发度平方的一夫一妻性质优于并发度平方
5. 通过具体示例展示了在多层系统中Gq-并发度平方满足一夫一妻关系而并发度平方不满足的情况

Conclusion: 本文结果更好地揭示了多层纠缠的有趣特性，为多体量子系统中的纠缠分布提供了关键见解。Gq-并发度在纠缠分布特性上优于传统的并发度，特别是在多层系统中表现出更强的一夫一妻关系。

Abstract: Exploring the shareability and distribution of entanglement possesses fundamental significance in quantum information tasks. In this paper, we demonstrate that the square of bipartite entanglement measures $G_q$-concurrence, which is the generalization of concurrence, follows a set of hierarchical monogamy relations for any $N$-qubit quantum state. On the basis of these monogamy inequalities, we render two kinds of hierarchical indicators that exhibit evident advantages in the capacity of witnessing entanglement. Moreover, we show an analytical relation between $G_q$-concurrence and concurrence in $2\otimes d$ systems. Furthermore, we rigorously prove that the monogamy property of squared $G_q$-concurrence is superior to that of squared concurrence in $2\otimes d_2\otimes d_3\otimes\cdots\otimes d_N$ systems. In addition, several concrete examples are provided to illustrate that for multilevel systems, the squared $G_q$-concurrence satisfies the monogamy relation, even if the squared concurrence does not. These results better reveal the intriguing characteristic of multilevel entanglement and provide critical insights into the entanglement distribution within multipartite quantum systems.

</details>


### [23] [Graph-theoretical search for integrable multistate Landau-Zener models](https://arxiv.org/abs/2512.15046)
*Zixuan Li,Chen Sun*

Main category: quant-ph

TL;DR: 通过图论方法系统搜索可积的多时间Landau-Zener模型，验证了现有猜想在N≤11顶点时成立，并提出了可能违反猜想的新图族。


<details>
  <summary>Details</summary>
Motivation: 寻找新的精确可解多态Landau-Zener模型是理论物理中的重要问题。已知的MTLZ模型仅存在于超立方体、扇形图及其笛卡尔积等少数图族中，这引发了一个猜想：是否只有这些图能承载MTLZ模型？本文旨在通过系统性的图论搜索来验证这一猜想并寻找新的可积模型。

Method: 首先识别承载MTLZ模型所需的最小图结构，然后设计高效算法系统搜索候选图。使用计算软件枚举N≤13顶点的所有候选图，并对N≤11的图进行深入分析。提出了"（0,2）-图的后代"这一新图族作为可能违反猜想的候选。

Result: 对于N≤11顶点的图，结果证实了现有猜想：只有超立方体、扇形图及其笛卡尔积能承载MTLZ模型。对于更大的图，提出了"（0,2）-图的后代"这一新图族，它们可能违反该猜想，为未来发现新的精确可解模型提供了方向。

Conclusion: 通过系统性的图论搜索，本文验证了MTLZ模型承载图的猜想在较小规模下成立，同时提出了可能违反猜想的新图族。这项工作为未来识别新的精确可解多态Landau-Zener模型提供了指导框架。

Abstract: The search for exactly solvable models is an evergreen topic in theoretical physics. In the context of multistate Landau-Zener models -- $N$-state quantum systems with linearly time-dependent Hamiltonians -- the theory of integrability provides a framework for identifying new solvable cases. In particular, it was proved that the integrability of a specific class known as the multitime Landau-Zener (MTLZ) models guarantees their exact solvability. A key finding was that an $N$-state MTLZ model can be represented by data defined on an $N$-vertex graph. While known host graphs for MTLZ models include hypercubes, fans, and their Cartesian products, no other families have been discovered, leading to the conjecture that these are the only possibilities. In this work, we conduct a systematic graph-theoretical search for integrable models within the MTLZ class. By first identifying minimal structures that a graph must contain to host an MTLZ model, we formulate an efficient algorithm to systematically search for candidate graphs for MTLZ models. Implementing this algorithm using computational software, we enumerate all candidate graphs with up to $N = 13$ vertices and perform an in-depth analysis of those with $N \le 11$. Our results corroborate the aforementioned conjecture for graphs up to $11$ vertices. For even larger graphs, we propose a specific family, termed descendants of ``$(0,2)$-graphs'', as promising candidates that may violate the conjecture above. Our work can serve as a guideline to identify new exactly solvable multistate Landau-Zener models in the future.

</details>


### [24] [Microscopic model for a spatial multimode generation based on Multi-pump Four Wave Mixing in hot vapours](https://arxiv.org/abs/2512.15051)
*H. M. Florez*

Main category: quant-ph

TL;DR: 该论文首次提出了在稠密原子介质中利用双泵浦四波混频实现多模纠缠的微观理论模型，描述了多模增益放大和量子关联特性。


<details>
  <summary>Details</summary>
Motivation: 多体纠缠是量子信息处理的重要资源，之前的研究表明可以利用碱金属原子通过非线性过程实现单器件多体纠缠。然而，对于双泵浦四波混频多模生成的微观描述尚属空白。

Method: 扩展了单泵浦四波混频的双Λ模型，提出了Floquet展开法来求解多模增益放大和噪声特性，描述了多模生成的角度和双光子依赖性以及模式间的量子关联。

Result: 建立了能够描述多模增益分布和量子关联的微观理论模型，成功解释了先前实验观测的主要特性，并能在典型实验参数范围内预测模式增益分布和量子相关性。

Conclusion: 该研究首次提供了双泵浦四波混频多模纠缠的微观理论描述，为优化实验设计和预测量子关联特性提供了理论基础，有助于推进基于原子系统的多体纠缠应用。

Abstract: Multipartite entanglement is an important resource for quantum information processing. It has been shown that it is possible to employ alkali atoms to implement single device multipartite entanglement by using nonlinear processes with spatial modes. This work presents the first microscopic description of such multi-mode generation with two-pump four wave mixing (4WM) in dense atomic media. We implement an extension of a double $Λ$ model for a single pump 4WM in order to describe the multi-mode generation with a two-pump configuration. We propose a Floquet expansion to solve the multimode gain amplification and noise properties. The model describes the angle and the two-photon dependency of the multimode generation and the quantum correlations among the modes. We investigate the entanglement properties of the system, describing the main properties of previous experimental observations. Such a microscopic description can be used to predict the gain distribution of modes and the quantum correlation within a typical range of experimental parameters.

</details>


### [25] [Bosonic quantum computing with near-term devices and beyond](https://arxiv.org/abs/2512.15063)
*Timo Hillmann*

Main category: quant-ph

TL;DR: 该论文研究可扩展容错量子计算，开发了玻色量子码、量子LDPC码和解码协议，连接连续变量和离散变量纠错，提出多种新型编码方案和解码方法。


<details>
  <summary>Details</summary>
Motivation: 实现可扩展的容错量子计算需要解决量子纠错中的关键挑战，包括开发高效的量子编码方案、解码协议以及分析实际噪声条件下的性能。

Method: 1. 开发玻色量子码（包括压缩猫比特、旋转对称码和GKP码）的超导微波实现；2. 提出利用模拟综合征信息的解码方法；3. 开发局部统计解码和量子径向码等新型LDPC码；4. 建立故障复形的同调框架分析动态纠错协议。

Result: 1. 实现了确定性立方相位态生成和噪声偏置的压缩猫比特编码；2. 揭示了测量方案中的关键权衡；3. 实现了级联系统中的准单次解码；4. 开发了低开销、强电路性能的单次LDPC码；5. 建立了分析容错方案的通用框架。

Conclusion: 该研究通过连接连续变量和离散变量纠错，开发了多种新型量子编码和解码技术，为可扩展容错量子计算提供了重要工具和理论框架，推动了量子纠错领域的发展。

Abstract: (Abridged.) This thesis investigates scalable fault-tolerant quantum computation through the development of bosonic quantum codes, quantum LDPC codes, and decoding protocols that connect continuous-variable and discrete-variable error correction. We investigate superconducting microwave implementations of continuous-variable quantum computing, including the deterministic generation of cubic phase states, and introduce the dissipatively stabilized squeezed cat qubit, a noise-biased bosonic encoding with enhanced error suppression and faster gates. The performance of rotation-symmetric and GKP codes is analyzed under realistic noise and measurement models, revealing key trade-offs in measurement-based schemes. To integrate bosonic codes into larger architectures, we develop decoding methods that exploit analog syndrome information, enabling quasi-single-shot decoding in concatenated systems. On the discrete-variable side, we introduce localized statistics decoding, a highly parallelizable decoder for quantum LDPC codes, and propose quantum radial codes, a new family of single-shot LDPC codes with low overhead and strong circuit-level performance. Finally, we present fault complexes, a homological framework for analyzing faults in dynamic quantum error correction protocols. Extending the role of homology in static CSS codes, fault complexes provide a general language for the design and analysis of fault-tolerant schemes.

</details>


### [26] [Quantum Batteries in Coherent Ising Machine](https://arxiv.org/abs/2512.15072)
*Jin-Tian Zhang,Shuang-Quan Ma,Jing-Yi-Ran Jin,Qing Ai*

Main category: quant-ph

TL;DR: 提出基于简并光学参量振荡器的量子电池方案，利用信号场存储能量，分析相干与不相干功容，发现相干功容衰减更慢，并找到最佳充电时刻，最后演示向二能级系统的放电过程。


<details>
  <summary>Details</summary>
Motivation: 量子热力学研究中，量子电池被提出用于通过量子效应存储和传输能量。尽管有许多理论模型，但退相干仍然是严峻挑战，实际平台仍然很少。需要建立现实可行且可立即实现的量子电池架构。

Method: 基于简并光学参量振荡器构建量子电池，使用信号场作为能量存储单元。仔细将功容分离为相干和不相干分量，分析它们的衰减特性。通过耦合到二能级系统作为负载来演示放电过程。

Result: 发现相干功容衰减速度大约是不相干功容的一半。相干功容和平均充电功率在γ_s t ≈ 10时同时达到最大值，这定义了关闭泵浦的最佳时刻。成功演示了向二能级系统的高效放电过程。

Conclusion: 该工作在一个成熟的光学平台上建立了一个现实且可立即实现的量子电池架构，为解决量子电池的实际实现提供了可行方案。

Abstract: With intensive studies of quantum thermodynamics, the quantum batteries (QBs) have been proposed to store and transfer energy via quantum effects. Despite many theoretical models, decoherence remains a severe challenge and practical platforms are still rare. Here we propose the QB based on the degenerate optical parametric oscillator (DOPO), using the signal field as the energy-storage unit. We carefully separate the ergotropy into coherent and incoherent components and find that the coherent part decays roughly half as slowly as the incoherent part. More importantly, the coherent ergotropy and the average charging power reach their respective maxima at essentially the same moment, i.e., $γ_s t \approx 10$. This coincidence defines the optimal instant to switch off the pump. Finally, coupling the QB to a two-level system (TLS) as the load, we demonstrate an efficient discharge process of the QB. Our work establishes a realistic and immediately-implementable QB architecture on a mature optical platform.

</details>


### [27] [Coherent transfer via parametric control of normal-mode splitting in a superconducting multimode resonator](https://arxiv.org/abs/2512.15087)
*Kai-I Chu,Xiao-Cheng Lu,Hsin Chang,Wei-Cheng Hung,Jing-Yang Chang,Jeng-Chung Chen,Chii-Dong Chen,Yung-Fu Chen*

Main category: quant-ph

TL;DR: 该论文展示了一种基于片上多模谐振器的微波存储与检索方法，通过强参数调制产生可调谐的正常模式分裂来实现微波存储，为超导电路中的可控量子存储器提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 微波存储和检索是超导量子电路的关键能力，需要开发实用的可控量子存储器机制。

Method: 使用片上多模谐振器，通过强参数调制产生大的可调谐正常模式分裂。当短微波脉冲的频谱带宽覆盖两个修饰态吸收峰时，部分脉冲被吸收并在模式间进行相干能量交换，产生时域拍频信号。通过在拍频到达前关闭调制，实现按需存储和检索。

Result: 成功实现了微波的按需存储和检索，展示了参数正常模式分裂协议作为超导电路中可控量子存储器机制的可行性。

Conclusion: 参数正常模式分裂协议为超导电路中的可控量子存储器机制提供了实用途径，是微波光子量子存储器的替代方法。

Abstract: Microwave storage and retrieval are essential capabilities for superconducting quantum circuits. Here, we demonstrate an on-chip multimode resonator in which strong parametric modulation induces a large and tunable normal-mode splitting that enables microwave storage. When the spectral bandwidth of a short microwave pulse covers the two dressed-state absorption peaks, part of the pulse is absorbed and undergoes coherent energy exchange between the modes, producing a clear time-domain beating signal. By switching off the modulation before the beating arrives, we realize on-demand storage and retrieval, demonstrating an alternative approach to microwave photonic quantum memory. This parametric-normal-mode-splitting protocol offers a practical route toward a controllable quantum-memory mechanism in superconducting circuits.

</details>


### [28] [Quantum data hiding with two-qubit separable states](https://arxiv.org/abs/2512.15095)
*Donghoon Ha,Jeong San Kim*

Main category: quant-ph

TL;DR: 提出一种基于两比特可分态的数据隐藏方案，建立了局部区分性的界限，并给出了正交可分态的具体实现


<details>
  <summary>Details</summary>
Motivation: 研究两方量子态的区分问题，旨在构建更实用的量子数据隐藏方案，特别是使用最低维度的可分态来实现

Method: 首先建立两方量子态最优局部区分的界限，然后建立构造数据隐藏方案的充分条件，最后用两比特正交可分态的具体例子进行说明

Result: 成功构建了基于两比特可分态的数据隐藏方案，该方案由于使用最低维度的可分态，实际实现变得更加可行

Conclusion: 该工作展示了使用简单可分态实现数据隐藏的可能性，为量子信息处理提供了更实用的实现方案

Abstract: We consider the discrimination of two-party quantum states and provide a quantum data-hiding scheme using two-qubit separable states. We first provide a bound on the optimal local discrimination of two-party quantum states, and establish a sufficient condition under which a two-party quantum state ensemble can be used to construct a data-hiding scheme. We illustrate this condition with examples of two-qubit state ensembles consisting of two orthogonal separable states. As our data-hiding scheme can be implemented with separable states of the lowest possible dimension, its practical realization becomes significantly more attainable.

</details>


### [29] [Exponential convergence dynamics in Grover's search algorithm](https://arxiv.org/abs/2512.15100)
*Samuel Cogan,Jonathan Raghoonanan,Tim Byrnes*

Main category: quant-ph

TL;DR: 改进Grover搜索算法，消除振荡动态，使搜索过程呈指数衰减进入解态，无需提前知道解的数量


<details>
  <summary>Details</summary>
Motivation: Grover算法需要提前知道解的数量才能获得最优成功概率（"舒芙蕾问题"），现有解决方案要么效率低下，要么对控制误差敏感

Method: 修改Grover算法消除振荡动态，将解态转换为储层，使初始态非反射吸收；通过Trotter化连续算法得到量子电路

Result: 算法具有与原始算法相同的二次量子加速，但无需提前知道解的数量

Conclusion: 提出了一种改进的Grover搜索算法，解决了"舒芙蕾问题"，在保持量子加速的同时消除了对解数量先验知识的需求

Abstract: Grover's search algorithm is the cornerstone of many applications of quantum computing, providing a quadratic speed-up over classical methods. One limitation of the algorithm is that it requires knowledge of the number of solutions to obtain an optimal success probability, due to the oscillatory dynamics between the initial and solutions states (the ``soufflé problem''). While various methods have been proposed to solve this problem, each has their drawbacks in terms of inefficiency or sensitivity to control errors. Here, we modify Grover's algorithm to eliminate the oscillatory dynamics, such that the search proceeds as an exponential decay into the solution states. The basic idea is to convert the solution states into a reservoir by using ancilla qubits such that the initial state is nonreflectively absorbed. Trotterizing the continuous algorithm yields a quantum circuit that gives equivalent performance, which has the same quadratic quantum speedup as the original algorithm.

</details>


### [30] [Universal Blind Quantum Computation with Recursive Rotation Gates](https://arxiv.org/abs/2512.15101)
*Mohit Joshi,Manoj Kumar Mishra,S. Karthikeyan*

Main category: quant-ph

TL;DR: 提出基于参数旋转门递归解密的通用盲量子计算协议，无需服务器端高度纠缠态，减少安全变分算法原型设计的通信轮次


<details>
  <summary>Details</summary>
Motivation: 现有盲量子计算协议要么依赖高度纠缠资源态（基于测量的模型），要么基于非参数资源集（基于电路的模型），这些限制阻碍了在NISQ时代特别是依赖参数门的混合量子-经典基础设施中的实际应用

Method: 基于参数旋转门的递归解密协议，不需要服务器端高度纠缠态，显著减少通信轮次

Result: 实现了通用盲量子计算协议，适用于安全变分算法的实际原型设计

Conclusion: 该协议解决了现有盲量子计算协议在NISQ时代的实际应用限制，为混合量子-经典基础设施中的安全计算提供了更实用的解决方案

Abstract: Blind Quantum Computation lets a limited-capability client delegate its complex computation to a remote server without revealing its data or computation. Several such protocols have been proposed under varied quantum computing models. However, these protocols either rely on highly entangled resource states (in measurement-based models) or are based on non-parametric resource sets (in circuit-based models). These restrictions hinder the practical applicability of such an algorithm in the NISQ era, especially concerning the hybrid quantum-classical infrastructure, which depends on parametric gates. We present a protocol for universal blind quantum computation based on recursive decryption of parametric rotation gates, which does not require a highly entangled state at the server side and substantially reduces the communication rounds required for practical prototyping of secure variational algorithms.

</details>


### [31] [Defect-Driven Nonlinear and Nonlocal Perturbations in Quantum Chains](https://arxiv.org/abs/2512.15130)
*Anish Acharya,Luca Giuggioli,Shamik Gupta*

Main category: quant-ph

TL;DR: 单缺陷可显著改变有限周期紧束缚晶格上的波函数扩展，产生非线性非局域效应，包括输运的非单调抑制、远距离增强局域化，以及长时对初始位置的强敏感性。


<details>
  <summary>Details</summary>
Motivation: 传统上量子系统中的输运和局域化主要归因于空间扩展的随机无序，而少数可控缺陷的影响在工程量子平台中虽相关但未被充分探索。

Method: 引入解析框架，将经典随机游走研究中的缺陷技术应用于有限孤立周期紧束缚晶格，获得精确的时间分辨格点占据概率和多个相关可观测量。

Result: 即使单个缺陷也能诱导显著的非线性和非局域效应：输运的非单调抑制、远距离格点的增强局域化、长时对初始粒子位置的强敏感性。

Conclusion: 最小扰动可产生意想不到的长时输运特征，建立了微观缺陷驱动的量子局域化机制。

Abstract: Transport and localization in isolated quantum systems are typically attributed to spatially-extended disorder, leaving the influence of a few controllable defects largely unexplored despite their relevance to engineered quantum platforms. We introduce an analytic framework showing how a single defect profoundly reshapes wave-function spreading on a finite isolated and periodic tight-binding lattice. Adapting the defect technique from classical random-walk studies, we obtain exact time-resolved site-occupation probabilities and several observables of interest. Even one defect induces striking nonlinear and nonlocal effects, including non-monotonic suppression of transport, enhanced localization at distant sites, and strong sensitivity to the initial particle position at long times. These results demonstrate that minimal perturbations can generate unexpected long-time transport signatures, establishing a microscopic defect-driven mechanism of quantum localization.

</details>


### [32] [Composite N-Q-S: Serial/Parallel Instrument Axioms, Bipartite Order-Effect Bounds, and a Monitored Lindblad Limit](https://arxiv.org/abs/2512.15166)
*Kazuyuki Yoshida*

Main category: quant-ph

TL;DR: 该论文提出了一种用于顺序量子测量的复合操作架构，提供了严格的顺序效应边界、数据驱动的指数混合速率、可观测偏差的量化界限，以及离散监测与连续时间动力学之间的明确联系。


<details>
  <summary>Details</summary>
Motivation: 量子测量中的顺序效应和混合速率通常只有渐近结果，缺乏有限样本的明确常数和可数据估计的保证。本文旨在超越渐近陈述，为顺序效应控制和操作混合提供可数据估计的明确常数。

Method: 基于GKLS框架，开发复合操作架构，将Doeblin型小化升级到复合仪器，推导钻石范数交换子界限，建立监测Lindblad极限，并通过精确二项式区间提供有限样本证书。

Result: 获得了紧致的顺序效应边界、操作Doeblin常数的乘积下界、数据驱动的指数混合速率、可观测偏差的量化界限，以及离散监测循环与连续时间GKLS动力学之间的明确联系。

Conclusion: 该框架将顺序效应控制和操作混合置于统一的定量轴上，从投影对的等式窗口到监测下的认证网络混合，为量子信息和量子基础领域提供可数据估计且可转移到设备级保证的明确常数。

Abstract: We develop a composite operational architecture for sequential quantum measurements that (i) gives a tight bipartite order-effect bound with an explicit equality set characterized on the Halmos two-subspace block, (ii) upgrades Doeblin-type minorization to composite instruments and proves a product lower bound for the operational Doeblin constants, yielding data-driven exponential mixing rates, (iii) derives a diamond-norm commutator bound that quantifies how serial and parallel rearrangements influence observable deviations, and (iv) establishes a monitored Lindblad limit that links discrete look-return loops to continuous-time GKLS dynamics under transparent assumptions. Building on the GKLS framework of Gorini, Kossakowski, Sudarshan, Lindblad, Davies, Spohn, and later work of Fagnola-Rebolledo and Lami et al., we go beyond asymptotic statements by providing finite-sample certificates for the minorization parameter via exact binomial intervals and propagating them to rigorous bounds on the number of interaction steps required to attain a prescribed accuracy. A minimal qubit toy model and CSV-based scripts are supplied for full reproducibility. Our results position order-effect control and operational mixing on a single quantitative axis, from equality windows for pairs of projections to certified network mixing under monitoring. The framework targets readers in quantum information and quantum foundations who need explicit constants that are estimable from data and transferable to device-level guarantees.

</details>


### [33] [Sharing quantum indistinguishability with multiple parties](https://arxiv.org/abs/2512.15199)
*Lemieux Wang,Hanwool Lee,Joonwoo Bae,Kieran Flatt*

Main category: quant-ph

TL;DR: 提出基于最大置信度测量的序列态区分方案，允许多方共享单个量子系统产生的量子不确定性（以最大相对熵衡量），利用弱测量实现多用户对同一量子系统的态区分。


<details>
  <summary>Details</summary>
Motivation: 量子不可区分性（非正交量子态的不可区分性）是量子密码学和随机数生成等应用中的重要资源。需要开发能够允许多方共享单个量子系统产生的量子不确定性的方案，以理解序列信息提取的极限并指导量子资源在序列设置中的共享。

Method: 基于最大置信度测量和弱测量的序列态区分方案。通过最大置信度测量实现态区分，利用弱测量允许多个参与方对单个量子系统进行序列态区分。方案分析了包含对称性和不包含对称性的多种示例。

Result: 提出了能够使多方共享单个量子系统产生的量子不确定性的序列态区分方案。该方案基于最大置信度测量，利用弱测量技术实现多用户对同一量子系统的序列态区分。

Conclusion: 该序列态区分方案对于理解序列信息提取的极限具有重要意义，并将指导量子资源在序列设置中的共享发展。方案通过最大置信度测量和弱测量实现了多方对单个量子系统量子不确定性的共享。

Abstract: Quantum indistinguishability of non-orthogonal quantum states is a valuable resource in quantum information applications such as cryptography and randomness generation. In this article, we present a sequential state-discrimination scheme that enables multiple parties to share quantum uncertainty, in terms of the max relative entropy, generated by a single party. Our scheme is based upon maximum-confidence measurements and takes advantages of weak measurements to allow a number of parties to perform state discrimination on a single quantum system. We review known sequential state discrimination and show how our scheme would work through a number of examples where ensembles may or may not contain symmetries. Our results will have a role to play in understanding the ultimate limits of sequential information extraction and guide the development of quantum resource sharing in sequential settings.

</details>


### [34] [Quantum Mpemba effect in Local Gauge Symmetry Restoration](https://arxiv.org/abs/2512.15223)
*Hao-Yue Qi,Wei Zheng*

Main category: quant-ph

TL;DR: 该论文研究具有局域规范对称性的规范理论中的量子Mpemba效应，在晶格Schwinger模型中发现了子系统规范结构由初态决定且演化中保持不变，并系统构造了展现QME的初态族。


<details>
  <summary>Details</summary>
Motivation: 理解孤立量子多体系统中的弛豫仍是核心挑战。量子Mpemba效应（QME）作为反直觉的弛豫现象，已在全局对称性系统中被广泛研究，但在具有局域规范对称性的规范理论中尚未探索。

Method: 研究晶格Schwinger模型中的QME，分析子系统约化密度矩阵的规范结构，研究对称淬火后规范对称性的动态恢复。通过解析和数值方法，考察Maxwell项为零和有限时的不同行为。在量子链接模型（截断晶格Schwinger模型）中进一步探索QME，并提出实验可观测的序参量。

Result: 发现子系统规范结构完全由初态决定且在时间演化中保持不变。当Maxwell项为零时，由于特殊守恒定律的出现，规范对称性恢复失败；但对于任何有限Maxwell项，在热力学极限下子系统规范对称性得以恢复。基于这些结果，系统构造了展现QME的初态族，并提出了能正确捕捉QME的实验可观测序参量。

Conclusion: 该工作证明了量子Mpemba效应在局域规范对称性中的普遍性，为正在进行中的规范理论量子模拟实验提供了直接相关的结果，展示了QME在更广泛对称性系统中的存在性。

Abstract: Understanding relaxation in isolated quantum many-body systems remains a central challenge. Recently, the quantum Mpemba effect (QME), a counterintuitive relaxation phenomenon, has attracted considerable attention and has been extensively studied in systems with global symmetries. Here, we study the QME in gauge theories with massive local gauge symmetries. In the lattice Schwinger model, we demonstrate that the gauge structure of the reduced density matrix of a subsystem is entirely determined by the initial state and remain unchanged during the time evolution. We then investigate whether gauge symmetry can be dynamically restored following a symmetric quench. Analytical and numerical results show that when the Maxwell term is zero, gauge symmetry restoration fails due to the emergence of a peculiar conservation law. However, for any finite Maxwell term, subsystem gauge symmetry is restored in the thermodynamic limit. Based on these results, we systematically construct a families of initial states exhibiting the QME. We further explore the QME in the quantum link model-a truncated lattice Schwinger model, which has been realized in experiments. Moreover, we propose an experimentally accessible order parameter that correctly captures the QME. Our work demonstrates the generality of the quantum Mpemba effect even in the local gauge symmetries, and are directly relevant to ongoing quantum simulation experiments of gauge theories.

</details>


### [35] [Decoherence in the Pure Dephasing Spin-Boson Model with Hermitian or Non-Hermitian Bath](https://arxiv.org/abs/2512.15297)
*Yue-Hong Wu,Ning-Hua Tong*

Main category: quant-ph

TL;DR: 该论文研究了量子比特在厄米与非厄米环境耦合下的退相干现象，发现非厄米环境能抑制退相干，揭示了非厄米环境工程在量子信息保护中的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究量子比特在厄米与非厄米环境耦合下的退相干机制，特别是探索非厄米环境对退相干的影响，以寻找抑制量子退相干的新方法。

Method: 使用纯退相自旋-玻色子模型，分析量子比特与厄米/非厄米环境的耦合，通过解析方法研究非平衡与平衡关联函数的关系，并分析短时/长时渐近行为。

Result: 1. 解析证明了非平衡关联函数P_x(t)与平衡关联函数C_x(t)的相似性；2. 发现P_x(t)的短时/长时渐近行为在整数A（耦合强度）和s（浴指数）处存在奇异依赖性；3. 发现非厄米环境在所有A和s值下都能抑制量子比特的退相干。

Conclusion: 非厄米环境能够有效抑制量子比特的退相干，这与先前Dey等人的结论相反，展示了非厄米环境工程在量子信息保护中的潜在应用价值。

Abstract: In this paper, we investigate the decoherence of qubit due to its coupling to a Hermitian or a non-Hermitian bath within the pure dephasing spin-boson model. First, using this model, we analytically establish the previously anticipated similarity between the non-equilibrium and the equilibrium correlation functions $P_x(t)$ and $C_x(t)$. Then, in the short/long time asymptotic behaviors of $P_x(t)$, we find singular dependence on $A$ (coupling strength) and $s$ (bath exponent) at their integer values. Finally, we find that the non-Hermitian bath tends to suppress the decoherence of qubit for all values of $A$ and $s$, in contrast to the conclusion of Dey et al. . Our results show the potential of non-Hermitian environment engineering in suppressing the decoherence of qubit.

</details>


### [36] [Continuous-mode analysis for practical continuous-variable quantum key distribution](https://arxiv.org/abs/2512.15301)
*Yanhao Sun,Jiayu Ma,Xiangyu Wang,Song Yu,Ziyang Chen,Hong Guo*

Main category: quant-ph

TL;DR: 该论文提出了一种基于时间模式的连续变量量子密钥分发理论框架，能更准确地描述设备非理想性，并通过优化脉冲整形格式和数字信号处理方法，在30公里光纤实验中实现了约50%的密钥率提升。


<details>
  <summary>Details</summary>
Motivation: 随着CV-QKD系统向数字化实现发展，设备非理想性导致光场从单模区域扩展到连续模区域，使得理论模型与实际系统之间存在不匹配问题。需要建立更准确的理论框架来描述设备非理想性并指导系统优化。

Method: 引入时间模式构建基于纠缠的方案，开发适用于连续模场景的密钥率计算方法。通过优化脉冲整形格式来改善探测器带宽受限条件下的性能，并提出线性加权重构数字信号处理方法。

Result: 实验证明优化脉冲整形格式能显著提升探测器带宽受限条件下的性能，提出的模型能有效描述采样时间偏差的影响。线性加权重构DSP方法在30公里光纤实验中实现了约50%的密钥率提升，无需额外硬件。

Conclusion: 提出的理论框架能适应更广泛的实验条件，可指导数字CV-QKD系统的优化。该方法在城域距离上实现了显著的性能提升，为实际CV-QKD系统的设计和优化提供了有效工具。

Abstract: Continuous-variable quantum key distribution (CV-QKD) enables two remote parties to establish information-theoretically secure keys and offers high practical feasibility due to its compatibility with mature coherent optical communication technologies. However, as CV-QKD systems progress toward digital implementations, device nonidealities drive the optical field from a single-mode to a continuous-mode region, thereby underscoring the mismatch between theoretical models and practical systems. Here, we introduce temporal modes to construct an entanglement-based scheme that more accurately captures device nonidealities and develop a corresponding secret key rate calculation method applicable to continuous-mode scenarios. We demonstrate that optimizing the pulse-shaping format can significantly improve performance under detector-bandwidth-limited conditions. Experimental results also confirm that the proposed model effectively describes the impact of sampling-time deviations. We further analyze a linear weighted-reconstruction digital signal processing method,which improves the secret key rate by approximately 50% in a 30-km fiber experiment without requiring additional hardware, demonstrating a substantial performance enhancement at metropolitan distances. The proposed theoretical framework accommodates a broader range of experimental conditions and can guide the optimization of digital CV-QKD systems.

</details>


### [37] [Practical Challenges in Executing Shor's Algorithm on Existing Quantum Platforms](https://arxiv.org/abs/2512.15330)
*Paul Bagourd,Julian Jang-Jaccard,Vincent Lenders,Alain Mermoud,Torsten Hoefler,Cornelius Hempel*

Main category: quant-ph

TL;DR: 当前量子计算机通过Shor算法破解RSA等公钥密码的能力有限，实验显示现有硬件与密码学相关整数分解需求存在巨大差距


<details>
  <summary>Details</summary>
Motivation: 量子计算机对RSA、ECC等公钥密码系统构成根本威胁，但实际量子硬件能力尚不明确。研究旨在评估当前云量子计算机使用Shor算法分解密钥的实际能力

Method: 在多个云量子计算机上实验运行Shor算法，使用公开可用的实现，评估不同密钥大小的分解能力

Result: 发现当前量子硬件能力与密码学相关整数分解需求存在巨大差距。电路构造仍需针对每个模数高度定制，机器保真度不稳定，错误率高且波动大

Conclusion: 虽然量子计算机理论上能破解公钥密码，但当前硬件能力有限，距离实际威胁密码系统仍有相当距离，需要更稳定的量子硬件和优化的电路实现

Abstract: Quantum computers pose a fundamental threat to widely deployed public-key cryptosystems, such as RSA and ECC, by enabling efficient integer factorization using Shor's algorithm. Theoretical resource estimates suggest that 2048-bit RSA keys could be broken using Shor's algorithm with fewer than a million noisy qubits. Although such machines do not yet exist, the availability of smaller, cloud-accessible quantum processors and open-source implementations of Shor's algorithm raises the question of what key sizes can realistically be factored with today's platforms. In this work, we experimentally investigate Shor's algorithm on several cloud-based quantum computers using publicly available implementations. Our results reveal a substantial gap between the capabilities of current quantum hardware and the requirements for factoring cryptographically relevant integers. In particular, we observe that circuit constructions still need to be highly specific for each modulus, and that machine fidelities are unstable, with high and fluctuating error rates.

</details>


### [38] [Wave-packet dynamics in pseudo-Hermitian lattices: Coexistence of Hermitian and non-Hermitian wavefronts](https://arxiv.org/abs/2512.15333)
*Alon Beck,Moshe Goldstein*

Main category: quant-ph

TL;DR: 非厄米晶格系统中波包动力学研究，发现双重波前传播现象：一个以非厄米速度传播，另一个以厄米速度传播。


<details>
  <summary>Details</summary>
Motivation: 研究非厄米系统中的波包动力学，揭示传统厄米系统之外的独特传播行为，探索非厄米物理中的新现象。

Method: 使用伪厄米哈密顿量理论框架，以典型的Hatano-Nelson模型为主要示例，结合解析预测和数值模拟验证。

Result: 发现双重波前共存现象，解释了包括"非厄米反射"、高斯波包突然位移、无序诱导波包涌现等多种非传统动力学效应。

Conclusion: 双重波前行为是理解非厄米系统动力学的关键，可能为非厄米系统拓扑性质提供新见解，并具有可测量的实验后果。

Abstract: This paper investigates wave-packet dynamics in non-Hermitian lattice systems and reveals a surprising phenomenon: The simultaneous propagation of two distinct wavefronts, one traveling at the non-Hermitian velocity and the other at the Hermitian velocity. We show that this dual-front behavior arises naturally in systems governed by a pseudo-Hermitian Hamiltonian. Using the paradigmatic Hatano-Nelson model as our primary example, we demonstrate that this coexistence is essential for understanding a wide array of unconventional dynamical effects, including abrupt ``non-Hermitian reflections'', sudden shifts of Gaussian wave-packets, and disorder-induced emergent packets seeded by the small initial tails. We present analytic predictions that closely match numerical simulations. These results may offer new insight into the topology of non-Hermitian systems and point toward measurable experimental consequences.

</details>


### [39] [A Quantum Bluestein's Algorithm for Arbitrary-Size Quantum Fourier Transform](https://arxiv.org/abs/2512.15349)
*Nan-Hong,Kuo,Renata Wong*

Main category: quant-ph

TL;DR: 提出量子版Bluestein算法(QBA)，实现任意N点的精确量子傅里叶变换，复杂度O((log N)²)，使用O(log N)量子比特，无需嵌入更大希尔伯特空间。


<details>
  <summary>Details</summary>
Motivation: 传统量子傅里叶变换(QFT)通常要求N为2的幂次，对于任意N需要嵌入更大希尔伯特空间，这增加了量子比特需求和计算复杂度。需要一种能处理任意N点QFT的高效算法。

Method: 将N维QFT酉矩阵分解为三个对角二次相位门和两个标准radix-2 QFT子电路（大小为M=2^m，其中M≥2N-1）。利用Bluestein算法的量子版本实现任意N点的精确傅里叶变换。

Result: 算法达到渐近门复杂度O((log N)²)，使用O(log N)量子比特，性能与m量子比特的2的幂次QFT相当。通过Qiskit实现和经典仿真验证了算法正确性，确认能产生任意长度输入的精确N点离散傅里叶变换。

Conclusion: QBA为任意N点QFT提供了高效实现方案，避免了传统方法中嵌入更大希尔伯特空间的需求，在量子比特利用和计算复杂度方面具有优势。

Abstract: We propose a quantum analogue of Bluestein's algorithm (QBA) that implements an exact $N$-point Quantum Fourier Transform (QFT) for arbitrary $N$. Our construction factors the $N$-dimensional QFT unitary into three diagonal quadratic-phase gates and two standard radix-2 QFT subcircuits of size $M = 2^m$ (with $M \ge 2N - 1$). This achieves asymptotic gate complexity $O((\log N)^2)$ and uses $O(\log N)$ qubits, matching the performance of a power-of-two QFT on $m$ qubits while avoiding the need to embed into a larger Hilbert space. We validate the correctness of the algorithm through a concrete implementation in Qiskit and classical simulation, confirming that QBA produces the exact $N$-point discrete Fourier transform on arbitrary-length inputs.

</details>


### [40] [Amplitude-amplified coherence detection and estimation](https://arxiv.org/abs/2512.15352)
*Rhea Alexander,Michalis Skotiniotis,Daniel Manzano*

Main category: quant-ph

TL;DR: 本文提出检测未知纯量子态相干性的协议，通过振幅放大技术将样本复杂度从Θ(c(|ψ⟩)⁻¹)降低到O(c(|ψ⟩)⁻¹/²)，并利用相位估计以O(1/ε)复杂度估计相干性度量。


<details>
  <summary>Details</summary>
Motivation: 量子相干性检测对量子理论基础和量子技术发展至关重要，但传统相干性见证方法只能检测部分量子态的相干性，无法处理未知纯量子态的情况。

Method: 1) 对于m个未知纯态|ψ⟩副本，证明检测相干性的样本复杂度为Θ(c(|ψ⟩)⁻¹)；2) 假设可访问制备|ψ⟩的幺正算符U_ψ及其逆，设计基于Grover振幅放大的相干性检测协议；3) 结合振幅放大和相位估计，实现几何相干性度量的加性误差估计。

Result: 1) 振幅放大协议将样本复杂度降低到O(c(|ψ⟩)⁻¹/²)；2) 相位估计协议以O(1/ε)复杂度估计相干性度量，优于蒙特卡洛方法的O(1/ε²)；3) 振幅估计协议的平均样本数提供了几何相干性度量的新操作解释；4) 推导了协议能容忍的噪声界限。

Conclusion: 本文开发了检测未知纯量子态相干性的高效协议，利用振幅放大技术显著降低样本复杂度，为几何相干性度量提供了新的操作解释，并分析了协议的噪声鲁棒性。

Abstract: The detection and characterization of quantum coherence is of fundamental importance both in the foundations of quantum theory as well as for the rapidly developing field of quantum technologies, where coherence has been linked to quantum advantage. Typical approaches for detecting coherence employ {\it coherence witnesses} -- observable quantities whose expectation value can be used to certify the presence of coherence. By design, coherence witnesses are only able to detect coherence for some, but not all, possible states of a quantum system. In this work we construct protocols capable of detecting the presence of coherence in an {\it unknown} pure quantum state $|ψ\rangle$. Having access to $m$ copies of an unknown pure state $|ψ\rangle$ we show that the sample complexity of any experimental procedure for detecting coherence with constant probability of success $\ge 2/3$ is $Θ(c(|ψ\rangle)^{-1})$, where $c(|ψ\rangle)$ is the geometric measure of coherence of $|ψ\rangle$. However, assuming access to the unitary $U_ψ$ which prepares the unknown state $|ψ\rangle$, and its inverse $U_ψ^\dagger$, we devise a coherence detecting protocol that employs amplitude-amplification {\it a la} Grover, and uses a quadratically smaller number $O(c(|ψ\rangle)^{-1/2})$ of samples. Furthermore, by augmenting amplitude amplification with phase estimation we obtain an experimental estimation of upper bounds on the geometric measure of coherence within additive error $\varepsilon$ with a sample complexity that scales as $O(1/\varepsilon)$ as compared to the $O(1/\varepsilon^2)$ sample complexity of Monte Carlo estimation methods. The average number of samples needed in our amplitude estimation protocol provides a new operational interpretation for the geometric measure of coherence. Finally, we also derive bounds on the amount of noise our protocols are able to tolerate.

</details>


### [41] [Quditto: Emulating and Orchestrating Distributed QKD Network Deployments](https://arxiv.org/abs/2512.15408)
*Blanca Lopez,Angela Diaz-Bricio,Javier Perez,Ivan Vidal,Francisco Valera*

Main category: quant-ph

TL;DR: Quditto是一个自动化开放访问的量子密钥分发（QKD）仿真平台，结合高保真量子信道建模和标准化密钥交付API，让用户能够像使用真实QKD硬件一样与仿真网络交互。


<details>
  <summary>Details</summary>
Motivation: 量子密钥分发虽然提供信息论安全性，但专用硬件和光纤基础设施的成本和复杂性限制了大规模部署和实验。需要一种能够模拟真实QKD网络行为的平台，以便进行研究和开发。

Method: 设计了一个模块化的仿真平台，支持可插拔的协议实现、复杂的密钥管理方案和详细的信道模型（包括可变衰减和退相干）。平台提供标准化密钥交付API，实现与真实硬件的无缝交互。

Result: 通过部署不同规模的网络验证了Quditto的有效性，并通过两个概念验证场景（窃听者攻击和异构信道条件）展示了平台的灵活性。

Conclusion: Quditto为QKD研究和开发提供了一个高保真、灵活且易于使用的仿真平台，有助于克服真实硬件部署的成本和复杂性障碍，促进量子安全通信的发展。

Abstract: Quantum Key Distribution (QKD) offers information-theoretic security by leveraging quantum mechanics, yet the cost and complexity of dedicated hardware and fiber infrastructure have so far limited large-scale deployment and experimentation. In this paper, we introduce Quditto, an automated open-access emulation platform that combines high-fidelity quantum-channel modeling with a standardized key-delivery API, enabling users to interact with the emulated network exactly as they would with real QKD hardware. Quditto modular design supports pluggable protocol implementations, complex key management schemes and detailed channel models, including variable attenuation and decoherence. We validate Quditto by deploying networks of various sizes and demonstrate its flexibility through two proof-of-concept scenarios featuring eavesdropper attacks and heterogeneous channel conditions.

</details>


### [42] [Hamiltonian and double-bracket flow formulations of quantum measurements](https://arxiv.org/abs/2512.15412)
*Aarón Villanueva,Luis Pedro García-Pintos*

Main category: quant-ph

TL;DR: 该论文提出一个统一框架，将量子测量动力学、哈密顿动力学和双括号梯度流联系起来，将波函数坍解释为粗粒化的随机哈密顿动力学或双括号梯度流。


<details>
  <summary>Details</summary>
Motivation: 建立量子测量动力学与哈密顿动力学、梯度流之间的统一理论框架，为波函数坍提供新的物理解释，并基于此设计量子反馈控制过程。

Method: 通过构造产生与连续量子测量相同状态动力学的随机哈密顿量，将测量过程重新解释为粗粒化哈密顿动力学；同时将测量过程重新解释为双括号梯度流，该梯度流最小化被监测可观测量方差。

Result: 证明了波函数坍可以解释为粗粒化的随机哈密顿动力学或双括号梯度流；该重新解释有助于设计量子反馈过程，包括制备目标哈密顿量基态的确定性双括号流方程和态制备反馈过程。

Conclusion: 量子测量动力学、哈密顿动力学和双括号梯度流可以通过统一框架联系起来；波函数坍具有新的动力学解释；该框架为量子反馈控制设计提供了新方法，反馈过程可重新解释为具有倾斜不动点的梯度流。

Abstract: We introduce a framework that unifies quantum measurement dynamics, Hamiltonian dynamics, and double-bracket gradient flows. We do so by providing explicit expressions for stochastic Hamiltonians that produce state dynamics identical to those that happen during continuous quantum measurements. When such dynamical processes are integrated over sufficiently long time intervals, they yield the same results and statistics as during wavefunction collapse. That is, wavefunction collapse can be interpreted as coarse-grained (stochastic) Hamiltonian dynamics. Alternatively, wavefunction collapse can be interpreted as double-bracket gradient flows determined by derivatives of (stochastic) potentials defined in terms of observables with direct physical interpretations. The gradient flows minimize the variance of the monitored observable. Our derivations hold for general monitoring described by non-Hermitian jump processes. We show that such reinterpretations of measurement dynamics facilitate the design of feedback processes. In particular, we introduce feedback processes that yield deterministic double-bracket flow equations, which prepare ground states of a target Hamiltonian, and feedback processes for state preparation. We conclude by re-interpreting feedback processes as gradient flows with tilted fixed points.

</details>


### [43] [A short history of Quantum Illumination](https://arxiv.org/abs/2512.15415)
*Marco Genovese,Ivano Ruo-Berchera*

Main category: quant-ph

TL;DR: 量子照明协议的历史回顾：该量子技术具有抗噪声和损耗的鲁棒性，在应用中前景广阔


<details>
  <summary>Details</summary>
Motivation: 量子照明作为最有趣的量子技术之一，一方面具有重要的应用前景，另一方面是少数能够抵抗噪声和损耗的量子协议，值得对其发展历史进行总结

Method: 本文采用文献综述和历史回顾的方法，对量子照明协议的发展历程进行梳理和总结

Result: 提供了量子照明协议的简要历史概述，展示了该技术从理论到应用的发展脉络

Conclusion: 量子照明是一个重要的量子技术领域，其抗噪声和损耗的特性使其在实际应用中具有独特优势，对其历史的回顾有助于理解该技术的发展轨迹

Abstract: Quantum illumination represents one of the most interesting examples of quantum technologies. On the one hand, it can find significant applications; on the other hand, it is one of the few quantum protocols robust against noise and losses. Here we present a short summary of the history of this quantum protocol.

</details>


### [44] [Characterizing Fisher information of quantum measurement](https://arxiv.org/abs/2512.15428)
*Rakesh Saini,Jukka Kiukas,Daniel Burgarth,Alexei Gilchrist*

Main category: quant-ph

TL;DR: 本文建立了信息完备测量与量子参数估计之间的联系，通过算子框架理论分析经典与量子Fisher信息的比值，揭示了信息完备性对局部量子参数估计施加的基本权衡。


<details>
  <summary>Details</summary>
Motivation: 信息完备测量是通用量子态重构的基础，而量子参数估计基于量子态流形的局部结构。本文旨在建立这两方面之间的理论联系，特别是在单个信息完备测量的背景下。

Method: 采用适当调整的算子框架理论，通过分析相关框架算子的谱分解，将经典Fisher信息与量子Fisher信息的比值进行界定，并将这些界限与参数编码的最优和最差方向联系起来。

Result: 获得了信息提取的几何和操作表征，揭示了信息完备性对局部量子参数估计施加的基本权衡，建立了信息完备测量与参数估计精度之间的理论关系。

Conclusion: 通过算子框架理论成功建立了信息完备测量与量子参数估计之间的理论联系，为理解信息提取的基本限制提供了新的视角，揭示了信息完备性在局部量子参数估计中的基本权衡作用。

Abstract: Informationally complete measurements form the foundation of universal quantum state reconstruction, while quantum parameter estimation is based on the local structure of the manifold of quantum states. Here we establish a general link between these two aspects, in the context of a single informationally complete measurement, by employing a suitably adapted operator frame theory. In particular, we bound the ratio between the classical and quantum Fisher information in terms of the spectral decomposition of the associated frame operator, and connect these bounds to the optimal and least optimal directions for parameter encoding. The geometric and operational characterization of information extraction thus obtained reveals the fundamental tradeoff imposed by informational completeness on local quantum parameter estimation.

</details>


### [45] [The inverse parametric problem](https://arxiv.org/abs/2512.15453)
*Michele Cortinovis,Fabio Lingua,David B. Haviland*

Main category: quant-ph

TL;DR: 提出一种计算参量振荡器泵浦波形频率分量的方法，用于实现模式间所需的频率混合或散射，并通过实验验证了其在微波频率下实现复杂散射过程的能力。


<details>
  <summary>Details</summary>
Motivation: 需要一种系统方法来设计和控制参量振荡器中模式间的频率混合和散射过程，这对于编码和操纵多模高斯态的连续变量量子信息至关重要。

Method: 开发了计算泵浦波形频率分量的方法，通过数值分析验证，研究了其对高斯噪声的敏感性，并提出了动态控制模式散射的近似方法。

Result: 实验成功实现了涉及多个模式的复杂散射过程，包括非互易模式循环，并展示了在微波频率下按预定方式快速路由信号的能力。

Conclusion: 这些方法为使用多模高斯态编码和操纵连续变量量子信息提供了有用的工具，能够实现复杂的模式散射和动态信号路由。

Abstract: We present a method to calculate the frequency components of a pump waveform driving a parametric oscillator, which realizes a desired frequency mixing or scattering between modes. The method is validated by numerical analysis and we study its sensitivity to added Gaussian noise. A series of experiments apply the method and demonstrate its ability to realize complex scattering processes involving many modes at microwave frequencies, including non-reciprocal mode circulation. We also present an approximate method to dynamically control mode scattering, capable of rapidly routing signals between modes in a prescribed manner. These methods are useful tools for encoding and manipulating continuous variable quantum information with multi-modal Gaussian states.

</details>


### [46] [Benchmarking Atomic Ionization Driven by Strong Quantum Light](https://arxiv.org/abs/2512.15458)
*Yi-Jia Mao,En-Rui Zhou,Yang Li,Pei-Lun He,Feng He*

Main category: quant-ph

TL;DR: 通过求解全量子化含时薛定谔方程，发现Q表示法在描述强量子光与原子相互作用时存在局限性，并基于费曼路径积分建立了能正确处理电子-光子量子纠缠的理论框架。


<details>
  <summary>Details</summary>
Motivation: 高强度量子光脉冲为控制光-物质相互作用提供了新工具，但目前描述强量子光与原子分子相互作用的理论框架的严谨性尚未得到验证。

Method: 1. 求解原子暴露于明亮压缩真空光下的全量子化含时薛定谔方程，建立严谨基准；2. 基于费曼路径积分开发能正确处理电子-光子量子纠缠的通用理论框架。

Result: 1. 发现广泛使用的Q表示法虽然能准确再现总光电子谱，但完全无法捕捉电子-光子联合能谱；2. 建立了能克服这一局限性的新理论框架。

Conclusion: 研究结果为新兴的强场量子光学领域提供了定量基准和基础理论见解，揭示了现有理论框架的局限性并提出了改进方案。

Abstract: The recently available high-intensity quantum light pulses provide novel tools for controlling light-matter interactions. However, the rigor of the theoretical frameworks currently used to describe the interaction of strong quantum light with atoms and molecules remains unverified. Here, we establish a rigorous benchmark by solving the fully quantized time-dependent Schrödinger equation for an atom exposed to bright squeezed vacuum light. Our \textit{ab initio} simulations reveal a critical limitation of the widely used $Q$-representation: although it accurately reproduces the total photoelectron spectrum after tracing over photon states, it completely fails to capture the electron-photon joint energy spectrum. To overcome this limitation, we develop a general theoretical framework based on the Feynman path integral that properly incorporates the electron-photon quantum entanglement. Our results provide both quantitative benchmarks and fundamental theoretical insights for the emerging field of strong-field quantum optics.

</details>


### [47] [Lower Bounding the Secret Key Capacity of Bosonic Gaussian Channels via Optimal Gaussian Measurements](https://arxiv.org/abs/2512.15502)
*Giuseppe Ortolano,Stefano Pirandola,Leonardo Banchi*

Main category: quant-ph

TL;DR: 本文研究了玻色量子信道中基于最优单模高斯测量的全高斯协议的最大可达私密通信速率，为信道私密容量提供了下界。


<details>
  <summary>Details</summary>
Motivation: 研究玻色量子信道中全高斯协议的私密通信性能，为相位不敏感高斯信道建立私密容量的下界。

Method: 采用基于最优单模高斯测量的全高斯协议，分析相位不敏感高斯信道类，包括热损耗信道、热放大信道和加性噪声信道。

Result: 对于热损耗和热放大信道，验证了先前协议的优化性并提供了简化的性能评估公式；对于加性噪声信道，获得了比以往更好的下界。

Conclusion: 全高斯协议在玻色量子信道私密通信中能达到的最大速率建立了信道私密容量的下界，为相关信道提供了优化的性能评估方法。

Abstract: We find the maximum rate achievable in the private communication over a bosonic quantum channel with a fully Gaussian protocol based on optimal single-mode Gaussian measurements. This rate establishes a lower bound on the secret rate capacity of the channel. We focus on the class of phase-insensitive Gaussian channels. For the thermal-loss and thermal amplification channels, our results demonstrate the optimality, within the constraints of our analysis, of previously proposed protocols, while also providing a significantly simplified formula for their performance evaluation. For the added noise channel, our rate provides a better lower bound than any previously known.

</details>


### [48] [Decoherence dynamics across sub-Planckian to arbitrary scales using kitten states](https://arxiv.org/abs/2512.15513)
*Naeem Akhtar,Jia-Xin Peng,Tan Hailin,Xiaosen Yang,Dong Wang*

Main category: quant-ph

TL;DR: 该研究探讨了量子态在相空间中的精细结构（特别是亚普朗克尺度特征）与环境退相干之间的权衡关系，发现更精细的相空间特征虽然能提升量子传感精度，但也更容易受到退相干影响而变得脆弱。


<details>
  <summary>Details</summary>
Motivation: 环境退相干会破坏量子系统的相干性和干涉效应，影响量子态关键特性的保持。不同量子态在相空间中的特征结构对退相干的敏感度不同，理解这种关系对于量子传感应用至关重要。

Method: 研究罗盘态及其光子增加和光子减少变体，这些态具有超越普朗克尺度的相空间特征。使用成熟的理论技术分析这些态与热库的相互作用，考察相空间精细结构与退相干程度之间的关系。

Result: 研究发现相空间中最精细特征（如亚普朗克结构）的精细程度与退相干程度存在明显权衡：增加参数能增强相空间中的亚普朗克精度，但同时会放大这些罗盘态对退相干的脆弱性。

Conclusion: 该研究揭示的权衡关系具有普适性，适用于任何与热库相互作用的纯量子态：相空间扩展越大，特征结构的可持续性越强；而更精细的亚普朗克尺度特征虽然能提升传感精度，但更容易受到退相干破坏。

Abstract: Environmental decoherence occurs when a quantum system interacts with its surroundings, progressively reducing quantum interference and coherence, complicating the preservation of critical quantum properties over time, especially during experimental implementation. The effect of decoherence varies depending on the phase-space features of quantum states, which are theoretically characterized by the Wigner phase space and appear at different scales. We explore the compass state and its photon-added and photon-subtracted variants, each of which exhibits phase-space features with dimensions beyond the Planck scale, making them suitable for quantum sensing applications. We investigate the interaction of these states with a heat reservoir by employing a range of well-established theoretical techniques, revealing a clear tradeoff between the degree of fineness in the smallest features, such as the sub-Planck structure, and the extent of decoherence. Specifically, increasing the parameters enhances sub-Planck precision in phase space, concomitantly amplifying the fragility of these compass states to undesired decoherence. Our general illustration, validated through these compass states, also applies to any pure quantum state interacting with the considered heat reservoir, exhibiting enhanced sustainability of features at larger phase-space extensions.

</details>


### [49] [Quadratic power enhancement in extended Dicke quantum battery](https://arxiv.org/abs/2512.15607)
*Harsh Sharma,Himadri Shekhar Dhar*

Main category: quant-ph

TL;DR: 该论文展示了一种由N个二能级系统（自旋）与两个光子腔模相互作用的电池，其中一个腔模处于色散区，实现了功率的二次增强（N²缩放）。


<details>
  <summary>Details</summary>
Motivation: 研究量子电池的功率增强机制，探索超越Dicke电池的量子优势，同时保持能量效率并提高系统的可调谐性和噪声稳定性。

Method: 采用混合量子系统：N个二能级系统（自旋）与两个光子腔模相互作用，其中一个腔模工作在色散区。通过量子关联和演化速度的N²缩放实现功率增强。

Result: 实现了功率的二次增强（N²缩放），这种增强源于量子关联和演化速度的同时N²缩放，展示了真正的量子优势。系统具有实验可行性，功率增强不以显著牺牲能量效率为代价，且具有更好的可调谐性和噪声稳定性。

Conclusion: 该混合量子电池方案在功率增强方面展示了真正的量子优势，相比Dicke电池具有更好的性能表现，同时保持了能量效率、可调谐性和噪声稳定性，具有实验实现前景。

Abstract: We demonstrate a quadratic enhancement of power in a battery consisting of $N$ two-level systems or spins interacting with two photonic cavity modes, where one of the modes is in the dispersive regime. In contrast to Dicke batteries, the power enhancement arises from a $N^2$ scaling of both quantum correlations and speed of evolution, thus highlighting genuine quantum advantage. Moreover, this hybrid setup is experimentally realizable and ensures that power enhancement is not achieved at significant cost to energy efficiency, while allowing for greater tunability and stable operation in the presence of noise.

</details>


### [50] [Implementation of the Quantum Fourier Transform on a molecular qudit with full refocusing and state tomography](https://arxiv.org/abs/2512.15611)
*Marcos Rubín-Osanz,Laura Bersani,Simone Chicco,Giuseppe Allodi,Roberto De Renzi,Athanasios Mavromagoulos,Michael D. Roy,Stergios Piligkos,Elena Garlatti,Stefano Carretta*

Main category: quant-ph

TL;DR: 在173Yb(trensal)分子自旋qudit中实现了量子傅里叶变换，通过全重聚焦协议抑制非均匀展宽，展示了分子自旋qudit量子逻辑的可行性。


<details>
  <summary>Details</summary>
Motivation: 镧系分子自旋qudit是量子技术的潜力平台，但实际演示其量子算法能力的研究较少，主要挑战在于如何在长脉冲序列中精确控制qudit态间的相干性。

Method: 在173Yb(trensal) qudit中实现量子傅里叶变换，采用嵌入全重聚焦协议来抑制非均匀展宽，通过完整态层析评估算法性能，并用模拟分析非均匀展宽的物理机制。

Result: 成功实现了高保真度的量子傅里叶变换，全重聚焦协议有效抑制了非均匀展宽，完整态层析验证了算法性能，模拟揭示了非均匀展宽的物理机制。

Conclusion: 这项工作证明了分子自旋qudit上实现量子逻辑的可行性，凸显了其在量子技术中的潜力，为未来量子算法在分子自旋系统中的实现奠定了基础。

Abstract: Molecular spin qudits based on lanthanide complexes offer a promising platform for quantum technologies, combining chemical tunability with multi-level encoding. However, experimental demonstrations of their envisaged capabilities remain scarce, posing the difficulty of achieving precise control over coherences between qudit states in long pulse sequences. Here, we implement in 173Yb(trensal) qudit the Quantum Fourier Transform (QFT), a core component of numerous quantum algorithms, storing quantum information in the phases of coherences. QFT provides an ideal benchmark for coherence manipulation and an unprecedented challenge for molecular spin qudits. We address this challenge by embedding a full-refocusing protocol for spin qudits in our algorithm, mitigating inhomogeneous broadening and enabling a high-fidelity recovery of the state. Complete state tomography demostrates the performance of the algorithm, while simulations provide insight into the physical mechanisms behind inhomogeneous broadening. This work shows the feasibility of quantum logic on molecular spin qudits and highlights their potential.

</details>


### [51] [Characterization of Generalized Coherent States through Intensity-Field Correlations](https://arxiv.org/abs/2512.15655)
*Ignacio Salinas Valdivieso,Victor Gondret,Gerd Hartmann S.,Mariano Uria,Pablo Solano,Carla Hermann-Avigliano*

Main category: quant-ph

TL;DR: 该论文提出使用强度-场关联函数作为非高斯量子态的非经典性见证，特别适用于广义相干态，其与单位值的任何偏离都指示非经典行为。


<details>
  <summary>Details</summary>
Motivation: 广义相干态是非高斯量子态的重要资源，具有Wigner负性和计量优势，但由于它们在所有阶都保持相干性，传统的强度-强度关联测量无法揭示其非经典特性。因此需要一种简单且实验可访问的方法来检测这些态的非经典特征。

Method: 提出使用强度-场关联函数作为非经典性见证。对于广义相干态，该归一化关联函数与单位值的任何偏离都指示非经典行为。推导了Kerr生成态的解析结果，并将分析扩展到广义相干态的统计混合。

Result: 强度-场关联函数能够有效检测广义相干态的非经典性，该方法具有实时、低复杂度的特点，适用于广泛的非线性体系实验。

Conclusion: 强度-场关联函数为检测非高斯量子态的非经典特征提供了一种实用工具，特别适用于广义相干态，能够实现实时、低复杂度的量子签名检测。

Abstract: Non-Gaussian quantum states of light are essential resources for quantum information processing and precision metrology. Among them, generalized coherent states (GCS), which naturally arise from the evolution of a coherent state with a nonlinear medium, exhibit useful quantum features such as Wigner negativity and metrological advantages [Phys. Rev. Res. 5, 013165 (2023)]. Because these states remain coherent to all orders, their nonclassical character cannot be revealed through standard intensity-intensity correlation measurements. Here, we demonstrate that the intensity-field correlation function alone provides a simple and experimentally accessible witness of nonclassicality. For GCSs, any deviation of this normalized correlation from unity signals nonclassical behavior. We derive analytical results for Kerr-generated states and extend the analysis to statistical mixtures of GCSs. The proposed approach enables real-time, low-complexity detection of quantum signatures in non-Gaussian states, offering a practical tool for experiments across a broad range of nonlinear regimes.

</details>


### [52] [All Entangled States are Nonlocal and Self-Testable in the Broadcast Scenario](https://arxiv.org/abs/2512.15656)
*Pavel Sekatski,Jef Pauwels*

Main category: quant-ph

TL;DR: 所有纠缠态在广播扩展的贝尔场景中都是非局域的，纠缠与贝尔非定域性之间的差距消失


<details>
  <summary>Details</summary>
Motivation: 纠缠与贝尔非定域性之间存在已知的不等价性：存在纠缠态在所有局域测量下都允许局域隐变量模型。本文旨在研究在贝尔场景的最小广播扩展中，这种差距是否消失。

Method: 假设量子理论的有效性，证明对于每个纠缠态ρ_AB，存在局域广播映射和局域测量，使得产生的四体关联无法被任何源在A|B切割上可分离的广播网络再现。

Result: 证明所有纠缠态在量子理论中都是广播非局域的，即纠缠与贝尔非定域性在广播扩展场景中等价。此外，所有（包括混合）多体态都可以根据自然的操作定义进行广播自测试。

Conclusion: 在贝尔场景的最小广播扩展中，纠缠与贝尔非定域性之间的差距完全消失，所有纠缠态都表现出非局域性。这一结果为量子纠缠的检测和表征提供了新的视角。

Abstract: Entanglement and Bell nonlocality are known to be inequivalent: there exist entangled states that admit a local hidden-variable model for all local measurements. Here we show that this gap disappears in a minimal broadcast extension of the Bell scenario. Assuming only the validity of quantum theory, we prove that for every entangled state $ρ_{AB}$ there exist local broadcasting maps and local measurements such that the resulting four--partite correlations cannot be reproduced by any broadcast network whose source is separable across the $A|B$ cut. Thus, all entangled states are broadcast nonlocal in quantum theory. In addition, we show that all (also mixed) multipartite states can be broadcast-self-tested, according to a natural operational definition.

</details>


### [53] [Prospects for quantum advantage in machine learning from the representability of functions](https://arxiv.org/abs/2512.15661)
*Sergi Masot-Llima,Elies Gil-Fuster,Carlos Bravo-Prieto,Jens Eisert,and Tommaso Guaita*

Main category: quant-ph

TL;DR: 该论文提出了一个连接参数化量子电路结构与可学习函数数学性质的框架，用于分析量子机器学习模型的经典可模拟性，并区分完全可模拟、函数空间经典可处理与保持量子优势的模型。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习领域存在大量模型和算法，需要清晰框架来理解哪些模型能真正实现量子优势，哪些可以被经典模拟，从而指导量子优势的探索。

Method: 引入连接参数化量子电路结构与可学习函数数学性质的框架，分析电路深度、非Clifford门数量等基本性质如何决定模型的经典可模拟性。

Result: 该框架揭示了现有模拟方法背后的去量子化共同路径，区分了完全可模拟、函数空间经典可处理与保持量子优势的模型，为量子机器学习提供了概念地图。

Conclusion: 该框架为量子机器学习领域提供了清晰的概念地图，阐明了不同模型与经典可模拟性的关系，并指出了量子优势可能存在的方向。

Abstract: Demonstrating quantum advantage in machine learning tasks requires navigating a complex landscape of proposed models and algorithms. To bring clarity to this search, we introduce a framework that connects the structure of parametrized quantum circuits to the mathematical nature of the functions they can actually learn. Within this framework, we show how fundamental properties, like circuit depth and non-Clifford gate count, directly determine whether a model's output leads to efficient classical simulation or surrogation. We argue that this analysis uncovers common pathways to dequantization that underlie many existing simulation methods. More importantly, it reveals critical distinctions between models that are fully simulatable, those whose function space is classically tractable, and those that remain robustly quantum. This perspective provides a conceptual map of this landscape, clarifying how different models relate to classical simulability and pointing to where opportunities for quantum advantage may lie.

</details>


### [54] [Combinatorial structures in quantum correlation: A new perspective](https://arxiv.org/abs/2512.15686)
*Rohit kumar,Satyabrata Adhikari*

Main category: quant-ph

TL;DR: 提出了一种基于图论的新型量子态——Aα-图态，通过图的度矩阵和邻接矩阵的凸组合构建，建立了纠缠检测的图论框架。


<details>
  <summary>Details</summary>
Motivation: 图论结构在量子系统描述和分析中具有核心作用，但现有的图态构建方法（如稳定子形式）有限。需要开发新的图态构建方法，并建立与纠缠检测的联系。

Method: 通过图的度矩阵D和邻接矩阵A_G的归一化凸组合构建Aα-图态，其中α∈(0,1]是可调参数。建立了正半定条件、PPT条件，并基于矩的纠缠检测准则（特别是p3-PPT准则）开发了图论表述。

Result: 确定了Aα-图态为正半定算子的条件，推导了仅依赖于图参数（邻接矩阵Frobenius范数、顶点度、顶点总数）的PPT条件。对于简单图，找到了使Aα-图态成为纠缠态的α参数范围。

Conclusion: Aα-图态提供了一种新的图态构建方法，建立了图论与基于矩的纠缠检测之间的桥梁，为从组合结构角度理解量子关联提供了新视角。

Abstract: Graph-theoretic structures play a central role in the description and analysis of quantum systems. In this work, we introduce a new class of quantum states, called $A_α$-graph states, which are constructed from either unweighted or weighted graphs by taking the normalised convex combination of the degree matrix $D$ and the adjacency matrix $A_G$ of a graph $G$. The constructed states are different from the standard graph states arising from stabiliser formalism. Our approach is also different from the approach used by Braunstein et al. This class of states depend on a tunable mixing parameter $α\in (0,1]$. We first establish the conditions under which the associated operator $ρ_α^{A_G}$ is positive semidefinite and hence represents a valid quantum state. We then derive a positive partial transposition (PPT) condition for $A_α$-graph states in terms of graph parameters. This PPT condition involves only the Frobenius norm of the adjacency matrix of the graph, the degrees of the vertices and the total number of vertices. For simple graphs, we obtain the range of the parameter $α$ for which the $A_α$-graph states represent a class of entangled states. We then develop a graph-theoretic formulation of a moments-based entanglement detection criterion, focusing on the recently proposed $p_3$-PPT criterion, which relies on the second and third moments of the partial transposition. Since the estimation of these moments is experimentally accessible via randomised measurements, swap operations, and machine-learning-based protocols, our approach provides a physically relevant framework for detecting entanglement in structured quantum states derived from graphs. This work bridges graph theory and moments-based entanglement detection, offering a new perspective on the role of combinatorial structures in quantum correlations.

</details>


### [55] [Error mitigation for logical circuits using decoder confidence](https://arxiv.org/abs/2512.15689)
*Maria Dincă,Tim Chan,Simon C. Benjamin*

Main category: quant-ph

TL;DR: 论文提出使用解码器置信度评分（DCS）来估计量子纠错中的逻辑错误概率，并探索了基于DCS的拒绝策略和最大似然推断方法来降低噪声影响。


<details>
  <summary>Details</summary>
Motivation: 量子计算机需要解码器来监测错误并找到合适的纠错方案。解码器置信度评分（DCS）可以用来评估解码成功的可能性，但如何有效利用DCS来降低整个电路的逻辑错误概率是一个重要问题。

Method: 采用游泳距离DCS（基于综合征簇之间的最短路径计算），通过张量网络收缩与互补间隙方法比较性能。探索了两种应用策略：1）对于浅层电路，当任何解码窗口产生异常低的DCS时中止执行；2）对于大型算法，使用DCS为每个电路输出分配唯一的逻辑错误概率，并基于此进行最大似然推断。

Result: 游泳距离DCS和互补间隙都能可靠估计解码窗口中的逻辑错误概率。对于距离-13的表面码，仅拒绝0.1%的DCS值就能将整个电路的逻辑错误概率降低超过5个数量级。DCS基础的拒绝策略在增强可观测量估计方面保持有效，最大似然推断方法可以在不增加量子成本的情况下将噪声影响降低一个数量级。

Conclusion: 解码器置信度评分是量子纠错中的有效工具，能够可靠估计逻辑错误概率。基于DCS的拒绝策略和最大似然推断方法可以显著降低噪声影响，这些方法可以结合使用以获得进一步改进，为量子计算中的错误缓解提供了实用方案。

Abstract: Fault-tolerant quantum computers use decoders to monitor for errors and find a plausible correction. A decoder may provide a decoder confidence score (DCS) to gauge its success. We adopt a swim distance DCS, computed from the shortest path between syndrome clusters. By contracting tensor networks, we compare its performance to the well-known complementary gap and find that both reliably estimate the logical error probability (LEP) in a decoding window. We explore ways to use this to mitigate the LEP in entire circuits. For shallow circuits, we just abort if any decoding window produces an exceptionally low DCS: for a distance-13 surface code, rejecting a mere 0.1% of possible DCS values improves the entire circuit's LEP by more than 5 orders of magnitude. For larger algorithms comprising up to trillions of windows, DCS-based rejection remains effective for enhancing observable estimation. Moreover, one can use DCS to assign each circuit's output a unique LEP, and use it as a basis for maximum likelihood inference. This can reduce the effects of noise by an order of magnitude at no quantum cost; methods can be combined for further improvements.

</details>


### [56] [A random purification channel for arbitrary symmetries with applications to fermions and bosons](https://arxiv.org/abs/2512.15690)
*Michael Walter,Freek Witteveen*

Main category: quant-ph

TL;DR: 论文提出了一种针对任意对称群的随机纯化通道的通用构造，将原始随机纯化定理推广到费米子和玻色子高斯态，并应用于最优费米子高斯态层析协议


<details>
  <summary>Details</summary>
Motivation: 将随机纯化通道从一般混合态推广到具有任意对称群（如费米子和玻色子高斯对称性）的量子态，以简化原始证明并扩展应用范围

Method: 为任意酉群G构造量子通道，将G生成的代数中的态映射到通过G上twirling操作获得的随机纯化态

Result: 获得了费米子和玻色子高斯纯化通道的存在性，首次实现了在模式和误差方面都最优的费米子高斯态层析协议，并改进了该类态的property test

Conclusion: 该通用构造不仅简洁证明了原始随机纯化定理，还为费米子和玻色子系统提供了新的纯化工具，在量子态层析和性质测试中具有重要应用价值

Abstract: The random purification channel maps n copies of any mixed quantum state to n copies of a random purification of the state. We generalize this construction to arbitrary symmetries: for any group G of unitaries, we construct a quantum channel that maps states contained in the algebra generated by G to random purifications obtained by twirling over G. In addition to giving a surprisingly concise proof of the original random purification theorem, our result implies the existence of fermionic and bosonic Gaussian purification channels. As applications, we obtain the first tomography protocol for fermionic Gaussian states that scales optimally with the number of modes and the error, as well as an improved property test for this class of states.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [57] [LLM as a Neural Architect: Controlled Generation of Image Captioning Models Under Strict API Contracts](https://arxiv.org/abs/2512.14706)
*Krunal Jesani,Dmitry Ignatov,Radu Timofte*

Main category: cs.LG

TL;DR: NN-Caption：基于LLM引导的神经架构搜索流水线，通过组合CNN编码器和序列解码器自动生成可运行的图像描述模型


<details>
  <summary>Details</summary>
Motivation: 传统神经架构搜索需要大量人工专业知识或自动化试错，本文旨在利用LLM自动化设计深度学习模型，减少人工干预

Method: 使用DeepSeek-R1-0528-Qwen3-8B作为主要生成器，基于严格Net API将LEMUR分类主干中的CNN编码器与序列解码器（LSTM/GRU/Transformer）组合，通过提示模板生成架构

Result: LLM生成了数十个描述模型，超过一半成功训练并产生有意义的描述；提供更多候选组件（10 vs 5）时成功率略有下降；报告了训练动态和最高BLEU-4分数

Conclusion: LLM引导的NAS具有潜力，不仅能提出架构，还能建议超参数和训练实践；通过提示规则和迭代代码修复解决了代码幻觉和API合规性问题；为LEMUR数据集添加了数十个新模型，促进可重复基准测试和AutoML研究

Abstract: Neural architecture search (NAS) traditionally requires significant human expertise or automated trial-and-error to design deep learning models. We present NN-Caption, an LLM-guided neural architecture search pipeline that generates runnable image-captioning models by composing CNN encoders from LEMUR's classification backbones with sequence decoders (LSTM/GRU/Transformer) under a strict Net API. Using DeepSeek-R1-0528-Qwen3-8B as the primary generator, we present the prompt template and examples of generated architectures. We evaluate on MS COCO with BLEU-4. The LLM generated dozens of captioning models, with over half successfully trained and producing meaningful captions. We analyse the outcomes of using different numbers of input model snippets (5 vs. 10) in the prompt, finding a slight drop in success rate when providing more candidate components. We also report training dynamics (caption accuracy vs. epochs) and the highest BLEU-4 attained. Our results highlight the promise of LLM-guided NAS: the LLM not only proposes architectures but also suggests hyperparameters and training practices. We identify the challenges encountered (e.g., code hallucinations or API compliance issues) and detail how prompt rules and iterative code fixes addressed them. This work presents a pipeline that integrates prompt-based code generation with automatic evaluation, and adds dozens of novel captioning models to the open LEMUR dataset to facilitate reproducible benchmarking and downstream AutoML research.

</details>


### [58] [Autonomous Source Knowledge Selection in Multi-Domain Adaptation](https://arxiv.org/abs/2512.14710)
*Keqiuyin Li,Jie Lu,Hua Zuo,Guangquan Zhang*

Main category: cs.LG

TL;DR: AutoS：一种多域自适应方法，通过自主选择源域样本和模型，利用密度驱动策略筛选最相关的源信息，并结合多模态预训练模型增强伪标签以减少目标域噪声。


<details>
  <summary>Details</summary>
Motivation: 在多源域自适应中，多个源域常包含大量冗余或不相关信息，这会损害迁移性能，特别是在大规模源域设置下。需要开发有效策略从大量源域中识别和选择最具可迁移性的知识来解决目标任务。

Method: 提出AutoS方法：1）采用密度驱动选择策略在训练中选择源域样本，并确定哪些源模型应对目标预测做出贡献；2）基于预训练多模态模型构建伪标签增强模块，以减轻目标标签噪声并改进自监督。

Result: 在真实世界数据集上的实验表明该方法具有优越性。

Conclusion: AutoS能够自主选择源域训练样本和模型，使目标任务预测能够利用更相关和可迁移的源信息，有效解决了多源域自适应中的信息冗余问题。

Abstract: Unsupervised multi-domain adaptation plays a key role in transfer learning by leveraging acquired rich source information from multiple source domains to solve target task from an unlabeled target domain. However, multiple source domains often contain much redundant or unrelated information which can harm transfer performance, especially when in massive-source domain settings. It is urgent to develop effective strategies for identifying and selecting the most transferable knowledge from massive source domains to address the target task. In this paper, we propose a multi-domain adaptation method named \underline{\textit{Auto}}nomous Source Knowledge \underline{\textit{S}}election (AutoS) to autonomosly select source training samples and models, enabling the prediction of target task using more relevant and transferable source information. The proposed method employs a density-driven selection strategy to choose source samples during training and to determine which source models should contribute to target prediction. Simulteneously, a pseudo-label enhancement module built on a pre-trained multimodal modal is employed to mitigate target label noise and improve self-supervision. Experiments on real-world datasets indicate the superiority of the proposed method.

</details>


### [59] [PIP$^2$ Net: Physics-informed Partition Penalty Deep Operator Network](https://arxiv.org/abs/2512.15086)
*Hongjin Mi,Huiqiang Lun,Changhong Mou,Yeyu Zhang*

Main category: cs.LG

TL;DR: PIP² Net：一种基于分区惩罚的物理信息深度算子网络，通过改进分区正则化技术，在保持DeepONet灵活性的同时提高表达能力和稳定性，在非线性PDE求解中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有算子学习方法（如DeepONet和FNO）需要大量训练数据、缺乏显式物理结构、存在主干网络特征不稳定的问题（如模式不平衡或崩溃），影响算子近似精度。受经典分区统一方法的稳定性和局部性启发，研究基于分区的正则化技术。

Method: 提出PIP² Net（物理信息分区惩罚深度算子网络），改进现有的POU-PI-DeepONet框架，引入更简化、更有原则的分区惩罚机制，协调主干网络输出，提高表达能力而不牺牲DeepONet的灵活性。

Result: 在三个非线性PDE（粘性Burgers方程、Allen-Cahn方程、扩散-反应系统）上评估，PIP² Net在预测精度和鲁棒性方面一致优于DeepONet、PI-DeepONet和POU-DeepONet。

Conclusion: 基于分区惩罚的正则化技术能有效提高算子学习的稳定性和表达能力，PIP² Net为参数化PDE的快速求解提供了更可靠的工具。

Abstract: Operator learning has become a powerful tool for accelerating the solution of parameterized partial differential equations (PDEs), enabling rapid prediction of full spatiotemporal fields for new initial conditions or forcing functions. Existing architectures such as DeepONet and the Fourier Neural Operator (FNO) show strong empirical performance but often require large training datasets, lack explicit physical structure, and may suffer from instability in their trunk-network features, where mode imbalance or collapse can hinder accurate operator approximation. Motivated by the stability and locality of classical partition-of-unity (PoU) methods, we investigate PoU-based regularization techniques for operator learning and develop a revised formulation of the existing POU--PI--DeepONet framework. The resulting \emph{P}hysics-\emph{i}nformed \emph{P}artition \emph{P}enalty Deep Operator Network (PIP$^{2}$ Net) introduces a simplified and more principled partition penalty that improved the coordinated trunk outputs that leads to more expressiveness without sacrificing the flexibility of DeepONet. We evaluate PIP$^{2}$ Net on three nonlinear PDEs: the viscous Burgers equation, the Allen--Cahn equation, and a diffusion--reaction system. The results show that it consistently outperforms DeepONet, PI-DeepONet, and POU-DeepONet in prediction accuracy and robustness.

</details>


### [60] [SepsisSuite: Beyond Risk Stratification -- A Comparative Analysis of Deep Fusion vs. Expert Stacking for Prescriptive Sepsis AI](https://arxiv.org/abs/2512.14712)
*Ryan Cartularo*

Main category: cs.LG

TL;DR: 本文对比了两种多模态融合架构用于脓毒症预测，发现新颖的端到端融合模型在小样本上过拟合，而设计的轻量级上下文感知混合专家模型实现了SOTA性能，并开发了临床部署框架SepsisSuite。


<details>
  <summary>Details</summary>
Motivation: 脓毒症占ICU入院近20%，但传统预测模型难以有效整合异质数据流，要么模态孤立，要么依赖脆弱的早期融合。需要探索更有效的多模态融合方法。

Method: 1. 对比端到端深度融合与上下文感知堆叠架构；2. 提出Quad-Modal Hierarchical Gated Attention Network (SepsisFusionFormer)；3. 发现其在小样本上过拟合后，设计SepsisLateFusion：将模态视为正交专家（"Historian"静态、"Monitor"时序、"Reader"NLP），通过CatBoost元学习器动态门控；4. 开发SepsisSuite部署框架。

Result: 1. SepsisFusionFormer在小抗生素队列(N≈2100)中因"注意力饥饿"过拟合，AUC仅0.66；2. SepsisLateFusion在临床发作前4小时预测达到SOTA性能：0.915 AUC；3. 通过校准决策阈值，漏诊病例减少48%；4. 四模态集成在多类抗生素选择任务中达到最高性能(0.72 AUC)。

Conclusion: 上下文感知混合专家架构在脓毒症预测中优于端到端深度融合，实现了SOTA性能并显著减少漏诊。开发的SepsisSuite框架为临床决策支持提供了实用工具，开启了真正的预防性干预窗口。

Abstract: Sepsis accounts for nearly 20% of global ICU admissions, yet conventional prediction models often fail to effectively integrate heterogeneous data streams, remaining either siloed by modality or reliant on brittle early fusion. In this work, we present a rigorous architectural comparison between End-to-End Deep Fusion and Context-Aware Stacking for sepsis tasks. We initially hypothesized that a novel Quad-Modal Hierarchical Gated Attention Network -- termed SepsisFusionFormer -- would resolve complex cross-modal interactions between vitals, text, and imaging. However, experiments on MIMIC-IV revealed that SepsisFusionFormer suffered from "attention starvation" in the small antibiotic cohort ($N \approx 2,100$), resulting in overfitting (AUC 0.66). This counterintuitive result informed the design of SepsisLateFusion, a "leaner" Context-Aware Mixture-of-Experts (MoE) architecture. By treating modalities as orthogonal experts -- the "Historian" (Static), the "Monitor" (Temporal), and the "Reader" (NLP) -- and dynamically gating them via a CatBoost meta-learner, we achieved State-of-the-Art (SOTA) performance: 0.915 AUC for prediction 4 hours prior to clinical onset. By calibrating the decision threshold for clinical safety, we reduced missed cases by 48% relative to the default operating point, thus opening a true preventative window for timely intervention over reactive alerts. Furthermore, for the novel prescriptive task of multi-class antibiotic selection, we demonstrate that a Quad-Modal Ensemble achieved the highest performance (0.72 AUC). These models are integrated into SepsisSuite, a deployment-ready Python framework for clinical decision support. SepsisSuite is available for free at: https://github.com/RyanCartularo/SepsisSuite-Info

</details>


### [61] [A Bayesian latent class reinforcement learning framework to capture adaptive, feedback-driven travel behaviour](https://arxiv.org/abs/2512.14713)
*Georges Sfeir,Stephane Hess,Thomas O. Hancock,Filipe Rodrigues,Jamal Amani Rad,Michiel Bliemer,Matthew Beck,Fayyaz Khan*

Main category: cs.LG

TL;DR: 提出了一种潜在类别强化学习(LCRL)模型，用于捕捉旅行决策中个体偏好形成和异质性，应用于驾驶模拟器数据，识别出三种不同的偏好适应模式。


<details>
  <summary>Details</summary>
Motivation: 旅行决策涉及经验形成过程，个体随时间学习偏好，同时存在显著的个体异质性（基础偏好和演化方式）。现有模型难以同时捕捉这两种现象。

Method: 提出潜在类别强化学习(LCRL)模型，通过变分贝叶斯方法估计参数，应用于驾驶模拟器数据集进行分析。

Result: 识别出三种不同的个体类别：第一类显示情境依赖偏好和情境特定开发倾向；第二类遵循持久开发策略；第三类采用探索策略结合情境特定偏好。

Conclusion: LCRL模型能有效捕捉旅行决策中的经验形成和个体异质性，为理解不同旅行者如何适应偏好提供了新视角。

Abstract: Many travel decisions involve a degree of experience formation, where individuals learn their preferences over time. At the same time, there is extensive scope for heterogeneity across individual travellers, both in their underlying preferences and in how these evolve. The present paper puts forward a Latent Class Reinforcement Learning (LCRL) model that allows analysts to capture both of these phenomena. We apply the model to a driving simulator dataset and estimate the parameters through Variational Bayes. We identify three distinct classes of individuals that differ markedly in how they adapt their preferences: the first displays context-dependent preferences with context-specific exploitative tendencies; the second follows a persistent exploitative strategy regardless of context; and the third engages in an exploratory strategy combined with context-specific preferences.

</details>


### [62] [Improving Underwater Acoustic Classification Through Learnable Gabor Filter Convolution and Attention Mechanisms](https://arxiv.org/abs/2512.14714)
*Lucas Cesar Ferreira Domingos,Russell Brinkworth,Paulo Eduardo Santos,Karl Sammut*

Main category: cs.LG

TL;DR: GSE ResNeXt：一种结合可学习Gabor卷积层和ResNeXt骨干网络的水下声学目标分类深度学习架构，通过注意力机制提升特征提取能力，在数据有限场景下优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 水下声学目标检测对环境和国防至关重要，但复杂的水下噪声和有限的数据集限制了现有机器学习方法的泛化能力和鲁棒性，需要更可靠的分类模型。

Method: 提出GSE ResNeXt架构，将可学习的Gabor卷积层与ResNeXt骨干网络结合，并加入挤压-激励注意力机制。Gabor滤波器作为二维自适应带通滤波器扩展特征通道表示，与通道注意力结合提升训练稳定性和收敛速度。

Result: 在三个复杂度递增的分类任务中，GSE ResNeXt在分类性能上持续优于Xception、ResNet和MobileNetV2等基线模型。Gabor卷积的加入使训练时间减少28%，且发现船只与传感器距离对性能有显著影响。

Conclusion: 信号处理策略对提升模型在不同环境条件下的可靠性和泛化能力至关重要，特别是在数据有限的水下声学分类场景中。未来研究应关注减轻环境因素对输入信号的影响。

Abstract: Remotely detecting and classifying underwater acoustic targets is critical for environmental monitoring and defence. However, the complex nature of ship-radiated and environmental underwater noise poses significant challenges to accurate signal processing. While recent advancements in machine learning have improved classification accuracy, issues such as limited dataset availability and a lack of standardised experimentation hinder generalisation and robustness. This paper introduces GSE ResNeXt, a deep learning architecture integrating learnable Gabor convolutional layers with a ResNeXt backbone enhanced by squeeze-and-excitation attention mechanisms. The Gabor filters serve as two-dimensional adaptive band-pass filters, extending the feature channel representation. Its combination with channel attention improves training stability and convergence while enhancing the model's ability to extract discriminative features. The model is evaluated on three classification tasks of increasing complexity. In particular, the impact of temporal differences between the training and testing data is explored, revealing that the distance between the vessel and sensor significantly affects performance. Results show that, GSE ResNeXt consistently outperforms baseline models like Xception, ResNet, and MobileNetV2, in terms of classification performance. Regarding stability and convergence, the addition of Gabor convolutions in the initial layers of the model represents a 28% reduction in training time. These results emphasise the importance of signal processing strategies in improving the reliability and generalisation of models under different environmental conditions, especially in data-limited underwater acoustic classification scenarios. Future developments should focus on mitigating the impact of environmental factors on input signals.

</details>


### [63] [How a Bit Becomes a Story: Semantic Steering via Differentiable Fault Injection](https://arxiv.org/abs/2512.14715)
*Zafaryab Haider,Md Hafizur Rahman,Shane Moeykens,Vijay Devabhaktuni,Prabuddha Chakraborty*

Main category: cs.LG

TL;DR: 首次研究低层比特扰动如何影响LLM图像描述生成的语义含义，提出可微分故障分析框架BLADE定位语义关键比特


<details>
  <summary>Details</summary>
Motivation: 现有故障分析方法主要关注分类器崩溃或准确率下降，忽视了生成系统的语义和语言维度。硬件比特翻转可能微妙改变视觉特征到词语的映射，从而改变AI对世界的叙述方式

Method: 设计可微分故障分析框架BLADE，使用基于梯度的敏感性估计定位语义关键比特，并通过描述级语义-流畅性目标优化比特选择

Result: 证明语义漂移不是随机的，而是可通过模型自身梯度预测哪些比特扰动会最强影响语义同时保持语法和流畅性完整

Conclusion: 即使不可察觉的低层比特变化也能引导生成式视觉语言模型的高层语义，为鲁棒性测试、对抗防御和可解释AI开辟新途径

Abstract: Hard-to-detect hardware bit flips, from either malicious circuitry or bugs, have already been shown to make transformers vulnerable in non-generative tasks. This work, for the first time, investigates how low-level, bitwise perturbations (fault injection) to the weights of a large language model (LLM) used for image captioning can influence the semantic meaning of its generated descriptions while preserving grammatical structure. While prior fault analysis methods have shown that flipping a few bits can crash classifiers or degrade accuracy, these approaches overlook the semantic and linguistic dimensions of generative systems. In image captioning models, a single flipped bit might subtly alter how visual features map to words, shifting the entire narrative an AI tells about the world. We hypothesize that such semantic drifts are not random but differentiably estimable. That is, the model's own gradients can predict which bits, if perturbed, will most strongly influence meaning while leaving syntax and fluency intact. We design a differentiable fault analysis framework, BLADE (Bit-level Fault Analysis via Differentiable Estimation), that uses gradient-based sensitivity estimation to locate semantically critical bits and then refines their selection through a caption-level semantic-fluency objective. Our goal is not merely to corrupt captions, but to understand how meaning itself is encoded, distributed, and alterable at the bit level, revealing that even imperceptible low-level changes can steer the high-level semantics of generative vision-language models. It also opens pathways for robustness testing, adversarial defense, and explainable AI, by exposing how structured bit-level faults can reshape a model's semantic output.

</details>


### [64] [Is GPT-OSS All You Need? Benchmarking Large Language Models for Financial Intelligence and the Surprising Efficiency Paradox](https://arxiv.org/abs/2512.14717)
*Ziqian Bi,Danyang Zhang,Junhao Song,Chiung-Yi Tseng*

Main category: cs.LG

TL;DR: GPT-OSS-20B模型在金融NLP任务中达到与更大模型相当的准确率(65.1% vs 66.5%)，同时计算效率显著更高，挑战了模型规模与性能直接相关的传统假设。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在金融服务中的快速采用，需要严格的评估框架来评估其性能、效率和实际适用性。现有研究通常假设模型规模越大性能越好，但缺乏对效率与性能平衡的系统性评估。

Method: 对GPT-OSS模型家族(120B和20B参数变体)与当代LLMs在10个金融NLP任务上进行全面评估。使用真实金融数据集(Financial PhraseBank, FiQA-SA, FLARE FINERORD)，涵盖情感分析、问答、实体识别等任务。引入新的效率指标来捕捉模型性能与资源利用之间的权衡。

Result: GPT-OSS-20B在准确率上与GPT-OSS-120B相当(65.1% vs 66.5%)，同时计算效率显著更高(198.4 Token Efficiency Score, 159.80 tokens/秒)。GPT-OSS模型在多项任务中超越包括Qwen3-235B在内的更大竞争对手。

Conclusion: GPT-OSS的架构创新和训练策略使较小模型能够以显著降低的计算开销实现竞争性性能，为金融应用中可持续且经济高效的大语言模型部署提供了路径，挑战了模型规模与任务性能直接相关的普遍假设。

Abstract: The rapid adoption of large language models in financial services necessitates rigorous evaluation frameworks to assess their performance, efficiency, and practical applicability. This paper conducts a comprehensive evaluation of the GPT-OSS model family alongside contemporary LLMs across ten diverse financial NLP tasks. Through extensive experimentation on 120B and 20B parameter variants of GPT-OSS, we reveal a counterintuitive finding: the smaller GPT-OSS-20B model achieves comparable accuracy (65.1% vs 66.5%) while demonstrating superior computational efficiency with 198.4 Token Efficiency Score and 159.80 tokens per second processing speed [1]. Our evaluation encompasses sentiment analysis, question answering, and entity recognition tasks using real-world financial datasets including Financial PhraseBank, FiQA-SA, and FLARE FINERORD. We introduce novel efficiency metrics that capture the trade-off between model performance and resource utilization, providing critical insights for deployment decisions in production environments. The benchmark reveals that GPT-OSS models consistently outperform larger competitors including Qwen3-235B, challenging the prevailing assumption that model scale directly correlates with task performance [2]. Our findings demonstrate that architectural innovations and training strategies in GPT-OSS enable smaller models to achieve competitive performance with significantly reduced computational overhead, offering a pathway toward sustainable and cost-effective deployment of LLMs in financial applications.

</details>


### [65] [SEED: Spectral Entropy-Guided Evaluation of SpatialTemporal Dependencies for Multivariate Time Series Forecasting](https://arxiv.org/abs/2512.14718)
*Feng Xiong,Zongxia Xie,Yanru Sun,Haoyu Wang,Jianhong Lin*

Main category: cs.LG

TL;DR: SEED是一个基于谱熵引导的时空依赖建模框架，通过动态评估变量依赖关系、保留负相关性、增强时间位置感知，显著提升了多元时间序列预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于注意力或图的方法存在三个关键问题：1) 强时间自依赖被无关变量干扰；2) softmax归一化忽略并反转负相关；3) 变量难以感知自身时间位置。这些问题限制了多元时间序列预测中对复杂变量间依赖关系的准确建模。

Method: SEED框架包含四个核心组件：1) 依赖评估器：利用谱熵动态评估每个变量的时空依赖，自适应平衡通道独立和通道依赖策略；2) 谱熵融合器：进一步细化依赖权重，分离来自其他变量的时间规律性；3) 符号图构造器：支持带符号边权重，克服softmax限制，保留负相关；4) 上下文空间提取器：利用局部上下文窗口提取空间特征，帮助变量感知时间位置。

Result: 在12个来自不同应用领域的真实世界数据集上进行广泛实验，SEED实现了最先进的性能，验证了其有效性和通用性。

Conclusion: SEED通过谱熵引导的依赖评估、保留负相关性、增强时间位置感知等创新方法，有效解决了现有多元时间序列预测方法的局限性，为复杂时空依赖建模提供了有效的框架。

Abstract: Effective multivariate time series forecasting often benefits from accurately modeling complex inter-variable dependencies. However, existing attention- or graph-based methods face three key issues: (a) strong temporal self-dependencies are often disrupted by irrelevant variables; (b) softmax normalization ignores and reverses negative correlations; (c) variables struggle to perceive their temporal positions. To address these, we propose \textbf{SEED}, a Spectral Entropy-guided Evaluation framework for spatial-temporal Dependency modeling. SEED introduces a Dependency Evaluator, a key innovation that leverages spectral entropy to dynamically provide a preliminary evaluation of the spatial and temporal dependencies of each variable, enabling the model to adaptively balance Channel Independence (CI) and Channel Dependence (CD) strategies. To account for temporal regularities originating from the influence of other variables rather than intrinsic dynamics, we propose Spectral Entropy-based Fuser to further refine the evaluated dependency weights, effectively separating this part. Moreover, to preserve negative correlations, we introduce a Signed Graph Constructor that enables signed edge weights, overcoming the limitations of softmax. Finally, to help variables perceive their temporal positions and thereby construct more comprehensive spatial features, we introduce the Context Spatial Extractor, which leverages local contextual windows to extract spatial features. Extensive experiments on 12 real-world datasets from various application domains demonstrate that SEED achieves state-of-the-art performance, validating its effectiveness and generality.

</details>


### [66] [Hybrid Attribution Priors for Explainable and Robust Model Training](https://arxiv.org/abs/2512.14719)
*Zhuoran Zhang,Feng Zhang,Shangyuan Li,Yang Shi,Yuanxing Zhang,Wei Chen,Tengjiao Wang,Kam-Fai Wong*

Main category: cs.LG

TL;DR: 本文提出Class-Aware Attribution Prior (CAP)框架，通过提取细粒度类别区分性的归因先验，结合现有归因技术形成更全面的监督信号，提升小语言模型在分类任务中的可解释性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有归因方法在分类任务中虽然能可靠地突出类别相关token，但往往关注语义相似类别共享的常见关键词，这些类别本身在标准训练中就难以区分，导致归因提供的区分性线索不足，限制了提升模型区分能力的效果。

Method: 提出Class-Aware Attribution Prior (CAP)框架，引导语言模型捕捉细粒度类别差异，生成更显著、更具区分性的归因先验。进一步提出CAP Hybrid，将CAP的先验与现有归因技术的先验结合，形成更全面平衡的监督信号。通过将模型的自归因与这些增强的先验对齐，促进学习多样化的决策相关特征。

Result: 在完整数据、少样本和对抗场景下的广泛实验表明，该方法能持续提升模型的可解释性和鲁棒性。

Conclusion: CAP框架通过提取细粒度类别区分性的归因先验，结合现有归因技术形成更全面的监督信号，有效解决了现有归因方法在分类任务中区分性不足的问题，显著提升了小语言模型的可解释性和鲁棒性。

Abstract: Small language models (SLMs) are widely used in tasks that require low latency and lightweight deployment, particularly classification. As interpretability and robustness gain increasing importance, explanation-guided learning has emerged as an effective framework by introducing attribution-based supervision during training; however, deriving general and reliable attribution priors remains a significant challenge. Through an analysis of representative attribution methods in classification settings, we find that although these methods can reliably highlight class-relevant tokens, they often focus on common keywords shared by semantically similar classes. Because such classes are already difficult to distinguish under standard training, these attributions provide insufficient discriminative cues, limiting their ability to improve model differentiation. To overcome this limitation, we propose Class-Aware Attribution Prior (CAP), a novel attribution prior extraction framework that guides language models toward capturing fine-grained class distinctions and producing more salient, discriminative attribution priors. Building on this idea, we further introduce CAP Hybrid, which combines priors from CAP with those from existing attribution techniques to form a more comprehensive and balanced supervisory signal. By aligning a model's self-attribution with these enriched priors, our approach encourages the learning of diverse, decision-relevant features. Extensive experiments in full-data, few-shot, and adversarial scenarios demonstrate that our method consistently enhances both interpretability and robustness.

</details>


### [67] [Automatic Extraction of Rules for Generating Synthetic Patient Data From Real-World Population Data Using Glioblastoma as an Example](https://arxiv.org/abs/2512.14721)
*Arno Appenzeller,Nick Terzer,André Hohmeyer,Jan-Philipp Redlich,Sabine Luttmann,Friedrich Feuerhake,Nadine S. Schaadt,Timm Intemann,Sarah Teuber-Hanselmann,Stefan Nikolin,Joachim Weis,Klaus Kraywinkel,Pascal Birnstill*

Main category: cs.LG

TL;DR: 提出自动从癌症报告表格数据生成Synthea规则的方法，以胶质母细胞瘤为例验证，生成的数据能复现疾病进程并保留统计特性


<details>
  <summary>Details</summary>
Motivation: Synthea基于规则生成合成医疗数据，但手动创建规则需要专家知识和真实样本数据，过程复杂。需要自动化方法从现有数据生成规则

Method: 从癌症报告中提取表格数据，自动生成Synthea规则。以胶质母细胞瘤为用例，创建Synthea模块并生成合成数据集

Result: 合成数据能复现已知疾病进程，大部分保留了原始数据的统计特性。合成数据可用于假设形成和原型开发

Conclusion: 合成患者数据在隐私保护研究中具有巨大潜力，但医学解释需要考虑当前方法的特定局限性

Abstract: The generation of synthetic data is a promising technology to make medical data available for secondary use in a privacy-compliant manner. A popular method for creating realistic patient data is the rule-based Synthea data generator. Synthea generates data based on rules describing the lifetime of a synthetic patient. These rules typically express the probability of a condition occurring, such as a disease, depending on factors like age. Since they only contain statistical information, rules usually have no specific data protection requirements. However, creating meaningful rules can be a very complex process that requires expert knowledge and realistic sample data. In this paper, we introduce and evaluate an approach to automatically generate Synthea rules based on statistics from tabular data, which we extracted from cancer reports. As an example use case, we created a Synthea module for glioblastoma from a real-world dataset and used it to generate a synthetic dataset. Compared to the original dataset, the synthetic data reproduced known disease courses and mostly retained the statistical properties. Overall, synthetic patient data holds great potential for privacy-preserving research. The data can be used to formulate hypotheses and to develop prototypes, but medical interpretation should consider the specific limitations as with any currently available approach.

</details>


### [68] [HATSolver: Learning Groebner Bases with Hierarchical Attention Transformers](https://arxiv.org/abs/2512.14722)
*Mohamed Malhou,Ludovic Perret,Kristin Lauter*

Main category: cs.LG

TL;DR: 使用分层注意力变换器（HATs）计算Gröbner基，相比传统平面注意力模型显著节省计算成本，能处理更大规模的多变量多项式方程组。


<details>
  <summary>Details</summary>
Motivation: 改进NeurIPS 2024中Kera等人使用变换器计算Gröbner基的方法，通过引入树状结构归纳偏置来建模数据中的层次关系，以应对更大规模的多变量多项式方程组求解问题。

Method: 采用分层注意力变换器（HATs）架构，该架构包含树状结构归纳偏置，能够建模数据中的层次关系。方法推广到任意深度，并结合课程学习策略，包含详细的计算成本分析。

Result: 相比Kera等人的方法，本方法实现了显著的计算节省，能够解决比原方法大得多的实例规模。

Conclusion: 分层注意力变换器为Gröbner基计算提供了更高效的方法，通过树状结构建模层次关系，结合课程学习，能够处理更大规模的多变量多项式方程组求解问题。

Abstract: At NeurIPS 2024, Kera et al. introduced the use of transformers for computing Groebner bases, a central object in computer algebra with numerous practical applications. In this paper, we improve this approach by applying Hierarchical Attention Transformers (HATs) to solve systems of multivariate polynomial equations via Groebner bases computation. The HAT architecture incorporates a tree-structured inductive bias that enables the modeling of hierarchical relationships present in the data and thus achieves significant computational savings compared to conventional flat attention models. We generalize to arbitrary depths and include a detailed computational cost analysis. Combined with curriculum learning, our method solves instances that are much larger than those in Kera et al. (2024 Learning to compute Groebner bases)

</details>


### [69] [Generative Urban Flow Modeling: From Geometry to Airflow with Graph Diffusion](https://arxiv.org/abs/2512.14725)
*Francisco Giral,Álvaro Manzano,Ignacio Gómez,Petros Koumoutsakos,Soledad Le Clainche*

Main category: cs.LG

TL;DR: 提出基于生成扩散模型的框架，用于在非结构化网格上合成稳态城市风场，仅需几何信息即可生成准确多样的速度场


<details>
  <summary>Details</summary>
Motivation: 城市风流建模对空气质量评估和可持续城市规划很重要，但现有方法存在局限：低阶模型无法捕捉几何效应，而高保真CFD模拟成本过高，特别是在处理多个几何形状或风况时

Method: 结合分层图神经网络和基于分数的扩散建模的生成扩散框架，在非结构化网格上训练，仅需几何信息即可生成稳态风场，无需时间演化或密集测量

Result: 模型能泛化到未见过的几何形状，恢复关键流动结构（如尾流和再循环区），提供不确定性感知预测，消融研究证实对网格变化具有鲁棒性

Conclusion: 这是构建环境基础模型的第一步，可帮助城市规划者快速评估在密集化和气候不确定性下的设计决策

Abstract: Urban wind flow modeling and simulation play an important role in air quality assessment and sustainable city planning. A key challenge for modeling and simulation is handling the complex geometries of the urban landscape. Low order models are limited in capturing the effects of geometry, while high-fidelity Computational Fluid Dynamics (CFD) simulations are prohibitively expensive, especially across multiple geometries or wind conditions. Here, we propose a generative diffusion framework for synthesizing steady-state urban wind fields over unstructured meshes that requires only geometry information. The framework combines a hierarchical graph neural network with score-based diffusion modeling to generate accurate and diverse velocity fields without requiring temporal rollouts or dense measurements. Trained across multiple mesh slices and wind angles, the model generalizes to unseen geometries, recovers key flow structures such as wakes and recirculation zones, and offers uncertainty-aware predictions. Ablation studies confirm robustness to mesh variation and performance under different inference regimes. This work develops is the first step towards foundation models for the built environment that can help urban planners rapidly evaluate design decisions under densification and climate uncertainty.

</details>


### [70] [Quantum Decision Transformers (QDT): Synergistic Entanglement and Interference for Offline Reinforcement Learning](https://arxiv.org/abs/2512.14726)
*Abraham Itzhak Weinberg*

Main category: cs.LG

TL;DR: 量子决策变换器(QDT)通过量子启发的注意力机制和前馈网络，解决了离线强化学习中传统决策变换器在长期信用分配和复杂状态-动作依赖方面的不足，实现了超过2000%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有决策变换器架构在离线强化学习中面临长期信用分配困难和复杂状态-动作依赖关系建模不足的问题，需要新的架构设计来提升性能。

Method: 提出量子决策变换器，包含两个核心组件：1) 量子启发注意力机制，通过纠缠操作捕获非局部特征相关性；2) 量子前馈网络，具有多路径处理和可学习干扰的自适应计算能力。

Result: 在连续控制任务上相比标准决策变换器实现了超过2000%的性能提升，并在不同数据质量下表现出优越的泛化能力。消融研究表明量子启发组件之间存在强协同效应。

Conclusion: 量子启发架构设计需要整体协同设计而非模块化组件采用，为序列决策中的变换器架构提供了新的设计原则，其影响可扩展到更广泛的神经架构设计领域。

Abstract: Offline reinforcement learning enables policy learning from pre-collected datasets without environment interaction, but existing Decision Transformer (DT) architectures struggle with long-horizon credit assignment and complex state-action dependencies. We introduce the Quantum Decision Transformer (QDT), a novel architecture incorporating quantum-inspired computational mechanisms to address these challenges. Our approach integrates two core components: Quantum-Inspired Attention with entanglement operations that capture non-local feature correlations, and Quantum Feedforward Networks with multi-path processing and learnable interference for adaptive computation. Through comprehensive experiments on continuous control tasks, we demonstrate over 2,000\% performance improvement compared to standard DTs, with superior generalization across varying data qualities. Critically, our ablation studies reveal strong synergistic effects between quantum-inspired components: neither alone achieves competitive performance, yet their combination produces dramatic improvements far exceeding individual contributions. This synergy demonstrates that effective quantum-inspired architecture design requires holistic co-design of interdependent mechanisms rather than modular component adoption. Our analysis identifies three key computational advantages: enhanced credit assignment through non-local correlations, implicit ensemble behavior via parallel processing, and adaptive resource allocation through learnable interference. These findings establish quantum-inspired design principles as a promising direction for advancing transformer architectures in sequential decision-making, with implications extending beyond reinforcement learning to neural architecture design more broadly.

</details>


### [71] [A Critical Perspective on Finite Sample Conformal Prediction Theory in Medical Applications](https://arxiv.org/abs/2512.14727)
*Klaus-Rudolf Kladny,Bernhard Schölkopf,Lisa Koch,Christian F. Baumgartner,Michael Muehlebach*

Main category: cs.LG

TL;DR: 论文质疑了保形预测在小校准集下的实际效用，尽管其统计保证在任意校准集大小下都成立，但在医疗领域数据稀缺时，小校准集的实际价值有限。


<details>
  <summary>Details</summary>
Motivation: 机器学习在医疗领域需要可靠的置信度估计，但标准ML模型无法提供。保形预测可以将启发式置信度估计转化为具有统计保证的置信度估计，但其在小校准集下的实际效用受到质疑。

Method: 通过理论分析和在医学图像分类任务上的实证演示，检验保形预测在小校准集下的实际效用。

Result: 虽然保形预测的统计保证在校准集任意大小时都成立，但这些保证的实际效用高度依赖于校准集的大小。小校准集在医疗领域数据稀缺时无法提供有实际意义的置信度估计。

Conclusion: 保形预测在小校准集下的统计保证虽然理论成立，但在医疗数据稀缺的实际应用中，需要谨慎评估其实际效用，不能仅依赖理论保证。

Abstract: Machine learning (ML) is transforming healthcare, but safe clinical decisions demand reliable uncertainty estimates that standard ML models fail to provide. Conformal prediction (CP) is a popular tool that allows users to turn heuristic uncertainty estimates into uncertainty estimates with statistical guarantees. CP works by converting predictions of a ML model, together with a calibration sample, into prediction sets that are guaranteed to contain the true label with any desired probability. An often cited advantage is that CP theory holds for calibration samples of arbitrary size, suggesting that uncertainty estimates with practically meaningful statistical guarantees can be achieved even if only small calibration sets are available. We question this promise by showing that, although the statistical guarantees hold for calibration sets of arbitrary size, the practical utility of these guarantees does highly depend on the size of the calibration set. This observation is relevant in medical domains because data is often scarce and obtaining large calibration sets is therefore infeasible. We corroborate our critique in an empirical demonstration on a medical image classification task.

</details>


### [72] [A data-driven approach to inferring travel trajectory during peak hours in urban rail transit systems](https://arxiv.org/abs/2512.14728)
*Jie He,Yong Qin,Jianyuan Guo,Xuan Sun,Xuanchuan Zheng*

Main category: cs.LG

TL;DR: 提出基于AFC和AVL数据的城市轨道交通个体出行轨迹推断方法，采用KLEM参数估计，无需外部调查数据，在高峰时段轨迹推断准确率超过90%


<details>
  <summary>Details</summary>
Motivation: 城市轨道交通精细化轨迹推断对运营组织有重要意义，现有方法依赖外部调查数据或合成数据验证，缺乏鲁棒性和适用性

Method: 基于时空约束建立列车备选集，提出基于KL散度结合EM算法的数据驱动参数估计方法(KLEM)，实现自适应轨迹推断和出行轨迹构建

Result: 该方法能实现高精度乘客轨迹推断，在高峰时段城市轨道交通出行轨迹推断准确率超过90%

Conclusion: 提出的全数据驱动方法消除了对外部调查数据的依赖，提高了模型的鲁棒性和适用性，实现了高精度的个体出行轨迹推断

Abstract: Refined trajectory inference of urban rail transit is of great significance to the operation organization. In this paper, we develop a fully data-driven approach to inferring individual travel trajectories in urban rail transit systems. It utilizes data from the Automatic Fare Collection (AFC) and Automatic Vehicle Location (AVL) systems to infer key trajectory elements, such as selected train, access/egress time, and transfer time. The approach includes establishing train alternative sets based on spatio-temporal constraints, data-driven adaptive trajectory inference, and trave l trajectory construction. To realize data-driven adaptive trajectory inference, a data-driven parameter estimation method based on KL divergence combined with EM algorithm (KLEM) was proposed. This method eliminates the reliance on external or survey data for parameter fitting, enhancing the robustness and applicability of the model. Furthermore, to overcome the limitations of using synthetic data to validate the result, this paper employs real individual travel trajectory data for verification. The results show that the approach developed in this paper can achieve high-precision passenger trajectory inference, with an accuracy rate of over 90% in urban rail transit travel trajectory inference during peak hours.

</details>


### [73] [Semantic Geometry for policy-constrained interpretation](https://arxiv.org/abs/2512.14731)
*Nikit Phadke*

Main category: cs.LG

TL;DR: 提出几何框架防止高风险领域中的幻觉承诺，将语义表示为单位球面方向，证据建模为见证向量集，可接受解释对应球面凸区域，通过约束优化实现解释，矛盾时拒绝是拓扑必然结果。


<details>
  <summary>Details</summary>
Motivation: 在高风险领域（如金融监管）中，防止AI系统产生幻觉承诺（hallucinated commitments）至关重要。现有方法难以保证零幻觉，需要理论严谨且可证明安全的语义解释框架。

Method: 1. 语义表示为单位球面上的方向向量；2. 证据建模为见证向量集合；3. 可接受解释对应球面凸区域；4. 引入策略约束作为同一流形上的显式先验；5. 解释转化为可接受区域上的约束优化问题；6. 矛盾或策略排除时，拒绝是拓扑必然结果。

Result: 1. 理论证明：复杂度界限是信息论最优的；2. 实证验证：在大规模监管金融数据上实现零幻觉批准，这是首次在多个政策制度下实现如此规模的结果。

Conclusion: 该几何框架为策略约束的语义解释提供了理论严谨的解决方案，能够可证明地防止高风险领域的幻觉承诺，将拒绝作为矛盾时的必要安全机制，并在实际应用中展现出卓越性能。

Abstract: We present a geometric framework for policy-constrained semantic interpretation that provably prevents hallucinated commitments in high-stakes domains. Semantic meaning is represented as direction on a unit sphere, evidence is modeled as sets of witness vectors, and admissible interpretations correspond to spherical convex regions. Policy constraints are introduced as explicit priors defined over the same manifold, separated from evidence geometry. Interpretation reduces to constrained optimization over admissible regions, with refusal emerging as a topologically necessary outcome under contradiction or policy exclusion. We connect this framework to information theory, Bayesian inference, and sheaf-theoretic semantics, proving that our complexity bounds are information-theoretically optimal. Empirical validation on large scale regulated financial data demonstrates zero hallucinated approvals across multiple policy regimes-the first such result at scale.

</details>


### [74] [INFORM-CT: INtegrating LLMs and VLMs FOR Incidental Findings Management in Abdominal CT](https://arxiv.org/abs/2512.14732)
*Idan Tankel,Nir Mazor,Rafi Brada,Christina LeBedis,Guy ben-Yosef*

Main category: cs.LG

TL;DR: 提出一个基于LLM和VLM的规划-执行代理框架，用于自动化腹部CT扫描中偶然发现的检测、分类和报告，相比纯VLM方法在准确性和效率上表现更优。


<details>
  <summary>Details</summary>
Motivation: CT扫描中的偶然发现虽然通常良性，但具有重要临床意义，需要遵循指南报告。传统放射科医生手动检查耗时且存在变异性，需要更高效精确的自动化解决方案。

Method: 采用规划-执行代理框架：基于LLM的规划器根据腹部器官医学指南生成Python脚本，执行器运行这些脚本，通过VLM、分割模型和图像处理子程序进行必要的检查和检测。

Result: 在腹部CT基准测试中，该框架在三个器官上以完全自动化的端到端方式运行，在准确性和效率方面优于现有的纯VLM方法。

Conclusion: 提出的LLM+VLM规划-执行框架能够有效自动化管理CT扫描中的偶然发现，提高检测和报告的效率与精度，为临床实践提供实用解决方案。

Abstract: Incidental findings in CT scans, though often benign, can have significant clinical implications and should be reported following established guidelines. Traditional manual inspection by radiologists is time-consuming and variable. This paper proposes a novel framework that leverages large language models (LLMs) and foundational vision-language models (VLMs) in a plan-and-execute agentic approach to improve the efficiency and precision of incidental findings detection, classification, and reporting for abdominal CT scans. Given medical guidelines for abdominal organs, the process of managing incidental findings is automated through a planner-executor framework. The planner, based on LLM, generates Python scripts using predefined base functions, while the executor runs these scripts to perform the necessary checks and detections, via VLMs, segmentation models, and image processing subroutines.
  We demonstrate the effectiveness of our approach through experiments on a CT abdominal benchmark for three organs, in a fully automatic end-to-end manner. Our results show that the proposed framework outperforms existing pure VLM-based approaches in terms of accuracy and efficiency.

</details>


### [75] [Inference Time Feature Injection: A Lightweight Approach for Real-Time Recommendation Freshness](https://arxiv.org/abs/2512.14734)
*Qiang Chen,Venkatesh Ganapati Hegde,Hongfei Li*

Main category: cs.LG

TL;DR: 提出一种轻量级、模型无关的日内个性化方法，通过推理时选择性注入近期观看历史来更新用户特征，无需模型重训练，显著提升长视频流媒体推荐效果。


<details>
  <summary>Details</summary>
Motivation: 现有长视频流媒体推荐系统依赖批量训练模型和每日更新的特征，无法捕捉用户最新行为，导致推荐内容陈旧。需要一种能在不重训练模型的情况下实现日内个性化更新的方法。

Method: 开发了一种轻量级、模型无关的日内个性化方法，在推理时选择性覆盖陈旧的用户特征，使用近期观看历史来即时适应用户偏好变化，无需模型重训练。

Result: 通过将个性化反馈循环从每日缩短到日内，观察到关键用户参与度指标有统计学意义的0.47%提升，这是近期实验周期中观察到的最大参与度增益之一。

Conclusion: 这是首个证明日内个性化能在长视频流媒体服务中产生显著影响的公开证据，为需要模型重训练的完整实时架构提供了一个有吸引力的替代方案。

Abstract: Many recommender systems in long-form video streaming reply on batch-trained models and batch-updated features, where user features are updated daily and served statically throughout the day. While efficient, this approach fails to incorporate a user's most recent actions, often resulting in stale recommendations. In this work, we present a lightweight, model-agnostic approach for intra-day personalization that selectively injects recent watch history at inference time without requiring model retraining. Our approach selectively overrides stale user features at inference time using the recent watch history, allowing the system to adapt instantly to evolving preferences. By reducing the personalization feedback loop from daily to intra-day, we observed a statistically significant 0.47% increase in key user engagement metrics which ranked among the most substantial engagement gains observed in recent experimentation cycles. To our knowledge, this is the first published evidence that intra-day personalization can drive meaningful impact in long-form video streaming service, providing a compelling alternative to full real-time architectures where model retraining is required.

</details>


### [76] [NoveltyRank: Estimating Conceptual Novelty of AI Papers](https://arxiv.org/abs/2512.14738)
*Zhengxu Yan,Han Li,Yuming Feng*

Main category: cs.LG

TL;DR: 开发了一个评估AI论文概念新颖性的模型，通过标题、摘要和语义相似度来量化研究原创性，帮助识别真正创新的工作。


<details>
  <summary>Details</summary>
Motivation: 随着学术出版门槛降低，AI领域论文数量激增，真正新颖和有影响力的工作难以脱颖而出。手动评估新颖性不稳定且耗时，需要数据驱动的可扩展解决方案。

Method: 采用两种任务框架：1) 二元分类，从先前新颖工作中学习模式预测绝对新颖性；2) 成对新颖性比较，学习区分论文的相对新颖性。使用Qwen3-4B-Instruct-2507和SciBERT进行微调，并与GPT-5.1进行基准测试。

Result: 实现了评估AI论文概念新颖性的模型，公开了代码实现，分析了任务框架和建模选择对性能的影响。

Conclusion: 开发了一个数据驱动的可扩展系统，能够量化评估研究原创性，帮助研究人员识别真正创新的工作，为会议评审提供一致的新颖性信号。

Abstract: With the growing ease of academic publishing, the volume of research papers, especially in AI-related fields, has surged dramatically. This flood of publications makes it difficult for truly novel and impactful work to stand out, and manual novelty assessment is often unstable and time-consuming. Our project aims to develop a model that estimates and ranks the conceptual novelty of AI papers, enabling a data-driven and scalable assessment of research originality. Such a system can help researchers efficiently identify submissions that introduce genuinely innovative ideas rather than minor variants, and provide conference reviewers with a quantitative and consistent signal of novelty. Our approach evaluates novelty primarily through a paper's title, abstract, and semantic similarity to prior literature. Given the motivation of novelty estimation, we explore two task formulations with different modeling objectives, each offering a different perspective: (1) binary classification, which predicts the paper's absolute novelty from learned patterns of prior novel works, and (2) pairwise novelty comparison, which learns to distinguish papers by relative novelty over others. We fine-tune Qwen3-4B-Instruct-2507 and SciBERT on both tasks, benchmarking against GPT-5.1 to analyze how task formulation and modeling choices affect performance. The implementation is publicly available at https://github.com/ZhengxuYan/NoveltyRank.

</details>


### [77] [Guided Discrete Diffusion for Constraint Satisfaction Problems](https://arxiv.org/abs/2512.14765)
*Justin Jung*

Main category: cs.LG

TL;DR: 提出离散扩散引导方法解决约束满足问题，以无监督方式解决数独谜题


<details>
  <summary>Details</summary>
Motivation: 传统方法解决约束满足问题通常需要监督或特定领域知识，本文旨在开发无需监督的通用方法

Method: 使用离散扩散模型，通过引导机制将生成过程导向满足约束的解空间

Result: 成功应用于数独谜题，证明该方法能有效解决约束满足问题

Conclusion: 离散扩散引导为约束满足问题提供了有效的无监督解决方案框架

Abstract: We propose discrete diffusion guidance for constraint satisfaction problems (CSPs) and demonstrate its ability to solve Sudoku puzzles without supervision.

</details>


### [78] [Evaluating Weather Forecasts from a Decision Maker's Perspective](https://arxiv.org/abs/2512.14779)
*Kornelius Raeth,Nicole Ludwig*

Main category: cs.LG

TL;DR: 论文提出决策校准框架，从决策者角度评估天气预报价值，发现传统预测评估与下游决策表现不一致


<details>
  <summary>Details</summary>
Motivation: 传统天气预报评估主要从预报员角度进行统计比较，但实际应用中预报用于决策，需要从决策者角度评估预报价值

Method: 提出决策校准框架，在决策层面而非预测层面评估预报性能，比较机器学习与传统数值天气预报模型在不同天气相关决策任务中的表现

Result: 模型在预测层面的性能不能可靠地转化为下游决策表现：一些性能差异只在决策层面显现，不同决策任务中模型排名会发生变化

Conclusion: 典型的预测评估不足以为特定决策任务选择最优预报模型，需要采用决策层面的评估方法

Abstract: Standard weather forecast evaluations focus on the forecaster's perspective and on a statistical assessment comparing forecasts and observations. In practice, however, forecasts are used to make decisions, so it seems natural to take the decision-maker's perspective and quantify the value of a forecast by its ability to improve decision-making. Decision calibration provides a novel framework for evaluating forecast performance at the decision level rather than the forecast level. We evaluate decision calibration to compare Machine Learning and classical numerical weather prediction models on various weather-dependent decision tasks. We find that model performance at the forecast level does not reliably translate to performance in downstream decision-making: some performance differences only become apparent at the decision level, and model rankings can change among different decision tasks. Our results confirm that typical forecast evaluations are insufficient for selecting the optimal forecast model for a specific decision task.

</details>


### [79] [Unreliable Uncertainty Estimates with Monte Carlo Dropout](https://arxiv.org/abs/2512.14851)
*Aslak Djupskås,Alexander Johannes Stasik,Signe Riemer-Sørensen*

Main category: cs.LG

TL;DR: MCD作为贝叶斯推理的高效近似，在捕捉真实不确定性方面表现不佳，尤其在插值和外推区域，不如传统贝叶斯方法可靠。


<details>
  <summary>Details</summary>
Motivation: 研究MCD在深度学习中作为贝叶斯推理近似方法的可靠性，特别是在安全关键领域中不确定性估计的重要性。

Method: 通过实证研究比较MCD与高斯过程和贝叶斯神经网络在不确定性估计方面的表现。

Result: MCD难以准确反映真实不确定性，特别是在插值和外推区域无法像贝叶斯模型那样捕捉到不确定性增加。

Conclusion: MCD的不确定性估计不如传统贝叶斯方法可靠，特别是在捕捉认知不确定性和偶然不确定性方面存在局限。

Abstract: Reliable uncertainty estimation is crucial for machine learning models, especially in safety-critical domains. While exact Bayesian inference offers a principled approach, it is often computationally infeasible for deep neural networks. Monte Carlo dropout (MCD) was proposed as an efficient approximation to Bayesian inference in deep learning by applying neuron dropout at inference time \citep{gal2016dropout}. Hence, the method generates multiple sub-models yielding a distribution of predictions to estimate uncertainty. We empirically investigate its ability to capture true uncertainty and compare to Gaussian Processes (GP) and Bayesian Neural Networks (BNN). We find that MCD struggles to accurately reflect the underlying true uncertainty, particularly failing to capture increased uncertainty in extrapolation and interpolation regions as observed in Bayesian models. The findings suggest that uncertainty estimates from MCD, as implemented and evaluated in these experiments, is not as reliable as those from traditional Bayesian approaches for capturing epistemic and aleatoric uncertainty.

</details>


### [80] [How Does Fourier Analysis Network Work? A Mechanism Analysis and a New Dual-Activation Layer Proposal](https://arxiv.org/abs/2512.14873)
*Sam Jeong,Hae Yong Kim*

Main category: cs.LG

TL;DR: FAN的改进主要来自sine激活函数在x=0附近的局部行为，而非其周期性，这缓解了梯度消失问题。研究提出了更高效的DAL层，在多个任务上实现更快收敛和更高精度。


<details>
  <summary>Details</summary>
Motivation: 虽然FAN（傅里叶分析网络）被证明能小幅提升神经网络性能，但其改进机制尚不明确。本文旨在揭示FAN真正有效的原理，并开发更高效的收敛加速器。

Method: 通过分析发现只有sine激活函数对性能有正面贡献，而cosine激活函数反而有害。研究揭示了sine函数在x=0附近的局部行为（非零导数）缓解了梯度消失问题。基于此提出了Dual-Activation Layer (DAL)。

Result: 在三个任务上评估DAL：噪声正弦信号与纯噪声分类、MNIST数字分类、ECG生物特征识别。在所有情况下，DAL模型比传统激活函数模型收敛更快，并达到相等或更高的验证精度。

Conclusion: FAN的改进机制应从频谱解释转向训练动态分析。sine函数通过缓解梯度消失问题，特别是解决dying-ReLU问题，改善了优化过程。DAL作为更高效的收敛加速器，在实际任务中表现优异。

Abstract: Fourier Analysis Network (FAN) was recently proposed as a simple way to improve neural network performance by replacing part of ReLU activations with sine and cosine functions. Although several studies have reported small but consistent gains across tasks, the underlying mechanism behind these improvements has remained unclear. In this work, we show that only the sine activation contributes positively to performance, whereas the cosine activation tends to be detrimental. Our analysis reveals that the improvement is not a consequence of the sine function's periodic nature; instead, it stems from the function's local behavior near x = 0, where its non-zero derivative mitigates the vanishing-gradient problem. We further show that FAN primarily alleviates the dying-ReLU problem, in which a neuron consistently receives negative inputs, produces zero gradients, and stops learning. Although modern ReLU-like activations, such as Leaky ReLU, GELU, and Swish, reduce ReLU's zero-gradient region, they still contain input domains where gradients remain significantly diminished, contributing to slower optimization and hindering rapid convergence. FAN addresses this limitation by introducing a more stable gradient pathway. This analysis shifts the understanding of FAN's benefits from a spectral interpretation to a concrete analysis of training dynamics, leading to the development of the Dual-Activation Layer (DAL), a more efficient convergence accelerator. We evaluate DAL on three tasks: classification of noisy sinusoidal signals versus pure noise, MNIST digit classification, and ECG-based biometric recognition. In all cases, DAL models converge faster and achieve equal or higher validation accuracy compared to models with conventional activations.

</details>


### [81] [Entropy-Reservoir Bregman Projection: An Information-Geometric Unification of Model Collapse](https://arxiv.org/abs/2512.14879)
*Jingwei Chen*

Main category: cs.LG

TL;DR: 论文提出了ERBP框架，用信息几何方法统一解释自指学习中的模型崩溃现象，并提出通过熵储层注入可控熵流来稳定系统。


<details>
  <summary>Details</summary>
Motivation: 自指学习（模型在自身生成的数据上训练）虽然具有无限扩展潜力，但普遍存在模型崩溃问题。尽管实践中采用各种临时修复方法，但缺乏统一的理论框架来解释失败模式和修复方法的成功原理。

Method: 提出熵储层Bregman投影（ERBP）框架，将自指学习建模为分布空间中的随机Bregman投影序列。通过引入熵储层（高熵分布）混合到每次投影中，注入可控熵流来稳定动力学。

Result: 理论推导出：(1) 模型崩溃的必要条件；(2) 保证非平凡熵底限的充分条件；(3) 仅依赖于样本量和Bregman生成器强凸性/Lipschitz常数的闭式收敛率。实验验证了理论预测。

Conclusion: ERBP将各种经验性稳定启发式方法统一为单一量化设计规则：监控和预算熵流。该框架为自指学习提供了理论基础和设计指导。

Abstract: Self-referential learning -- training a model on data it generated itself -- promises boundless scalability but chronically suffers from model collapse: language models degenerate into repetitive text, GANs drop modes, and reinforcement-learning policies over-exploit. Although practitioners employ ad~hoc fixes such as real-data mixing, entropy bonuses, knowledge distillation, or retrieval-augmented generation, a single principle that explains both the failure mode and the success of these fixes has remained elusive. We present Entropy-Reservoir Bregman Projection (ERBP), an information-geometric framework that unifies these phenomena. We model the closed loop as a stochastic Bregman projection sequence in distribution space. Without external coupling, finite-sample noise forces the system to project onto an ever-shrinking empirical support, causing exponential entropy decay and eventual collapse. Introducing an Entropy Reservoir -- a high-entropy distribution mixed into each projection -- injects a controllable entropy flux that provably stabilises the dynamics. Our theory yields (i) a necessary condition for collapse, (ii) a sufficient condition that guarantees a non-trivial entropy floor, and (iii) closed-form rates that depend only on sample size and the strong-convexity/Lipschitz constants of the Bregman generator. Experiments on large-language-model self-training, Soft Actor-Critic in reinforcement learning, and GAN optimisation validate our predictions and show that disparate stabilisation heuristics correspond to specific reservoir choices and coupling coefficients. ERBP thus transforms a collection of folk remedies into a single, quantitative design rule: monitor and budget your entropy flux.

</details>


### [82] [Task Matrices: Linear Maps for Cross-Model Finetuning Transfer](https://arxiv.org/abs/2512.14880)
*Darrin O' Brien,Dhikshith Gajulapalli,Eric Xia*

Main category: cs.LG

TL;DR: 论文提出"任务矩阵"概念，证明预训练和微调模型之间存在跨层线性编码，通过线性变换可逼近微调性能


<details>
  <summary>Details</summary>
Motivation: 现有研究表明大型视觉和语言模型在上下文提示偏置下学习隐式线性编码，但更一般的适应机制中是否存在类似线性表示尚未得到证实

Method: 提出任务矩阵概念——从基础到微调嵌入状态的线性变换，在视觉和文本模型及十个数据集上验证，通过数据近似方法实现高效且可泛化的编码

Result: 基础模型增强任务矩阵后性能超越线性探针，有时接近微调水平，验证了预训练与微调架构间存在跨层线性编码

Conclusion: 任务矩阵方法高效且可泛化到多个领域，为模型适应提供了新的线性表示框架，代码已公开

Abstract: Results in interpretability suggest that large vision and language models learn implicit linear encodings when models are biased by in-context prompting. However, the existence of similar linear representations in more general adaptation regimes has not yet been demonstrated. In this work, we develop the concept of a task matrix, a linear transformation from a base to finetuned embedding state. We demonstrate that for vision and text models and ten different datasets, a base model augmented with a task matrix achieves results surpassing linear probes, sometimes approaching finetuned levels. Our results validate the existence of cross-layer linear encodings between pretrained and finetuned architectures. Moreover, we show that a data-based approximation for such encodings is both efficient and generalizable to multiple domains. We make our implementation publicly available.

</details>


### [83] [OLR-WA: Online Weighted Average Linear Regression in Multivariate Data Streams](https://arxiv.org/abs/2512.14892)
*Mohammad Abu-Shaira,Alejandro Rodriguez,Greg Speegle,Victor Sheng,Ishfaq Ahmad*

Main category: cs.LG

TL;DR: OLR-WA是一种新颖的多变量在线线性回归模型，通过加权平均方法处理数据流，在性能上可与批量回归相媲美，并在收敛速度和处理数据漂移方面优于现有在线模型。


<details>
  <summary>Details</summary>
Motivation: 在线学习需要增量更新模型以避免大规模数据存储和昂贵的模型重新计算，但现有在线回归模型在处理数据漂移（特别是时间漂移和置信度漂移）方面存在局限，需要一种更通用且稳健的解决方案。

Method: 提出OLR-WA（在线回归加权平均）模型，采用加权平均方法进行多变量在线线性回归。该模型采用保守更新策略，优先考虑置信度较高的旧数据点，能够有效处理时间漂移和置信度漂移场景。

Result: OLR-WA在性能上可与批量回归相媲美，收敛速度远超其他在线模型，即使仅用1%-10%的数据初始化也能从第一次迭代就获得高r²值。它是唯一能有效处理置信度漂移挑战场景的模型。

Conclusion: OLR-WA通过其加权平均方法和保守更新策略，在多场景下展现出卓越的通用性和实用性，为在线线性回归任务提供了有价值的解决方案。

Abstract: Online learning updates models incrementally with new data, avoiding large storage requirements and costly model recalculations. In this paper, we introduce "OLR-WA; OnLine Regression with Weighted Average", a novel and versatile multivariate online linear regression model. We also investigate scenarios involving drift, where the underlying patterns in the data evolve over time, conduct convergence analysis, and compare our approach with existing online regression models. The results of OLR-WA demonstrate its ability to achieve performance comparable to the batch regression, while also showcasing comparable or superior performance when compared with other state-of-the-art online models, thus establishing its effectiveness. Moreover, OLR-WA exhibits exceptional performance in terms of rapid convergence, surpassing other online models with consistently achieving high r2 values as a performance measure from the first iteration to the last iteration, even when initialized with minimal amount of data points, as little as 1% to 10% of the total data points. In addition to its ability to handle time-based (temporal drift) scenarios, remarkably, OLR-WA stands out as the only model capable of effectively managing confidence-based challenging scenarios. It achieves this by adopting a conservative approach in its updates, giving priority to older data points with higher confidence levels. In summary, OLR-WA's performance further solidifies its versatility and utility across different contexts, making it a valuable solution for online linear regression tasks.

</details>


### [84] [Imitation Learning for Multi-turn LM Agents via On-policy Expert Corrections](https://arxiv.org/abs/2512.14895)
*Niklas Lauffer,Xiang Deng,Srivatsa Kundurthy,Brad Kenstler,Jeff Da*

Main category: cs.LG

TL;DR: 提出OEC方法解决多轮LLM智能体训练中的协变量偏移问题，通过学生模型启动、专家模型中途接管的混合轨迹生成，在软件工程任务上相比传统模仿学习提升13-14%


<details>
  <summary>Details</summary>
Motivation: 传统基于专家轨迹的模仿学习方法在多轮LLM智能体训练中存在协变量偏移问题：学生策略行为偏离专家时，会遇到训练数据中未见过的新状态，导致微调效果下降

Method: 提出on-policy expert corrections (OEC)数据生成方法：学生模型启动轨迹，中途切换到专家模型完成剩余部分，生成部分在策略的数据。在软件工程任务中，结合拒绝采样和监督微调技术进行训练

Result: 在7B和32B模型上，OEC方法相比传统模仿学习在SWE-bench verified上分别取得14%和13%的相对提升，证明了结合专家演示和在策略数据对多轮LLM智能体训练的重要性

Conclusion: 多轮LLM智能体训练需要结合专家演示和在策略数据，OEC方法通过混合轨迹生成有效解决协变量偏移问题，为多轮交互任务提供了更有效的训练范式

Abstract: A popular paradigm for training LM agents relies on imitation learning, fine-tuning on expert trajectories. However, we show that the off-policy nature of imitation learning for multi-turn LM agents suffers from the fundamental limitation known as covariate shift: as the student policy's behavior diverges from the expert's, it encounters states not present in the training data, reducing the effectiveness of fine-tuning. Taking inspiration from the classic DAgger algorithm, we propose a novel data generation methodology for addressing covariate shift for multi-turn LLM training. We introduce on-policy expert corrections (OECs), partially on-policy data generated by starting rollouts with a student model and then switching to an expert model part way through the trajectory. We explore the effectiveness of our data generation technique in the domain of software engineering (SWE) tasks, a multi-turn setting where LLM agents must interact with a development environment to fix software bugs. Our experiments compare OEC data against various other on-policy and imitation learning approaches on SWE agent problems and train models using a common rejection sampling (i.e., using environment reward) combined with supervised fine-tuning technique. Experiments find that OEC trajectories show a relative 14% and 13% improvement over traditional imitation learning in the 7b and 32b setting, respectively, on SWE-bench verified. Our results demonstrate the need for combining expert demonstrations with on-policy data for effective multi-turn LM agent training.

</details>


### [85] [ATLAS: Adaptive Topology-based Learning at Scale for Homophilic and Heterophilic Graphs](https://arxiv.org/abs/2512.14908)
*Turja Kundu,Sanjukta Bhowmick*

Main category: cs.LG

TL;DR: ATLAS是一种新颖的图学习算法，通过提取多级社区拓扑信息并与特征向量拼接，使用MLP替代GNN聚合，解决异配图精度下降和大图可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 解决图神经网络的两个关键挑战：1) 异配图（heterophilic graphs）中GNN精度下降问题；2) 迭代特征聚合限制GNN在大图上的可扩展性。

Method: 提取多级细化的图社区拓扑信息，将社区分配结果与特征向量拼接，然后对得到的表示应用多层感知机（MLP），避免使用聚合操作。

Result: 在多种图上，ATLAS达到与基线方法相当的精度，在具有负结构偏置的异配图上比GCN提高20个百分点，在同配图上比MLP提高11个百分点。多分辨率社区特征能系统性地调节性能。

Conclusion: ATLAS通过拓扑信息增强和MLP替代GNN聚合，有效解决了异配图精度和大图可扩展性问题，为可解释图学习提供了原则性路径。

Abstract: We present ATLAS (Adaptive Topology-based Learning at Scale for Homophilic and Heterophilic Graphs), a novel graph learning algorithm that addresses two important challenges in graph neural networks (GNNs). First, the accuracy of GNNs degrades when the graph is heterophilic. Second, iterative feature aggregation limits the scalability of GNNs to large graphs. We address these challenges by extracting topological information about graph communities at multiple levels of refinement, concatenating community assignments to the feature vector, and applying multilayer perceptrons (MLPs) to the resulting representation. This provides topological context about nodes and their neighborhoods without invoking aggregation. Because MLPs are typically more scalable than GNNs, our approach applies to large graphs without the need for sampling. Across a wide set of graphs, ATLAS achieves comparable accuracy to baseline methods, with gains as high as 20 percentage points over GCN for heterophilic graphs with negative structural bias and 11 percentage points over MLP for homophilic graphs. Furthermore, we show how multi-resolution community features systematically modulate performance in both homophilic and heterophilic settings, opening a principled path toward explainable graph learning.

</details>


### [86] [Low-rank MMSE filters, Kronecker-product representation, and regularization: a new perspective](https://arxiv.org/abs/2512.14932)
*Daniel Gomes de Pinho Zanco,Leszek Szczecinski,Jacob Benesty,Eduardo Vinicius Kuhn*

Main category: cs.LG

TL;DR: 提出一种基于Kronecker积表示的低秩MMSE滤波器正则化参数高效选择方法，该方法与秩选择问题相关，在低秩设置中至关重要


<details>
  <summary>Details</summary>
Motivation: 低秩MMSE滤波器中正则化参数的选择对性能影响显著，但传统方法效率不高且缺乏理论指导，特别是在低秩设置中需要更有效的参数选择策略

Method: 基于Kronecker积表示的正则化参数选择方法，将正则化参数选择与秩选择问题联系起来，通过理论分析建立两者关系，提出高效算法

Result: 仿真验证显示，相比常用方法，所提方法能显著提升性能，特别是在低秩设置中表现出明显优势

Conclusion: 正则化参数选择与秩选择密切相关，在低秩MMSE滤波器中至关重要，所提基于Kronecker积表示的方法能高效选择参数并获得显著性能增益

Abstract: In this work, we propose a method to efficiently find the regularization parameter for low-rank MMSE filters based on a Kronecker-product representation. We show that the regularization parameter is surprisingly linked to the problem of rank selection and, thus, properly choosing it, is crucial for low-rank settings. The proposed method is validated through simulations, showing significant gains over commonly used methods.

</details>


### [87] [Deep Learning and Elicitability for McKean-Vlasov FBSDEs With Common Noise](https://arxiv.org/abs/2512.14967)
*Felipe J. P. Antunes,Yuri F. Saporito,Sebastian Jaimungal*

Main category: cs.LG

TL;DR: 提出结合Picard迭代、可引出性和深度学习的数值方法，用于求解带共同噪声的McKean-Vlasov前向-后向随机微分方程，避免昂贵的嵌套蒙特卡洛模拟。


<details>
  <summary>Details</summary>
Motivation: 传统方法求解带共同噪声的MV-FBSDEs需要计算条件期望，通常依赖计算成本高昂的嵌套蒙特卡洛模拟。本文旨在开发更高效的数值方法，避免这种计算负担。

Method: 结合Picard迭代、可引出性理论和深度学习。利用可引出性推导路径损失函数，用循环神经网络参数化平均场交互项，前馈网络近似解耦场表示后向过程。训练神经网络最小化可引出评分。

Result: 在系统性风险银行借贷模型上验证算法，准确恢复解析解；扩展到分位数介导的交互，展示框架灵活性；应用于非平稳Aiyagari-Bewley-Huggett经济增长模型，展示复杂平均场博弈的适用性。

Conclusion: 提出的可引出性框架为求解带共同噪声的MV-FBSDEs提供了高效数值方法，避免嵌套蒙特卡洛，适用于复杂平均场博弈问题，具有扩展到条件均值或矩之外交互的灵活性。

Abstract: We present a novel numerical method for solving McKean-Vlasov forward-backward stochastic differential equations (MV-FBSDEs) with common noise, combining Picard iterations, elicitability and deep learning. The key innovation involves elicitability to derive a path-wise loss function, enabling efficient training of neural networks to approximate both the backward process and the conditional expectations arising from common noise - without requiring computationally expensive nested Monte Carlo simulations. The mean-field interaction term is parameterized via a recurrent neural network trained to minimize an elicitable score, while the backward process is approximated through a feedforward network representing the decoupling field. We validate the algorithm on a systemic risk inter-bank borrowing and lending model, where analytical solutions exist, demonstrating accurate recovery of the true solution. We further extend the model to quantile-mediated interactions, showcasing the flexibility of the elicitability framework beyond conditional means or moments. Finally, we apply the method to a non-stationary Aiyagari--Bewley--Huggett economic growth model with endogenous interest rates, illustrating its applicability to complex mean-field games without closed-form solutions.

</details>


### [88] [Softly Constrained Denoisers for Diffusion Models](https://arxiv.org/abs/2512.14980)
*Victor M. Yeom Song,Severi Rissanen,Arno Solin,Samuel Kaski,Mingfei Sun*

Main category: cs.LG

TL;DR: 提出一种软约束去噪器方法，将约束知识融入去噪器本身，而非修改损失函数或采样过程，在保持数据分布真实性的同时提高约束遵从性


<details>
  <summary>Details</summary>
Motivation: 扩散模型在科学应用中难以生成满足约束的样本，现有方法通过损失正则化或采样引导会偏离真实数据分布，特别是在约束定义错误时问题更严重

Method: 将引导式调整集成到去噪器本身，赋予去噪器对约束合规样本的软归纳偏置，而非改变损失函数或采样循环

Result: 软约束去噪器利用约束知识提高合规性，同时在约束与观测数据不匹配时保持足够灵活性偏离约束

Conclusion: 通过将约束知识融入去噪器本身，可以在不偏离真实数据分布的情况下提高约束遵从性，特别适用于约束定义可能不准确的科学应用场景

Abstract: Diffusion models struggle to produce samples that respect constraints, a common requirement in scientific applications. Recent approaches have introduced regularization terms in the loss or guidance methods during sampling to enforce such constraints, but they bias the generative model away from the true data distribution. This is a problem, especially when the constraint is misspecified, a common issue when formulating constraints on scientific data. In this paper, instead of changing the loss or the sampling loop, we integrate a guidance-inspired adjustment into the denoiser itself, giving it a soft inductive bias towards constraint-compliant samples. We show that these softly constrained denoisers exploit constraint knowledge to improve compliance over standard denoisers, and maintain enough flexibility to deviate from it when there is misspecification with observed data.

</details>


### [89] [Prompt Repetition Improves Non-Reasoning LLMs](https://arxiv.org/abs/2512.14982)
*Yaniv Leviathan,Matan Kalman,Yossi Matias*

Main category: cs.LG

TL;DR: 重复输入提示能提升主流模型（Gemini、GPT、Claude、Deepseek）在不使用推理时的性能，且不增加生成token数量或延迟


<details>
  <summary>Details</summary>
Motivation: 探索在不增加计算成本（token数量和延迟）的情况下提升大语言模型性能的简单方法，特别是针对非推理任务场景

Method: 通过实验验证重复输入提示对多个主流模型（Gemini、GPT、Claude、Deepseek）在不使用推理功能时的影响，比较性能变化

Result: 重复输入提示能有效提升模型性能，且不会增加生成的token数量或处理延迟

Conclusion: 重复输入提示是一种简单有效的性能提升方法，适用于多种主流大语言模型，为模型优化提供了新思路

Abstract: When not using reasoning, repeating the input prompt improves performance for popular models (Gemini, GPT, Claude, and Deepseek) without increasing the number of generated tokens or latency.

</details>


### [90] [Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes](https://arxiv.org/abs/2512.14991)
*Hanqing Jin,Renyuan Xu,Yanzhao Yang*

Main category: cs.LG

TL;DR: 提出一种用于无界连续状态空间扩散过程的自适应分区强化学习算法，通过平衡探索与近似实现高效学习，并建立与缩放维度相关的遗憾界。


<details>
  <summary>Details</summary>
Motivation: 金融、经济和运筹学中常见的扩散过程通常具有无界连续状态空间、有界连续动作和多项式增长奖励，现有方法难以处理这种高维连续域问题。

Method: 提出基于模型的自适应分区算法，在状态-动作空间进行自适应划分，在每个分区内估计漂移、波动率和奖励函数，当估计偏差超过统计置信度时细化离散化。

Result: 建立了依赖于问题时域、状态维度、奖励增长阶数和缩放维度的遗憾界，将现有有界结果推广到更广泛的扩散过程问题，并通过多资产均值-方差投资组合选择等实验验证有效性。

Conclusion: 该自适应分区算法能够有效处理无界连续状态空间的扩散过程强化学习问题，为金融经济等领域的高维连续控制问题提供了理论保证和实用方法。

Abstract: We study reinforcement learning for controlled diffusion processes with unbounded continuous state spaces, bounded continuous actions, and polynomially growing rewards: settings that arise naturally in finance, economics, and operations research. To overcome the challenges of continuous and high-dimensional domains, we introduce a model-based algorithm that adaptively partitions the joint state-action space. The algorithm maintains estimators of drift, volatility, and rewards within each partition, refining the discretization whenever estimation bias exceeds statistical confidence. This adaptive scheme balances exploration and approximation, enabling efficient learning in unbounded domains. Our analysis establishes regret bounds that depend on the problem horizon, state dimension, reward growth order, and a newly defined notion of zooming dimension tailored to unbounded diffusion processes. The bounds recover existing results for bounded settings as a special case, while extending theoretical guarantees to a broader class of diffusion-type problems. Finally, we validate the effectiveness of our approach through numerical experiments, including applications to high-dimensional problems such as multi-asset mean-variance portfolio selection.

</details>


### [91] [DreamPRM-Code: Function-as-Step Process Reward Model with Label Correction for LLM Coding](https://arxiv.org/abs/2512.15000)
*Ruiyi Zhang,Peijia Qin,Qi Cao,Pengtao Xie*

Main category: cs.LG

TL;DR: DreamPRM-Code：针对代码任务的流程奖励模型，通过函数链提示实现模块化代码生成，并采用元学习校正机制减少标签噪声，在LiveCodeBench上达到80.9% pass@1的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有流程奖励模型（PRMs）在代码任务上效果有限，主要因为代码缺乏有意义的步骤分解，以及蒙特卡洛生成的部分标签存在噪声。需要专门针对代码优化的PRM方法。

Method: 1. 提出DreamPRM-Code，将函数作为推理步骤，使用Chain-of-Function提示策略诱导模块化代码生成；2. 引入基于元学习的校正机制，利用干净的最终解决方案单元测试标签，通过双层优化精炼中间标签。

Result: 在测试时扩展中，DreamPRM-Code在LiveCodeBench上达到80.9% pass@1的最先进性能，超越了OpenAI o4-mini。

Conclusion: DreamPRM-Code通过将函数作为推理步骤和元学习校正，有效解决了代码PRM中的分解和标签噪声问题，显著提升了代码生成性能。

Abstract: Process Reward Models (PRMs) have become essential for improving Large Language Models (LLMs) via test-time scaling, yet their effectiveness in coding remains limited due to the lack of meaningful step decompositions in code and the noise of Monte-Carlo-generated partial labels. We propose DreamPRM-Code, a coding-focused PRM that treats functions as reasoning steps using a Chain-of-Function prompting strategy to induce modular code generation, enabling PRM training and application analogous to mathematical reasoning tasks. To address label noise, DreamPRM-Code introduces a meta-learning-based correction mechanism that leverages clean final-solution unit-test labels and performs bi-level optimization to refine intermediate labels. Applying on test-time scaling, DreamPRM-Code achieved state-of-the-art performance on LiveCodeBench with 80.9 pass@1 rate, surpassing OpenAI o4-mini.

</details>


### [92] [Stock Pattern Assistant (SPA): A Deterministic and Explainable Framework for Structural Price Run Extraction and Event Correlation in Equity Markets](https://arxiv.org/abs/2512.15008)
*Sandeep Neela*

Main category: cs.LG

TL;DR: SPA是一个确定性框架，用于从股价数据中提取单调价格走势，关联公开事件，并生成可解释的历史分析，而非预测系统。


<details>
  <summary>Details</summary>
Motivation: 现有技术指标和预测模型缺乏透明度和可解释性，在需要审计和解释的市场分析场景中存在挑战。

Method: 使用确定性框架从每日OHLCV数据中提取单调价格走势，通过对称相关窗口关联标准化事件流，生成事实性、历史性且有约束的解释。

Result: 在AAPL、NVDA、SCHW、PGR四只股票上的评估显示，SPA能稳定生成结构性分解和上下文叙事，消融实验验证了各组件对可解释性的贡献。

Conclusion: SPA提供透明、可复现的历史价格结构分析，可补充分析师工作流程、风险评估和可解释AI管道，但不是预测或交易信号系统。

Abstract: Understanding how prices evolve over time often requires peeling back the layers of market noise to identify clear, structural behavior. Many of the tools commonly used for this purpose technical indicators, chart heuristics, or even sophisticated predictive models leave important questions unanswered. Technical indicators depend on platform-specific rules, and predictive systems typically offer little in terms of explanation. In settings that demand transparency or auditability, this poses a significant challenge. We introduce the Stock Pattern Assistant (SPA), a deterministic framework designed to extract monotonic price runs, attach relevant public events through a symmetric correlation window, and generate explanations that are factual, historical, and guardrailed. SPA relies only on daily OHLCV data and a normalized event stream, making the pipeline straight-forward to audit and easy to reproduce. To illustrate SPA's behavior in practice, we evaluate it across four equities-AAPL, NVDA, SCHW, and PGR-chosen to span a range of volatility regimes and sector characteristics. Although the evaluation period is modest, the results demonstrate how SPA consistently produces stable structural decompositions and contextual narratives. Ablation experiments further show how deterministic segmentation, event alignment, and constrained explanation each contribute to interpretability. SPA is not a forecasting system, nor is it intended to produce trading signals. Its value lies in offering a transparent, reproducible view of historical price structure that can complement analyst workflows, risk reviews, and broader explainable-AI pipelines.

</details>


### [93] [Epistemic diversity across language models mitigates knowledge collapse](https://arxiv.org/abs/2512.15011)
*Damian Hodel,Jevin D. West*

Main category: cs.LG

TL;DR: 研究AI生态系统多样性如何缓解知识崩溃，发现适度的认知多样性能有效减缓性能衰退，但过多或过少都会导致问题


<details>
  <summary>Details</summary>
Motivation: 随着AI的广泛使用，出现了知识崩溃的担忧——即知识减少到最主导和核心的思想集合。先前研究展示了单一模型崩溃现象，本研究受生态学启发，探索AI生态系统多样性（模型间的多样性）是否能缓解这种崩溃

Method: 基于单一模型方法，但专注于在集体输出上训练的模型生态系统。通过将训练数据在不同语言模型间分割，评估由此产生的生态系统在十次自训练迭代中的表现，研究多样性对模型性能的影响

Result: 增加认知多样性确实能缓解崩溃，但有趣的是，只达到一个最优水平。包含太少多样化模型的生态系统无法表达完整真实分布的丰富混合，导致性能快速衰退；而将数据分散到太多模型中会降低每个模型对真实分布的近似能力，导致第一次迭代就表现不佳

Conclusion: 在AI单一文化的背景下，研究结果表明需要监控AI系统间的多样性，并制定政策激励更多领域特定和社区特定的模型开发

Abstract: The growing use of artificial intelligence (AI) raises concerns of knowledge collapse, i.e., a reduction to the most dominant and central set of ideas. Prior work has demonstrated single-model collapse, defined as performance decay in an AI model trained on its own output. Inspired by ecology, we ask whether AI ecosystem diversity, that is, diversity among models, can mitigate such a collapse. We build on the single-model approach but focus on ecosystems of models trained on their collective output. To study the effect of diversity on model performance, we segment the training data across language models and evaluate the resulting ecosystems over ten, self-training iterations. We find that increased epistemic diversity mitigates collapse, but, interestingly, only up to an optimal level. Our results suggest that an ecosystem containing only a few diverse models fails to express the rich mixture of the full, true distribution, resulting in rapid performance decay. Yet distributing the data across too many models reduces each model's approximation capacity on the true distribution, leading to poor performance already in the first iteration step. In the context of AI monoculture, our results suggest the need to monitor diversity across AI systems and to develop policies that incentivize more domain- and community-specific models.

</details>


### [94] [Spectral Representation-based Reinforcement Learning](https://arxiv.org/abs/2512.15036)
*Chenxiao Gao,Haotian Sun,Na Li,Dale Schuurmans,Bo Dai*

Main category: cs.LG

TL;DR: 论文提出将谱表示作为强化学习的新视角，通过转移算子的谱分解来抽象系统动态，为策略优化提供理论基础，并在DeepMind Control Suite的20多个任务上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 强化学习在大状态和动作空间的实际应用中通常使用函数近似（如神经网络），但这些方法存在理论模糊性、优化不稳定、探索困难以及计算成本高等问题。需要一种既能提供清晰理论特性又能有效抽象系统动态的解决方案。

Method: 引入谱表示框架，基于转移算子的谱分解来构建系统动态的有效抽象。针对具有隐变量结构或基于能量结构的转移算子，提出了不同的谱表示学习方法。每个学习方法都实现了有效的RL算法，并将该谱视角扩展到部分可观察MDPs。

Result: 在DeepMind Control Suite的20多个挑战性任务上验证了所提算法，其性能达到或超过了当前最先进的model-free和model-based基线方法。

Conclusion: 谱表示框架为强化学习提供了新的理论视角，能够有效解决传统函数近似方法的问题，在复杂任务上展现出优越性能，并为部分可观察环境提供了理论扩展。

Abstract: In real-world applications with large state and action spaces, reinforcement learning (RL) typically employs function approximations to represent core components like the policies, value functions, and dynamics models. Although powerful approximations such as neural networks offer great expressiveness, they often present theoretical ambiguities, suffer from optimization instability and exploration difficulty, and incur substantial computational costs in practice. In this paper, we introduce the perspective of spectral representations as a solution to address these difficulties in RL. Stemming from the spectral decomposition of the transition operator, this framework yields an effective abstraction of the system dynamics for subsequent policy optimization while also providing a clear theoretical characterization. We reveal how to construct spectral representations for transition operators that possess latent variable structures or energy-based structures, which implies different learning methods to extract spectral representations from data. Notably, each of these learning methods realizes an effective RL algorithm under this framework. We also provably extend this spectral view to partially observable MDPs. Finally, we validate these algorithms on over 20 challenging tasks from the DeepMind Control Suite, where they achieve performances comparable or superior to current state-of-the-art model-free and model-based baselines.

</details>


### [95] [EMFusion: Conditional Diffusion Framework for Trustworthy Frequency Selective EMF Forecasting in Wireless Networks](https://arxiv.org/abs/2512.15067)
*Zijiang Yan,Yixiang Huang,Jianhua Pei,Hina Tabassum,Luca Chiaraviglio*

Main category: cs.LG

TL;DR: EMFusion：基于条件多变量扩散的概率性电磁场预测框架，整合上下文信息并提供不确定性估计，在频率选择性EMF预测中优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 无线基础设施快速增长需要准确估计和预测电磁场水平以确保合规性、评估健康影响和支持网络规划。现有研究依赖宽带聚合EMF数据的单变量预测，但需要频率选择性多变量预测来捕捉运营商间和频率间的变化。

Method: 提出EMFusion框架：基于条件多变量扩散的概率预测，整合时间、季节、节假日等上下文因素；采用增强的残差U-Net骨干网络和交叉注意力机制动态整合外部条件；使用基于插值的采样策略，将预测视为结构化修复任务以确保时间一致性。

Result: 在频率选择性EMF数据集上的实验表明，EMFusion在工作时间上下文信息下优于有/无条件的基线模型：CRPS提升23.85%，归一化RMSE提升13.93%，预测CRPS误差降低22.47%。

Conclusion: EMFusion能够生成校准的概率预测区间，提供明确的不确定性量化，对于可信赖的决策制定至关重要，在频率选择性EMF预测中表现出优越性能。

Abstract: The rapid growth in wireless infrastructure has increased the need to accurately estimate and forecast electromagnetic field (EMF) levels to ensure ongoing compliance, assess potential health impacts, and support efficient network planning. While existing studies rely on univariate forecasting of wideband aggregate EMF data, frequency-selective multivariate forecasting is needed to capture the inter-operator and inter-frequency variations essential for proactive network planning. To this end, this paper introduces EMFusion, a conditional multivariate diffusion-based probabilistic forecasting framework that integrates diverse contextual factors (e.g., time of day, season, and holidays) while providing explicit uncertainty estimates. The proposed architecture features a residual U-Net backbone enhanced by a cross-attention mechanism that dynamically integrates external conditions to guide the generation process. Furthermore, EMFusion integrates an imputation-based sampling strategy that treats forecasting as a structural inpainting task, ensuring temporal coherence even with irregular measurements. Unlike standard point forecasters, EMFusion generates calibrated probabilistic prediction intervals directly from the learned conditional distribution, providing explicit uncertainty quantification essential for trustworthy decision-making. Numerical experiments conducted on frequency-selective EMF datasets demonstrate that EMFusion with the contextual information of working hours outperforms the baseline models with or without conditions. The EMFusion outperforms the best baseline by 23.85% in continuous ranked probability score (CRPS), 13.93% in normalized root mean square error, and reduces prediction CRPS error by 22.47%.

</details>


### [96] [The Semantic Illusion: Certified Limits of Embedding-Based Hallucination Detection in RAG Systems](https://arxiv.org/abs/2512.15068)
*Debu Sinha*

Main category: cs.LG

TL;DR: RAG系统幻觉检测存在语义幻觉问题：基于嵌入的方法在真实基准上假阳性率过高，而GPT-4作为LLM法官能显著降低假阳性率，表明推理能力是关键。


<details>
  <summary>Details</summary>
Motivation: 尽管RAG系统基于检索证据，但仍容易产生幻觉。现有检测方法依赖语义相似性和NLI，但其根本局限性尚未被严格表征。需要更可靠的幻觉检测方法来评估RAG系统的实际部署能力。

Method: 应用保形预测（conformal prediction）进行幻觉检测，提供有限样本覆盖保证。在多个真实幻觉基准（HaluEval、RAGTruth、WikiBio）上测试多种方法：包括基于嵌入的方法（OpenAI text-embedding-3-large、交叉编码器）和GPT-4作为LLM法官。

Result: 在合成幻觉（Natural Questions）上达到94%覆盖率且0%假阳性率。但在真实基准上，基于嵌入的方法假阳性率极高：HaluEval 100%、RAGTruth 88%、WikiBio 50%。GPT-4作为LLM法官假阳性率仅7%（95% CI: [3.4%, 13.7%]），证明任务可通过推理解决。

Conclusion: 存在"语义幻觉"现象：语义合理的幻觉保持与源文档的相似性，同时引入嵌入方法无法检测的事实错误。这种局限性跨越嵌入架构、LLM生成器和任务类型，表明基于嵌入的检测不足以用于生产RAG部署，需要结合推理能力的方法。

Abstract: Retrieval-Augmented Generation (RAG) systems remain susceptible to hallucinations despite grounding in retrieved evidence. Current detection methods rely on semantic similarity and natural language inference (NLI), but their fundamental limitations have not been rigorously characterized. We apply conformal prediction to hallucination detection, providing finite-sample coverage guarantees that enable precise quantification of detection capabilities. Using calibration sets of approximately 600 examples, we achieve 94% coverage with 0% false positive rate on synthetic hallucinations (Natural Questions). However, on three real hallucination benchmarks spanning multiple LLMs (GPT-4, ChatGPT, GPT-3, Llama-2, Mistral), embedding-based methods - including state-of-the-art OpenAI text-embedding-3-large and cross-encoder models - exhibit unacceptable false positive rates: 100% on HaluEval, 88% on RAGTruth, and 50% on WikiBio. Crucially, GPT-4 as an LLM judge achieves only 7% FPR (95% CI: [3.4%, 13.7%]) on the same data, proving the task is solvable through reasoning. We term this the "semantic illusion": semantically plausible hallucinations preserve similarity to source documents while introducing factual errors invisible to embeddings. This limitation persists across embedding architectures, LLM generators, and task types, suggesting embedding-based detection is insufficient for production RAG deployment.

</details>


### [97] [The Semantic Architect: How FEAML Bridges Structured Data and LLMs for Multi-Label Tasks](https://arxiv.org/abs/2512.15082)
*Wanfu Gao,Zebin He,Jun Gao*

Main category: cs.LG

TL;DR: FEAML是一种基于大语言模型的自动化特征工程方法，专门针对多标签学习任务，通过代码生成、反馈机制和标签依赖建模来提升多标签分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的特征工程方法尚未应用于多标签学习任务，缺乏对复杂标签依赖关系的建模能力，也没有针对多标签任务特点进行专门适配。

Method: 利用LLM的代码生成能力，通过元数据和标签共现矩阵引导LLM理解数据特征与任务目标的关系，生成高质量特征。使用模型准确率评估特征有效性，皮尔逊相关系数检测冗余，并将评估结果作为反馈驱动LLM在后续迭代中持续优化代码生成。

Result: 在各种多标签数据集上的实证结果表明，FEAML优于其他特征工程方法。

Conclusion: 通过将LLM与反馈机制相结合，FEAML实现了一种高效、可解释且自我改进的特征工程范式。

Abstract: Existing feature engineering methods based on large language models (LLMs) have not yet been applied to multi-label learning tasks. They lack the ability to model complex label dependencies and are not specifically adapted to the characteristics of multi-label tasks. To address the above issues, we propose Feature Engineering Automation for Multi-Label Learning (FEAML), an automated feature engineering method for multi-label classification which leverages the code generation capabilities of LLMs. By utilizing metadata and label co-occurrence matrices, LLMs are guided to understand the relationships between data features and task objectives, based on which high-quality features are generated. The newly generated features are evaluated in terms of model accuracy to assess their effectiveness, while Pearson correlation coefficients are used to detect redundancy. FEAML further incorporates the evaluation results as feedback to drive LLMs to continuously optimize code generation in subsequent iterations. By integrating LLMs with a feedback mechanism, FEAML realizes an efficient, interpretable and self-improving feature engineering paradigm. Empirical results on various multi-label datasets demonstrate that our FEAML outperforms other feature engineering methods.

</details>


### [98] [Neural Modular Physics for Elastic Simulation](https://arxiv.org/abs/2512.15083)
*Yifei Li,Haixu Wu,Zeyi Xu,Tuur Stuyck,Wojciech Matusik*

Main category: cs.LG

TL;DR: 提出Neural Modular Physics (NMP)方法，将弹性模拟分解为物理意义明确的神经模块，结合神经网络近似能力和传统模拟器的物理可靠性，提升物理一致性和泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的物理模拟方法通常使用端到端的单一神经网络，虽然有效但缺乏传统数值模拟器的物理可解释性和可靠性。受传统模块化模拟器启发，希望结合神经网络近似能力和传统模拟器的物理可靠性。

Method: 将弹性动力学分解为具有物理意义的神经模块，通过中间物理量连接。采用专门架构和训练策略，将数值计算流程转化为模块化神经模拟器，实现对中间量和物理约束的直接监督。

Result: NMP在未见初始条件和分辨率上表现出优越泛化能力，实现稳定长时程模拟，相比其他神经模拟器更好地保持物理特性，在未知底层动力学场景中比传统模拟器更具可行性。

Conclusion: NMP通过模块化设计成功结合了神经网络近似能力和传统模拟器的物理可靠性，超越了之前的单一学习范式，为物理模拟提供了更可靠、可泛化的解决方案。

Abstract: Learning-based methods have made significant progress in physics simulation, typically approximating dynamics with a monolithic end-to-end optimized neural network. Although these models offer an effective way to simulation, they may lose essential features compared to traditional numerical simulators, such as physical interpretability and reliability. Drawing inspiration from classical simulators that operate in a modular fashion, this paper presents Neural Modular Physics (NMP) for elastic simulation, which combines the approximation capacity of neural networks with the physical reliability of traditional simulators. Beyond the previous monolithic learning paradigm, NMP enables direct supervision of intermediate quantities and physical constraints by decomposing elastic dynamics into physically meaningful neural modules connected through intermediate physical quantities. With a specialized architecture and training strategy, our method transforms the numerical computation flow into a modular neural simulator, achieving improved physical consistency and generalizability. Experimentally, NMP demonstrates superior generalization to unseen initial conditions and resolutions, stable long-horizon simulation, better preservation of physical properties compared to other neural simulators, and greater feasibility in scenarios with unknown underlying dynamics than traditional simulators.

</details>


### [99] [SigMA: Path Signatures and Multi-head Attention for Learning Parameters in fBm-driven SDEs](https://arxiv.org/abs/2512.15088)
*Xianglin Wu,Chiheb Ben Hammouda,Cornelis W. Oosterlee*

Main category: cs.LG

TL;DR: SigMA：结合路径签名和多头自注意力的神经网络架构，用于分数布朗运动驱动的随机微分方程参数估计，在精度和模型复杂度间取得更好平衡。


<details>
  <summary>Details</summary>
Motivation: 分数布朗运动驱动的随机微分方程在金融和可靠性工程中广泛应用，但这些过程非马尔可夫且缺乏半鞅结构，传统参数估计方法不适用或计算复杂。需要开发能处理粗糙动态和长程依赖的有效估计方法。

Method: 提出SigMA（Signature Multi-head Attention）架构，集成路径签名与多头自注意力机制，包含卷积预处理层和多层感知机进行特征编码。从分数布朗运动、分数Ornstein-Uhlenbeck和粗糙Heston模型生成的合成路径中学习参数。

Result: 在合成数据和两个真实数据集（股票指数已实现波动率和锂离子电池退化）上的实验表明，SigMA在准确性、鲁棒性和模型紧凑性方面一致优于CNN、LSTM、普通Transformer和Deep Signature基线方法。

Conclusion: 将签名变换与基于注意力的架构相结合，为具有粗糙或持久时间结构的随机系统中的参数推断提供了一个有效且可扩展的框架。

Abstract: Stochastic differential equations (SDEs) driven by fractional Brownian motion (fBm) are increasingly used to model systems with rough dynamics and long-range dependence, such as those arising in quantitative finance and reliability engineering. However, these processes are non-Markovian and lack a semimartingale structure, rendering many classical parameter estimation techniques inapplicable or computationally intractable beyond very specific cases. This work investigates two central questions: (i) whether integrating path signatures into deep learning architectures can improve the trade-off between estimation accuracy and model complexity, and (ii) what constitutes an effective architecture for leveraging signatures as feature maps. We introduce SigMA (Signature Multi-head Attention), a neural architecture that integrates path signatures with multi-head self-attention, supported by a convolutional preprocessing layer and a multilayer perceptron for effective feature encoding. SigMA learns model parameters from synthetically generated paths of fBm-driven SDEs, including fractional Brownian motion, fractional Ornstein-Uhlenbeck, and rough Heston models, with a particular focus on estimating the Hurst parameter and on joint multi-parameter inference, and it generalizes robustly to unseen trajectories. Extensive experiments on synthetic data and two real-world datasets (i.e., equity-index realized volatility and Li-ion battery degradation) show that SigMA consistently outperforms CNN, LSTM, vanilla Transformer, and Deep Signature baselines in accuracy, robustness, and model compactness. These results demonstrate that combining signature transforms with attention-based architectures provides an effective and scalable framework for parameter inference in stochastic systems with rough or persistent temporal structure.

</details>


### [100] [Feature-Centric Unsupervised Node Representation Learning Without Homophily Assumption](https://arxiv.org/abs/2512.15112)
*Sunwoo Kim,Soo Yong Lee,Kyungho Kim,Hyunjin Hwang,Jaemin Yoo,Kijung Shin*

Main category: cs.LG

TL;DR: FUEL：一种无监督节点表示学习方法，通过自适应调整图卷积的使用程度，在嵌入空间中增强类内相似性和类间分离性，在多种同质性水平的图上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前无监督节点表示学习过度依赖图卷积，尤其在非同质性图中可能导致特征或拓扑属性不同的节点产生过度相似的嵌入。现有方法主要在有监督学习中调整图卷积使用程度，而无监督场景下此类方法研究不足。

Method: 提出FUEL方法，自适应学习适当的图卷积使用程度。通过利用节点特征识别节点簇作为类别代理，在嵌入空间中增强类内相似性和类间分离性。使用节点特征作为类别代理，无需真实标签。

Result: 在15个基线方法和14个基准数据集上的广泛实验表明，FUEL在下游任务中表现优异，在不同同质性水平的图上均实现了最先进的性能。

Conclusion: FUEL通过自适应调整图卷积使用程度，有效解决了无监督节点表示学习中过度依赖图卷积的问题，特别是在非同质性图中，为无监督图学习提供了有效的解决方案。

Abstract: Unsupervised node representation learning aims to obtain meaningful node embeddings without relying on node labels. To achieve this, graph convolution, which aggregates information from neighboring nodes, is commonly employed to encode node features and graph topology. However, excessive reliance on graph convolution can be suboptimal-especially in non-homophilic graphs-since it may yield unduly similar embeddings for nodes that differ in their features or topological properties. As a result, adjusting the degree of graph convolution usage has been actively explored in supervised learning settings, whereas such approaches remain underexplored in unsupervised scenarios. To tackle this, we propose FUEL, which adaptively learns the adequate degree of graph convolution usage by aiming to enhance intra-class similarity and inter-class separability in the embedding space. Since classes are unknown, FUEL leverages node features to identify node clusters and treats these clusters as proxies for classes. Through extensive experiments using 15 baseline methods and 14 benchmark datasets, we demonstrate the effectiveness of FUEL in downstream tasks, achieving state-of-the-art performance across graphs with diverse levels of homophily.

</details>


### [101] [How Many Heads Make an SSM? A Unified Framework for Attention and State Space Models](https://arxiv.org/abs/2512.15115)
*Ali Ghodsi*

Main category: cs.LG

TL;DR: 该论文提出了一个统一框架来分析序列建模架构，揭示了注意力机制与状态空间模型在表达能力与梯度传播之间的基本权衡。


<details>
  <summary>Details</summary>
Motivation: 序列建模产生了多种架构（从RNN到Transformer和状态空间模型），但缺乏对表达能力与可训练性权衡的统一理论理解。需要建立一个理论框架来统一分析这些不同架构。

Method: 引入统一框架，通过输入依赖的有效交互算子W_ij(X)表示广泛的序列映射，识别两种构建模式：统一因子化框架（显式，注意力风格）和结构化动态（隐式，状态空间递归）。

Result: 1. 交互秩间隙：统一因子化框架中的模型（如单头注意力）受限于低维算子空间，无法表示某些结构化动态映射。2. 等价定理：在多头因子化类中，表示线性SSM需要且可实现于H=k个头。3. 梯度高速公路结果：注意力层允许距离无关的梯度路径，而稳定线性动态则表现出距离相关的梯度衰减。

Conclusion: 这些结果形式化了代数表达能力（交互/算子空间）与长距离梯度传播之间的基本权衡，为现代序列架构设计提供了理论基础。

Abstract: Sequence modeling has produced diverse architectures -- from classical recurrent neural networks to modern Transformers and state space models (SSMs) -- yet a unified theoretical understanding of expressivity and trainability trade-offs remains limited. We introduce a unified framework that represents a broad class of sequence maps via an input-dependent effective interaction operator $W_{ij}(X)$, making explicit two recurring construction patterns: (i) the Unified Factorized Framework (Explicit) (attention-style mixing), in which $W_{ij}(X)$ varies through scalar coefficients applied to shared value maps, and (ii) Structured Dynamics (Implicit) (state-space recurrences), in which $W_{ij}$ is induced by a latent dynamical system. Using this framework, we derive three theoretical results. First, we establish the Interaction Rank Gap: models in the Unified Factorized Framework, such as single-head attention, are constrained to a low-dimensional operator span and cannot represent certain structured dynamical maps. Second, we prove an Equivalence (Head-Count) Theorem showing that, within our multi-head factorized class, representing a linear SSM whose lag operators span a $k$-dimensional subspace on length-$n$ sequences requires and is achievable with $H=k$ heads. Third, we prove a Gradient Highway Result, showing that attention layers admit inputs with distance-independent gradient paths, whereas stable linear dynamics exhibit distance-dependent gradient attenuation. Together, these results formalize a fundamental trade-off between algebraic expressivity (interaction/operator span) and long-range gradient propagation, providing theoretical grounding for modern sequence architecture design.

</details>


### [102] [FADTI: Fourier and Attention Driven Diffusion for Multivariate Time Series Imputation](https://arxiv.org/abs/2512.15116)
*Runze Li,Hanchen Wang,Wenjie Zhang,Binghao Li,Yu Zhang,Xuemin Lin,Ying Zhang*

Main category: cs.LG

TL;DR: FADTI是一个基于扩散的多元时间序列插补框架，通过可学习的傅里叶偏置投影模块注入频率感知特征调制，结合自注意力和门控卷积进行时序建模，在多个基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer和扩散的模型缺乏明确的归纳偏置和频率感知能力，限制了它们在结构化缺失模式和分布偏移下的泛化性能。多元时间序列插补在医疗、交通预测和生物建模等应用中至关重要。

Method: 提出FADTI框架：1）通过可学习的傅里叶偏置投影模块注入频率感知特征调制；2）支持多种谱基，能够自适应编码平稳和非平稳模式；3）结合自注意力和门控卷积进行时序建模；4）将频率域归纳偏置注入生成式插补过程。

Result: 在多个基准测试（包括新引入的生物时间序列数据集）上，FADTI始终优于现有最先进方法，特别是在高缺失率情况下表现更佳。

Conclusion: FADTI通过注入频率感知的归纳偏置，有效提升了多元时间序列插补的性能，特别是在结构化缺失模式和分布偏移下的泛化能力，为实际应用提供了更可靠的解决方案。

Abstract: Multivariate time series imputation is fundamental in applications such as healthcare, traffic forecasting, and biological modeling, where sensor failures and irregular sampling lead to pervasive missing values. However, existing Transformer- and diffusion-based models lack explicit inductive biases and frequency awareness, limiting their generalization under structured missing patterns and distribution shifts. We propose FADTI, a diffusion-based framework that injects frequency-informed feature modulation via a learnable Fourier Bias Projection (FBP) module and combines it with temporal modeling through self-attention and gated convolution. FBP supports multiple spectral bases, enabling adaptive encoding of both stationary and non-stationary patterns. This design injects frequency-domain inductive bias into the generative imputation process. Experiments on multiple benchmarks, including a newly introduced biological time series dataset, show that FADTI consistently outperforms state-of-the-art methods, particularly under high missing rates. Code is available at https://anonymous.4open.science/r/TimeSeriesImputation-52BF

</details>


### [103] [Automatic Reward Shaping from Multi-Objective Human Heuristics](https://arxiv.org/abs/2512.15120)
*Yuqing Xie,Jiayu Chen,Wenhao Tang,Ya Zhang,Chao Yu,Yu Wang*

Main category: cs.LG

TL;DR: MORSE框架通过双层优化自动组合多个启发式奖励，引入随机性促进探索，在多目标机器人任务中达到与人工调优相当的性能


<details>
  <summary>Details</summary>
Motivation: 强化学习中设计有效的奖励函数仍然是一个核心挑战，特别是在多目标环境中。人工设计奖励函数困难且耗时，需要自动化的方法来组合多个启发式奖励。

Method: 提出MORSE框架，将奖励塑造过程建模为双层优化问题：内层训练策略最大化当前塑造的奖励，外层更新奖励函数以优化任务性能。为促进奖励空间探索并避免局部最优，引入随机性，注入由任务性能和固定随机初始化神经网络预测误差引导的噪声。

Result: 在MuJoCo和Isaac Sim环境中的实验结果表明，MORSE能有效平衡各种机器人任务中的多个目标，实现与手动调优奖励函数相当的任务性能。

Conclusion: MORSE提供了一个通用框架，能够自动组合多个启发式奖励，通过引入引导性随机性促进探索，在多目标强化学习任务中取得良好效果。

Abstract: Designing effective reward functions remains a central challenge in reinforcement learning, especially in multi-objective environments. In this work, we propose Multi-Objective Reward Shaping with Exploration (MORSE), a general framework that automatically combines multiple human-designed heuristic rewards into a unified reward function. MORSE formulates the shaping process as a bi-level optimization problem: the inner loop trains a policy to maximize the current shaped reward, while the outer loop updates the reward function to optimize task performance. To encourage exploration in the reward space and avoid suboptimal local minima, MORSE introduces stochasticity into the shaping process, injecting noise guided by task performance and the prediction error of a fixed, randomly initialized neural network. Experimental results in MuJoCo and Isaac Sim environments show that MORSE effectively balances multiple objectives across various robotic tasks, achieving task performance comparable to those obtained with manually tuned reward functions.

</details>


### [104] [TrajSyn: Privacy-Preserving Dataset Distillation from Federated Model Trajectories for Server-Side Adversarial Training](https://arxiv.org/abs/2512.15123)
*Mukur Gupta,Niharika Gupta,Saifur Rahman,Shantanu Pal,Chandan Karmakar*

Main category: cs.LG

TL;DR: TrajSyn是一个隐私保护的联邦学习框架，通过从客户端模型更新的轨迹中合成代理数据集，实现服务器端的对抗训练，提高模型鲁棒性而不增加客户端计算负担。


<details>
  <summary>Details</summary>
Motivation: 边缘设备上的深度学习模型在安全关键应用中面临对抗性攻击风险。联邦学习环境中，由于严格的客户端数据隐私约束和边缘设备有限的计算资源，传统的对抗训练难以应用。

Method: TrajSyn框架从客户端模型更新的轨迹中合成代理数据集，在服务器端进行对抗训练，无需访问原始客户端数据，保护了数据隐私。

Result: 在图像分类基准测试中，TrajSyn一致地提高了对抗鲁棒性，且没有给客户端设备带来额外的计算负担。

Conclusion: TrajSyn为联邦学习环境提供了一种有效的隐私保护对抗训练方法，解决了客户端数据隐私和计算资源限制的问题。

Abstract: Deep learning models deployed on edge devices are increasingly used in safety-critical applications. However, their vulnerability to adversarial perturbations poses significant risks, especially in Federated Learning (FL) settings where identical models are distributed across thousands of clients. While adversarial training is a strong defense, it is difficult to apply in FL due to strict client-data privacy constraints and the limited compute available on edge devices. In this work, we introduce TrajSyn, a privacy-preserving framework that enables effective server-side adversarial training by synthesizing a proxy dataset from the trajectories of client model updates, without accessing raw client data. We show that TrajSyn consistently improves adversarial robustness on image classification benchmarks with no extra compute burden on the client device.

</details>


### [105] [From Isolation to Entanglement: When Do Interpretability Methods Identify and Disentangle Known Concepts?](https://arxiv.org/abs/2512.15134)
*Aaron Mueller,Andrew Lee,Shruti Joshi,Ekdeep Singh Lubana,Dhanya Sridhar,Patrik Reizinger*

Main category: cs.LG

TL;DR: 该研究提出多概念评估框架，分析稀疏自编码器和稀疏探针在概念相关性增强时的解耦表现，发现特征与概念存在一对多关系，且即使概念分布均匀，特征操纵仍会影响多个概念，表明相关性度量不足以评估独立性。


<details>
  <summary>Details</summary>
Motivation: 当前可解释性研究通常孤立评估概念表示质量，隐含独立性假设可能不成立。需要探究常见特征化方法（稀疏自编码器和稀疏探针）是否能真正恢复解耦的概念表示，特别是在概念间存在相关性的现实场景中。

Method: 提出多概念评估设置，控制文本概念（如情感、领域、时态）间的相关性，分析相关性增强时的性能。首先评估特征化方法在不同相关强度下学习解耦表示的能力，然后进行操纵实验，测量每个概念是否可独立操控。

Result: 发现特征与概念存在一对多关系：特征最多对应一个概念，但概念分布在多个特征中。即使概念分布均匀，稀疏自编码器特征操纵时通常影响多个概念，表明它们既不具有选择性也不独立；但特征影响不相交的子空间。

Conclusion: 相关性度量通常不足以评估操纵时的独立性，影响不相交子空间也不足以保证概念选择性。这些结果强调了可解释性研究中组合评估的重要性。

Abstract: A central goal of interpretability is to recover representations of causally relevant concepts from the activations of neural networks. The quality of these concept representations is typically evaluated in isolation, and under implicit independence assumptions that may not hold in practice. Thus, it is unclear whether common featurization methods - including sparse autoencoders (SAEs) and sparse probes - recover disentangled representations of these concepts. This study proposes a multi-concept evaluation setting where we control the correlations between textual concepts, such as sentiment, domain, and tense, and analyze performance under increasing correlations between them. We first evaluate the extent to which featurizers can learn disentangled representations of each concept under increasing correlational strengths. We observe a one-to-many relationship from concepts to features: features correspond to no more than one concept, but concepts are distributed across many features. Then, we perform steering experiments, measuring whether each concept is independently manipulable. Even when trained on uniform distributions of concepts, SAE features generally affect many concepts when steered, indicating that they are neither selective nor independent; nonetheless, features affect disjoint subspaces. These results suggest that correlational metrics for measuring disentanglement are generally not sufficient for establishing independence when steering, and that affecting disjoint subspaces is not sufficient for concept selectivity. These results underscore the importance of compositional evaluations in interpretability research.

</details>


### [106] [Generalization and Feature Attribution in Machine Learning Models for Crop Yield and Anomaly Prediction in Germany](https://arxiv.org/abs/2512.15140)
*Roland Baatz*

Main category: cs.LG

TL;DR: 机器学习模型在德国NUTS-3区域作物产量预测中，虽然测试集表现良好，但时间泛化能力差，且解释性方法可能在模型未泛化时仍显示可信特征重要性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在评估机器学习模型在农业产量预测中的泛化性能和可解释性，特别关注模型在时间独立验证中的表现，以及解释性方法在模型未真正泛化时的可靠性问题。

Method: 使用高质量长期数据集，系统比较集成树模型（XGBoost、随机森林）和深度学习方法（LSTM、TCN）在德国NUTS-3区域的作物产量预测，分析空间分割测试集和时间独立验证的表现差异。

Result: 所有模型在空间分割测试集上表现良好，但在时间独立验证年份性能显著下降，揭示泛化能力有限。即使时间验证性能差的模型，SHAP特征重要性仍显示可信结果，暴露了解释性方法的脆弱性。

Conclusion: 农业环境系统需要验证感知的ML解释，特征重要性不能表面接受，除非模型明确展示对未见时空条件的泛化能力。建议领域感知验证、混合建模策略，并更严格审查解释性方法。

Abstract: This study examines the generalization performance and interpretability of machine learning (ML) models used for predicting crop yield and yield anomalies in Germany's NUTS-3 regions. Using a high-quality, long-term dataset, the study systematically compares the evaluation and temporal validation behavior of ensemble tree-based models (XGBoost, Random Forest) and deep learning approaches (LSTM, TCN).
  While all models perform well on spatially split, conventional test sets, their performance degrades substantially on temporally independent validation years, revealing persistent limitations in generalization. Notably, models with strong test-set accuracy, but weak temporal validation performance can still produce seemingly credible SHAP feature importance values. This exposes a critical vulnerability in post hoc explainability methods: interpretability may appear reliable even when the underlying model fails to generalize.
  These findings underscore the need for validation-aware interpretation of ML predictions in agricultural and environmental systems. Feature importance should not be accepted at face value unless models are explicitly shown to generalize to unseen temporal and spatial conditions. The study advocates for domain-aware validation, hybrid modeling strategies, and more rigorous scrutiny of explainability methods in data-driven agriculture. Ultimately, this work addresses a growing challenge in environmental data science: how can we evaluate generalization robustly enough to trust model explanations?

</details>


### [107] [An Efficient Gradient-Based Inference Attack for Federated Learning](https://arxiv.org/abs/2512.15143)
*Pablo Montaña-Fernández,Ines Ortega-Fernandez*

Main category: cs.LG

TL;DR: 提出一种新的联邦学习梯度成员推理攻击，利用多层梯度的时间演化模式，无需访问私有数据集，可扩展到属性推理，在图像和表格数据上表现强劲。


<details>
  <summary>Details</summary>
Motivation: 尽管联邦学习减少了直接数据暴露，但模型更新交换仍可能泄露敏感信息。现有攻击方法有限，需要探索基于多轮梯度时间演化的新型攻击。

Method: 使用影子技术学习训练记录的多轮梯度模式，考虑半诚实和恶意对手（聚合器或数据所有者）。通过对比不同属性假设下的梯度响应扩展到离散属性推理。方法模型无关，适用于任何基于梯度的模型。

Result: 在CIFAR-100和Purchase100数据集上评估成员推理，在Breast Cancer Wisconsin上评估属性推理。攻击表现强劲，计算和内存开销与现有攻击相当。发现多轮联邦学习增加推理攻击脆弱性，聚合器威胁更大，高维数据泄露更严重。

Conclusion: 多轮联邦学习可能增加推理攻击风险，聚合器构成更大威胁，数据特征强烈影响攻击效果。需要更强的隐私保护机制来应对这类基于梯度时间模式的攻击。

Abstract: Federated Learning is a machine learning setting that reduces direct data exposure, improving the privacy guarantees of machine learning models. Yet, the exchange of model updates between the participants and the aggregator can still leak sensitive information. In this work, we present a new gradient-based membership inference attack for federated learning scenarios that exploits the temporal evolution of last-layer gradients across multiple federated rounds. Our method uses the shadow technique to learn round-wise gradient patterns of the training records, requiring no access to the private dataset, and is designed to consider both semi-honest and malicious adversaries (aggregators or data owners). Beyond membership inference, we also provide a natural extension of the proposed attack to discrete attribute inference by contrasting gradient responses under alternative attribute hypotheses. The proposed attacks are model-agnostic, and therefore applicable to any gradient-based model and can be applied to both classification and regression settings. We evaluate the attack on CIFAR-100 and Purchase100 datasets for membership inference and on Breast Cancer Wisconsin for attribute inference. Our findings reveal strong attack performance and comparable computational and memory overhead in membership inference when compared to another attack from the literature. The obtained results emphasize that multi-round federated learning can increase the vulnerability to inference attacks, that aggregators pose a more substantial threat than data owners, and that attack performance is strongly influenced by the nature of the training dataset, with richer, high-dimensional data leading to stronger leakage than simpler tabular data.

</details>


### [108] [Understanding NTK Variance in Implicit Neural Representations](https://arxiv.org/abs/2512.15169)
*Chengguang Ou,Yixin Zhuang*

Main category: cs.LG

TL;DR: 该论文提出了一种统一的理论框架，通过分析神经正切核（NTK）的特征值方差来解释不同隐式神经表示（INR）架构如何缓解频谱偏置问题。


<details>
  <summary>Details</summary>
Motivation: 隐式神经表示（INRs）通常收敛缓慢且难以恢复高频细节，这是由于频谱偏置问题。虽然先前工作将此行为与神经正切核（NTK）联系起来，但具体架构选择如何影响NTK条件数仍不清楚。

Method: 作者证明许多INR机制可以通过它们对少量成对相似性因子和缩放项的影响来理解，这些因素共同决定NTK特征值方差。推导了常见INR组件的闭式方差分解，分析了位置编码、球面归一化和Hadamard调制等机制如何影响NTK条件数。

Result: 实验表明，位置编码重塑输入相似性，球面归一化通过层间缩放减少方差，Hadamard调制引入严格小于1的额外相似性因子，产生乘法方差减少。这些机制都能改善NTK条件数，从而缓解频谱偏置。

Conclusion: 该研究提供了一个统一的理论框架，解释了不同INR架构如何通过改善NTK条件数来缓解频谱偏置问题，实现了更快、更稳定的收敛和更好的重建质量。

Abstract: Implicit Neural Representations (INRs) often converge slowly and struggle to recover high-frequency details due to spectral bias. While prior work links this behavior to the Neural Tangent Kernel (NTK), how specific architectural choices affect NTK conditioning remains unclear. We show that many INR mechanisms can be understood through their impact on a small set of pairwise similarity factors and scaling terms that jointly determine NTK eigenvalue variance. For standard coordinate MLPs, limited input-feature interactions induce large eigenvalue dispersion and poor conditioning. We derive closed-form variance decompositions for common INR components and show that positional encoding reshapes input similarity, spherical normalization reduces variance via layerwise scaling, and Hadamard modulation introduces additional similarity factors strictly below one, yielding multiplicative variance reduction. This unified view explains how diverse INR architectures mitigate spectral bias by improving NTK conditioning. Experiments across multiple tasks confirm the predicted variance reductions and demonstrate faster, more stable convergence with improved reconstruction quality.

</details>


### [109] [DEER: Draft with Diffusion, Verify with Autoregressive Models](https://arxiv.org/abs/2512.15176)
*Zicong Cheng,Guo-Wei Yang,Jia Li,Zhijie Deng,Meng-Hao Guo,Shi-Min Hu*

Main category: cs.LG

TL;DR: DEER提出使用扩散大语言模型(dLLM)作为草稿生成器，通过并行解码生成长草稿段，显著提升推测解码效率，相比传统自回归草稿模型获得5.54倍加速


<details>
  <summary>Details</summary>
Motivation: 传统推测解码使用自回归草稿模型存在两个根本问题：1) 逐步不确定性累积导致目标模型与草稿模型之间的信任逐渐崩溃；2) 自回归草稿模型固有的顺序解码。这些问题限制了加速效果

Method: 提出DEER框架，使用扩散大语言模型(dLLM)作为草稿生成器，采用两阶段训练流程对齐dLLM与目标自回归模型，并采用单步解码生成长草稿段

Result: DEER达到32个token的草稿接受长度，远超EAGLE-3的10个token。在HumanEval上使用Qwen3-30B-A3B获得5.54倍加速，而EAGLE-3仅2.41倍

Conclusion: 扩散大语言模型草稿器通过其根本不同的概率建模和高效并行解码策略，能够克服传统自回归草稿模型的限制，显著提升推测解码效率

Abstract: Efficiency, as a critical practical challenge for LLM-driven agentic and reasoning systems, is increasingly constrained by the inherent latency of autoregressive (AR) decoding. Speculative decoding mitigates this cost through a draft-verify scheme, yet existing approaches rely on AR draft models (a.k.a., drafters), which introduce two fundamental issues: (1) step-wise uncertainty accumulation leads to a progressive collapse of trust between the target model and the drafter, and (2) inherently sequential decoding of AR drafters. Together, these factors cause limited speedups. In this paper, we show that a diffusion large language model (dLLM) drafters can naturally overcome these issues through its fundamentally different probabilistic modeling and efficient parallel decoding strategy. Building on this insight, we introduce DEER, an efficient speculative decoding framework that drafts with diffusion and verifies with AR models. To enable high-quality drafting, DEER employs a two-stage training pipeline to align the dLLM-based drafters with the target AR model, and further adopts single-step decoding to generate long draft segments. Experiments show DEER reaches draft acceptance lengths of up to 32 tokens, far surpassing the 10 tokens achieved by EAGLE-3. Moreover, on HumanEval with Qwen3-30B-A3B, DEER attains a 5.54x speedup, while EAGLE-3 achieves only 2.41x. Code, model, demo, etc, will be available at https://czc726.github.io/DEER/

</details>


### [110] [Chorus: Harmonizing Context and Sensing Signals for Data-Free Model Customization in IoT](https://arxiv.org/abs/2512.15206)
*Liyu Zhang,Yejia Liu,Kwun Ho Liu,Runxi Huang,Xiaomin Ouyang*

Main category: cs.LG

TL;DR: Chorus：一种面向物联网传感器的上下文感知、无数据模型定制方法，能够在无需目标域数据的情况下适应未见过的部署条件，通过跨模态重构学习上下文表示，并动态平衡传感器和上下文贡献。


<details>
  <summary>Details</summary>
Motivation: 现实世界物联网应用中，传感器数据通常在多样化和动态的上下文条件下收集，传感器放置或环境因素会显著影响数据模式和下游性能。传统领域适应或泛化方法通常忽略上下文信息或使用简单集成策略，导致在部署后处理未见过的上下文偏移时效果不佳。

Method: 1. 通过无监督跨模态重构学习上下文表示：在未标记传感器数据和基于语言的上下文嵌入之间进行重构，正则化上下文嵌入空间以学习鲁棒、可泛化的上下文表示。2. 训练轻量级门控头：在有限标记样本上训练，动态平衡传感器和上下文贡献——当传感器证据模糊时偏向上下文，反之亦然。3. 上下文缓存机制：重用缓存的上下文表示，仅在检测到上下文偏移时更新，以减少推理延迟。

Result: 在IMU、语音和WiFi感知任务上，面对多样上下文偏移，Chorus在未见过的上下文条件下比最先进的基线方法性能提升高达11.3%，同时在智能手机和边缘设备上保持可比的延迟。

Conclusion: Chorus通过有效学习上下文表示并自适应集成上下文信息，能够在无需目标域数据的情况下适应未见过的部署条件，显著提升物联网传感器应用在动态上下文环境中的性能，同时保持低延迟特性。

Abstract: In real-world IoT applications, sensor data is usually collected under diverse and dynamic contextual conditions where factors such as sensor placements or ambient environments can significantly affect data patterns and downstream performance. Traditional domain adaptation or generalization methods often ignore such context information or use simplistic integration strategies, making them ineffective in handling unseen context shifts after deployment. In this paper, we propose Chorus, a context-aware, data-free model customization approach that adapts models to unseen deployment conditions without requiring target-domain data. The key idea is to learn effective context representations that capture their influence on sensor data patterns and to adaptively integrate them based on the degree of context shift. Specifically, Chorus first performs unsupervised cross-modal reconstruction between unlabeled sensor data and language-based context embeddings, while regularizing the context embedding space to learn robust, generalizable context representations. Then, it trains a lightweight gated head on limited labeled samples to dynamically balance sensor and context contributions-favoring context when sensor evidence is ambiguous and vice versa. To further reduce inference latency, Chorus employs a context-caching mechanism that reuses cached context representations and updates only upon detected context shifts. Experiments on IMU, speech, and WiFi sensing tasks under diverse context shifts show that Chorus outperforms state-of-the-art baselines by up to 11.3% in unseen contexts, while maintaining comparable latency on smartphone and edge devices.

</details>


### [111] [Accelerating High-Throughput Catalyst Screening by Direct Generation of Equilibrium Adsorption Structures](https://arxiv.org/abs/2512.15228)
*Songze Huo,Xiao-Ming Cao*

Main category: cs.LG

TL;DR: DBCata是一个深度生成模型，通过周期性布朗桥框架和等变图神经网络，直接从非松弛结构生成DFT松弛的吸附结构，无需能量或力信息，显著提升催化剂筛选效率。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习原子间势（MLIP）的训练数据主要来自近平衡结构，导致吸附结构和吸附能预测不可靠，限制了催化剂大规模筛选的准确性。

Method: 结合周期性布朗桥框架和等变图神经网络，建立非松弛结构与DFT松弛结构之间的低维过渡流形，无需显式能量或力信息；采用混合化学启发式和自监督异常检测方法识别和优化异常预测。

Result: 在Catalysis-Hub数据集上，DBCata生成的吸附几何结构达到0.035 Å的原子间距离平均绝对误差（DMAE），比当前最先进的机器学习势模型提升近三倍；94%的情况下DFT精度可在0.1 eV内改进。

Conclusion: DBCata在氧还原反应中高效合金催化剂的高通量计算筛选中表现出色，展示了其作为催化剂设计和优化强大工具的潜力。

Abstract: The adsorption energy serves as a crucial descriptor for the large-scale screening of catalysts. Nevertheless, the limited distribution of training data for the extensively utilised machine learning interatomic potential (MLIP), predominantly sourced from near-equilibrium structures, results in unreliable adsorption structures and consequent adsorption energy predictions. In this context, we present DBCata, a deep generative model that integrates a periodic Brownian-bridge framework with an equivariant graph neural network to establish a low-dimensional transition manifold between unrelaxed and DFT-relaxed structures, without requiring explicit energy or force information. Upon training, DBCata effectively generates high-fidelity adsorption geometries, achieving an interatomic distance mean absolute error (DMAE) of 0.035 \textÅ on the Catalysis-Hub dataset, which is nearly three times superior to that of the current state-of-the-art machine learning potential models. Moreover, the corresponding DFT accuracy can be improved within 0.1 eV in 94\% of instances by identifying and refining anomalous predictions through a hybrid chemical-heuristic and self-supervised outlier detection approach. We demonstrate that the remarkable performance of DBCata facilitates accelerated high-throughput computational screening for efficient alloy catalysts in the oxygen reduction reaction, highlighting the potential of DBCata as a powerful tool for catalyst design and optimisation.

</details>


### [112] [O-EENC-SD: Efficient Online End-to-End Neural Clustering for Speaker Diarization](https://arxiv.org/abs/2512.15229)
*Elio Gruttadauria,Mathieu Fontaine,Jonathan Le Roux,Slim Essid*

Main category: cs.LG

TL;DR: O-EENC-SD是一种基于EEND-EDA的端到端在线说话人日志系统，采用新颖的RNN拼接机制，通过质心细化解码器实现高效在线预测，在CallHome数据集上达到SOTA水平。


<details>
  <summary>Details</summary>
Motivation: 现有在线端到端方法计算成本高，而无监督聚类方法需要超参数调优。需要开发一个既高效又无需超参数调优的在线说话人日志系统。

Method: 基于EEND-EDA框架，引入RNN拼接机制处理在线预测，开发质心细化解码器，在独立无重叠的音频块上工作，实现高效处理。

Result: 在CallHome数据集的双人电话对话语音领域，O-EENC-SD与最先进方法竞争，在DER和复杂度之间提供良好权衡，系统极其高效。

Conclusion: O-EENC-SD提供了一种超参数自由的解决方案，相比无监督聚类方法更简单，相比当前在线端到端方法更高效，在效率和性能之间取得了良好平衡。

Abstract: We introduce O-EENC-SD: an end-to-end online speaker diarization system based on EEND-EDA, featuring a novel RNN-based stitching mechanism for online prediction. In particular, we develop a novel centroid refinement decoder whose usefulness is assessed through a rigorous ablation study. Our system provides key advantages over existing methods: a hyperparameter-free solution compared to unsupervised clustering approaches, and a more efficient alternative to current online end-to-end methods, which are computationally costly. We demonstrate that O-EENC-SD is competitive with the state of the art in the two-speaker conversational telephone speech domain, as tested on the CallHome dataset. Our results show that O-EENC-SD provides a great trade-off between DER and complexity, even when working on independent chunks with no overlap, making the system extremely efficient.

</details>


### [113] [Leveraging Foundational Models and Simple Fusion for Multi-modal Physiological Signal Analysis](https://arxiv.org/abs/2512.15250)
*Youssef Ghallab,Omar Iraqy,Mohamed Kandil,Mohamed Ashraf,Saadeldine Eletter,Morougue Ghazal,Ayman Khalafallah,Nagwa El-Makky*

Main category: cs.LG

TL;DR: 该研究提出一种多模态生理信号分析方法，通过自监督预训练的CBraMod编码器分别处理ECG和EEG信号，采用简单的嵌入拼接融合策略，在有限的多模态标注数据下实现有效的情绪识别。


<details>
  <summary>Details</summary>
Motivation: ECG和EEG等生理信号为人类健康和认知提供互补信息，但多模态整合面临挑战：多模态标注数据有限，以及模态间存在特异性差异。需要开发能够在有限监督下有效融合多模态生理信号的方法。

Method: 1. 采用CBraMod编码器进行大规模自监督ECG预训练，引入双掩码策略捕捉导联内和导联间依赖关系
2. 使用预训练的CBraMod编码器处理EEG信号
3. 为ECG预训练对称编码器，为每个模态建立丰富的基础表示
4. 通过简单的嵌入拼接融合多模态表示，让分类头学习跨模态交互

Result: 在情绪识别任务上达到接近最先进的性能，表明精心设计的生理信号编码器即使采用简单的融合策略也能显著提升下游任务性能。

Conclusion: 基础模型方法能够利用生理信号的整体特性，为医疗保健和情感计算提供可扩展、标签高效且可泛化的解决方案。精心设计的生理信号编码器配合简单融合策略即可实现有效的多模态学习。

Abstract: Physiological signals such as electrocardiograms (ECG) and electroencephalograms (EEG) provide complementary insights into human health and cognition, yet multi-modal integration is challenging due to limited multi-modal labeled data, and modality-specific differences . In this work, we adapt the CBraMod encoder for large-scale self-supervised ECG pretraining, introducing a dual-masking strategy to capture intra- and inter-lead dependencies. To overcome the above challenges, we utilize a pre-trained CBraMod encoder for EEG and pre-train a symmetric ECG encoder, equipping each modality with a rich foundational representation. These representations are then fused via simple embedding concatenation, allowing the classification head to learn cross-modal interactions, together enabling effective downstream learning despite limited multi-modal supervision. Evaluated on emotion recognition, our approach achieves near state-of-the-art performance, demonstrating that carefully designed physiological encoders, even with straightforward fusion, substantially improve downstream performance. These results highlight the potential of foundation-model approaches to harness the holistic nature of physiological signals, enabling scalable, label-efficient, and generalizable solutions for healthcare and affective computing.

</details>


### [114] [Distillation-Guided Structural Transfer for Continual Learning Beyond Sparse Distributed Memory](https://arxiv.org/abs/2512.15267)
*Huiyan Xue,Xuming Ran,Yaxin Li,Qi Xu,Enhui Li,Yi Xu,Qiang Zhang*

Main category: cs.LG

TL;DR: SSD是一种结构引导的持续学习框架，通过选择性子网络蒸馏在稀疏神经网络中实现跨任务知识重用，提升准确率和保留率。


<details>
  <summary>Details</summary>
Motivation: 稀疏神经网络（如SDMLP）虽然通过任务特定子网络和Top-K激活减少了灾难性遗忘，但其刚性模块化限制了跨任务知识重用，在高稀疏度下性能会下降。

Method: 提出选择性子网络蒸馏（SSD），将蒸馏视为拓扑对齐的信息通道而非正则化器。识别高激活频率的神经元，在先前Top-K子网络和输出logits内选择性蒸馏知识，无需重放或任务标签，实现结构重新对齐同时保持稀疏模块化。

Result: 在Split CIFAR-10、CIFAR-100和MNIST上的实验表明，SSD提高了准确率、保留率和表示覆盖率。

Conclusion: SSD为稀疏持续学习提供了一个结构基础解决方案，通过选择性蒸馏实现跨任务知识重用，同时保持稀疏模块化的优势。

Abstract: Sparse neural systems are gaining traction for efficient continual learning due to their modularity and low interference. Architectures such as Sparse Distributed Memory Multi-Layer Perceptrons (SDMLP) construct task-specific subnetworks via Top-K activation and have shown resilience against catastrophic forgetting. However, their rigid modularity limits cross-task knowledge reuse and leads to performance degradation under high sparsity. We propose Selective Subnetwork Distillation (SSD), a structurally guided continual learning framework that treats distillation not as a regularizer but as a topology-aligned information conduit. SSD identifies neurons with high activation frequency and selectively distills knowledge within previous Top-K subnetworks and output logits, without requiring replay or task labels. This enables structural realignment while preserving sparse modularity. Experiments on Split CIFAR-10, CIFAR-100, and MNIST demonstrate that SSD improves accuracy, retention, and representation coverage, offering a structurally grounded solution for sparse continual learning.

</details>


### [115] [Topological Metric for Unsupervised Embedding Quality Evaluation](https://arxiv.org/abs/2512.15285)
*Aleksei Shestov,Anton Klenitskiy,Daria Denisova,Amurkhan Dzagkoev,Daniil Petrovich,Andrey Savchenko,Maksim Makarenko*

Main category: cs.LG

TL;DR: 提出Persistence：基于持续同调的无监督度量，用于评估嵌入空间的质量，无需标签即可量化几何结构和拓扑丰富度。


<details>
  <summary>Details</summary>
Motivation: 现代表示学习依赖于大规模无标签数据的无监督和自监督方法，但这些方法在无标签情况下评估嵌入质量仍然是一个开放挑战。现有度量通常假设线性可分性或依赖协方差结构，无法捕捉全局和多尺度组织。

Method: 提出Persistence度量，基于持续同调（persistent homology）的拓扑感知方法，在完全无监督的方式下量化嵌入空间的几何结构和拓扑丰富度。该方法能够捕捉全局和多尺度组织特征。

Result: 在多个领域的实证结果显示，Persistence始终与下游性能保持顶级相关性，优于现有的无监督度量方法，能够实现可靠的模型和超参数选择。

Conclusion: Persistence作为一种拓扑感知的无监督度量，能够有效评估嵌入空间质量，为无监督表示学习提供了可靠的评估工具，解决了无标签情况下嵌入质量评估的挑战。

Abstract: Modern representation learning increasingly relies on unsupervised and self-supervised methods trained on large-scale unlabeled data. While these approaches achieve impressive generalization across tasks and domains, evaluating embedding quality without labels remains an open challenge. In this work, we propose Persistence, a topology-aware metric based on persistent homology that quantifies the geometric structure and topological richness of embedding spaces in a fully unsupervised manner. Unlike metrics that assume linear separability or rely on covariance structure, Persistence captures global and multi-scale organization. Empirical results across diverse domains show that Persistence consistently achieves top-tier correlations with downstream performance, outperforming existing unsupervised metrics and enabling reliable model and hyperparameter selection.

</details>


### [116] [Quantum Machine Learning for Cybersecurity: A Taxonomy and Future Directions](https://arxiv.org/abs/2512.15286)
*Siva Sai,Ishika Goyal,Shubham Sharma,Sri Harshita Manuri,Vinay Chamola,Rajkumar Buyya*

Main category: cs.LG

TL;DR: 该论文是一篇关于量子机器学习在网络安全领域应用的综述，系统介绍了QML技术（如QNNs、QSVMs、VQCs、QGANs）在入侵检测、恶意软件分类等安全任务中的应用，并讨论了当前局限性和未来方向。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习、规则和基于签名的防御策略在面对日益增长的网络威胁、快速演变的攻击手法以及海量数据时已显不足，无法跟上安全需求。量子机器学习作为一种新兴技术，利用量子力学计算原理，为处理高维结构数据提供了更好的编码和处理能力，有望解决传统方法的局限性。

Method: 采用综述研究方法，全面梳理量子机器学习技术在安全领域的相关技术，包括量子神经网络、量子支持向量机、变分量子电路和量子生成对抗网络等。将这些方法映射到监督学习、无监督学习和生成学习范式，并与核心网络安全任务（入侵检测、异常检测、恶意软件分类、僵尸网络分类、加密流量分析）进行对应分析。

Result: 论文系统性地展示了QML技术在网络安全各领域的应用潜力，特别是在云计算安全领域，QML可以增强安全性和可扩展性操作。同时识别了QML在网络安全应用中的许多局限性，并提出了解决这些问题的方向。

Conclusion: 量子机器学习为网络安全领域提供了有前景的替代方案，能够更好地处理高维数据和复杂威胁。虽然目前存在局限性，但通过进一步研究和发展，QML有望显著提升网络安全防御能力，特别是在云计算等新兴领域。

Abstract: The increasing number of cyber threats and rapidly evolving tactics, as well as the high volume of data in recent years, have caused classical machine learning, rules, and signature-based defence strategies to fail, rendering them unable to keep up. An alternative, Quantum Machine Learning (QML), has recently emerged, making use of computations based on quantum mechanics. It offers better encoding and processing of high-dimensional structures for certain problems. This survey provides a comprehensive overview of QML techniques relevant to the domain of security, such as Quantum Neural Networks (QNNs), Quantum Support Vector Machines (QSVMs), Variational Quantum Circuits (VQCs), and Quantum Generative Adversarial Networks (QGANs), and discusses the contributions of this paper in relation to existing research in the field and how it improves over them. It also maps these methods across supervised, unsupervised, and generative learning paradigms, and to core cybersecurity tasks, including intrusion and anomaly detection, malware and botnet classification, and encrypted-traffic analytics. It also discusses their application in the domain of cloud computing security, where QML can enhance secure and scalable operations. Many limitations of QML in the domain of cybersecurity have also been discussed, along with the directions for addressing them.

</details>


### [117] [Bits for Privacy: Evaluating Post-Training Quantization via Membership Inference](https://arxiv.org/abs/2512.15335)
*Chenxiang Zhang,Tongxi Qu,Zhong Li,Tian Zhang,Jun Pang,Sjouke Mauw*

Main category: cs.LG

TL;DR: 量化技术通过降低模型参数精度来减少内存和计算成本，但现有隐私分析主要关注全精度模型。本文首次系统研究了后训练量化中的隐私-效用关系，发现低精度量化可显著降低成员推理攻击的隐私泄露风险。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络广泛使用量化技术来降低内存和计算成本，但现有隐私分析主要关注全精度模型，缺乏对量化如何影响隐私泄露的理解。需要填补这一研究空白，理解比特宽度减少对隐私泄露的影响。

Method: 使用成员推理攻击作为评估框架，分析三种流行的后训练量化算法（AdaRound、BRECQ和OBC），在多个精度级别（4位、2位和1.58位）上对CIFAR-10、CIFAR-100和TinyImageNet数据集进行评估。还进行了额外的消融研究，探索仅对最后一层进行高精度量化的效果。

Result: 低精度后训练量化可以显著减少隐私泄露。与全精度模型相比，低精度模型在成员推理攻击中的脆弱性最多可降低一个数量级，尽管这会以效用降低为代价。在1.58位量化级别上的消融研究表明，仅对最后一层进行高精度量化可以实现对隐私-效用权衡的精细控制。

Conclusion: 后训练量化不仅提高了效率，还能增强隐私保护。低精度量化模型在成员推理攻击中表现出更强的隐私保护能力，为实际部署中平衡效率、效用和隐私保护提供了可行的见解。仅对最后一层进行高精度量化的策略为隐私-效用权衡提供了精细控制手段。

Abstract: Deep neural networks are widely deployed with quantization techniques to reduce memory and computational costs by lowering the numerical precision of their parameters. While quantization alters model parameters and their outputs, existing privacy analyses primarily focus on full-precision models, leaving a gap in understanding how bit-width reduction can affect privacy leakage. We present the first systematic study of the privacy-utility relationship in post-training quantization (PTQ), a versatile family of methods that can be applied to pretrained models without further training. Using membership inference attacks as our evaluation framework, we analyze three popular PTQ algorithms-AdaRound, BRECQ, and OBC-across multiple precision levels (4-bit, 2-bit, and 1.58-bit) on CIFAR-10, CIFAR-100, and TinyImageNet datasets. Our findings consistently show that low-precision PTQs can reduce privacy leakage. In particular, lower-precision models demonstrate up to an order of magnitude reduction in membership inference vulnerability compared to their full-precision counterparts, albeit at the cost of decreased utility. Additional ablation studies on the 1.58-bit quantization level show that quantizing only the last layer at higher precision enables fine-grained control over the privacy-utility trade-off. These results offer actionable insights for practitioners to balance efficiency, utility, and privacy protection in real-world deployments.

</details>


### [118] [Empirical Investigation of the Impact of Phase Information on Fault Diagnosis of Rotating Machinery](https://arxiv.org/abs/2512.15344)
*Hiroyoshi Nagahama,Katsufumi Inoue,Masayoshi Todorokihara,Michifumi Yoshioka*

Main category: cs.LG

TL;DR: 提出两种相位感知预处理策略来处理多轴振动数据中的随机相位变化，通过相位对齐显著提升旋转机械预测性维护的准确率


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的旋转机械预测性维护方法在频谱特征提取时通常丢弃相位信息，或使用原始时域波形而未显式利用相位信息，这限制了性能提升

Method: 提出两种相位感知预处理策略：1）三轴独立相位调整（独立对齐各轴至零相位）；2）单轴参考相位调整（通过统一时间偏移保持轴间相位关系）。使用新构建的同步三轴传感器转子数据集，在两级学习框架下评估六种深度学习架构

Result: 三轴独立方法实现一致性能提升（Transformer提升2.7%），单轴参考方法通过保持空间相位关系达到96.2%准确率（提升5.4%），两种策略均带来架构无关的改进

Conclusion: 两种相位对齐策略是预测性维护系统实用且可扩展的增强方法，相位信息对旋转机械故障诊断具有重要价值

Abstract: Predictive maintenance of rotating machinery increasingly relies on vibration signals, yet most learning-based approaches either discard phase during spectral feature extraction or use raw time-waveforms without explicitly leveraging phase information. This paper introduces two phase-aware preprocessing strategies to address random phase variations in multi-axis vibration data: (1) three-axis independent phase adjustment that aligns each axis individually to zero phase (2) single-axis reference phase adjustment that preserves inter-axis relationships by applying uniform time shifts. Using a newly constructed rotor dataset acquired with a synchronized three-axis sensor, we evaluate six deep learning architectures under a two-stage learning framework. Results demonstrate architecture-independent improvements: the three-axis independent method achieves consistent gains (+2.7\% for Transformer), while the single-axis reference approach delivers superior performance with up to 96.2\% accuracy (+5.4\%) by preserving spatial phase relationships. These findings establish both phase alignment strategies as practical and scalable enhancements for predictive maintenance systems.

</details>


### [119] [A Regime-Aware Fusion Framework for Time Series Classification](https://arxiv.org/abs/2512.15378)
*Honey Singh Chauhan,Zahraa S. Abdallah*

Main category: cs.LG

TL;DR: F3是一个轻量级框架，通过自适应融合Rocket、Sax和Sfa三种表示来提升时间序列分类性能，在特定数据特征下能系统性地改进Rocket方法。


<details>
  <summary>Details</summary>
Motivation: 虽然基于核的方法如Rocket是单变量时间序列分类的有效默认方法，但它们在所有数据集上表现并不一致。研究旨在验证不同表示能捕捉互补结构的直觉，通过选择性融合来在特定类型数据集上获得一致改进。

Method: 提出Fusion-3(F3)框架，自适应融合Rocket、Sax和Sfa三种表示。使用元特征（序列长度、频谱结构、粗糙度、类别不平衡）将UCR数据集聚类为6组，作为可解释的数据结构机制。通过非参数配对统计、消融研究和SHAP归因三种互补分析来理解融合何时有效。

Result: 在113个UCR数据集上的5折交叉验证显示，F3相比Rocket获得小而一致的平均改进，得到频率主义和贝叶斯证据支持。融合通常在具有结构化变异性或丰富频率内容的机制中表现更好，而在高度不规则或异常值多的设置中收益递减。

Conclusion: 选择性应用的融合为强大的基于核的方法提供了可靠且可解释的扩展，在数据支持的情况下精确纠正其弱点。融合主要通过纠正特定错误来提升性能，自适应增加频率域权重恰好发生在需要修正的地方。

Abstract: Kernel-based methods such as Rocket are among the most effective default approaches for univariate time series classification (TSC), yet they do not perform equally well across all datasets. We revisit the long-standing intuition that different representations capture complementary structure and show that selectively fusing them can yield consistent improvements over Rocket on specific, systematically identifiable kinds of datasets. We introduce Fusion-3 (F3), a lightweight framework that adaptively fuses Rocket, Sax, and Sfa representations. To understand when fusion helps, we cluster UCR datasets into six groups using meta-features capturing series length, spectral structure, roughness, and class imbalance, and treat these clusters as interpretable data-structure regimes. Our analysis shows that fusion typically outperforms strong baselines in regimes with structured variability or rich frequency content, while offering diminishing returns in highly irregular or outlier-heavy settings. To support these findings, we combine three complementary analyses: non-parametric paired statistics across datasets, ablation studies isolating the roles of individual representations, and attribution via SHAP to identify which dataset properties predict fusion gains. Sample-level case studies further reveal the underlying mechanism: fusion primarily improves performance by rescuing specific errors, with adaptive increases in frequency-domain weighting precisely where corrections occur. Using 5-fold cross-validation on the 113 UCR datasets, F3 yields small but consistent average improvements over Rocket, supported by frequentist and Bayesian evidence and accompanied by clearly identifiable failure cases. Our results show that selectively applied fusion provides dependable and interpretable extension to strong kernel-based methods, correcting their weaknesses precisely where the data support it.

</details>


### [120] [Robustness Evaluation of Machine Learning Models for Fault Classification and Localization In Power System Protection](https://arxiv.org/abs/2512.15385)
*Julian Oelhaf,Mehran Pashaei,Georg Kordowich,Christian Bergler,Andreas Maier,Johann Jäger,Siming Bayer*

Main category: cs.LG

TL;DR: 提出一个统一框架，用于系统评估电力系统保护中机器学习模型的鲁棒性，分析传感器数据退化对故障分类和定位的影响。


<details>
  <summary>Details</summary>
Motivation: 可再生能源和分布式发电的普及挑战了传统基于固定设置和本地测量的保护方案，机器学习提供了数据驱动的替代方案，但实际部署需要确保在传感器数据缺失、噪声或退化时的鲁棒性。

Method: 使用高保真电磁暂态仿真模拟现实退化场景（传感器中断、采样率降低、瞬态通信丢失），建立统一框架系统评估ML模型鲁棒性，提供一致的基准测试方法。

Result: 故障分类在大多数退化类型下保持高度稳定，但在单相丢失时下降约13%；故障定位整体更敏感，电压丢失使定位误差增加超过150%。

Conclusion: 该框架为未来机器学习辅助保护系统的鲁棒性设计提供了可操作的指导，能够量化有限可观测性的影响并识别关键测量通道。

Abstract: The growing penetration of renewable and distributed generation is transforming power systems and challenging conventional protection schemes that rely on fixed settings and local measurements. Machine learning (ML) offers a data-driven alternative for centralized fault classification (FC) and fault localization (FL), enabling faster and more adaptive decision-making. However, practical deployment critically depends on robustness. Protection algorithms must remain reliable even when confronted with missing, noisy, or degraded sensor data. This work introduces a unified framework for systematically evaluating the robustness of ML models in power system protection.
  High-fidelity EMT simulations are used to model realistic degradation scenarios, including sensor outages, reduced sampling rates, and transient communication losses. The framework provides a consistent methodology for benchmarking models, quantifying the impact of limited observability, and identifying critical measurement channels required for resilient operation. Results show that FC remains highly stable under most degradation types but drops by about 13% under single-phase loss, while FL is more sensitive overall, with voltage loss increasing localization error by over 150%. These findings offer actionable guidance for robustness-aware design of future ML-assisted protection systems.

</details>


### [121] [EUBRL: Epistemic Uncertainty Directed Bayesian Reinforcement Learning](https://arxiv.org/abs/2512.15405)
*Jianfei Ma,Wee Sun Lee*

Main category: cs.LG

TL;DR: 提出EUBRL算法，利用认知不确定性指导探索，在无限时域折扣MDP中实现接近极小极大最优的遗憾和样本复杂度保证


<details>
  <summary>Details</summary>
Motivation: 智能体在已知与未知边界面临探索-利用困境，认知不确定性反映了知识有限导致的系统性不确定性，需要利用这种不确定性指导探索

Method: 提出贝叶斯强化学习算法EUBRL，利用认知不确定性指导探索，自适应减少由估计误差引起的每步遗憾

Result: 在无限时域折扣MDP中，对一类充分表达的先验建立了接近极小极大最优的遗憾和样本复杂度保证；在稀疏奖励、长时域和随机性任务中表现出优越的样本效率、可扩展性和一致性

Conclusion: EUBRL通过认知不确定性指导实现了原则性探索，在理论和实验上都表现出优越性能

Abstract: At the boundary between the known and the unknown, an agent inevitably confronts the dilemma of whether to explore or to exploit. Epistemic uncertainty reflects such boundaries, representing systematic uncertainty due to limited knowledge. In this paper, we propose a Bayesian reinforcement learning (RL) algorithm, $\texttt{EUBRL}$, which leverages epistemic guidance to achieve principled exploration. This guidance adaptively reduces per-step regret arising from estimation errors. We establish nearly minimax-optimal regret and sample complexity guarantees for a class of sufficiently expressive priors in infinite-horizon discounted MDPs. Empirically, we evaluate $\texttt{EUBRL}$ on tasks characterized by sparse rewards, long horizons, and stochasticity. Results demonstrate that $\texttt{EUBRL}$ achieves superior sample efficiency, scalability, and consistency.

</details>


### [122] [FlowBind: Efficient Any-to-Any Generation with Bidirectional Flows](https://arxiv.org/abs/2512.15420)
*Yeonwoo Cha,Semin Kim,Jinhyeon Kwon,Seunghoon Hong*

Main category: cs.LG

TL;DR: FlowBind：一种高效的任意到任意生成框架，通过共享潜在空间和模态特定可逆流实现跨模态转换，显著减少参数数量和训练时间


<details>
  <summary>Details</summary>
Motivation: 现有基于流的方法存在效率低下问题：需要大规模数据集且配对约束严格，建模联合分布计算成本高，依赖复杂的多阶段训练。需要更高效的任意到任意生成方法。

Method: 学习一个捕获跨模态信息的共享潜在空间，使用模态特定的可逆流将每个模态桥接到该潜在空间。两个组件在单一流匹配目标下联合优化，推理时使用可逆流作为编码器和解码器进行直接模态转换。

Result: 在文本、图像和音频上的实验表明，FlowBind达到可比质量的同时，参数数量减少高达6倍，训练速度快10倍。通过共享潜在空间因子化交互，自然利用任意模态子集进行训练。

Conclusion: FlowBind提供了一种简单高效的任意到任意生成框架，显著减少数据需求和计算成本，同时保持竞争性的生成质量，为跨模态合成提供了更实用的解决方案。

Abstract: Any-to-any generation seeks to translate between arbitrary subsets of modalities, enabling flexible cross-modal synthesis. Despite recent success, existing flow-based approaches are challenged by their inefficiency, as they require large-scale datasets often with restrictive pairing constraints, incur high computational cost from modeling joint distribution, and rely on complex multi-stage training. We propose FlowBind, an efficient framework for any-to-any generation. Our approach is distinguished by its simplicity: it learns a shared latent space capturing cross-modal information, with modality-specific invertible flows bridging this latent to each modality. Both components are optimized jointly under a single flow-matching objective, and at inference the invertible flows act as encoders and decoders for direct translation across modalities. By factorizing interactions through the shared latent, FlowBind naturally leverages arbitrary subsets of modalities for training, and achieves competitive generation quality while substantially reducing data requirements and computational cost. Experiments on text, image, and audio demonstrate that FlowBind attains comparable quality while requiring up to 6x fewer parameters and training 10x faster than prior methods. The project page with code is available at https://yeonwoo378.github.io/official_flowbind.

</details>


### [123] [Statistics of Min-max Normalized Eigenvalues in Random Matrices](https://arxiv.org/abs/2512.15427)
*Hyakka Nakada,Shu Tanaka*

Main category: cs.LG

TL;DR: 研究随机矩阵中经过最小-最大归一化后的特征值的统计特性，推导其累积分布的标度律及矩阵分解中的残差误差，并通过数值实验验证理论预测。


<details>
  <summary>Details</summary>
Motivation: 随机矩阵理论在纯数学、数学物理和机器学习中都有重要应用。从数据科学的实践角度看，输入数据通常需要先进行归一化处理。因此，本研究旨在探究随机矩阵中经过最小-最大归一化后的特征值的统计特性。

Method: 应用先前提出的归一化特征值有效分布，评估累积分布的标度律，并推导随机矩阵矩阵分解过程中产生的残差误差。通过数值实验验证理论预测。

Result: 推导了归一化特征值累积分布的标度律，得到了矩阵分解的残差误差表达式，并通过数值实验验证了这些理论预测的正确性。

Conclusion: 本研究为随机矩阵中归一化特征值的统计特性提供了理论分析框架，推导了累积分布的标度律和矩阵分解残差，并通过实验验证了理论结果，对数据科学中的归一化处理有实际指导意义。

Abstract: Random matrix theory has played an important role in various areas of pure mathematics, mathematical physics, and machine learning. From a practical perspective of data science, input data are usually normalized prior to processing. Thus, this study investigates the statistical properties of min-max normalized eigenvalues in random matrices. Previously, the effective distribution for such normalized eigenvalues has been proposed. In this study, we apply it to evaluate a scaling law of the cumulative distribution. Furthermore, we derive the residual error that arises during matrix factorization of random matrices. We conducted numerical experiments to verify these theoretical predictions.

</details>


### [124] [FM-EAC: Feature Model-based Enhanced Actor-Critic for Multi-Task Control in Dynamic Environments](https://arxiv.org/abs/2512.15430)
*Quanxi Zhou,Wencan Mao,Manabu Tsukada,John C. S. Lui,Yusheng Ji*

Main category: cs.LG

TL;DR: 提出FM-EAC算法，结合基于模型和无模型强化学习，通过特征模型和增强的actor-critic框架提升多任务控制中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现代强化学习方法在跨任务和场景的有效迁移性方面仍存在困难，虽然MBRL和MFRL在Dyna-Q设计中有所融合，但仍有改进空间。

Method: 提出FM-EAC算法，整合规划、行动和学习，结合基于模型和无模型强化学习的优势，使用新颖的特征模型和增强的actor-critic框架。

Result: 在城市和农业应用中的仿真表明，FM-EAC持续优于许多最先进的MBRL和MFRL方法，且其子网络可根据用户特定需求定制。

Conclusion: FM-EAC通过结合规划、行动和学习，有效提升了强化学习在多任务动态环境中的泛化能力和性能。

Abstract: Model-based reinforcement learning (MBRL) and model-free reinforcement learning (MFRL) evolve along distinct paths but converge in the design of Dyna-Q [1]. However, modern RL methods still struggle with effective transferability across tasks and scenarios. Motivated by this limitation, we propose a generalized algorithm, Feature Model-Based Enhanced Actor-Critic (FM-EAC), that integrates planning, acting, and learning for multi-task control in dynamic environments. FM-EAC combines the strengths of MBRL and MFRL and improves generalizability through the use of novel feature-based models and an enhanced actor-critic framework. Simulations in both urban and agricultural applications demonstrate that FM-EAC consistently outperforms many state-of-the-art MBRL and MFRL methods. More importantly, different sub-networks can be customized within FM-EAC according to user-specific requirements.

</details>


### [125] [Double Horizon Model-Based Policy Optimization](https://arxiv.org/abs/2512.15439)
*Akihiro Kubo,Paavo Parmas,Shin Ishii*

Main category: cs.LG

TL;DR: DHMBPO提出双视野模型基强化学习，通过长分布视野和短训练视野分别解决分布偏移和梯度不稳定问题，提升样本效率和运行速度。


<details>
  <summary>Details</summary>
Motivation: 传统MBRL中视野长度选择面临两难：长视野能更好保持同策略训练但放大模型偏差，同时长视野可能减少价值估计偏差但增加策略梯度方差。这两个最优视野可能不同，需要解决这一冲突。

Method: 提出双视野模型基策略优化(DHMBPO)，将视野过程分为长"分布视野"(DR)和短"训练视野"(TR)。DR生成同策略状态样本缓解分布偏移，短TR利用可微分转移提供准确价值梯度估计，实现稳定梯度更新。

Result: 双视野方法有效平衡了分布偏移、模型偏差和梯度不稳定性，在连续控制基准测试中超越了现有MBRL方法，在样本效率和运行时间方面都有优势。

Conclusion: 通过分离分布视野和训练视野，DHMBPO解决了MBRL中视野长度选择的根本冲突，为模型基强化学习提供了更有效的训练框架。

Abstract: Model-based reinforcement learning (MBRL) reduces the cost of real-environment sampling by generating synthetic trajectories (called rollouts) from a learned dynamics model. However, choosing the length of the rollouts poses two dilemmas: (1) Longer rollouts better preserve on-policy training but amplify model bias, indicating the need for an intermediate horizon to mitigate distribution shift (i.e., the gap between on-policy and past off-policy samples). (2) Moreover, a longer model rollout may reduce value estimation bias but raise the variance of policy gradients due to backpropagation through multiple steps, implying another intermediate horizon for stable gradient estimates. However, these two optimal horizons may differ. To resolve this conflict, we propose Double Horizon Model-Based Policy Optimization (DHMBPO), which divides the rollout procedure into a long "distribution rollout" (DR) and a short "training rollout" (TR). The DR generates on-policy state samples for mitigating distribution shift. In contrast, the short TR leverages differentiable transitions to offer accurate value gradient estimation with stable gradient updates, thereby requiring fewer updates and reducing overall runtime. We demonstrate that the double-horizon approach effectively balances distribution shift, model bias, and gradient instability, and surpasses existing MBRL methods on continuous-control benchmarks in terms of both sample efficiency and runtime.

</details>


### [126] [Copyright Infringement Risk Reduction via Chain-of-Thought and Task Instruction Prompting](https://arxiv.org/abs/2512.15442)
*Neeraj Sarna,Yuanyuan Li,Michael von Gablenz*

Main category: cs.LG

TL;DR: 该论文研究了通过思维链和任务指令提示来减少文本到图像生成模型中受版权保护内容的生成，结合负向提示和提示重写技术，评估了不同模型上的效果。


<details>
  <summary>Details</summary>
Motivation: 大规模文本到图像生成模型会记忆并复制其训练数据，而训练数据常包含受版权保护的材料，这带来了版权侵权风险，可能导致AI用户和开发者面临法律责任和经济损失。

Method: 提出了结合思维链和任务指令提示的框架，并与两种版权缓解策略结合：a) 负向提示，b) 提示重写。通过评估生成图像与受版权图像的相似性以及与用户输入的相关性来研究这些技术。

Result: 在不同复杂度的模型上进行了数值实验，提供了关于上述技术有效性的见解，展示了这些方法在减少版权内容生成方面的效果。

Conclusion: 思维链和任务指令提示结合负向提示和提示重写可以有效减少文本到图像生成模型中的版权内容生成，为缓解版权侵权风险提供了实用方法。

Abstract: Large scale text-to-image generation models can memorize and reproduce their training dataset. Since the training dataset often contains copyrighted material, reproduction of training dataset poses a copyright infringement risk, which could result in legal liabilities and financial losses for both the AI user and the developer. The current works explores the potential of chain-of-thought and task instruction prompting in reducing copyrighted content generation. To this end, we present a formulation that combines these two techniques with two other copyright mitigation strategies: a) negative prompting, and b) prompt re-writing. We study the generated images in terms their similarity to a copyrighted image and their relevance of the user input. We present numerical experiments on a variety of models and provide insights on the effectiveness of the aforementioned techniques for varying model complexity.

</details>


### [127] [From Risk to Resilience: Towards Assessing and Mitigating the Risk of Data Reconstruction Attacks in Federated Learning](https://arxiv.org/abs/2512.15460)
*Xiangrui Xu,Zhize Li,Yufei Han,Bin Wang,Jiqiang Liu,Wei Wang*

Main category: cs.LG

TL;DR: 提出Invertibility Loss (InvLoss)量化联邦学习中数据重构攻击的最大风险，建立理论框架评估和防御此类攻击。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中的数据重构攻击威胁严重，但缺乏理论基础的量化框架来评估风险，需要系统性的风险评估和缓解方法。

Method: 引入Invertibility Loss (InvLoss)量化数据重构攻击的最大有效性，推导其紧致可计算上界，开发InvRE风险估计器，并提出两种自适应噪声扰动防御方法。

Result: 实验验证了框架的有效性，证明DRA风险由Jacobian矩阵的谱特性决定，InvRE能提供攻击方法无关的全面风险评估，自适应防御能在不影响分类准确性的情况下增强隐私。

Conclusion: 提出的InvLoss框架为联邦学习中的数据重构攻击提供了系统性的风险评估和缓解方法，填补了理论空白，具有实际应用价值。

Abstract: Data Reconstruction Attacks (DRA) pose a significant threat to Federated Learning (FL) systems by enabling adversaries to infer sensitive training data from local clients. Despite extensive research, the question of how to characterize and assess the risk of DRAs in FL systems remains unresolved due to the lack of a theoretically-grounded risk quantification framework. In this work, we address this gap by introducing Invertibility Loss (InvLoss) to quantify the maximum achievable effectiveness of DRAs for a given data instance and FL model. We derive a tight and computable upper bound for InvLoss and explore its implications from three perspectives. First, we show that DRA risk is governed by the spectral properties of the Jacobian matrix of exchanged model updates or feature embeddings, providing a unified explanation for the effectiveness of defense methods. Second, we develop InvRE, an InvLoss-based DRA risk estimator that offers attack method-agnostic, comprehensive risk evaluation across data instances and model architectures. Third, we propose two adaptive noise perturbation defenses that enhance FL privacy without harming classification accuracy. Extensive experiments on real-world datasets validate our framework, demonstrating its potential for systematic DRA risk evaluation and mitigation in FL systems.

</details>


### [128] [Metanetworks as Regulatory Operators: Learning to Edit for Requirement Compliance](https://arxiv.org/abs/2512.15469)
*Ioannis Kalogeropoulos,Giorgos Bouritsas,Yannis Panagakis*

Main category: cs.LG

TL;DR: 提出一种通过图元网络编辑神经网络的方法，可在不牺牲性能的情况下高效满足各种需求（如公平性、计算约束等），相比后处理或重新训练方法在性能、需求满足和时间效率方面取得更好平衡。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在关键领域部署时需要满足多种需求（法规合规、公平性、计算约束等），但现有方法面临挑战：后处理方法会损害性能，而微调或重新训练耗时且不可行。需要一种能高效编辑模型以满足需求而不牺牲效用的方法。

Method: 提出统一的数据驱动框架，使用图元网络作为编辑器来编辑神经网络。元网络在神经网络群体上训练，最小化由需求满足和效用保持组成的目标函数。编辑过程仅需单次推理步骤。

Result: 在多种任务（数据最小化原则、偏差缓解和权重剪枝）上进行实验，相比流行的后处理或重新训练方法，在性能、需求满足和时间效率之间取得了更好的平衡。

Conclusion: 图元网络编辑方法能有效解决模型编辑问题，在保持性能的同时满足各种需求，为实际部署中的模型调整提供了高效解决方案。

Abstract: As machine learning models are increasingly deployed in high-stakes settings, e.g. as decision support systems in various societal sectors or in critical infrastructure, designers and auditors are facing the need to ensure that models satisfy a wider variety of requirements (e.g. compliance with regulations, fairness, computational constraints) beyond performance. Although most of them are the subject of ongoing studies, typical approaches face critical challenges: post-processing methods tend to compromise performance, which is often counteracted by fine-tuning or, worse, training from scratch, an often time-consuming or even unavailable strategy. This raises the following question: "Can we efficiently edit models to satisfy requirements, without sacrificing their utility?" In this work, we approach this with a unifying framework, in a data-driven manner, i.e. we learn to edit neural networks (NNs), where the editor is an NN itself - a graph metanetwork - and editing amounts to a single inference step. In particular, the metanetwork is trained on NN populations to minimise an objective consisting of two terms: the requirement to be enforced and the preservation of the NN's utility. We experiment with diverse tasks (the data minimisation principle, bias mitigation and weight pruning) improving the trade-offs between performance, requirement satisfaction and time efficiency compared to popular post-processing or re-training alternatives.

</details>


### [129] [Multi-stage Bayesian optimisation for dynamic decision-making in self-driving labs](https://arxiv.org/abs/2512.15483)
*Luca Torresi,Pascal Friederich*

Main category: cs.LG

TL;DR: 本文提出了一种贝叶斯优化的扩展方法，支持多阶段工作流和代理测量，显著提升了自动驾驶实验室的实验效率和优化效果。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶实验室中广泛使用的标准贝叶斯优化方法存在局限性：它依赖于固定的实验工作流程，无法在实验过程中根据中间测量结果动态调整实验计划。这导致许多真实世界的实验需要被简化和适应才能应用于自动驾驶实验室。

Method: 作者提出了一种贝叶斯优化的扩展方法，能够灵活采样多阶段工作流，并基于中间可观测的代理测量做出最优决策。该方法允许在实验过程中根据中间结果动态调整实验计划。

Result: 在广泛的应用场景中，考虑代理测量的方法相比仅观察最终测量的传统贝叶斯优化，在找到良好解决方案的时间和最终解决方案的最优性方面都带来了显著改进。

Conclusion: 该方法不仅为在自动驾驶实验室中使用更复杂、更真实的实验工作流程铺平了道路，也为下一代自动驾驶实验室中平滑结合模拟和实验提供了可能。

Abstract: Self-driving laboratories (SDLs) are combining recent technological advances in robotics, automation, and machine learning based data analysis and decision-making to perform autonomous experimentation toward human-directed goals without requiring any direct human intervention. SDLs are successfully used in materials science, chemistry, and beyond, to optimise processes, materials, and devices in a systematic and data-efficient way. At present, the most widely used algorithm to identify the most informative next experiment is Bayesian optimisation. While relatively simple to apply to a wide range of optimisation problems, standard Bayesian optimisation relies on a fixed experimental workflow with a clear set of optimisation parameters and one or more measurable objective functions. This excludes the possibility of making on-the-fly decisions about changes in the planned sequence of operations and including intermediate measurements in the decision-making process. Therefore, many real-world experiments need to be adapted and simplified to be converted to the common setting in self-driving labs. In this paper, we introduce an extension to Bayesian optimisation that allows flexible sampling of multi-stage workflows and makes optimal decisions based on intermediate observables, which we call proxy measurements. We systematically compare the advantage of taking into account proxy measurements over conventional Bayesian optimisation, in which only the final measurement is observed. We find that over a wide range of scenarios, proxy measurements yield a substantial improvement, both in the time to find good solutions and in the overall optimality of found solutions. This not only paves the way to use more complex and thus more realistic experimental workflows in autonomous labs but also to smoothly combine simulations and experiments in the next generation of SDLs.

</details>


### [130] [Robustness and uncertainty: two complementary aspects of the reliability of the predictions of a classifier](https://arxiv.org/abs/2512.15492)
*Adrián Detavernier,Jasper De Bock*

Main category: cs.LG

TL;DR: 本文比较了评估分类器个体预测可靠性的两种方法：鲁棒性量化(RQ)和不确定性量化(UQ)，发现两者互补，结合后的混合方法优于单独使用任一种方法。


<details>
  <summary>Details</summary>
Motivation: 评估分类器个体预测的可靠性对于实际应用至关重要，目前存在两种概念上不同的方法：鲁棒性量化(RQ)和不确定性量化(UQ)，但缺乏对这两种方法的系统比较和整合研究。

Method: 在多个基准数据集上系统比较RQ和UQ方法，分析它们的优缺点，并提出一种结合两者优势的混合方法。

Result: RQ和UQ没有明显的优劣之分，而是互补的；结合两者的混合方法在性能上优于单独使用RQ或UQ；同时还能评估每个数据集中不确定性和鲁棒性作为不可靠性来源的相对重要性。

Conclusion: RQ和UQ是评估分类器预测可靠性的互补方法，结合两者的混合方法提供了更优的可靠性评估方案，并能帮助理解不同数据集中不可靠性的主要来源。

Abstract: We consider two conceptually different approaches for assessing the reliability of the individual predictions of a classifier: Robustness Quantification (RQ) and Uncertainty Quantification (UQ). We compare both approaches on a number of benchmark datasets and show that there is no clear winner between the two, but that they are complementary and can be combined to obtain a hybrid approach that outperforms both RQ and UQ. As a byproduct of our approach, for each dataset, we also obtain an assessment of the relative importance of uncertainty and robustness as sources of unreliability.

</details>


### [131] [Soft Geometric Inductive Bias for Object Centric Dynamics](https://arxiv.org/abs/2512.15493)
*Hampus Linander,Conor Heins,Alexander Tschantz,Marco Perin,Christopher Buckley*

Main category: cs.LG

TL;DR: 提出使用几何代数神经网络构建物体中心世界模型，提供软几何归纳偏置，在2D刚体动力学环境中优于非等变基线模型


<details>
  <summary>Details</summary>
Motivation: 等变性是学习物理动力学的强大先验，但精确的群等变性在对称性被破坏时可能降低性能。需要一种软几何归纳偏置来平衡等变性和灵活性。

Method: 使用几何代数神经网络构建物体中心世界模型，在具有静态障碍物的2D刚体动力学模拟环境中训练，采用自回归方式进行下一步预测

Result: 在长时程推演中，模型的软归纳偏置在物理保真度方面优于非等变基线模型，几何代数在手工物理和无结构深度网络之间提供了有效中间地带

Conclusion: 几何代数提供了手工物理和无结构深度网络之间的有效折中方案，能够为多物体场景提供样本高效的动力学模型，简单而精心选择的先验可以产生鲁棒的泛化能力

Abstract: Equivariance is a powerful prior for learning physical dynamics, yet exact group equivariance can degrade performance if the symmetries are broken. We propose object-centric world models built with geometric algebra neural networks, providing a soft geometric inductive bias. Our models are evaluated using simulated environments of 2d rigid body dynamics with static obstacles, where we train for next-step predictions autoregressively. For long-horizon rollouts we show that the soft inductive bias of our models results in better performance in terms of physical fidelity compared to non-equivariant baseline models. The approach complements recent soft-equivariance ideas and aligns with the view that simple, well-chosen priors can yield robust generalization. These results suggest that geometric algebra offers an effective middle ground between hand-crafted physics and unstructured deep nets, delivering sample-efficient dynamics models for multi-object scenes.

</details>


### [132] [Tracking Temporal Dynamics of Vector Sets with Gaussian Process](https://arxiv.org/abs/2512.15538)
*Taichi Aida,Mamoru Komachi,Toshinobu Ogiso,Hiroya Takamura,Daichi Mochihashi*

Main category: cs.LG

TL;DR: 提出一种基于无限维高斯过程和随机傅里叶特征的方法，用于建模和分析随时间变化的向量集分布，能够捕捉跨领域（如犯罪分布、词嵌入）的时序动态变化。


<details>
  <summary>Details</summary>
Motivation: 许多领域（生态学、犯罪分析、语言学）都存在随时间演化的向量集，如生态系统结构、犯罪空间分布、词嵌入向量等。分析这些具有复杂结构且随时间变化的向量集具有挑战性。

Method: 使用无限维高斯过程建模每个向量集的底层分布，通过随机傅里叶特征近似高斯过程中的隐函数，获得紧凑且可比较的时序向量表示，从而在低维空间中跟踪和可视化向量集的时序变化。

Result: 方法在犯罪分布数据和词嵌入数据上验证有效，能够捕捉时序动态变化，提供可解释且稳健的表示。

Conclusion: 该方法为分析跨领域时序索引向量集的结构变化提供了一个强大框架，能够生成可解释的时序表示。

Abstract: Understanding the temporal evolution of sets of vectors is a fundamental challenge across various domains, including ecology, crime analysis, and linguistics. For instance, ecosystem structures evolve due to interactions among plants, herbivores, and carnivores; the spatial distribution of crimes shifts in response to societal changes; and word embedding vectors reflect cultural and semantic trends over time. However, analyzing such time-varying sets of vectors is challenging due to their complicated structures, which also evolve over time. In this work, we propose a novel method for modeling the distribution underlying each set of vectors using infinite-dimensional Gaussian processes. By approximating the latent function in the Gaussian process with Random Fourier Features, we obtain compact and comparable vector representations over time. This enables us to track and visualize temporal transitions of vector sets in a low-dimensional space. We apply our method to both sociological data (crime distributions) and linguistic data (word embeddings), demonstrating its effectiveness in capturing temporal dynamics. Our results show that the proposed approach provides interpretable and robust representations, offering a powerful framework for analyzing structural changes in temporally indexed vector sets across diverse domains.

</details>


### [133] [Joint Learning of Unsupervised Multi-view Feature and Instance Co-selection with Cross-view Imputation](https://arxiv.org/abs/2512.15574)
*Yuxin Cai,Yanyong Huang,Jinyuan Chang,Dongjie Wang,Tianrui Li,Xiaoyi Jiang*

Main category: cs.LG

TL;DR: 提出了一种名为JUICE的联合学习方法，用于处理未标记的不完整多视图数据，同时进行特征和实例协同选择与跨视图插补。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理不完整多视图数据时，通常先插补缺失数据，然后将所有视图拼接成单一数据集进行协同选择。这种策略将协同选择和缺失数据插补视为两个独立过程，忽略了它们之间的潜在相互作用。此外，简单合并多视图数据无法捕捉视图间的互补信息。

Method: JUICE方法首先利用可用观测重建不完整多视图数据，将缺失数据恢复与特征和实例协同选择统一在一个框架中。然后利用跨视图邻域信息学习样本间关系，在重建过程中进一步细化缺失值的插补，从而选择更具代表性的特征和实例。

Result: 大量实验表明，JUICE方法优于现有的最先进方法。

Conclusion: JUICE通过联合学习框架，有效解决了不完整多视图数据中特征和实例协同选择的问题，通过跨视图插补和协同选择的相互增强，提高了选择性能。

Abstract: Feature and instance co-selection, which aims to reduce both feature dimensionality and sample size by identifying the most informative features and instances, has attracted considerable attention in recent years. However, when dealing with unlabeled incomplete multi-view data, where some samples are missing in certain views, existing methods typically first impute the missing data and then concatenate all views into a single dataset for subsequent co-selection. Such a strategy treats co-selection and missing data imputation as two independent processes, overlooking potential interactions between them. The inter-sample relationships gleaned from co-selection can aid imputation, which in turn enhances co-selection performance. Additionally, simply merging multi-view data fails to capture the complementary information among views, ultimately limiting co-selection effectiveness. To address these issues, we propose a novel co-selection method, termed Joint learning of Unsupervised multI-view feature and instance Co-selection with cross-viEw imputation (JUICE). JUICE first reconstructs incomplete multi-view data using available observations, bringing missing data recovery and feature and instance co-selection together in a unified framework. Then, JUICE leverages cross-view neighborhood information to learn inter-sample relationships and further refine the imputation of missing values during reconstruction. This enables the selection of more representative features and instances. Extensive experiments demonstrate that JUICE outperforms state-of-the-art methods.

</details>


### [134] [Corrective Diffusion Language Models](https://arxiv.org/abs/2512.15596)
*Shuibai Zhang,Fred Zhangzhi Peng,Yiheng Zhang,Jin Pan,Grigorios G. Chrysos*

Main category: cs.LG

TL;DR: 本文提出一种针对扩散语言模型的校正导向后训练方法，通过显式监督可见错误标记来提升模型识别和修正错误的能力，在代码修订任务中显著优于传统掩码扩散模型。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型在结构上适合迭代错误修正，但标准掩码扩散语言模型训练无法可靠地诱导这种校正行为，因为模型常常无法识别完整输入中的不可靠标记，导致基于置信度的细化无效。

Method: 提出校正导向的后训练原则，显式监督可见的错误标记，使模型能够进行错误感知的置信度评估和针对性细化。同时引入代码修订基准（CRB）来评估错误定位和原地修正能力。

Result: 实验表明，采用所提方法训练的模型在校正场景中显著优于标准掩码扩散语言模型，同时也能提升纯补全性能。

Conclusion: 校正导向的后训练方法能有效增强扩散语言模型的错误识别和修正能力，为迭代错误校正提供了可行的解决方案。

Abstract: Diffusion language models are structurally well-suited for iterative error correction, as their non-causal denoising dynamics allow arbitrary positions in a sequence to be revised. However, standard masked diffusion language model (MDLM) training fails to reliably induce this behavior, as models often cannot identify unreliable tokens in a complete input, rendering confidence-guided refinement ineffective. We study corrective behavior in diffusion language models, defined as the ability to assign lower confidence to incorrect tokens and iteratively refine them while preserving correct content. We show that this capability is not induced by conventional masked diffusion objectives and propose a correction-oriented post-training principle that explicitly supervises visible incorrect tokens, enabling error-aware confidence and targeted refinement. To evaluate corrective behavior, we introduce the Code Revision Benchmark (CRB), a controllable and executable benchmark for assessing error localization and in-place correction. Experiments on code revision tasks and controlled settings demonstrate that models trained with our approach substantially outperform standard MDLMs in correction scenarios, while also improving pure completion performance. Our code is publicly available at https://github.com/zhangshuibai/CDLM.

</details>


### [135] [How Smoothing is N-simplicial Attention?](https://arxiv.org/abs/2512.15600)
*Alexandre Dussolle,Pietro Liò*

Main category: cs.LG

TL;DR: 提出N-单纯形注意力，从成对token相似性扩展到高阶交互，并适配RoPE位置编码，通过成本有效的单纯形选择机制管理复杂度，同时分析其平滑性特征。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如GATs或Transformers）虽然从纯MLP发展到可学习的图消息传递机制，但仅限于成对token交互。为了进一步扩展，需要引入更高阶的交互机制，同时管理由此增加的复杂度。

Method: 1. 提出N-单纯形注意力，将注意力机制从成对相似性扩展到高阶交互；2. 适配Rotary Position Embeddings (RoPE)；3. 引入成本有效的单纯形选择机制，让模型聚焦于任务敏感度更高的交互；4. 分析N-单纯形注意力的平滑性，推导Lipschitz上界并研究其过平滑现象。

Result: 论文提出了一个理论上更强大的注意力机制框架，能够捕捉更高阶的token交互，同时通过选择机制控制计算成本。分析表明，尽管扩展到了高阶交互，该机制仍然存在过平滑问题。

Conclusion: N-单纯形注意力为注意力机制提供了向高阶交互扩展的理论框架，通过单纯形选择机制平衡了表达能力和计算效率，但过平滑问题仍需进一步解决。

Abstract: Going from pure Multilayer Perceptron (MLP) to a learnable graph message-passing mechanism at each layer has been foundational to state-of-the-art results, despite the computational trade-off (e.g. GATs or Transformers). To go a step further, in this work, we introduce N-simplicial attention, going from pairwise token similarity to higher-order interactions, and adapt it for Rotary Position Embeddings (RoPE). To help manage the increased complexity, we propose a cost-effective simplex selection enabling the model to focus its computation load onto the more task-sensitive interactions. Beyond these core mechanisms, we study how smoothing N-simplicial attention is by deriving a Lipschitz upper-bound and by demonstrating that by itself it also suffers from over-smoothing, despite opening the attention message-passing to higher-order interactions.

</details>


### [136] [Autoregressive Language Models are Secretly Energy-Based Models: Insights into the Lookahead Capabilities of Next-Token Prediction](https://arxiv.org/abs/2512.15605)
*Mathieu Blondel,Michael E. Sander,Germain Vivier-Ardisson,Tianlin Liu,Vincent Roulet*

Main category: cs.LG

TL;DR: 该论文建立了自回归模型（ARMs）与能量模型（EBMs）之间的函数空间双射，揭示了它们在概率链式法则下的等价性，并分析了EBMs蒸馏到ARMs的理论误差界限。


<details>
  <summary>Details</summary>
Motivation: 虽然自回归模型是当前大语言模型的主流范式，但能量模型在训练后对齐中自然表征最优策略。论文旨在统一这两种模型类别，理解它们之间的关系，并解释自回归模型为何能进行前瞻规划。

Method: 以概率链式法则为起点，在函数空间中建立ARMs和EBMs之间的显式双射，将其与最大熵强化学习中的软贝尔曼方程联系起来。基于此双射推导监督学习的等价性，并提供EBMs蒸馏到ARMs的理论误差界限分析。

Result: 建立了ARMs和EBMs之间的函数空间双射关系，证明了监督学习的等价性，提供了蒸馏过程的理论误差界限，为理解ARMs的前瞻规划能力提供了理论依据。

Conclusion: 论文通过建立ARMs和EBMs的统一框架，揭示了它们之间的深刻联系，解释了自回归模型基于下一词预测范式却能进行前瞻规划的能力，为模型设计和分析提供了新的理论视角。

Abstract: Autoregressive models (ARMs) currently constitute the dominant paradigm for large language models (LLMs). Energy-based models (EBMs) represent another class of models, which have historically been less prevalent in LLM development, yet naturally characterize the optimal policy in post-training alignment. In this paper, we provide a unified view of these two model classes. Taking the chain rule of probability as a starting point, we establish an explicit bijection between ARMs and EBMs in function space, which we show to correspond to a special case of the soft Bellman equation in maximum entropy reinforcement learning. Building upon this bijection, we derive the equivalence between supervised learning of ARMs and EBMs. Furthermore, we analyze the distillation of EBMs into ARMs by providing theoretical error bounds. Our results provide insights into the ability of ARMs to plan ahead, despite being based on the next-token prediction paradigm.

</details>


### [137] [Behavior Tokens Speak Louder: Disentangled Explainable Recommendation with Behavior Vocabulary](https://arxiv.org/abs/2512.15614)
*Xinshun Feng,Mingzhe Liu,Yi Qiao,Tongyu Zhu,Leilei Sun,Shuai Wang*

Main category: cs.LG

TL;DR: BEAT是一个统一可迁移的推荐框架，通过将用户和物品行为token化为离散可解释序列，并利用向量量化自编码构建行为词汇表，从而在冻结语言模型中实现零样本推荐和解释生成。


<details>
  <summary>Details</summary>
Motivation: 现有可解释推荐方法通常依赖ID表示，这模糊了语义含义并对语言模型施加结构约束，限制了在开放场景中的适用性。真实世界交互的复杂性（用户意图纠缠、协作信号与语言语义不对齐）加剧了这些挑战。

Method: 提出BEAT框架：1) 将用户和物品行为token化为离散可解释序列；2) 通过向量量化自编码构建行为词汇表，从图表示中解耦宏观兴趣和微观意图；3) 引入多级语义监督桥接行为信号与语言空间；4) 设计语义对齐正则化机制，将行为token直接嵌入冻结语言模型的输入空间。

Result: 在三个公共数据集上的实验表明，BEAT提高了零样本推荐性能，同时生成连贯且信息丰富的解释。进一步分析显示，行为token捕获了细粒度语义，并为将复杂行为模式集成到大型语言模型提供了即插即用接口。

Conclusion: BEAT通过将行为token化为离散序列并嵌入语言模型，克服了现有可解释推荐方法的局限性，实现了更好的零样本推荐性能和解释生成能力，为复杂行为模式与语言模型的集成提供了有效解决方案。

Abstract: Recent advances in explainable recommendations have explored the integration of language models to analyze natural language rationales for user-item interactions. Despite their potential, existing methods often rely on ID-based representations that obscure semantic meaning and impose structural constraints on language models, thereby limiting their applicability in open-ended scenarios. These challenges are intensified by the complex nature of real-world interactions, where diverse user intents are entangled and collaborative signals rarely align with linguistic semantics. To overcome these limitations, we propose BEAT, a unified and transferable framework that tokenizes user and item behaviors into discrete, interpretable sequences. We construct a behavior vocabulary via a vector-quantized autoencoding process that disentangles macro-level interests and micro-level intentions from graph-based representations. We then introduce multi-level semantic supervision to bridge the gap between behavioral signals and language space. A semantic alignment regularization mechanism is designed to embed behavior tokens directly into the input space of frozen language models. Experiments on three public datasets show that BEAT improves zero-shot recommendation performance while generating coherent and informative explanations. Further analysis demonstrates that our behavior tokens capture fine-grained semantics and offer a plug-and-play interface for integrating complex behavior patterns into large language models.

</details>


### [138] [SoFlow: Solution Flow Models for One-Step Generative Modeling](https://arxiv.org/abs/2512.15657)
*Tianze Luo,Haotian Yuan,Zhuang Liu*

Main category: cs.LG

TL;DR: SoFlow是一种用于一步生成的新框架，通过分析速度函数与解函数的关系，提出Flow Matching损失和解一致性损失来训练模型，无需计算Jacobian-vector product，在ImageNet 256×256上优于MeanFlow。


<details>
  <summary>Details</summary>
Motivation: 扩散模型和Flow Matching模型的多步去噪过程存在效率问题，这促使研究者探索少步生成方法。本文旨在开发一种能够从零开始进行一步生成的框架。

Method: 提出Solution Flow Models (SoFlow)框架，通过分析速度ODE中速度函数与解函数的关系，设计了两种损失函数：Flow Matching损失（用于训练并提供CFG所需的估计速度场）和解一致性损失（无需计算JVP，避免了深度学习框架中的优化问题）。使用与DiT相同的架构进行训练。

Result: 在ImageNet 256×256数据集上，使用相同DiT架构和相同训练轮数从头训练时，SoFlow模型比MeanFlow模型获得了更好的FID-50K分数。

Conclusion: SoFlow框架成功实现了一步生成，通过创新的损失函数设计避免了JVP计算，在图像生成质量上超越了现有方法，为高效生成模型提供了新思路。

Abstract: The multi-step denoising process in diffusion and Flow Matching models causes major efficiency issues, which motivates research on few-step generation. We present Solution Flow Models (SoFlow), a framework for one-step generation from scratch. By analyzing the relationship between the velocity function and the solution function of the velocity ordinary differential equation (ODE), we propose a Flow Matching loss and a solution consistency loss to train our models. The Flow Matching loss allows our models to provide estimated velocity fields for Classifier-Free Guidance (CFG) during training, which improves generation performance. Notably, our consistency loss does not require the calculation of the Jacobian-vector product (JVP), a common requirement in recent works that is not well-optimized in deep learning frameworks like PyTorch. Experimental results indicate that, when trained from scratch using the same Diffusion Transformer (DiT) architecture and an equal number of training epochs, our models achieve better FID-50K scores than MeanFlow models on the ImageNet 256x256 dataset.

</details>


### [139] [A Multivariate Statistical Framework for Detection, Classification and Pre-localization of Anomalies in Water Distribution Networks](https://arxiv.org/abs/2512.15685)
*Oleg Melnikov,Yurii Dorofieiev,Yurii Shakhnovskiy,Huy Truong,Victoria Degeler*

Main category: cs.LG

TL;DR: SICAMS框架使用多元统计分析检测、分类和初步定位供水管网异常，无需校准水力模型，在BattLeDIM L-Town数据集上表现出高灵敏度和可靠性。


<details>
  <summary>Details</summary>
Motivation: 供水管网中的异常（如泄漏和传感器故障）检测和定位对水资源管理和减少损失至关重要。传统方法通常需要校准的水力模型，限制了实际应用。需要一种无需模型校准、能处理异质传感器数据的统一框架。

Method: 提出SICAMS框架：1) 对压力和流量传感器数据进行白化变换消除空间相关性；2) 构建Hotelling's T²统计量作为系统健康指标；3) 通过假设检验检测异常；4) 开发启发式算法分析T²时间序列，将异常分类为突发泄漏、渐进泄漏和传感器故障；5) 提出基于传感器统计贡献排序和拉普拉斯插值的粗定位方法。

Result: 在BattLeDIM L-Town基准数据集上验证，表现出高灵敏度和可靠的泄漏检测能力，即使在多重泄漏情况下也能保持鲁棒性能。T²统计量与总泄漏量相关，可通过回归模型近似估计水损失。

Conclusion: SICAMS框架为供水管网异常检测、分类和初步定位提供了有效的统计方法，无需校准水力模型，适用于实际运行环境，具有实际应用价值。

Abstract: This paper presents a unified framework, for the detection, classification, and preliminary localization of anomalies in water distribution networks using multivariate statistical analysis. The approach, termed SICAMS (Statistical Identification and Classification of Anomalies in Mahalanobis Space), processes heterogeneous pressure and flow sensor data through a whitening transformation to eliminate spatial correlations among measurements. Based on the transformed data, the Hotelling's $T^2$ statistic is constructed, enabling the formulation of anomaly detection as a statistical hypothesis test of network conformity to normal operating conditions. It is shown that Hotelling's $T^2$ statistic can serve as an integral indicator of the overall "health" of the system, exhibiting correlation with total leakage volume, and thereby enabling approximate estimation of water losses via a regression model. A heuristic algorithm is developed to analyze the $T^2$ time series and classify detected anomalies into abrupt leaks, incipient leaks, and sensor malfunctions. Furthermore, a coarse leak localization method is proposed, which ranks sensors according to their statistical contribution and employs Laplacian interpolation to approximate the affected region within the network. Application of the proposed framework to the BattLeDIM L-Town benchmark dataset demonstrates high sensitivity and reliability in leak detection, maintaining robust performance even under multiple leaks. These capabilities make the method applicable to real-world operational environments without the need for a calibrated hydraulic model.

</details>


### [140] [Can LLMs Guide Their Own Exploration? Gradient-Guided Reinforcement Learning for LLM Reasoning](https://arxiv.org/abs/2512.15687)
*Zhenwen Liang,Sidi Lu,Wenhao Yu,Kishan Panaganti,Yujun Zhou,Haitao Mi,Dong Yu*

Main category: cs.LG

TL;DR: G2RL提出基于梯度几何的强化学习框架，用模型自身的梯度方向指导探索，而非传统的外部启发式方法，在数学推理任务上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习探索机制（如熵奖励、外部语义比较器）与大型语言模型实际学习方式不匹配，仅鼓励表面变化而不能保证采样轨迹在优化方向上产生差异。

Method: G2RL框架：从模型最终层敏感度构建序列级特征（标准前向传播即可获得），在采样组内比较这些特征来衡量每个轨迹如何重塑策略。引入新颖梯度方向的轨迹获得有界乘法奖励缩放，冗余或离流形更新被弱化。

Result: 在MATH500、AMC、AIME24、AIME25、GPQA、MMLUpro等数学和通用推理基准上，Qwen3基础1.7B和4B模型的pass@1、maj@16、pass@k指标均优于基于熵的GRPO和外部嵌入方法。

Conclusion: G2RL将探索扩展到更多正交且常相反的梯度方向，同时保持语义连贯性，表明策略自身的更新空间为大型语言模型强化学习探索提供了更忠实有效的基础。

Abstract: Reinforcement learning has become essential for strengthening the reasoning abilities of large language models, yet current exploration mechanisms remain fundamentally misaligned with how these models actually learn. Entropy bonuses and external semantic comparators encourage surface level variation but offer no guarantee that sampled trajectories differ in the update directions that shape optimization. We propose G2RL, a gradient guided reinforcement learning framework in which exploration is driven not by external heuristics but by the model own first order update geometry. For each response, G2RL constructs a sequence level feature from the model final layer sensitivity, obtainable at negligible cost from a standard forward pass, and measures how each trajectory would reshape the policy by comparing these features within a sampled group. Trajectories that introduce novel gradient directions receive a bounded multiplicative reward scaler, while redundant or off manifold updates are deemphasized, yielding a self referential exploration signal that is naturally aligned with PPO style stability and KL control. Across math and general reasoning benchmarks (MATH500, AMC, AIME24, AIME25, GPQA, MMLUpro) on Qwen3 base 1.7B and 4B models, G2RL consistently improves pass@1, maj@16, and pass@k over entropy based GRPO and external embedding methods. Analyzing the induced geometry, we find that G2RL expands exploration into substantially more orthogonal and often opposing gradient directions while maintaining semantic coherence, revealing that a policy own update space provides a far more faithful and effective basis for guiding exploration in large language model reinforcement learning.

</details>


### [141] [Multi-Modal Semantic Communication](https://arxiv.org/abs/2512.15691)
*Matin Mortaheb,Erciyes Karakaya,Sennur Ulukus*

Main category: cs.LG

TL;DR: 提出多模态语义通信框架，通过文本查询引导视觉信息提取，使用跨模态注意力机制和自适应分辨率传输，在带宽受限环境中实现高效语义通信。


<details>
  <summary>Details</summary>
Motivation: 传统基于transformer的语义通信方法在复杂多目标场景中表现不佳，因为自注意力机制缺乏明确的任务指导。需要一种能够结合用户意图来指导信息提取的框架。

Method: 1) 提出多模态语义通信框架，整合文本查询指导信息提取；2) 使用跨模态注意力机制融合视觉特征和语言嵌入，生成软相关性分数；3) 基于分数和瞬时带宽，采用自适应分辨率传输图像块；4) 使用独立训练的编码器-解码器对，总比特率匹配信道容量。

Result: 提出的框架能够在复杂场景中有效提取任务关键信息，实现带宽受限环境下的高效语义通信。系统具有灵活性和目标驱动特性。

Conclusion: 通过整合文本查询指导视觉信息提取，提出的多模态语义通信框架解决了复杂场景中自注意力缺乏任务指导的问题，实现了高效、灵活的语义通信系统。

Abstract: Semantic communication aims to transmit information most relevant to a task rather than raw data, offering significant gains in communication efficiency for applications such as telepresence, augmented reality, and remote sensing. Recent transformer-based approaches have used self-attention maps to identify informative regions within images, but they often struggle in complex scenes with multiple objects, where self-attention lacks explicit task guidance. To address this, we propose a novel Multi-Modal Semantic Communication framework that integrates text-based user queries to guide the information extraction process. Our proposed system employs a cross-modal attention mechanism that fuses visual features with language embeddings to produce soft relevance scores over the visual data. Based on these scores and the instantaneous channel bandwidth, we use an algorithm to transmit image patches at adaptive resolutions using independently trained encoder-decoder pairs, with total bitrate matching the channel capacity. At the receiver, the patches are reconstructed and combined to preserve task-critical information. This flexible and goal-driven design enables efficient semantic communication in complex and bandwidth-constrained environments.

</details>


### [142] [FrontierCS: Evolving Challenges for Evolving Intelligence](https://arxiv.org/abs/2512.15699)
*Qiuyang Mang,Wenhao Chai,Zhifei Li,Huanzhi Mao,Shang Zhou,Alexander Du,Hanchen Li,Shu Liu,Edwin Chen,Yichuan Wang,Xieting Chu,Zerui Cheng,Yuan Xu,Tian Xia,Zirui Wang,Tianneng Shi,Jianzhu Yao,Yilong Zhao,Qizheng Zhang,Charlie Ruan,Zeyu Shen,Kaiyuan Liu,Runyuan He,Dong Xing,Zerui Li,Zirong Zeng,Yige Jiang,Lufeng Cheng,Ziyi Zhao,Youran Sun,Wesley Zheng,Meiyuwang Zhang,Ruyi Ji,Xuechang Tu,Zihan Zheng,Zexing Chen,Kangyang Zhou,Zhaozi Wang,Jingbang Chen,Aleksandra Korolova,Peter Henderson,Pramod Viswanath,Vijay Ganesh,Saining Xie,Zhuang Liu,Dawn Song,Sewon Min,Ion Stoica,Joseph E. Gonzalez,Jingbo Shang,Alvin Cheung*

Main category: cs.LG

TL;DR: FrontierCS是一个包含156个开放式计算机科学问题的基准测试，这些问题由专家设计，针对未知最优解但可客观评估质量的任务，要求模型生成可执行程序而非直接答案。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注已知最优解的任务，缺乏针对计算机科学前沿开放式问题的评估标准，需要能够衡量模型在未知最优解但可客观评估质量的问题上的表现。

Method: 创建包含算法问题和研究问题的基准测试，每个问题提供专家参考解决方案和自动评估器。问题涵盖NP-hard变体的竞争编程问题和具有客观部分评分的研究问题，要求模型生成可执行程序。

Result: 前沿推理模型在算法和研究赛道上仍远落后于人类专家；仅增加推理预算无法缩小这一差距；模型往往过度优化生成仅能工作的代码，而非发现高质量算法和系统设计。

Conclusion: FrontierCS提供了一个处于计算机科学难度前沿的基准测试，结合开放式设计、可测量进展和专家策划，揭示了当前模型在解决复杂计算机科学问题上的局限性。

Abstract: We introduce FrontierCS, a benchmark of 156 open-ended problems across diverse areas of computer science, designed and reviewed by experts, including CS PhDs and top-tier competitive programming participants and problem setters. Unlike existing benchmarks that focus on tasks with known optimal solutions, FrontierCS targets problems where the optimal solution is unknown, but the quality of a solution can be objectively evaluated. Models solve these tasks by implementing executable programs rather than outputting a direct answer. FrontierCS includes algorithmic problems, which are often NP-hard variants of competitive programming problems with objective partial scoring, and research problems with the same property. For each problem we provide an expert reference solution and an automatic evaluator. Combining open-ended design, measurable progress, and expert curation, FrontierCS provides a benchmark at the frontier of computer-science difficulty. Empirically, we find that frontier reasoning models still lag far behind human experts on both the algorithmic and research tracks, that increasing reasoning budgets alone does not close this gap, and that models often over-optimize for generating merely workable code instead of discovering high-quality algorithms and system designs.

</details>


### [143] [Learning Model Parameter Dynamics in a Combination Therapy for Bladder Cancer from Sparse Biological Data](https://arxiv.org/abs/2512.15706)
*Kayode Olumoyin,Lamees El Naqa,Katarzyna Rejniak*

Main category: cs.LG

TL;DR: 使用物理信息神经网络（PINN）学习膀胱癌肿瘤与免疫细胞间随时间变化的相互作用，预测稀疏数据下的亚群轨迹，为外部干预下的生物系统动态建模提供框架。


<details>
  <summary>Details</summary>
Motivation: 传统固定参数模型无法捕捉生物系统随时间变化的动态，特别是在肿瘤学中，实验数据稀疏且时间点有限，需要新方法来学习外部干预下的演化相互作用。

Method: 采用物理信息神经网络（PINN）方法，在有限数据场景下学习膀胱癌肿瘤与免疫细胞间的时间变化相互作用，预测未观测时间点的亚群轨迹。

Result: 方法能够预测亚群轨迹，且与生物学解释一致，为学习外部干预下生物系统演化相互作用提供了有效框架。

Conclusion: PINN方法能够有效处理稀疏数据，学习生物系统在外部干预下的时间变化相互作用，为肿瘤学等领域的动态建模提供了新工具。

Abstract: In a mathematical model of interacting biological organisms, where external interventions may alter behavior over time, traditional models that assume fixed parameters usually do not capture the evolving dynamics. In oncology, this is further exacerbated by the fact that experimental data are often sparse and sometimes are composed of a few time points of tumor volume. In this paper, we propose to learn time-varying interactions between cells, such as those of bladder cancer tumors and immune cells, and their response to a combination of anticancer treatments in a limited data scenario. We employ the physics-informed neural network (PINN) approach to predict possible subpopulation trajectories at time points where no observed data are available. We demonstrate that our approach is consistent with the biological explanation of subpopulation trajectories. Our method provides a framework for learning evolving interactions among biological organisms when external interventions are applied to their environment.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [144] [Achromatic, spin-odd Kerr EVPA as a null Frenet--Serret torsion integral on the photon ring](https://arxiv.org/abs/2512.14773)
*M. Baran Ökten*

Main category: gr-qc

TL;DR: 计算克尔时空在光子环上对线偏振的消色差引力印记，提出用于探测黑洞自旋和倾角的偏振测量方法。


<details>
  <summary>Details</summary>
Motivation: 研究克尔黑洞时空对偏振光子的引力效应，特别是光子环上的偏振方向变化，为通过毫米/亚毫米偏振观测探测黑洞自旋和倾角提供理论框架。

Method: 使用零Frenet-Serret框架重新表述平行输运，得到电场矢量位置角的标量演化方程；采用反向射线追踪、Carter分离测地线和中点RK2输运方法；通过三种独立构造验证结果一致性。

Result: 在观测者屏幕上，克尔与史瓦西时空的偏振差异模式非零，在自旋反转下严格奇对称，局限于薄环区域；振幅随自旋和倾角单调增长（RMS约0.5-2度）；开发出奇宇称环估计器，压缩为低方位角模式。

Conclusion: 建立了包含自旋和倾角两个参数的最小模板，可用于M87*和Sgr A*等源的视界尺度环偏振测量，能够探测框架拖曳引起的强场平行输运相位或提供有意义的限制。

Abstract: We compute the achromatic gravitational imprint that Kerr spacetime leaves on linear polarization at the photon ring. Recasting parallel transport in a null Frenet--Serret frame yields a single scalar evolution law for the electric-vector position angle. On the observer's screen, the Kerr-minus-Schwarzschild pattern on the direct critical curve is nonzero, strictly odd under spin reversal after a half-turn azimuth relabelling, and tightly confined to a thin annulus. Using backward-shot, Carter-separated geodesics with midpoint RK2 transport, we achieve second-order convergence and degree-scale amplitudes that grow monotonically with spin and inclination (RMS $\simeq 0.5$--$2^\circ$ for $a/M\gtrsim 0.8$, $i\gtrsim 60^\circ$). Three independent constructions -- Frenet--Serret line integral, explicit Levi--Civita transport of the polarization vector, and the phase of the Walker--Penrose constant -- agree ray by ray. We then define a parity-odd ring estimator that is intrinsically achromatic after standard wavelength-squared regression, symmetry-protected against common even-parity systematics, and compressed into low azimuthal modes. This yields a minimal two-parameter template (spin and inclination) for mm/sub-mm polarimetry of horizon-scale rings in sources such as M87$^\ast$ and Sgr~A$^\ast$. The pipeline enables either a detection of the strong-field parallel-transport phase induced by frame dragging or informative upper limits.

</details>


### [145] [Analytical model of the photon ring with finite thickness](https://arxiv.org/abs/2512.14775)
*S. V. Chernov*

Main category: gr-qc

TL;DR: 提出厚非对称高斯环的解析模型，计算了地球直径6倍基线内两个垂直方向的可见度函数


<details>
  <summary>Details</summary>
Motivation: 需要建立厚非对称高斯环的解析模型，以分析其在长基线干涉测量中的可见度特性

Method: 开发厚非对称高斯环的解析模型，计算两个垂直方向上地球直径6倍基线范围内的可见度函数

Result: 获得了厚非对称高斯环的解析模型，并计算了其在两个垂直方向上的可见度函数，适用于长达地球直径6倍的基线

Conclusion: 成功建立了厚非对称高斯环的解析模型，为分析此类结构在长基线干涉测量中的观测特性提供了理论基础

Abstract: An analytical model of a thick asymmetric Gaussian ring is presented for which the visibility function is calculated in two perpendicular directions for baselines up to 6 of the Earth's diameter.

</details>


### [146] [Gravitational decoupling and regular hairy black holes: Geodesic stability, quasinormal modes, and thermodynamic properties](https://arxiv.org/abs/2512.14920)
*R. C. de Paiva,K. S. Alves,R. T. Cavalcanti,R. da Rocha*

Main category: gr-qc

TL;DR: 研究引力解耦框架下规则毛状黑洞周围测地轨道的稳定性，使用李雅普诺夫指数分析轨道稳定性，探讨毛参数对轨道的影响，并计算准正规模和热力学性质。


<details>
  <summary>Details</summary>
Motivation: 研究规则毛状黑洞在引力解耦框架下的轨道稳定性，探索毛参数对测地轨道的影响，寻找可能的观测特征，并深入理解强场区域中的引力动力学。

Method: 使用李雅普诺夫指数量化动力学系统中邻近轨迹的发散率，分析类时和零测地线，计算准正规模，并研究热力学性质包括Rényi熵和Bekenstein-Hawking熵。

Result: 与史瓦西解相比，毛参数对轨道稳定性有显著影响，可能提供观测特征；计算了准正规模并讨论了热力学性质，深化了对强场区域引力动力学的理解。

Conclusion: 规则毛状黑洞在引力解耦框架下的轨道稳定性受毛参数显著影响，这些研究为修改引力理论提供了重要见解，并可能通过观测特征验证理论预测。

Abstract: The stability of geodesic orbits around a regular hairy black hole, in the gravitational decoupling setup, is investigated by employing Lyapunov exponents, which quantify the divergence rate of nearby trajectories in dynamical systems. Both timelike and null geodesics are addressed, probing the effect of the hair parameter on orbital stability. Deviations from the Schwarzschild solution have a significant influence on orbit stability, potentially providing observational signatures. Quasinormal modes of regular hairy black holes are calculated, and their thermodynamic properties are discussed. Both the Rényi and the Bekenstein-Hawking entropies are reported, deepening our understanding of gravitational dynamics in the strong-field regime, contributing to ongoing approaches to modified gravity.

</details>


### [147] [$\ell$-Boson stars in anti-de Sitter spacetime](https://arxiv.org/abs/2512.14921)
*Miguel Megevand*

Main category: gr-qc

TL;DR: 研究带负宇宙常数的ℓ-玻色星，推广了标准玻色星模型，在渐近反德西特时空中保持球对称性


<details>
  <summary>Details</summary>
Motivation: 将之前提出的ℓ-玻色星模型扩展到具有负宇宙常数的时空，研究在渐近反德西特背景下的性质

Method: 推广ℓ-玻色星模型到负宇宙常数时空，保持角动量数ℓ参数化，同时维持时空的球对称性

Result: 建立了渐近反德西特时空中ℓ-玻色星的数学模型，并研究了其基本性质

Conclusion: 成功将ℓ-玻色星扩展到负宇宙常数背景，为研究反德西特时空中的玻色星结构提供了理论框架

Abstract: In previous work, we introduced the $\ell$-boson stars, a generalization of standard boson stars, which are parameterized by an angular momentum number $\ell$, while still preserving the spacetime's spherical symmetry. In this article, we present and study the properties of $\ell$-boson stars in spacetimes with a negative cosmological constant, such that they are asymptotically anti-de Sitter.

</details>


### [148] [Axions, Black Holes and the Detection of Gravitons: from Astrophysics to Cosmology](https://arxiv.org/abs/2512.14951)
*Nick E. Mavromatos,Panagiotis Dorlis,Sarben Sarkar,Sotirios-Neilos Vlachos*

Main category: gr-qc

TL;DR: 黑洞超辐射轴子云产生自旋极化纠缠压缩引力子态，可通过引力波干涉仪直接探测，或在宇宙学中通过原初引力波间接探测。


<details>
  <summary>Details</summary>
Motivation: 探索旋转黑洞周围超辐射轴子云产生的纠缠压缩引力子态，为量子引力效应提供可观测的物理现象，并连接早期宇宙的量子引力效应与当前宇宙学观测。

Method: 结合广义相对论型轴子-引力相互作用和引力Chern-Simons异常项，在弱量子引力框架下分析旋转黑洞周围轴子云产生的纠缠压缩引力子态，估计压缩参数。

Result: 两种相互作用对纠缠压缩态有不同对称性贡献；LIGO/Virgo数据可对压缩参数和轴子云寿命给出上限约束；原初宇宙手征量子引力波扰动可能导致gCS项凝聚，产生运行真空型暴胀。

Conclusion: 旋转黑洞轴子云产生的纠缠压缩引力子态为量子引力效应提供了直接和间接探测途径，连接了天体物理、引力波观测和宇宙学，有望缓解当前宇宙学张力。

Abstract: We review a novel scenario for the emergence of spin-polarisation entangled squeezed graviton states from superradiant axionic clouds in the neighborhood of astrophysical rotating black holes (BHs). The entangled squeezed graviton states are produced by both, conventional General-Relativity (GR) type axion-gravity interactions, and gravitational Chern-Simons (gCS) anomalous terms coupled to axions, which are non-trivial in the presence of rotating BHs. The two kinds of terms have different-symmetry contributions to the entangled squeezed states. The squeezing parameter is estimated in a weak-quantum-gravity framework. Some phenomenology with respect to current and future interferometric detection devices is discussed. Importantly, current data from LIGO/Virgo Experiments can impose upper-bound constraints on the value of the squeezing parameter and, thus, on the lifetime of the axionic clouds. In addition to the above rather direct-detection possibility of squeezed gravitons, there is also the possibility of indirect detection of quantum gravitons in Cosmology, given that chiral quantum gravitational-wave (GW) perturbations in the primordial Universe may imply condensation of gCS terms. This, in turn, leads to inflation of running vacuum type, with in principle observable patterns in the profile of the GW produced during the post-inflationary early radiation era, as well as the potential of alleviating cosmic tensions in the current era.

</details>


### [149] [Cosmological Models with Symmetric Teleparallel Gravity and its Extension](https://arxiv.org/abs/2512.15096)
*S. A. Narawade*

Main category: gr-qc

TL;DR: 该论文研究使用修正引力理论f(Q)重力解释宇宙晚期加速膨胀，作为ΛCDM模型的替代方案，通过观测数据约束模型参数并比较性能。


<details>
  <summary>Details</summary>
Motivation: 标准ΛCDM模型存在暗物质和暗能量本质未解、与某些观测数据不一致等问题，需要探索修正引力理论作为替代解释宇宙加速膨胀。

Method: 采用f(Q)修正引力理论，利用Ia型超新星、哈勃参数等观测数据，通过马尔可夫链蒙特卡洛(MCMC)分析约束模型参数。

Result: 通过观测数据成功约束了f(Q)重力模型的参数，并与ΛCDM模型进行了比较评估。

Conclusion: f(Q)重力理论作为ΛCDM的可行替代方案，能够解释宇宙晚期加速膨胀，避免了常数宇宙学项的需要。

Abstract: This thesis investigates late-time cosmic acceleration using modified gravity theories with a focus on $f(Q)$ gravity, as an alternative to the $Λ$CDM model. The standard cosmological model attributes the acceleration to a cosmological constant, but it faces issues like the unexplained nature of dark matter and dark energy and discrepancies with certain observations. Modified gravity including $f(Q)$ gravity, offers a potential solution by incorporating dynamic dark energy or changes to gravitational interactions, avoiding the need for a constant cosmological term. Also, thesis evaluates the viability of $f(Q)$ gravity by analyzing observational data from Type Ia Supernovae, Hubble parameter measurements and other cosmological datasets. Using statistical tools like Markov Chain Monte Carlo (MCMC) analysis, this work constrains the parameters of $f(Q)$ gravity and compares it to the $Λ$CDM model.....

</details>


### [150] [Strong lensing cosmography using binary-black-hole mergers: Prospects for the near future](https://arxiv.org/abs/2512.15168)
*Koustav N. Maity,Souvik Jana,Tejaswi Venumadhav,Ankur Barsode,Parameswaran Ajith*

Main category: gr-qc

TL;DR: 该论文探讨利用升级版LIGO-Virgo-KAGRA网络探测到的引力波强透镜事件进行宇宙学参数约束的可能性，考虑了之前被忽略的探测器网络选择效应。


<details>
  <summary>Details</summary>
Motivation: 先前研究提出利用下一代探测器探测的强透镜引力波事件约束宇宙学参数，但忽略了探测器网络选择效应。本研究旨在探索升级版LVK网络是否也能进行透镜宇宙学测量，并考虑选择效应的影响。

Method: 通过分析升级版LVK探测器网络预期探测到的数十个强透镜引力波事件，结合探测器网络选择效应，研究透镜事件数量和时延分布对宇宙学参数的约束能力。

Result: 升级版LVK网络有望探测到数十个强透镜引力波事件，即使数量相对有限，也能对宇宙学参数提供适度约束。对于下一代探测器，修正后的预测与忽略选择效应的先前预测一致。

Conclusion: 强透镜引力波宇宙学在升级版LVK网络中具有可行性，即使透镜事件数量有限也能提供有价值的宇宙学约束，为引力波宇宙学开辟了新途径。

Abstract: A small fraction of gravitational-wave (GW) signals from binary black holes (BBHs) will be gravitationally lensed by intervening galaxies and galaxy clusters. Strong lensing will produce multiple identical copies of the GW signal arriving at different times. Jana et al.~\cite{Jana_2023} recently proposed a method to constrain cosmological parameters using strongly lensed GW events detected by next-generation (XG) detectors. The idea is that the number of strongly lensed GW events and the distribution of their lensing time delays encode imprints of the cosmological parameters. From the observed number of lensed GW events (tens of thousands) and their time delay distribution, this method can provide a new probe of cosmology, obtaining information at intermediate redshifts. In this work, we explore the possibility of doing lensing cosmography using upcoming observations of the upgraded LIGO-Virgo-KAGRA (LVK) network. This requires incorporating the detector network selection effects in the analysis, which was neglected earlier. We expect dozens of lensed GW events to be detected by upgraded LVK detectors, potentially enabling modest constraints on cosmological parameters. Even with relatively modest numbers of lensed detections, we demonstrate the potential of lensing cosmography. For XG detectors, our revised forecasts are consistent with with the earlier forecasts that neglected the selection effects.

</details>


### [151] [Multiple mountains on a pulsar: implications for gravitational waves and the spin-down rate](https://arxiv.org/abs/2512.15200)
*Paritosh Verma,Sudip Bhattacharyya*

Main category: gr-qc

TL;DR: 该论文研究具有多个"山脉"（不规则质量分布）的脉冲星如何通过Brans-Dicke引力理论发射连续引力波，包括应变、功率、扭矩和自旋减慢率的计算。


<details>
  <summary>Details</summary>
Motivation: 传统上估计脉冲星连续引力波时通常考虑整体恒星椭率，但实际可能存在多个由星壳支撑的不规则质量分布（山脉）。这些未被恒星引力平滑的多个山脉会产生更复杂的引力波信号，对研究引力物理和极端中子星物理具有重要意义。

Method: 采用Brans-Dicke引力理论（包含两个张量极化态和一个标量极化态），考虑天文上合理的山脉分布，计算多个山脉支撑的星壳产生的应变、功率、扭矩和脉冲星自旋减慢率，并给出广义相对论下的极限结果。

Result: 计算了具有多个山脉的脉冲星在Brans-Dicke理论下发射的连续引力波特性，包括详细的应变、功率、扭矩和自旋减慢率表达式，为实际观测提供了更现实的模型。

Conclusion: 多个山脉的脉冲星会产生比传统椭率模型更复杂的连续引力波信号，Brans-Dicke理论提供了包含标量极化的完整描述，这些结果对于未来连续引力波探测和极端中子星物理研究具有重要价值。

Abstract: A pulsar, i.e., a spinning neutron star, with a deformation could emit gravitational waves continuously. Such continuous waves, which have not been detected yet, will be very useful to study gravitational physics and to probe the extreme physics of neutron stars. While typically such waves from a pulsar are estimated considering an overall stellar ellipticity, there can be multiple irregularities or mountains in the stellar crust that the gravity of the star cannot smooth. In this paper, we consider this realistic situation and compute the strain, power, torque and the pulsar spin-down rate due to multiple mountains supported by the stellar crust. Here, we consider astronomically motivated mountain distributions and use the Brans-Dicke theory of gravity which has three polarization states: two tensors dominated by the time-varying quadrupole moment and one scalar dominated by the time-varying dipole moment. We also give the limiting results for general relativity.

</details>


### [152] [A bigravity model from noncommutative geometry](https://arxiv.org/abs/2512.15234)
*Marco de Cesare,Mairi Sakellariadou,Araceli Soler Oficial*

Main category: gr-qc

TL;DR: 非对易引力理论通过扭转变形扩展了广义相对论，引入了额外的引力自由度，在可交换极限下表现为类似双引力理论的结构，具有两个独立标架和丰富的宇宙学分支。


<details>
  <summary>Details</summary>
Motivation: 基于扭转变形的非对易引力理论需要扩展规范群和额外的引力自由度，这为构建广义相对论的基本扩展提供了理论框架，探索超越经典引力的可能性。

Method: 采用扭转变形微分几何和标架场的一阶动力学表述，引入GL(2,C)规范联络和两个独立标架，允许标架间的相互作用项，结构与无鬼双引力理论相似。

Result: 额外引力自由度在可交换极限下仍然存在，获得有效作用量并分析其对称性。宇宙学解分为两支：一支具有恒定纯空间曲率二形式；另一支显示更丰富的规范自由度，哈密顿分析揭示除时间重参数化生成元外的三个额外一阶约束。

Conclusion: 非对易引力理论为广义相对论扩展提供了有前景的框架，其可交换极限下的有效理论表现出与双引力理论的相似性，具有丰富的动力学结构和宇宙学分支，值得进一步研究。

Abstract: Noncommutative gravity, based on a twist-deformation of the differential geometry of spacetime and a first-order formulation of the dynamics, requires additional gravitational degrees of freedom as well as an enlargement of the gauge group of Lorentz transformations of the tetrad frame. As such, it offers a theoretical playground to build fundamentally motivated extension to general relativity. The dynamical degrees of freedom include a ${\rm GL}(2,\mathbb{C})$ gauge connection and two independent tetrads. The theory allows for interaction terms between the two tetrads, whose structure displays some similarities with ghost-free bigravity. The extra gravitational degrees of freedom survive in the commutative limit. We show the effective action obtained in this limit, discuss its symmetries, and compare it with other bigravity theories. The dynamics of homogeneous and isotropic cosmological solutions split into two branches. One is characterized by a constant and purely spatial curvature two-form. The other displays a richer gauge freedom, and the Hamiltonian analysis of the dynamics reveals three extra first-class constraints in addition to the generator of time reparametrizations.

</details>


### [153] [The Missing Massive Sector: Massive Boson Stars -- Stability and GW Emission in Head-on Mergers](https://arxiv.org/abs/2512.15242)
*Bo-Xuan Ge*

Main category: gr-qc

TL;DR: 研究四次自相互作用大质量玻色子星的平衡序列和动力学演化，发现质量曲线有多个极值但稳定性只在第一个最大值处改变，高致密构型会坍缩。等质量星体对头碰撞产生三种结果，引力波能量反映致密性与潮汐形变性的竞争，强自相互作用下坍缩前接触分支呈现显著非单调结构。


<details>
  <summary>Details</summary>
Motivation: 研究四次自相互作用大质量玻色子星的平衡序列和动力学演化，探索其稳定性、碰撞行为和引力波特征，为构建神经网络技术提供基础数据，以改进玻色子星初始数据并建立能够快速预测引力波信号的替代模型。

Method: 通过构造平衡序列和进行动力学演化来研究四次自相互作用大质量玻色子星。分析质量曲线M(|φ_c|)的极值点，研究稳定性变化，模拟等质量星体的对头碰撞，分析三种不同结果，并计算相关的引力波能量。

Result: 质量曲线有多个极值但稳定性只在第一个最大值处改变；超过该点的构型变得高度致密并在数值扰动下坍缩；近临界模型显示短暂的双重下潜行为。等质量星体碰撞产生三种结果：玻色子星残余、接触时黑洞形成、接触前各星体坍缩成黑洞。引力波能量反映致密性与潮汐形变性的竞争，强自相互作用下坍缩前接触分支呈现显著非单调结构。

Conclusion: 该研究提供了大量初始条件和波形数据，为神经网络技术提供了自然基础，可用于改进玻色子星初始数据并构建能够快速预测扩展参数空间内引力波信号的替代模型。

Abstract: We investigate quartically self-interacting massive boson stars by constructing equilibrium sequences and performing dynamical evolutions. The mass curve $M(|φ_c|)$ along these sequences develops multiple extrema, yet stability changes only at the first maximum; configurations beyond it become highly compact and collapse under numerically induced perturbations, with near-critical models displaying a short-lived double-dive behaviour. Head-on collisions of equal-mass stars yield three distinct outcomes - boson star remnants, black hole formation at contact, and collapse of each star to a black hole prior to contact. The associated gravitational-wave energies reflect the competition between increasing compactness and decreasing tidal deformability, and at large self-interaction strengths the collapse-before-contact branch exhibits a pronounced non-monotonic structure. The simulations reported here constitute a substantial catalogue of initial conditions and waveforms, providing a natural basis for neural-network techniques aimed at improving boson star initial data and constructing surrogate models capable of rapidly predicting gravitational-wave signals across an extended parameter space.

</details>


### [154] [Spontaneous wave function collapse from non-local gravitational self-energy](https://arxiv.org/abs/2512.15393)
*Kimet Jusufi,Douglas Singleton,Francisco S. N. Lobo*

Main category: gr-qc

TL;DR: 该论文将弦理论启发的T对偶性引入薛定谔-牛顿方程，揭示了引力与量子叠加原理之间的根本冲突，导致波函数自发坍缩。


<details>
  <summary>Details</summary>
Motivation: 研究引力与量子力学基本原理之间的根本冲突，特别是等效原理与量子叠加原理在非局域引力背景下的不相容性。

Method: 将弦理论T对偶性启发的非局域引力自能纳入薛定谔-牛顿方程，通过惯性系和自由落体系中的波函数比较，分析引力诱导的相位变化。

Result: 发现波函数在惯性系和自由落体系中存在引力诱导的相位差（包含线性和立方时间项），导致波函数自发坍缩，坍缩时间与系统质量成反比。

Conclusion: 引力与量子叠加原理之间存在根本性张力，在非局域引力背景下线性叠加原理只是近似，引力效应必然导致量子叠加态不稳定并自发坍缩。

Abstract: We incorporate non-local gravitational self-energy, motivated by string-inspired T-duality, into the Schrödinger-Newton equation. In this framework spacetime has an intrinsic non-locality, rendering the standard linear superposition principle only an approximation valid in the absence of gravitational effects. We then invert the logic by assuming the validity of linear superposition and demonstrate that such superpositions inevitably become unstable once gravity is included. The resulting wave-function collapse arises from a fundamental tension between the equivalence principle and the quantum superposition principle in a semiclassical spacetime background. We further show that wave functions computed in inertial and freely falling frames differ by a gravitationally induced phase shift containing linear and cubic time contributions along with a constant global term. These corrections produce a global phase change and lead to a spontaneous, model-independent collapse time inversely proportional to the mass of the system.

</details>


### [155] [Stefan-Boltzmann Law and Thermal Casimir Effect in Neutron Star Spacetime via Thermo Field Dynamics](https://arxiv.org/abs/2512.15610)
*Klecio E. L. de Farias,Marcos A. Anacleto,Rafael A. Batista,Iver Brevik,Francisco A. Brito,Eduardo Passos,Amilcar R. Queiroz,Lázaro L. Sales*

Main category: gr-qc

TL;DR: 该论文研究了中子星弯曲时空中质量为零标量场的热卡西米尔效应，将斯蒂芬-玻尔兹曼定律推广到包含引力红移和曲率修正，揭示了强引力如何显著改变局部能量密度和压力。


<details>
  <summary>Details</summary>
Motivation: 研究量子真空涨落与致密天体几何结构之间的非平凡相互作用，特别是在强引力场（如中子星）中热卡西米尔效应的表现。

Method: 采用热场动力学(TFD)形式体系，从重整化的能量-动量张量出发，利用Tolman-Oppenheimer-Volkoff(TOV)度规，同时引入有限温度和空间紧致化，统一处理星体内外的真空和热贡献。

Result: 推导了高低温极限下的解析表达式，显示曲率和红移如何修正热辐射的特征T^4依赖关系；强引力显著改变局部能量密度和压力；通过多方模型进行数值分析，凸显时空背景对真空涨落的影响。

Conclusion: 该研究成功建立了弯曲时空中热卡西米尔效应的统一理论框架，揭示了强引力场对量子真空效应的显著修正，为理解致密天体中的量子场论效应提供了新见解。

Abstract: We investigate the thermal Casimir effect for a massless scalar field in the curved spacetime of a neutron star within the Thermo Field Dynamics (TFD) formalism. Starting from the renormalized energy-momentum tensor, we generalize the Stefan-Boltzmann law to include gravitational redshift and curvature corrections governed by the Tolman-Oppenheimer-Volkoff (TOV) metric. Finite temperature and spatial compactification are introduced simultaneously, allowing a unified and consistent treatment of both vacuum and thermal contributions inside and outside the star. Analytical expressions are derived for the high- and low-temperature limits, showing explicitly how curvature and redshift modify the characteristic $T^4$ dependence of thermal radiation. The results reveal that strong gravity significantly alters the local energy density and pressure, demonstrating the nontrivial interplay between quantum vacuum fluctuations and compact astrophysical geometries. A polytropic model is considered to perform numerical analyses, highlighting the influence of the spacetime background on vacuum fluctuations.

</details>


### [156] [Observational constraints on the spin/anisotropy of the CCOs of Cassiopeia A, Vela Jr. and G347.3-0.5 and a single surviving continuous gravitational wave candidate](https://arxiv.org/abs/2512.15672)
*Jing Ming,Maria Alessandra Papa,Heinz-Bernd Eggenstein,Bernd Machenschalk,J. Martins,B. Steltner,B. McGloughlin,V. Dergachev,R. Prix,M. Bensch*

Main category: gr-qc

TL;DR: 利用Einstein@Home志愿者计算资源，对三个超新星遗迹中心的中子星进行了最深入广泛的连续引力波信号搜索，设定了对引力波振幅、椭圆率、r模饱和振幅和地壳各向异性的最严格约束。


<details>
  <summary>Details</summary>
Motivation: 寻找来自中子星的连续引力波信号，这些信号可以揭示中子星的内部结构和物理特性，如椭圆率、r模饱和振幅和地壳各向异性。

Method: 利用Einstein@Home分布式计算平台进行大规模搜索，对4500万个最有望的信号候选进行多阶段后续分析，并使用独立数据进行验证。

Result: 设定了对引力波振幅、椭圆率、r模饱和振幅和地壳各向异性的最严格约束：对于自转周期低于2毫秒的中子星，椭圆率小于4×10⁻⁷；对于1.3-100毫秒的自转周期，地壳各向异性大于5×10⁻³。仅有一个来自G347.3低频搜索的候选信号通过了所有后续验证。

Conclusion: 这是迄今为止对连续引力波信号最严格的约束研究，发现了一个有希望的候选信号，但需要新数据进行确认。现有数据虽已存在但尚未公开，未来分析将有助于澄清该候选信号的性质。

Abstract: We carry out the deepest and broadest search for continuous gravitational-wave signals with frequencies between 20-1500 Hz, from three neutron stars at the center of the supernova remnants Cassiopeia A, Vela Jr., and G347.3-0.5. This search was made possible by the computing power shared by thousands of Einstein@Home volunteers. After the initial Einstein@Home search, we perform a multi-stage follow-up of the most promising $\approx$ 45 million signal candidates. In the last stages, we use independent data to further investigate the remaining candidates from the previous stages. We set the most stringent constraints to date on the gravitational-wave amplitude, equatorial ellipticity, r-mode saturation amplitude, and -- for the first time -- the neutron-star crustal anisotropy. For spin periods lower than 2 ms we constrain the ellipticity to be smaller than $4\times 10^{-7}$ for all targets. We exclude the crustal anisotropy to be smaller than $5\times 10^{-3}$ for spin periods between 1.3-100 ms. Only one candidate -- from the low frequency G347.3 search -- survives all follow-ups. We illustrate properties of this candidate. Investigations on new data will aid in clarifying its nature. Such ``new" data exists and would be optimal for this purpose, but they are not publicly accessible at the time of writing.

</details>


### [157] [An introduction to nonlinear fiber optics and optical analogues to gravitational phenomena](https://arxiv.org/abs/2512.15695)
*Dimitrios Kranas,Andleeb Zahra,Friedrich König*

Main category: gr-qc

TL;DR: 该论文系统阐述了光纤中光传播的理论框架，特别关注非线性效应，并将其应用于模拟引力研究，包括光学霍金效应和准正规模等黑洞现象的光学类比。


<details>
  <summary>Details</summary>
Motivation: 现有光纤模型通常针对光通信优化，包含许多假设且细节不足。本文旨在为模拟引力研究提供一个自包含、详细的光纤光传播理论框架，以最小假设推导相关方程。

Method: 从阶跃折射率光纤结构出发，推导线性光学传播模式，证明基模横向电场可近似为线性偏振高斯分布。引入立方非线性，推导一般波包传播方程，进一步简化得到非线性薛定谔方程。将该框架应用于模拟引力，展示强光如何为探测光创建有效背景时空。

Result: 建立了光纤中光传播的完整理论框架，可用于模拟引力现象。展示了强光介质如何产生类似黑洞时空的有效背景，引入光学视界和粒子产生机制（光学霍金效应），并讨论了两种相关光发射机制。还提出了黑洞振荡（准正规模）的光学类比模型。

Conclusion: 光纤提供了一个强大的平台，可以在实验室中研究量子水平的引力现象。通过详细推导光纤中光传播的基本方程，本文为模拟引力研究建立了坚实的理论基础，展示了光纤在探索黑洞物理等前沿领域的应用潜力。

Abstract: The optical fiber is a revolutionary technology of the past century. It enables us to manipulate single modes in nonlinear interactions with precision at the quantum level without involved setups. This setting is useful in the field of analogue gravity (AG), where gravitational phenomena are investigated in accessible analogue lab setups. These lecture notes provide an account of this AG framework and applications. Although light in nonlinear dielectrics is discussed in textbooks, the involved modelling often includes many assumptions that are directed at optical communications, some of which are rarely detailed. Here, we provide a self-contained and sufficiently detailed description of the propagation of light in fibers, with a minimal set of assumptions, which is relevant in the context of AG. Starting with the structure of a step-index fiber, we derive linear-optics propagating modes and show that the transverse electric field of the fundamental mode is well approximated as linearly polarized and of a Gaussian profile. We then incorporate a cubic nonlinearity and derive a general wave envelope propagation equation. With further simplifying assumptions, we arrive at the famous nonlinear Schrödinger equation, which governs fundamental effects in nonlinear fibers, such as solitons. As a first application in AG, we show how intense light in the medium creates an effective background spacetime for probe light akin to the propagation of a scalar field in a black hole spacetime. We introduce optical horizons and particle production in this effective spacetime, giving rise to the optical Hawking effect. Furthermore, we discuss two related light emission mechanisms. Finally, we present a second optical analogue model for the oscillations of black holes, the quasinormal modes, which are important in the program of black hole spectroscopy.

</details>


### [158] [Physical Effects of Gravitational Waves at Second Order](https://arxiv.org/abs/2512.15704)
*Guillem Domènech,Shi Pi,Ao Wang*

Main category: gr-qc

TL;DR: 该论文解决了二阶宇宙学微扰理论中引力波应变缺乏严格定义的问题，通过计算测地线观测者测量的物理效应，确定了牛顿规范下的横向无迹分量对应实际测量的引力波应变。


<details>
  <summary>Details</summary>
Motivation: 当前二阶宇宙学微扰理论中缺乏引力波应变的严格定义。通常将引力波与空间超曲面上的横向无迹度规涨落相关联，但在二阶情况下变得模糊，因为这本质上依赖于时空切片选择。虽然在线性化引力中这不是实际问题，但对于次级引力波（特别是由原初涨落诱导的引力波）构成了根本性问题。

Method: 首次计算了二阶引力波的物理效应，通过测地线观测者发射和接收电磁信号来测量这些效应。这种方法绕过了规范选择问题，直接计算可观测的物理量。

Result: 研究发现测量的引力波应变与牛顿规范下的横向无迹分量一致。这解决了关于规范模糊性的争论，为二阶引力波提供了明确的物理定义。

Conclusion: 论文通过计算测地观测者的物理测量，为二阶引力波应变提供了明确的物理定义，解决了规范模糊性问题。牛顿规范下的横向无迹分量对应实际测量的引力波应变，这一结果为研究次级引力波（特别是原初涨落诱导的引力波）提供了理论基础。

Abstract: There is currently no rigorous definition of gravitational wave strain at second order in cosmological perturbation theory. The usual association of gravitational waves with transverse and traceless fluctuations of the metric on spatial hypersurfaces becomes ambiguous at second order, as it inherently depends on the spacetime slicing. While this poses no practical issues in linearized gravity, it presents a fundamental problem for secondary gravitational waves, especially notorious for gravitational waves induced by primordial fluctuations. We compute, for the first time, the physical effects of gravitational waves at second order, as measured by geodesic observers that emit and receive electromagnetic signals, thereby settling the debate on gauge ambiguities. We find that the measured gravitational wave strain coincides with the transverse-traceless components in the Newton gauge.

</details>
