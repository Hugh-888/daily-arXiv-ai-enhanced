<div id=toc></div>

# Table of Contents

- [gr-qc](#gr-qc) [Total: 13]
- [cs.LG](#cs.LG) [Total: 92]
- [physics.comp-ph](#physics.comp-ph) [Total: 5]
- [quant-ph](#quant-ph) [Total: 43]


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [1] [Differential topology and micro-structure of black hole in Einstein-Euler-Heisenberg spacetimes with exponential entropy](https://arxiv.org/abs/2510.12855)
*Muhammad Yasir,Tong Lining,Kazuharu Bamba*

Main category: gr-qc

TL;DR: 使用拓扑电流Ψ映射理论研究爱因斯坦-欧拉-海森堡理论中的精确黑洞，分析不同系综下的拓扑电荷和临界点，发现拓扑电荷为1、-1或无生成/湮灭点，并研究黑洞稳定性与热力学曲率行为。


<details>
  <summary>Details</summary>
Motivation: 探索爱因斯坦-欧拉-海森堡理论中精确黑洞的拓扑性质，通过不同热力学系综研究黑洞的稳定性与热力学行为。

Method: 采用拓扑电流Ψ映射理论，分别在正则系综、混合系综和巨正则系综下分析拓扑电荷和临界点，研究温度、热容量与视界半径的关系，并使用几何方法分析热力学曲率。

Result: 发现不同系综下拓扑电荷为1、-1或无生成/湮灭点，温度与热容量随视界半径变化，验证了黑洞的稳定性，揭示了热力学曲率的行为特征。

Conclusion: 通过拓扑方法成功分析了爱因斯坦-欧拉-海森堡理论中黑洞的热力学性质，为理解黑洞稳定性与热力学行为提供了新的视角。

Abstract: Exact black holes in the Einstein Euler-Heisenberg theory are explored with
an exponential entropy framework by using the topological current
$\Psi$-mapping theory. The topology classes are investigated through the
canonical, mixed, and grand canonical ensembles. In particular, the magnetic
charge is fixed for the canonical ensemble, whereas the magnetic potential is
included for the mixed ensemble and the grand canonical ensemble with
maintaining its consistency through the magnetic potential. The topological
charges are analyzed for each ensemble through critical points. As a result, it
is found that the canonical, mixed, and grand canonical ensembles lead to
either $1$, $-1$, or no generation/annihilation points. Moreover, it is shown
how temperature and heat capacity depend on the horizon radius in order to
verify the stability of a black hole. Furthermore, the behavior of the
thermodynamic curvatures of a black hole is investigated through the geometric
methods.

</details>


### [2] [Generalized Second Law and Thermodynamical Aspects of $f(Q,\mathcal{T})$ Gravity](https://arxiv.org/abs/2510.12863)
*S. H. Shekh,Anirudh Pradhan,A. Husain,M. Zeyauddin*

Main category: gr-qc

TL;DR: 本文研究了f(Q,T)引力理论在平坦FLRW宇宙视界上的热力学性质，建立了第一定律和广义第二定律，分析了不同f(Q,T)模型的热力学一致性。


<details>
  <summary>Details</summary>
Motivation: 晚期宇宙加速膨胀促使人们探索广义相对论的各种扩展理论，其中基于非度量标量Q和能量-动量张量迹T的f(Q,T)引力理论受到关注，需要研究其热力学性质以评估理论可行性。

Method: 通过吉布斯关系确定总熵变化率，在平坦FLRW宇宙的视界上建立热力学第一定律和广义第二定律，分析线性、幂律、二次迹、指数和交叉耦合等不同f(Q,T)模型。

Result: 分析表明线性和弱非线性模型通常具有热力学一致性，而强非线性或相互作用型模型需要精细调节参数才能满足广义第二定律。

Conclusion: 热力学考量可作为评估修正引力模型可行性及其与宇宙学动力学相关性的有效判据。

Abstract: Late-time cosmic acceleration has motivated the exploration of various
extensions of general relativity, among which $f(Q,\mathcal{T})$ gravity, based
on the non-metricity scalar $Q$ and the trace of the energy--momentum tensor
$\mathcal{T}$, has gained increasing attention. In this study, we explore the
thermodynamic aspects of $f(Q,\mathcal{T})$ gravity by establishing the first
law and generalized second law of thermodynamics at the apparent horizon of a
flat FLRW universe. By applying the Gibbs relation, we determined the rate of
change of the total entropy and assessed the conditions under which the
generalized second law remains valid for various choices of $f(Q,\mathcal{T})$.
Our analysis focuses on linear, power-law, quadratic trace, exponential, and
cross-coupling models, inspired by frameworks such as $f(R,\mathcal{T})$,
$f(T)$, and modifications motivated by string theory. Our analysis showed that
linear and mildly nonlinear models are generally thermodynamically consistent,
whereas strongly nonlinear or interaction-type models require fine-tuned
parameters for the generalized second law to hold. The present analysis
underscores that thermodynamic considerations serve as effective criteria for
assessing the viability of modified gravity models and their relevance to
cosmological dynamics.

</details>


### [3] [On the maximum compactness of neutron stars](https://arxiv.org/abs/2510.12870)
*Luciano Rezzolla,Christian Ecker*

Main category: gr-qc

TL;DR: 该论文研究了中子星的最大致密性上限，通过统计方法分析大量满足核理论、微扰QCD和天体物理观测约束的状态方程，发现最大致密性上限为1/3。


<details>
  <summary>Details</summary>
Motivation: 中子星的致密性（质量与半径比）对理解引力和核物理至关重要，但由于依赖于未知的核物质状态方程，'中子星能有多致密？'这个问题仍未解决。

Method: 采用统计方法，考虑大量满足核理论、微扰QCD和天体物理观测约束的参数化状态方程，并推测对于任何给定状态方程，最大致密性由非旋转构型序列中的最大质量星体实现。

Result: 发现最大致密性存在上限，即𝒞_max = 1/3，这个上限基本独立于恒星质量，是微扰QCD约束的直接结果。

Conclusion: 中子星的最大致密性存在理论上限1/3，这一发现对理解极端密度下核物质性质具有重要意义，且主要受微扰QCD约束驱动。

Abstract: The stellar compactness, that is, the dimensionless ratio between the mass
and radius of a compact star, $\mathcal{C} := M/R$, plays a fundamental role in
characterising the gravitational and nuclear-physics aspects of neutron stars.
Yet, because the compactness depends sensitively on the unknown equation of
state (EOS) of nuclear matter, the simple question: ``how compact can a neutron
star be?'' remains unanswered. To address this question, we adopt a statistical
approach and consider a large number of parameterised EOSs that satisfy all
known constraints from nuclear theory, perturbative Quantum Chromodynamics
(QCD), and astrophysical observations. Next, we conjecture that, for any given
EOS, the maximum compactness is attained by the star with the maximum mass of
the sequence of nonrotating configurations. While we can prove this conjecture
for a rather large class of solutions, its general proof is still lacking.
However, the evidence from all of the EOSs considered strongly indicates that
it is true in general. Exploiting the conjecture, we can concentrate on the
compactness of the maximum-mass stars and show that an upper limit appears for
the maximum compactness and is given by $\mathcal{C}_{\rm max} = 1/3$.
Importantly, this upper limit is essentially independent of the stellar mass
and a direct consequence of perturbative-QCD constraints.

</details>


### [4] [Bumblebee Gravity - Lessons from Perturbation Theory](https://arxiv.org/abs/2510.13135)
*Nils A. Nilsson*

Main category: gr-qc

TL;DR: 本文分析了bumblebee矢量-张量理论，发现在非最小耦合引力下存在鬼模，需施加简并条件才能消除。最小耦合极限下标量扰动会强耦合，说明非最小耦合的必要性。同时从张量模速度得到对bumblebee场的约束约为10^{-15}量级。


<details>
  <summary>Details</summary>
Motivation: 研究bumblebee模型这类自发破缺局域洛伦兹和微分同胚不变性的矢量-张量理论，理解其在宇宙学扰动理论中的行为。

Method: 在精确的dS背景上使用宇宙学扰动理论，分析非最小耦合和最小耦合情况下的模式行为。

Result: 非最小耦合引力下存在鬼模，施加简并条件后模型变为广义Proca理论的子集；最小耦合极限下标量扰动强耦合；从张量模速度得到对bumblebee场的约束约为10^{-15}。

Conclusion: bumblebee模型需要非最小耦合来避免强耦合问题，且对bumblebee场有严格的观测约束。

Abstract: These proceedings summarize some recent efforts in understanding a class of
vector-tensor theories known as {\it bumblebee} models, which spontaneously
break local Lorentz and diffeomorphism invariance. Using cosmological
perturbation theory on an exact dS background, we find that for non-minimal
coupling to gravity, the theory contains a ghost mode unless a degeneracy
condition is imposed, after which the model becomes a subset of generalized
Proca theory. We go further to show that scalar perturbations become strongly
coupled in the minimal-coupling limit, which shows the necessity of the
non-minimal coupling. Moreover, we find a constraint on the bumblebee field
from the speed of tensor modes on the order of $10^{-15}$.

</details>


### [5] [Entropic uncertainty and coherence in Einstein-Gauss-Bonnet gravity](https://arxiv.org/abs/2510.13167)
*Wen-Mei Li,Jianbo Lu,Shu-Min Wu*

Main category: gr-qc

TL;DR: 研究爱因斯坦-高斯-博内引力背景下黑洞中GHZ和W态的量子记忆辅助熵不确定性和量子相干性，分析不同配置下的维度依赖性和状态鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 探索在弯曲时空中量子信息处理的优化策略，研究不同量子态在黑洞引力场中的行为差异，为量子资源在引力环境下的应用提供理论指导。

Method: 分析两种场景：(i)量子记忆在视界附近而测量粒子在平坦区；(ii)相反配置。研究GHZ和W态在EGB黑洞背景下的熵不确定性和量子相干性，考察维度依赖性。

Result: 在d>5维中，测量不确定性随视界半径增加单调减小，相干性增加；d=5维中两者呈非单调行为。W态在保持相干性方面更鲁棒，GHZ态对测量不确定性增加更具抵抗力。两种场景产生定性不同的行为模式。

Conclusion: 不同量子资源的特性为在弯曲时空中选择和优化量子态进行信息处理提供了重要见解，量子态的鲁棒性特征对引力环境下的量子信息应用具有指导意义。

Abstract: We investigate tripartite quantum-memory-assisted entropic uncertain and
quantum coherence for GHZ and W states of a fermionic field in the background
of a spherically symmetric black hole of Einstein-Gauss-Bonnet (EGB) gravity.
Two distinct scenarios are analyzed: (i) the quantum memories (held by Bob and
Charlie) are near the horizon while the measured particle (Alice) remains in
the flat region, and (ii) the reverse configuration. Dimensional dependence is
observed: in $d>5$ dimensions, the measurement uncertainty decreases
monotonically with increasing horizon radius, while coherence increases; in
$d=5$, both quantities exhibit non-monotonic behavior due to distinctive
thermodynamic properties. Furthermore, comparative analysis reveals that the W
state exhibits higher robustness in preserving coherence, whereas the GHZ state
shows greater resistance to measurement uncertainty increase induced by Hawking
radiation. Notably, the two scenarios yield qualitatively distinct behaviors:
quantum coherence is consistently lower in Scenario 1 (quantum memory near
horizon) than in Scenario 2 (measured particle near horizon), irrespective of
the quantum state. For measurement uncertainty, the W state displays lower
uncertainty in Scenario 1, while the GHZ state exhibits the opposite trend,
with higher measurement uncertainty in Scenario 1. These results indicate that
the characteristics of different quantum resources provide important insights
into the selection and optimization of quantum states for information
processing in curved spacetime.

</details>


### [6] [APRIL: Auxiliary Physically-Redundant Information in Loss - A physics-informed framework for parameter estimation with a gravitational-wave case study](https://arxiv.org/abs/2510.13677)
*Matteo Scialpi,Francesco Di Clemente,Leigh Smith,Michał Bejger*

Main category: gr-qc

TL;DR: 提出了APRIL方法，通过在损失函数中加入物理冗余信息来改进PINNs在多系统数据集上的性能，在引力波参数估计中实现了数量级精度提升


<details>
  <summary>Details</summary>
Motivation: 标准PINNs在处理包含多个相同物理系统但参数不同的数据集时扩展性差，需要改进多系统场景下的物理一致性学习

Method: 在标准监督损失基础上添加辅助物理冗余关系项，保持真实物理最小值的同时重塑损失函数景观，改善收敛性

Result: 在引力波参数估计基准测试中，APRIL实现了高达一个数量级的测试精度提升，特别是对难以学习的参数效果显著

Conclusion: APRIL方法为大型多系统数据集提供了物理一致性学习，适用于未来涉及真实噪声和更广参数范围的引力波分析

Abstract: Physics-Informed Neural Networks (PINNs) embed the partial differential
equations (PDEs) governing the system under study directly into the training of
Neural Networks, ensuring solutions that respect physical laws. While effective
for single-system problems, standard PINNs scale poorly to datasets containing
many realizations of the same underlying physics with varying parameters. To
address this limitation, we present a complementary approach by including
auxiliary physically-redundant information in loss (APRIL), i.e. augment the
standard supervised output-target loss with auxiliary terms which exploit exact
physical redundancy relations among outputs. We mathematically demonstrate that
these terms preserve the true physical minimum while reshaping the loss
landscape, improving convergence toward physically consistent solutions. As a
proof-of-concept, we benchmark APRIL on a fully-connected neural network for
gravitational wave (GW) parameter estimation (PE). We use simulated, noise-free
compact binary coalescence (CBC) signals, focusing on inspiral-frequency
waveforms to recover the chirp mass $\mathcal{M}$, the total mass
$M_\mathrm{tot}$, and symmetric mass ratio $\eta$ of the binary. In this
controlled setting, we show that APRIL achieves up to an order-of-magnitude
improvement in test accuracy, especially for parameters that are otherwise
difficult to learn. This method provides physically consistent learning for
large multi-system datasets and is well suited for future GW analyses involving
realistic noise and broader parameter ranges.

</details>


### [7] [Singularity avoidance in black hole interiors by quantum gravity effects](https://arxiv.org/abs/2510.13175)
*Takeshi Chiba,Hiroki Matsui,Keiju Murata*

Main category: gr-qc

TL;DR: 通过Wheeler-DeWitt方程研究史瓦西黑洞内部的量子性质，发现量子效应增强时波包偏离经典轨迹，表现出奇点避免行为，量子效应越强奇点形成时间越长。


<details>
  <summary>Details</summary>
Motivation: 研究黑洞内部的量子性质，特别是量子引力效应如何影响奇点形成，探索量子引力在黑洞内部的表现。

Method: 使用Kantowski-Sachs度规描述黑洞内部，推导引力系统的哈密顿量和WDW方程，通过改变引力常数参数来调控量子效应。

Result: 在量子效应可忽略时波包遵循经典轨迹；量子效应增强时波包偏离经典轨迹，奇点形成时间随量子效应增强而延长。

Conclusion: 量子引力效应可能导致黑洞内部奇点避免，量子效应越强奇点形成时间越长，支持量子引力在解决奇点问题中的作用。

Abstract: The quantum nature of the Schwarzschild black hole interior is investigated
through the Wheeler-DeWitt (WDW) equation. The interior of a static,
spherically symmetric black hole is described by the Kantowski-Sachs (KS)
metric, which represents a homogeneous but anisotropic cosmology. We derive the
Hamiltonian for the gravitational system corresponding to the black hole
interior and obtain the associated WDW equation. By varying the gravitational
constant as a parameter controlling quantum effects, we examine how the
solutions of the WDW equation change with respect to this parameter. In the
parameter regime where quantum effects are negligible, we find that the wave
packet solutions closely follow the classical trajectory of the black hole
interior. On the other hand, as quantum effects are enhanced, the wave packet
deviates from the classical trajectory and exhibits behavior suggestive of
singularity avoidance. To quantify this behavior, we introduce an appropriate
"clock" inside the black hole and compute the time to singularity formation
with respect to this clock. The results show that stronger quantum effects lead
to a longer formation time, suggesting a tendency toward the avoidance of
singularity formation due to quantum gravity effects.

</details>


### [8] [Particle production in a bouncing universe](https://arxiv.org/abs/2510.13213)
*Mustafa Saeed,Irfan Javed,Aiman Nauman*

Main category: gr-qc

TL;DR: 该论文研究量子场在宇宙反弹过程中的粒子产生，发现反弹时粒子产生达到峰值，且晚期粒子谱呈现热谱特征，揭示了反弹宇宙在量子物质上的独特印记。


<details>
  <summary>Details</summary>
Motivation: 研究质量标量场宇宙学中，通过将宇宙物理体积离散化解决大爆炸奇点问题，探索反弹宇宙中量子场的粒子产生及其对几何演化的影响。

Method: 使用弯曲背景上的量子场论数值追踪量子场在宇宙反弹过程中真空中的粒子产生，并与膨胀宇宙情况进行对比，同时采用半经典引力方法验证结果。

Result: 发现粒子产生在所有模式中先上升，在反弹时达到峰值，之后缓慢变化；反弹宇宙的晚期粒子产生呈现热谱特征，与膨胀宇宙有明显区别。

Conclusion: 研究深化了对反弹宇宙中引力-物质相互作用的理解，为寻找反弹宇宙特征提供了新线索，并加强了引力与热力学之间的联系。

Abstract: In massless scalar field cosmology, imposing the universe's physical volume
as fundamentally discrete resolves the big bang singularity via a big bounce.
We use quantum field theory on curved background to numerically track the
number of particles created in the vacuum of a quantum field that propagates
through the cosmological bounce. We find that due to geometry's evolution,
particle production in all modes initially rises, sharply peaks at the bounce,
and varies slowly afterwards. Further, by comparing with the case of a quantum
field propagating on an expanding universe, we discover that the bouncing
universe's imprints on quantum matter are distinct: notably, the late time
particle production across modes resembles a thermal spectrum. We then use
semiclassical gravity and find similar qualitative results. Here, we also
determine how particle production affects geometry's evolution. Our study adds
to existing literature on gravity-matter interactions in the context of a
bouncing universe, contributes to searches of a bouncing universe's signatures,
and strengthens the link between gravity and thermodynamics.

</details>


### [9] [Probing thermodynamic phase transitions by dynamics of timelike particle around a magnetic AdS black hole](https://arxiv.org/abs/2510.13552)
*R. H. Ali,Zi-Yu Tang,Xiao-Mei Kuang*

Main category: gr-qc

TL;DR: 通过李雅普诺夫指数和准周期振荡分析非最小耦合磁AdS黑洞的相结构，发现热力学相变会显著影响动力学量，这些动力学量可作为黑洞热力学相结构的敏感探针。


<details>
  <summary>Details</summary>
Motivation: 研究黑洞热力学相变与动力学行为之间的联系，探索李雅普诺夫指数和准周期振荡作为热力学相结构探针的可能性。

Method: 分析自由能随霍金温度的变化，研究类时测地线对应的不稳定圆形轨道，计算李雅普诺夫指数，并利用相对论进动模型探索准周期振荡频率。

Result: 发现范德瓦尔斯型相变，存在小、中、大黑洞相共存；热力学相变会导致李雅普诺夫指数和准周期振荡谱发生显著变化。

Conclusion: 李雅普诺夫指数和准周期振荡等动力学量可以作为探测黑洞热力学相结构的敏感工具，热力学相变会在动力学行为中留下明显印记。

Abstract: In this paper, we investigate the phase structure of a nonminimal coupled
magnetic AdS black hole by connecting its thermodynamic properties with the
dynamical behavior of orbiting particles, within the framework of Lyapunov
exponent and quasi-periodic oscillation. The analysis of the free energy as a
function of the Hawking temperature reveals a Van der Waals-like phase
transition, characterized by the coexistence of small, intermediate, and large
black hole phases. By examining timelike geodesics corresponding to unstable
circular orbits, we evaluate the Lyapunov exponent of the test particles
crossing the phase transition and explore its role as dynamical indicator of
stability. Furthermore, by perturbing the unstable circular orbit and employing
the relativistic precession model, we explore the associated upper and lower
quasi-periodic oscillation frequencies. Our findings show that the occurrence
of thermodynamic phase transitions induces marked changes in both Lyapunov
exponent and quasi-periodic oscillation spectra, indicating that these
dynamical quantities can serve as sensitive probes of the underlying
thermodynamic phase structure of the black hole.

</details>


### [10] [Orbital dynamics and precession in magnetized Kerr spacetime](https://arxiv.org/abs/2510.13569)
*Karthik Iyer,Chandrachur Chakraborty*

Main category: gr-qc

TL;DR: 该论文研究了磁化克尔黑洞时空中中性测试粒子的轨道结构和进动动力学，揭示了磁场强度对轨道稳定性和进动行为的显著影响。


<details>
  <summary>Details</summary>
Motivation: 研究外部磁场对黑洞周围粒子轨道动力学的影响，为理解强场区域中引力与磁场的相互作用提供自洽框架。

Method: 在磁化克尔黑洞这一爱因斯坦-麦克斯韦方程精确解中，分析中性测试粒子的轨道结构、进动频率和稳定性条件。

Result: 发现临界磁场强度限制了圆形轨道存在，磁化效应导致进动方向反转，在亚临界场强下形成有限径向稳定区域。

Conclusion: 磁场曲率对强场动力学有重要几何影响，为解释准周期振荡现象和精确计时观测中的磁印记提供了理论框架。

Abstract: We study the orbital structure and precession dynamics of neutral test
particles in the magnetized Kerr black hole (MKBH) spacetime-an exact
electrovacuum solution of the Einstein-Maxwell equations that self-consistently
incorporates the curvature effects of an external magnetic field. This geometry
allows a unified treatment of gravitational and magnetic influences across weak
to ultra-strong regimes. The analysis reveals a critical magnetic field
strength above which no circular geodesics, timelike or null, can exist,
establishing an upper magnetic bound for orbital motion. For subcritical
fields, the photon circular orbit admits two real roots, the outer of which
defines an outermost stable circular orbit (OSCO), complementing the
conventional innermost stable circular orbit (ISCO) and confining stable motion
within a finite radial domain. Exact expressions for the orbital, radial, and
vertical epicyclic frequencies, and their associated precession rates, show
substantial deviations from Kerr behavior, including a magnetically induced
reversal of periastron precession within a finite radial range. For
astrophysically relevant magnetic field strengths, the retrograde precession
could be observable at large radii around astrophysical BHs, offering a
potential diagnostic of large-scale magnetization. These findings highlight the
geometric influence of magnetic curvature on strong-field dynamics, providing a
self-consistent framework to interpret quasi-periodic oscillation phenomenology
and potential magnetic imprints in precision timing observations of compact
objects.

</details>


### [11] [Mass and spin coevolution of black holes inspiralling through dark matter](https://arxiv.org/abs/2510.13604)
*Theophanes K. Karydas,Rodrigo Vicente,Gianfranco Bertone*

Main category: gr-qc

TL;DR: 研究暗物质尖峰中极端/中等质量比旋进系统中次级黑洞的吸积过程，发现黑洞自旋会抑制质量吸积率但增强吸积诱导的力矩，导致自旋减慢和与轨道平面的对齐。


<details>
  <summary>Details</summary>
Motivation: 探索在暗物质环境中黑洞自旋如何控制碰撞性粒子的吸积过程，以及这种吸积对黑洞自旋大小和方向的反馈作用。

Method: 通过理论分析研究次级黑洞在暗物质尖峰中吸积碰撞性粒子的过程，重点关注自旋对吸积率和力矩的影响。

Result: 发现高自旋会抑制质量吸积率但增强吸积力矩，导致自旋减慢和与轨道平面对齐，形成近乎普适的质量-自旋相关性（s≈2.8）。

Conclusion: 碰撞性暗物质吸积会在天体物理相关时标上产生显著的自旋减慢效应，观测到快速自旋的中等质量比旋进伴星将不利于存在稠密暗物质环境。

Abstract: In extreme/intermediate-mass-ratio inspirals (E/IMRIs) embedded in
dark-matter (DM) spikes, the secondary black hole can accrete collisionless
particles from the surrounding halo. We study how the companion's spin controls
this process, and the ensuing back-reaction on the magnitude and direction of
the companion's spin vector. We find that higher spin suppresses the mass
accretion rate but enhances the accretion-induced torques, driving spin-down
and secular alignment of the companion's spin with the orbital plane.
Collisionless DM accretion generically imprints a near-universal mass-spin
correlation characterized by a spin-evolution parameter $s \simeq 2.8$, much
larger than is the case for typical astrophysical environments, and largely
independent of the local DM density and the spike slope. The associated
spin-down proceeds on astrophysically relevant timescales, thus observations of
rapidly spinning IMRI companions would disfavor the presence of dense DM
environments, providing constraints complementary to those arising from
dynamical friction.

</details>


### [12] [Dirac Quasinormal Modes in Noncommutative Reissner-Nordström Black Holes](https://arxiv.org/abs/2510.13701)
*Nikola Herceg,Nikola Konjik,A. Naveena Kumara,Andjelo Samsarov*

Main category: gr-qc

TL;DR: 该论文研究了非对易几何对变形Reissner-Nordström黑洞中狄拉克准正规模式的影响，发现非对易性导致准正规模式频率发生显著偏移和类似塞曼效应的分裂。


<details>
  <summary>Details</summary>
Motivation: 探索非对易几何在黑洞时空中量子引力效应的表现，特别是对狄拉克场准正规模式的影响。

Method: 采用半经典模型等价于非对易规范理论，使用连分式方法结合高斯消元法处理六项递推关系，计算质量为零的狄拉克场的准正规模式频率。

Result: 结果显示相对于对易Reissner-Nordström情况，振荡频率和阻尼率发生显著偏移，准正规模式谱中出现由非对易参数驱动的类似塞曼效应的分裂。

Conclusion: 非对易几何在黑洞时空中确实会产生可观测的量子引力效应，表现为准正规模式谱的特定分裂模式。

Abstract: Noncommutative (NC) geometry provides a novel approach to probe quantum
gravity effects in black hole spacetimes. This work explores Dirac quasinormal
modes (QNMs) of a deformed Reissner-Nordstr\"om black hole, where
noncommutativity induces an effective metric with an additional ($ r-\varphi$)
component. Employing a semiclassical model equivalent to a NC gauge theory, we
investigate the dynamics of massless Dirac fields and calculate their QNM
frequencies using the continued fraction method, enhanced by Gauss elimination
to address the six-term recurrence relations. Our results demonstrate notable
shifts in oscillation frequencies and damping rates relative to the commutative
Reissner-Nordstr\"om case, exhibiting a distinctive Zeeman-like splitting in
the QNM spectrum driven by the NC parameter.

</details>


### [13] [Primordial magnetogenesis in loop quantum cosmology](https://arxiv.org/abs/2510.13742)
*Ganga R. Nair,V. Sreenath*

Main category: gr-qc

TL;DR: 该论文研究了在圈量子宇宙学（LQC）框架下原初磁场（PMFs）的生成机制，通过分析电磁场在量子反弹和暴胀阶段的演化，发现生成的功率谱具有尺度依赖性。


<details>
  <summary>Details</summary>
Motivation: 原初磁场被认为是河外磁场的种子，但其起源尚不清楚。通过观测河外磁场可能为原初物理提供见解，因此在LQC背景下研究PMFs的生成机制。

Method: 将电磁场作为测试场与背景耦合，研究其在量子反弹和后续暴胀阶段的演化，分析不同初始条件下的功率谱、等效耦合函数形式、反作用效应。

Result: 在LQC中生成的功率谱具有尺度依赖性，计算了现今可测量的原初磁场量级。

Conclusion: 论文总结了在LQC框架下原初磁场生成的研究结果，并讨论了相关发现的意义。

Abstract: Primordial magnetic fields (PMFs) are magnetic fields generated during the
early universe. These fields are thought to be the seeds of extragalactic
magnetic fields. The origin of PMFs is not well known. Further, if they are
indeed sources of extragalactic fields, then there is a possibility that
observations of extragalactic magnetic fields could provide insights into the
primordial physics. With this motivation, we study the generation of the
primordial magnetic field in the context of loop quantum cosmology (LQC). In
LQC, inflation is preceded by a quantum bounce. In this work, we consider an
electromagnetic field coupled to the background as a test field and study its
evolution through the bounce and through the subsequent inflationary phase. We
investigate the power spectra generated in LQC and show that it is
scale-dependent. We study the power spectra with different initial conditions,
discuss equivalent forms of coupling functions, investigate backreaction, and
compute the amount of primordial magnetic field which can be measured today. We
conclude the article with a summary and discussion of the results.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [14] [Local Timescale Gates for Timescale-Robust Continual Spiking Neural Networks](https://arxiv.org/abs/2510.12843)
*Ansh Tiwari,Ayush Chauhan*

Main category: cs.LG

TL;DR: 提出LT-Gate脉冲神经元模型，通过双时间尺度动态和自适应门控机制解决SNN在持续学习中的稳定性-可塑性困境，在时序分类任务中实现51%准确率，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 脉冲神经网络在神经形态硬件上具有能效优势，但在需要快速适应和长期记忆的持续学习任务中表现不佳，特别是面临稳定性-可塑性困境。

Method: LT-Gate模型让每个脉冲神经元并行跟踪快慢两个时间尺度的信息，通过学习的门控机制局部调整它们的影响，并引入方差跟踪正则化来稳定放电活动。

Result: 在时序分类基准测试中达到约51%的最终准确率，优于Hebbian持续学习基线的46%和先前SNN方法，且无需外部重放或昂贵正交化。

Conclusion: 多时间尺度门控能显著增强SNN的持续学习能力，缩小脉冲网络与传统深度网络在终身学习任务上的差距，并兼容神经形态硬件。

Abstract: Spiking neural networks (SNNs) promise energy-efficient artificial
intelligence on neuromorphic hardware but struggle with tasks requiring both
fast adaptation and long-term memory, especially in continual learning. We
propose Local Timescale Gating (LT-Gate), a neuron model that combines dual
time-constant dynamics with an adaptive gating mechanism. Each spiking neuron
tracks information on a fast and a slow timescale in parallel, and a learned
gate locally adjusts their influence. This design enables individual neurons to
preserve slow contextual information while responding to fast signals,
addressing the stability-plasticity dilemma. We further introduce a
variance-tracking regularization that stabilizes firing activity, inspired by
biological homeostasis. Empirically, LT-Gate yields significantly improved
accuracy and retention in sequential learning tasks: on a challenging temporal
classification benchmark it achieves about 51 percent final accuracy, compared
to about 46 percent for a recent Hebbian continual-learning baseline and lower
for prior SNN methods. Unlike approaches that require external replay or
expensive orthogonalizations, LT-Gate operates with local updates and is fully
compatible with neuromorphic hardware. In particular, it leverages features of
Intel's Loihi chip (multiple synaptic traces with different decay rates) for
on-chip learning. Our results demonstrate that multi-timescale gating can
substantially enhance continual learning in SNNs, narrowing the gap between
spiking and conventional deep networks on lifelong-learning tasks.

</details>


### [15] [Lifting Manifolds to Mitigate Pseudo-Alignment in LLM4TS](https://arxiv.org/abs/2510.12847)
*Liangwei Nathan Zheng,Wenhao Liang,Wei Emma Zhang,Miao Xu,Olaf Maennel,Weitong Chen*

Main category: cs.LG

TL;DR: 论文研究了LLM4TS模型中的伪对齐问题，发现其源于预训练LLM的锥效应和时间序列数据固有低维流形的相互作用，并提出了TimeSUP技术来缓解该问题。


<details>
  <summary>Details</summary>
Motivation: 伪对齐是LLM4TS模型中普遍存在的挑战，导致其性能不如线性模型或随机初始化骨干网络，但社区对此问题的根源讨论有限。

Method: 提出了TimeSUP技术，通过增加时间序列流形维度以更接近语言嵌入的内在维度，使模型能清晰区分时间信号，同时捕捉跨模态共享结构。

Result: TimeSUP在长期预测性能上持续优于最先进的LLM4TS方法和其他轻量级基线，并能无缝集成到四个现有LLM4TS管道中，显著提升预测性能。

Conclusion: TimeSUP通过平衡时间序列和语言嵌入的区分度与相似性，有效解决了伪对齐问题，在保持各模态独特特征的同时学习其共性。

Abstract: Pseudo-Alignment is a pervasive challenge in many large language models for
time series (LLM4TS) models, often causing them to underperform compared to
linear models or randomly initialised backbones. However, there is limited
discussion in the community for the reasons that pseudo-alignment occurs. In
this work, we conduct a thorough investigation into the root causes of
pseudo-alignment in LLM4TS and build a connection of pseudo-alignment to the
cone effect in LLM. We demonstrate that pseudo-alignment arises from the
interplay of cone effect within pretrained LLM components and the intrinsically
low-dimensional manifold of time-series data. In addition, we also introduce
\textit{\textbf{TimeSUP}}, a novel technique designed to mitigate this issue
and improve forecast performance in existing LLM4TS approaches. TimeSUP
addresses this by increasing the time series manifold to more closely match the
intrinsic dimension of language embeddings, allowing the model to distinguish
temporal signals clearly while still capturing shared structures across
modalities. As a result, representations for time and language tokens remain
distinct yet exhibit high cosine similarity, signifying that the model
preserves each modality unique features while learning their commonalities in a
unified embedding space. Empirically, TimeSUP consistently outperforms
state-of-the-art LLM4TS methods and other lightweight baselines on long-term
forecasting performance. Furthermore, it can be seamlessly integrated into four
existing LLM4TS pipelines and delivers significant improvements in forecasting
performance.

</details>


### [16] [FedGTEA: Federated Class-Incremental Learning with Gaussian Task Embedding and Alignment](https://arxiv.org/abs/2510.12927)
*Haolin Li,Hoda Bidkhori*

Main category: cs.LG

TL;DR: FedGTEA是一个联邦类增量学习框架，通过高斯任务嵌入和对齐机制，在保持通信效率的同时捕获任务特定知识和模型不确定性。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习环境中类增量学习面临的统计异质性、遗忘问题和隐私约束等挑战。

Method: 客户端使用Cardinality-Agnostic Task Encoder生成高斯分布的任务嵌入，服务器端利用2-Wasserstein距离测量任务间差距并制定Wasserstein损失来增强任务分离。

Result: 在多个流行数据集上的实验表明，FedGTEA实现了优越的分类性能，显著减轻了遗忘现象，并持续优于现有基线方法。

Conclusion: FedGTEA通过概率化任务嵌入和对齐机制，为联邦类增量学习提供了一个可扩展、通信高效且隐私保护的解决方案。

Abstract: We introduce a novel framework for Federated Class Incremental Learning,
called Federated Gaussian Task Embedding and Alignment (FedGTEA). FedGTEA is
designed to capture task-specific knowledge and model uncertainty in a scalable
and communication-efficient manner. At the client side, the
Cardinality-Agnostic Task Encoder (CATE) produces Gaussian-distributed task
embeddings that encode task knowledge, address statistical heterogeneity, and
quantify data uncertainty. Importantly, CATE maintains a fixed parameter size
regardless of the number of tasks, which ensures scalability across long task
sequences. On the server side, FedGTEA utilizes the 2-Wasserstein distance to
measure inter-task gaps between Gaussian embeddings. We formulate the
Wasserstein loss to enforce inter-task separation. This probabilistic
formulation not only enhances representation learning but also preserves
task-level privacy by avoiding the direct transmission of latent embeddings,
aligning with the privacy constraints in federated learning. Extensive
empirical evaluations on popular datasets demonstrate that FedGTEA achieves
superior classification performance and significantly mitigates forgetting,
consistently outperforming strong existing baselines.

</details>


### [17] [Machine Learning-Based Ultrasonic Weld Characterization Using Hierarchical Wave Modeling and Diffusion-Driven Distribution Alignment](https://arxiv.org/abs/2510.13023)
*Joshua R. Tempelman,Adam J. Wachtor,Eric B. Flynn*

Main category: cs.LG

TL;DR: 提出一个端到端的机器学习工作流，通过降阶建模、扩散分布对齐和U-Net分割反演来解决超声波焊接检测中的数据稀缺和信号噪声问题。


<details>
  <summary>Details</summary>
Motivation: 自动化超声波焊接检测面临训练数据有限和环境噪声干扰的挑战，工业环境下的端到端机器学习解决方案尚未实现。

Method: 使用基于Lamb波理论的降阶Helmholtz模型生成数据集，通过扩散模型处理实验数据中的噪声分布，采用U-Net进行分割和反演。

Result: 该集成框架为真实数据上的自动化焊接检测提供了端到端解决方案。

Conclusion: 该方法成功解决了焊接检测中的数据稀缺和噪声问题，实现了工业环境下的自动化检测。

Abstract: Automated ultrasonic weld inspection remains a significant challenge in the
nondestructive evaluation (NDE) community to factors such as limited training
data (due to the complexity of curating experimental specimens or high-fidelity
simulations) and environmental volatility of many industrial settings
(resulting in the corruption of on-the-fly measurements). Thus, an end-to-end
machine learning (ML) workflow for acoustic weld inspection in realistic (i.e.,
industrial) settings has remained an elusive goal. This work addresses the
challenges of data curation and signal corruption by proposing workflow
consisting of a reduced-order modeling scheme, diffusion based distribution
alignment, and U-Net-based segmentation and inversion. A reduced-order
Helmholtz model based on Lamb wave theory is used to generate a comprehensive
dataset over varying weld heterogeneity and crack defects. The relatively
inexpensive low-order solutions provide a robust training dateset for inversion
models which are refined through a transfer learning stage using a limited set
of full 3D elastodynamic simulations. To handle out-of-distribution (OOD)
real-world measurements with varying and unpredictable noise distributions,
i.e., Laser Doppler Vibrometry scans, guided diffusion produces in-distribution
representations of OOD experimental LDV scans which are subsequently processed
by the inversion models. This integrated framework provides an end-to-end
solution for automated weld inspection on real data.

</details>


### [18] [Learning at the Speed of Physics: Equilibrium Propagation on Oscillator Ising Machines](https://arxiv.org/abs/2510.12934)
*Alex Gower*

Main category: cs.LG

TL;DR: 该论文展示了在振荡器伊辛机（OIMs）上实现平衡传播（EP）算法，将优化和采样统一到单一能量景观中，实现了竞争性的分类准确率，并证明了在硬件约束下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 利用自然执行能量下降的物理系统来加速机器学习，特别是通过OIMs的GHz频率动态来模拟能量基模型（EBMs）的优化和梯度下降，同时内在噪声对应朗之万动力学，支持采样和优化。

Method: 在振荡器伊辛机上实现平衡传播算法，将优化和采样过程统一到单一总能量景观中，使用局部学习规则而非全局反向传播。

Result: 在MNIST上达到97.2±0.1%的准确率，在Fashion-MNIST上达到88.0±0.1%的准确率，在参数量化和相位噪声等实际硬件约束下保持鲁棒性。

Conclusion: OIMs成为快速、节能的神经形态学习基底，EBMs可能在直接执行其优化的物理硬件上找到实际实现途径。

Abstract: Physical systems that naturally perform energy descent offer a direct route
to accelerating machine learning. Oscillator Ising Machines (OIMs) exemplify
this idea: their GHz-frequency dynamics mirror both the optimization of
energy-based models (EBMs) and gradient descent on loss landscapes, while
intrinsic noise corresponds to Langevin dynamics - supporting sampling as well
as optimization. Equilibrium Propagation (EP) unifies these processes into
descent on a single total energy landscape, enabling local learning rules
without global backpropagation. We show that EP on OIMs achieves competitive
accuracy ($\sim 97.2 \pm 0.1 \%$ on MNIST, $\sim 88.0 \pm 0.1 \%$ on
Fashion-MNIST), while maintaining robustness under realistic hardware
constraints such as parameter quantization and phase noise. These results
establish OIMs as a fast, energy-efficient substrate for neuromorphic learning,
and suggest that EBMs - often bottlenecked by conventional processors - may
find practical realization on physical hardware whose dynamics directly perform
their optimization.

</details>


### [19] [Neural Triangular Transport Maps: A New Approach Towards Sampling in Lattice QCD](https://arxiv.org/abs/2510.13112)
*Andrey Bryutkin,Youssef Marzouk*

Main category: cs.LG

TL;DR: 提出了稀疏三角传输映射方法，利用周期性边界条件下晶格图的条件独立结构，通过单调整流神经网络解决晶格场理论采样中的多模态和长程相关性挑战。


<details>
  <summary>Details</summary>
Motivation: 晶格场理论是计算物理学的基础测试平台，但由于多模态和长程相关性，采样其玻尔兹曼分布仍然具有挑战性。归一化流提供了有希望的替代方案，但在大晶格上的应用受到内存需求和模型表达能力维持的限制。

Method: 提出了稀疏三角传输映射，利用周期性边界条件下晶格图的条件独立结构，使用单调整流神经网络。通过将每个三角映射组件限制在局部历史中，实现站点并行评估和线性时间复杂度，同时保持可表达、可逆的结构。

Result: 在二维φ⁴理论中作为受控设置，分析了节点标记如何影响三角映射的稀疏性和性能。与混合蒙特卡洛和现有流方法进行了比较。

Conclusion: 稀疏三角传输映射提供了一种在保持计算可处理性的同时，有效利用目标分布条件独立结构的方法，为大规模晶格场理论采样提供了可行的解决方案。

Abstract: Lattice field theories are fundamental testbeds for computational physics;
yet, sampling their Boltzmann distributions remains challenging due to
multimodality and long-range correlations. While normalizing flows offer a
promising alternative, their application to large lattices is often constrained
by prohibitive memory requirements and the challenge of maintaining sufficient
model expressivity. We propose sparse triangular transport maps that explicitly
exploit the conditional independence structure of the lattice graph under
periodic boundary conditions using monotone rectified neural networks (MRNN).
We introduce a comprehensive framework for triangular transport maps that
navigates the fundamental trade-off between \emph{exact sparsity} (respecting
marginal conditional independence in the target distribution) and
\emph{approximate sparsity} (computational tractability without fill-ins).
Restricting each triangular map component to a local past enables site-wise
parallel evaluation and linear time complexity in lattice size $N$, while
preserving the expressive, invertible structure. Using $\phi^4$ in two
dimensions as a controlled setting, we analyze how node labelings (orderings)
affect the sparsity and performance of triangular maps. We compare against
Hybrid Monte Carlo (HMC) and established flow approaches (RealNVP).

</details>


### [20] [Pruning Cannot Hurt Robustness: Certified Trade-offs in Reinforcement Learning](https://arxiv.org/abs/2510.12939)
*James Pedley,Benjamin Etheridge,Stephen J. Roberts,Francesco Quinzan*

Main category: cs.LG

TL;DR: 该论文首次为状态对抗马尔可夫决策过程（SA-MDPs）中的剪枝认证鲁棒性建立了理论框架，证明了元素级剪枝只会增强认证鲁棒性边界，揭示了性能-鲁棒性前沿，并在实验中发现了中等稀疏度下的鲁棒性提升。


<details>
  <summary>Details</summary>
Motivation: 现实世界中部署的强化学习策略需要在对抗扰动下保持可靠性，而现代深度强化学习代理过度参数化导致成本增加和脆弱性问题。虽然剪枝在监督学习中已被证明能提高鲁棒性，但其在对抗强化学习中的作用尚不明确。

Method: 开发了首个在SA-MDPs中剪枝认证鲁棒性的理论框架，针对高斯和分类策略的Lipschitz网络，证明了元素级剪枝能收紧鲁棒性边界。基于此推导了三项遗憾分解，区分了清洁任务性能、剪枝引起的性能损失和鲁棒性增益。

Result: 在连续控制基准测试中评估了幅度和微剪枝策略，发现在中等稀疏度下存在可复现的"甜蜜点"，鲁棒性显著提升且不损害（有时甚至提升）清洁性能。

Conclusion: 剪枝不仅是压缩工具，更是强化学习鲁棒性的结构性干预手段，能有效平衡性能与鲁棒性。

Abstract: Reinforcement learning (RL) policies deployed in real-world environments must
remain reliable under adversarial perturbations. At the same time, modern deep
RL agents are heavily over-parameterized, raising costs and fragility concerns.
While pruning has been shown to improve robustness in supervised learning, its
role in adversarial RL remains poorly understood. We develop the first
theoretical framework for certified robustness under pruning in
state-adversarial Markov decision processes (SA-MDPs). For Gaussian and
categorical policies with Lipschitz networks, we prove that element-wise
pruning can only tighten certified robustness bounds; pruning never makes the
policy less robust. Building on this, we derive a novel three-term regret
decomposition that disentangles clean-task performance, pruning-induced
performance loss, and robustness gains, exposing a fundamental
performance--robustness frontier. Empirically, we evaluate magnitude and
micro-pruning schedules on continuous-control benchmarks with strong
policy-aware adversaries. Across tasks, pruning consistently uncovers
reproducible ``sweet spots'' at moderate sparsity levels, where robustness
improves substantially without harming - and sometimes even enhancing - clean
performance. These results position pruning not merely as a compression tool
but as a structural intervention for robust RL.

</details>


### [21] [An Investigation of Memorization Risk in Healthcare Foundation Models](https://arxiv.org/abs/2510.12950)
*Sana Tonekaboni,Lena Stempfle,Adibvafa Fallahpour,Walter Gerych,Marzyeh Ghassemi*

Main category: cs.LG

TL;DR: 提出了一套黑盒评估测试来评估基于结构化电子健康记录数据训练的基础模型中的隐私相关记忆风险，包括嵌入层和生成层的记忆探测方法，并发布了开源工具包。


<details>
  <summary>Details</summary>
Motivation: 基础模型在大型去标识化电子健康记录上的训练具有临床应用前景，但其记忆患者信息的能力引发了重要的隐私担忧，特别是对弱势群体的隐私威胁。

Method: 开发了黑盒评估框架，包含在嵌入层和生成层探测记忆的方法，旨在区分模型泛化和有害记忆，并在临床相关环境中验证。

Result: 在公开可用的电子健康记录基础模型上验证了该方法，并发布了开源工具包以促进医疗AI中可重现和协作的隐私评估。

Conclusion: 该工作为评估医疗基础模型中的隐私记忆风险提供了系统框架，有助于识别和缓解患者隐私泄露风险，特别是对弱势群体的保护。

Abstract: Foundation models trained on large-scale de-identified electronic health
records (EHRs) hold promise for clinical applications. However, their capacity
to memorize patient information raises important privacy concerns. In this
work, we introduce a suite of black-box evaluation tests to assess
privacy-related memorization risks in foundation models trained on structured
EHR data. Our framework includes methods for probing memorization at both the
embedding and generative levels, and aims to distinguish between model
generalization and harmful memorization in clinically relevant settings. We
contextualize memorization in terms of its potential to compromise patient
privacy, particularly for vulnerable subgroups. We validate our approach on a
publicly available EHR foundation model and release an open-source toolkit to
facilitate reproducible and collaborative privacy assessments in healthcare AI.

</details>


### [22] [A Multimodal XAI Framework for Trustworthy CNNs and Bias Detection in Deep Representation Learning](https://arxiv.org/abs/2510.12957)
*Noor Islam S. Mohammad*

Main category: cs.LG

TL;DR: 提出了一种新颖的多模态可解释AI框架，通过注意力增强特征融合、Grad-CAM++局部解释和Reveal-to-Revise反馈循环来检测和缓解偏见，在MNIST多模态扩展数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 标准基准数据集（如MNIST）往往无法暴露潜在偏见和多模态特征复杂性，限制了深度神经网络在高风险应用中的可信度。

Method: 统一了注意力增强特征融合、基于Grad-CAM++的局部解释，以及用于偏见检测和缓解的Reveal-to-Revise反馈循环。

Result: 在MNIST多模态扩展数据集上达到93.2%分类准确率、91.6% F1分数和78.1%解释保真度（IoU-XAI），优于单模态和非可解释基线方法。

Conclusion: 该工作弥合了性能、透明度和公平性之间的差距，为敏感领域的可信AI提供了一条实用路径。

Abstract: Standard benchmark datasets, such as MNIST, often fail to expose latent
biases and multimodal feature complexities, limiting the trustworthiness of
deep neural networks in high-stakes applications. We propose a novel multimodal
Explainable AI (XAI) framework that unifies attention-augmented feature fusion,
Grad-CAM++-based local explanations, and a Reveal-to-Revise feedback loop for
bias detection and mitigation. Evaluated on multimodal extensions of MNIST, our
approach achieves 93.2% classification accuracy, 91.6% F1-score, and 78.1%
explanation fidelity (IoU-XAI), outperforming unimodal and non-explainable
baselines. Ablation studies demonstrate that integrating interpretability with
bias-aware learning enhances robustness and human alignment. Our work bridges
the gap between performance, transparency, and fairness, highlighting a
practical pathway for trustworthy AI in sensitive domains.

</details>


### [23] [Balancing Performance and Reject Inclusion: A Novel Confident Inlier Extrapolation Framework for Credit Scoring](https://arxiv.org/abs/2510.12967)
*Athyrson Machado Ribeiro,Marcos Medeiros Raimundo*

Main category: cs.LG

TL;DR: 提出了一种新的拒绝推断框架CI-EX，通过异常检测识别拒绝客户样本分布，基于分类模型概率为最接近接受人群分布的拒绝个体分配标签，在保持AUC竞争力的同时，在拒绝推断特定指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统拒绝推断方法假设拒绝客户行为可以从接受客户外推的问题，避免盲目外推带来的分布差异风险。

Method: CI-EX框架迭代使用异常检测模型识别拒绝客户样本分布，基于监督分类模型的概率为最接近接受人群分布的拒绝个体分配标签。

Result: 在两个大型真实信用数据集上的实验表明，CI-EX在拒绝推断特定指标（如Kickout和Area under the Kickout）上优于现有方法，同时在AUC指标上保持竞争力。

Conclusion: 拒绝推断方法通常需要在AUC和拒绝推断特定指标之间权衡，但提出的CI-EX框架在拒绝推断特定指标上表现更优，同时保持AUC竞争力。

Abstract: Reject Inference (RI) methods aim to address sample bias by inferring missing
repayment data for rejected credit applicants. Traditional approaches often
assume that the behavior of rejected clients can be extrapolated from accepted
clients, despite potential distributional differences between the two
populations. To mitigate this blind extrapolation, we propose a novel Confident
Inlier Extrapolation framework (CI-EX). CI-EX iteratively identifies the
distribution of rejected client samples using an outlier detection model and
assigns labels to rejected individuals closest to the distribution of the
accepted population based on probabilities derived from a supervised
classification model. The effectiveness of our proposed framework is validated
through experiments on two large real-world credit datasets. Performance is
evaluated using the Area Under the Curve (AUC) as well as RI-specific metrics
such as Kickout and a novel metric introduced in this work, denoted as Area
under the Kickout. Our findings reveal that RI methods, including the proposed
framework, generally involve a trade-off between AUC and RI-specific metrics.
However, the proposed CI-EX framework consistently outperforms existing RI
models from the credit literature in terms of RI-specific metrics while
maintaining competitive performance in AUC across most experiments.

</details>


### [24] [A Connection Between Score Matching and Local Intrinsic Dimension](https://arxiv.org/abs/2510.12975)
*Eric Yeats,Aaron Jacobson,Darryl Hannan,Yiran Jia,Timothy Doster,Henry Kvinge,Scott Mahan*

Main category: cs.LG

TL;DR: 论文提出使用去噪分数匹配损失作为局部内在维度(LID)的估计器，该方法比现有方法更高效且可扩展。


<details>
  <summary>Details</summary>
Motivation: 现有量化高维复杂数据LID的方法需要多次前向传播或梯度计算，在计算和内存受限场景下适用性有限。

Method: 证明LID是去噪分数匹配损失的下界，从而将其用作LID估计器，并与隐式分数匹配损失和FLIPD估计器建立联系。

Result: 在流形基准测试和Stable Diffusion 3.5上的实验表明，该方法在精度和内存占用方面具有竞争优势，且随着问题规模和量化级别的增加表现更优。

Conclusion: 去噪分数匹配损失是一种高效、可扩展的LID估计方法，特别适用于计算和内存受限的场景。

Abstract: The local intrinsic dimension (LID) of data is a fundamental quantity in
signal processing and learning theory, but quantifying the LID of
high-dimensional, complex data has been a historically challenging task. Recent
works have discovered that diffusion models capture the LID of data through the
spectra of their score estimates and through the rate of change of their
density estimates under various noise perturbations. While these methods can
accurately quantify LID, they require either many forward passes of the
diffusion model or use of gradient computation, limiting their applicability in
compute- and memory-constrained scenarios.
  We show that the LID is a lower bound on the denoising score matching loss,
motivating use of the denoising score matching loss as a LID estimator.
Moreover, we show that the equivalent implicit score matching loss also
approximates LID via the normal dimension and is closely related to a recent
LID estimator, FLIPD. Our experiments on a manifold benchmark and with Stable
Diffusion 3.5 indicate that the denoising score matching loss is a highly
competitive and scalable LID estimator, achieving superior accuracy and memory
footprint under increasing problem size and quantization level.

</details>


### [25] [Reference-Specific Unlearning Metrics Can Hide the Truth: A Reality Check](https://arxiv.org/abs/2510.12981)
*Sungjun Cho,Dasol Hwang,Frederic Sala,Sangheum Hwang,Kyunghyun Cho,Sungmin Cha*

Main category: cs.LG

TL;DR: 提出FADE指标，通过比较未学习模型与参考模型在生成样本上的双向似然分配来评估分布相似性，解决现有遗忘指标依赖特定参考的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前生成模型的遗忘指标基于参考响应或分类器输出评估，而非核心目标——未学习模型是否与从未见过不需要数据的模型行为无法区分，这种参考特定方法存在系统性盲点。

Method: 提出功能对齐分布等价性(FADE)指标，通过比较未学习模型和参考模型在生成样本上的双向似然分配来测量分布相似性，捕捉整个输出分布的功能对齐。

Result: 在TOFU和UnlearnCanvas基准测试中，传统指标接近最优的方法未能实现分布等价性，许多方法比遗忘前更远离黄金标准。

Conclusion: 现有评估实践存在根本性差距，FADE为开发和评估真正有效的遗忘方法提供了更稳健的基础。

Abstract: Current unlearning metrics for generative models evaluate success based on
reference responses or classifier outputs rather than assessing the core
objective: whether the unlearned model behaves indistinguishably from a model
that never saw the unwanted data. This reference-specific approach creates
systematic blind spots, allowing models to appear successful while retaining
unwanted knowledge accessible through alternative prompts or attacks. We
address these limitations by proposing Functional Alignment for Distributional
Equivalence (FADE), a novel metric that measures distributional similarity
between unlearned and reference models by comparing bidirectional likelihood
assignments over generated samples. Unlike existing approaches that rely on
predetermined references, FADE captures functional alignment across the entire
output distribution, providing a principled assessment of genuine unlearning.
Our experiments on the TOFU benchmark for LLM unlearning and the UnlearnCanvas
benchmark for text-to-image diffusion model unlearning reveal that methods
achieving near-optimal scores on traditional metrics fail to achieve
distributional equivalence, with many becoming more distant from the gold
standard than before unlearning. These findings expose fundamental gaps in
current evaluation practices and demonstrate that FADE provides a more robust
foundation for developing and assessing truly effective unlearning methods.

</details>


### [26] [CSI-4CAST: A Hybrid Deep Learning Model for CSI Prediction with Comprehensive Robustness and Generalization Testing](https://arxiv.org/abs/2510.12996)
*Sikai Cheng,Reza Zandehshahvar,Haoruo Zhao,Daniel A. Garcia-Ulloa,Alejandro Villena-Rodriguez,Carles Navarro Manchón,Pascal Van Hentenryck*

Main category: cs.LG

TL;DR: CSI-4CAST是一个混合深度学习架构，通过整合CNN残差、自适应校正层、ShuffleNet块和Transformer，有效捕获CSI预测中的局部和长程依赖关系，在计算效率和预测精度方面显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习CSI预测方法在非高斯噪声鲁棒性、跨信道条件泛化能力和计算效率方面存在局限，需要开发更稳健高效的预测模型。

Method: 提出CSI-4CAST混合架构，整合四种关键组件：CNN残差、自适应校正层、ShuffleNet块和Transformer，以高效捕获CSI预测中的局部和长程依赖关系。

Result: 在CSI-RRG基准测试中，CSI-4CAST在88.9%的TDD场景和43.8%的FDD场景中表现最佳，相比最强基线LLM4CP，FLOPs分别减少5倍和3倍。

Conclusion: CSI-4CAST在CSI预测精度和计算效率方面显著优于现有方法，同时发布的CSI-RRG数据集和评估协议为稳健高效的CSI预测研究建立了标准化基准。

Abstract: Channel state information (CSI) prediction is a promising strategy for
ensuring reliable and efficient operation of massive multiple-input
multiple-output (mMIMO) systems by providing timely downlink (DL) CSI. While
deep learning-based methods have advanced beyond conventional model-driven and
statistical approaches, they remain limited in robustness to practical
non-Gaussian noise, generalization across diverse channel conditions, and
computational efficiency. This paper introduces CSI-4CAST, a hybrid deep
learning architecture that integrates 4 key components, i.e., Convolutional
neural network residuals, Adaptive correction layers, ShuffleNet blocks, and
Transformers, to efficiently capture both local and long-range dependencies in
CSI prediction. To enable rigorous evaluation, this work further presents a
comprehensive benchmark, CSI-RRG for Regular, Robustness and Generalization
testing, which includes more than 300,000 samples across 3,060 realistic
scenarios for both TDD and FDD systems. The dataset spans multiple channel
models, a wide range of delay spreads and user velocities, and diverse noise
types and intensity degrees. Experimental results show that CSI-4CAST achieves
superior prediction accuracy with substantially lower computational cost,
outperforming baselines in 88.9% of TDD scenarios and 43.8% of FDD scenario,
the best performance among all evaluated models, while reducing FLOPs by 5x and
3x compared to LLM4CP, the strongest baseline. In addition, evaluation over
CSI-RRG provides valuable insights into how different channel factors affect
the performance and generalization capability of deep learning models. Both the
dataset (https://huggingface.co/CSI-4CAST) and evaluation protocols
(https://github.com/AI4OPT/CSI-4CAST) are publicly released to establish a
standardized benchmark and to encourage further research on robust and
efficient CSI prediction.

</details>


### [27] [Max It or Miss It: Benchmarking LLM On Solving Extremal Problems](https://arxiv.org/abs/2510.12997)
*Binxin Gao,Jingjun Han*

Main category: cs.LG

TL;DR: 论文提出ExtremBench基准数据集，用于评估LLMs在数学极值问题求解中的推理能力，发现现有数学基准无法全面衡量极值求解等特定推理能力。


<details>
  <summary>Details</summary>
Motivation: 理解LLMs推理能力的来源和机制，特别是优化推理（在约束条件下寻找极值）这一基础抽象能力，该能力在规划、控制和资源分配等应用中至关重要。

Method: 引入ExtremBench基准数据集，包含93个标准化极值求解问题，源自中国数学奥林匹克不等式练习。对Qwen3、GPT-OSS和DeepSeek等开源模型进行广泛评估。

Result: 发现LLMs的极值求解推理能力与当前数学基准（如AIME25和MATH-500）的评估结果不一致，有些模型在通用数学推理上表现良好但在极值求解上较差，反之亦然。

Conclusion: 现有基准可能无法全面捕捉数学推理能力的全谱系，揭示了当前评估实践中的关键差距。

Abstract: Test-time scaling has enabled Large Language Models (LLMs) with remarkable
reasoning capabilities, particularly in mathematical domains, through
intermediate chain-of-thought (CoT) reasoning before generating final answers.
However, the specific sources and mechanisms underlying these reasoning
capabilities remain insufficiently understood. Optimization reasoning, i.e.
finding extrema under constraints, represents a fundamental abstraction that
underpins critical applications in planning, control, resource allocation, and
prompt search. To systematically evaluate this capability, we introduce
ExtremBench, a benchmark dataset for solving mathematical extremal problems,
curated from inequality exercises used for Chinese Mathematical Olympiad and
transformed into $93$ standardized extrema-finding problems. We conduct
extensive evaluations across various state-of-the-art open-source model
families, including the Qwen3, GPT-OSS, and DeepSeek. Our results reveal that
LLMs' extremal-solving reasoning capabilities do not always align with those of
current mathematical benchmarks such as AIME25 and MATH-500, with some models
showing strong general mathematical reasoning but poor extremal-solving skills,
and vice versa. This discrepancy highlights a critical gap in current
evaluation practices and suggests that existing benchmarks may not
comprehensively capture the full spectrum of mathematical reasoning abilities.

</details>


### [28] [AMORE: Adaptive Multi-Output Operator Network for Stiff Chemical Kinetics](https://arxiv.org/abs/2510.12999)
*Kamaljyoti Nath,Additi Pandey,Bryan T. Susi,Hessam Babaee,George Em Karniadakis*

Main category: cs.LG

TL;DR: AMORE是一个自适应多输出算子网络框架，用于解决化学反应系统中的刚性积分问题，通过自适应损失函数和约束满足技术来预测热化学状态。


<details>
  <summary>Details</summary>
Motivation: 刚性系统的时间积分是燃烧、高超声速等反应输运系统的主要计算成本来源，需要开发能够缓解刚性挑战的可靠算子学习策略。

Method: 开发AMORE框架，包含多输出预测算子和自适应损失函数；设计自动满足单位分割的trunk网络；提出可逆分析映射来精确执行质量分数约束；采用两步训练方法并扩展自适应损失函数。

Result: 在合成气（12个状态）和GRI-Mech 3.0（54个状态中的24个活跃状态）两个示例中验证了模型的有效性和适用性。

Conclusion: AMORE是一个通用框架，提出的DeepONet将成为未来CFD研究中加速湍流燃烧模拟的基础，该框架也可应用于FNO等其他算子。

Abstract: Time integration of stiff systems is a primary source of computational cost
in combustion, hypersonics, and other reactive transport systems. This
stiffness can introduce time scales significantly smaller than those associated
with other physical processes, requiring extremely small time steps in explicit
schemes or computationally intensive implicit methods. Consequently, strategies
to alleviate challenges posed by stiffness are important. While neural
operators (DeepONets) can act as surrogates for stiff kinetics, a reliable
operator learning strategy is required to appropriately account for differences
in the error between output variables and samples. Here, we develop AMORE,
Adaptive Multi-Output Operator Network, a framework comprising an operator
capable of predicting multiple outputs and adaptive loss functions ensuring
reliable operator learning. The operator predicts all thermochemical states
from given initial conditions. We propose two adaptive loss functions within
the framework, considering each state variable's and sample's error to penalize
the loss function. We designed the trunk to automatically satisfy Partition of
Unity. To enforce unity mass-fraction constraint exactly, we propose an
invertible analytical map that transforms the $n$-dimensional species
mass-fraction vector into an ($n-1$)-dimensional space, where DeepONet training
is performed. We consider two-step training for DeepONet for multiple outputs
and extend adaptive loss functions for trunk and branch training. We
demonstrate the efficacy and applicability of our models through two examples:
the syngas (12 states) and GRI-Mech 3.0 (24 active states out of 54). The
proposed DeepONet will be a backbone for future CFD studies to accelerate
turbulent combustion simulations. AMORE is a general framework, and here, in
addition to DeepONet, we also demonstrate it for FNO.

</details>


### [29] [Escaping Local Optima in the Waddington Landscape: A Multi-Stage TRPO-PPO Approach for Single-Cell Perturbation Analysis](https://arxiv.org/abs/2510.13018)
*Francis Boabang,Samuel Asante Gyamerah*

Main category: cs.LG

TL;DR: 提出了一种针对单细胞扰动建模的多阶段强化学习算法，通过自然梯度更新和PPO优化，显著提高了单细胞测序数据分析的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动模型在细胞命运决策的非凸Waddington景观中容易陷入局部最优，导致轨迹陷入虚假谱系或不合理的分化结果，需要设计良好的初始化方法来逃离局部最优并收敛到正确的谱系。

Method: 多阶段强化学习算法：第一阶段使用Fisher向量积和共轭梯度求解器计算显式自然梯度更新，通过KL信任域约束提供安全、曲率感知的策略第一步；第二阶段应用带裁剪代理的近端策略优化（PPO），利用小批量效率优化策略。

Result: 该初始化方法显著提高了在单细胞RNA测序（scRNA-seq）和单细胞ATAC测序（scATAC-seq）扰动分析中的泛化能力。

Conclusion: 提出的多阶段强化学习算法通过精心设计的初始化策略，有效解决了单细胞扰动建模中的局部最优问题，为细胞命运决策预测提供了更可靠的解决方案。

Abstract: Modeling cellular responses to genetic and chemical perturbations remains a
central challenge in single-cell biology. Existing data-driven framework have
advanced perturbation prediction through variational autoencoders, chemically
conditioned autoencoders, and large-scale transformer pretraining. However,
these models are prone to local optima in the nonconvex Waddington landscape of
cell fate decisions, where poor initialization can trap trajectories in
spurious lineages or implausible differentiation outcomes. While executable
gene regulatory networks complement these approaches, automated design
frameworks incorporate biological priors through multi-agent optimization. Yet,
an approach that is completely data-driven with well-designed initialization to
escape local optima and converge to a proper lineage remains elusive. In this
work, we introduce a multistage reinforcement learning algorithm tailored for
single-cell perturbation modeling. We first compute an explicit natural
gradient update using Fisher-vector products and a conjugate gradient solver,
scaled by a KL trust-region constraint to provide a safe, curvature-aware the
first step for the policy. Starting with these preconditioned parameters, we
then apply a second phase of proximal policy optimization (PPO) with clipped
surrogates, exploiting minibatch efficiency to refine the policy. We
demonstrate that this initialization substantially improves generalization on
Single-cell RNA sequencing (scRNA-seq) and Single-cell ATAC sequencing
(scATAC-seq) pertubation analysis.

</details>


### [30] [Information Shapes Koopman Representation](https://arxiv.org/abs/2510.13025)
*Xiaoyuan Cheng,Wenxuan Yuan,Yiming Yang,Yuanzhao Zhang,Sibo Cheng,Yi He,Zhuo Sun*

Main category: cs.LG

TL;DR: 本文提出了一种基于信息论的Koopman算子学习方法，通过平衡潜在表示的表达性和简洁性来改进深度架构中的Koopman学习。


<details>
  <summary>Details</summary>
Motivation: Koopman算子的无限维特性使得寻找合适的有限维子空间具有挑战性，特别是在深度架构中。作者认为这些困难源于次优的表示学习，其中潜在变量未能平衡表达性和简洁性。

Method: 提出了一种信息论拉格朗日公式，明确平衡潜在互信息（促进简洁性）和冯·诺依曼熵（防止模式崩溃并鼓励模式多样性）之间的权衡。基于此开发了新算法。

Result: 在多种动力系统上验证了该方法，相比现有Koopman学习方法表现出改进的性能。可视化学习到的流形与理论预测一致。

Conclusion: 通过信息论视角重新思考Koopman学习，提出的方法能够产生稳定且可解释的Koopman表示，平衡了表达性和简洁性之间的权衡。

Abstract: The Koopman operator provides a powerful framework for modeling dynamical
systems and has attracted growing interest from the machine learning community.
However, its infinite-dimensional nature makes identifying suitable
finite-dimensional subspaces challenging, especially for deep architectures. We
argue that these difficulties come from suboptimal representation learning,
where latent variables fail to balance expressivity and simplicity. This
tension is closely related to the information bottleneck (IB) dilemma:
constructing compressed representations that are both compact and predictive.
Rethinking Koopman learning through this lens, we demonstrate that latent
mutual information promotes simplicity, yet an overemphasis on simplicity may
cause latent space to collapse onto a few dominant modes. In contrast,
expressiveness is sustained by the von Neumann entropy, which prevents such
collapse and encourages mode diversity. This insight leads us to propose an
information-theoretic Lagrangian formulation that explicitly balances this
tradeoff. Furthermore, we propose a new algorithm based on the Lagrangian
formulation that encourages both simplicity and expressiveness, leading to a
stable and interpretable Koopman representation. Beyond quantitative
evaluations, we further visualize the learned manifolds under our
representations, observing empirical results consistent with our theoretical
predictions. Finally, we validate our approach across a diverse range of
dynamical systems, demonstrating improved performance over existing Koopman
learning methods. The implementation is publicly available at
https://github.com/Wenxuan52/InformationKoopman.

</details>


### [31] [Bridging Idealized and Operational Models: An Explainable AI Framework for Earth System Emulators](https://arxiv.org/abs/2510.13030)
*Pouria Behnoudfar,Charlotte Moser,Marc Bocquet,Sibo Cheng,Nan Chen*

Main category: cs.LG

TL;DR: 开发了一个可解释的AI框架，通过结合高分辨率操作模型和理想化模型的优势，构建地球系统模拟器，显著改善了CMIP6中厄尔尼诺模式的模拟偏差。


<details>
  <summary>Details</summary>
Motivation: 高分辨率操作模型在模拟极端事件和统计分布时存在持续偏差，而理想化模型虽然能精确校准特定特征，但不同模型之间存在学科壁垒。需要结合不同复杂度模型的互补优势。

Method: 采用重新配置的潜在数据同化技术，构建桥接模型层次的可解释AI框架，利用理想化模型的稀疏输出，继承操作模型的高分辨率和全面变量。

Result: 桥接模型在保持高分辨率的同时，通过理想化模型的针对性改进实现了全局精度提升，显著纠正了CMIP6中厄尔尼诺时空模式的模拟偏差。

Conclusion: 该框架超越了黑盒修正，提供了物理洞察力，支持高效计算下的物理辅助数字孪生和不确定性量化，强调了推动理想化模型发展和建模社区间交流的重要性。

Abstract: Computer models are indispensable tools for understanding the Earth system.
While high-resolution operational models have achieved many successes, they
exhibit persistent biases, particularly in simulating extreme events and
statistical distributions. In contrast, coarse-grained idealized models isolate
fundamental processes and can be precisely calibrated to excel in
characterizing specific dynamical and statistical features. However, different
models remain siloed by disciplinary boundaries. By leveraging the
complementary strengths of models of varying complexity, we develop an
explainable AI framework for Earth system emulators. It bridges the model
hierarchy through a reconfigured latent data assimilation technique, uniquely
suited to exploit the sparse output from the idealized models. The resulting
bridging model inherits the high resolution and comprehensive variables of
operational models while achieving global accuracy enhancements through
targeted improvements from idealized models. Crucially, the mechanism of AI
provides a clear rationale for these advancements, moving beyond black-box
correction to physically insightful understanding in a computationally
efficient framework that enables effective physics-assisted digital twins and
uncertainty quantification. We demonstrate its power by significantly
correcting biases in CMIP6 simulations of El Ni\~no spatiotemporal patterns,
leveraging statistically accurate idealized models. This work also highlights
the importance of pushing idealized model development and advancing
communication between modeling communities.

</details>


### [32] [Randomness and Interpolation Improve Gradient Descent](https://arxiv.org/abs/2510.13040)
*Jiawen Li,Pascal Lefevre,Anwar Pp Abdul Majeed*

Main category: cs.LG

TL;DR: 本文提出了两种基于SGD的优化器：IAGD和NRSGD，分别通过牛顿插值加速收敛和噪声正则化防止过拟合，在CIFAR数据集上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 改进传统SGD优化器的性能，通过加速收敛和防止过拟合来提升深度学习模型的训练效果。

Method: IAGD利用二阶牛顿插值加速梯度下降收敛过程，假设迭代间梯度相关性；NRSGD通过向梯度添加受控噪声实现正则化防止过拟合。

Result: 在CIFAR-10和CIFAR-100数据集上的实验表明，这两种方法相比Keras中的经典优化器具有更好的性能。

Conclusion: IAGD和NRSGD是SGD的有效改进方法，展示了在深度学习优化中的潜力。

Abstract: Based on Stochastic Gradient Descent (SGD), the paper introduces two
optimizers, named Interpolational Accelerating Gradient Descent (IAGD) as well
as Noise-Regularized Stochastic Gradient Descent (NRSGD). IAGD leverages
second-order Newton Interpolation to expedite the convergence process during
training, assuming relevancy in gradients between iterations. To avoid
over-fitting, NRSGD incorporates a noise regularization technique that
introduces controlled noise to the gradients during the optimization process.
Comparative experiments of this research are conducted on the CIFAR-10, and
CIFAR-100 datasets, benchmarking different CNNs(Convolutional Neural Networks)
with IAGD and NRSGD against classical optimizers in Keras Package. Results
demonstrate the potential of those two viable improvement methods in SGD,
implicating the effectiveness of the advancements.

</details>


### [33] [An Operational Deep Learning System for Satellite-Based High-Resolution Global Nowcasting](https://arxiv.org/abs/2510.13050)
*Shreya Agrawal,Mohammed Alewi Hassen,Emmanuel Asiedu Brempong,Boris Babenko,Fred Zyda,Olivia Graham,Di Li,Samier Merchant,Santiago Hincapie Potes,Tyler Russell,Danny Cheresnick,Aditya Prakash Kakkirala,Stephan Rasp,Avinatan Hassidim,Yossi Matias,Nal Kalchbrenner,Pramod Gupta,Jason Hickey,Aaron Bell*

Main category: cs.LG

TL;DR: Global MetNet是一个基于机器学习的全球降水临近预报模型，利用卫星和NWP数据在数据稀疏地区提供高分辨率预报，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决全球南方地区因雷达覆盖稀疏而无法使用传统机器学习预报方法的问题，减少全球预报质量差异。

Method: 利用全球降水任务CORRA数据集、地球静止卫星数据和全球NWP数据，构建高分辨率（约5km，15分钟）的机器学习预报模型。

Result: 在12小时预报范围内显著优于行业标准小时预报，在数据稀疏地区表现优于美国高分辨率NWP模型，预报生成时间不到1分钟。

Conclusion: 该模型代表了减少全球预报质量差异和将稀疏高分辨率卫星观测整合到天气预报中的关键一步，已在Google搜索中为百万用户部署。

Abstract: Precipitation nowcasting, which predicts rainfall up to a few hours ahead, is
a critical tool for vulnerable communities in the Global South frequently
exposed to intense, rapidly developing storms. Timely forecasts provide a
crucial window to protect lives and livelihoods. Traditional numerical weather
prediction (NWP) methods suffer from high latency, low spatial and temporal
resolution, and significant gaps in accuracy across the world. Recent machine
learning-based nowcasting methods, common in the Global North, cannot be
extended to the Global South due to extremely sparse radar coverage. We present
Global MetNet, an operational global machine learning nowcasting model. It
leverages the Global Precipitation Mission's CORRA dataset, geostationary
satellite data, and global NWP data to predict precipitation for the next 12
hours. The model operates at a high resolution of approximately 0.05{\deg}
(~5km) spatially and 15 minutes temporally. Global MetNet significantly
outperforms industry-standard hourly forecasts and achieves significantly
higher skill, making forecasts useful over a much larger area of the world than
previously available. Our model demonstrates better skill in data-sparse
regions than even the best high-resolution NWP models achieve in the US.
Validated using ground radar and satellite data, it shows significant
improvements across key metrics like the critical success index and fractions
skill score for all precipitation rates and lead times. Crucially, our model
generates forecasts in under a minute, making it readily deployable for
real-time applications. It is already deployed for millions of users on Google
Search. This work represents a key step in reducing global disparities in
forecast quality and integrating sparse, high-resolution satellite observations
into weather forecasting.

</details>


### [34] [Time-Varying Optimization for Streaming Data Via Temporal Weighting](https://arxiv.org/abs/2510.13052)
*Muhammad Faraz Ul Abrar,Nicolò Michelusi,Erik G. Larsson*

Main category: cs.LG

TL;DR: 本文通过时变优化视角研究流数据学习问题，提出了基于权重的结构化公式，分析了均匀权重和折扣权重两种策略下的跟踪误差界限。


<details>
  <summary>Details</summary>
Motivation: 传统优化理论处理固定目标函数，而时变优化在动态环境决策中日益重要。本文旨在从流数据学习的角度研究时变优化问题，特别关注数据来源的结构化建模。

Method: 引入基于权重的结构化公式，明确捕捉流数据的时变目标特性。采用梯度下降更新，分析均匀权重（平等对待所有样本）和折扣权重（几何衰减旧数据影响）两种策略。

Result: 均匀权重下跟踪误差以O(1/t)速率渐近消失，折扣权重下存在非零误差下限，由折扣因子和每时间步梯度更新次数控制。数值模拟验证了理论发现。

Conclusion: 权重策略对跟踪误差有显著影响：均匀权重可实现渐近精确跟踪，而折扣权重在跟踪精度和遗忘旧数据间存在权衡，误差下限受算法参数控制。

Abstract: Classical optimization theory deals with fixed, time-invariant objective
functions. However, time-varying optimization has emerged as an important
subject for decision-making in dynamic environments. In this work, we study the
problem of learning from streaming data through a time-varying optimization
lens. Unlike prior works that focus on generic formulations, we introduce a
structured, \emph{weight-based} formulation that explicitly captures the
streaming-data origin of the time-varying objective, where at each time step,
an agent aims to minimize a weighted average loss over all the past data
samples. We focus on two specific weighting strategies: (1) uniform weights,
which treat all samples equally, and (2) discounted weights, which
geometrically decay the influence of older data. For both schemes, we derive
tight bounds on the ``tracking error'' (TE), defined as the deviation between
the model parameter and the time-varying optimum at a given time step, under
gradient descent (GD) updates. We show that under uniform weighting, the TE
vanishes asymptotically with a $\mathcal{O}(1/t)$ decay rate, whereas
discounted weighting incurs a nonzero error floor controlled by the discount
factor and the number of gradient updates performed at each time step. Our
theoretical findings are validated through numerical simulations.

</details>


### [35] [Achieving Logarithmic Regret in KL-Regularized Zero-Sum Markov Games](https://arxiv.org/abs/2510.13060)
*Anupam Nayak,Tong Yang,Osman Yagan,Gauri Joshi,Yuejie Chi*

Main category: cs.LG

TL;DR: 本文研究了KL正则化在博弈论环境中的理论优势，提出了OMG和SOMG算法，在矩阵博弈和马尔可夫博弈中实现了与KL正则化强度β相关的对数级遗憾。


<details>
  <summary>Details</summary>
Motivation: 尽管KL正则化在强化学习和语言模型对齐中取得了显著经验成功，但其在博弈论环境中的理论优势仍不清楚，需要开发可证明样本效率提升的算法。

Method: 针对矩阵博弈提出OMG算法（基于最佳响应采样和乐观奖励），针对马尔可夫博弈提出SOMG算法（使用最佳响应采样和超乐观奖励概念）。

Result: 两种算法都实现了与T相关的对数级遗憾，该遗憾与KL正则化强度β成反比，同时保持了标准的不依赖β的√T遗憾。

Conclusion: KL正则化在博弈论环境中确实能提供理论上的样本效率优势，所提出的算法在正则化和非正则化设置下都能达到最优性能。

Abstract: Reverse Kullback-Leibler (KL) divergence-based regularization with respect to
a fixed reference policy is widely used in modern reinforcement learning to
preserve the desired traits of the reference policy and sometimes to promote
exploration (using uniform reference policy, known as entropy regularization).
Beyond serving as a mere anchor, the reference policy can also be interpreted
as encoding prior knowledge about good actions in the environment. In the
context of alignment, recent game-theoretic approaches have leveraged KL
regularization with pretrained language models as reference policies, achieving
notable empirical success in self-play methods. Despite these advances, the
theoretical benefits of KL regularization in game-theoretic settings remain
poorly understood. In this work, we develop and analyze algorithms that
provably achieve improved sample efficiency under KL regularization. We study
both two-player zero-sum Matrix games and Markov games: for Matrix games, we
propose OMG, an algorithm based on best response sampling with optimistic
bonuses, and extend this idea to Markov games through the algorithm SOMG, which
also uses best response sampling and a novel concept of superoptimistic
bonuses. Both algorithms achieve a logarithmic regret in $T$ that scales
inversely with the KL regularization strength $\beta$ in addition to the
standard $\widetilde{\mathcal{O}}(\sqrt{T})$ regret independent of $\beta$
which is attained in both regularized and unregularized settings

</details>


### [36] [Absolute indices for determining compactness, separability and number of clusters](https://arxiv.org/abs/2510.13065)
*Adil M. Bagirov,Ramiz M. Aliguliyev,Nargiz Sultanova,Sona Taheri*

Main category: cs.LG

TL;DR: 提出了新的绝对聚类指数来评估聚类紧凑性和分离性，通过定义紧凑性函数和邻近点集来确定真实聚类数量。


<details>
  <summary>Details</summary>
Motivation: 现有聚类有效性指数通常是相对的，依赖于数据结构和算法比较，难以识别"真实"聚类。需要开发绝对指标来直接评估聚类质量。

Method: 定义每个聚类的紧凑性函数和聚类对之间的邻近点集，用于计算聚类紧凑性和分布紧凑性，以及聚类间边界和整体分布边界。

Result: 在合成和真实数据集上验证了新指数的性能，与其他广泛使用的聚类有效性指数进行了比较。

Conclusion: 提出的紧凑性和分离性指数能够有效识别真实聚类数量，为聚类质量评估提供了新的绝对指标。

Abstract: Finding "true" clusters in a data set is a challenging problem. Clustering
solutions obtained using different models and algorithms do not necessarily
provide compact and well-separated clusters or the optimal number of clusters.
Cluster validity indices are commonly applied to identify such clusters.
Nevertheless, these indices are typically relative, and they are used to
compare clustering algorithms or choose the parameters of a clustering
algorithm. Moreover, the success of these indices depends on the underlying
data structure. This paper introduces novel absolute cluster indices to
determine both the compactness and separability of clusters. We define a
compactness function for each cluster and a set of neighboring points for
cluster pairs. This function is utilized to determine the compactness of each
cluster and the whole cluster distribution. The set of neighboring points is
used to define the margin between clusters and the overall distribution margin.
The proposed compactness and separability indices are applied to identify the
true number of clusters. Using a number of synthetic and real-world data sets,
we demonstrate the performance of these new indices and compare them with other
widely-used cluster validity indices.

</details>


### [37] [NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models](https://arxiv.org/abs/2510.13068)
*Konstantinos Barmpas,Na Lee,Alexandros Koliousis,Yannis Panagakis,Dimitrios A. Adamos,Nikolaos Laskaris,Stefanos Zafeiriou*

Main category: cs.LG

TL;DR: NeuroRVQ是一种基于码本的脑电信号分词器，通过多尺度特征提取、分层残差向量量化和相位-幅度感知损失函数，解决了现有脑电基础模型在信号重构保真度方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有脑电基础模型的分词模块无法保留高频动态信息，限制了信号重构的保真度，需要开发能够捕捉全频段神经频谱的高性能分词器。

Method: 提出NeuroRVQ分词器，包含：(1)多尺度特征提取模块捕捉全频段神经频谱；(2)分层残差向量量化码本进行高分辨率编码；(3)相位和幅度感知的损失函数进行高效训练。

Result: NeuroRVQ实现了更低的信号重构误差，在各种下游任务中超越了现有的大型脑波模型，建立了基于码本的通用脑波模型的强先验。

Conclusion: NeuroRVQ分词器为基于码本的通用脑波模型建立了强大基础，推动了神经解码、生成建模和多模态生物信号集成的发展。

Abstract: Electroencephalography (EEG) captures neural activity across multiple
temporal and spectral scales, yielding signals that are rich but complex for
representation learning. Recently, EEG foundation models trained to predict
masked signal-tokens have shown promise for learning generalizable
representations. However, their performance is hindered by their signal
tokenization modules. Existing neural tokenizers fail to preserve
high-frequency dynamics, limiting their ability to reconstruct EEG signals with
high fidelity. We introduce NeuroRVQ, a scalable Large Brainwave Model (LBM)
centered on a codebook-based tokenizer. Our tokenizer integrates: (i)
multi-scale feature extraction modules that capture the full frequency neural
spectrum; (ii) hierarchical residual vector quantization (RVQ) codebooks for
high-resolution encoding; and, (iii) an EEG signal phase- and amplitude-aware
loss function for efficient training. This design enables efficient EEG
compression while supporting accurate reconstruction across all frequency
bands, leading to robust generative masked modeling. Our empirical results
demonstrate that NeuroRVQ achieves lower reconstruction error and outperforms
existing LBMs on a variety of downstream tasks. More broadly, NeuroRVQ
tokenizer establishes a strong prior for codebook-based general-purpose
brainwave models, enabling advances in neural decoding, generative modeling and
multimodal biosignal integration.

</details>


### [38] [Transformer-based Scalable Beamforming Optimization via Deep Residual Learning](https://arxiv.org/abs/2510.13077)
*Yubo Zhang,Xiao-Yang Liu,Xiaodong Wang*

Main category: cs.LG

TL;DR: 提出了一种基于Transformer的无监督深度学习框架，用于大规模MU-MISO系统的下行波束成形，通过离线训练实现实时推理，在动态通信环境中具有快速计算优势。


<details>
  <summary>Details</summary>
Motivation: 解决大规模多用户MISO系统中下行波束成形的计算复杂度问题，传统迭代算法如WMMSE在实时应用中计算负担重，需要开发能够快速推理的深度学习解决方案。

Method: 采用学习优化范式，使用多层Transformer通过残差连接迭代优化信道和波束成形器特征，并引入课程学习、半摊销学习和滑动窗口训练三种策略来增强训练效果。

Result: 在低到中等信噪比下优于现有基线方法，在高信噪比下接近WMMSE性能，同时推理速度显著快于迭代和在线学习方法。

Conclusion: 该无监督深度学习框架为大规模MU-MISO系统提供了一种高效的下行波束成形解决方案，在性能和计算效率之间取得了良好平衡。

Abstract: We develop an unsupervised deep learning framework for downlink beamforming
in large-scale MU-MISO channels. The model is trained offline, allowing
real-time inference through lightweight feedforward computations in dynamic
communication environments. Following the learning-to-optimize (L2O) paradigm,
a multi-layer Transformer iteratively refines both channel and beamformer
features via residual connections. To enhance training, three strategies are
introduced: (i) curriculum learning (CL) to improve early-stage convergence and
avoid local optima, (ii) semi-amortized learning to refine each Transformer
block with a few gradient ascent steps, and (iii) sliding-window training to
stabilize optimization by training only a subset of Transformer blocks at a
time. Extensive simulations show that the proposed scheme outperforms existing
baselines at low-to-medium SNRs and closely approaches WMMSE performance at
high SNRs, while achieving substantially faster inference than iterative and
online learning approaches.

</details>


### [39] [DeepCausalMMM: A Deep Learning Framework for Marketing Mix Modeling with Causal Inference](https://arxiv.org/abs/2510.13087)
*Aditya Puttaparthi Tirumala*

Main category: cs.LG

TL;DR: DeepCausalMMM是一个结合深度学习、因果推断和营销科学的Python包，用于改进传统营销组合建模，能自动学习时间模式、渠道依赖关系和饱和效应。


<details>
  <summary>Details</summary>
Motivation: 传统营销组合建模方法依赖线性回归或贝叶斯层次模型，假设营销渠道间独立，难以捕捉复杂的时间动态和非线性饱和效应。

Method: 使用门控循环单元(GRU)自动学习时间模式(如广告存量效应和滞后)，通过有向无环图(DAG)学习营销渠道间的统计依赖关系和潜在因果结构，并基于Hill方程实现饱和曲线建模。

Result: 实现了数据驱动设计、多区域建模、鲁棒统计方法、全面的响应曲线分析和14+交互式可视化仪表板等关键创新功能。

Conclusion: DeepCausalMMM通过结合深度学习、因果推断和营销科学，有效解决了传统营销组合建模的局限性，提供了更准确和实用的营销效果分析工具。

Abstract: Marketing Mix Modeling (MMM) is a statistical technique used to estimate the
impact of marketing activities on business outcomes such as sales, revenue, or
customer visits. Traditional MMM approaches often rely on linear regression or
Bayesian hierarchical models that assume independence between marketing
channels and struggle to capture complex temporal dynamics and non-linear
saturation effects [@Hanssens2005; @Ng2021Bayesian].
  DeepCausalMMM is a Python package that addresses these limitations by
combining deep learning, causal inference, and advanced marketing science. The
package uses Gated Recurrent Units (GRUs) to automatically learn temporal
patterns such as adstock (carryover effects) and lag, while simultaneously
learning statistical dependencies and potential causal structures between
marketing channels through Directed Acyclic Graph (DAG) learning
[@Zheng2018NOTEARS; @Gong2024CausalMMM]. Additionally, it implements Hill
equation-based saturation curves to model diminishing returns and optimize
budget allocation.
  Key innovations include: (1) a data-driven design where hyperparameters and
transformations (e.g., adstock decay, saturation curves) are learned or
estimated from data with sensible defaults, rather than requiring fixed
heuristics or manual specification, (2) multi-region modeling with both shared
and region-specific parameters, (3) robust statistical methods including Huber
loss and advanced regularization, (4) comprehensive response curve analysis for
understanding channel saturation, and (5) an extensive visualization suite with
14+ interactive dashboards for business insights.

</details>


### [40] [On the Reasoning Abilities of Masked Diffusion Language Models](https://arxiv.org/abs/2510.13117)
*Anej Svete,Ashish Sabharwal*

Main category: cs.LG

TL;DR: 本文证明了在有限精度对数宽度设置下，掩码扩散模型（MDMs）与多项式填充循环变换器（PLTs）等价，且能解决所有CoT增强变换器可解的问题。MDMs在某些问题（如正则语言）上比CoT变换器更高效，并行生成能显著加速推理。


<details>
  <summary>Details</summary>
Motivation: 探索掩码扩散模型的计算能力和并行性限制，理解其在推理问题上的理论能力，并与现有推理框架进行对比。

Method: 通过将MDMs与链式思维（CoT）和填充循环变换器（PLTs）在有限精度对数宽度设置下建立理论联系，证明它们的等价性和计算能力。

Result: 证明了MDMs与多项式填充PLTs在理论上的等价性，MDMs能解决所有CoT变换器可解的问题，并在某些问题上（如正则语言）比CoT变换器更高效。

Conclusion: 掩码扩散模型在并行生成方面具有理论优势，能够高效解决传统推理模型可处理的问题，并在某些场景下提供更快的推理速度。

Abstract: Masked diffusion models (MDMs) for text offer a compelling alternative to
traditional autoregressive language models. Parallel generation makes them
efficient, but their computational capabilities and the limitations inherent to
their parallelism remain largely unexplored. To this end, we characterize what
types of reasoning problems MDMs can provably solve and how efficiently. We do
this by connecting MDMs to the well-understood reasoning frameworks of chain of
thought (CoT) and padded looped transformers (PLTs) in the finite-precision
log-width setting: We show that MDMs and polynomially-padded PLTs are, in fact,
equivalent in this setting, and that MDMs can solve all problems that
CoT-augmented transformers can. Moreover, we showcase classes of problems
(including regular languages) for which MDMs are inherently more efficient than
CoT transformers, where parallel generation allows for substantially faster
reasoning.

</details>


### [41] [Cluster-Based Client Selection for Dependent Multi-Task Federated Learning in Edge Computing](https://arxiv.org/abs/2510.13132)
*Jieping Luo,Qiyue Li,Zhizhang Liu,Hang Qi,Jiaying Yin,Jingjin Wu*

Main category: cs.LG

TL;DR: CoDa-FL框架通过基于EMD的客户端聚类和依赖感知任务调度，在联邦学习中降低多任务完成时间，提升收敛速度和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决移动边缘计算环境下联邦学习中的客户端选择问题，特别是在依赖多任务设置下，减少完成各种学习任务所需的总时间。

Method: 提出CoDa-FL框架，使用Earth Mover's Distance进行客户端聚类，基于本地数据分布降低计算成本和提升通信效率；结合有向无环图的任务调度机制管理任务依赖关系。

Result: 数值实验验证CoDa-FL优于现有基准，在异构MEC设置下实现更快收敛、更低通信和计算成本、更高学习准确性。

Conclusion: CoDa-FL通过集群导向和依赖感知的方法，有效解决了联邦学习中的客户端选择问题，显著提升了多任务学习效率。

Abstract: We study the client selection problem in Federated Learning (FL) within
mobile edge computing (MEC) environments, particularly under the dependent
multi-task settings, to reduce the total time required to complete various
learning tasks. We propose CoDa-FL, a Cluster-oriented and Dependency-aware
framework designed to reduce the total required time via cluster-based client
selection and dependent task assignment. Our approach considers Earth Mover's
Distance (EMD) for client clustering based on their local data distributions to
lower computational cost and improve communication efficiency. We derive a
direct and explicit relationship between intra-cluster EMD and the number of
training rounds required for convergence, thereby simplifying the otherwise
complex process of obtaining the optimal solution. Additionally, we incorporate
a directed acyclic graph-based task scheduling mechanism to effectively manage
task dependencies. Through numerical experiments, we validate that our proposed
CoDa-FL outperforms existing benchmarks by achieving faster convergence, lower
communication and computational costs, and higher learning accuracy under
heterogeneous MEC settings.

</details>


### [42] [Convergence, design and training of continuous-time dropout as a random batch method](https://arxiv.org/abs/2510.13134)
*Antonio Álvarez-López,Martín Hernández*

Main category: cs.LG

TL;DR: 本文通过随机批处理方法研究连续时间模型中的dropout正则化，构建了无偏估计器，建立了轨迹和分布级别的收敛性，并在训练过程中分析了最优控制和梯度下降的偏差。


<details>
  <summary>Details</summary>
Motivation: 研究连续时间模型中dropout正则化的理论基础，通过随机批处理方法降低计算成本，同时保持正则化效果。

Method: 使用随机批处理方法构建无偏估计器，在时间间隔h内对神经元进行批量采样，建立轨迹收敛性和分布稳定性分析，并进行伴随分析和梯度下降迭代偏差分析。

Result: 轨迹收敛具有线性速率，分布稳定性在温和矩假设下达到h^{1/2}的总变差误差，在单层神经ODE上验证了理论预测的速率、正则化效果以及良好的运行时和内存性能。

Conclusion: 该方法成功将dropout扩展到连续时间模型，提供了理论基础和收敛保证，在保持正则化效果的同时降低了计算成本。

Abstract: We study dropout regularization in continuous-time models through the lens of
random-batch methods -- a family of stochastic sampling schemes originally
devised to reduce the computational cost of interacting particle systems. We
construct an unbiased, well-posed estimator that mimics dropout by sampling
neuron batches over time intervals of length $h$. Trajectory-wise convergence
is established with linear rate in $h$ for the expected uniform error. At the
distribution level, we establish stability for the associated continuity
equation, with total-variation error of order $h^{1/2}$ under mild moment
assumptions. During training with fixed batch sampling across epochs, a
Pontryagin-based adjoint analysis bounds deviations in the optimal cost and
control, as well as in gradient-descent iterates. On the design side, we
compare convergence rates for canonical batch sampling schemes, recover
standard Bernoulli dropout as a special case, and derive a cost--accuracy
trade-off yielding a closed-form optimal $h$. We then specialize to a
single-layer neural ODE and validate the theory on classification and flow
matching, observing the predicted rates, regularization effects, and favorable
runtime and memory profiles.

</details>


### [43] [Behavioral Embeddings of Programs: A Quasi-Dynamic Approach for Optimization Prediction](https://arxiv.org/abs/2510.13158)
*Haolin Pan,Jinyuan Dong,Hongbin Zhang,Hongyu Lin,Mingjie Xing,Yanjun Wu*

Main category: cs.LG

TL;DR: 提出了一种准动态程序表示框架，通过建模程序对优化的敏感性来生成程序行为谱，使用产品量化和多任务Transformer模型学习行为代码的上下文语法。


<details>
  <summary>Details</summary>
Motivation: 现有程序表示方法存在两难：静态表示高效但缺乏对程序行为演化的洞察，动态表示深入但开销大且非确定性。需要一种兼顾两者优势的方法。

Method: 使用多样化优化序列探测程序IR，量化静态特征变化生成程序行为谱；采用产品量化将连续反应向量离散化，然后用多任务Transformer模型PQ-BERT学习行为代码的上下文语法。

Result: 在两个编译器优化任务（最佳通道预测和-Oz收益预测）上的综合实验表明，该方法优于最先进的静态基线方法。

Conclusion: 提出的准动态框架成功超越了静态和动态表示之间的权衡，为程序表示学习提供了新的有效方法。

Abstract: Learning effective numerical representations, or embeddings, of programs is a
fundamental prerequisite for applying machine learning to automate and enhance
compiler optimization. Prevailing paradigms, however, present a dilemma. Static
representations, derived from source code or intermediate representation (IR),
are efficient and deterministic but offer limited insight into how a program
will behave or evolve under complex code transformations. Conversely, dynamic
representations, which rely on runtime profiling, provide profound insights
into performance bottlenecks but are often impractical for large-scale tasks
due to prohibitive overhead and inherent non-determinism. This paper transcends
this trade-off by proposing a novel quasi-dynamic framework for program
representation. The core insight is to model a program's optimization
sensitivity. We introduce the Program Behavior Spectrum, a new representation
generated by probing a program's IR with a diverse set of optimization
sequences and quantifying the resulting changes in its static features. To
effectively encode this high-dimensional, continuous spectrum, we pioneer a
compositional learning approach. Product Quantization is employed to discretize
the continuous reaction vectors into structured, compositional sub-words.
Subsequently, a multi-task Transformer model, termed PQ-BERT, is pre-trained to
learn the deep contextual grammar of these behavioral codes. Comprehensive
experiments on two representative compiler optimization tasks -- Best Pass
Prediction and -Oz Benefit Prediction -- demonstrate that our method
outperforms state-of-the-art static baselines. Our code is publicly available
at https://github.com/Panhaolin2001/PREP/.

</details>


### [44] [Universally Invariant Learning in Equivariant GNNs](https://arxiv.org/abs/2510.13169)
*Jiacheng Cen,Anyi Li,Ning Lin,Tingyang Xu,Yu Rong,Deli Zhao,Zihe Wang,Wenbing Huang*

Main category: cs.LG

TL;DR: 提出了一种高效且实用的构建完全等变图神经网络的理论框架，通过规范形式和满秩可转向基集实现完全性，显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有等变GNN通过更深架构、增强体序或增加可转向特征维度来实现完全性，但计算成本高且缺乏多项式时间解。

Method: 基于两个关键组件：1）几何图的规范形式（完全标量函数）；2）满秩可转向基集，在EGNN和TFN模型基础上构建高效算法。

Result: 实证结果显示模型在仅使用几层的情况下表现出优越的完全性和优秀性能，显著减少计算开销。

Conclusion: 该框架为构建完全等变GNN提供了理论依据和实用方法，在保持强实用效力的同时大幅降低计算成本。

Abstract: Equivariant Graph Neural Networks (GNNs) have demonstrated significant
success across various applications. To achieve completeness -- that is, the
universal approximation property over the space of equivariant functions -- the
network must effectively capture the intricate multi-body interactions among
different nodes. Prior methods attain this via deeper architectures, augmented
body orders, or increased degrees of steerable features, often at high
computational cost and without polynomial-time solutions. In this work, we
present a theoretically grounded framework for constructing complete
equivariant GNNs that is both efficient and practical. We prove that a complete
equivariant GNN can be achieved through two key components: 1) a complete
scalar function, referred to as the canonical form of the geometric graph; and
2) a full-rank steerable basis set. Leveraging this finding, we propose an
efficient algorithm for constructing complete equivariant GNNs based on two
common models: EGNN and TFN. Empirical results demonstrate that our model
demonstrates superior completeness and excellent performance with only a few
layers, thereby significantly reducing computational overhead while maintaining
strong practical efficacy.

</details>


### [45] [Information-Theoretic Criteria for Knowledge Distillation in Multimodal Learning](https://arxiv.org/abs/2510.13182)
*Rongrong Xie,Yizhou Xu,Guido Sanguinetti*

Main category: cs.LG

TL;DR: 提出了跨模态互补性假设(CCH)，认为当教师和学生表征之间的互信息超过学生表征与标签之间的互信息时，跨模态知识蒸馏才有效。通过理论验证和多种模态数据的实证研究，为跨模态知识蒸馏提供了理论框架和实践指导。


<details>
  <summary>Details</summary>
Motivation: 跨模态知识蒸馏技术虽然应用广泛，但缺乏理论指导，导致效果不稳定。研究旨在填补这一理论空白，为实践提供可靠依据。

Method: 提出跨模态互补性假设(CCH)，在联合高斯模型中进行理论验证，并在图像、文本、视频、音频和癌症组学等多种模态数据集上进行实证研究。

Result: 理论分析和实证结果均验证了CCH的有效性，为选择最优教师模态提供了实用标准。

Conclusion: 建立了跨模态知识蒸馏的新理论框架，基于CCH准则可以指导实践中选择最佳教师模态来提升较弱模态的性能。

Abstract: The rapid increase in multimodal data availability has sparked significant
interest in cross-modal knowledge distillation (KD) techniques, where richer
"teacher" modalities transfer information to weaker "student" modalities during
model training to improve performance. However, despite successes across
various applications, cross-modal KD does not always result in improved
outcomes, primarily due to a limited theoretical understanding that could
inform practice. To address this gap, we introduce the Cross-modal
Complementarity Hypothesis (CCH): we propose that cross-modal KD is effective
when the mutual information between teacher and student representations exceeds
the mutual information between the student representation and the labels. We
theoretically validate the CCH in a joint Gaussian model and further confirm it
empirically across diverse multimodal datasets, including image, text, video,
audio, and cancer-related omics data. Our study establishes a novel theoretical
framework for understanding cross-modal KD and offers practical guidelines
based on the CCH criterion to select optimal teacher modalities for improving
the performance of weaker modalities.

</details>


### [46] [CleverCatch: A Knowledge-Guided Weak Supervision Model for Fraud Detection](https://arxiv.org/abs/2510.13205)
*Amirhossein Mozafari,Kourosh Hashemi,Erfan Shafagh,Soroush Motamedi,Azar Taheri Tayebi,Mohammad A. Tayebi*

Main category: cs.LG

TL;DR: CleverCatch是一个知识引导的弱监督模型，通过将结构化领域专业知识整合到神经架构中，在共享嵌入空间中对齐规则和数据样本，从而改进医疗欺诈检测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 医疗欺诈检测面临标记数据有限、欺诈手段不断演变和医疗记录高维度的挑战。传统监督方法受限于极端标签稀缺，而纯无监督方法往往无法捕捉临床意义异常。

Method: 在共享嵌入空间中联合训练编码器，使用代表合规和违规的合成数据学习软规则嵌入，将数据驱动学习与领域知识约束相结合。

Result: 在大型真实数据集上的实验表明，CleverCatch优于四种最先进的异常检测基线方法，AUC平均提升1.3%，召回率平均提升3.4%。

Conclusion: 将专家规则嵌入学习过程不仅能提高检测准确性，还能增加透明度，为医疗欺诈检测等高风险领域提供可解释的方法。

Abstract: Healthcare fraud detection remains a critical challenge due to limited
availability of labeled data, constantly evolving fraud tactics, and the high
dimensionality of medical records. Traditional supervised methods are
challenged by extreme label scarcity, while purely unsupervised approaches
often fail to capture clinically meaningful anomalies. In this work, we
introduce CleverCatch, a knowledge-guided weak supervision model designed to
detect fraudulent prescription behaviors with improved accuracy and
interpretability. Our approach integrates structured domain expertise into a
neural architecture that aligns rules and data samples within a shared
embedding space. By training encoders jointly on synthetic data representing
both compliance and violation, CleverCatch learns soft rule embeddings that
generalize to complex, real-world datasets. This hybrid design enables
data-driven learning to be enhanced by domain-informed constraints, bridging
the gap between expert heuristics and machine learning. Experiments on the
large-scale real-world dataset demonstrate that CleverCatch outperforms four
state-of-the-art anomaly detection baselines, yielding average improvements of
1.3\% in AUC and 3.4\% in recall. Our ablation study further highlights the
complementary role of expert rules, confirming the adaptability of the
framework. The results suggest that embedding expert rules into the learning
process not only improves detection accuracy but also increases transparency,
offering an interpretable approach for high-stakes domains such as healthcare
fraud detection.

</details>


### [47] [Performance Evaluation of Ising and QUBO Variable Encodings in Boltzmann Machine Learning](https://arxiv.org/abs/2510.13210)
*Yasushi Hasegawa,Masayuki Ohzeki*

Main category: cs.LG

TL;DR: 比较Ising({-1,+1})和QUBO({0,1})编码在玻尔兹曼机学习中的表现，发现QUBO编码导致Fisher信息矩阵(FIM)条件数较差，使得随机梯度下降(SGD)收敛更慢，而自然梯度下降(NGD)由于重参数化不变性在不同编码间表现相似。


<details>
  <summary>Details</summary>
Motivation: 研究不同变量编码（Ising vs QUBO）如何影响玻尔兹曼机学习的信息几何特性和收敛动态，为变量编码和预处理提供实用指导。

Method: 在控制模型、采样器和步长的协议下，利用Fisher信息矩阵等于充分统计量协方差的性质，可视化模型样本的经验矩，分析编码相关的系统性差异。

Result: QUBO编码在一阶和二阶统计量之间产生更大的交叉项，导致FIM中出现更多小特征值方向，降低谱熵，这种病态条件解释了SGD收敛较慢的原因。

Conclusion: 对于基于SGD的训练，Ising编码提供更各向同性的曲率和更快收敛；对于QUBO，中心化/缩放或NGD式预处理可缓解曲率病态问题。这些结果阐明了表示如何塑造玻尔兹曼机中的信息几何和有限时间学习动态。

Abstract: We compare Ising ({-1,+1}) and QUBO ({0,1}) encodings for Boltzmann machine
learning under a controlled protocol that fixes the model, sampler, and step
size. Exploiting the identity that the Fisher information matrix (FIM) equals
the covariance of sufficient statistics, we visualize empirical moments from
model samples and reveal systematic, representation-dependent differences. QUBO
induces larger cross terms between first- and second-order statistics, creating
more small-eigenvalue directions in the FIM and lowering spectral entropy. This
ill-conditioning explains slower convergence under stochastic gradient descent
(SGD). In contrast, natural gradient descent (NGD)-which rescales updates by
the FIM metric-achieves similar convergence across encodings due to
reparameterization invariance. Practically, for SGD-based training, the Ising
encoding provides more isotropic curvature and faster convergence; for QUBO,
centering/scaling or NGD-style preconditioning mitigates curvature pathologies.
These results clarify how representation shapes information geometry and
finite-time learning dynamics in Boltzmann machines and yield actionable
guidelines for variable encoding and preprocessing.

</details>


### [48] [Towards Understanding Valuable Preference Data for Large Language Model Alignment](https://arxiv.org/abs/2510.13212)
*Zizhuo Zhang,Qizhou Wang,Shanshan Ye,Jianing Zhu,Jiangchao Yao,Bo Han,Masashi Sugiyama*

Main category: cs.LG

TL;DR: 本文提出了一种基于截断影响函数(TIF)的数据质量评估方法，发现偏好数据质量是模型相关的，并开发了两种简化的评分函数来改进偏好数据选择。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常使用外部奖励模型或现成LLM来预处理原始训练数据集以识别有价值的偏好对，但很少检验单个数据点是否真正有益。

Method: 提出截断影响函数(TIF)评估数据质量，开发两种计算更简单的评分函数，并将它们结合以抵消不同的误差源。

Result: 在多样化对齐基准和多种LLM家族上的实验表明，使用更少数据可以实现更好的对齐性能。

Conclusion: 偏好数据质量是模型相关的，提出的数据选择方法能够更精确地选择有价值的偏好数据，提高对齐效率。

Abstract: Large language model (LLM) alignment is typically achieved through learning
from human preference comparisons, making the quality of preference data
critical to its success. Existing studies often pre-process raw training
datasets to identify valuable preference pairs using external reward models or
off-the-shelf LLMs, achieving improved overall performance but rarely examining
whether individual, selected data point is genuinely beneficial. We assess data
quality through individual influence on validation data using our newly
proposed truncated influence function (TIF), which mitigates the over-scoring
present in traditional measures and reveals that preference data quality is
inherently a property of the model. In other words, a data pair that benefits
one model may harm another. This leaves the need to improve the preference data
selection approaches to be adapting to specific models. To this end, we
introduce two candidate scoring functions (SFs) that are computationally
simpler than TIF and positively correlated with it. They are also model
dependent and can serve as potential indicators of individual data quality for
preference data selection. Furthermore, we observe that these SFs inherently
exhibit errors when compared to TIF. To this end, we combine them to offset
their diverse error sources, resulting in a simple yet effective data selection
rule that enables the models to achieve a more precise selection of valuable
preference data. We conduct experiments across diverse alignment benchmarks and
various LLM families, with results demonstrating that better alignment
performance can be achieved using less data, showing the generality of our
findings and new methods.

</details>


### [49] [Rethinking Graph Domain Adaptation: A Spectral Contrastive Perspective](https://arxiv.org/abs/2510.13254)
*Haoyu Zhang,Yuxuan Cheng,Wenqi Fan,Yulong Chen,Yifan Zhang*

Main category: cs.LG

TL;DR: 提出FracNet，一种基于频谱分析的图神经网络域自适应方法，通过分解高低频组件并集成对比学习来解决结构分布偏移问题。


<details>
  <summary>Details</summary>
Motivation: 传统GNN在域自适应中表现不佳，主要原因是未能区分处理全局和局部模式，且多层GNN可能破坏图的局部细节。通过频谱分析发现低频组件编码域不变的全局模式，高频组件捕获域特定的局部细节。

Method: 提出FracNet，包含两个协同模块：将原始图分解为高频和低频组件，执行频率感知的域自适应，并集成对比学习框架来改善域自适应中的模糊边界问题。

Result: 大量实验证明FracNet相比最先进方法有显著改进。

Conclusion: FracNet通过频谱分解和对比学习有效解决了图神经网络的域自适应问题，理论证明和实验验证了其优越性。

Abstract: Graph neural networks (GNNs) have achieved remarkable success in various
domains, yet they often struggle with domain adaptation due to significant
structural distribution shifts and insufficient exploration of transferable
patterns. One of the main reasons behind this is that traditional approaches do
not treat global and local patterns discriminatingly so that some local details
in the graph may be violated after multi-layer GNN. Our key insight is that
domain shifts can be better understood through spectral analysis, where
low-frequency components often encode domain-invariant global patterns, and
high-frequency components capture domain-specific local details. As such, we
propose FracNet (\underline{\textbf{Fr}}equency \underline{\textbf{A}}ware
\underline{\textbf{C}}ontrastive Graph \underline{\textbf{Net}}work) with two
synergic modules to decompose the original graph into high-frequency and
low-frequency components and perform frequency-aware domain adaption. Moreover,
the blurring boundary problem of domain adaptation is improved by integrating
with a contrastive learning framework. Besides the practical implication, we
also provide rigorous theoretical proof to demonstrate the superiority of
FracNet. Extensive experiments further demonstrate significant improvements
over state-of-the-art approaches.

</details>


### [50] [Hypernetworks for Perspectivist Adaptation](https://arxiv.org/abs/2510.13259)
*Daniil Ignatev,Denis Paperno,Massimo Poesio*

Main category: cs.LG

TL;DR: 应用超网络+适配器架构到视角感知分类任务，在保持性能的同时显著减少参数数量


<details>
  <summary>Details</summary>
Motivation: 解决视角感知分类任务中参数效率低下的问题，现有研究对此关注不足

Method: 采用超网络+适配器的组合架构，该方案与基础模型架构无关，可广泛适用

Result: 在仇恨言论和毒性检测任务中，能够与专用模型竞争性能，同时使用更少的参数

Conclusion: 提出了一种参数高效的视角感知分类解决方案，具有架构无关性和即插即用特性

Abstract: The task of perspective-aware classification introduces a bottleneck in terms
of parametric efficiency that did not get enough recognition in existing
studies. In this article, we aim to address this issue by applying an existing
architecture, the hypernetwork+adapters combination, to perspectivist
classification. Ultimately, we arrive at a solution that can compete with
specialized models in adopting user perspectives on hate speech and toxicity
detection, while also making use of considerably fewer parameters. Our solution
is architecture-agnostic and can be applied to a wide range of base models out
of the box.

</details>


### [51] [BlendFL: Blended Federated Learning for Handling Multimodal Data Heterogeneity](https://arxiv.org/abs/2510.13266)
*Alejandro Guerra-Manzanares,Omar El-Herraoui,Michail Maniatakos,Farah E. Shamout*

Main category: cs.LG

TL;DR: 提出了BlendFL框架，混合水平和垂直联邦学习的优势，解决多模态数据异构性问题，支持去中心化推理和自适应模型聚合


<details>
  <summary>Details</summary>
Motivation: 解决现实世界中多模态数据异构性挑战，现有联邦学习框架在非理想设置下效果不佳，无法处理客户端间模态和样本不对称的情况

Method: BlendFL框架混合水平和垂直联邦学习原则，支持去中心化推理，引入BlendAvg自适应全局模型聚合策略

Result: 在三个分类任务上评估，使用大规模真实多模态医疗数据集和基准数据集，BlendFL在多模态和单模态分类中表现优异，收敛速度更快

Conclusion: BlendFL在处理多模态数据异构性方面具有潜力，特别适用于医疗和金融等需要数据隐私保护的现实场景

Abstract: One of the key challenges of collaborative machine learning, without data
sharing, is multimodal data heterogeneity in real-world settings. While
Federated Learning (FL) enables model training across multiple clients,
existing frameworks, such as horizontal and vertical FL, are only effective in
`ideal' settings that meet specific assumptions. Hence, they struggle to
address scenarios where neither all modalities nor all samples are represented
across the participating clients. To address this gap, we propose BlendFL, a
novel FL framework that seamlessly blends the principles of horizontal and
vertical FL in a synchronized and non-restrictive fashion despite the asymmetry
across clients. Specifically, any client within BlendFL can benefit from either
of the approaches, or both simultaneously, according to its available dataset.
In addition, BlendFL features a decentralized inference mechanism, empowering
clients to run collaboratively trained local models using available local data,
thereby reducing latency and reliance on central servers for inference. We also
introduce BlendAvg, an adaptive global model aggregation strategy that
prioritizes collaborative model updates based on each client's performance. We
trained and evaluated BlendFL and other state-of-the-art baselines on three
classification tasks using a large-scale real-world multimodal medical dataset
and a popular multimodal benchmark. Our results highlight BlendFL's superior
performance for both multimodal and unimodal classification. Ablation studies
demonstrate BlendFL's faster convergence compared to traditional approaches,
accelerating collaborative learning. Overall, in our study we highlight the
potential of BlendFL for handling multimodal data heterogeneity for
collaborative learning in real-world settings where data privacy is crucial,
such as in healthcare and finance.

</details>


### [52] [To Steer or Not to Steer? Mechanistic Error Reduction with Abstention for Language Models](https://arxiv.org/abs/2510.13290)
*Anna Hedström,Salim I. Amoukou,Tom Bewley,Saumitra Mishra,Manuela Veloso*

Main category: cs.LG

TL;DR: MERA是一个通过选择性、自适应干预来减少语言模型错误的框架，通过优化干预方向和校准干预时机与强度，在无法自信修正时选择弃权，从而安全有效地提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖固定、手动调整的干预强度，往往导致干预不足或过度，MERA旨在解决这些限制。

Method: 通过优化干预方向和校准干预时机与强度，在无法自信修正时选择弃权，可应用于现有干预技术之上。

Result: 在多个数据集和语言模型家族上的实验表明，MERA能安全有效地进行错误修正且不降低性能，优于现有基线方法。

Conclusion: MERA是一个通用且高效的机制性激活干预方法，可显著提升现有干预技术的性能。

Abstract: We introduce Mechanistic Error Reduction with Abstention (MERA), a principled
framework for steering language models (LMs) to mitigate errors through
selective, adaptive interventions. Unlike existing methods that rely on fixed,
manually tuned steering strengths, often resulting in under or oversteering,
MERA addresses these limitations by (i) optimising the intervention direction,
and (ii) calibrating when, and how much to steer, thereby provably improving
performance or abstaining when no confident correction is possible. Experiments
across diverse datasets, and LM families demonstrate safe, effective,
non-degrading error correction, and that MERA outperforms existing baselines.
Moreover, MERA can be applied on top of existing steering techniques to further
enhance their performance, establishing it as a general-purpose, and efficient
approach to mechanistic activation steering.

</details>


### [53] [Federated Conditional Conformal Prediction via Generative Models](https://arxiv.org/abs/2510.13297)
*Rui Xu,Sihong Xie*

Main category: cs.LG

TL;DR: 提出Fed-CCP方法，通过生成模型实现联邦学习中的条件保形预测，解决客户端数据分布差异问题。


<details>
  <summary>Details</summary>
Motivation: 标准保形预测假设数据独立同分布，但在联邦学习中客户端数据分布差异显著，现有方法只能保证边际覆盖，无法反映输入条件的不确定性。

Method: 使用生成模型（如归一化流或扩散模型）近似条件数据分布，无需共享原始数据，每个客户端本地校准反映其独特不确定性的保形分数，通过联邦聚合保持全局一致性。

Result: 在真实数据集上的实验表明，Fed-CCP实现了更自适应的预测集。

Conclusion: Fed-CCP通过生成模型有效解决了联邦学习中数据分布差异带来的条件覆盖问题，实现了更精确的不确定性量化。

Abstract: Conformal Prediction (CP) provides distribution-free uncertainty
quantification by constructing prediction sets that guarantee coverage of the
true labels. This reliability makes CP valuable for high-stakes federated
learning scenarios such as multi-center healthcare. However, standard CP
assumes i.i.d. data, which is violated in federated settings where client
distributions differ substantially. Existing federated CP methods address this
by maintaining marginal coverage on each client, but such guarantees often fail
to reflect input-conditional uncertainty. In this work, we propose Federated
Conditional Conformal Prediction (Fed-CCP) via generative models, which aims
for conditional coverage that adapts to local data heterogeneity. Fed-CCP
leverages generative models, such as normalizing flows or diffusion models, to
approximate conditional data distributions without requiring the sharing of raw
data. This enables each client to locally calibrate conformal scores that
reflect its unique uncertainty, while preserving global consistency through
federated aggregation. Experiments on real datasets demonstrate that Fed-CCP
achieves more adaptive prediction sets.

</details>


### [54] [Km-scale dynamical downscaling through conformalized latent diffusion models](https://arxiv.org/abs/2510.13301)
*Alessandro Brusaferri,Andrea Ballarino*

Main category: cs.LG

TL;DR: 本文提出了一种结合生成扩散模型和保形预测框架的降尺度方法，通过后处理生成样本获得条件分位数估计，构建具有有限样本边际有效性的局部自适应预测区间，显著改善了不确定性估计的覆盖率和概率评分。


<details>
  <summary>Details</summary>
Motivation: 生成扩散模型在气象降尺度任务中虽然能提供高保真重建和可扩展采样，但缺乏有限样本保证，导致网格点级不确定性估计失准，影响在业务环境中的可靠性。

Method: 在降尺度流程中引入保形预测框架，对扩散模型的生成样本进行后处理得到条件分位数估计，然后采用保形化分位数回归方法构建局部自适应预测区间。

Result: 在意大利地区的ERA5再分析数据上评估，将数据降尺度到2公里网格。结果显示网格点级不确定性估计的覆盖率和概率评分相比基线扩散模型有明显改善。

Conclusion: 保形化生成模型在高分辨率气象场概率降尺度方面具有构建更可信赖系统的潜力。

Abstract: Dynamical downscaling is crucial for deriving high-resolution meteorological
fields from coarse-scale simulations, enabling detailed analysis for critical
applications such as weather forecasting and renewable energy modeling.
Generative Diffusion models (DMs) have recently emerged as powerful data-driven
tools for this task, offering reconstruction fidelity and more scalable
sampling supporting uncertainty quantification. However, DMs lack finite-sample
guarantees against overconfident predictions, resulting in miscalibrated
grid-point-level uncertainty estimates hindering their reliability in
operational contexts. In this work, we tackle this issue by augmenting the
downscaling pipeline with a conformal prediction framework. Specifically, the
DM's samples are post-processed to derive conditional quantile estimates,
incorporated into a conformalized quantile regression procedure targeting
locally adaptive prediction intervals with finite-sample marginal validity. The
proposed approach is evaluated on ERA5 reanalysis data over Italy, downscaled
to a 2-km grid. Results demonstrate grid-point-level uncertainty estimates with
markedly improved coverage and stable probabilistic scores relative to the DM
baseline, highlighting the potential of conformalized generative models for
more trustworthy probabilistic downscaling to high-resolution meteorological
fields.

</details>


### [55] [Isolation-based Spherical Ensemble Representations for Anomaly Detection](https://arxiv.org/abs/2510.13311)
*Yang Cao,Sikun Yang,Hao Tian,Kai He,Lianyong Qi,Ming Liu,Yujiu Yang*

Main category: cs.LG

TL;DR: 提出ISER方法，通过使用超球体半径作为局部密度特征的代理，扩展了现有的基于隔离的方法，同时保持线性时间和常数空间复杂度。


<details>
  <summary>Details</summary>
Motivation: 解决现有无监督异常检测方法在分布假设冲突、计算效率低和处理不同类型异常方面的基本挑战。

Method: 构建集成表示，其中超球体半径编码密度信息：较小半径表示密集区域，较大半径对应稀疏区域。引入基于相似性的评分方法，通过将集成表示与理论异常参考模式进行比较来测量模式一致性。

Result: 在22个真实世界数据集上的综合实验表明，ISER优于11种基线方法。

Conclusion: ISER通过使用超球体半径作为局部密度特征的代理，有效解决了现有异常检测方法的局限性，并在多个数据集上表现出优越性能。

Abstract: Anomaly detection is a critical task in data mining and management with
applications spanning fraud detection, network security, and log monitoring.
Despite extensive research, existing unsupervised anomaly detection methods
still face fundamental challenges including conflicting distributional
assumptions, computational inefficiency, and difficulty handling different
anomaly types. To address these problems, we propose ISER (Isolation-based
Spherical Ensemble Representations) that extends existing isolation-based
methods by using hypersphere radii as proxies for local density characteristics
while maintaining linear time and constant space complexity. ISER constructs
ensemble representations where hypersphere radii encode density information:
smaller radii indicate dense regions while larger radii correspond to sparse
areas. We introduce a novel similarity-based scoring method that measures
pattern consistency by comparing ensemble representations against a theoretical
anomaly reference pattern. Additionally, we enhance the performance of
Isolation Forest by using ISER and adapting the scoring function to address
axis-parallel bias and local anomaly detection limitations. Comprehensive
experiments on 22 real-world datasets demonstrate ISER's superior performance
over 11 baseline methods.

</details>


### [56] [RockNet: Distributed Learning on Ultra-Low-Power Devices](https://arxiv.org/abs/2510.13320)
*Alexander Gräfe,Fabian Mager,Marco Zimmerling,Sebastian Trimpe*

Main category: cs.LG

TL;DR: RockNet是一种专为超低功耗硬件设计的TinyML方法，通过分布式学习和无线通信集成，在时间序列分类任务中实现最先进精度，无需离线预训练。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习在信息物理系统中日益重要，传统云端训练存在隐私和延迟问题，而超低功耗微控制器的有限计算资源使得训练具有挑战性。

Method: 利用CPS由多个设备组成的特点，设计分布式学习方法，结合ML和无线通信，训练专门的、计算效率高的分类器，最小化并行化通信开销。

Result: 在20个超低功耗设备的测试平台上，RockNet成功从零开始学习时间序列分类任务，准确率比最新的神经网络微控制器训练方法提高达2倍，分布式架构在扩展到20个设备时，每个设备的内存、延迟和能耗降低达90%。

Conclusion: 分布式ML、分布式计算和通信的紧密集成首次实现了在超低功耗硬件上以最先进精度进行训练。

Abstract: As Machine Learning (ML) becomes integral to Cyber-Physical Systems (CPS),
there is growing interest in shifting training from traditional cloud-based to
on-device processing (TinyML), for example, due to privacy and latency
concerns. However, CPS often comprise ultra-low-power microcontrollers, whose
limited compute resources make training challenging. This paper presents
RockNet, a new TinyML method tailored for ultra-low-power hardware that
achieves state-of-the-art accuracy in timeseries classification, such as fault
or malware detection, without requiring offline pretraining. By leveraging that
CPS consist of multiple devices, we design a distributed learning method that
integrates ML and wireless communication. RockNet leverages all devices for
distributed training of specialized compute efficient classifiers that need
minimal communication overhead for parallelization. Combined with tailored and
efficient wireless multi-hop communication protocols, our approach overcomes
the communication bottleneck that often occurs in distributed learning.
Hardware experiments on a testbed with 20 ultra-low-power devices demonstrate
RockNet's effectiveness. It successfully learns timeseries classification tasks
from scratch, surpassing the accuracy of the latest approach for neural network
microcontroller training by up to 2x. RockNet's distributed ML architecture
reduces memory, latency and energy consumption per device by up to 90 % when
scaling from one central device to 20 devices. Our results show that a tight
integration of distributed ML, distributed computing, and communication
enables, for the first time, training on ultra-low-power hardware with
state-of-the-art accuracy.

</details>


### [57] [When In Doubt, Abstain: The Impact of Abstention on Strategic Classification](https://arxiv.org/abs/2510.13327)
*Lina Alkarmi,Ziyuan Huang,Mingyan Liu*

Main category: cs.LG

TL;DR: 该论文研究了在战略分类中引入弃权机制的影响，证明最优弃权策略能确保决策者的效用不低于非弃权设置，并能抑制代理人的操纵行为。


<details>
  <summary>Details</summary>
Motivation: 算法决策系统易受战略操纵，而分类器弃权机制已被证明能提高准确性。本文旨在探索在战略分类背景下引入弃权机制如何影响战略代理人的响应，以及决策者应如何最优利用这一机制。

Method: 使用Stackelberg博弈模型，决策者作为领导者首先宣布决策策略，战略代理人作为跟随者随后操纵其特征以获得期望结果。研究聚焦于二元分类器，代理人操纵可观察特征而非真实特征。

Result: 最优弃权策略确保决策者的效用不会比非弃权设置更差，即使存在战略代理人。弃权不仅能提高准确性，还能作为操纵的威慑，使代理人（特别是资格较差的）操纵成本更高。

Conclusion: 弃权机制是减少算法决策系统中战略行为负面效应的有价值工具，特别是在操纵成本足够影响代理人行为时能有效抑制操纵。

Abstract: Algorithmic decision making is increasingly prevalent, but often vulnerable
to strategic manipulation by agents seeking a favorable outcome. Prior research
has shown that classifier abstention (allowing a classifier to decline making a
decision due to insufficient confidence) can significantly increase classifier
accuracy. This paper studies abstention within a strategic classification
context, exploring how its introduction impacts strategic agents' responses and
how principals should optimally leverage it. We model this interaction as a
Stackelberg game where a principal, acting as the classifier, first announces
its decision policy, and then strategic agents, acting as followers, manipulate
their features to receive a desired outcome. Here, we focus on binary
classifiers where agents manipulate observable features rather than their true
features, and show that optimal abstention ensures that the principal's utility
(or loss) is no worse than in a non-abstention setting, even in the presence of
strategic agents. We also show that beyond improving accuracy, abstention can
also serve as a deterrent to manipulation, making it costlier for agents,
especially those less qualified, to manipulate to achieve a positive outcome
when manipulation costs are significant enough to affect agent behavior. These
results highlight abstention as a valuable tool for reducing the negative
effects of strategic behavior in algorithmic decision making systems.

</details>


### [58] [Thompson Sampling via Fine-Tuning of LLMs](https://arxiv.org/abs/2510.13328)
*Nicolas Menet,Aleksandar Terzić,Andreas Krause,Abbas Rahimi*

Main category: cs.LG

TL;DR: 提出了一种基于Thompson采样的可扩展方法ToSFiT，通过直接参数化候选解产生最大奖励的概率，避免了传统贝叶斯优化中获取函数最大化的计算瓶颈。


<details>
  <summary>Details</summary>
Motivation: 解决大型非结构化离散空间中贝叶斯优化的计算效率问题，传统方法由于缺乏梯度导致获取函数最大化计算成本高昂。

Method: 利用提示条件大型语言模型的先验知识，通过在线微调逐步适应后验分布，直接参数化候选解的最大奖励概率。

Result: 在FAQ响应优化、热稳定蛋白质搜索和量子电路设计三个任务上验证了方法有效性，在线微调显著提高了样本效率，对计算效率影响可忽略。

Conclusion: ToSFiT方法通过变分Thompson采样框架，在保持理论保证的同时，实现了在大型离散空间中的高效贝叶斯优化。

Abstract: Bayesian optimization in large unstructured discrete spaces is often hindered
by the computational cost of maximizing acquisition functions due to the
absence of gradients. We propose a scalable alternative based on Thompson
sampling that eliminates the need for acquisition function maximization by
directly parameterizing the probability that a candidate yields the maximum
reward. Our approach, Thompson Sampling via Fine-Tuning (ToSFiT) leverages the
prior knowledge embedded in prompt-conditioned large language models, and
incrementally adapts them toward the posterior. Theoretically, we derive a
novel regret bound for a variational formulation of Thompson Sampling that
matches the strong guarantees of its standard counterpart. Our analysis reveals
the critical role of careful adaptation to the posterior probability of
maximality--a principle that underpins our ToSFiT algorithm. Empirically, we
validate our method on three diverse tasks: FAQ response refinement, thermally
stable protein search, and quantum circuit design. We demonstrate that online
fine-tuning significantly improves sample efficiency, with negligible impact on
computational efficiency.

</details>


### [59] [Kernel Representation and Similarity Measure for Incomplete Data](https://arxiv.org/abs/2510.13352)
*Yang Cao,Sikun Yang,Kai He,Wenjun Ma,Ming Liu,Yujiu Yang,Jian Weng*

Main category: cs.LG

TL;DR: 提出了邻近核方法，直接在核特征空间中计算不完整数据的相似度，无需在原始空间进行显式插补，在12个真实世界不完整数据集上表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法要么丢弃不完整数据，要么进行插补预处理，导致信息丢失和相似度估计偏差。需要一种能直接处理不完整数据的相似度度量方法。

Method: 使用数据依赖分箱结合邻近分配，将数据投影到高维稀疏表示中，适应局部密度变化。采用级联回退策略估计缺失特征分布。

Result: 在12个真实世界不完整数据集上的聚类任务中，相比现有方法表现出优越性能，同时保持线性时间复杂度。

Conclusion: 邻近核方法能有效处理不完整数据的相似度计算问题，避免了传统插补方法的信息损失和偏差问题。

Abstract: Measuring similarity between incomplete data is a fundamental challenge in
web mining, recommendation systems, and user behavior analysis. Traditional
approaches either discard incomplete data or perform imputation as a
preprocessing step, leading to information loss and biased similarity
estimates. This paper presents the proximity kernel, a new similarity measure
that directly computes similarity between incomplete data in kernel feature
space without explicit imputation in the original space. The proposed method
introduces data-dependent binning combined with proximity assignment to project
data into a high-dimensional sparse representation that adapts to local density
variations. For missing value handling, we propose a cascading fallback
strategy to estimate missing feature distributions. We conduct clustering tasks
on the proposed kernel representation across 12 real world incomplete datasets,
demonstrating superior performance compared to existing methods while
maintaining linear time complexity. All the code are available at
https://anonymous.4open.science/r/proximity-kernel-2289.

</details>


### [60] [Generalist++: A Meta-learning Framework for Mitigating Trade-off in Adversarial Training](https://arxiv.org/abs/2510.13361)
*Yisen Wang,Yichuan Mo,Hongjun Wang,Junyi Li,Zhouchen Lin*

Main category: cs.LG

TL;DR: 提出Generalist框架，通过多专家网络分工协作解决对抗训练中的自然精度下降和跨攻击鲁棒性迁移问题


<details>
  <summary>Details</summary>
Motivation: 对抗训练存在两个主要局限：自然精度显著下降，以及在不同范数约束攻击下的鲁棒性迁移能力差

Method: 将整体泛化目标分解为多个子任务，每个基础学习器专注于特定目标，后期通过参数插值形成全局学习器，并周期性重新分配参数防止优化轨迹漂移

Result: 理论分析和实验表明，Generalist实现了更低的泛化误差，显著缓解了权衡问题

Conclusion: Generalist为开发完全鲁棒的分类器提供了有前景的方向

Abstract: Despite the rapid progress of neural networks, they remain highly vulnerable
to adversarial examples, for which adversarial training (AT) is currently the
most effective defense. While AT has been extensively studied, its practical
applications expose two major limitations: natural accuracy tends to degrade
significantly compared with standard training, and robustness does not transfer
well across attacks crafted under different norm constraints. Unlike prior
works that attempt to address only one issue within a single network, we
propose to partition the overall generalization goal into multiple sub-tasks,
each assigned to a dedicated base learner. By specializing in its designated
objective, each base learner quickly becomes an expert in its field. In the
later stages of training, we interpolate their parameters to form a
knowledgeable global learner, while periodically redistributing the global
parameters back to the base learners to prevent their optimization trajectories
from drifting too far from the shared target. We term this framework Generalist
and introduce three variants tailored to different application scenarios. Both
theoretical analysis and extensive experiments demonstrate that Generalist
achieves lower generalization error and significantly alleviates the trade-off
problems compared with baseline methods. Our results suggest that Generalist
provides a promising step toward developing fully robust classifiers in the
future.

</details>


### [61] [A New Perspective on Transformers in Online Reinforcement Learning for Continuous Control](https://arxiv.org/abs/2510.13367)
*Nikita Kachaev,Daniil Zelezetsky,Egor Cherepanov,Alexey K. Kovelev,Aleksandr I. Panov*

Main category: cs.LG

TL;DR: 本文研究了在在线无模型强化学习中应用Transformer架构的关键设计问题，展示了Transformer在连续控制任务中可以作为强大的基线方法。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer在离线或基于模型的强化学习中表现优异且流行，但在在线无模型强化学习中仍未被充分探索，主要因为其对训练设置和模型设计决策（如策略和价值网络结构、组件共享、时序信息处理）的敏感性。

Method: 研究了关键设计问题：如何条件化输入、在actor和critic之间共享组件、以及如何对序列数据进行切片训练。通过实验探索了稳定的架构和训练策略。

Result: 实验结果表明，所提出的方法在完全可观测和部分可观测任务中，以及在向量和图像两种设置下都能获得有竞争力的性能。

Conclusion: 这些发现为在在线强化学习中应用Transformer提供了实用的指导。

Abstract: Despite their effectiveness and popularity in offline or model-based
reinforcement learning (RL), transformers remain underexplored in online
model-free RL due to their sensitivity to training setups and model design
decisions such as how to structure the policy and value networks, share
components, or handle temporal information. In this paper, we show that
transformers can be strong baselines for continuous control in online
model-free RL. We investigate key design questions: how to condition inputs,
share components between actor and critic, and slice sequential data for
training. Our experiments reveal stable architectural and training strategies
enabling competitive performance across fully and partially observable tasks,
and in both vector- and image-based settings. These findings offer practical
guidance for applying transformers in online RL.

</details>


### [62] [Contrastive Learning-Based Dependency Modeling for Anomaly Detection in Cloud Services](https://arxiv.org/abs/2510.13368)
*Yue Xing,Yingnan Deng,Heyao Liu,Ming Wang,Yun Zi,Xiaoxuan Sun*

Main category: cs.LG

TL;DR: 提出了一种结合对比学习的依赖建模和异常检测方法，通过构建依赖图、提取时空特征，并使用对比学习框架增强正常与异常模式的可分性，在云服务环境中实现稳定可靠的异常检测。


<details>
  <summary>Details</summary>
Motivation: 解决云服务环境中复杂依赖关系和多样化异常模式的挑战，传统方法难以有效处理这些复杂场景。

Method: 将服务交互抽象为依赖图，通过嵌入函数提取时空特征，使用图卷积机制聚合邻域信息，引入对比学习框架构建正负样本对，并设计时间一致性约束来保持表示稳定性。

Result: 在公开数据集上的实验表明，该方法在精确率、召回率、F1分数和AUC等关键指标上显著优于现有方法，在稀疏标注、监控噪声和流量波动条件下保持鲁棒性。

Conclusion: 验证了依赖建模与对比学习结合的有效性，为云服务异常检测提供了完整技术方案，在复杂环境中表现出强大的适应性和稳定性。

Abstract: This paper addresses the challenges of complex dependencies and diverse
anomaly patterns in cloud service environments by proposing a dependency
modeling and anomaly detection method that integrates contrastive learning. The
method abstracts service interactions into a dependency graph, extracts
temporal and structural features through embedding functions, and employs a
graph convolution mechanism to aggregate neighborhood information for
context-aware service representations. A contrastive learning framework is then
introduced, constructing positive and negative sample pairs to enhance the
separability of normal and abnormal patterns in the representation space.
Furthermore, a temporal consistency constraint is designed to maintain
representation stability across time steps and reduce the impact of short-term
fluctuations and noise. The overall optimization combines contrastive loss and
temporal consistency loss to ensure stable and reliable detection across
multi-dimensional features. Experiments on public datasets systematically
evaluate the method from hyperparameter, environmental, and data sensitivity
perspectives. Results show that the proposed approach significantly outperforms
existing methods on key metrics such as Precision, Recall, F1-Score, and AUC,
while maintaining robustness under conditions of sparse labeling, monitoring
noise, and traffic fluctuations. This study verifies the effectiveness of
integrating dependency modeling with contrastive learning, provides a complete
technical solution for cloud service anomaly detection, and demonstrates strong
adaptability and stability in complex environments.

</details>


### [63] [Prediction Markets with Intermittent Contributions](https://arxiv.org/abs/2510.13385)
*Michael Vitali,Pierre Pinson*

Main category: cs.LG

TL;DR: 提出一个基于预测市场的框架，允许独立代理在考虑历史表现、适应时变条件的情况下交易未来事件预测，并支持自由进出市场。


<details>
  <summary>Details</summary>
Motivation: 虽然数据可用性和准确预测需求都在增加，但利益相关者之间的协作常受数据所有权和竞争利益限制。现有合作博弈理论框架存在局限，需要更通用的解决方案。

Method: 采用预测市场框架，使用稳健回归模型学习最优预测组合并处理缺失提交，引入考虑样本内外表现的收益分配机制。

Result: 通过模拟和真实数据案例研究证明了所提市场设计的有效性和适应性。

Conclusion: 该预测市场设计能够有效促进利益相关者之间的协作，同时满足重要的经济特性要求。

Abstract: Although both data availability and the demand for accurate forecasts are
increasing, collaboration between stakeholders is often constrained by data
ownership and competitive interests. In contrast to recent proposals within
cooperative game-theoretical frameworks, we place ourselves in a more general
framework, based on prediction markets. There, independent agents trade
forecasts of uncertain future events in exchange for rewards. We introduce and
analyse a prediction market that (i) accounts for the historical performance of
the agents, (ii) adapts to time-varying conditions, while (iii) permitting
agents to enter and exit the market at will. The proposed design employs robust
regression models to learn the optimal forecasts' combination whilst handling
missing submissions. Moreover, we introduce a pay-off allocation mechanism that
considers both in-sample and out-of-sample performance while satisfying several
desirable economic properties. Case-studies using simulated and real-world data
allow demonstrating the effectiveness and adaptability of the proposed market
design.

</details>


### [64] [Going with the Flow: Approximating Banzhaf Values via Graph Neural Networks](https://arxiv.org/abs/2510.13391)
*Benjamin Kempinski,Tal Kachman*

Main category: cs.LG

TL;DR: 提出使用图神经网络(GNN)来近似计算网络流博弈中的Banzhaf值，解决了传统方法在大规模系统中的计算瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 传统精确计算方法在超过20个代理时变得不可行，蒙特卡洛采样方法样本复杂度高且无法跨网络配置迁移知识，难以应用于大规模动态系统。

Method: 将问题构建为图级预测任务，使用GNN直接从网络拓扑和控制结构中学习代理影响力的通用模式。比较了GAT、GINE和EdgeConv三种GNN架构。

Result: 训练后的GNN模型实现了高保真度的Banzhaf值近似，相比精确和采样方法有数量级的速度提升。最重要的是展示了强大的零样本泛化能力。

Conclusion: 这项工作确立了GNN作为复杂网络系统可扩展合作博弈论分析的实用工具。

Abstract: Computing the Banzhaf value in network flow games is fundamental for
quantifying agent influence in multi-agent systems, with applications ranging
from cybersecurity to infrastructure planning. However, exact computation is
intractable for systems with more than $\sim20$ agents due to exponential
complexity $\mathcal{O}(2^m)$. While Monte Carlo sampling methods provide
statistical estimates, they suffer from high sample complexity and cannot
transfer knowledge across different network configurations, making them
impractical for large-scale or dynamic systems. We present a novel
learning-based approach using Graph Neural Networks (GNNs) to approximate
Banzhaf values in cardinal network flow games. By framing the problem as a
graph-level prediction task, our method learns generalisable patterns of agent
influence directly from network topology and control structure. We conduct a
comprehensive empirical study comparing three state-of-the-art GNN
architectures-Graph Attention Networks (GAT), Graph Isomorphism Networks with
Edge features (GINE), and EdgeConv-on a large-scale synthetic dataset of
200,000 graphs per configuration, varying in size (20-100 nodes), agent count
(5-20), and edge probability (0.5-1.0). Our results demonstrate that trained
GNN models achieve high-fidelity Banzhaf value approximation with
order-of-magnitude speedups compared to exact and sampling-based methods. Most
significantly, we show strong zero-shot generalisation: models trained on
graphs of a specific size and topology accurately predict Banzhaf values for
entirely new networks with different structural properties, without requiring
retraining. This work establishes GNNs as a practical tool for scalable
cooperative game-theoretic analysis of complex networked systems.

</details>


### [65] [Assessing the robustness of heterogeneous treatment effects in survival analysis under informative censoring](https://arxiv.org/abs/2510.13397)
*Yuxin Wang,Dennis Frauen,Jonas Schweisthal,Maresa Schröder,Stefan Feuerriegel*

Main category: cs.LG

TL;DR: 提出一个假设宽松的框架来评估生存分析中条件平均处理效应(CATE)估计在面临删失偏差时的稳健性，使用部分识别方法推导CATE的信息边界，并开发了一个具有双重稳健性和准oracle效率的新元学习器。


<details>
  <summary>Details</summary>
Motivation: 临床研究中高达一半的患者因副作用或其他原因提前退出，当退出是信息性时（即依赖于生存时间），会引入删失偏差，导致治疗效果估计也存在偏差。现有方法依赖强假设（如非信息性删失）来获得点估计。

Method: 使用部分识别方法推导CATE的信息边界，而不是依赖强假设获得点估计。开发了一个新的元学习器，可以使用任意机器学习模型估计这些边界，并具有双重稳健性和准oracle效率的理论性质。

Result: 通过数值实验和癌症药物试验应用证明了该元学习器的实用价值，能够识别在信息性删失情况下治疗仍然有效的患者亚组。

Conclusion: 该框架提供了一个实用工具，用于在存在删失的情况下评估估计治疗效果的稳健性，从而促进在医学和流行病学中可靠使用生存数据进行证据生成。

Abstract: Dropout is common in clinical studies, with up to half of patients leaving
early due to side effects or other reasons. When dropout is informative (i.e.,
dependent on survival time), it introduces censoring bias, because of which
treatment effect estimates are also biased. In this paper, we propose an
assumption-lean framework to assess the robustness of conditional average
treatment effect (CATE) estimates in survival analysis when facing censoring
bias. Unlike existing works that rely on strong assumptions, such as
non-informative censoring, to obtain point estimation, we use partial
identification to derive informative bounds on the CATE. Thereby, our framework
helps to identify patient subgroups where treatment is effective despite
informative censoring. We further develop a novel meta-learner that estimates
the bounds using arbitrary machine learning models and with favorable
theoretical properties, including double robustness and quasi-oracle
efficiency. We demonstrate the practical value of our meta-learner through
numerical experiments and in an application to a cancer drug trial. Together,
our framework offers a practical tool for assessing the robustness of estimated
treatment effects in the presence of censoring and thus promotes the reliable
use of survival data for evidence generation in medicine and epidemiology.

</details>


### [66] [SWIR-LightFusion: Multi-spectral Semantic Fusion of Synthetic SWIR with {Thermal} IR {(LWIR/MWIR)} and RGB](https://arxiv.org/abs/2510.13404)
*Muhammad Ishfaq Hussain,Ma Van Linh,Zubia Naz,Unse Fatima,Yeongmin Ko,Moongu Jeon*

Main category: cs.LG

TL;DR: 提出了一种从LWIR数据合成SWIR图像的方法，并构建了多模态融合框架，在恶劣能见度条件下提升场景理解能力。


<details>
  <summary>Details</summary>
Motivation: 解决在恶劣能见度条件下传统RGB和热红外成像融合不足的问题，以及SWIR数据集稀缺的挑战。

Method: 使用对比度增强技术从LWIR数据合成SWIR图像，构建包含RGB、LWIR和合成SWIR的多模态融合框架，采用编码器-解码器神经网络架构。

Result: 在多个公开数据集和私有数据集上验证，融合图像质量（对比度、边缘定义、结构保真度）得到提升，同时保持实时性能。

Conclusion: 该方法在监控和自动驾驶系统中具有实际应用潜力，能够有效应对大气干扰和光照不足等挑战。

Abstract: Enhancing scene understanding in adverse visibility conditions remains a
critical challenge for surveillance and autonomous navigation systems.
Conventional imaging modalities, such as RGB and thermal infrared (MWIR /
LWIR), when fused, often struggle to deliver comprehensive scene information,
particularly under conditions of atmospheric interference or inadequate
illumination. To address these limitations, Short-Wave Infrared (SWIR) imaging
has emerged as a promising modality due to its ability to penetrate atmospheric
disturbances and differentiate materials with improved clarity. However, the
advancement and widespread implementation of SWIR-based systems face
significant hurdles, primarily due to the scarcity of publicly accessible SWIR
datasets. In response to this challenge, our research introduces an approach to
synthetically generate SWIR-like structural/contrast cues (without claiming
spectral reproduction) images from existing LWIR data using advanced contrast
enhancement techniques. We then propose a multimodal fusion framework
integrating synthetic SWIR, LWIR, and RGB modalities, employing an optimized
encoder-decoder neural network architecture with modality-specific encoders and
a softmax-gated fusion head. Comprehensive experiments on public {RGB-LWIR
benchmarks (M3FD, TNO, CAMEL, MSRS, RoadScene) and an additional private real
RGB-MWIR-SWIR dataset} demonstrate that our synthetic-SWIR-enhanced fusion
framework improves fused-image quality (contrast, edge definition, structural
fidelity) while maintaining real-time performance. We also add fair trimodal
baselines (LP, LatLRR, GFF) and cascaded trimodal variants of
U2Fusion/SwinFusion under a unified protocol. The outcomes highlight
substantial potential for real-world applications in surveillance and
autonomous systems.

</details>


### [67] [Optimizing Storage Overhead of User Behavior Log for ML-embedded Mobile Apps](https://arxiv.org/abs/2510.13405)
*Chen Gong,Yan Zhuang,Zhenzhe Zheng,Yiliu Chen,Sheng Wang,Fan Wu,Guihai Chen*

Main category: cs.LG

TL;DR: AdaLog是一个轻量级自适应系统，通过消除特征级冗余数据和优化异构行为存储，显著减少移动应用中用户行为日志的存储成本，同时保持模型推理精度和延迟。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型在移动应用中的普及，记录用户行为数据带来了巨大的存储成本，导致系统响应性降低和应用卸载率增加。现有工业实践中存在特征冗余和存储稀疏的问题。

Method: 1) 将特征级冗余数据消除建模为超图中的最大加权匹配问题，提出分层算法；2) 使用虚拟哈希属性设计将异构行为分布到少量日志文件中；3) 设计增量更新机制以适应动态用户行为模式。

Result: 在真实用户数据上的评估显示，AdaLog将行为日志大小减少了19%到44%，系统开销极小（仅2秒延迟和15MB内存使用）。

Conclusion: AdaLog为更广泛采用设备端机器学习提供了更高效的数据基础，有效解决了移动应用中用户行为日志的存储瓶颈问题。

Abstract: Machine learning (ML) models are increasingly integrated into modern mobile
apps to enable personalized and intelligent services. These models typically
rely on rich input features derived from historical user behaviors to capture
user intents. However, as ML-driven services become more prevalent, recording
necessary user behavior data imposes substantial storage cost on mobile apps,
leading to lower system responsiveness and more app uninstalls. To address this
storage bottleneck, we present AdaLog, a lightweight and adaptive system
designed to improve the storage efficiency of user behavior log in ML-embedded
mobile apps, without compromising model inference accuracy or latency. We
identify two key inefficiencies in current industrial practices of user
behavior log: (i) redundant logging of overlapping behavior data across
different features and models, and (ii) sparse storage caused by storing
behaviors with heterogeneous attribute descriptions in a single log file. To
solve these issues, AdaLog first formulates the elimination of feature-level
redundant data as a maximum weighted matching problem in hypergraphs, and
proposes a hierarchical algorithm for efficient on-device deployment. Then,
AdaLog employs a virtually hashed attribute design to distribute heterogeneous
behaviors into a few log files with physically dense storage. Finally, to
ensure scalability to dynamic user behavior patterns, AdaLog designs an
incremental update mechanism to minimize the I/O operations needed for adapting
outdated behavior log. We implement a prototype of AdaLog and deploy it into
popular mobile apps in collaboration with our industry partner. Evaluations on
real-world user data show that AdaLog reduces behavior log size by 19% to 44%
with minimal system overhead (only 2 seconds latency and 15 MB memory usage),
providing a more efficient data foundation for broader adoption of on-device
ML.

</details>


### [68] [When Embedding Models Meet: Procrustes Bounds and Applications](https://arxiv.org/abs/2510.13406)
*Lucas Maystre,Alvaro Ortega Gonzalez,Charles Park,Rares Dolga,Tudor Berariu,Yu Zhao,Kamil Ciosek*

Main category: cs.LG

TL;DR: 本文研究了如何通过正交变换对齐两个嵌入模型，提出了一种简单的对齐方法（Procrustes后处理），使不同嵌入模型能够互操作，同时保持各自嵌入空间的几何结构。


<details>
  <summary>Details</summary>
Motivation: 解决分别训练的相似数据嵌入模型之间缺乏互操作性的问题，这在模型重训练、部分模型升级和多模态搜索等实际应用中带来挑战。

Method: 使用Procrustes后处理方法，通过正交变换对齐两个嵌入集合，前提是成对点积近似保持。

Result: 实验证明该方法在三个应用中有效：跨重训练的兼容性维护、不同文本检索模型的组合以及混合模态搜索的改进，在后者中达到了最先进性能。

Conclusion: 通过简单的正交变换对齐方法，可以有效解决嵌入模型互操作性问题，同时保持原始嵌入空间的几何特性。

Abstract: Embedding models trained separately on similar data often produce
representations that encode stable information but are not directly
interchangeable. This lack of interoperability raises challenges in several
practical applications, such as model retraining, partial model upgrades, and
multimodal search. Driven by these challenges, we study when two sets of
embeddings can be aligned by an orthogonal transformation. We show that if
pairwise dot products are approximately preserved, then there exists an
isometry that closely aligns the two sets, and we provide a tight bound on the
alignment error. This insight yields a simple alignment recipe, Procrustes
post-processing, that makes two embedding models interoperable while preserving
the geometry of each embedding space. Empirically, we demonstrate its
effectiveness in three applications: maintaining compatibility across
retrainings, combining different models for text retrieval, and improving
mixed-modality search, where it achieves state-of-the-art performance.

</details>


### [69] [Modeling Adoptive Cell Therapy in Bladder Cancer from Sparse Biological Data using PINNs](https://arxiv.org/abs/2510.13431)
*Kayode Olumoyin,Katarzyna Rejniak*

Main category: cs.LG

TL;DR: 将物理信息神经网络（PINN）应用于肿瘤学，通过嵌入微分方程建模的动力学系统定律到损失函数中，学习组合疗法在肿瘤微环境中的时变相互作用。


<details>
  <summary>Details</summary>
Motivation: 在肿瘤学中，实验数据通常稀疏且仅包含少量时间点的肿瘤体积数据。通过嵌入从动力学系统先验信息推导的归纳偏置，扩展PINN框架以处理稀疏数据问题。

Method: 扩展物理信息神经网络框架，将观察到的生物约束作为正则化项。该方法能够引导自身找到合理解，并在仅有少量训练样本时具有良好的泛化能力。

Result: 算法成功学习了间歇性治疗的动力学，获得了ODE的解和部分ODE模型参数的时变形式。在MSE、MAE和MAPE等指标上表现出强收敛性。

Conclusion: 改进的PINN算法能够有效处理肿瘤学中的稀疏数据问题，为组合疗法的动力学建模提供了可行方案。

Abstract: Physics-informed neural networks (PINNs) are neural networks that embed the
laws of dynamical systems modeled by differential equations into their loss
function as constraints. In this work, we present a PINN framework applied to
oncology. Here, we seek to learn time-varying interactions due to a combination
therapy in a tumor microenvironment. In oncology, experimental data are often
sparse and composed of a few time points of tumor volume. By embedding
inductive biases derived from prior information about a dynamical system, we
extend the physics-informed neural networks (PINN) and incorporate observed
biological constraints as regularization agents. The modified PINN algorithm is
able to steer itself to a reasonable solution and can generalize well with only
a few training examples. We demonstrate the merit of our approach by learning
the dynamics of treatment applied intermittently in an ordinary differential
equation (ODE) model of a combination therapy. The algorithm yields a solution
to the ODE and time-varying forms of some of the ODE model parameters. We
demonstrate a strong convergence using metrics such as the mean squared error
(MSE), mean absolute error (MAE), and mean absolute percentage error (MAPE).

</details>


### [70] [Hybrid Interval Type-2 Mamdani-TSK Fuzzy System for Regression Analysis](https://arxiv.org/abs/2510.13437)
*Ashish Bhatia,Renato Cordeiro de Amorim,Vito De Feo*

Main category: cs.LG

TL;DR: 提出了一种结合Mamdani系统可解释性和TSK模型精度的新型模糊回归方法，通过混合规则结构和双支配类型，在保持可解释性的同时提高了预测精度。


<details>
  <summary>Details</summary>
Motivation: 传统回归方法难以处理现实数据中的不确定性和模糊性，深度学习缺乏可解释性且在小数据集上容易过拟合，模糊系统在可解释性和准确性之间存在权衡。

Method: 采用混合规则结构，包含模糊和清晰组件以及双支配类型，结合Mamdani系统的可解释性和TSK模型的精度优势。

Result: 在6个基准数据集测试中，该方法在4个数据集上获得最佳模糊方法得分，在2个数据集上优于不透明模型，在1个数据集上获得总体最佳得分，RMSE改进范围从0.4%到19%。

Conclusion: 这种混合方法为预测建模提供了一个平衡且多功能的工具，有效解决了模糊系统中可解释性与准确性之间的权衡问题。

Abstract: Regression analysis is employed to examine and quantify the relationships
between input variables and a dependent and continuous output variable. It is
widely used for predictive modelling in fields such as finance, healthcare, and
engineering. However, traditional methods often struggle with real-world data
complexities, including uncertainty and ambiguity. While deep learning
approaches excel at capturing complex non-linear relationships, they lack
interpretability and risk over-fitting on small datasets. Fuzzy systems provide
an alternative framework for handling uncertainty and imprecision, with Mamdani
and Takagi-Sugeno-Kang (TSK) systems offering complementary strengths:
interpretability versus accuracy. This paper presents a novel fuzzy regression
method that combines the interpretability of Mamdani systems with the precision
of TSK models. The proposed approach introduces a hybrid rule structure with
fuzzy and crisp components and dual dominance types, enhancing both accuracy
and explainability. Evaluations on benchmark datasets demonstrate
state-of-the-art performance in several cases, with rules maintaining a
component similar to traditional Mamdani systems while improving precision
through improved rule outputs. This hybrid methodology offers a balanced and
versatile tool for predictive modelling, addressing the trade-off between
interpretability and accuracy inherent in fuzzy systems. In the 6 datasets
tested, the proposed approach gave the best fuzzy methodology score in 4
datasets, out-performed the opaque models in 2 datasets and produced the best
overall score in 1 dataset with the improvements in RMSE ranging from 0.4% to
19%.

</details>


### [71] [Rectify and Align GPS Points to Parking Spots via Rank-1 Constraint](https://arxiv.org/abs/2510.13439)
*Jiaxing Deng,Junbiao Pang,Zhicheng Wang,Haitao Yu*

Main category: cs.LG

TL;DR: 提出了一种无监督的低秩方法，用于校正停车位GPS点的误差并将其对齐到实际停车位位置，解决了高层建筑导致的GPS漂移问题。


<details>
  <summary>Details</summary>
Motivation: 高层建筑会导致停车位GPS点从实际位置漂移，且低成本GPS设备本身存在定位误差，需要一种无监督方法来校正大量停车位中的错误GPS点。

Method: 基于停车位与道路平行的物理约束，提出无监督低秩方法，在统一框架中同时进行GPS点误差校正和对齐。

Result: 大量实验证明该方法能有效解决实际问题，对任何类型的GPS点误差都简单有效。

Conclusion: 该方法提供了一种简单而有效的解决方案，可用于停车管理、停车政策和城市发展等后续应用。

Abstract: Parking spots are essential components, providing vital mobile resources for
residents in a city. Accurate Global Positioning System (GPS) points of parking
spots are the core data for subsequent applications,e.g., parking management,
parking policy, and urban development. However, high-rise buildings tend to
cause GPS points to drift from the actual locations of parking spots; besides,
the standard lower-cost GPS equipment itself has a certain location error.
Therefore, it is a non-trivial task to correct a few wrong GPS points from a
large number of parking spots in an unsupervised approach. In this paper,
motivated by the physical constraints of parking spots (i.e., parking spots are
parallel to the sides of roads), we propose an unsupervised low-rank method to
effectively rectify errors in GPS points and further align them to the parking
spots in a unified framework. The proposed unconventional rectification and
alignment method is simple and yet effective for any type of GPS point errors.
Extensive experiments demonstrate the superiority of the proposed method to
solve a practical problem. The data set and the code are publicly accessible
at:https://github.com/pangjunbiao/ITS-Parking-spots-Dataset.

</details>


### [72] [Neural Sum-of-Squares: Certifying the Nonnegativity of Polynomials with Transformers](https://arxiv.org/abs/2510.13444)
*Nico Pelleriti,Christoph Spiegel,Shiwei Liu,David Martínez-Rubio,Max Zimmer,Sebastian Pokutta*

Main category: cs.LG

TL;DR: 提出首个学习增强算法来验证多项式非负性的SOS准则，通过Transformer模型预测几乎最小的单项式基，大幅减少相应SDP问题规模，实现100倍以上的加速。


<details>
  <summary>Details</summary>
Motivation: 验证多项式非负性是NP难问题，SOS条件是充分条件但计算昂贵，需要求解维度随单项式基大小二次增长的SDP，现有方法在减少基规模方面仍有局限。

Method: 训练Transformer模型预测几乎最小的单项式基，包含三个关键组件：生成超过1亿个SOS多项式的训练数据集、设计和训练Transformer架构、确保正确终止的系统性回退机制。

Result: 在200多个基准数据集上验证，相比最先进求解器实现100倍以上加速，能够解决竞争方法失败的实例。

Conclusion: 该方法为提升SOS编程的实际可扩展性提供了新见解，通过学习增强方法显著提高了SOS验证的效率。

Abstract: Certifying nonnegativity of polynomials is a well-known NP-hard problem with
direct applications spanning non-convex optimization, control, robotics, and
beyond. A sufficient condition for nonnegativity is the Sum of Squares (SOS)
property, i.e., it can be written as a sum of squares of other polynomials. In
practice, however, certifying the SOS criterion remains computationally
expensive and often involves solving a Semidefinite Program (SDP), whose
dimensionality grows quadratically in the size of the monomial basis of the SOS
expression; hence, various methods to reduce the size of the monomial basis
have been proposed. In this work, we introduce the first learning-augmented
algorithm to certify the SOS criterion. To this end, we train a Transformer
model that predicts an almost-minimal monomial basis for a given polynomial,
thereby drastically reducing the size of the corresponding SDP. Our overall
methodology comprises three key components: efficient training dataset
generation of over 100 million SOS polynomials, design and training of the
corresponding Transformer architecture, and a systematic fallback mechanism to
ensure correct termination, which we analyze theoretically. We validate our
approach on over 200 benchmark datasets, achieving speedups of over $100\times$
compared to state-of-the-art solvers and enabling the solution of instances
where competing approaches fail. Our findings provide novel insights towards
transforming the practical scalability of SOS programming.

</details>


### [73] [$L_2$-Regularized Empirical Risk Minimization Guarantees Small Smooth Calibration Error](https://arxiv.org/abs/2510.13450)
*Masahiro Fujisawa,Futoshi Futami*

Main category: cs.LG

TL;DR: 该论文首次从理论上证明，标准的L2正则化经验风险最小化可以直接控制平滑校准误差，无需后处理校准或专门的校准促进正则化器。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习中预测概率的校准对于可靠性至关重要，但标准训练程序如何产生良好校准模型的理解不足。

Method: 基于优化误差、正则化强度和Rademacher复杂度，建立了平滑校准误差的有限样本泛化边界，并在再生核希尔伯特空间中实例化该理论。

Result: 实验验证了理论保证，表明L2正则化ERM可以提供良好校准模型，无需增强或后处理重新校准。

Conclusion: 标准L2正则化经验风险最小化本身就能提供良好的概率校准，无需额外的校准技术。

Abstract: Calibration of predicted probabilities is critical for reliable machine
learning, yet it is poorly understood how standard training procedures yield
well-calibrated models. This work provides the first theoretical proof that
canonical $L_{2}$-regularized empirical risk minimization directly controls the
smooth calibration error (smCE) without post-hoc correction or specialized
calibration-promoting regularizer. We establish finite-sample generalization
bounds for smCE based on optimization error, regularization strength, and the
Rademacher complexity. We then instantiate this theory for models in
reproducing kernel Hilbert spaces, deriving concrete guarantees for kernel
ridge and logistic regression. Our experiments confirm these specific
guarantees, demonstrating that $L_{2}$-regularized ERM can provide a
well-calibrated model without boosting or post-hoc recalibration. The source
code to reproduce all experiments is available at
https://github.com/msfuji0211/erm_calibration.

</details>


### [74] [Towards Blackwell Optimality: Bellman Optimality Is All You Can Get](https://arxiv.org/abs/2510.13476)
*Victor Boone,Adrienne Tuynman*

Main category: cs.LG

TL;DR: 本文研究了马尔可夫决策过程中偏差最优性层次结构的策略识别问题，构建了具有渐近误差的学习算法，并确定了能在有限时间内停止识别的MDP类别。


<details>
  <summary>Details</summary>
Motivation: 平均收益最优性在MDP中过于渐近，需要结合即时损失度量来考虑偏差最优性层次结构，从偏差最优到Blackwell最优。

Method: 为每个最优性阶构建学习算法，具有渐近消失的错误概率；确定能在有限时间内停止识别的MDP类别；提供可处理的停止规则。

Result: 构造了具有渐近误差的学习算法；确定了唯一Bellman最优策略的MDP类别可以在有限时间内停止识别；提供了与学习算法耦合的停止规则。

Conclusion: 该工作为偏差最优性层次结构的策略识别提供了理论框架和实用算法，特别关注了有限时间停止的可能性条件。

Abstract: Although average gain optimality is a commonly adopted performance measure in
Markov Decision Processes (MDPs), it is often too asymptotic. Further
incorporating measures of immediate losses leads to the hierarchy of bias
optimalities, all the way up to Blackwell optimality. In this paper, we
investigate the problem of identifying policies of such optimality orders. To
that end, for each order, we construct a learning algorithm with vanishing
probability of error. Furthermore, we characterize the class of MDPs for which
identification algorithms can stop in finite time. That class corresponds to
the MDPs with a unique Bellman optimal policy, and does not depend on the
optimality order considered. Lastly, we provide a tractable stopping rule that
when coupled to our learning algorithm triggers in finite time whenever it is
possible to do so.

</details>


### [75] [Tahakom LLM guidelines and receipts: from pre-training data to an Arabic LLM](https://arxiv.org/abs/2510.13481)
*Areej AlOtaibi,Lina Alyahya,Raghad Alshabanah,Shahad Alfawzan,Shuruq Alarefei,Reem Alsabti,Nouf Alsubaie,Abdulaziz Alhuzaymi,Lujain Alkhelb,Majd Alsayari,Waad Alahmed,Omar Talabay,Jalal Alowibdi,Salem Alelyani,Adel Bibi*

Main category: cs.LG

TL;DR: 本文探讨了开发阿拉伯语大语言模型(LLM)的挑战，重点关注数据整理、分词器设计和评估方法，并分享了相关数据和方法的透明化实践。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语LLM开发面临独特挑战，需要解决数据收集、分词器优化和评估框架不足等问题，以促进阿拉伯语自然语言处理的发展。

Method: 采用系统化方法：收集和过滤阿拉伯语预训练数据集，评估不同分词器设计对模型性能的影响，并提出针对现有阿拉伯语评估框架局限性的纠正方法。

Result: 开发了阿拉伯语LLM的数据整理和分词器设计方法，提出了改进的评估框架，并公开分享了相关数据和方法。

Conclusion: 通过系统化解决阿拉伯语LLM开发的关键挑战，促进了阿拉伯语语言建模的进步，并通过透明化实践支持了协作发展。

Abstract: Large Language Models (LLMs) have significantly advanced the field of natural
language processing, enhancing capabilities in both language understanding and
generation across diverse domains. However, developing LLMs for Arabic presents
unique challenges. This paper explores these challenges by focusing on critical
aspects such as data curation, tokenizer design, and evaluation. We detail our
approach to the collection and filtration of Arabic pre-training datasets,
assess the impact of various tokenizer designs on model performance, and
examine the limitations of existing Arabic evaluation frameworks, for which we
propose a systematic corrective methodology. To promote transparency and
facilitate collaborative development, we share our data and methodologies,
contributing to the advancement of language modeling, particularly for the
Arabic language.

</details>


### [76] [DistilCLIP-EEG: Enhancing Epileptic Seizure Detection Through Multi-modal Learning and Knowledge Distillation](https://arxiv.org/abs/2510.13497)
*Zexin Wang,Lin Shi,Haoyu Wu,Junru Luo,Xiangzeng Kong,Jun Qi*

Main category: cs.LG

TL;DR: 提出基于CLIP框架的多模态癫痫检测模型DistilCLIP-EEG，整合EEG信号和文本描述，通过知识蒸馏训练轻量级学生模型，在多个数据集上准确率超过97%，模型大小减少41.9%。


<details>
  <summary>Details</summary>
Motivation: 现有癫痫检测深度学习方法仅依赖单模态EEG信号，忽视了多模态信息的潜在优势，需要开发能整合EEG和文本描述的综合特征提取方法。

Method: 基于CLIP框架构建多模态模型，使用Conformer架构的EEG编码器和可学习BERT作为文本编码器，在共享潜在空间进行跨模态表示学习，并通过知识蒸馏训练更紧凑的学生模型。

Result: 在TUSZ、AUBMC和CHB-MIT数据集上，师生模型准确率均超过97%，F1分数均高于0.94，学生模型参数量和大小仅为教师模型的58.1%。

Conclusion: 该模型在癫痫检测中表现出色，为资源受限环境部署轻量级模型奠定了坚实基础，展示了多模态方法在EEG分析中的潜力。

Abstract: Epilepsy is a prevalent neurological disorder marked by sudden, brief
episodes of excessive neuronal activity caused by abnormal electrical
discharges, which may lead to some mental disorders. Most existing deep
learning methods for epilepsy detection rely solely on unimodal EEG signals,
neglecting the potential benefits of multimodal information. To address this,
we propose a novel multimodal model, DistilCLIP-EEG, based on the CLIP
framework, which integrates both EEG signals and text descriptions to capture
comprehensive features of epileptic seizures. The model involves an EEG encoder
based on the Conformer architecture as a text encoder, the proposed Learnable
BERT (BERT-LP) as prompt learning within the encoders. Both operate in a shared
latent space for effective cross-modal representation learning. To enhance
efficiency and adaptability, we introduce a knowledge distillation method where
the trained DistilCLIP-EEG serves as a teacher to guide a more compact student
model to reduce training complexity and time. On the TUSZ, AUBMC, and CHB-MIT
datasets, both the teacher and student models achieved accuracy rates exceeding
97%. Across all datasets, the F1-scores were consistently above 0.94,
demonstrating the robustness and reliability of the proposed framework.
Moreover, the student model's parameter count and model size are approximately
58.1% of those of the teacher model, significantly reducing model complexity
and storage requirements while maintaining high performance. These results
highlight the potential of our proposed model for EEG-based epilepsy detection
and establish a solid foundation for deploying lightweight models in
resource-constrained settings.

</details>


### [77] [Offline and Online KL-Regularized RLHF under Differential Privacy](https://arxiv.org/abs/2510.13512)
*Yulian Wu,Rushil Thareja,Praneeth Vepakomma,Francesco Orabona*

Main category: cs.LG

TL;DR: 本文研究了在局部差分隐私（LDP）条件下，基于人类反馈的强化学习（RLHF）的离线和在线设置，提出了新的算法并分析了其理论性能。


<details>
  <summary>Details</summary>
Motivation: 研究在隐私保护（LDP）条件下RLHF的性能，填补该领域在理论分析上的空白，特别是在KL正则化目标下的隐私保护RLHF问题。

Method: 在离线设置中采用悲观主义原则设计算法，在在线设置中采用乐观主义原则设计算法，并分析其在LDP条件下的理论性能。

Result: 离线设置中获得了$\tilde{O}(1/[(e^\epsilon-1)^2 n])$的最优次优性差距；在线设置中获得了$O(d_{\mathcal{F}}\log(N_{\mathcal{F}}\cdot T)/(e^\epsilon-1)^2)$的对数遗憾界。

Conclusion: 本文首次在理论上研究了LDP条件下的KL正则化RLHF问题，提出了有效的算法并证明了其最优性，同时为无隐私的在线KL正则化RLHF提供了首个理论分析。

Abstract: In this paper, we study the offline and online settings of reinforcement
learning from human feedback (RLHF) with KL-regularization -- a widely used
objective function in large language model alignment -- under the $\epsilon$
local differential privacy ($\epsilon$-LDP) model on the label of the human
preference. In the offline setting, we design an algorithm based on the
principle of pessimism and derive a new suboptimality gap of
$\tilde{O}(1/[(e^\epsilon-1)^2 n])$ on the KL-regularized objective under
single-policy concentrability. We also prove its optimality by providing a
matching lower bound where $n$ is the sample size.
  In the online setting, we are the first one to theoretically investigate the
problem of KL-regularized RLHF with LDP. We design an optimism-based algorithm
and derive a logarithmic regret bound of $O(d_{\mathcal{F}}\log
(N_{\mathcal{F}}\cdot T) /(e^\epsilon-1)^2 )$, where $T$ is the total time
step, $N_{\mathcal{F}}$ is cardinality of the reward function space
$\mathcal{F}$ and $d_{\mathcal{F}}$ is a variant of eluder dimension for RLHF.
As a by-product of our analysis, our results also imply the first analysis for
online KL-regularized RLHF without privacy. We implement our algorithm in the
offline setting to verify our theoretical results and release our open source
code at: https://github.com/rushil-thareja/PPKL-RLHF-Official.

</details>


### [78] [K-Merge: Online Continual Merging of Adapters for On-device Large Language Models](https://arxiv.org/abs/2510.13537)
*Donald Shenaj,Ondrej Bohdal,Taha Ceritli,Mete Ozay,Pietro Zanuttigh,Umberto Michieli*

Main category: cs.LG

TL;DR: 提出了一种在设备存储有限的情况下，用于在线持续合并LoRA适配器的数据无关且计算高效的方法


<details>
  <summary>Details</summary>
Motivation: 解决移动设备上大语言模型部署时，由于LoRA适配器增量交付带来的在线持续合并挑战，需要在存储限制下保持先前任务性能

Method: 使用数据无关且计算高效的策略来选择和新LoRA合并，设备只能存储有限数量的适配器

Result: 在真实世界任务上的广泛实验表明，该方法在遵守设备存储和计算限制的同时，优于其他替代策略

Conclusion: 该方法能够有效支持设备上的在线持续LoRA合并，在资源受限环境下保持任务性能

Abstract: On-device deployment of Large Language Models (LLMs) frequently leverages
Low-Rank Adapters (LoRAs) to support diverse downstream tasks under tight
resource constraints. To address the limited storage capacity of mobile
devices, recent works have explored model merging techniques to fuse multiple
LoRAs into a single one. In practice, however, LoRAs are often delivered
incrementally, as users request support for new tasks (e.g., novel problem
types or languages). This scenario introduces a new challenge: on-device online
continual merging, where the objective is to incorporate new LoRAs while
preserving the performance on previously supported tasks. In this paper, we
propose a data-free and computationally efficient strategy for selecting and
merging LoRAs when a new one becomes available, assuming the device can store
only a limited number of adapters. Extensive experiments across real-world
tasks demonstrate the superiority of our approach compared to alternative
strategies while adhering to the storage budget and compute limitations of
on-device settings.

</details>


### [79] [ProtoTopic: Prototypical Network for Few-Shot Medical Topic Modeling](https://arxiv.org/abs/2510.13542)
*Martin Licht,Sara Ketabi,Farzad Khalvati*

Main category: cs.LG

TL;DR: ProtoTopic是一种基于原型网络的主题模型，专门用于医学论文摘要的主题生成，在数据有限的情况下表现优于传统主题建模方法。


<details>
  <summary>Details</summary>
Motivation: 传统主题建模技术在医学文本上表现不佳，特别是当某些医疗主题的文档数量较少时。

Method: 使用原型网络构建主题模型，通过计算输入数据点与原型表示之间的距离来进行预测，特别适用于低数据或小样本学习场景。

Result: 与文献中使用的两种主题建模基线相比，ProtoTopic在主题连贯性和多样性方面都有所改善。

Conclusion: 该模型能够在数据有限的情况下生成医学相关主题，证明了原型网络在医学文本主题建模中的有效性。

Abstract: Topic modeling is a useful tool for analyzing large corpora of written
documents, particularly academic papers. Despite a wide variety of proposed
topic modeling techniques, these techniques do not perform well when applied to
medical texts. This can be due to the low number of documents available for
some topics in the healthcare domain. In this paper, we propose ProtoTopic, a
prototypical network-based topic model used for topic generation for a set of
medical paper abstracts. Prototypical networks are efficient, explainable
models that make predictions by computing distances between input datapoints
and a set of prototype representations, making them particularly effective in
low-data or few-shot learning scenarios. With ProtoTopic, we demonstrate
improved topic coherence and diversity compared to two topic modeling baselines
used in the literature, demonstrating the ability of our model to generate
medically relevant topics even with limited data.

</details>


### [80] [Multi-Objective $\textit{min-max}$ Online Convex Optimization](https://arxiv.org/abs/2510.13560)
*Rahul Vaze,Sumiran Mishra*

Main category: cs.LG

TL;DR: 本文提出了多目标在线凸优化问题，考虑K个不同的损失函数序列，目标是设计算法使最小-最大遗憾达到O(√(T log K))。


<details>
  <summary>Details</summary>
Motivation: 扩展传统在线凸优化(OCO)框架，考虑多目标场景，其中存在K个不同的损失函数序列，需要同时跟踪所有序列的性能。

Method: 结合经典的Hedge算法和在线梯度下降(OGD)方法，提出一个简单算法来处理多目标OCO问题。

Result: 在i.i.d.输入设置下，证明了该算法的期望最小-最大遗憾为O(√(T log K))。

Conclusion: 提出的算法能够有效处理多目标在线凸优化问题，通过简单的证明获得了接近最优的遗憾界。

Abstract: In online convex optimization (OCO), a single loss function sequence is
revealed over a time horizon of $T$, and an online algorithm has to choose its
action at time $t$, before the loss function at time $t$ is revealed. The goal
of the online algorithm is to incur minimal penalty (called $\textit{regret}$
compared to a static optimal action made by an optimal offline algorithm
knowing all functions of the sequence in advance.
  In this paper, we broaden the horizon of OCO, and consider multi-objective
OCO, where there are $K$ distinct loss function sequences, and an algorithm has
to choose its action at time $t$, before the $K$ loss functions at time $t$ are
revealed. To capture the tradeoff between tracking the $K$ different sequences,
we consider the $\textit{min-max}$ regret, where the benchmark (optimal offline
algorithm) takes a static action across all time slots that minimizes the
maximum of the total loss (summed across time slots) incurred by each of the
$K$ sequences. An online algorithm is allowed to change its action across time
slots, and its {\it min-max} regret is defined as the difference between its
$\textit{min-max}$ cost and that of the benchmark. The $\textit{min-max}$
regret is a stringent performance measure and an algorithm with small regret
needs to `track' all loss function sequences closely at all times.
  We consider this $\textit{min-max}$ regret in the i.i.d. input setting where
all loss functions are i.i.d. generated from an unknown distribution. For the
i.i.d. model we propose a simple algorithm that combines the well-known
$\textit{Hedge}$ and online gradient descent (OGD) and show via a remarkably
simple proof that its expected $\textit{min-max}$ regret is $O(\sqrt{T \log
K})$.

</details>


### [81] [DOLFIN: Balancing Stability and Plasticity in Federated Continual Learning](https://arxiv.org/abs/2510.13567)
*Omayma Moussadek,Riccardo Salami,Simone Calderara*

Main category: cs.LG

TL;DR: 提出了DOLFIN方法，结合Vision Transformers和低秩适配器，在联邦持续学习中高效稳定地学习新任务，同时最小化通信开销和防止遗忘。


<details>
  <summary>Details</summary>
Motivation: 联邦持续学习需要在保护隐私、通信效率和性能之间取得平衡，现有方法面临挑战。

Method: 使用低秩适配器(LoRA)减少通信开销，结合DualGradient Projection Memory防止遗忘，在Vision Transformers上实现。

Result: 在CIFAR-100、ImageNet-R、ImageNet-A和CUB-200数据集上，DOLFIN在最终平均准确率上持续超越六个强基线方法，同时保持相同的内存占用。

Conclusion: 正交低秩适配器为联邦环境中的隐私保护持续学习提供了有效且可扩展的解决方案。

Abstract: Federated continual learning (FCL) enables models to learn new tasks across
multiple distributed clients, protecting privacy and without forgetting
previously acquired knowledge. However, current methods face challenges
balancing performance, privacy preservation, and communication efficiency. We
introduce a Distributed Online LoRA for Federated INcremental learning method
DOLFIN, a novel approach combining Vision Transformers with low-rank adapters
designed to efficiently and stably learn new tasks in federated environments.
Our method leverages LoRA for minimal communication overhead and incorporates
DualGradient Projection Memory (DualGPM) to prevent forgetting. Evaluated on
CIFAR-100, ImageNet-R, ImageNet-A, and CUB-200 under two Dirichlet
heterogeneity settings, DOLFIN consistently surpasses six strong baselines in
final average accuracy while matching their memory footprint. Orthogonal
low-rank adapters offer an effective and scalable solution for
privacy-preserving continual learning in federated settings.

</details>


### [82] [Selective Adversarial Attacks on LLM Benchmarks](https://arxiv.org/abs/2510.13570)
*Ivan Dubrovsky,Anastasia Orlova,Illarion Iov,Nina Gubina,Irena Gureeva,Alexey Zaytsev*

Main category: cs.LG

TL;DR: 本文研究了在MMLU基准测试上的选择性对抗攻击，发现即使微小的文本扰动也能显著改变语言模型的相对排名，挑战了排行榜评估的公平性和可复现性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估基准容易受到语义等效的对抗扰动影响，但现有研究主要关注对所有模型产生同等影响的攻击，而缺乏对选择性攻击（即仅针对特定模型性能）的研究。

Method: 使用TextAttack框架中的标准攻击方法，开发了选择性评估协议和自定义约束，提出了基于代理LLM的管道来生成选择性扰动。

Result: 实证研究发现选择性对抗攻击确实存在，并且能够实质性地改变模型的相对排名，表明即使是细微的编辑也能影响比较判断。

Conclusion: 研究结果强调了在LLM评估中需要采用扰动感知的报告和鲁棒性诊断，以确保评估的公平性、可复现性和透明度。

Abstract: Benchmarking outcomes increasingly govern trust, selection, and deployment of
LLMs, yet these evaluations remain vulnerable to semantically equivalent
adversarial perturbations. Prior work on adversarial robustness in NLP has
emphasized text attacks that affect many models equally, leaving open the
question of whether it is possible to selectively degrade or enhance
performance while minimally affecting other models. We formalize this problem
and study selective adversarial attacks on MMLU - a widely used benchmark
designed to measure a language model's broad general knowledge and reasoning
ability across different subjects. Using canonical attacks integrated into
TextAttack framework, we introduce a protocol for selectivity assessment,
develop a custom constraint to increase selectivity of attacks and propose a
surrogate-LLM pipeline that generates selective perturbations. Empirically, we
find that selective adversarial attacks exist and can materially alter relative
rankings, challenging the fairness, reproducibility, and transparency of
leaderboard-driven evaluation. Our results motivate perturbation-aware
reporting and robustness diagnostics for LLM evaluation and demonstrate that
even subtle edits can shift comparative judgments.

</details>


### [83] [ArtNet: Hierarchical Clustering-Based Artificial Netlist Generator for ML and DTCO Application](https://arxiv.org/abs/2510.13582)
*Andrew B. Kahng. Seokhyeong Kang,Seonghyeon Park,Dooseok Yoon*

Main category: cs.LG

TL;DR: ArtNet是一种新型的人工网表生成器，通过生成具有关键拓扑特征的多样化训练数据，提升机器学习模型的泛化能力，支持更广泛的设计空间探索，从而解决先进节点中PPA优化的复杂挑战。


<details>
  <summary>Details</summary>
Motivation: 在先进节点中，功耗、性能和面积（PPA）的优化变得高度复杂和具有挑战性。机器学习和设计技术协同优化（DTCO）虽然提供了有前景的解决方案，但由于缺乏多样化的训练数据以及设计流程周转时间较长而面临限制。

Method: 提出ArtNet人工网表生成器，与之前的方法不同，ArtNet复制关键拓扑特征，增强ML模型泛化能力，支持更广泛的DTCO设计空间探索。通过生成更接近给定目标参数的逼真人工数据集，实现更高效的PPA优化。

Result: 在基于CNN的DRV预测中，ArtNet的数据增强使F1分数比仅使用原始（真实）数据集提高了0.16。在DTCO背景下，ArtNet生成的mini-brains实现了高达97.94%的PPA匹配度，与目标全规模块设计的设计指标高度一致。

Conclusion: ArtNet通过生成多样化且逼真的人工网表数据集，有效解决了ML和DTCO中训练数据不足的问题，显著提升了PPA优化的效率和效果，为先进节点设计提供了有力的数据增强工具。

Abstract: In advanced nodes, optimization of power, performance and area (PPA) has
become highly complex and challenging. Machine learning (ML) and
design-technology co-optimization (DTCO) provide promising mitigations, but
face limitations due to a lack of diverse training data as well as long design
flow turnaround times (TAT). We propose ArtNet, a novel artificial netlist
generator designed to tackle these issues. Unlike previous methods, ArtNet
replicates key topological characteristics, enhancing ML model generalization
and supporting broader design space exploration for DTCO. By producing
realistic artificial datasets that moreclosely match given target parameters,
ArtNet enables more efficient PPAoptimization and exploration of flows and
design enablements. In the context of CNN-based DRV prediction, ArtNet's data
augmentationimproves F1 score by 0.16 compared to using only the original
(real) dataset. In the DTCO context, ArtNet-generated mini-brains achieve a PPA
match up to 97.94%, demonstrating close alignment with design metrics of
targeted full-scale block designs.

</details>


### [84] [EEGChaT: A Transformer-Based Modular Channel Selector for SEEG Analysis](https://arxiv.org/abs/2510.13592)
*Chen Wang,Yansen Wang,Dongqi Han,Zilong Wang,Dongsheng Li*

Main category: cs.LG

TL;DR: EEGChaT是一种基于Transformer的通道选择模块，能够自动识别SEEG记录中最具任务相关性的通道，通过改进的Attention Rollout技术提供可解释的通道重要性评分。


<details>
  <summary>Details</summary>
Motivation: SEEG信号分析面临输入通道数量大且相关性异质的挑战，传统通道选择方法难以扩展且缺乏可解释性。

Method: 提出EEGChaT模块，引入通道聚合令牌(CATs)聚合跨通道信息，利用改进的Attention Rollout技术计算通道重要性分数。

Result: 在DuIN数据集上的评估显示，EEGChaT与现有分类模型结合能持续提高解码准确率，最高提升17%，且通道权重与人工选择通道有显著重叠。

Conclusion: EEGChaT是高维SEEG分析中有效且可泛化的通道选择解决方案，既提升性能又提供神经信号相关性的洞察。

Abstract: Analyzing stereoelectroencephalography (SEEG) signals is critical for
brain-computer interface (BCI) applications and neuroscience research, yet
poses significant challenges due to the large number of input channels and
their heterogeneous relevance. Traditional channel selection methods struggle
to scale or provide meaningful interpretability for SEEG data. In this work, we
propose EEGChaT, a novel Transformer-based channel selection module designed to
automatically identify the most task-relevant channels in SEEG recordings.
EEGChaT introduces Channel Aggregation Tokens (CATs) to aggregate information
across channels, and leverages an improved Attention Rollout technique to
compute interpretable, quantitative channel importance scores. We evaluate
EEGChaT on the DuIN dataset, demonstrating that integrating EEGChaT with
existing classification models consistently improves decoding accuracy,
achieving up to 17\% absolute gains. Furthermore, the channel weights produced
by EEGChaT show substantial overlap with manually selected channels, supporting
the interpretability of the approach. Our results suggest that EEGChaT is an
effective and generalizable solution for channel selection in high-dimensional
SEEG analysis, offering both enhanced performance and insights into neural
signal relevance.

</details>


### [85] [Physics-augmented Multi-task Gaussian Process for Modeling Spatiotemporal Dynamics](https://arxiv.org/abs/2510.13601)
*Xizhuo Zhang,Bing Yao*

Main category: cs.LG

TL;DR: 提出了一种物理增强的多任务高斯过程框架，用于建模高维时空动态系统，通过结合几何感知的多任务高斯过程和物理规律正则化来提升预测精度。


<details>
  <summary>Details</summary>
Motivation: 当前高维时空数据建模面临几何结构不规则、时间动态快速、多变量联合预测等挑战，需要开发能够有效结合物理规律和几何先验的模型。

Method: 开发了几何感知的多任务高斯过程模型来捕捉时空结构和任务间依赖关系，并通过物理规律正则化方案将控制物理定律融入模型。

Result: 在3D心脏电动力学建模任务上的数值实验表明，该方法通过有效整合领域特定的物理约束和几何先验，显著优于现有方法的预测精度。

Conclusion: 物理增强的多任务高斯过程框架能够有效建模复杂时空动态系统，通过结合物理规律和几何先验显著提升模型性能。

Abstract: Recent advances in sensing and imaging technologies have enabled the
collection of high-dimensional spatiotemporal data across complex geometric
domains. However, effective modeling of such data remains challenging due to
irregular spatial structures, rapid temporal dynamics, and the need to jointly
predict multiple interrelated physical variables. This paper presents a
physics-augmented multi-task Gaussian Process (P-M-GP) framework tailored for
spatiotemporal dynamic systems. Specifically, we develop a geometry-aware,
multi-task Gaussian Process (M-GP) model to effectively capture intrinsic
spatiotemporal structure and inter-task dependencies. To further enhance the
model fidelity and robustness, we incorporate governing physical laws through a
physics-based regularization scheme, thereby constraining predictions to be
consistent with governing dynamical principles. We validate the proposed P-M-GP
framework on a 3D cardiac electrodynamics modeling task. Numerical experiments
demonstrate that our method significantly improves prediction accuracy over
existing methods by effectively incorporating domain-specific physical
constraints and geometric prior.

</details>


### [86] [Towards Robust Knowledge Removal in Federated Learning with High Data Heterogeneity](https://arxiv.org/abs/2510.13606)
*Riccardo Santi,Riccardo Salami,Simone Calderara*

Main category: cs.LG

TL;DR: 提出了一种基于任务算术和神经正切核的创新方法，用于快速从模型中移除客户端的影响，解决联邦学习中数据删除的时效性问题。


<details>
  <summary>Details</summary>
Motivation: 由于隐私法规和安全要求，联邦学习需要能够有效删除客户端贡献的机制。现有方法需要多轮通信，导致模型在删除过程中不可用，影响系统服务。

Method: 采用任务算术和神经正切核技术，实现快速移除客户端对模型的影响。

Result: 开发了一种高效的客户端贡献删除方法，显著减少了通信轮次和删除时间。

Conclusion: 该方法能够满足隐私保护要求，同时保持模型在删除过程中的可用性，提升了联邦学习系统的实用性。

Abstract: Nowdays, there are an abundance of portable devices capable of collecting
large amounts of data and with decent computational power. This opened the
possibility to train AI models in a distributed manner, preserving the
participating clients' privacy. However, because of privacy regulations and
safety requirements, elimination upon necessity of a client contribution to the
model has become mandatory. The cleansing process must satisfy specific
efficacy and time requirements. In recent years, research efforts have produced
several knowledge removal methods, but these require multiple communication
rounds between the data holders and the process coordinator. This can cause the
unavailability of an effective model up to the end of the removal process,
which can result in a disservice to the system users. In this paper, we
introduce an innovative solution based on Task Arithmetic and the Neural
Tangent Kernel, to rapidly remove a client's influence from a model.

</details>


### [87] [Message Passing on the Edge: Towards Scalable and Expressive GNNs](https://arxiv.org/abs/2510.13615)
*Pablo Barceló,Fabian Jogl,Alexander Kozachinskiy,Matthias Lanzinger,Stefan Neumann,Cristóbal Rojas*

Main category: cs.LG

TL;DR: 提出了EB-1WL（基于边的颜色细化测试）和EB-GNN架构，该架构在消息传递中显式使用三角形，比1-WL更具表达能力，且在实践任务中保持近线性时间和内存复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有GNN架构表达能力有限，且更强大的架构通常计算成本高昂。需要设计既具强表达能力又保持计算效率的GNN架构。

Method: 基于Chiba和Nishizeki的经典三角形计数算法，提出EB-1WL测试和EB-GNN架构，在消息传递过程中显式利用三角形结构。

Result: EB-1WL比1-WL显著更具表达能力；EB-GNN在保持近线性时间/内存复杂度的同时，性能大幅优于简单MPNN，与任务专用GNN竞争且计算效率更高。

Conclusion: EB-GNN是一种高效通用的GNN架构，在表达能力和计算效率之间取得了良好平衡，为图学习任务提供了实用的解决方案。

Abstract: We propose EB-1WL, an edge-based color-refinement test, and a corresponding
GNN architecture, EB-GNN. Our architecture is inspired by a classic triangle
counting algorithm by Chiba and Nishizeki, and explicitly uses triangles during
message passing. We achieve the following results: (1)~EB-1WL is significantly
more expressive than 1-WL. Further, we provide a complete logical
characterization of EB-1WL based on first-order logic, and matching
distinguishability results based on homomorphism counting. (2)~In an important
distinction from previous proposals for more expressive GNN architectures,
EB-1WL and EB-GNN require near-linear time and memory on practical graph
learning tasks. (3)~Empirically, we show that EB-GNN is a highly-efficient
general-purpose architecture: It substantially outperforms simple MPNNs, and
remains competitive with task-specialized GNNs while being significantly more
computationally efficient.

</details>


### [88] [Manifold Decoders: A Framework for Generative Modeling from Nonlinear Embeddings](https://arxiv.org/abs/2510.13622)
*Riddhish Thakare,Kingdom Mutala Akugri*

Main category: cs.LG

TL;DR: 该论文提出了一个系统框架，为经典非线性降维方法构建神经解码器，首次实现双向映射，并在此基础上开发了在流形空间直接操作的扩散生成过程。


<details>
  <summary>Details</summary>
Motivation: 经典非线性降维技术如t-SNE、Isomap和LLE虽然擅长创建低维嵌入用于数据可视化，但缺乏将嵌入映射回原始高维空间的能力，这种单向转换限制了它们在生成应用中的使用。

Method: 构建神经解码器架构用于主要NLDR方法，实现双向映射，并扩展该框架实现基于扩散的生成过程，在学习的流形空间直接操作。

Result: 在CelebA数据集上的实验表明，解码器能够成功重建数据，但质量被端到端优化的自编码器超越；流形约束扩散产生的样本质量较差，表明经典NLDR嵌入的离散稀疏特性不适合生成模型所需的连续插值。

Conclusion: 这项工作突显了在为可视化分析设计的NLDR方法上添加生成能力所面临的固有挑战。

Abstract: Classical nonlinear dimensionality reduction (NLDR) techniques like t-SNE,
Isomap, and LLE excel at creating low-dimensional embeddings for data
visualization but fundamentally lack the ability to map these embeddings back
to the original high-dimensional space. This one-way transformation limits
their use in generative applications. This paper addresses this critical gap by
introducing a system- atic framework for constructing neural decoder
architectures for prominent NLDR methods, enabling bidirectional mapping for
the first time. We extend this framework by implementing a diffusion-based
generative process that operates directly within these learned manifold spaces.
Through experiments on the CelebA dataset, we evaluate the reconstruction and
generative performance of our approach against autoencoder and standard
diffusion model baselines. Our findings reveal a fundamental trade- off: while
the decoders successfully reconstruct data, their quality is surpassed by
end-to-end optimized autoencoders. Moreover, manifold-constrained diffusion
yields poor-quality samples, suggesting that the discrete and sparse nature of
classical NLDR embeddings is ill-suited for the continuous inter- polation
required by generative models. This work highlights the inherent challenges in
retrofitting generative capabilities onto NLDR methods designed primarily for
visualization and analysis.

</details>


### [89] [Multivariate Time Series Forecasting with Gate-Based Quantum Reservoir Computing on NISQ Hardware](https://arxiv.org/abs/2510.13634)
*Wissal Hamhoum,Soumaya Cherkaoui,Jean-Frederic Laprade,Ola Ahmed,Shengrui Wang*

Main category: cs.LG

TL;DR: 该论文提出了基于门的量子储层计算（MTS-QRC）方法，用于多元时间序列预测，在NISQ硬件上实现了与经典方法相媲美的性能，并发现设备噪声在某些情况下可以起到正则化作用。


<details>
  <summary>Details</summary>
Motivation: 现有量子储层计算研究主要针对单变量信号，且忽视了近期硬件的实际约束。本文旨在开发适用于多元时间序列且考虑当前设备连接性和深度的量子储层计算方法。

Method: 采用基于门的量子储层计算，配对注入和记忆量子比特，使用Trotter化的最近邻横向场Ising演化，针对当前设备连接性和深度进行优化。

Result: 在Lorenz-63和ENSO数据集上分别获得0.0087和0.0036的均方误差，与经典储层计算性能相当，在某些情况下优于学习型RNN。在IBM Heron R2上保持精度，有趣的是在ENSO上表现优于无噪声模拟器。

Conclusion: 基于门的量子储层计算在NISQ硬件上对多元时间序列预测具有实用性，设备噪声可能对线性读出起到隐式正则化作用，值得系统研究噪声何时以及如何有益于量子储层计算读出。

Abstract: Quantum reservoir computing (QRC) offers a hardware-friendly approach to
temporal learning, yet most studies target univariate signals and overlook
near-term hardware constraints. This work introduces a gate-based QRC for
multivariate time series (MTS-QRC) that pairs injection and memory qubits and
uses a Trotterized nearest-neighbor transverse-field Ising evolution optimized
for current device connectivity and depth. On Lorenz-63 and ENSO, the method
achieves a mean square error (MSE) of 0.0087 and 0.0036, respectively,
performing on par with classical reservoir computing on Lorenz and above
learned RNNs on both, while NVAR and clustered ESN remain stronger on some
settings. On IBM Heron R2, MTS-QRC sustains accuracy with realistic depths and,
interestingly, outperforms a noiseless simulator on ENSO; singular value
analysis indicates that device noise can concentrate variance in feature
directions, acting as an implicit regularizer for linear readout in this
regime. These findings support the practicality of gate-based QRC for MTS
forecasting on NISQ hardware and motivate systematic studies on when and how
hardware noise benefits QRC readouts.

</details>


### [90] [What is the objective of reasoning with reinforcement learning?](https://arxiv.org/abs/2510.13651)
*Damek Davis,Benjamin Recht*

Main category: cs.LG

TL;DR: 本文揭示了多个流行的大语言模型强化学习算法在二元奖励下可视为对正确答案概率的单调变换进行随机梯度上升


<details>
  <summary>Details</summary>
Motivation: 理解不同强化学习算法在数学上的本质联系，揭示它们与正确答案概率变换之间的关系

Method: 通过数学分析将拒绝采样算法和GRPO算法分别映射为对数变换和反正弦平方根变换的随机梯度上升

Result: 证明拒绝采样算法对应对数变换，GRPO算法对应反正弦平方根变换，两者都是对正确答案概率的单调变换

Conclusion: 多种强化学习算法在数学上具有统一性，都可视为对正确答案概率的特定单调变换进行优化

Abstract: We show that several popular algorithms for reinforcement learning in large
language models with binary rewards can be viewed as stochastic gradient ascent
on a monotone transform of the probability of a correct answer given a prompt.
In particular, the transformation associated with rejection sampling algorithms
is the logarithm and that associated with the GRPO algorithm is the arcsine of
the square root.

</details>


### [91] [Time Series Foundation Models: Benchmarking Challenges and Requirements](https://arxiv.org/abs/2510.13654)
*Marcel Meyer,Sascha Kaltenpoth,Kevin Zalipski,Oliver Müller*

Main category: cs.LG

TL;DR: 该论文分析了时间序列基础模型(TSFMs)评估中存在的多个挑战，包括基准数据集代表性不足、缺乏时空评估、信息泄露风险以及外部冲击导致的全局模式记忆问题，呼吁开发更稳健的评估方法。


<details>
  <summary>Details</summary>
Motivation: 随着时间序列基础模型的发展，其零样本预测能力需要可靠的评估方法。但现有评估存在数据完整性、信息泄露等风险，可能夸大模型性能，需要建立更严谨的评估框架。

Method: 通过调查现有TSFM评估实践，识别出基准数据集代表性、时空评估缺失、数据分区混淆、信息泄露和外部冲击记忆等关键问题。

Result: 研究发现现有评估方法存在广泛的数据分区混淆，可能导致性能估计膨胀和全局知识错误传递到局部时间序列。

Conclusion: 需要开发稳健的评估方法，包括使用真正样本外未来数据进行评估，以保障TSFM评估的完整性，避免重蹈LLM和传统时间序列基准测试的覆辙。

Abstract: Time Series Foundation Models (TSFMs) represent a new paradigm for time
series forecasting, offering zero-shot forecasting capabilities without the
need for domain-specific pre-training or fine-tuning. However, as with Large
Language Models (LLMs), evaluating TSFMs is tricky, as with ever more extensive
training sets, it becomes more and more challenging to ensure the integrity of
benchmarking data. Our investigation of existing TSFM evaluation highlights
multiple challenges, ranging from the representativeness of the benchmark
datasets, over the lack of spatiotemporal evaluation, to risks of information
leakage due to overlapping and obscure datasets, and the memorization of global
patterns caused by external shocks like economic crises or pandemics. Our
findings reveal widespread confusion regarding data partitions, risking
inflated performance estimates and incorrect transfer of global knowledge to
local time series. We argue for the development of robust evaluation
methodologies to prevent pitfalls already observed in LLM and classical time
series benchmarking, and call upon the research community to design new,
principled approaches, such as evaluations on truly out-of-sample future data,
to safeguard the integrity of TSFM assessment.

</details>


### [92] [Rebalancing with Calibrated Sub-classes (RCS): An Enhanced Approach for Robust Imbalanced Classification](https://arxiv.org/abs/2510.13656)
*Priyobrata Mondal,Faizanuddin Ansari,Swagatam Das*

Main category: cs.LG

TL;DR: 提出RCS方法，通过分布校准和子类重平衡解决类别不平衡问题，利用多数类和中间类的混合高斯分布参数来估计少数类分布，避免仅使用多数类分布导致的过泛化问题。


<details>
  <summary>Details</summary>
Motivation: 类别不平衡问题导致分类器偏向多数类，传统方法仅使用多数类分布来近似少数类统计会产生过泛化问题，需要更准确的分布校准方法。

Method: 使用编码器-解码器网络保持不平衡数据结构，通过加权多数类和中间类的高斯混合分布参数来校准少数类分布，生成合成样本进行重平衡。

Result: 在图像、文本和表格数据集上的实验表明，该方法相比多种基线和先进技术获得了更优越的分类性能。

Conclusion: RCS方法通过利用邻近区域数据点分布进行参数校准，有效缓解了类别不平衡问题，显著提升了分类性能。

Abstract: The class imbalance problem refers to the insufficiency of data in certain
classes, which causes a classifier to be biased toward the majority class.
Distribution calibration is a technique that seeks to estimate a more accurate
class distribution based on an observed or estimated one. To address this
issue, we propose a distribution calibration-based method-Rebalancing with
Calibrated Sub-classes (RCS): An Enhanced Approach for Robust Imbalanced
Classification, which estimates the distribution parameters of the minority
classes using weighted parameters derived from a mixture of Gaussian components
from both the majority and intermediate classes. An encoder-decoder network is
trained to preserve the structure of the imbalanced data and prevent
disentanglement. After training, feature vectors extracted from the encoder are
used to generate synthetic samples through our distribution calibration
strategy. This approach effectively mitigates the overgeneralization problem
that arises when only the distribution of the majority class is used to
approximate the minority class statistics. Instead, our method calibrates the
parameters by leveraging the distribution of data points in neighboring
regions. Experimental results demonstrate that the proposed method achieves
superior classification performance compared to several baseline and
state-of-the-art techniques across a diverse range of image, text, and tabular
datasets.

</details>


### [93] [Axial Neural Networks for Dimension-Free Foundation Models](https://arxiv.org/abs/2510.13665)
*Hyunsu Kim,Jonggeon Park,Joan Bruna,Hongseok Yang,Juho Lee*

Main category: cs.LG

TL;DR: 提出了一种维度无关的神经网络架构XNN，用于解决物理数据中不同维度系统的训练挑战，在多种训练场景下表现优异且具有更好的维度泛化能力。


<details>
  <summary>Details</summary>
Motivation: 基础模型在物理数据训练中面临维度变化的挑战，传统方法效率低下，需要一种能处理不同维度的通用架构。

Method: 提出轴向神经网络(XNN)，受Deep Sets和图神经网络启发，通过参数共享结构实现跨维度泛化，并将现有PDE基础模型转换为XNN架构。

Result: XNN在从头训练、多PDE预训练和单PDE微调三种场景下均表现优异，与原始模型竞争且对未见维度具有更好的泛化能力。

Conclusion: XNN成功解决了物理基础模型的维度挑战，多维预训练对基础模型至关重要，该架构为处理不同维度物理数据提供了有效解决方案。

Abstract: The advent of foundation models in AI has significantly advanced
general-purpose learning, enabling remarkable capabilities in zero-shot
inference and in-context learning. However, training such models on physics
data, including solutions to partial differential equations (PDEs), poses a
unique challenge due to varying dimensionalities across different systems.
Traditional approaches either fix a maximum dimension or employ separate
encoders for different dimensionalities, resulting in inefficiencies. To
address this, we propose a dimension-agnostic neural network architecture, the
Axial Neural Network (XNN), inspired by parameter-sharing structures such as
Deep Sets and Graph Neural Networks. XNN generalizes across varying tensor
dimensions while maintaining computational efficiency. We convert existing PDE
foundation models into axial neural networks and evaluate their performance
across three training scenarios: training from scratch, pretraining on multiple
PDEs, and fine-tuning on a single PDE. Our experiments show that XNNs perform
competitively with original models and exhibit superior generalization to
unseen dimensions, highlighting the importance of multidimensional pretraining
for foundation models.

</details>


### [94] [Adam or Gauss-Newton? A Comparative Study In Terms of Basis Alignment and SGD Noise](https://arxiv.org/abs/2510.13680)
*Bingbin Liu,Rachit Bansal,Depen Morwani,Nikhil Vyas,David Alvarez-Melis,Sham M. Kakade*

Main category: cs.LG

TL;DR: 比较Adam和Gauss-Newton两种对角预条件方法在深度学习优化中的表现，分析基选择和梯度噪声的影响。


<details>
  <summary>Details</summary>
Motivation: 对角预条件器作为二阶优化器的近似方法在深度学习训练中显示出巨大潜力，需要系统比较Adam和Gauss-Newton这两种主流方法的优劣。

Method: 在二次目标和逻辑回归问题上分析两种方法，考虑不同基选择和随机梯度噪声的影响，通过理论分析和实证研究进行验证。

Result: 在完整批次设置中，无论基选择如何，都存在Adam优于GN方法的实例；在随机设置中，Adam在线性回归下与GN^{-1/2}表现相似。

Conclusion: 两种对角预条件方法各有优势，Adam在某些情况下表现更好，而在随机设置中与GN方法有相似行为，理论结果得到实证支持。

Abstract: Diagonal preconditioners are computationally feasible approximate to
second-order optimizers, which have shown significant promise in accelerating
training of deep learning models. Two predominant approaches are based on Adam
and Gauss-Newton (GN) methods: the former leverages statistics of current
gradients and is the de-factor optimizers for neural networks, and the latter
uses the diagonal elements of the Gauss-Newton matrix and underpins some of the
recent diagonal optimizers such as Sophia.
  In this work, we compare these two diagonal preconditioning methods through
the lens of two key factors: the choice of basis in the preconditioner, and the
impact of gradient noise from mini-batching. To gain insights, we analyze these
optimizers on quadratic objectives and logistic regression under all four
quadrants. We show that regardless of the basis, there exist instances where
Adam outperforms both GN$^{-1}$ and GN$^{-1/2}$ in full-batch settings.
Conversely, in the stochastic regime, Adam behaves similarly to GN$^{-1/2}$ for
linear regression under a Gaussian data assumption. These theoretical results
are supported by empirical studies on both convex and non-convex objectives.

</details>


### [95] [Information-Theoretic Reward Modeling for Stable RLHF: Detecting and Mitigating Reward Hacking](https://arxiv.org/abs/2510.13694)
*Yuchun Miao,Liang Ding,Sen Zhang,Rong Bao,Lefei Zhang,Dacheng Tao*

Main category: cs.LG

TL;DR: 提出InfoRM和IBL框架解决RLHF中的奖励破解问题，通过信息瓶颈原理过滤偏好无关信息，并使用分布级正则化防止策略偏离。


<details>
  <summary>Details</summary>
Motivation: RLHF在语言模型对齐中面临奖励破解挑战，主要障碍包括奖励模型的错误泛化（过度拟合偏好无关特征）和RL优化中缺乏合适的正则化约束。

Method: 1. InfoRM：基于信息瓶颈原理的奖励建模框架，过滤偏好无关信息；2. IBL：分布级正则化，惩罚IB潜在空间中偏离SFT分布的异常响应；3. MOP：基于马氏距离的统计指标量化奖励破解严重程度。

Result: 在多种LLM和数据集上的广泛实验证实了方法的有效性，InfoRM和IBL能够有效缓解奖励破解问题，MOP作为诊断工具表现可靠。

Conclusion: 提出的InfoRM、IBL框架和MOP指标共同推进了RLHF技术的发展，为解决奖励破解问题提供了理论支持和实用工具。

Abstract: Despite the success of Reinforcement Learning from Human Feedback (RLHF) in
aligning language models with human values, reward hacking-or reward
over-optimization-remains a major challenge. We identify two key obstacles to
its mitigation: (1) reward misgeneralization in reward modeling, where reward
models overfit to spurious, preference-irrelevant features; and (2) the lack of
suitable regularization during RL optimization, as existing token-level
constraints often over-restrict the policy space. To address these issues, we
propose InfoRM, an information-theoretic reward modeling framework based on the
Information Bottleneck (IB) principle, which filters out preference-irrelevant
information to alleviate reward misgeneralization. We further observe that
reward-hacked responses manifest as pronounced outliers in InfoRM's IB latent
space, measured by Mahalanobis distance from the SFT-induced distribution.
Motivated by this, we introduce IBL, a distribution-level regularization that
penalizes such deviations, effectively expanding the optimization landscape
while maintaining alignment. We prove that IBL is theoretically equivalent to
the pessimistic RL objective within the IB latent space. Finally, we present
Mahalanobis Outlier Probability (MOP), a statistical metric for quantifying
reward hacking severity, enabling principled hyperparameter tuning and online
mitigation such as early stopping. Extensive experiments across diverse LLMs
and datasets confirm the generality of our findings, the effectiveness of
InfoRM and IBL, and the reliability of MOP as a diagnostic tool-collectively
advancing the state of RLHF.

</details>


### [96] [Simplicial Embeddings Improve Sample Efficiency in Actor-Critic Agents](https://arxiv.org/abs/2510.13704)
*Johan Obando-Ceron,Walter Mayor,Samuel Lavoie,Scott Fujimoto,Aaron Courville,Pablo Samuel Castro*

Main category: cs.LG

TL;DR: 提出使用单纯形嵌入作为轻量级表示层，通过几何归纳偏置产生稀疏离散特征，提升强化学习算法的样本效率和最终性能，同时不损失运行速度。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模环境并行化方法虽然加速了训练时间，但仍需要大量环境交互才能达到理想性能。结构良好的表示可以改善深度强化学习代理的泛化能力和样本效率。

Method: 引入单纯形嵌入层，将嵌入约束在单纯形结构中，产生稀疏和离散的特征，从而稳定评论家自举并增强策略梯度。

Result: 在FastTD3、FastSAC和PPO算法上应用单纯形嵌入，在多种连续和离散控制环境中一致提高了样本效率和最终性能，且不损失运行速度。

Conclusion: 单纯形嵌入作为一种几何归纳偏置，能够有效提升强化学习算法的性能，是改善样本效率的有效方法。

Abstract: Recent works have proposed accelerating the wall-clock training time of
actor-critic methods via the use of large-scale environment parallelization;
unfortunately, these can sometimes still require large number of environment
interactions to achieve a desired level of performance. Noting that
well-structured representations can improve the generalization and sample
efficiency of deep reinforcement learning (RL) agents, we propose the use of
simplicial embeddings: lightweight representation layers that constrain
embeddings to simplicial structures. This geometric inductive bias results in
sparse and discrete features that stabilize critic bootstrapping and strengthen
policy gradients. When applied to FastTD3, FastSAC, and PPO, simplicial
embeddings consistently improve sample efficiency and final performance across
a variety of continuous- and discrete-control environments, without any loss in
runtime speed.

</details>


### [97] [Don't Be Greedy, Just Relax! Pruning LLMs via Frank-Wolfe](https://arxiv.org/abs/2510.13713)
*Christophe Roux,Max Zimmer,Alexandre d'Aspremont,Sebastian Pokutta*

Main category: cs.LG

TL;DR: 本文提出了一种基于Frank-Wolfe算法的LLM剪枝方法，通过凸松弛解决组合优化问题，显著减少了层间剪枝误差，在GPT架构上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统LLM剪枝方法依赖贪婪启发式算法，忽略了权重间的交互作用，导致剪枝效果不佳。本文旨在解决这一组合优化问题的难解性。

Method: 采用凸松弛技术将组合约束转化为可优化问题，使用Frank-Wolfe算法求解，并通过舍入获得近似最优解。

Result: 方法显著降低了层间剪枝误差，在GPT架构上超越强基线方法，同时保持内存效率。

Conclusion: 结合FW算法的收敛保证，该方法为原始组合问题提供了有效的近似解决方案，在LLM剪枝中表现出优越性能。

Abstract: Pruning is a common technique to reduce the compute and storage requirements
of Neural Networks. While conventional approaches typically retrain the model
to recover pruning-induced performance degradation, state-of-the-art Large
Language Model (LLM) pruning methods operate layer-wise, minimizing the
per-layer pruning error on a small calibration dataset to avoid full
retraining, which is considered computationally prohibitive for LLMs. However,
finding the optimal pruning mask is a hard combinatorial problem and solving it
to optimality is intractable. Existing methods hence rely on greedy heuristics
that ignore the weight interactions in the pruning objective. In this work, we
instead consider the convex relaxation of these combinatorial constraints and
solve the resulting problem using the Frank-Wolfe (FW) algorithm. Our method
drastically reduces the per-layer pruning error, outperforms strong baselines
on state-of-the-art GPT architectures, and remains memory-efficient. We provide
theoretical justification by showing that, combined with the convergence
guarantees of the FW algorithm, we obtain an approximate solution to the
original combinatorial problem upon rounding the relaxed solution to
integrality.

</details>


### [98] [Assessing the Geographic Generalization and Physical Consistency of Generative Models for Climate Downscaling](https://arxiv.org/abs/2510.13722)
*Carlo Saccardi,Maximilian Pierzyna,Haitz Sáez de Ocáriz Borde,Simone Monaco,Cristian Meo,Pietro Liò,Rudolf Saathof,Geethu Joseph,Justin Dauwels*

Main category: cs.LG

TL;DR: 该论文评估了深度学习模型在气候降尺度任务中的表现，发现现有模型在地理泛化和物理一致性方面存在不足，并提出使用功率谱密度损失函数来改进模型性能。


<details>
  <summary>Details</summary>
Motivation: 千米级天气数据对实际应用至关重要，但传统天气模拟计算成本高。深度学习模型提供了更快的替代方案，但其可靠性仍受质疑，因为评估通常使用标准机器学习指标而非基于大气物理学的诊断方法。

Method: 论文对最先进的深度学习模型进行基准测试，引入基于物理学的诊断方法来评估性能，特别关注地理泛化和物理一致性。提出使用功率谱密度损失函数来改进模型。

Result: 实验表明，即使如CorrDiff等模型在训练区域表现良好，但在泛化到其他地理区域（如伊比利亚、摩洛哥、斯堪的纳维亚）时表现不佳，且无法准确捕捉从预测速度场导出的二阶变量（如散度和涡度）。

Conclusion: 当前深度学习模型在气候降尺度任务中面临地理泛化和物理一致性的挑战。提出的功率谱密度损失函数经验性地改善了地理泛化能力，有助于重建小尺度物理结构。

Abstract: Kilometer-scale weather data is crucial for real-world applications but
remains computationally intensive to produce using traditional weather
simulations. An emerging solution is to use deep learning models, which offer a
faster alternative for climate downscaling. However, their reliability is still
in question, as they are often evaluated using standard machine learning
metrics rather than insights from atmospheric and weather physics. This paper
benchmarks recent state-of-the-art deep learning models and introduces
physics-inspired diagnostics to evaluate their performance and reliability,
with a particular focus on geographic generalization and physical consistency.
Our experiments show that, despite the seemingly strong performance of models
such as CorrDiff, when trained on a limited set of European geographies (e.g.,
central Europe), they struggle to generalize to other regions such as Iberia,
Morocco in the south, or Scandinavia in the north. They also fail to accurately
capture second-order variables such as divergence and vorticity derived from
predicted velocity fields. These deficiencies appear even in in-distribution
geographies, indicating challenges in producing physically consistent
predictions. We propose a simple initial solution: introducing a power spectral
density loss function that empirically improves geographic generalization by
encouraging the reconstruction of small-scale physical structures. The code for
reproducing the experimental results can be found at
https://github.com/CarloSaccardi/PSD-Downscaling

</details>


### [99] [Asymptotically optimal reinforcement learning in Block Markov Decision Processes](https://arxiv.org/abs/2510.13748)
*Thomas van Vuren,Fiona Sloothaak,Maarten G. Wolf,Jaron Sanders*

Main category: cs.LG

TL;DR: 本文提出了一种针对块马尔可夫决策过程（BMDPs）的两阶段强化学习算法，通过聚类学习潜在结构，实现了O(√T+n)的遗憾界，优于之前的O(√T+n²)结果，并证明了该算法的渐近最优性。


<details>
  <summary>Details</summary>
Motivation: 高维状态和动作空间使得强化学习在许多实际应用中不可行，但许多环境存在可利用的结构。BMDPs模型具有大观测空间但由潜在状态决定转移动态的特性，利用聚类方法恢复这种潜在结构可以加速学习。

Method: 采用两阶段强化学习算法：第一阶段通过随机探索学习潜在结构，第二阶段切换到适应已发现结构的乐观引导策略。

Result: 算法在可聚类的BMDPs类上实现了O(√T+n)的遗憾界，显著优于之前的O(√T+n²)结果，特别是在n较大时。

Conclusion: 该算法在可聚类的BMDPs类上达到了渐近最优性，证明了准确估计潜在状态确实能有效加速学习。

Abstract: The curse of dimensionality renders Reinforcement Learning (RL) impractical
in many real-world settings with exponentially large state and action spaces.
Yet, many environments exhibit exploitable structure that can accelerate
learning. To formalize this idea, we study RL in Block Markov Decision
Processes (BMDPs). BMDPs model problems with large observation spaces, but
where transition dynamics are fully determined by latent states. Recent
advances in clustering methods have enabled the efficient recovery of this
latent structure. However, a regret analysis that exploits these techniques to
determine their impact on learning performance remained open. We are now
addressing this gap by providing a regret analysis that explicitly leverages
clustering, demonstrating that accurate latent state estimation can indeed
effectively speed up learning.
  Concretely, this paper analyzes a two-phase RL algorithm for BMDPs that first
learns the latent structure through random exploration and then switches to an
optimism-guided strategy adapted to the uncovered structure. This algorithm
achieves a regret that is $O(\sqrt{T}+n)$ on a large class of BMDPs susceptible
to clustering. Here, $T$ denotes the number of time steps, $n$ is the
cardinality of the observation space, and the Landau notation $O(\cdot)$ holds
up to constants and polylogarithmic factors. This improves the best prior
bound, $O(\sqrt{T}+n^2)$, especially when $n$ is large. Moreover, we prove that
no algorithm can achieve lower regret uniformly on this same class of BMDPs.
This establishes that, on this class, the algorithm achieves asymptotic
optimality.

</details>


### [100] [Progressive multi-fidelity learning for physical system predictions](https://arxiv.org/abs/2510.13762)
*Paolo Conti,Mengwu Guo,Attilio Frangi,Andrea Manzoni*

Main category: cs.LG

TL;DR: 提出了一种渐进式多保真度代理模型，能够顺序整合不同类型的数据，通过定制编码器和神经网络进行多保真度回归，利用双重连接系统确保性能不退化。


<details>
  <summary>Details</summary>
Motivation: 高精度数据获取成本高且耗时，而低精度数据虽然易得但精度不足。实际应用中数据可能来自不同模态且非同时可用，需要一种能够有效整合多保真度信息的建模方法。

Method: 使用定制编码器顺序处理不同类型数据，通过神经网络进行多保真度回归。采用双重连接系统：所有编码输入的连接和最终输出的加法连接，确保每个级别对前一级进行加法修正而不改变它。

Result: 在数值基准和实际案例研究中，该方法可靠地整合了多模态数据，提供准确预测，在时间和参数变化泛化时保持性能。

Conclusion: 该渐进式多保真度代理模型能够有效处理不同类型和模态的数据，确保性能不退化，为多保真度建模提供了一种实用的解决方案。

Abstract: Highly accurate datasets from numerical or physical experiments are often
expensive and time-consuming to acquire, posing a significant challenge for
applications that require precise evaluations, potentially across multiple
scenarios and in real-time. Even building sufficiently accurate surrogate
models can be extremely challenging with limited high-fidelity data.
Conversely, less expensive, low-fidelity data can be computed more easily and
encompass a broader range of scenarios. By leveraging multi-fidelity
information, prediction capabilities of surrogates can be improved. However, in
practical situations, data may be different in types, come from sources of
different modalities, and not be concurrently available, further complicating
the modeling process. To address these challenges, we introduce a progressive
multi-fidelity surrogate model. This model can sequentially incorporate diverse
data types using tailored encoders. Multi-fidelity regression from the encoded
inputs to the target quantities of interest is then performed using neural
networks. Input information progressively flows from lower to higher fidelity
levels through two sets of connections: concatenations among all the encoded
inputs, and additive connections among the final outputs. This dual connection
system enables the model to exploit correlations among different datasets while
ensuring that each level makes an additive correction to the previous level
without altering it. This approach prevents performance degradation as new
input data are integrated into the model and automatically adapts predictions
based on the available inputs. We demonstrate the effectiveness of the approach
on numerical benchmarks and a real-world case study, showing that it reliably
integrates multi-modal data and provides accurate predictions, maintaining
performance when generalizing across time and parameter variations.

</details>


### [101] [Tensor Gaussian Processes: Efficient Solvers for Nonlinear PDEs](https://arxiv.org/abs/2510.13772)
*Qiwei Yuan,Zhitong Xu,Yinghao Chen,Yiming Xu,Houman Owhadi,Shandian Zhe*

Main category: cs.LG

TL;DR: 提出了TGPS，一种基于张量高斯过程的PDE求解器，通过一维高斯过程建模各输入维度的因子函数，并通过张量分解组合它们来逼近完整解，显著降低了计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习PDE求解器存在效率问题：神经网络求解器依赖随机训练效率低，高斯过程求解器在处理大量配置点时存在可扩展性问题。

Method: 使用张量分解将高维PDE求解任务分解为学习一组一维高斯过程，采用部分冻结策略和牛顿法线性化非线性项，开发交替最小二乘法进行高效训练。

Result: 在多个基准PDE上的实验表明，该方法相比现有方法具有更高的准确性和效率。

Conclusion: TGPS方法通过张量分解和高效训练策略，成功解决了传统PDE求解器的可扩展性和效率问题，为高维PDE求解提供了有效方案。

Abstract: Machine learning solvers for partial differential equations (PDEs) have
attracted growing interest. However, most existing approaches, such as neural
network solvers, rely on stochastic training, which is inefficient and
typically requires a great many training epochs. Gaussian process
(GP)/kernel-based solvers, while mathematical principled, suffer from
scalability issues when handling large numbers of collocation points often
needed for challenging or higher-dimensional PDEs.
  To overcome these limitations, we propose TGPS, a tensor-GP-based solver that
models factor functions along each input dimension using one-dimensional GPs
and combines them via tensor decomposition to approximate the full solution.
This design reduces the task to learning a collection of one-dimensional GPs,
substantially lowering computational complexity, and enabling scalability to
massive collocation sets.
  For efficient nonlinear PDE solving, we use a partial freezing strategy and
Newton's method to linerize the nonlinear terms. We then develop an alternating
least squares (ALS) approach that admits closed-form updates, thereby
substantially enhancing the training efficiency. We establish theoretical
guarantees on the expressivity of our model, together with convergence proof
and error analysis under standard regularity assumptions. Experiments on
several benchmark PDEs demonstrate that our method achieves superior accuracy
and efficiency compared to existing approaches.

</details>


### [102] [UrbanFusion: Stochastic Multimodal Fusion for Contrastive Learning of Robust Spatial Representations](https://arxiv.org/abs/2510.13774)
*Dominik J. Mühlematter,Lin Che,Ye Hong,Martin Raubal,Nina Wiedemann*

Main category: cs.LG

TL;DR: UrbanFusion是一个地理基础模型，通过随机多模态融合技术整合街景图像、遥感数据、地图和POI数据，在41个任务的全球评估中表现出优异的泛化能力和预测性能。


<details>
  <summary>Details</summary>
Motivation: 当前方法主要使用任务特定模型，而现有的空间表示基础模型仅支持有限模态且缺乏多模态融合能力，需要解决这些挑战。

Method: 使用模态特定编码器处理不同类型输入，通过基于Transformer的融合模块学习统一表示，支持在预训练和推理期间灵活使用任何可用模态子集。

Result: 在56个城市的41个任务评估中，UrbanFusion在位置编码方面优于先前的基础模型，支持推理时的多模态输入，并能很好地泛化到训练期间未见过的区域。

Conclusion: UrbanFusion能够灵活利用任何可用模态子集，在不同数据可用性场景下具有广泛适用性，为城市现象预测提供了有效的多模态融合解决方案。

Abstract: Forecasting urban phenomena such as housing prices and public health
indicators requires the effective integration of various geospatial data.
Current methods primarily utilize task-specific models, while recent foundation
models for spatial representations often support only limited modalities and
lack multimodal fusion capabilities. To overcome these challenges, we present
UrbanFusion, a Geo-Foundation Model (GeoFM) that features Stochastic Multimodal
Fusion (SMF). The framework employs modality-specific encoders to process
different types of inputs, including street view imagery, remote sensing data,
cartographic maps, and points of interest (POIs) data. These multimodal inputs
are integrated via a Transformer-based fusion module that learns unified
representations. An extensive evaluation across 41 tasks in 56 cities worldwide
demonstrates UrbanFusion's strong generalization and predictive performance
compared to state-of-the-art GeoAI models. Specifically, it 1) outperforms
prior foundation models on location-encoding, 2) allows multimodal input during
inference, and 3) generalizes well to regions unseen during training.
UrbanFusion can flexibly utilize any subset of available modalities for a given
location during both pretraining and inference, enabling broad applicability
across diverse data availability scenarios. All source code is available at
https://github.com/DominikM198/UrbanFusion.

</details>


### [103] [The Art of Scaling Reinforcement Learning Compute for LLMs](https://arxiv.org/abs/2510.13786)
*Devvrit Khatri,Lovish Madaan,Rishabh Tiwari,Rachit Bansal,Sai Surya Duvvuri,Manzil Zaheer,Inderjit S. Dhillon,David Brandfonbrener,Rishabh Agarwal*

Main category: cs.LG

TL;DR: 本文提出了首个大规模系统研究，建立了强化学习在大型语言模型中的可预测扩展框架，通过40万GPU小时实验定义了RL扩展的分析方法，并提出了最佳实践配方ScaleRL。


<details>
  <summary>Details</summary>
Motivation: 强化学习已成为训练大型语言模型的核心方法，但缺乏与预训练相当的预测性扩展方法。尽管计算预算迅速增长，但缺乏评估RL计算扩展算法改进的原则性理解。

Method: 进行了超过40万GPU小时的大规模系统研究，拟合RL训练的S型计算-性能曲线，消融分析各种常见设计选择对渐近性能和计算效率的影响。

Result: 发现：(1)不同配方产生不同的渐近性能；(2)损失聚合、归一化、课程学习和离策略算法等细节主要调节计算效率而不显著改变渐近性能；(3)稳定可扩展的配方遵循可预测的扩展轨迹。基于这些发现提出了ScaleRL配方。

Conclusion: 该研究为分析RL扩展提供了科学框架，并通过ScaleRL实践配方使RL训练更接近预训练长期实现的预测性。

Abstract: Reinforcement learning (RL) has become central to training large language
models (LLMs), yet the field lacks predictive scaling methodologies comparable
to those established for pre-training. Despite rapidly rising compute budgets,
there is no principled understanding of how to evaluate algorithmic
improvements for scaling RL compute. We present the first large-scale
systematic study, amounting to more than 400,000 GPU-hours, that defines a
principled framework for analyzing and predicting RL scaling in LLMs. We fit
sigmoidal compute-performance curves for RL training and ablate a wide range of
common design choices to analyze their effects on asymptotic performance and
compute efficiency. We observe: (1) Not all recipes yield similar asymptotic
performance, (2) Details such as loss aggregation, normalization, curriculum,
and off-policy algorithm primarily modulate compute efficiency without
materially shifting the asymptote, and (3) Stable, scalable recipes follow
predictable scaling trajectories, enabling extrapolation from smaller-scale
runs. Combining these insights, we propose a best-practice recipe, ScaleRL, and
demonstrate its effectiveness by successfully scaling and predicting validation
performance on a single RL run scaled up to 100,000 GPU-hours. Our work
provides both a scientific framework for analyzing scaling in RL and a
practical recipe that brings RL training closer to the predictability long
achieved in pre-training.

</details>


### [104] [T3former: Temporal Graph Classification with Topological Machine Learning](https://arxiv.org/abs/2510.13789)
*Md. Joshem Uddin,Soham Changani,Baris Coskunuzer*

Main category: cs.LG

TL;DR: T3former是一个新颖的拓扑时序Transformer模型，通过滑动窗口拓扑和谱描述符作为主要token，使用专门的描述符注意力机制，在时序图分类任务中实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 时序图分类在网络安全、脑连接分析等领域很重要，但现有方法要么丢失细粒度时序信息，要么难以处理长程依赖，且局部消息传递方法存在过平滑和过压缩问题。

Method: 提出T3former模型，利用滑动窗口拓扑和谱描述符作为主要token，通过描述符注意力机制进行整合，避免刚性离散化，保持时序保真度。

Result: T3former在动态社交网络、脑功能连接数据集和交通网络等多个基准测试中达到最先进性能，并对时序和结构扰动具有理论稳定性保证。

Conclusion: 结合拓扑和谱洞察力能够推动时序图学习的前沿发展，T3former展示了这种方法的强大能力。

Abstract: Temporal graph classification plays a critical role in applications such as
cybersecurity, brain connectivity analysis, social dynamics, and traffic
monitoring. Despite its significance, this problem remains underexplored
compared to temporal link prediction or node forecasting. Existing methods
often rely on snapshot-based or recurrent architectures that either lose
fine-grained temporal information or struggle with long-range dependencies.
Moreover, local message-passing approaches suffer from oversmoothing and
oversquashing, limiting their ability to capture complex temporal structures.
  We introduce T3former, a novel Topological Temporal Transformer that
leverages sliding-window topological and spectral descriptors as first-class
tokens, integrated via a specialized Descriptor-Attention mechanism. This
design preserves temporal fidelity, enhances robustness, and enables principled
cross-modal fusion without rigid discretization. T3former achieves
state-of-the-art performance across multiple benchmarks, including dynamic
social networks, brain functional connectivity datasets, and traffic networks.
It also offers theoretical guarantees of stability under temporal and
structural perturbations. Our results highlight the power of combining
topological and spectral insights for advancing the frontier of temporal graph
learning.

</details>


### [105] [Provably Invincible Adversarial Attacks on Reinforcement Learning Systems: A Rate-Distortion Information-Theoretic Approach](https://arxiv.org/abs/2510.13792)
*Ziqing Lu,Lifeng Lai,Weiyu Xu*

Main category: cs.LG

TL;DR: 提出了一种基于信息论的"不可战胜"对抗攻击方法，通过随机扰动智能体对转移核的观察，使其在训练中无法获得真实环境信息。


<details>
  <summary>Details</summary>
Motivation: 现有确定性对抗攻击可被智能体通过逆向攻击来防御，需要开发更强大的攻击方法以提高RL系统的鲁棒性研究。

Method: 采用率失真信息论方法，随机改变智能体对转移核的观察，限制其获取真实环境信息的能力。

Result: 推导了智能体奖励遗憾的信息论下界，证明了该攻击对最先进的基于模型和无模型算法的影响。

Conclusion: 这种信息论方法可扩展到其他类型的对抗攻击，如状态观察攻击，为RL安全研究提供了新视角。

Abstract: Reinforcement learning (RL) for the Markov Decision Process (MDP) has emerged
in many security-related applications, such as autonomous driving, financial
decisions, and drone/robot algorithms. In order to improve the
robustness/defense of RL systems against adversaries, studying various
adversarial attacks on RL systems is very important. Most previous work
considered deterministic adversarial attack strategies in MDP, which the
recipient (victim) agent can defeat by reversing the deterministic attacks. In
this paper, we propose a provably ``invincible'' or ``uncounterable'' type of
adversarial attack on RL. The attackers apply a rate-distortion
information-theoretic approach to randomly change agents' observations of the
transition kernel (or other properties) so that the agent gains zero or very
limited information about the ground-truth kernel (or other properties) during
the training. We derive an information-theoretic lower bound on the recipient
agent's reward regret and show the impact of rate-distortion attacks on
state-of-the-art model-based and model-free algorithms. We also extend this
notion of an information-theoretic approach to other types of adversarial
attack, such as state observation attacks.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [106] [Dependence of Microstructure Classification Accuracy on Crystallographic Data Representation](https://arxiv.org/abs/2510.13104)
*Shrunal Pothagoni,Dylan Miley,Tyrus Berry,Jeremy K. Mason,Benjamin Schweinhart*

Main category: physics.comp-ph

TL;DR: 该研究比较了四种晶体学取向表示方法在卷积神经网络中分类微观结构的效果，发现基于谱嵌入的表示方法在考虑晶体学对称性的情况下表现最佳。


<details>
  <summary>Details</summary>
Motivation: 随着卷积神经网络在材料微观结构分析中的应用增加，特别是应用于EBSD微观图时，需要确定如何最佳地表示晶体学取向信息，以及这种选择对网络分类准确性的影响。

Method: 研究比较了四种不同的晶体学取向表示方法，使用卷积神经网络对五种具有不同织构和晶粒几何形状的合成微观结构进行分类。

Result: 在所有测试的表示方法中，在考虑晶体学对称性的空间中进行谱嵌入的表示方法表现最佳，即使在训练数据量较小的情况下也能保持良好性能。

Conclusion: 晶体学取向的表示方式对卷积神经网络的分类准确性有显著影响，谱嵌入方法在考虑对称性的情况下是最有效的表示策略。

Abstract: Convolutional neural networks are increasingly being used to analyze and
classify material microstructures, motivated by the possibility that they will
be able to identify relevant microstructural features more efficiently and
impartially than human experts. While up to now convolutional neural networks
have mostly been applied to light optimal microscopy and scanning electron
microscope micrographs, application to EBSD micrographs will be increasingly
common as rational design generates materials with unknown textures and phase
compositions. This raises the question of how crystallographic orientation
should be represented in such a convolutional neural network, and whether this
choice has a significant effect on the network's analysis and classification
accuracy. Four representations of orientation information are examined and are
used with convolutional neural networks to classify five synthetic
microstructures with varying textures and grain geometries. Of these, a
spectral embedding of crystallographic orientations in a space that respects
the crystallographic symmetries performs by far the best, even when the network
is trained on small volumes of data such as could be accessible by practical
experiments.

</details>


### [107] [Long-Range Chiral Pairing enables Topological Superconductivity in Triangular Lattices without Spin-Orbit Coupling and Magnetic Field](https://arxiv.org/abs/2510.13120)
*Yizhi Li,Yanyan Lu,Jianxin Zhong,Lijun Meng*

Main category: physics.comp-ph

TL;DR: 该论文展示了在单层三角晶格中通过长程配对实现拓扑超导的途径，无需自旋轨道耦合和磁场，与传统依赖超导性、自旋轨道耦合和时间反演对称性破缺的框架形成对比。


<details>
  <summary>Details</summary>
Motivation: 探索不依赖自旋轨道耦合和磁场的新机制来实现拓扑超导，为简化拓扑量子器件设计提供理论基础。

Method: 通过贝里曲率分析揭示长程配对下的自发时间反演对称性破缺，计算拓扑边缘态，研究不同边界对称性和配对相互作用范围的影响。

Result: 长程配对强度增加仅改变能带隙大小而不引发拓扑相变；在锯齿形和扶手椅边界纳米带中，拓扑边缘态受边界对称性和配对相互作用范围调控；近邻配对保持粒子-空穴对称性，而次近邻和第三近邻配对在扶手椅边界中破坏该对称性。

Conclusion: 提出了一种不依赖自旋轨道耦合和磁场实现拓扑超导的新机制，为简化拓扑量子器件设计提供了理论支持。

Abstract: This paper demonstrates a pathway to topological superconductivity in
monolayer triangular lattices through long-range pairing without requiring
spin-orbit coupling and magnetic field, contrasting conventional frameworks
reliant on superconductivity and spin-orbit coupling and time-reversal symmetry
(TRS) breaking. Berry curvature analysis reveals spontaneous
TRS-breaking-induced peaks or valleys under long-range pairing, signaling
nontrivial topology superconducting state. Notably, the increase in the
long-range pairing strength only changes the size of the energy band-gap,
without triggering a topological phase transition. This characteristic is
verified by calculating Berry curvature and topological edge states. In zigzag
and armchair-edge ribbons of finite width, the topological edge states are
regulated by the ribbon boundary symmetry and the interact range of long-range
pairing. Under nearest-neighbor pairing, the topological edge states maintain
particle-hole symmetry and matches the corresponding Chern number. However,
next-nearest-neighbor and third-nearest-neighbor pairings break the
particle-hole symmetry of the topological edge states in armchair-edge ribbon.
This work proposes a mechanism for realizing topological superconductivity
without relying on spin-orbit coupling and magnetic field, offering a
theoretical foundation for simplifying the design of topological quantum
devices.

</details>


### [108] [GO-Diff: Data-free and amortized global structure optimization](https://arxiv.org/abs/2510.13448)
*Nikolaj Rønne,Tejs Vegge,Arghya Bhowmik*

Main category: physics.comp-ph

TL;DR: GO-Diff是一种基于扩散的全局结构优化方法，无需先验数据或显式松弛即可直接采样低能原子构型


<details>
  <summary>Details</summary>
Motivation: 传统优化方法需要大量能量评估，开发一种更高效的结构优化方法以减少计算成本

Method: 使用Boltzmann加权分数匹配损失进行训练，仅利用已知能量函数引导生成热力学有利区域，采用自采样和模型精化的两阶段循环

Result: 与传统优化方法相比，GO-Diff以显著更少的能量评估获得竞争性结果，通过重用预训练模型支持摊销优化

Conclusion: GO-Diff提供了一种高效的全局结构优化方法，能够减少计算成本并实现跨系统的知识迁移

Abstract: We introduce GO-Diff, a diffusion-based method for global structure
optimization that learns to directly sample low-energy atomic configurations
without requiring prior data or explicit relaxation. GO-Diff is trained from
scratch using a Boltzmann-weighted score-matching loss, leveraging only the
known energy function to guide generation toward thermodynamically favorable
regions. The method operates in a two-stage loop of self-sampling and model
refinement, progressively improving its ability to target low-energy
structures. Compared to traditional optimization pipelines, GO-Diff achieves
competitive results with significantly fewer energy evaluations. Moreover, by
reusing pretrained models across related systems, GO-Diff supports amortized
optimization - enabling faster convergence on new tasks without retraining from
scratch.

</details>


### [109] [Rippled Moire Superlattices for Decoupled Ferroelectric Bits](https://arxiv.org/abs/2510.13568)
*Di Fan,Changming Ke,Shi Liu*

Main category: physics.comp-ph

TL;DR: 该论文挑战了关于扭曲二维材料中铁电性起源的缺陷钉扎假说，提出了由面内压缩应变引起的面外弯曲场作为关键的对称性破缺机制，并展示了如何利用这种机制在纳米尺度上实现可寻址的铁电比特。


<details>
  <summary>Details</summary>
Motivation: 理论和实验之间存在根本性差异：对称性考虑表明扭曲二维材料形成的莫尔超晶格应保持整体反演对称性，但实验却一致报告在扭曲双层h-BN等系统中存在稳健的铁电性。

Method: 使用大规模有限场分子动力学模拟，分析应变诱导的波纹如何驱动空间异质性的层间滑动并扭曲莫尔畴壁网络。

Result: 识别出面外弯曲场是关键的对称性破缺机制，形成了四态铁电系统，并证明局域纳米气泡可将莫尔晶格的基本六边形畴团簇作为最小的可单独寻址铁电比特。

Conclusion: 建立了几何驱动的框架来理解和工程莫尔铁电体，为实现超高密度可重写存储器提供了途径，并为局部调控莫尔势本身提供了策略，这对于操纵涌现的相关和拓扑量子相至关重要。

Abstract: Symmetry considerations suggest that moire superlattices formed by twisted
two-dimensional materials should preserve overall inversion symmetry. However,
experiments consistently report robust ferroelectricity in systems such as
twisted bilayer h-BN, posing a fundamental discrepancy between theory and
experiment regarding its microscopic origin. Here, using large-scale
finite-field molecular dynamics simulations, we challenge the prevailing
defect-pinning hypothesis and instead identify an out-of-plane bending field,
induced by in-plane compressive strain, as the key symmetry-breaking mechanism.
This strain-induced rippling drives spatially heterogeneous interlayer sliding
and distorts the moire domain wall network, resulting in a four-state
ferroelectric system. Remarkably, we show this mechanism can be harnessed at
the nanoscale, where localized nanobubbles designate the moire lattice's
fundamental hexagonal domain clusters as the smallest individually addressable
ferroelectric bits, thereby imposing local control on an otherwise globally
defined structure. Our findings establish a geometry-driven framework for
understanding and engineering moire ferroelectrics, offering not only a route
toward ultra-high-density, rewritable memory, but also a strategy for locally
tuning the moire potential itself, a critical step for manipulating emergent
correlated and topological quantum phases.

</details>


### [110] [Multiphysics Finite Element Modeling of Irradiation and Thermal Behavior Demonstrated on a Fuel-Assembly Problem](https://arxiv.org/abs/2510.13597)
*Fabrizio Aguzzi,Martín Armoa,Santiago M. Rabazzi,César Pairetti,Alejandro Albanesi*

Main category: physics.comp-ph

TL;DR: 提出了一个基于微观力学动力学的建模框架，用于模拟复杂材料的热力学行为，应用于核燃料棒元件在压水堆条件下的行为分析


<details>
  <summary>Details</summary>
Motivation: 需要准确预测核燃料棒元件在反应堆条件下的热力学行为，特别是考虑热膨胀、热蠕变和辐照效应的耦合作用

Method: 采用VPSC-FEM耦合方法，结合有限元求解器Code_Aster，分析热、机械和辐照载荷下的行为

Result: 模型成功捕捉了由晶体织构和棱柱滑移驱动的各向异性变形，热蠕变导致早期应力松弛和应变积累，辐照机制主导长期间隙行为

Conclusion: 该高分辨率建模框架能够预测间隔件-包壳相互作用，为开发降阶模型提供了基础

Abstract: This work presents a modeling framework to represent the thermomechanical
behavior of complex materials based on micromechanical dynamics. The framework
is applied to nuclear fuel rod elements composed of Zircaloy-2 cladding tubes
and spacer grids under typical Pressurized Water Reactor (PWR) conditions.
Thermal expansion and thermal creep are incorporated through a VPSC-FEM
coupling with the finite element solver Code_Aster, enabling analysis of
in-reactor behavior under combined thermal, mechanical, and irradiation
loading. The model captures anisotropic deformation driven by crystallographic
texture and prismatic slip activity under radial loading. Thermal creep, being
stress-sensitive, contributes to early-stage stress relaxation and strain
accumulation, leading to higher strain compared to the irradiation-only case.
The interaction of thermal creep with irradiation mechanisms modifies the
stress distribution and clearance evolution, with relaxation governed by
prismatic slip. For fuel rod components, irradiation-induced mechanisms
dominate the long-term clearance behavior, whereas thermal effects remain
relevant in contact dynamics during thermal preloading. The stress-strain
response is found to be more sensitive to micromechanical processes than to
elastic constants. This high-resolution formulation enables predictive modeling
of spacer-cladding interaction and provides a foundation for developing
reduced-order models.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [111] [Geometric Bound for Trade-off Relation in Quantum Tricycle](https://arxiv.org/abs/2510.12849)
*Shihao Xia,Jingyi Chen,Jincan Chen,Shanhe Su*

Main category: quant-ph

TL;DR: 研究有限时间量子三循环热机的热力学性能，在慢驱动机制下通过微扰展开分析热交换过程，揭示冷却速率、性能系数和耗散之间的基本权衡关系。


<details>
  <summary>Details</summary>
Motivation: 探索量子热机在有限时间操作下的热力学性能极限，超越准静态极限理解热交换过程动力学。

Method: 采用几何框架，通过控制空间中热力学长度和轨迹几何的微扰展开分析热交换过程。

Result: 推导出冷却速率、性能系数和耗散之间由热力学长度和轨迹几何控制的基本权衡界限。

Conclusion: 揭示了量子热机性能的内在限制，强调了几何在有限时间热力学中的关键作用，为下一代量子技术设计提供指导原则。

Abstract: We establish a finite-time quantum tricycle driven by an external field and
investigate its thermodynamic performance in the slow-driving regime. By
developing a perturbative expansion of heat with respect to operation time, we
capture the dynamics of heat exchange processes beyond the quasistatic limit.
Within a geometric framework, we derive fundamental bounds on trade-offs
between the cooling rate, coefficient of performance, and dissipation, governed
by the thermodynamic length and trajectory geometry in control space. Our
findings unveil intrinsic limits to the performance of quantum thermal machines
and highlight the role of geometry in shaping finite-time thermodynamics. This
work advances the fundamental understanding of quantum thermodynamic processes
and offers guiding principles for the design of next-generation quantum
technologies.

</details>


### [112] [Tunable quantum Mpemba effect in long-range interacting systems](https://arxiv.org/abs/2510.12875)
*Andrew Hallam,Matthew Yusuf,Aashish A. Clerk,Ivar Martin,Zlatko Papić*

Main category: quant-ph

TL;DR: 本文研究了长程相互作用XYZ模型中量子Mpemba效应的可调性，揭示了外部磁场、相互作用范围和初始温度对对称性恢复动力学的影响。


<details>
  <summary>Details</summary>
Motivation: 研究量子Mpemba效应在存在对称性破缺系统中的出现条件，特别是长程相互作用如何影响这种非平衡热化现象。

Method: 使用一维自旋1/2 XYZ模型，考虑幂律衰减的长程相互作用和外加磁场，在预热态区域分析U(1)对称性的动力学恢复过程。

Result: 发现量子Mpemba效应只在相互作用足够短程时出现，长程相互作用可以调节该效应，且效应依赖于初始状态设定的有效温度。

Conclusion: 长程相互作用为量子Mpemba效应提供了可调性，这一现象可在离子阱、极性分子和NV中心等实验平台中探测。

Abstract: Symmetry plays a fundamental role in many-body systems, both in and out of
equilibrium. The quantum Mpemba effect (QME) - a phenomenon where systems
initially farther from equilibrium can thermalize faster - can be understood in
terms of how rapidly a symmetry, broken by initial conditions, is dynamically
restored. In this work, we study the QME in a one-dimensional spin-1/2 XYZ
model with power-law decaying interactions in the presence of a magnetic field.
In the prethermal regime generated by large field strengths, the system
develops a continuous U(1) symmetry, enabling the QME to emerge. However, due
to the Hohenberg-Mermin-Wagner theorem, the QME can only arise when
interactions are sufficiently short-ranged. This leads to an interplay between
the external field, interaction range, and dynamical symmetry restoration. We
systematically explore this interplay and analyze the dependence of the QME on
the effective temperature set by the initial state. Our results demonstrate the
tunability of the QME via long-range interactions, which can be probed in
experimental platforms of trapped ions, polar molecules, and NV centers.

</details>


### [113] [Probing non-Markovian qubit noise and modeling Post Markovian Master Equation](https://arxiv.org/abs/2510.12894)
*Chun-Tse Li,Jingming Tan,Vasil Gucev*

Main category: quant-ph

TL;DR: 使用后马尔可夫主方程(PMME)研究量子处理器中的非马尔可夫噪声特性，通过IBM量子设备实验验证了电路执行中的非马尔可夫行为，并发现串扰是当前量子硬件中非马尔可夫效应的主要来源。


<details>
  <summary>Details</summary>
Motivation: 量子处理器噪声特性的准确理解对实现容错量子计算至关重要，但传统马尔可夫近似无法完全捕捉真实动态，如量子比特耦合和扩展浴相关时间引入的非马尔可夫效应。

Method: 采用后马尔可夫主方程(PMME)形式化方法来表征噪声动态中的记忆效应，并在IBM量子设备上使用超导量子比特进行实验验证，同时用量子信息论方法量化串扰效应。

Result: 实验验证了PMME框架，明确展示了电路执行中的非马尔可夫行为，并揭示串扰在当前量子硬件中主导了观察到的非马尔可夫效应。

Conclusion: 非马尔可夫效应在量子处理器噪声中普遍存在，串扰是主要贡献因素，PMME框架为准确表征量子噪声提供了有效工具。

Abstract: Understanding the noise characteristics of quantum processors is crucial when
achieving fault-tolerant quantum computing. However, typical qubit designs are
often studied under the Markovian approximation, which does not fully capture
realistic dynamics. Factors such as qubit-qubit coupling and extended bath
correlation times can introduce significant non-Markovian effects into the
noise processes. In this study, we employ the Post-Markovian Master Equation
(PMME) formalism to characterize memory effects in the noise dynamics. We
further experimentally validate the PMME framework using superconducting qubits
on an IBM Quantum device, demonstrating clear non-Markovian behavior during
circuit execution. Additionally, we quantify the crosstalk effect using an
information-theoretic approach and reveal that crosstalk can dominate the
observed non-Markovian effects in current quantum hardware.

</details>


### [114] [Censorship of quantum resources against catalytic account sharing](https://arxiv.org/abs/2510.12876)
*Julien Pinske,Klaus Mølmer*

Main category: quant-ph

TL;DR: 提出了一种量子审查协议，该协议不要求完全擦除量子资源，而是通过阻止用户使用自由操作恢复原始量子状态来确保审查成功。


<details>
  <summary>Details</summary>
Motivation: 量子审查中，任何现实审查都会残留量子性，存在通过恢复或蒸馏量子资源来规避审查的风险。需要确保审查后用户无法恢复原始量子状态。

Method: 引入基于量子资源理论的审查协议，分析审查安全的条件和可能失败的情况，并解决量子网络中的账户共享问题。

Result: 建立了量子审查安全性的理论框架，连接了量子催化和资源辅助通信等前沿话题。

Conclusion: 量子审查协议为量子网络安全提供了与传统量子密码学和后量子密码学根本不同的新视角。

Abstract: In quantum censorship, an agency oversees quantum communication in a
public-domain network. The agency restricts the users communication to the free
states of a quantum resource theory (QRT). Despite quantum correlations being
fragile, any realistic censorship leaves behind some quantumness, raising
concerns that censorship may be overcome through revival or distillation of
quantum resources. Here, we introduce censorship protocols that do not require
a perfect erasure of a quantum resource, but rather deem censorship successful
if users are unable to restore the original quantum state using free
operations. We investigate under which conditions censorship is secure, and
when it might fail. Moreover, we address the issue of account sharing in
quantum networks, wherein independent parties assist in transmitting quantum
resources to censored users. This connects resource censorship to timely topics
such as quantum catalysis and resource-assisted communication. Censorship
protocols offer a novel perspective on quantum network security, that differs
fundamentally from existing approaches such as quantum and post-quantum
cryptography.

</details>


### [115] [Statistical phase-space complexity of continuous-variable quantum channels](https://arxiv.org/abs/2510.12878)
*Siting Tang,Francesco Albarelli,Yue Zhang,Shunlong Luo,Matteo G. A. Paris*

Main category: quant-ph

TL;DR: 提出了一种基于Husimi Q函数信息论量的量子通道复杂度量化方法，定义了量子通道复杂度为其能从最小复杂度初始态生成的最大复杂度。


<details>
  <summary>Details</summary>
Motivation: 需要一种方法来量化连续变量量子态的统计复杂度，并将其扩展到量子通道的复杂度研究。

Method: 利用Husimi Q函数的信息论量定义量子态复杂度，然后将量子通道复杂度定义为从最小复杂度初始态能生成的最大复杂度。

Result: 通过评估高斯通道和一些非高斯通道的复杂度来验证该方法。

Conclusion: 该方法能够有效量化量子通道的复杂度，为研究量子系统的统计复杂性提供了新工具。

Abstract: The statistical complexity of continuous-variable quantum states can be
characterized with a quantifier defined in terms of information-theoretic
quantities derived from the Husimi Q-function. In this work, we utilize this
complexity quantifier of quantum states to study the complexity of single-mode
bosonic quantum channels. We define the complexity of quantum channels as the
maximal amount of complexity they can generate from an initial state with the
minimal complexity. We illustrate this concept by evaluating the complexity of
Gaussian channels and some examples of non-Gaussian channels.

</details>


### [116] [Can outcome communication explain Bell nonlocality?](https://arxiv.org/abs/2510.12886)
*Carlos Vieira,Carlos de Gois,Pedro Lauand,Lucas E. A. Porto,Sébastien Designolle,Marco Túlio Quintino*

Main category: quant-ph

TL;DR: 本文证明了在量子信息中，对于任意qubit-qudit态，如果必须重现所有投影测量，则基于测量结果的经典通信无法增强局部隐变量模型解释纠缠相关性的能力。


<details>
  <summary>Details</summary>
Motivation: 研究在量子纠缠相关性解释中，如果限制通信内容为测量结果而非任意比特，局部隐变量模型是否仍能解释所有量子相关性。

Method: 通过理论证明和分析，考察了在投影测量条件下，基于测量结果的通信对局部隐变量模型能力的限制。

Result: 发现对于任意qubit-qudit态，如果必须重现所有投影测量，则基于测量结果的通信无法提供优势，模型能力与无通信时相同。但在受限测量集合下，结果通信确实能提供优势。

Conclusion: 结果通信在量子相关性建模中的作用高度依赖于测量集合的选择，标准LHV场景中的确定性测量和结果重标记等特性在结果通信场景中起着关键作用。

Abstract: A central aspect of quantum information is that correlations between
spacelike separated observers sharing entangled states cannot be reproduced by
local hidden variable (LHV) models, a phenomenon known as Bell nonlocality. If
one wishes to explain such correlations by classical means, a natural
possibility is to allow communication between the parties. In particular, LHV
models augmented with two bits of classical communication can explain the
correlations of any two-qubit state. Would this still hold if communication is
restricted to measurement outcomes? While in certain scenarios with a finite
number of inputs the answer is yes, we prove that if a model must reproduce all
projective measurements, then for any qubit-qudit state the answer is no. In
fact, a qubit-qudit under projective measurements admits an LHV model with
outcome communication if and only if it already admits an LHV model without
communication. On the other hand, we also show that when restricted sets of
measurements are considered (for instance, when the qubit measurements are in
the upper hemisphere of the Bloch ball), outcome communication does offer an
advantage. This exemplifies that trivial properties in standard LHV scenarios,
such as deterministic measurements and outcome-relabelling, play a crucial role
in the outcome communication scenario.

</details>


### [117] [Many-body post-processing of density functional calculations using the variational quantum eigensolver for Bader charge analysis](https://arxiv.org/abs/2510.12887)
*Erik Schultheis,Alexander Rehn,Gabriel Breuil*

Main category: quant-ph

TL;DR: 使用变分量子本征求解器计算周期系统的Bader电荷，在强关联过渡金属氧化物中相比标准DFT显著改进结果


<details>
  <summary>Details</summary>
Motivation: 量子化学和凝聚态物理是量子计算机最有前景的应用领域之一，评估材料特性对工业应用至关重要

Method: 通过变分量子本征求解器求解多体哈密顿量来计算Bader电荷，哈密顿量来自DFT计算得到的Kohn-Sham轨道

Result: 在掺杂MgH2超晶格中验证了方法的准确性，在强关联过渡金属氧化物中相比标准DFT显著改善了Bader电荷值

Conclusion: 开发了名为Dopyqo的开源计算框架，为量子计算在材料特性研究中的应用提供了有效工具

Abstract: Quantum chemistry and condensed matter physics are among the most promising
applications of quantum computers. Further, estimating properties of a material
is crucial to evaluate its industrial applications. To investigate charge
distributions of weakly and strongly correlated systems we calculate Bader
charges for various periodic systems by solving many-body Hamiltonians using
the variational quantum eigensolver. The Hamiltonians are computed from
Kohn-Sham orbitals obtained from a prior DFT calculation. We first demonstrate
the accuracy of our method on various doped MgH2 supercells. Further, we show
that our approach, compared to standard DFT, significantly improves the Bader
charge values for strongly correlated transition metal oxides, where we take
DFT+U results as a reference. The computational framework behind our many-body
calculations, called Dopyqo, is made openly available as a software package.

</details>


### [118] [Quantum Key Distribution in the Iberian Peninsula](https://arxiv.org/abs/2510.12951)
*Vicky Domínguez Tubío,Mario Badás Aldecocea,David L. Bakker,Gustavo C. Amaral,Diego López,Johannes Borregaard*

Main category: quant-ph

TL;DR: 提出并评估了覆盖伊比利亚半岛的卫星量子密钥分发网络，使用LEO卫星通过SPDC源分发纠缠光子对，优化光束参数以提高密钥率，证明可实现实际应用的密钥速率。


<details>
  <summary>Details</summary>
Motivation: 光纤QKD网络存在指数级损耗问题，卫星辅助量子通信为长距离安全密钥交换提供了可扩展解决方案。

Method: 使用配备SPDC源的LEO卫星向地面站分发纠缠光子对，考虑卫星振动优化光束腰围以提高传输概率和密钥率。

Result: 结果显示可实现满足实际应用需求的密钥速率，如医院间安全通信，使用混合经典-量子协议。

Conclusion: 证明了近期卫星QKD网络在国家规模安全通信中的可行性。

Abstract: A promising use of quantum networking is quantum key distribution (QKD),
which can provide information-theoretic security unattainable by classical
means. While optical fiber-based QKD networks suffer from exponential loss,
satellite-assisted quantum communication offers a scalable solution for
long-distance secure key exchange. In this work, we propose and evaluate a
satellite-based QKD setup covering the Iberian Peninsula, linking Madrid with
Barcelona, Bilbao, and Lisbon. Our proposed setup uses a Low-Earth-Orbit (LEO)
state-of-the-art satellite equipped with a spontaneous parametric
down-conversion (SPDC) source to distribute entangled photon pairs to ground
stations. Considering vibrations in the satellite, we optimize the beam waist
to enhance the transmission probability and improve the secret key rate (SKR).
Our results show that key rates sufficient for real-world applications, such as
secure communication between hospitals, using hybrid classical-quantum
protocols are feasible with existing protocols. Our results highlight the
viability of near-term satellite-based QKD networks for national-scale secure
communications.

</details>


### [119] [Simulation-Free Fidelity Estimation via Quantum Output Order Statistics](https://arxiv.org/abs/2510.13026)
*Tobias Micklitz*

Main category: quant-ph

TL;DR: 提出了一种基于高度纠缠混沌态输出概率顺序统计的无仿真方法，用于估计大型量子电路的保真度，仅需最高概率输出比特串。


<details>
  <summary>Details</summary>
Motivation: 针对中等规模量子电路中交叉熵基准测试成本高且直接保真度估计困难的问题，开发可扩展的保真度估计方法。

Method: 基于Haar随机量子态顺序统计的精确解析结果，分析其在去极化噪声下的变化，提出可扩展保真度估计器。

Result: 在Google的12量子比特Sycamore实验上验证了该方法，并通过数值模拟进一步支持其有效性。

Conclusion: 该方法为中等规模量子电路提供了一种实用的保真度估计方案，解决了现有方法成本高和实现困难的问题。

Abstract: We introduce a simulation-free method to estimate the fidelity of large
quantum circuits based on the order statistics of measured output probabilities
from highly entangled, chaotic states. The approach requires only the
highest-probability output bitstrings -- the most frequently observed
measurement outcomes -- and builds on exact analytical results for the order
statistics of Haar-random quantum states derived here. Analyzing their
modification under depolarizing noise, we propose a scalable fidelity
estimator, validated on Google's 12-qubit Sycamore experiment and further
supported by numerical simulations. We demonstrate its practicality for
intermediate-scale quantum circuits, where cross-entropy benchmarking is costly
and direct fidelity estimation is difficult.

</details>


### [120] [Blind-spots of Randomized Benchmarking Under Temporal Correlations](https://arxiv.org/abs/2510.13051)
*Varun Srivastava,Abhinash Kumar Roy,Soumik Mahanti,Jasleen Kaur,Salini Karuvade,Alexei Gilchrist*

Main category: quant-ph

TL;DR: 本文分析了在时间相关噪声下随机基准测试的表现，推导了非马尔可夫噪声下的平均序列保真度解析表达式，并展示了时间相关性可能抑制最坏情况误差。


<details>
  <summary>Details</summary>
Motivation: 标准随机基准测试假设时间不相关噪声，但当前量子设备中常存在时间相关噪声，需要研究RB在非马尔可夫噪声下的表现。

Method: 推导了在具有经典记忆的时间相关噪声下平均序列保真度的解析表达式，分析了与量子环境相互作用的情况。

Result: 识别了使时间相关性对RB完全不可见的相互作用哈密顿量类别，提供了通过RB实验见证量子记忆时间相关性的操作标准，发现时间相关性可能抑制最坏情况误差。

Conclusion: 时间相关性不一定总是对门性能产生不利影响，可能抑制最坏情况误差，这对容错量子计算具有重要意义。

Abstract: Randomized benchmarking (RB) is a widely adopted protocol for estimating the
average gate fidelity in quantum hardware. However, its standard formulation
relies on the assumption of temporally uncorrelated noise, an assumption often
violated in current devices. In this work, we derive analytic expressions for
the average sequence fidelity (ASF) in the presence of temporally correlated
(non-Markovian) noise with classical memory, including cases where such
correlations originate from interactions with a quantum environment. We show
how the ASF can be interpreted to extract meaningful benchmarking parameters
under such noise and identify classes of interaction Hamiltonians that render
temporal correlations completely invisible to RB. We further provide
operational criteria for witnessing temporal correlations due to quantum memory
through RB experiments. Importantly, while classical correlations may remain
undetectable in the ASF data, they can nonetheless significantly affect
worst-case errors quantified by the diamond norm, a metric central to fault
tolerant quantum computing. In particular, we demonstrate that temporal
correlations may suppress worst-case errors highlighting that temporal
correlations may not always have detrimental effects on gate performance.

</details>


### [121] [Optimal key rates for quantum key distribution with partial source characterization](https://arxiv.org/abs/2510.13085)
*Margarida Pereira,Guillermo Currás-Lorenzo,Mateus Araújo*

Main category: quant-ph

TL;DR: 扩展锥优化方法以处理量子密钥分发中源不完美的情况，在部分信息已知的场景下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 实际量子设备存在不可避免的缺陷和侧信道，而现有数值安全证明大多假设发射态完全已知，这在实践中不现实。

Method: 扩展锥优化方法到部分信息已知的场景，涵盖制备-测量和测量设备无关协议。

Result: 在现实源不完美情况下，该方法优于最先进的解析和数值方法，特别是对于使用非量子比特编码的协议。

Conclusion: 这些结果推进了基于数值的证明，使其成为评估存在源不完美时量子密钥分发协议的标准、可实施的框架。

Abstract: Numerical security proofs based on conic optimization are known to deliver
optimal secret-key rates, but so far they have mostly assumed that the emitted
states are fully characterized. In practice, this assumption is unrealistic,
since real devices inevitably suffer from imperfections and side channels that
are extremely difficult to model in detail. Here, we extend conic-optimization
methods to scenarios where only partial information about the emitted states is
known, covering both prepare-and-measure and measurement-device-independent
protocols. We demonstrate that our method outperforms state-of-the-art
analytical and numerical approaches under realistic source imperfections,
especially for protocols that use non-qubit encodings. These results advance
numerical-based proofs towards a standard, implementation-ready framework for
evaluating quantum key distribution protocols in the presence of source
imperfections.

</details>


### [122] [Software-enhanced simultaneous quantum-classical communication protocol with Gaussian post-selection](https://arxiv.org/abs/2510.13138)
*Ozlem Erkilic,Biveen Shajilal,Nicholas Zaunders,Timothy C. Ralph*

Main category: quant-ph

TL;DR: 将高斯后选择引入同时量子经典通信协议，通过软件优化调制方差来提升量子密钥分发的性能，无需硬件改动即可在光纤和自由空间信道中显著提高传输距离和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统量子密钥分发协议在波动环境（如自由空间链路）中性能受限，因为实验参数基于静态信道假设优化，导致密钥率次优和传输距离减少。

Method: 在同时量子经典通信框架中引入高斯后选择，在信道估计后通过软件方式优化调制方差，这是一种被动方法。

Result: 协议在渐近和有限尺寸机制下均能提升密钥率，考虑接收器不完美时仍有效，显著提高了光纤和自由空间信道的传输距离和鲁棒性。

Conclusion: 基于后选择的同时量子经典通信协议对于现实世界的量子通信具有实用性，适用于地面光纤网络和卫星自由空间链路。

Abstract: Simultaneous quantum-classical communication (SQCC) protocols offer a
practical approach to continuous-variable quantum key distribution (CV-QKD) by
encoding quantum and classical signals onto the same optical pulse. However,
like most QKD protocols, their performance is limited when experimental
parameters, such as modulation variance, are optimised based on stationary
channel assumptions. In fluctuating environments, such as free-space links,
this can result in sub-optimal key rates and reduced transmission distances. In
this work, we introduce Gaussian post-selection into the SQCC framework,
enabling a software-based optimisation of the modulation variance after channel
estimation. This passive approach enhances key rates in both asymptotic and
finite-size regimes without requiring hardware modifications and remains
effective even when receiver imperfections are taken into account. We
demonstrate that our protocol significantly improves the transmission distance
and robustness of SQCC across both fibre and free-space channels. In
particular, we show that the protocol enables full communication windows under
ideal weather conditions and maintains higher duty cycles during adverse
weather in satellite-to-ground scenarios. These results highlight the
practicality of post-selection based SQCC for real-world quantum communication
over both terrestrial fiber networks and satellite-based free-space links.

</details>


### [123] [Quantum Dynamics, Master Equation and Equilibrium for a Qubit Coupled to a Thermal Boson Field](https://arxiv.org/abs/2510.13142)
*Hiromichi Nakazato,Saverio Pascazio*

Main category: quant-ph

TL;DR: 本文推导了二能级量子系统与玻色环境在旋转波近似下的精确主方程，分析了系统与环境动力学演化算符的长时间行为，并研究了系统达到热平衡的条件。


<details>
  <summary>Details</summary>
Motivation: 研究二能级量子系统与热玻色环境相互作用时的精确动力学行为，特别是系统在长时间演化后是否以及如何达到热平衡状态。

Method: 在旋转波近似下，解析推导了系统与初始处于任意热态的环境相互作用时的精确主方程，分析了演化算符的长时间行为。

Result: 得到了形式精确的主方程，确定了系统达到热平衡所需的具体条件。

Conclusion: 在特定条件下，二能级量子系统与热玻色环境相互作用后会达到热平衡状态，这为理解开放量子系统的热化过程提供了理论依据。

Abstract: We analytically derive the exact -- though formal -- master equation for a
two-level quantum system (qubit) interacting with a bosonic environment within
the rotating-wave approximation, assuming the environment is initially in an
arbitrary thermal state. The long-time behavior of the evolution operator
governing the dynamics of both the system and the environment is analyzed, and
the conditions under which the system approaches thermal equilibrium are
examined.

</details>


### [124] [Quantumness near the Schwarzschild black hole based on W-state](https://arxiv.org/abs/2510.13666)
*Guang-Wei Mi,Xiaofen Huang,Shao-Ming Fei,Tinggui Zhang*

Main category: quant-ph

TL;DR: 该论文研究了施瓦西黑洞附近的量子特性，利用W态分析了霍金效应对量子相干性和量子纠缠的影响，并考虑了环境噪声的影响。


<details>
  <summary>Details</summary>
Motivation: 研究霍金效应如何影响黑洞附近量子系统的相干性和纠缠特性，特别是对于不同可访问模式数量的系统。

Method: 使用W态分析施瓦西黑洞中的量子特性，计算l1范数量子相干性、一阶相干性、并发填充和全局并发，考虑霍金效应和环境噪声（AD通道）的影响。

Result: 对于三个可访问模式的系统，霍金效应破坏量子相干性但增强量子纠缠；对于一或两个可访问模式的系统，霍金效应对量子相干性和纠缠都有积极影响。在AD通道下，霍金效应对三个可访问模式系统的量子纠缠仍具有积极影响。

Conclusion: 霍金效应对量子相干性和纠缠的影响取决于可访问模式的数量，在某些情况下可能破坏相干性但增强纠缠，这为理解黑洞附近的量子特性提供了新见解。

Abstract: We investigate certain quantumness in the vicinity of the Schwarzschild black
hole by utilizing the W state. We explore the influence of the Hawking effect
on the l_1-norm of quantum coherence, the first-order coherence (FOC), the
concurrence-fill (CF) and the global concurrence (GC) in Schwarzschild black
hole, for systems with one, two and three physically accessible modes. We
conclude that the Hawking effect of the black hole not only disrupts but also
enhance the quantum entanglement, while destroying the quantum coherence for
systems with three physically accessible modes. For systems with one or two
physically accessible modes, the Hawking effect exerts a positive influence on
quantum coherence and quantum entanglement. Moreover, we study the influence of
both the Hawking effect and environmental noise (AD channels) on l_1-norm of
quantum coherence, FOC, CF and GC. It is demonstrated that for systems with
three physically accessible modes, the Hawking effect of the black hole
disrupts quantum coherence but exerts a positive influence on quantum
entanglement under the AD channels.

</details>


### [125] [Autler-Townes spectroscopy of a Rydberg ladder](https://arxiv.org/abs/2510.13150)
*Tai Xiang,Yue-Hui Lu,Jacquelyn Ho,Tsai-Chen Lee,Zhenjie Yan,Dan M. Stamper-Kurn*

Main category: quant-ph

TL;DR: 该论文提出了一种替代传统EIT的双光子光谱特征——双光子奥特-汤斯共振，在倒置波长方案中具有更好的信噪比，可用于高量子数里德堡态检测和激光频率稳定。


<details>
  <summary>Details</summary>
Motivation: 在倒置波长方案中，传统EIT信号在多普勒展宽介质中强度显著降低，需要寻找替代的双光子光谱检测方法。

Method: 在倒置波长方案下，通过观测上支光束中的双光子奥特-汤斯共振来检测里德堡态跃迁。

Result: 相比EIT信号，双光子奥特-汤斯共振具有更优的信噪比，能够分辨高达n=80的里德堡共振，并可用于上支光束的频率稳定。

Conclusion: 双光子奥特-汤斯共振为倒置波长方案中的里德堡态检测提供了有效的替代方法，具有更好的性能和实用性。

Abstract: Ladder-type two-photon excitation of an atom from a ground state $|g\rangle$,
to an intermediate excited state $|e\rangle$, and, finally, to a Rydberg state
$|r\rangle$, has a variety of uses from quantum information to sensing. A
common scheme for detecting this transition optically is through
electromagnetically induced transparency (EIT). However, in inverted wavelength
schemes, where the ground-to-excited transition wavelength is shorter than the
excited-to-Rydberg transition wavelength, the strength of the EIT feature on
the lower-leg beam is strongly reduced in a Doppler-broadened medium. Here, we
report on an alternative two-photon spectroscopic feature, which we term the
two-photon Autler-Townes resonance, observed on the upper-leg beam. Compared to
the EIT signal, this feature's superior signal-to-noise ratio allows one to
resolve Rydberg resonances with principal quantum number as high as $n=80$. We
also show that such a feature can be utilized to generate an error signal for
stabilizing the frequency of the upper-leg beam.

</details>


### [126] [Observation of Nonlinear Spin Dynamics in Dual-Cell Atomic Gases](https://arxiv.org/abs/2510.13218)
*Xiaofan Wang,Haitao Lu,Hengyan Wang,Zhihuang Luo,Wenqiang Zheng*

Main category: quant-ph

TL;DR: 实验观测了双偏置磁场中非线性自旋动力学，发现了极限环、准周期轨道和混沌三种稳定动力学行为，并研究了它们之间的非线性相变。


<details>
  <summary>Details</summary>
Motivation: 非线性自旋系统展现出丰富的动力学现象，但理论预测的非线性动力学相变在实验上尚未得到验证。

Method: 使用双偏置磁场和双室碱金属原子气体系统，通过调节反馈增益和双偏置磁场差来研究非线性动力学行为。

Result: 观测到三种代表性稳定动力学行为：极限环、准周期轨道和混沌，并发现极限环和准周期轨道对磁场噪声具有鲁棒性。

Conclusion: 建立了一个探索复杂自旋动力学的多功能平台，为多模自旋微波激射器、时间晶体和准晶体以及高精度磁强计的实现开辟了新途径。

Abstract: Nonlinear spin systems exhibit rich and exotic dynamical phenomena, offering
promising applications ranging from spin masers and time crystals to precision
measurement. Recent theoretical work [T. Wang et al., Commun. Phys. 8, 41
(2025)] predicted intriguing nonlinear dynamical phases arising from
inhomogeneous magnetic fields and feedback interactions. However, experimental
exploration of these predictions remains lacking. Here, we report the
observation of nonlinear spin dynamics in dual-bias magnetic fields with
dual-cell alkali-metal atomic gases and present three representative stable
dynamical behaviors of limit cycles, quasi-periodic orbits, and chaos.
Additionally, we probe the nonlinear phase transitions between these phases by
varying the feedback gain and the difference of dual-bias magnetic fields.
Furthermore, we demonstrate the robustness of the limit cycle and
quasi-periodic orbit against the noise of magnetic fields. Our findings
establish a versatile platform for exploring complex spin dynamics and open new
avenues for the realization of multimode spin masers, time crystals and
quasi-crystals, and high-precision magnetometers.

</details>


### [127] [Agency cannot be a purely quantum phenomenon](https://arxiv.org/abs/2510.13247)
*Emily C. Adlam,Kelvin J. McQueen,Mordecai Waegell*

Main category: quant-ph

TL;DR: 量子系统无法满足能动性的三个基本条件：世界模型构建、行动后果评估和最优行动执行，这主要源于不可克隆定理和量子动力学的线性特性。


<details>
  <summary>Details</summary>
Motivation: 探究纯粹量子系统是否能够满足能动性的物理要求，即能否构建世界模型、评估行动后果并可靠执行最优行动。

Method: 通过分析量子系统的三个能动性条件与世界模型构建、行动评估的关系，结合不可克隆定理和量子动力学线性特性的理论分析。

Result: 发现纯粹量子系统无法满足能动性要求：世界模型构建违反不可克隆定理，行动评估需要复制世界模型，最优行动执行受限于量子线性动力学。

Conclusion: 能动性需要显著的经典资源，这对量子计算机模拟能动行为、量子能动性理论和自由意志理论提出了重要挑战。

Abstract: What are the physical requirements for agency? We investigate whether a
purely quantum system (one evolving unitarily in a coherent regime without
decoherence or collapse) can satisfy three minimal conditions for agency: an
agent must be able to create a world-model, use it to evaluate the likely
consequences of alternative actions, and reliably perform the action that
maximizes expected utility. We show that the first two conditions conflict with
the no-cloning theorem, which forbids copying unknown quantum states:
world-model construction requires copying information from the environment, and
deliberation requires copying the world-model to assess multiple actions.
Approximate cloning strategies do not permit sufficient fidelity or generality
for agency to be viable in purely quantum systems. The third agency condition
also fails due to the linearity of quantum dynamics. These results imply four
key consequences. First, agency requires significant classical resources,
placing clear constraints on its physical basis. Second, they provide insight
into how classical agents emerge within a quantum universe. Third, they show
that quantum computers cannot straightforwardly simulate agential behavior
without significant classical components. Finally, they challenge quantum
theories of agency, free will, and consciousness.

</details>


### [128] [Equivalence of Genuine Multipartite Entanglement and Nonlocality of Nearly Symmetric Multiqubit Pure States](https://arxiv.org/abs/2510.13296)
*Jakub Wójcik,Wojciech Bruzda,Ignacy Stachura,Remigiusz Augusiak*

Main category: quant-ph

TL;DR: 通过结合贝尔不等式、Hardy悖论和纯态规范分解，证明了所有高度对称的纯真正多体纠缠态都展现出真正多体非局域性，支持了Gisin猜想在多体情形下的成立。


<details>
  <summary>Details</summary>
Motivation: 解决纯真正多体纠缠态是否必然展现真正多体非局域性这一开放性问题，验证Gisin猜想在多体情形下的有效性。

Method: 结合新提出的贝尔不等式、Hardy悖论以及纯态的规范分解方法，对高度对称的多体纠缠态进行解析证明。

Result: 所有高度对称的纯真正多体纠缠态都展现出真正多体非局域性，为GME与GMNL等价性猜想提供了支持。

Conclusion: 这项工作向证明量子理论中纯真正多体纠缠与真正多体非局域性等价性迈出了重要一步，支持了Gisin猜想在多体情形下的成立。

Abstract: Whether every pure genuinely multipartite entangled (GME) state necessarily
exhibits genuine multipartite nonlocality (GMNL) remains an open question. By
combining a recently proposed Bell inequality [I. Stachura \textit{et al.},
\href{https://iopscience.iop.org/article/10.1088/1367-2630/ad7753}{New J. Phys.
\textbf{26}, 093029 (2024)}] with Hardy's paradox and the canonical
decomposition of pure states, we analytically demonstrate that all highly
symmetric, genuinely entangled multipartite qubit states exhibit genuine
multipartite nonlocality, thereby supporting Gisin's conjecture in the
multipartite setting. This result constitutes a step toward a general proof of
the conjectured equivalence between GME and GMNL in quantum theory.

</details>


### [129] [Hybrid Boson Sampling-Neural Network Architecture for Enhanced Classification](https://arxiv.org/abs/2510.13332)
*Mohammad Sharifian,Abolfazl Bayat*

Main category: quant-ph

TL;DR: 提出了一种结合玻色子采样和神经网络的混合框架，构建量子核以增强支持向量机分类性能，在多个数据集上超越经典核方法


<details>
  <summary>Details</summary>
Motivation: 解决量子优势在实际机器学习任务中的两个瓶颈：高维数据集和近期量子计算机性能限制，同时为玻色子采样寻找实际应用

Method: 神经网络自适应压缩数据特征到可编程玻色子采样电路，产生跨越高维希尔伯特空间的量子态，构建量子核用于支持向量机分类

Result: 在四个不同类别数据集上，该模型性能优于经典线性和sigmoid核

Conclusion: 基于玻色子采样的量子核在实用量子增强机器学习方面具有潜力

Abstract: Demonstration of quantum advantage for classical machine learning tasks
remains a central goal for quantum technologies and artificial intelligence.
Two major bottlenecks to this goal are the high dimensionality of practical
datasets and limited performance of near-term quantum computers. Boson sampling
is among the few models with experimentally verified quantum advantage, yet it
lacks practical applications. Here, we develop a hybrid framework that combines
the computational power of boson sampling with the adaptability of neural
networks to construct quantum kernels that enhance support vector machine
classification. The neural network adaptively compresses the data features onto
a programmable boson sampling circuit, producing quantum states that span a
high-dimensional Hilbert space and enable improved classification performance.
Using four datasets with various classes, we demonstrate that our model
outperforms classical linear and sigmoid kernels. These results highlight the
potential of boson sampling-based quantum kernels for practical
quantum-enhanced machine learning.

</details>


### [130] [Homodyne Measurement of a Non-Hermitian Qubit Undergoing Fluorescence](https://arxiv.org/abs/2510.13345)
*Roson Nongthombam,Amarendra K. Sarma*

Main category: quant-ph

TL;DR: 通过后选择三能级系统实现非厄米量子比特，研究测量反作用与非厄米衰变的相互作用，分析近异常点处的动力学行为。


<details>
  <summary>Details</summary>
Motivation: 探索后选择引入的非厄米衰变与测量反作用之间的相互作用，理解开放量子系统在异常点附近的瞬态行为。

Method: 对非厄米量子比特进行连续零差测量，比较测量轨迹的系综平均与刘维尔平均，建立无跳跃随机微分方程和路径积分框架。

Result: 远离异常点时，后选择非厄米量子比特的系综平均动力学与跳跃更新演化一致；近异常点时偏差取决于驱动性质，源于测量反作用与非厄米衰变的相互作用。

Conclusion: 测量反作用与非厄米动力学共同塑造开放量子系统的瞬态行为，为在异常点附近操控量子比特提供了新见解。

Abstract: Implementation of a two-level non-Hermitian qubit via postselection of a
three-level system has been demonstrated. The postselection procedure, which
discards quantum jump to the ground-state manifold while retaining excitations
in the first and second excited-state manifolds, effectively generates a
non-Hermitian qubit exhibiting PT symmetry. In this work, we perform continuous
homodyne mea- surement of this non-Hermitian qubit and analyze the interplay
between decay introduced by posts- election and measurement backaction. We
compare the ensemble-averaged dynamics obtained from measurement trajectories
with the the Liouvillian average. We formulate the no-jump stochastic
differential equation describing the postselected non-Hermitian qubit and show
that its ensemble- averaged dynamics agree with those of the jump-updated
postselected evolution at drive strengths far from the Liouvillian exceptional
point (EP). The degree of deviation near the EP depends sensitively on the
nature of the drive. This discrepancy is attributed to the interplay between
measurement backaction and the non-Hermitian decay introduced by postselection.
Furthermore, we determine the optimal path of the non-Hermitian qubit by
extremizing the action within the path-integral formulation of the quantum
trajectory framework Our results provide insights into how measurement
backaction and non-Hermitian dynamics together shape the transient behavior of
open quantum systems and enable controlled manipulation of qubits near
exceptional points.

</details>


### [131] [Quantum Approximate Optimization Algorithm for Maximum Likelihood Detection in Massive MIMO](https://arxiv.org/abs/2510.13350)
*Yuxiang Liu,Fanxu Meng,Zetong Li,Xutao Yu,Zaichen Zhang*

Main category: quant-ph

TL;DR: 提出基于QAOA的二进制符号最大似然检测求解器，通过贝叶斯优化参数初始化加速收敛并提高精确解概率


<details>
  <summary>Details</summary>
Motivation: 大规模MIMO系统中的最大似然检测问题是NP难问题，随着天线数量和符号增加变得复杂，需要利用量子算法优势

Method: 推导1级QAOA期望值的通用紧凑解析表达式，提出基于贝叶斯优化的参数初始化方法

Result: 相比现有QAOA检测算法，具有更通用紧凑的期望值表达式，需要更少量子资源，获得精确解的概率更高

Conclusion: 所提方案在大规模MIMO检测中展现出量子优势，为NISQ设备上的组合优化问题提供了有效解决方案

Abstract: In the massive multiple-input and multiple-output (Massive MIMO) systems, the
maximum likelihood (ML) detection problem is NP-hard and becoming classically
intricate with the number of the transmitting antennas and the symbols
increasing. The quantum approximate optimization algorithm (QAOA), a leading
candidate algorithm running in the noisy intermediate-scale quantum (NISQ)
devices, can show quantum advantage for approximately solving combinatorial
optimization problems. In this paper, we propose the QAOA based the maximum
likelihood detection solver of binary symbols. In proposed scheme, we first
conduct a universal and compact analytical expression for the expectation value
of the 1-level QAOA. Second, a bayesian optimization based parameters
initialization is presented, which can speedup the convergence of the QAOA to a
lower local minimum and improve the probability of measuring the exact
solution. Compared to the state-of-the-art QAOA based ML detection algorithm,
our scheme have the more universal and compact expectation value expression of
the 1-level QAOA, and requires few quantum resources and has the higher
probability to obtain the exact solution.

</details>


### [132] [Efficient lambda-enhanced gray molasses using an EIT-based laser locking scheme](https://arxiv.org/abs/2510.13360)
*Timothy Leese,Siobhan Patrick,Silvia Bergamini,Calum MacCormick*

Main category: quant-ph

TL;DR: 提出了一种低成本激光锁定系统的lambda增强灰黏胶冷却实现方案，使用两个独立激光器通过电磁诱导透明共振进行频率锁定，无需昂贵的GHz电子设备


<details>
  <summary>Details</summary>
Motivation: 传统相位锁定方法资源密集且昂贵，需要开发更经济实用的冷原子技术方案

Method: 采用非标准光束几何结构和低成本激光锁定设置，两个独立激光器通过电磁诱导透明共振特征进行频率锁定

Result: 该方法实现了足够的相干性，能够有效进行灰黏胶冷却，波函数蒙特卡洛分析支持实验发现

Conclusion: 这种方案显著降低了实验设置的复杂性和成本，是迈向更易获取的冷原子技术的重要一步

Abstract: We present a novel implementation of lambda-enhanced gray molasses cooling in
a non-standard beam geometry and with an inexpensive laser locking set-up. In
contrast to the established use of resource-intensive phase locking methods,
our laser system uses two independent lasers, frequency -locked to a spectral
feature produced by an electromagnetically induced transparency (EIT)
resonance. We show that this approach achieves sufficient coherence to enable
effective gray molasses cooling without the need for costly GHz electronics,
significantly reducing the complexity and cost of experimental setups and
represents a step toward more accessible cold atom technologies. A
wave-function Monte Carlo analysis supports the experimental findings, offering
insight into the cooling dynamics of this unconventional scheme

</details>


### [133] [An Industry-Academia Partnership for Advancing Quantum Frontiers: Perspective from the U.S. Center for Quantum Technologies](https://arxiv.org/abs/2510.13365)
*David Stewart,Gerardo Ortiz,Peter M. Kogge,Ricardo S. Decca,Tongcang Li*

Main category: quant-ph

TL;DR: 美国量子技术中心（CQT）是由普渡大学、印第安纳大学和圣母大学联合领导的多大学联盟，通过产学研合作加速量子技术创新。


<details>
  <summary>Details</summary>
Motivation: 建立跨学科研究联盟，整合学术研究与产业政府合作，推动量子技术发展。

Method: 通过IUCRC项目建立多大学合作机制，开展产学研协同研究。

Result: 形成了战略使命明确、研究议程跨学科的合作框架。

Conclusion: CQT通过协作开发、转化影响和人才培养，将在塑造量子赋能技术未来方面发挥重要作用。

Abstract: The U.S. Center for Quantum Technologies (CQT) is a multi-university
consortium established under the National Science Foundation's (NSF)
Industry-University Cooperative Research Centers (IUCRC) program. Led jointly
by Purdue University, Indiana University (both Bloomington and Indianapolis
campuses), and the University of Notre Dame, CQT integrates academic research
with industrial and governmental collaboration to accelerate quantum
innovation. This perspective outlines the consortium's strategic mission,
interdisciplinary research agenda, and its role in shaping the future of
quantum-enabled technologies through collaborative development, translational
impact, and workforce cultivation.

</details>


### [134] [Performance Comparison of Gate-Based and Adiabatic Quantum Computing for Power Flow Analysis](https://arxiv.org/abs/2510.13378)
*Zeynab Kaseb,Matthias Moller,Peter Palensky,Pedro P. Vergara*

Main category: quant-ph

TL;DR: 首次直接比较门基量子计算和绝热量子计算在求解交流潮流方程方面的性能，将AQPF算法适配到QAOA，在4节点测试系统上评估精度和计算时间。


<details>
  <summary>Details</summary>
Motivation: 解决现代电力网络中的计算挑战，在NISQ时代探索量子算法在潮流分析中的实际可行性。

Method: 将潮流方程重构为组合优化问题，基于AQPF算法适配到QAOA，并与D-Wave Advantage系统和富士通数字退火器进行对比。

Result: 提供了门基量子计算与绝热量子计算在性能权衡、可扩展性和实际可行性方面的定量见解。

Conclusion: 量子算法在解决潮流分析计算挑战方面具有潜力，特别是在NISQ时代。

Abstract: In this paper, we present the first direct comparison between gate-based
quantum computing (GQC) and adiabatic quantum computing (AQC) for solving the
AC power flow (PF) equations. Building on the Adiabatic Quantum Power Flow
(AQPF) algorithm originally designed for annealing platforms, we adapt it to
the Quantum Approximate Optimization Algorithm (QAOA). The PF equations are
reformulated as a combinatorial optimization problem. Numerical experiments on
a 4-bus test system assess solution accuracy and computational time. Results
from QAOA are benchmarked against those obtained using D-Wave's Advantage
system and Fujitsu's latest generation Digital Annealer, i.e., Quantum-Inspired
Integrated Optimization software (QIIO). The findings provide quantitative
insights into the performance trade-offs, scalability, and practical viability
of GQC versus AQC paradigms for PF analysis, highlighting the potential of
quantum algorithms to address the computational challenges associated with
modern electricity networks in the Noisy Intermediate-Scale Quantum (NISQ).

</details>


### [135] [Quantum teleportation, entanglement, LQU and LQFI in $e^{+}e^{-} \to \text{Y}\bar{\text{Y}}$ processes at BESIII through noisy channels](https://arxiv.org/abs/2510.13402)
*Elhabib Jaloum,Mohamed Amazioug*

Main category: quant-ph

TL;DR: 该研究分析性地研究了在BESIII实验中通过噪声通道的e+e-→YȲ过程中，量子隐形传态的保真度和量子关联度量（对数负性、局域量子不确定性和局域量子Fisher信息），发现保真度在所有噪声通道中均超过经典极限2/3。


<details>
  <summary>Details</summary>
Motivation: 研究量子隐形传态在粒子物理实验环境中的表现，特别是在噪声通道影响下量子关联的演化，这对于量子信息处理和粒子物理应用具有重要意义。

Method: 使用实验可行参数，分析性地研究e+e-→YȲ过程中量子隐形传态的保真度和量子关联度量（LN、LQU、LQFI），考虑三种不同的退相干通道（振幅阻尼、相位阻尼、相位翻转）。

Result: 无退相干时，LN、LQU和LQFI在φ=±π处消失；振幅阻尼和相位阻尼通道中量子关联随退相干参数s增加而减少；相位翻转通道在s=1/2处呈现对称行为；所有通道中保真度均超过经典极限2/3。

Conclusion: 量子噪声并非总是有害的，保真度在所有噪声通道中都能保持超过经典极限，这一发现在量子信息和粒子物理中具有重要应用前景。

Abstract: Quantum teleportation, a protocol that has received extensive and intensive
attention in quantum information processing, allows a quantum state to be
transferred from one particle to another. In this study, we analytically
investigate fidelity ($F$), logarithmic negativity (LN), local quantum
uncertainty (LQU) and local quantum Fisher information (LQFI) as a discord-like
measure of quantum correlations in $e^{+}e^{-} \to \text{Y}\bar{\text{Y}}$
processes at BESIII through noisy channels, using experimental feasible
parameters, where $\text{Y}$ and $\bar{\text{Y}}$ refer to the spin-$1/2$
hyperon and its antihyperon, respectively. Without a dephasing effect, we show
that, LN, LQU, and LQFI vanish at $\varphi=\pm\pi$ and are symmetric around
$\varphi=\pi/2$. We also explore the LN, LQU, and LQFI for different
$\text{Y}\bar{\text{Y}}$ pairs subjected to three distinct types of decoherence
channels. Specifically, we show that amplitude damping (AD) and phase damping
(PD) lead to a decrease in LN, LQU, and LQFI with an increasing decoherence
parameter $s$. In contrast, the phase flip (PF) channel exhibits symmetric
behavior around $s=1/2$. Besides, we realize for teleportation, optimal
fidelity for different hyperon-antihyperon pairs ($ \Lambda\bar{\Lambda}$,
$\Xi^{0}\bar{\Xi^{0}}$, $\Xi^{-}\bar{\Xi^{+}}$, $\Sigma^{+}\bar{\Sigma^{-}}$).
We discuss the influence of noisy channels, specifically (AD, PF and PD), on
the fidelity of quantum teleportation and on quantum correlations that can
exist even beyond entanglement. Furthermore, the results show that the fidelity
remains above the classical limit of $2/3$ in all three channels, even as the
noise increases. This is a significant finding because it shows that not all
quantum noise is detrimental. These results can have promising applications in
quantum information and particle physics.

</details>


### [136] [Towards Quantum Enhanced Adversarial Robustness with Rydberg Reservoir Learnin](https://arxiv.org/abs/2510.13473)
*Shehbaz Tariq,Muhammad Talha,Symeon Chatzinotas,Hyundong Shin*

Main category: quant-ph

TL;DR: 本文首次系统评估了基于量子储层计算(QRC)学习模型的对抗鲁棒性，使用Rydberg原子阵列作为量子储层，结合轻量级多层感知机作为可训练读出层，在对抗攻击下展现出比纯经典模型更高的准确性。


<details>
  <summary>Details</summary>
Motivation: 量子储层计算利用量子多体系统的高维非线性动力学处理时序数据，但现有研究表明基于变分电路的量子分类器易受对抗扰动影响，因此需要系统评估QRC模型的对抗鲁棒性。

Method: 使用强相互作用Rydberg原子阵列作为量子储层，在固定哈密顿量下自然演化产生高维嵌入，结合轻量级多层感知机作为读出层，在MNIST、Fashion-MNIST和Kuzushiji-MNIST数据集上进行白盒对抗攻击评估。

Result: 该方法在所有测试的扰动强度下都显著优于纯经典模型，展现出更高的准确性。

Conclusion: 这种混合方法揭示了一种新的量子优势来源，量子储层计算在对抗鲁棒性方面具有显著优势。

Abstract: Quantum reservoir computing (QRC) leverages the high-dimensional, nonlinear
dynamics inherent in quantum many-body systems for extracting spatiotemporal
patterns in sequential and time-series data with minimal training overhead.
Although QRC inherits the expressive capabilities associated with quantum
encodings, recent studies indicate that quantum classifiers based on
variational circuits remain susceptible to adversarial perturbations. In this
perspective, we investigate the first systematic evaluation of adversarial
robustness in a QRC based learning model. Our reservoir comprises an array of
strongly interacting Rydberg atoms governed by a fixed Hamiltonian, which
naturally evolves under complex quantum dynamics, producing high-dimensional
embeddings. A lightweight multilayer perceptron serves as the trainable readout
layer. We utilize the balanced datasets, namely MNIST, Fashion-MNIST, and
Kuzushiji-MNIST, as a benchmark for rigorously evaluating the impact of
augmenting the quantum reservoir with a Multilayer perceptron (MLP) in
white-box adversarial attacks to assess its robustness. We demonstrate that
this approach yields significantly higher accuracy than purely classical models
across all perturbation strengths tested. This hybrid approach reveals a new
source of quantum advantage and

</details>


### [137] [Quantum thermal diode with additional control by auxiliary atomic states](https://arxiv.org/abs/2510.13489)
*Qin Zhang,Zi-chen Zhang,Yi-jia Yang,Zheng Liu,Chang-shui Yu*

Main category: quant-ph

TL;DR: 研究量子热二极管，通过耦合辅助二能级原子来控制热流和整流效应。激发态辅助原子会减弱热流并增强整流效应，而基态辅助原子会增强热流并减弱整流效应。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过控制辅助原子的状态来调控量子热二极管的性能，实现热流的单向传输控制。

Method: 构建由两个二能级原子耦合辅助二能级原子组成的量子热二极管系统，分析不同状态下辅助原子对热流和整流效应的影响。

Result: 发现激发态辅助原子减弱热流但增强整流效应，基态辅助原子增强热流但减弱整流效应。辅助原子越多，这种增强或减弱效果越强。叠加态中只有激发态分量起主要作用。

Conclusion: 通过适当设计辅助原子的耦合方式可以消除整流效应，这为通过控制辅助原子状态来调控热流和整流性能提供了可能性。

Abstract: A quantum thermal diode, similar to an electronic diode, allows for
unidirectional heat transmission. In this paper, we study a quantum thermal
diode composed of two two-level atoms coupled to auxiliary two-level atoms. We
find that the excited auxiliary atoms can weaken heat current and enhance the
rectification effect, but the ground-state auxiliary atoms can enhance heat
current and weaken the rectification effect. The more auxiliary atoms are
coupled, the stronger the enhancing or weakening impact is. If the auxiliary
atom is in a superposition state, we find that only the fraction that projects
onto the excited state plays a significant role. In particular, if we properly
design the coupling of the auxiliary atoms, the rectification effect can be
eliminated. This provides the potential to control the heat current and the
rectification performance by the states of the auxiliary atoms.

</details>


### [138] [Lattice surgery with Bell measurements: Modular fault-tolerant quantum computation at low entanglement cost](https://arxiv.org/abs/2510.13541)
*Trond Hjerpekjøn Haug,Timo Hillmann,Anton Frisk Kockum,Raphaël Van Laer*

Main category: quant-ph

TL;DR: 提出了一种新的模块化量子计算协议，通过贝尔测量实现表面码的格点手术，将链路噪声限制在接口处，同时将模块间门操作数量减半。


<details>
  <summary>Details</summary>
Motivation: 模块化架构是扩展量子计算机到容错规模的有前景方法。需要在模块间实现高效量子链路，因为模块间纠缠的产生比本地纠缠更具挑战性。

Method: 引入基于表面码的格点手术协议，所有非局域操作都是贝尔测量。采用交替门序列策略来减轻距离减少的钩子错误。

Result: 电路级模拟显示，在广泛链路噪声范围内，该协议在给定纠缠速率下的逻辑错误抑制始终优于其他协议，典型情况下可节省40%的纠缠资源。

Conclusion: 该方法适用于任何需要跨处理器模块划分的量子电路，可指导开发资源高效的模块化量子计算。

Abstract: Modular architectures are a promising approach to scaling quantum computers
to fault tolerance. Small, low-noise quantum processors connected through
relatively noisy quantum links are capable of fault-tolerant operation as long
as the noise can be confined to the interface. Finding protocols that implement
the quantum links between modules as efficiently as possible is essential
because inter-module entanglement is challenging to produce at a similar rate
and fidelity as local entanglement. We introduce a protocol for lattice surgery
on surface codes in which all non-local operations are Bell measurements. The
protocol simultaneously confines the link noise and requires only half as many
module-crossing gates as previously proposed protocols. To mitigate
distance-reducing hook errors, we introduce a strategy of alternating the gate
sequence between rounds of syndrome measurement, which prevents multiple hooks
from simultaneously aligning with a logical operator in the code. We evaluate
our protocol's performance when two logical qubits on separate modules are
prepared in a logical Bell state. Circuit-level simulations under depolarizing
noise show that the logical error suppression for a given entanglement rate
between modules is consistently stronger compared to the best-performing
alternative protocols for a wide range of link noise, with a typical 40%
entanglement resource saving for a constant logical error rate. Our approach to
protocol design is applicable to any quantum circuit that must be divided
across processor modules and can therefore guide development of
resource-efficient modular quantum computation beyond the surface code.

</details>


### [139] [State-Specific Orbital Optimization for Enhanced Excited-States Calculation on Quantum Computers](https://arxiv.org/abs/2510.13544)
*Guorui Zhu,Joel Bierman,Jianfeng Lu,Yingzhou Li*

Main category: quant-ph

TL;DR: 提出了一种状态特定的轨道优化方案，用于提高电子结构哈密顿量激发态在近量子计算机上的计算精度，可与任何基于重叠的激发态量子本征求解器结合使用。


<details>
  <summary>Details</summary>
Motivation: 提高在近量子计算机上计算电子结构激发态的准确性，为基于重叠的激发态量子本征求解器提供更灵活的轨道选择。

Method: 推导了不同轨道生成的不同状态之间重叠项相对于轨道旋转矩阵的梯度，并使用基于梯度的优化方法优化轨道。将该方案与变分量子紧缩算法结合实现。

Result: 在H4和LiH等各种分子上，状态特定轨道优化方案比状态平均轨道优化方案达到更高的精度。

Conclusion: 状态特定轨道优化方案能够有效提高激发态计算的准确性，为量子计算中的电子结构问题提供了更优的解决方案。

Abstract: We propose a state-specific orbital optimization scheme for improving the
accuracy of excited states of the electronic structure Hamiltonian for the use
on near-term quantum computers, which can be combined with any overlap-based
excited-state quantum eigensolver. We derived the gradient of the overlap term
between different states generated by different orbitals with respect to the
orbital rotation matrix and use the gradient-based optimization methods to
optimize the orbitals. This scheme allows for more flexibility in the choice of
orbitals. We implement the state-specific orbital optimization scheme with the
variational quantum deflation (VQD) algorithm, and show that it achieves higher
accuracy than the state-averaged orbital optimization scheme on various
molecules including H4 and LiH.

</details>


### [140] [Exact dynamics and qubit inversion of non-Hermitian driven two-level systems](https://arxiv.org/abs/2510.13550)
*Ivan A. Bocanegra-Garay,Luis M. Nieto*

Main category: quant-ph

TL;DR: 本文展示了广义非厄米驱动二能级系统的超对称结构，通过酉旋转和微分方程解耦揭示了该结构，并通过辅助薛定谔方程的光谱分析获得了可解析求解的复驱动函数。


<details>
  <summary>Details</summary>
Motivation: 研究非厄米驱动二能级系统的超对称结构，为核磁共振和光学增益-损耗材料实验提供理论支持。

Method: 使用酉旋转将哈密顿量转换为更方便的形式，解耦微分方程组，分析辅助薛定谔方程的光谱以获得复驱动函数。

Result: 发现了能产生量子比特状态跃迁的复驱动函数，这些驱动以不同但有趣的方式实现状态转换。

Conclusion: 所报道的结果对核磁共振和光学增益-损耗材料实验的设计和实施具有重要价值。

Abstract: The supersymmetric structure of a generalized non-Hermitian driven two-level
system is demonstrated. A unitary rotation turns the Hamiltonian into a more
convenient form. After decoupling a set of differential equations, the
supersymmetric structure of the problem can be unequivocally ap- appreciated.
Performing a spectral analysis of an auxiliary stationary Schr\"odinger-like
equation, complex time-dependent driving functions are obtained for which the
corresponding (time-dependent) Schr\"odinger equation can be straightforwardly
solved. Such complex drivings are seen to produce transitions in the qubit
state in different, however interesting, manners. We believe that the results
reported here will be of interest for designing and carrying out various
experiments in laboratories specializing in nuclear magnetic resonance or in
optics with gain and loss materials.

</details>


### [141] [Non-Clifford Fusion: T-Gate Optimization for Quantum Simulation](https://arxiv.org/abs/2510.13573)
*Yingheng Li,Xulong Tang,Paul Hovland,Ji Liu*

Main category: quant-ph

TL;DR: NCF是一种用于哈密顿量模拟的编译框架，通过将泡利字符串分组并共轭变换到受限量子比特子集，同时减少T门数量和深度。


<details>
  <summary>Details</summary>
Motivation: 哈密顿量模拟中，RZ门通常被合成为Clifford和T门序列，在容错量子计算机中，T门数量和深度是关键指标，需要优化。

Method: 将泡利字符串分组，每个组可以共轭变换为在受限量子比特子集上应用量子门的泡利字符串列表，从而实现整个组的同步合成。

Result: 相比现有最优方法，NCF平均减少T门数量57.4%、T门深度49.1%、Clifford门数量49.0%。

Conclusion: NCF框架有效降低了哈密顿量模拟的T门开销，显著提升了量子计算的效率。

Abstract: Hamiltonian simulation is a key quantum algorithm for modeling complex
systems. To implement a Hamiltonian simulation, it is typically decomposed into
a list of Pauli strings, each corresponds to an RZ rotation gate with many
Clifford gates. These RZ gates are generally synthesized into a sequence of
Clifford and T gates in fault-tolerant quantum computers, where the T-gate
count and T-gate depth are critical metrics for such systems. In this paper, we
propose NCF, a compilation framework that reduces both the T-gate count and
T-gate depth for Hamiltonian simulation. NCF partitions Pauli strings into
groups, where each group can be conjugated (i.e., transformed) into a list of
Pauli strings that apply quantum gates on a restricted subset of qubits,
allowing for simultaneous synthesis of the whole group and reducing both T-gate
count and depth. Experimental results demonstrate that NCF achieves an average
reduction of 57.4%, 49.1%, and 49.0% in T-gate count, T-gate depth, and
Clifford count, respectively, compared to the state-of-the-art method.

</details>


### [142] [Emergent Discrete Time Crystals on Digital Quantum Computers: Boundary-Protected and Ancilla-Induced Disorder Mechanisms of Thermalization Slowdown](https://arxiv.org/abs/2510.13577)
*Kazuya Shinjo,Kazuhiro Seki,Seiji Yunoki*

Main category: quant-ph

TL;DR: 研究了在IBM量子处理器上实现的周期性驱动伊辛模型中，量子噪声如何诱导产生两种不同类型的离散时间晶体（DTCs），展示了噪声可以稳定非平衡动力学相。


<details>
  <summary>Details</summary>
Motivation: 周期性驱动系统通常会演化到无限温度热态，但在达到平衡前可以表现出长寿命的预热态，如离散时间晶体。本研究旨在探索量子噪声在这些非平衡现象中的作用。

Method: 在IBM Quantum Eagle和Heron处理器上实现周期性驱动的伊辛模型，使用辅助量子比特构建Kagome和Lieb晶格，通过噪声矩阵积态模拟验证实验结果。

Result: 在噪声较大的Eagle设备上观察到两种DTCs：类型I来自边界模振荡的重新分布，类型II在无电荷泵浦系统中由噪声稳定产生。在低噪声Heron设备上，振荡仅限于边界。

Conclusion: 量子噪声可以诱导产生新型预热动力学相，包括边界保护和噪声诱导的离散时间晶体，揭示了噪声在非平衡系统中的积极作用。

Abstract: Periodically driven (Floquet) systems typically evolve toward an
infinite-temperature thermal state due to continuous energy absorption. Before
reaching equilibrium, however, they can transiently exhibit long-lived
prethermal states that host exotic nonequilibrium phenomena, such as discrete
time crystals (DTCs). In this study, we investigate the relaxation dynamics of
periodically driven product states in a kicked Ising model implemented on the
IBM Quantum Eagle and Heron processors. By using ancilla qubits to mediate
interactions, we construct Kagome and Lieb lattices on superconducting qubits
with heavy-hex connectivity. We identify two distinct types of noise-induced
DTCs on Kagome and Lieb lattices, both arising from quantum noise in ancilla
qubits. Type-I DTCs originate from robust boundary-mode period-doubling
oscillations, stabilized by symmetry charge pumping, that are redistributed
into the bulk due to ancilla noise. Type-II DTCs, in contrast, emerge in
systems without charge-pumped qubits, where quantum noise unexpectedly
stabilizes period-doubling oscillations that would otherwise rapidly decay. On
the noisier Eagle device (ibm_kyiv), we observe both type-I and type-II DTCs on
53-qubit Kagome lattices with and without charge-pumped qubits, respectively.
In contrast, on the lower-noise Heron device (ibm_marrakesh), period-doubling
oscillations are confined to boundary-localized oscillations on 82-qubit Kagome
and 40-qubit Lieb lattices, as redistribution into the bulk is suppressed.
These experimental findings are supported by noisy matrix-product-state
simulations, in which ancilla noise is modeled as random sign flips in the
two-qubit gate rotation angles. Our results demonstrate that quantum noise in
ancilla qubits can give rise to novel classes of prethermal dynamical phases,
including boundary-protected and noise-induced DTCs.

</details>


### [143] [Yang-Lee edge singularity and quantum criticality in non-Hermitian PXP model](https://arxiv.org/abs/2510.13581)
*Wen-Yi Zhang,Meng-Yun Mao,Qing-Min Hu,Xinzhi Zhao,Gaoyong Sun,Wen-Long You*

Main category: quant-ph

TL;DR: 提出了非厄米失谐PXP模型中量子临界性的完整理论框架，建立了完整的相图，揭示了Ising普适类相变、Yang-Lee边缘奇点等关键现象，并提出了在里德堡原子阵列中观测的实验方案。


<details>
  <summary>Details</summary>
Motivation: 先前研究未能建立非厄米失谐PXP模型的完整相图，需要系统理论框架来描述其量子临界行为。

Method: 通过相似变换构建二阶相变边界，引入双正交纠缠熵和双正交Loschmidt回波，使用关联函数区分相，并采用双正交和自归一化Loschmidt回波定位Yang-Lee边缘奇点。

Result: 确定了Ising普适类相变，区分了PT对称区域内的约束和去约束相，识别了完整PT转变和第一激发态PT转变，提取了与non-unitary共形场论一致的临界指数。

Conclusion: 建立了完整的非厄米量子临界性理论框架，揭示了丰富的相变现象，并提出了可行的实验观测方案。

Abstract: We present a comprehensive theoretical framework for quantum criticality in
the non-Hermitian detuned PXP model, and establish the complete phase diagram,
which had remained elusive in previous studies. Starting from a numerically
identified phase transition point, we construct an exact second-order phase
transition boundary through a similarity transformation in the real-energy
regime. By introducing the biorthogonal entanglement entropy and biorthogonal
Loschmidt echo, we demonstrate from both equilibrium and nonequilibrium
perspectives that this transition belongs to the Ising universality class.
Using the correlation function, we further distinguish between confined and
deconfined phases within the $\mathcal{PT}$-symmetric region. In the
complex-energy regime, we identify both a full $\mathcal{PT}$ transition and a
first-excited-state $\mathcal{PT}$ transition, respectively. Moreover, we
identify the location of the Yang-Lee edge singularity (YLES) using both the
associated-biorthogonal and self-normal Loschmidt echoes, and extract the
corresponding critical exponent, which agrees with the predictions of
non-unitary conformal field theory. Finally, we propose an experimental scheme
to observe the YLES in Rydberg atomic arrays, which offers a promising route to
exploring non-Hermitian critical phenomena and singularities in future
experimental settings.

</details>


### [144] [Inverse designed Hamiltonians for perfect state transfer and remote entanglement generation, and applications in superconducting qubits](https://arxiv.org/abs/2510.13584)
*Tian-Le Wang,Ze-An Zhao,Peng Wang,Sheng Zhang,Ren-Ze Zhao,Xiao-Yan Yang,Hai-Feng Zhang,Zhi-Fei Li,Yuan Wu,Peng Duan,Ming Gong,Guo-Ping Guo*

Main category: quant-ph

TL;DR: 提出了一种称为穹顶模型的哈密顿量逆工程方法，通过可调参数m构建噪声鲁棒的量子系统，实现完美态传输和远程纠缠生成，并提出了级联策略解决可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 传统哈密顿量逆工程方法获得的协议对噪声缺乏鲁棒性，需要开发能够抵抗噪声干扰的量子信息处理方案。

Method: 从噪声鲁棒的能量谱出发，构建具有可调参数m的穹顶模型哈密顿量，该模型在m=0时退化为传统PST模型，在大m时简化为仅涉及两个末端量子比特的SWAP模型。

Result: 数值模拟证实穹顶模型显著提高了系统对噪声的鲁棒性，提出的级联策略解决了长距离PST的可扩展性挑战。

Conclusion: 该工作特别适合在具有可调耦合器的超导量子比特上演示，通过快速灵活的哈密顿量工程推进鲁棒且可扩展的量子信息处理的实验潜力。

Abstract: Hamiltonian inverse engineering enables the design of protocols for specific
quantum evolutions or target state preparation. Perfect state transfer (PST)
and remote entanglement generation are notable examples, as they serve as key
primitives in quantum information processing. However, Hamiltonians obtained
through conventional methods often lack robustness against noise. Assisted by
inverse engineering, we begin with a noise-resilient energy spectrum and
construct a class of Hamiltonians, referred to as the dome model, that
significantly improves the system's robustness against noise, as confirmed by
numerical simulations. This model introduces a tunable parameter $m$ that
modifies the energy-level spacing and gives rise to a well-structured
Hamiltonian. It reduces to the conventional PST model at $m=0$ and simplifies
to a SWAP model involving only two end qubits in the large-$m$ regime. To
address the challenge of scalability, we propose a cascaded strategy that
divides long-distance PST into multiple consecutive PST steps. Our work is
particularly suited for demonstration on superconducting qubits with tunable
couplers, which enable rapid and flexible Hamiltonian engineering, thereby
advancing the experimental potential of robust and scalable quantum information
processing.

</details>


### [145] [Quality assessment of quantum teleportation through the distribution of fidelity](https://arxiv.org/abs/2510.13600)
*D. G. Bussandri,G. M. Bosyk,P. Crespo Del Amo,K. Życzkowski*

Main category: quant-ph

TL;DR: 提出了超越传统平均保真度的单量子比特量子隐形传态性能评估框架，包括保真度概率密度函数和基于先验重要性函数的认证方法


<details>
  <summary>Details</summary>
Motivation: 传统平均保真度基准无法充分反映量子隐形传态的真实性能，可能掩盖噪声引入的不对称性并导致错误结论

Method: 推导了实际保真度的完整概率密度函数闭式表达式，应用于经典测量-制备方案和标准量子隐形传态；引入基于先验重要性函数的认证方法

Result: 相同平均保真度的协议可能表现出显著不同的统计行为；认证高保真度隐形传态需要更强的纠缠或非局域性；"用噪声对抗噪声"效应源于先验函数选择而非真正优势

Conclusion: 该框架为定制化、应用特定的隐形传态基准提供了多功能工具

Abstract: In this work, we introduce a comprehensive statistical framework for
assessing single-qubit quantum teleportation performance beyond the
conventional average-fidelity benchmark. At first, we derive a closed-form
expression for the full probability density function of actual teleportation
fidelities and apply it to both classical measure-and-prepare schemes and
standard quantum teleportation, considering two relevant noise models:
Bell-diagonal resource states and local amplitude-damping channels. These
results reveal that protocols with identical average fidelities can exhibit
markedly different statistical behaviors, and that relying solely on average
fidelity can mask inherent asymmetries introduced by local noise, potentially
leading to spurious conclusions of symmetry. Secondly, we introduce a
certification method based on prior importance functions (e.g., Beta
distributions), which unifies moment-based criteria and threshold-based success
probabilities into a single figure of merit. Applying this framework, we show
that certifying high-fidelity teleportation requires increasingly stronger
entanglement or non-locality, and we clarify that the so-called ``fighting
noise with noise'' effect arises from the chosen prior importance function
rather than representing a genuine advantage. Our approach thus provides
versatile tools for tailored, application-specific teleportation benchmarks.

</details>


### [146] [What can we do in a symmetry-constrained perspective? The importance of the total charge's status in quantum reference frame frameworks](https://arxiv.org/abs/2510.13607)
*Guilhem Doat,Augustin Vanrietvelde*

Main category: quant-ph

TL;DR: 该论文澄清了量子参考系框架的差异，主要区分了弱对称性和强对称性方法，并讨论了全局电荷可访问性这一基本物理问题。


<details>
  <summary>Details</summary>
Motivation: 由于不同社群开发了不等价的量子参考系框架，需要澄清这些框架之间的差异及其物理含义。

Method: 通过数学分析区分弱对称性和强对称性方法，并引入基于操作能力的视角定义，讨论两种方法的物理后果。

Result: 发现采用弱对称性方法会导致动量模糊性，并阻碍定义可逆的QRF变换；同时证明了内部观测者可以通过相对干涉测量和经典通信来测量全局电荷。

Conclusion: 论文阐明了量子参考系框架的关键差异，提出了基于操作能力的视角定义，并展示了如何通过合理物理假设使内部观测者能够测量全局电荷。

Abstract: The study of quantum reference frames has received renewed interest over the
last years, leading to the parallel development of non-equivalent frameworks by
different communities. We clarify the differences between these frameworks. At
the mathematical level, they mainly differ in the kind of symmetry (either weak
or strong) employed to constrain the system. We show that this mathematical
difference corresponds to a fundamental physical question: whether the global
charge associated to the symmetry group is accessible to symmetry-constrained
observers. In this context, we formulate a definition of a perspective in terms
of operational capacities, or lack thereof. Turning to consequences of adopting
either approach, we discuss how adopting the weak approach induces an ambiguity
in the momenta included in each perspective and bars from defining reversible
QRF transformations. We then review and analyze the existing arguments
motivating each approach, and show how they bear upon the problem of charge
accessibility. Finally, we introduce a simple operational scenario in which
upholding two reasonable physical postulates leads to the conclusion that
internal observers could measure the global charge by 1/ performing a
relativized interference measurement and 2/ classically communicating.

</details>


### [147] [Cryo-CMOS Antenna for Wireless Communications within a Quantum Computer Cryostat](https://arxiv.org/abs/2510.13627)
*Viviana Centritto,Ama Bandara,Heqi Deng,Masoud Babaie,Evgenii Vinogradov,Sergi Abadal,Eduard Alarcon*

Main category: quant-ph

TL;DR: 提出了一种在4K低温环境下工作的28GHz差分偶极天线，用于量子计算机多核架构中的无线通信，以解决有线连接的瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 量子计算机从少量量子比特扩展到大规模时，多核架构通过分布式量子处理单元实现可扩展性，但有线连接存在空间限制、功耗和延迟问题，阻碍了性能提升。

Method: 设计了一种低温兼容的片上差分偶极天线，工作在28GHz频段，考虑了4K温度下的材料特性，并在真实的低温恒温器结构中评估天线性能。

Result: 该天线在自由空间中反射系数达到-20.8dB，在低温恒温器内达到-18.38dB，表现出高效的阻抗匹配性能。

Conclusion: 提出的低温兼容无线通信方案为解决量子计算机多核架构中的有线连接瓶颈提供了可行解决方案。

Abstract: Scaling quantum computers from a few qubits to large numbers remains one of
the critical challenges in realizing practical quantum advantage. Multi-core
quantum architectures have emerged as a promising solution, enabling
scalability through distributed quantum processing units (QPUs) interconnected
via classical and quantum links. However, the bottleneck of wired connections
persists, as densely packed wired interconnects, both vertically across
temperature stages and horizontally within the same layer, introduce spatial
constraints, power dissipation, and latency, which could hinder performance as
the number of QPUs increases. To overcome these limitations, this work proposes
a cryo-compatible on-chip differential dipole antenna operating at 28 GHz to
enable short-range wireless communication within a quantum computer cryostat.
Temperature-dependent material properties are incorporated to accurately
capture antenna behavior at 4 K. Moreover, by embedding the antenna in a
realistic cryostat structure, we evaluate the feasibility of antenna operation
within the cryogenic environment. The proposed antenna achieves a reflection
coefficient of -20.8 dB in free space and -18.38 dB within the cryostat,
demonstrating efficient impedance matching.

</details>


### [148] [Robust Superradiance and Spontaneous Spin Ordering in Disordered Waveguide QED](https://arxiv.org/abs/2510.13671)
*Xin H. H. Zhang,Daniel Malz,Peter Rabl*

Main category: quant-ph

TL;DR: 研究无序原子阵列在波导中的集体辐射行为，发现即使在强无序条件下，超辐射爆发的关键特征仍然保持稳健，峰值发射率仍按N²缩放。


<details>
  <summary>Details</summary>
Motivation: 探索无序原子阵列中是否仍能保持超辐射现象，解决强无序系统中集体量子光学现象存在性的重要开放问题。

Method: 使用大规模半经典模拟和解析变分估计，分析一维波导中N个激发二能级原子的集体发射行为，研究空间和光谱无序的影响。

Result: 超辐射爆发的峰值发射率在强无序条件下仍保持N²缩放，原子会自发地根据位置自组织以优化相长干涉效应，产生镜像不对称相关性。

Conclusion: 超辐射在强无序阵列中仍然存在且具有稳健性，原子自组织行为解释了无序系统中集体衰变的出现机制，为理解实际系统中的集体量子光学现象提供了重要见解。

Abstract: We study the collective emission of a disordered array of $N$ excited
two-level atoms into a one-dimensional photonic waveguide. In the perfectly
ordered case, where atoms are spaced by exact integer multiples of the
wavelength, the system exhibits the characteristic superradiant burst with a
peak emission rate scaling as $N^2$. Using large-scale semiclassical
simulations, we find that this key signature of superradiance remains
asymptotically robust under strong spatial and spectral disorder, but also
exhibits subtle finite-size scaling toward this limit. To explain our
observations, we provide an analytical variational estimate for the maximal
decay rate, which tightly bounds the numerical results and reveals how disorder
shapes the collective decay. Specifically, we find that even in the presence of
strong disorder, the spins tend to self-organize spontaneously according to
their locations, which overall optimizes constructive interference effects and
explains the emergence of mirror-asymmetric correlations in superradiant decay.
These findings resolve important open questions regarding the existence and
nature of superradiance in strongly disordered arrays and offer valuable
insights for understanding collective quantum optical phenomena in realistic
systems.

</details>


### [149] [Spin Readout in a 22 nm Node Integrated Circuit](https://arxiv.org/abs/2510.13674)
*Isobel C. Clarke,Virginia Ciriano-Tejel,David J. Ibberson,Grayson M. Noah,Thomas H. Swift,Mark A. I. Johnson,Ross C. C. Leon,Alberto Gomez-Saiz,John J. L. Morton,M. Fernando Gonzalez-Zalba*

Main category: quant-ph

TL;DR: 该论文展示了在22纳米全耗尽绝缘体上硅CMOS技术中实现可寻址量子点器件的单次自旋读取，通过能量选择测量实现自旋到电荷转换，支持大规模集成自旋量子比特的发展。


<details>
  <summary>Details</summary>
Motivation: 构建具有广泛应用能力的量子计算机需要数百万个可寻址物理量子比特，这带来了量子系统与经典电子学大规模集成的挑战。研究旨在探索在同一制造平台上实现控制电子学和自旋量子比特的可能性。

Method: 使用行业标准22纳米全耗尽绝缘体上硅CMOS技术制造集成电路，通过斜坡能量选择测量实现自旋到电荷转换，使用射频单电子晶体管进行检测，并由片上低温电子学进行寻址。

Result: 在可寻址阵列中的两个名义相同器件中观察到超过90%的一致读取可见度和毫秒级自旋弛豫时间，支持单元电池的可重复性。

Conclusion: 使用该CMOS工艺成功观测到自旋读取是实现高度可扩展和集成自旋量子比特的关键步骤。

Abstract: Constructing a quantum computer capable of broad and important applications
is likely to require millions of addressable physical qubits, posing the
challenge of large-scale integration of quantum systems with classical
electronics. Fully depleted silicon-on-insulator CMOS technology has been used
to develop a range of cryogenic electronic components for the control and
readout of different qubit modalities interfaced on separate chips. However,
recent measurements of quantum dots on this technology raise the tantalising
prospect of realising control electronics and spin qubits on the same
manufacturing platform, within a single integrated circuit (IC). Here, we
demonstrate single-shot spin readout in addressable quantum dot devices within
an IC fabricated using industry-standard 22 nm fully depleted
silicon-on-insulator technology. We achieve spin-to-charge conversion via a
ramped energy-selective measurement, detected using a radio-frequency
single-electron transistor and addressed by on-chip cryogenic electronics. The
observation of consistent readout visibilities exceeding 90% and millisecond
spin relaxation times in two nominally identical devices within the addressable
array supports the reproducibility of the unit cell. The successful observation
of spin readout using this CMOS process marks a key step towards realising
highly scalable and integrated spin qubits.

</details>


### [150] [Reduced constant-cost implementations of Clifford operations using global interactions](https://arxiv.org/abs/2510.13761)
*Jonathan Nemirovsky,Lee Peleg,Amit Ben Kish,Yotam Shapira*

Main category: quant-ph

TL;DR: 本文提出了一种在量子电路中用最多6次全连接多量子比特纠缠门实现任意长度Clifford操作序列的方法，以及用5次实现任意长度CNOT门序列的方法，无需辅助量子比特。


<details>
  <summary>Details</summary>
Motivation: 研究基于任意单量子比特操作和可编程全连接多量子比特纠缠门构建的量子电路，这类门在囚禁离子量子计算平台中是原生支持的。

Method: 开发了一种实用且计算高效的编译算法，将任意长度的Clifford操作序列和CNOT门序列分别编译为最多6次和5次全连接多量子比特纠缠门。

Result: 实现了Clifford操作序列的常数代价编译（最多6次多量子比特门），以及CNOT门序列的5次多量子比特门编译，无需辅助量子比特。

Conclusion: 该工作为量子电路编译提供了高效方法，显著减少了多量子比特门的应用次数，并分析了实现所需的量子比特驱动功率。

Abstract: We investigate quantum circuits built from arbitrary single-qubit operations
combined with programmable all-to-all multiqubit entangling gates that are
native to, among other systems, trapped-ion quantum computing platforms. We
report a constant-cost of no more than 6 application of such Clifford
entangling multiqubit gates to realize any sequence of Clifford operations of
any length, without ancillae. Furthermore, we show that any sequence of CNOT
gates of any length, can be replaced with 5 applications of such Clifford
entangling multiqubit gates, without ancillae. We investigate the required
qubit drive power that is associated with these implementations. Our work
introduces a practical and computationally efficient algorithm to realize these
compilations.

</details>


### [151] [Are Randomized Quantum Linear Systems Solvers Practical?](https://arxiv.org/abs/2510.13766)
*Siddharth Hariprakash,Roel Van Beeumen,Katherine Klymko,Daan Camps*

Main category: quant-ph

TL;DR: 本文分析了基于随机傅里叶级数的量子线性系统求解器的端到端资源需求，通过结合傅里叶级数采样和哈密顿模拟来估计矩阵逆的标量性质。研究表明该方法的采样复杂度可能呈指数增长，质疑了其在早期容错量子计算时代的实用性。


<details>
  <summary>Details</summary>
Motivation: 在量子模拟和量子线性代数中，随机量子算法被提出以构建比基于块编码方法更浅的电路。虽然这类随机方案的算法复杂度被证明是次优的，但人们推测在电路深度代价高昂的早期容错时代，它们可能提供优势。

Method: 结合傅里叶级数采样与哈密顿模拟，分析两种哈密顿模拟核：二阶乘积公式近似和随机泰勒展开(RTE)方法。推导控制总误差的所有相关算法参数的显式边界。

Result: 数值演示证实了分析结果的有效性，并显示随机傅里叶级数方法的采样复杂度可能呈指数增长，质疑了该方法在线性系统问题中的实际可行性。

Conclusion: 通过提供显式边界，这项工作在理论算法提案和高效硬件实现之间架起桥梁，同时能够与在资源开销较大但具有最优渐近复杂度的替代算法进行公平比较。

Abstract: Randomized quantum algorithms have been proposed in the context of quantum
simulation and quantum linear algebra with the goal of constructing shallower
circuits than methods based on block encodings. While the algorithmic
complexities of such randomized schemes have been shown to be suboptimal, it
has been speculated that they may offer benefits in the early fault-tolerant
era where circuit depth comes at a premium. In this work, we investigate the
end-to-end resource requirements for a randomized quantum linear systems solver
to estimate scalar properties of the matrix inverse by combining sampling from
a Fourier series with Hamiltonian simulation. We derive explicit bounds on all
relevant algorithmic parameters that control the total error. We analyze two
algorithmic kernels for Hamiltonian simulation: a second order product formula
approximation and a method called random Taylor expansion (RTE).
  Finally, we provide numerical demonstrations that confirm the validity of our
analytical results and question the actual practicality of the randomized
Fourier series-based approach for linear systems problems as we show that the
sampling complexity can grow exponentially. By providing explicit bounds, our
work serves as a bridge between theoretical algorithmic proposals and efficient
hardware implementations while also enabling fair comparisons to alternative
algorithms that exhibit optimal asymptotic complexities at the cost of large
resource overheads.

</details>


### [152] [Observation of area laws in an interacting quantum field simulator](https://arxiv.org/abs/2510.13783)
*Maciej T. Jarema,Mohammadamin Tajik,Jörg Schmiedmayer,Silke Weinfurtner,Tobias Haas*

Main category: quant-ph

TL;DR: 该论文通过实验在超冷原子模拟器中首次验证了量子多体系统中互信息的面积极律，开发了数据驱动、模型无关的方法来探测高维量子系统中的信息。


<details>
  <summary>Details</summary>
Motivation: 在相互作用系统中，由于状态重构的复杂性，信息测量的读取受到阻碍，目前只在小量子系统中进行了测量。需要填补这一空白，实验验证面积极律。

Method: 使用超冷原子模拟器模拟具有可调相互作用强度的量子场，采用数据驱动、模型无关的方法测量互信息。

Result: 实验详细展示了互信息随子系统体积、边界面积和空间区域间距的标度关系，并用量子相对熵量化了非高斯关联的总效应。

Conclusion: 该方法构成了探测高维量子系统中信息及其在塑造量子物质和时空中作用的通用工具包。

Abstract: Information shared between parties quantifies their correlation. The encoding
of correlations across space and time characterises the structure, history, and
interactions of systems. One of the most fundamental properties that emerges
from studies of information is the area law, which states that information
shared between spatial subregions typically scales with the area of their
boundary rather than their volume. In non-interacting, quantum many-body
systems, where Gaussian statistics apply, the scaling of information measures
is well understood. Within interacting systems, the readout of information
measures is impeded by the complexity of state reconstruction. As such, no
measurements beyond small quantum systems (e.g., composed of few, localised
particles) have been made. Here, we fill this gap by experimentally
demonstrating the area law of mutual information in an ultra-cold atom
simulator of quantum fields with tuneable interaction strength. Our results
detail the scaling of mutual information with subsystem volume, boundary area,
and separation between spatial regions at finite temperature. Moreover, we
quantify the total effect of non-Gaussian correlations using an
information-theoretic measure - relative entropy. Our presented approach is
data-driven, model agnostic, and readily applicable to other platforms and
observables, thus constituting a universal toolkit for probing information in
high-dimensional quantum systems and its role in shaping quantum matter and
spacetime.

</details>


### [153] [Digitized Counterdiabatic Quantum Feature Extraction](https://arxiv.org/abs/2510.13807)
*Anton Simen,Carlos Flores-Garrigós,Murilo Henrique De Oliveira,Gabriel Dario Alvarado Barrios,Alejandro Gomez Cadavid,Archismita Dalal,Enrique Solano,Narendra N. Hegade,Qi Zhang*

Main category: quant-ph

TL;DR: 提出基于哈密顿量的量子特征提取方法，利用多体自旋系统的量子动力学生成复杂特征，在分子毒性分类和图像识别等任务中超越经典方法。


<details>
  <summary>Details</summary>
Motivation: 传统经典方法难以捕捉数据中的高阶统计依赖关系，需要开发能够利用量子系统特性的特征提取技术来提升机器学习性能。

Method: 将经典特征向量嵌入到自旋玻璃哈密顿量中，通过量子动力学演化在IBM量子处理器上生成高阶可观测量的期望值，映射到高维特征空间。

Result: 在分子毒性分类和图像识别等真实数据集上，量子提取的特征能够补充并在许多情况下超越经典特征，提供一致的性能提升。

Conclusion: 量子与经典特征提取的结合能够在多种机器学习任务中提供可靠改进，表明近期量子设备在数据驱动应用中已具备早期实用价值。

Abstract: We introduce a Hamiltonian-based quantum feature extraction method that
generates complex features via the dynamics of $k$-local many-body spins
Hamiltonians, enhancing machine learning performance. Classical feature vectors
are embedded into spin-glass Hamiltonians, where both single-variable
contributions and higher-order correlations are represented through many-body
interactions. By evolving the system under suitable quantum dynamics on IBM
digital quantum processors with 156 qubits, the data are mapped into a
higher-dimensional feature space via expectation values of low- and
higher-order observables. This allows us to capture statistical dependencies
that are difficult to access with standard classical methods. We assess the
approach on high-dimensional, real-world datasets, including molecular toxicity
classification and image recognition, and analyze feature importance to show
that quantum-extracted features complement and, in many cases, surpass
classical ones. The results suggest that combining quantum and classical
feature extraction can provide consistent improvements across diverse machine
learning tasks, indicating a reliable level of early quantum usefulness for
near-term quantum devices in data-driven applications.

</details>
