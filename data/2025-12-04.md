<div id=toc></div>

# Table of Contents

- [gr-qc](#gr-qc) [Total: 18]
- [quant-ph](#quant-ph) [Total: 46]
- [cs.LG](#cs.LG) [Total: 101]
- [physics.comp-ph](#physics.comp-ph) [Total: 5]


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [1] [Tau--Function Multilinear Hierarchy of the Tomimatsu--Sato Spacetime: A Gravitational Realization of the YTSF Integrable Structure](https://arxiv.org/abs/2512.03104)
*Takeshi Fukuyama*

Main category: gr-qc

TL;DR: 论文发现Tomimatsu-Sato黑洞族隐藏着可积结构，其Ernst势可分解为立方部分（包含所有二阶导数）和四次梯度包络，立方部分可用Z3对称三线性Hirota算子表示，揭示了引力场中的多线性τ函数层次结构。


<details>
  <summary>Details</summary>
Motivation: Tomimatsu-Sato黑洞族长期以来被认为代数复杂且缺乏明确的可积性。作者旨在揭示这一引力解族背后隐藏的可积结构，探索其与可积系统理论的内在联系。

Method: 将平稳轴对称真空爱因斯坦方程的Ernst势表示为τ比值形式，将其分子分解为包含所有二阶导数的立方部分和四次梯度包络。立方部分用Z3对称三线性Hirota算子表示，并与Yu-Toda-Sasa-Fukuyama方程核进行比较验证。

Result: 对于δ=2的Tomimatsu-Sato解，验证了其立方部分与YTSF方程核一致，表明TS几何是平稳轴对称广义相对论中多线性τ函数层次结构的引力实现。

Conclusion: Tomimatsu-Sato黑洞族实际上具有隐藏的可积结构，是引力场中多线性τ函数层次的具体体现，为理解复杂引力解与可积系统理论的关系提供了新视角。

Abstract: The Tomimatsu--Sato (TS) family generalizes the Kerr black hole to higher multipole order $δ$ and has long been regarded as algebraically complicated without any clear integrability. We show instead that stationary axisymmetric vacuum Einstein equations, when the Ernst potential is written as a $τ$--ratio $\mathcal{E}=τ_1/τ_0$, admit a universal decomposition of the Ernst numerator into a cubic part containing all second derivatives and a quartic \emph{gradient envelope}. The cubic sector can be written in terms of $Z_3$--symmetric trilinear Hirota operators, revealing a hidden integrable structure. For $δ=2$, using the explicit Tomimatsu--Sato polynomials, we verify that this trilinear sector coincides with a Yu--Toda--Sasa--Fukuyama (YTSF) equation-type kernel. Thus the TS geometry forms a gravitational realization of a multilinear $τ$--function hierarchy in stationary axisymmetric general relativity.

</details>


### [2] [Probing for primordial black hole candidates in exoplanet search data](https://arxiv.org/abs/2512.03118)
*Paul Halpern,Erik Cauley,Max Stoltzmann,Mauritz Wilshusen*

Main category: gr-qc

TL;DR: 该研究通过分析径向速度和微引力透镜数据，寻找可能被误认为系外行星的原初黑洞候选体，筛选出多个潜在PBH目标。


<details>
  <summary>Details</summary>
Motivation: 原初黑洞是早期宇宙能量涨落的假设产物，其质量范围与行星相似，如果被恒星捕获，可能通过径向速度法或微引力透镜被探测到，但可能被误认为系外行星。

Method: 通过筛选已探测到的系外行星数据，排除那些通过直接成像或凌星法发现的目标（这些具有行星尺寸特征），专注于仅通过径向速度法发现但从未被成像的目标，以及特定的微引力透镜事件。

Result: 识别出多个潜在PBH候选体：Kepler-21 Ac、HD 219134 f、Gliese 686 b、HR 5183 b、HD 20794 e、Wolf 1061 d（径向速度法发现），以及微引力透镜事件MOA 2009-BLG-387L和OGLE-2016-BLG-1540。

Conclusion: 这些天体代表了一组潜在的原初黑洞候选体，未来通过直接成像区分行星尺寸特征与蒸发特征，可能确认哪些是真正的系外行星，哪些是原初黑洞。

Abstract: We have sifted through astrophysical data collected by various radial velocity and gravitational microlensing searches for exoplanets with the goal of identifying potential signs of the presence of primordial black holes (PBH). Our motivation is that those hypothesized remnants of inhomogeneous energetic fluctuations in the early universe, though too small for direct detection, are thought to have a mass range similar to that of planets. Thereby, if captured by stars, they could conceivably make their presence known through stellar wobbles picked up by means of Doppler spectroscopy in the radial velocity method, or alternatively through microlensing. In our analysis of such data, we have identified potential PBH contenders by ruling out any exoplanet candidates that have been detected through direct imaging or transit methods, as they would have sizes consistent with planets rather than PBHs. In particular we focus on the objects Kepler-21 Ac, HD 219134 f, Gliese 686 b, HR 5183 b, HD 20794 e, and Wolf 1061 d, each of which has been found using the radial velocity method but never imaged (either directly or through transit). We also examine the microlensing events MOA 2009-BLG-387L and OGLE-2016-BLG-1540, which offer promise as candidate PBHs. We present these as a representative, but not exclusive list, of potential PBH contenders. Furthermore, future imaging, especially focused on signals of planetary dimensions versus evaporation signatures, might clarify which of these are indeed exoplanets.

</details>


### [3] [Inferring black hole formation channels in GWTC-4.0 via parametric mass-spin correlations derived from first principles](https://arxiv.org/abs/2512.03152)
*Emanuele Berti,Francesco Crescimbeni,Gabriele Franciolini,Simone Mastrogiovanni,Paolo Pani,Grégoire Pierra*

Main category: gr-qc

TL;DR: 研究比较了不同双黑洞形成机制，发现数据强烈支持质量与自旋大小正相关，分层形成机制（包含第二代合并）能更好解释观测，而原始黑洞模型与数据拟合较差。


<details>
  <summary>Details</summary>
Motivation: 研究动机是区分双黑洞的不同形成机制（孤立恒星演化、致密星团和活动星系核盘中的动力学组装、原始黑洞），通过分析引力波观测数据中的自旋特征来理解双黑洞的形成过程。

Method: 利用每种形成通道预测的自旋特征，建立质量与自旋大小（及方向）的参数化相关模型，基于第一性原理。使用分层贝叶斯推断方法分析GWTC-4.0数据集，比较所有模型并评估每种场景对数据的解释能力。

Result: 数据强烈支持质量与自旋大小存在正相关；分层形成机制（包含第二代合并导致更大质量时更高自旋）能更好拟合观测数据；当前数据对自旋方向信息不足，星团（随机方向）和活动星系核（对齐方向）场景的贝叶斯证据相当；原始黑洞场景预测的质量-自旋相关性与数据拟合较差，只能解释部分观测事件。

Conclusion: 双黑洞形成机制中，质量与自旋大小的正相关关系得到数据支持，分层形成机制（包含第二代合并）能更好解释观测特征，而原始黑洞模型在解释观测数据方面存在困难，需要进一步的数据来区分自旋方向特征。

Abstract: We investigate the differences between several proposed formation scenarios for binary black holes (BBHs), including isolated stellar evolution, dynamical assembly in dense clusters and AGN disks, and primordial BHs. Our approach exploits the predicted spin features of each formation channel, and adopts parameterized models of the predicted correlations between the spin magnitudes (and orientations) and mass, inspired by first principles. Using hierarchical Bayesian inference on the recent GWTC-4.0 dataset, we compare these features across all models and assess how well each scenario explains the data. We find that the data strongly favor the presence of a positive correlation between mass and spin magnitude, in agreement with previous studies. Furthermore, the hierarchical scenario provides a better fit to the observations, due to the inclusion of second-generation mergers leading to higher spins at larger masses. The current dataset is not informative enough about spin orientation: the cluster (random orientations) and AGN (aligned orientations) scenarios have comparable Bayesian evidence. Finally, the mass-spin correlation predicted by the primordial scenario gives a poor fit to the data, and this scenario can only account for a subset of the observed events.

</details>


### [4] [From scalar clouds around evaporating black holes to boson star](https://arxiv.org/abs/2512.03155)
*Daniel Neves,João G. Rosa*

Main category: gr-qc

TL;DR: 首次研究蒸发黑洞束缚标量云的演化，发现当黑洞质量降至云质量一半以下时，标量云可（部分）存活为自引力玻色星，为玻色星形成提供新机制


<details>
  <summary>Details</summary>
Motivation: 研究蒸发黑洞束缚标量云的演化，探索玻色星形成的新机制，特别是轻原初黑洞产生的玻色暗物质可能形成微玻色星

Method: 模拟非相对论性球对称标量云相关的薛定谔-泊松系统，研究黑洞蒸发过程中标量云的演化

Result: 当黑洞蒸发到质量小于标量云质量一半时，标量云可（部分）存活为自引力玻色星；轻原初黑洞产生的玻色暗物质可能形成具有极大占据数的微玻色星

Conclusion: 为玻色星形成提供了新机制，表明玻色暗物质通过轻原初黑洞产生可能形成微玻色星，极大增强了即使非常弱相互作用暗物质粒子的可探测性

Abstract: We study, for the first time, the evolution of a scalar cloud bound to an evaporating black hole. Our simulations of the associated Schrödinger-Poisson system for non-relativistic and spherically symmetric clouds reveal that a scalar cloud may (partially) survive as a self-gravitating boson star if the black hole evaporates adiabatically until its mass becomes less than one half of the cloud's mass. This yields a novel mechanism for boson star formation and shows that, as previously conjectured, bosonic dark matter production by light primordial black holes may result in micro-boson stars with very large occupation numbers, greatly enhancing their potential detectability even for very weakly interacting dark matter particles.

</details>


### [5] [Many Worlds in Theory Space: A Quantum Origin for the Constants of Nature](https://arxiv.org/abs/2512.03251)
*Edward J Shaya*

Main category: gr-qc

TL;DR: 该论文提出宇宙常数源于量子力学本身，通过扩展量子宇宙学的构型空间，将自然常数视为宇宙波函数的一部分，早期宇宙过程使不同常数可能性退相干为不同的经典宇宙分支。


<details>
  <summary>Details</summary>
Motivation: 探索物理学基本常数（如电磁强度和基本粒子质量）为何恰好处于允许恒星、行星和化学存在的精确范围内，这是科学中最深刻的问题之一。

Method: 扩展量子宇宙学的构型空间，将自然常数纳入宇宙波函数；定义"大希尔伯特空间"作为不同物理定律集合的直和；推导控制理论参数动力学的"元Wheeler-DeWitt方程"；提出理论空间的总积分振幅作为贝叶斯证据度量。

Result: 在普朗克时代，理论参数的动力学项活跃，创造了原始相干态，使物理定律有效波动；宇宙波函数包含许多可能的常数集合，早期宇宙过程使这些可能性退相干为不同的经典宇宙分支；我们的宇宙是其中一个与复杂性和生命兼容的分支。

Conclusion: 该形式主义为高能物理提供了定量工具；提出了一个具体的、可证伪的预测：永远不会有一个纯粹数学推导的标准模型参数；理论空间的总积分振幅可作为比较不同微观理论的贝叶斯证据度量。

Abstract: Many of the numbers appearing in the laws of physics, such as the strength of electromagnetism or the masses of elementary particles, must lie in precise ranges for stars, planets, and chemistry to exist. Why the universe has such these values is one of the deepest questions in science. Here we propose that these constants arise from quantum mechanics itself. By enlarging the configuration space of quantum cosmology, we treat the constants of nature as part of the wavefunction of the universe. The universal wavefunction contains support for many possible sets of constants, and early-universe processes cause these possibilities to decohere into distinct classical universes. Our universe is one such branch, compatible with complexity and life. We defined the Grand Hilbert Space as the direct sum of U-sectors, each representing a distinct set of physical laws. We derived the Meta-Wheeler--DeWitt equation, which governs the dynamics of the theory parameters. We showed that in the Planck era, the kinetic terms for these parameters are active, creating a state of primordial coherence where the laws of physics effectively fluctuate. This formalism offers a quantitative tool for high-energy physics. We proposed that the total integrated amplitude over theory space serves as a Bayesian evidence metric, allowing for the statistical comparison of rival microscopic theories based on their fertility in generating habitable sectors. Finally, this work makes a specific, falsifiable prediction: there will never be a successful, purely mathematical derivation of the Standard Model parameters.

</details>


### [6] [Constraints on Reversing the Thermodynamic Arrow of Time from Black Hole Thermodynamics, Wormholes, and Time-Symmetric Quantum Mechanics](https://arxiv.org/abs/2512.03380)
*Kevin Song,John Zhang*

Main category: gr-qc

TL;DR: 该论文探讨在单一宇宙中能否逆转热力学时间箭头，通过分析黑洞蒸发、虫洞和双时间边界值框架，得出结论：在当前半经典、全息和统计力学约束下，这些机制只能重新分配熵，无法真正逆转宇宙的热力学时间箭头。


<details>
  <summary>Details</summary>
Motivation: 研究在单一连通时空中，不引入额外宇宙或分支的情况下，是否可能通过黑洞、可穿越虫洞或时间对称/逆因果量子力学来暂时逆转热力学时间箭头。

Method: 区分精细、粗粒化和广义引力熵，建立宇宙学粗粒化熵概念，分析黑洞蒸发、受量子能量不等式约束的虫洞以及双时间边界值框架，引入"全局熵传输"(GET)框架并推导扇区不等式。

Result: 黑洞、虫洞和逆因果协议最多只能在物质、辐射和引力扇区之间重新分配熵，并重塑局部熵产生模式，但无法在单一连通宇宙中真正逆转热力学时间箭头。

Conclusion: 在当前半经典、全息和统计力学约束下，单一连通宇宙中的热力学时间箭头无法被逆转，黑洞、虫洞和逆因果量子力学只能重新分配熵而不能真正减少总熵。

Abstract: Can the thermodynamic arrow of time in a single universe be reversed, even temporarily, within semiclassical gravity without invoking additional universes or branches? We address this question in a single, connected spacetime where quantum field theory is coupled to classical general relativity, and where black holes, traversable wormholes, and time-symmetric or retrocausal formulations of quantum mechanics might naively appear to open channels for entropy export or cancellation. After distinguishing fine-grained, coarse-grained, and generalized gravitational entropy, and formulating a cosmological coarse-grained entropy, we treat black hole evaporation, wormholes constrained by quantum energy inequalities, and two-time boundary-value frameworks (including absorber-type and two-state-vector formalisms) within a common information-theoretic language. We then introduce a "Global Entropy Transport" (GET) framework and derive a sectoral inequality that bounds the net decrease of matter-plus-radiation entropy in terms of changes in horizon area and correlation (mutual-information) terms, assuming the generalized second law and modern focusing and energy conditions. Within this framework, black holes, wormholes, and retrocausal protocols can at most redistribute entropy among matter, radiation, and gravitational sectors and reshape the local pattern of entropy production. They do not, under current semiclassical, holographic, and statistical-mechanical constraints, permit a genuine reversal of the universal thermodynamic arrow in a single connected universe.

</details>


### [7] [Motion of a charged test particle around a static black hole in a monopole magnetic field](https://arxiv.org/abs/2512.03484)
*Ken-ichi Nakao,Yota Endo,Hideki Ishihara,Kenta Matsuo,Kensuke Sueto,Koudai Ueda,Hirotaka Yoshino*

Main category: gr-qc

TL;DR: 带电测试粒子在具有单极磁场的球对称黑洞时空中的运动：径向运动不受磁场影响，但切向运动被限制在薄锥面上，导致等离子体团块可能在黑洞上方悬浮并变得非常热。


<details>
  <summary>Details</summary>
Motivation: 研究带电测试粒子在具有单极磁场的球对称黑洞时空中的运动特性，探索磁场如何影响粒子轨迹以及这对黑洞周围等离子体行为的影响。

Method: 分析带电测试粒子在具有单极磁场的球对称黑洞时空中的运动方程，特别关注径向和切向运动的差异，并考虑粒子服从麦克斯韦速度分布的情况。

Result: 1. 径向运动方程与无磁场情况完全相同；2. 黑洞会被质子-电子等离子体充电；3. 切向运动中，带电粒子轨迹被限制在非常薄的锥面上（磁场约10高斯）；4. 等离子体团块可能在黑洞上方悬浮并变得非常热。

Conclusion: 单极磁场对带电粒子的径向运动无影响，但会强烈限制切向运动，导致粒子轨迹被约束在薄锥面上，这可能解释黑洞周围等离子体团块的悬浮和加热现象。

Abstract: We study the motion of a charged test particle in the spacetime with a spherically symmetric black hole which is immersed in a monopole magnetic field. We show that the radial motion of the charged test particle is governed by completely the same equation as that in the case of no magnetic field. This result implies that the black hole will acquire the electric charge if it is surrounded by the collisionless plasma composed of protons and electrons which obey the Maxwell velocity distribution. The drastically different situation appears in the tangential motions of charged test particles due to the magnetic field. The trajectory of a charged test particle in the black hole with the magnetic field of the order of 10 Gauss near the black hole, is confined on a very thin cone as long as the specific angular momentum of the particle is not much larger than the gravitational radius of the black hole times the speed of light. This result leads to a possibility that a plasma lump can hover over the black hole and is very hot, in the monopole magnetic field.

</details>


### [8] [Multi-probe analysis of strong-field effects in $f(Q)$ gravity](https://arxiv.org/abs/2512.03529)
*Mohsen Khodadi,Behnam Pourhassan,Emmanuel N. Saridakis*

Main category: gr-qc

TL;DR: 本文通过黑洞阴影、EHT观测、S2星进动和强引力透镜等强场测试，对协变f(Q)引力理论的两个解分支进行了约束，发现Case II分支会产生可观测的修正，并获得了迄今最严格的强场约束。


<details>
  <summary>Details</summary>
Motivation: 协变f(Q)引力是广义相对论的一个可行扩展，但其强场预测尚未得到充分测试。本文旨在利用最严格的强场探针来检验该理论，填补这一空白。

Method: 使用理论的静态球对称黑洞解，通过黑洞阴影（EHT对M87*和Sgr A*的测量）、S2星进动和强引力透镜系数等观测数据进行对比分析。

Result: 两个解分支表现迥异：Case I与史瓦西解偏差可忽略；Case II对光子球和阴影大小产生显著、可能可观测的修正。从EHT数据获得了严格约束，强透镜系数进一步强化了这些约束。

Conclusion: 这些结果为协变f(Q)引力提供了迄今最严格的强场约束，并指出了利用下一代视界尺度成像和银河系中心精密天体测量进行未来测试的方向。

Abstract: Covariant $f(Q)$ gravity is a viable extension of General Relativity, however its strong-field predictions remain largely untested. Using the static, spherically symmetric black-hole solutions of the theory, we confront it with the most stringent probes available: black-hole shadows, Event Horizon Telescope (EHT) measurements, S2-star precession, and strong gravitational lensing. We show that the two admissible solution branches behave very differently: Case~I produces negligible deviations from Schwarzschild solution, whereas Case~II yields significant, potentially observable corrections to the photon sphere and shadow size. From the EHT shadow diameters of M87* and Sgr~A*, we obtain tight bounds, which are further strengthened by strong-lensing coefficients. These results provide the sharpest strong-field constraints on covariant $f(Q)$ gravity to date, and point toward future tests using next-generation horizon-scale imaging and precision Galactic-center astrometry.

</details>


### [9] [Feeding a Kerr black hole with quantized vortices](https://arxiv.org/abs/2512.03561)
*Shilong Jin,Xiaofei Zhao,Yong Zhang,Chi Xiong*

Main category: gr-qc

TL;DR: 通过求解克尔几何中的非线性克莱因-戈登方程，发现克尔黑洞附近量子流体中量子化涡旋的新现象，这些涡旋可作为研究黑洞物理的新探针。


<details>
  <summary>Details</summary>
Motivation: 研究克尔黑洞附近量子流体（如轴子凝聚、超轻玻色子云等标量场）中的量子化涡旋，以探索黑洞物理的新探测手段并修正相关暗物质模型。

Method: 在克尔几何中求解非线性克莱因-戈登方程，分析量子流体中量子化涡旋的形成、轨道运动、吸积过程以及湍流演化。

Result: 发现量子化涡旋可稳定绕黑洞轨道运行，其角速度可定量表征参考系拖曳效应；大涡旋会被黑洞吸积并发生分裂重组；高涡旋密度下产生湍流并在事件视界附近形成涡旋边界层；在能层外观测到涡旋发射和能量爆发。

Conclusion: 量子化涡旋作为宏观量子拓扑缺陷，可作为研究黑洞物理的新型探针，其观测特征（如涡旋发射和能量爆发）可能为XRISM卫星发现的类似天体物理事件提供关键见解。

Abstract: By solving a nonlinear Klein-Gordon equation in Kerr geometry, we uncover new phenomena and key characteristics of quantized vortices in quantum fluids near a Kerr black hole. The formation of these vortices induces rotational or turbulent flows, which profoundly alter the fluid properties and revise those dark matter models describing axion condensates, ultralight boson clouds, and other scalar fields in the vicinity of spinning black holes. As macroscopic, quantum, and topological defects, these vortices can stably orbit the black hole over extended periods, establishing their viability as novel probes for investigating black hole physics. For instance, we calculate the angular velocities of orbiting vortices to quantitatively characterize the frame-dragging effect, a classic prediction of general relativity. Additionally, we observe that relatively large vortices are accreted onto the black hole, wrapping around it while undergoing splitting and reconnecting processes. In quantum fluids with high vortex densities, turbulent flows emerge, accompanied by the formation of a vortex boundary layer near the event horizon. Beyond the ergosphere, we find vortex emissions and energetic outbursts, which may provide crucial insights into analogous astrophysical events recently discovered by the XRISM satellite.

</details>


### [10] [Gauge Symmetries, Contact Reduction, and Singular Field Theories](https://arxiv.org/abs/2512.03645)
*Callum Bell,David Sloan*

Main category: gr-qc

TL;DR: 该论文将尺度不变动力系统的约简理论扩展到由奇异拉格朗日描述的物理模型，包括粒子和场论，并应用于广义相对论等物理实例。


<details>
  <summary>Details</summary>
Motivation: 经典粒子理论和场论中尺度不变动力系统的约简已有成熟理论，但需要将其扩展到由奇异拉格朗日描述的物理模型，包括广义相对论等物理理论。

Method: 基于协变Hamilton-De Donder-Weyl形式体系，将拉格朗日密度作为预多重辛速度相空间上的丛态射引入，处理奇异拉格朗日描述的经典场论。

Result: 成功将尺度约简形式体系扩展到奇异拉格朗日系统，得到动态等效但具有摩擦性质的理论，并将结果应用于多个物理实例。

Conclusion: 该工作为处理奇异拉格朗日系统的尺度不变性提供了统一框架，对经典广义相对论等理论有重要启示意义。

Abstract: The reduction of dynamical systems which are invariant under changes of global scale is well-understood, for classical theories of particles, and fields. The excision of the superfluous degree of freedom describing such a scale leads to a dynamically-equivalent theory, which is frictional in nature. In this article, we extend the formalism to physical models, of both particles and fields, described by singular Lagrangians. Our treatment of classical field theory is based on the manifestly covariant Hamilton De-Donder Weyl formalism, in which the Lagrangian density is introduced as a bundle morphism on the pre-multisymplectic velocity phase space $J^1E$. The results obtained are subsequently applied to a number of physically-motivated examples, as well as a discussion presented on the implications of our work for classical General Relativity.

</details>


### [11] [Spherical accretion onto higher-dimensional Reissner-Nordström Black Hole](https://arxiv.org/abs/2512.03668)
*Bibhash Das,Anirban Chanda,Bikash Chandra Paul*

Main category: gr-qc

TL;DR: 该论文研究了高维Reissner-Nordström黑洞中球对称吸积的相对论解，分析了各向同性流体和非线性多方流体的临界点行为，发现临界半径随时空维度变化呈现先减后增的趋势。


<details>
  <summary>Details</summary>
Motivation: 研究高维Reissner-Nordström黑洞中流体吸积的动力学行为，探索时空维度、黑洞电荷和流体类型对吸积过程的影响，特别是临界点和质量吸积率的变化规律。

Method: 采用广义哈密顿量方法对高维RN黑洞进行动力学分析，考虑各向同性流体和非线性多方流体两种流体模型，在哈密顿形式框架下研究不同时空维度中的流动动力学。

Result: 各向同性流体同时存在跨声速和非跨声速流动，而多方流体仅表现出非跨声速流动；临界半径随维度增加先减小后增大；高维Schwarzschild黑洞的质量吸积率最低，随电荷参数增加而增加。

Conclusion: 高维RN黑洞的吸积行为受时空维度、黑洞电荷和流体类型的显著影响，临界点位置和质量吸积率随这些参数变化呈现复杂但可预测的模式，为理解高维黑洞吸积过程提供了理论框架。

Abstract: We obtain relativistic solutions of spherically symmetric accretion by a dynamical analysis of a generalised Hamiltonian for higher-dimensional Reissner-Nordström (RN) Black Hole (BH). We consider two different fluids namely, an isotropic fluid and a non-linear polytropic fluid to analyse the critical points in a higher-dimensional RN BH. The flow dynamics of the fluids are studied in different spacetime dimensions in the framework of Hamiltonian formalism. The isotropic fluid is found to have both transonic and non-transonic flow behaviour, but in the case of polytropic fluid, the flow behaviour is found to exhibit only non-transonic flow, determined by a critical point that is related to the local sound speed. The critical radius is found to change with the spacetime dimensions. Starting from the usual four dimensions it is noted that as the dimension increases the critical radius decreases, attains a minimum at a specific dimension ($D>4$) and thereafter increases again. The mass accretion rate for isotropic fluid is determined using Hamiltonian formalism. The maximum mass accretion rate for RN BH with different equations of state parameters is studied in addition to spacetime dimensions. The flow behaviour and mass accretion rate for a change in BH charge is also studied analytically. It is noted that the maximum mass accretion rate in a higher-dimensional Schwarzschild BH is the lowest, which however, increases with the increase in charge parameter in a higher-dimensional RN BH.

</details>


### [12] [A theory-agnostic hierarchical Bayesian framework for black-hole spectroscopy: a case study on GW250114 in Einstein-dilaton-Gauss-Bonnet gravity](https://arxiv.org/abs/2512.03713)
*Shitong Guo,Yan-Gang Miao*

Main category: gr-qc

TL;DR: 提出了一种理论无关的层次贝叶斯框架，用于通过准正规模谱直接比较引力波环降观测与理论预测，避免传统波形匹配方法的模型依赖性。


<details>
  <summary>Details</summary>
Motivation: 当前修改引力理论测试通常通过搜索广义相对论波形的微扰修正来实现，但这种方法可能引入模型依赖的系统误差，且难以适用于更广泛的引力理论类别。

Method: 开发理论无关的层次贝叶斯框架，将环降观测（建模为阻尼正弦波）直接与理论准正规模谱连接，在谱层面进行比较而非理论特定的波形匹配。框架包含软截断模块处理理论参数空间有限有效域，并配备定量诊断识别稳定分析时间窗口。

Result: 在爱因斯坦-膨胀子-高斯-博内引力中应用该框架分析GW250114事件，发现无量纲耦合参数ζ的后验分布对先验假设稳健，但在考虑范围内信息较弱。控制注入研究确认非零耦合可被恢复，同时发现基于Kerr先验的ζ推断可能部分吸收替代引力理论中的谱偏差。

Conclusion: 该工作为未来强场引力测试建立了透明且可扩展的基础，自然兼容下一代引力波探测器日益增长的精度和模式分辨率。

Abstract: Black-hole spectroscopy has emerged as a powerful probe of strong-field gravity in the era of gravitational-wave astronomy. In this context, many current tests of modified or extended gravity are implemented by searching for predicted signatures modeled as perturbative corrections to general-relativistic waveforms; however, this approach may introduce model-dependent systematics and limit applicability to broader classes of theories. To complement such methods, we develop a theory-agnostic hierarchical Bayesian framework that connects ringdown observations -- modeled as damped sinusoids -- directly with theoretical quasinormal mode spectra, performing the comparison at the spectral level rather than through theory-specific waveform matching. The framework incorporates a soft-truncation module to account for the finite domain of validity in the theory's parameter space and is equipped with quantitative diagnostics that identify stable analysis time windows. As an illustrative application, we implement the framework within Einstein-dilaton-Gauss-Bonnet gravity and apply it to the gravitational-wave event GW250114, finding that the resulting posterior for the dimensionless coupling $ζ$ is robust against prior assumptions yet remains only weakly informative over the range considered in this work. We further perform controlled ringdown injection studies across different values of $ζ$, confirming that nonzero couplings can be recovered while also indicating a potential systematic effect: Kerr-based priors in the $ζ$ inference may partially absorb spectral deviations arising in alternative theories of gravity. This work establishes a transparent and extensible foundation for future strong-field gravity tests, naturally compatible with the growing precision and modal resolution of next-generation gravitational-wave detectors.

</details>


### [13] [Approximations and modifications of celestial dynamics tested on the three-body system](https://arxiv.org/abs/2512.03823)
*Søren Toxvaerd*

Main category: gr-qc

TL;DR: 该论文通过三体系统测试发现，粒子网格近似和MOND修正会破坏经典动力学的不变性，导致系统不稳定，而MOGA修正则能稳定系统。


<details>
  <summary>Details</summary>
Motivation: 研究大规模天体系统模拟中常用的近似方法（粒子网格PM）和动力学修正（MOND）是否保持经典动力学的基本不变性，以及这些方法对系统稳定性的影响。

Method: 使用简单的三体系统作为测试平台，在计算机上实现并模拟粒子网格近似、MOND修正和MOGA修正，比较它们对系统稳定性的影响。

Result: PM近似和MOND修正破坏了经典动力学的不变性，不精确保持动量和角动量守恒，PM还不满足牛顿第三定律，导致三体系统不稳定；而MOGA修正（用反比引力替代远距离相互作用的平方反比引力）能稳定系统。

Conclusion: 虽然PM近似和MOND修正的误差很小，但它们破坏了经典动力学的基本不变性，导致规则动力学的不稳定性，而MOGA修正提供了更稳定的替代方案。

Abstract: Large-scale simulations of celestial systems are based on approximations or modifications of classical dynamics. The approximations are with ``particle-mesh'' (PM) substitutions of the attractions from objects far away, or one modify the Newtonian accelerations (MOND) or the gravities (MOGA). The PM approximation and MOND modification of classical dynamics break the invariances of classical dynamics. The simple three-body system (TBS) is the simplest system to test the approximations and modifications of celestial dynamics, and it is easy to implement on a computer. Simulations of the TBS show that the PM approximation and MOND destabilize TBS. In contrast, the MOGA modification of gravity by replacing Newton's inverse square attraction with an inverse attraction for far-away interactions stabilizes the system. The PM approximation and the MOND modification of classical dynamics do not preserve the momentum and angular momentum of a conservative system exactly, and PM does not obey Newton's third law. Although the errors and shortcomings of these PM approximations and MOND modifications are small, they cause the instability of the regular dynamics.

</details>


### [14] [Some perspective of thermodynamical and optical properties of black holes in Maxwell-dilaton-dRGT-like massive gravity](https://arxiv.org/abs/2512.03832)
*B. Eslam Panah. N. Heidari,M. Soleimani*

Main category: gr-qc

TL;DR: 该研究将膨胀子场（UV修正）与类dRGT大质量引力（IR修正）整合到爱因斯坦引力中，分析了该引力框架下黑洞的热力学和光学性质。


<details>
  <summary>Details</summary>
Motivation: 将膨胀子场（作为紫外修正）和类dRGT大质量引力（作为红外修正）整合到爱因斯坦引力中，研究这种复合引力框架下黑洞的性质。

Method: 首先回顾Maxwell-膨胀子-类dRGT大质量引力中的黑洞解，分析参数对时空渐近行为和事件视界的影响；然后研究黑洞的守恒量和热力学量，通过热容和温度评估局部稳定性；使用几何热力学方法研究相变；最后分析参数对黑洞光学特性和辐射行为的影响。

Result: 参数β、α、大质量参数η₁和η₂显著影响黑洞的局部稳定性；膨胀子耦合常数α、电荷q、大质量引力参数η₁和引力子质量m_g影响光子球半径和黑洞阴影；理论阴影半径与Sgr A*观测数据比较；这些参数还显著影响能量发射率的峰值。

Conclusion: Maxwell-膨胀子-类dRGT大质量引力框架中的参数对黑洞的热力学稳定性和光学特性都有重要影响，为理解复合引力修正下的黑洞物理提供了新见解。

Abstract: Motivated by integrating the dilaton field (as a UV correction) with dRGT-like massive gravity (as an IR correction) into Einstein gravity, we investigate the thermodynamic and optical properties of black holes within this gravitational framework. We begin by reviewing the black hole solutions in Maxwell-dilaton-dRGT-like massive gravity, followed by an analysis of how various parameters influence on the asymptotical behavior of the spacetime and the event horizon of these black holes. In the subsequent section, we examine the conserved and thermodynamic quantities associated with these black holes, paying particular attention to the effects of parameters like $β$, $α$, and the massive parameters ($η_{1}$ and $η_{2}$) on their local stability by simultaneously evaluating the heat capacity and temperature. We also adopt an alternative method to study phase transitions using geometrothermodynamics. Furthermore, we explore how the parameters of Maxwell-dilaton-dRGT-like massive gravity impacts the optical characteristics and radiative behavior of black holes. In particular, we analyze the effects of the dilaton coupling constant ($α$), charge ($q$), the massive gravity parameter ($η_1$), and the graviton mass ($m_g$) on the radius of the photon sphere and the resulting black hole shadow. Moreover, the theoretical shadow radius is compared to the observational data from $Sgr A^*$. Additionally, we investigate the energy emission rate of these black holes, revealing that these parameters substantially influence the emission peak.

</details>


### [15] [Fractional Holographic Dark Energy Driven Reconstruction of $f(Q)$ Gravity and its Cosmological Implications](https://arxiv.org/abs/2512.03855)
*Rajdeep Mazumdar,Kalyan Malakar,Kalyan Bhuyan*

Main category: gr-qc

TL;DR: 基于分数全息暗能量重建的f(Q)引力理论，能解释宇宙晚期加速膨胀，与观测数据高度一致，是ΛCDM的稳定替代方案。


<details>
  <summary>Details</summary>
Motivation: 为了解释宇宙晚期加速膨胀现象，作者提出一种几何驱动的暗能量模型，作为ΛCDM模型的替代方案。该模型将分数全息暗能量与哈勃视界作为红外截断相结合，在对称远平行框架下构建f(Q)引力理论。

Method: 通过将分数全息暗能量与哈勃视界红外截断相结合，重建f(Q)引力理论。使用最新的DESI BAO数据、先前BAO汇编(P-BAO)和宇宙计时器(CC)数据集，通过马尔可夫链蒙特卡洛(MCMC)分析约束模型参数。进行动力学诊断、能量条件分析和线性均匀扰动分析来验证模型稳定性。

Result: 重建的哈勃参数H(z)与观测数据高度一致(R²高，χ²_min、AIC、BIC低)。当前减速参数q(0)∈[-0.40,-0.32]，转变红移z_tr∼0.56-0.72，显示从减速到加速的平滑转变。Om(z)诊断显示负斜率，表明模型不是ΛCDM，有效状态参数ω_eff(z)保持在精质区域(-1<ω_eff<-1/3)。WEC、DEC、NEC能量条件在整个宇宙演化中满足，SEC在低红移处违反，与晚期加速一致。线性扰动分析确认模型动力学稳定性。

Conclusion: 基于分数全息暗能量重建的f(Q)引力理论提供了一个稳定、观测兼容且几何驱动的ΛCDM替代方案，成功在对称远平行框架下描述了宇宙晚期加速膨胀。

Abstract: In order to explain the late-time acceleration of the Universe, we present a reconstructed version of the $f(Q)$ gravity theory in this work, which is inspired by the integrating the fractional holographic dark energy with the Hubble horizon as the infrared cutoff. This reconstructed $f(Q)$ gravity model shows a geometrically motivated dark energy component and naturally recovers General Relativity in the appropriate limit. The free parameters of the model are constrained using the latest DESI BAO data, previous BAO compilations (P-BAO), and cosmic chronometer (CC) datasets through a Markov Chain Monte Carlo (MCMC) analysis. The reconstructed Hubble parameter $H(z)$ exhibits excellent consistency with observational data, with high values of $R^2$ and low values of $χ^2_{\min}$, AIC, and BIC, confirming the model's strong statistical performance relative to $Λ$CDM. With current $q(0) \in [-0.40, -0.32]$ and a transition redshift $z_{\text{tr}} \sim 0.56$--$0.72$, the dynamical diagnostics show a smooth transition from a decelerated to an accelerated phase. While the $Om(z)$ diagnostic exhibits a negative slope, indicating that the model is not $Λ$CDM, the effective equation-of-state parameter $ω_{\text{eff}}(z)$ stays within the quintessence regime ($-1 < ω_{\text{eff}} < -1/3$). The analysis of classical energy conditions shows that the WEC, DEC, and NEC are satisfied throughout the cosmic evolution, with a violation of the SEC at lower-redshift, which is consistent with late-time acceleration. Linear homogeneous perturbation analysis further confirms the model's dynamical stability. Conclusively, the FHDE-inspired reconstructed $f(Q)$ gravity provides a stable, observationally compatible, and geometrically motivated alternative to $Λ$CDM, that successfully describes the late-time cosmic acceleration within the symmetric teleparallel framework.

</details>


### [16] [Shadow geometry of Kerr MOG naked singularity and analysis of accretion disk luminosity](https://arxiv.org/abs/2512.03896)
*Saira Yasmin,Mubasher Jamil*

Main category: gr-qc

TL;DR: 该研究分析了Kerr修正引力（MOG）裸奇点的阴影特性和吸积盘辐射性质，发现KMNS阴影可呈现闭合、开放甚至消失等不同形态，并具有BH阴影所没有的间隙特征。研究还表明这些观测特征可有效区分KMNS与标准Kerr裸奇点。


<details>
  <summary>Details</summary>
Motivation: 裸奇点是理论上存在的没有事件视界的引力奇异点。研究旨在探索Kerr修正引力裸奇点（KMNS）的观测特征，特别是其阴影特性和吸积盘辐射性质，以寻找区分KMNS与标准Kerr裸奇点的观测方法。

Method: 1. 分析KMNS的时空几何结构和测试粒子运动方程；2. 研究KMNS阴影随自旋参数a、修正引力参数α和观测者倾角的变化特性；3. 建立薄吸积盘简化模型，包括辐射通量、温度分布和光谱光度；4. 分析相同质量但不同自旋和MOG变形参数下吸积盘的辐射通量分布。

Result: 1. KMNS阴影可呈现闭合、开放或消失三种形态，取决于参数组合；2. 发现KMNS阴影具有间隙特征，这是黑洞阴影所没有的独特现象；3. 吸积盘辐射性质随自旋参数a和MOG参数α的变化而变化；4. 这些观测特征可作为区分KMNS与标准Kerr裸奇点（α=0）的有效工具。

Conclusion: KMNS的阴影特性和吸积盘辐射性质提供了独特的观测特征，这些特征不仅有助于区分裸奇点与黑洞，还能有效区分KMNS与标准Kerr裸奇点，为通过天文观测探测修正引力效应提供了新途径。

Abstract: Naked singularities are hypothetical astrophysical entities featuring gravitational singularities without event horizons. In this study, we analyze the shadow properties of Kerr Modified Gravity (Kerr MOG) naked singularities (KMNSs). We show that the KMNS shadow can appear closed, open, or even vanish, depending on the dimensionless spin parameter a, the modified gravity parameter alpha, and the observer's inclination angle. We identify the critical conditions under which the KMNS shadow develops a gap, a unique feature not present in BH shadows. We analyze the properties of a thin accretion disk surrounding a KMNS, within the framework of MOG characterized by the parameter alpha. The study includes a detailed examination of the spacetime geometry and the equations of motion for test particles. In addition, we adopt a simplified model for the disk's radiative flux, temperature distribution, and spectral luminosity. Our analysis primarily focuses on the flux distribution of the accretion disk around KMNS with identical mass but varying spin and MOG deformation parameters. This allows us to explore how modifications in rotation and the MOG parameter alpha influence the radiative properties of the disk. Further, these observational signatures may serve as effective tools for clearly distinguishing KMNS from standard Kerr naked singularities (KNSs), where the MOG parameter alpha = 0

</details>


### [17] [Primordial Gravitational Wave Birefringence in a de Sitter Background with Chern-Simons Coupling](https://arxiv.org/abs/2512.03919)
*Abhishek Rout,Brett Altschul*

Main category: gr-qc

TL;DR: 在Chern-Simons修正引力框架下，研究de Sitter背景中的张量扰动，发现引力波传播的宇称破坏修正，导致振幅和速度双折射效应，并在原初张量谱中留下永久性宇称破坏印记。


<details>
  <summary>Details</summary>
Motivation: 研究Chern-Simons修正引力理论中de Sitter背景下的张量扰动，探索引力波传播的宇称破坏效应，以及如何将Chern-Simons场与类轴子暗物质现象学联系起来。

Method: 引入横向无迹扰动，分析Chern-Simons Cotton张量对引力波传播的影响；使用标量背景场的模式分解，推导波方程的亚视界和超视界极限；将Chern-Simons场推广为有质量暗物质候选者。

Result: 发现张量模式色散关系中的手性修正，产生振幅和速度双折射效应；特定解显示螺旋度依赖的放大效应；左右手模式间的累积相位差在视界内呈二次增长，在视界外冻结，在原初张量谱中留下永久宇称破坏印记。

Conclusion: Chern-Simons修正引力在de Sitter背景中产生可观测的引力波双折射效应，为原初引力波探测提供宇称破坏信号，且该理论框架可与类轴子暗物质现象学自然连接。

Abstract: In this work, we investigate tensor perturbations in a de Sitter background within the framework of Chern-Simons modified gravity. We introduce transverse-traceless perturbations and analyze how the Chern-Simons Cotton tensor induces parity-violating modifications to gravitational wave propagation, while the Pontryagin density vanishes at linear order. Using a mode decomposition of the scalar background field, we derive the sub- and super-horizon limits of the wave equations and uncover chiral corrections in the dispersion relations of tensor modes. The resulting birefringence exhibits both amplitude and velocity components, alternating with the phase of the scalar field. Particular solutions sourced by the scalar background show helicity-dependent amplification and a characteristic scaling of the radiated flux that reduces smoothly to the Minkowski limit. The accumulated phase difference between right- and left-handed modes grows quadratically inside the horizon and becomes frozen outside, leaving a permanent parity-violating imprint in the primordial tensor spectrum. Finally, by promoting the Chern-Simons field to a massive dark matter candidate, we demonstrate how its mass-dependent dynamics connect gravitational birefringence to axion-like dark matter phenomenology.

</details>


### [18] [Screening of dipolar emission in two-scale Gauss-Bonnet gravity](https://arxiv.org/abs/2512.04083)
*Farid Thaalba,Leonardo Gualtieri,Thomas P. Sotiriou,Enrico Trincherini*

Main category: gr-qc

TL;DR: 论文研究了在具有立方伽利略相互作用的移位对称标量高斯-博内引力中的黑洞，该相互作用具有不同的能量尺度，显著改变了理论现象学，允许更小的黑洞并产生屏蔽机制。


<details>
  <summary>Details</summary>
Motivation: 探索在扩展的移位对称标量高斯-博内引力理论中引入立方伽利略相互作用如何改变黑洞物理，特别是如何通过能量尺度层次结构影响理论现象学，并使大高斯-博内耦合与引力波观测约束相兼容。

Method: 在移位对称标量高斯-博内引力理论中引入具有不同能量尺度的立方伽利略相互作用，构建多尺度有效场理论，分析该层次结构如何修改黑洞解，特别是研究屏蔽机制的产生及其对可观测量如标量电荷、最内稳定圆轨道及其频率的影响。

Result: 立方相互作用允许更小的黑洞存在，并在视界附近产生屏蔽机制，使大高斯-博内耦合与引力波约束一致；对于小黑洞，标量电荷、最内稳定圆轨道及其频率等可观测量受影响最大；构建的多尺度有效场理论在技术上保持自然性。

Conclusion: 引入具有不同能量尺度的立方伽利略相互作用显著改变了移位对称标量高斯-博内引力中的黑洞物理，提供了新的屏蔽机制，使大耦合常数与观测约束兼容，为在强场区域探测引力理论开辟了新途径。

Abstract: We study black holes in shift-symmetric scalar Gauss-Bonnet gravity extended by a cubic Galileon interaction with a distinct energy scale. Introducing this hierarchy profoundly modifies the theory's phenomenology. The cubic interaction allows for smaller black holes, and can generate a screening mechanism near the horizon, making large Gauss-Bonnet couplings consistent with gravitational-wave bounds. Observable quantities such as the scalar charge, the innermost stable circular orbit, and its frequency are most affected for small black holes. The resulting multi-scale effective field theory remains technically natural and offers new avenues to probe gravity in the strong-field regime.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [19] [New Identity for Cayley's First Hyperdeterminant with Applications to Symmetric Tensors and Entanglement](https://arxiv.org/abs/2512.03093)
*Isaac Dobes*

Main category: quant-ph

TL;DR: 提出了计算Cayley第一超行列式的新公式，并证明该公式可用于在多项式时间内计算对称超矩阵的超行列式，最后讨论了在玻色子量子纠缠中的应用。


<details>
  <summary>Details</summary>
Motivation: 超行列式计算在量子纠缠等领域有重要应用，但传统计算方法效率较低，特别是对于对称超矩阵。本文旨在开发更高效的计算方法。

Method: 1. 使用Levi-Civita符号给出了Cayley第一超行列式的新计算公式；2. 定义了超矩阵的消元和复制矩阵的推广形式；3. 推导了这些矩阵的显式公式（在附录中）。

Result: 1. 获得了超行列式的新计算公式；2. 证明了该公式可以在多项式时间内计算对称超矩阵的超行列式（假设边长固定）；3. 实现了对称超矩阵超行列式的快速计算。

Conclusion: 本文提出的新公式为计算对称超矩阵的超行列式提供了多项式时间算法，这一进展在量子纠缠（特别是玻色子纠缠）等领域具有重要应用价值。

Abstract: In this article, a new formula for computing Cayley's first hyperdeterminant in terms of the Levi-Civita symbol is given. It is then shown that this formula can be used to compute the hyperdeterminant of symmetric hypermatrices in polynomial time with respect to their order (assuming fixed side length). Applications to the quantum entanglement of bosons are then discussed. Additionally, in order to obtain the fast calculation of the hyperdeterminant on symmetric hypermatrices, hypermatrix generalizations of elimination and duplication matrices are defined, and explicit formulas for them are derived in the appendix of this article.

</details>


### [20] [Performance Analysis of Quantum Support Vector Classifiers and Quantum Neural Networks](https://arxiv.org/abs/2512.03094)
*Tomás Villalba-Ferreiro,Eduardo Mosqueira-Rey,Diego Alvarez-Estevez*

Main category: quant-ph

TL;DR: 量子支持向量分类器和量子神经网络在复杂分类任务中表现优于经典模型，其中QNN在高复杂度任务中表现更佳，Qiskit框架在优化和效率方面优于PennyLane


<details>
  <summary>Details</summary>
Motivation: 探索量子机器学习模型（QSVC和QNN）与经典模型在机器学习任务中的性能比较，评估量子模型在复杂问题中的潜力

Method: 在Iris和MNIST-PCA数据集上评估QSVC、QNN和经典模型，分析超参数调优（特征映射和ansatz配置）的影响，比较PennyLane和Qiskit框架

Result: 随着问题复杂度增加，量子模型表现优于经典方法；QSVC结果更一致，QNN在高复杂度任务中表现更佳；特征映射和ansatz配置显著影响模型精度；Qiskit框架在优化和效率方面优于PennyLane

Conclusion: 量子机器学习在复杂分类问题中具有潜力，Qiskit是更优的实现框架，研究为模型选择和优化策略提供了重要见解

Abstract: This study explores the performance of Quantum Support Vector Classifiers (QSVCs) and Quantum Neural Networks (QNNs) in comparison to classical models for machine learning tasks. By evaluating these models on the Iris and MNIST-PCA datasets, we find that quantum models tend to outperform classical approaches as the problem complexity increases. While QSVCs generally provide more consistent results, QNNs exhibit superior performance in higher-complexity tasks due to their increased quantum load. Additionally, we analyze the impact of hyperparameter tuning, showing that feature maps and ansatz configurations significantly influence model accuracy. We also compare the PennyLane and Qiskit frameworks, concluding that Qiskit provides better optimization and efficiency for our implementation. These findings highlight the potential of Quantum Machine Learning (QML) for complex classification problems and provide insights into model selection and optimization strategies

</details>


### [21] [QGShap: Quantum Acceleration for Faithful GNN Explanations](https://arxiv.org/abs/2512.03099)
*Haribandhu Jena,Jyotirmaya Shivottam,Subhankar Mishra*

Main category: quant-ph

TL;DR: QGShap：一种基于量子计算的GNN可解释性方法，利用振幅放大实现Shapley值计算的二次加速，保持精确性而无近似折衷。


<details>
  <summary>Details</summary>
Motivation: GNN在关键领域应用广泛，但其黑盒特性阻碍了在需要透明度和可问责场景中的部署。现有Shapley值计算方法需要评估2^n个联盟或n!个排列，计算复杂度高，而近似方法在保真度和效率之间存在折衷。

Method: 提出QGShap方法，利用量子计算的振幅放大技术，在联盟评估阶段实现二次加速，同时保持Shapley值的精确计算，避免了经典采样或代理方法的近似折衷。

Result: 在合成图数据集上的实验表明，QGShap在所有评估指标上均达到或超过经典方法，保持高保真度和解释准确性，提供可解释、稳定且结构一致的GNN解释。

Conclusion: QGShap不仅保持精确的Shapley值保真度，还提供与GNN底层图推理一致的可解释、稳定且结构一致的解释，为GNN可解释性提供了量子计算解决方案。

Abstract: Graph Neural Networks (GNNs) have become indispensable in critical domains such as drug discovery, social network analysis, and recommendation systems, yet their black-box nature hinders deployment in scenarios requiring transparency and accountability. While Shapley value-based methods offer mathematically principled explanations by quantifying each component's contribution to predictions, computing exact values requires evaluating $2^n$ coalitions (or aggregating over $n!$ permutations), which is intractable for real-world graphs. Existing approximation strategies sacrifice either fidelity or efficiency, limiting their practical utility. We introduce QGShap, a quantum computing approach that leverages amplitude amplification to achieve quadratic speedups in coalition evaluation while maintaining exact Shapley computation. Unlike classical sampling or surrogate methods, our approach provides fully faithful explanations without approximation trade-offs for tractable graph sizes. We conduct empirical evaluations on synthetic graph datasets, demonstrating that QGShap achieves consistently high fidelity and explanation accuracy, matching or exceeding the performance of classical methods across all evaluation metrics. These results collectively demonstrate that QGShap not only preserves exact Shapley faithfulness but also delivers interpretable, stable, and structurally consistent explanations that align with the underlying graph reasoning of GNNs. The implementation of QGShap is available at https://github.com/smlab-niser/qgshap.

</details>


### [22] [Sketch Tomography: Hybridizing Classical Shadow and Matrix Product State](https://arxiv.org/abs/2512.03333)
*Xun Tang,Haoxuan Chen,Yuehaw Khoo,Lexing Ying*

Main category: quant-ph

TL;DR: 提出基于经典阴影协议的量子态层析新方法Sketch Tomography，适用于矩阵乘积态，通过张量网络分解和可观测值估计高效重构密度矩阵


<details>
  <summary>Details</summary>
Motivation: 传统量子态层析方法在系统规模增大时面临指数级复杂度挑战，需要开发适用于特定量子态结构（如矩阵乘积态）的高效层析方法

Method: 基于经典阴影协议，利用矩阵乘积态的密度矩阵具有张量网络结构的特点，通过一系列可观测值估计来近似张量网络分量，从而重构整个密度矩阵

Result: 方法具有理论收敛性保证，样本复杂度随系统规模呈二次方增长；数值实验显示能准确近似量子态，在中等规模子系统可观测值估计任务中优于经典阴影协议和最大似然估计

Conclusion: Sketch Tomography为矩阵乘积态提供了一种高效、准确的量子态层析方法，在可观测值估计任务中表现出优越性能，为大规模量子系统表征提供了新工具

Abstract: We introduce Sketch Tomography, an efficient procedure for quantum state tomography based on the classical shadow protocol used for quantum observable estimations. The procedure applies to the case where the ground truth quantum state is a matrix product state (MPS). The density matrix of the ground truth state admits a tensor train ansatz as a result of the MPS assumption, and we estimate the tensor components of the ansatz through a series of observable estimations, thus outputting an approximation of the density matrix. The procedure is provably convergent with a sample complexity that scales quadratically in the system size. We conduct extensive numerical experiments to show that the procedure outputs an accurate approximation to the quantum state. For observable estimation tasks involving moderately large subsystems, we show that our procedure gives rise to a more accurate estimation than the classical shadow protocol. We also show that sketch tomography is more accurate in observable estimation than quantum states trained from the maximum likelihood estimation formulation.

</details>


### [23] [Generating redundantly encoded resource states for photonic quantum computing](https://arxiv.org/abs/2512.03131)
*Samuel J. Sheldon,Pieter Kok*

Main category: quant-ph

TL;DR: 提出一种使用单量子发射器确定性生成冗余编码光子资源态的方法，研究协议错误和光子损耗对资源态和II型光子融合的影响，为高效构建复杂纠缠光子态提供途径。


<details>
  <summary>Details</summary>
Motivation: 基于测量的量子计算需要大规模纠缠簇态作为通用资源。现有策略通过融合多个量子发射器生成的小型资源态来构建大簇态，但标准融合过程具有50%的成功概率。虽然已有方案提出通过GHZ态冗余编码来提高融合成功率，但需要确定性生成这种冗余编码的资源态。

Method: 提出一种使用单量子发射器确定性生成冗余编码光子资源态的协议。研究协议中可能出现的错误和光子损耗对生成资源态的影响，特别分析这些因素对II型光子融合操作的影响。

Result: 该协议能够确定性生成冗余编码的光子资源态，为高效构建复杂纠缠光子态提供了可行方案。通过分析错误和损耗的影响，为实际实现提供了指导。

Conclusion: 这项工作为高效构建用于光子量子计算和量子中继器的复杂纠缠光子量子比特态提供了一条途径，通过确定性生成冗余编码资源态，有望提高光子融合的成功率。

Abstract: Measurement-based quantum computing relies on the generation of large entangled cluster states that act as a universal resource on which logical circuits can be imprinted and executed through local measurements. A number of strategies for constructing sufficiently large photonic cluster states propose fusing many smaller resource states generated by a series of quantum emitters. However, the fusion process is inherently probabilistic with a 50% success probability in standard guise. A recent proposal has shown that, in the limit of low loss, the probability of achieving successful fusion may be boosted to near unity by redundantly encoding the vertices of linear graph states using Greenberger-Horne-Zeilinger states [Quantum 7, 992 (2023)]. Here we present a protocol for deterministically generating redundantly encoded photonic resource states using single quantum emitters, and study the impact of protocol errors and photonic losses on the generated resource states and type-II photonic fusion. Our work provides a route for efficiently constructing complex entangled photonic qubit states for photonic quantum computing and quantum repeaters.

</details>


### [24] [Many-body symmetry-protected zero boundary modes of synthetic photo-magnonic crystals](https://arxiv.org/abs/2512.03135)
*Alan Gardin,Emilio Cobanera,Giuseppe C. Tettamanzi*

Main category: quant-ph

TL;DR: 该论文提出了受玻色子多体对称性保护的自由玻色子拓扑理论，识别了两种一维非平凡对称类，并设计了光子-磁子晶体作为实验平台验证理论。


<details>
  <summary>Details</summary>
Motivation: 费米子的拓扑分类（"十重方式"）在物理学多个领域产生了深远影响，因此研究玻色子的类似拓扑分类同样重要。然而，由于费米子和玻色子的基本物理差异，玻色子拓扑分类面临诸多障碍。

Method: 提出了受玻色子多体对称操作（压缩变换、粒子数、玻色子时间反演）保护的自由玻色子拓扑理论。设计了光子-磁子晶体作为实验平台，通过电磁有限元建模模拟反射和传输特性。

Result: 识别了两种一维非平凡对称类，包括玻色子Kitaev链和玻色子SSH模型。通过Pfaffian不变量构建了多体对称保护拓扑光子-磁子链，并确定了边界模式的实验特征。

Conclusion: 该工作为玻色子拓扑分类提供了理论框架和实验验证平台，光子-磁子晶体模型为实验实现和观测奇异物理现象提供了详细蓝图。

Abstract: The topological classification of insulators and superconductors, the "ten-fold way", is grounded on fermionic many-body symmetries and has had a dramatic impact on many fields of physics. Therefore, it seems equally important to investigate a similar approach for bosons as tightly analogous to the fermionic prototype as possible. There are, however, several obstacles coming from the fundamental physical differences between fermions and bosons. Here, we propose a potentially optimal way forward: a theory of free boson topology (topological classification and bulk-boundary correspondence) protected by bosonic many-body symmetry operations, namely, squeezing transformations, particle number, and bosonic time reversal. We identify two symmetry classes that are topologically non-trivial in one dimension. They include key models like the bosonic Kitaev chain, protected by a squeezing symmetry within our framework, and the celebrated bosonic SSH model, protected by a squeezing symmetry and particle number. To provide a robust experimental platform for testing our theory, we introduce a new quantum meta-material: photo-magnonic crystals. They consist of arrays of interconnected photo-magnonic cavities. They are remarkable for their experimental flexibility and natural affinity for displaying band topological physics at microwave frequencies. We engineer a many-body symmetry-protected topological photo-magnonic chain with boundary modes mandated by a Pfaffian invariant. Using an electromagnetic finite-element modelling, we simulate its reflection and transmission and identify experimental signatures of its boundary modes. The experimental tuning of the crystal to its symmetry-protected topological phase is also addressed. Our modelling of the photo-magnonic chain provides a thorough blueprint for its experimental realisation and the unambiguous observation of its exotic physics.

</details>


### [25] [The Pound-Drever-Hall Method for Superconducting-Qubit Readout](https://arxiv.org/abs/2512.03138)
*Ibukunoluwa Adisa,Won Chan Lee,Kevin C. Cox,Alicia J. Kollár*

Main category: quant-ph

TL;DR: 提出一种基于多音自相位参考Pound-Drever-Hall技术的超导量子比特读取方法，具有出色的相位稳定性和抗相位误差能力，相比传统外差读取有显著信号增强。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算机规模扩大，需要实现大量并行量子比特读取。传统读取方法面临相位漂移和信号稳定性问题，需要开发更稳定可靠的读取技术。

Method: 采用多音自相位参考Pound-Drever-Hall技术，该技术最初为光学腔开发。通过室温外差检测所有音调来重建PDH信号，对单个transmon量子比特进行PDH读取基准测试。

Result: PDH量子比特读取对微波相位漂移不敏感，2小时内相位稳定性达0.73°，能够在超过量子比特状态引起的相位误差下实现单次读取。PDH边带音调不会引起不必要的测量诱导状态跃迁，相比传统外差读取至少有14dB的信号增强潜力。

Conclusion: PDH读取技术为大规模量子计算机提供了稳定可靠的量子比特读取解决方案，具有优异的相位稳定性和信号增强能力，适合并行读取应用。

Abstract: Scaling quantum computers to large sizes requires the implementation of many parallel qubit readouts. Here we present an ultrastable superconducting-qubit readout method using the multi-tone self-phase-referenced Pound-Drever-Hall (PDH) technique, originally developed for use with optical cavities. In this work, we benchmark PDH readout of a single transmon qubit, using room-temperature heterodyne detection of all tones to reconstruct the PDH signal. We demonstrate that PDH qubit readout is insensitive to microwave phase drift, displaying $0.73^\circ$ phase stability over 2 hours, and capable of single-shot readout in the presence of phase errors exceeding the phase shift induced by the qubit state. We show that the PDH sideband tones do not cause unwanted measurement-induced state transitions for a transmon qubit, leading to a potential signal enhancement of at least $14$~dB over traditional heterodyne readout.

</details>


### [26] [Classical Thermometry of Quantum Annealers](https://arxiv.org/abs/2512.03162)
*George Grattan,Pratik Sathe,Cristiano Nisoli*

Main category: quant-ph

TL;DR: 量子退火器作为Gibbs采样器的保真度评估：发现有效温度标度定律需要耦合无关的偏移量，量化了残余非热效应但仍符合有效Gibbs描述


<details>
  <summary>Details</summary>
Motivation: 量子退火器作为研究强关联自旋系统的实验平台，但其关键热力学假设（特别是Gibbs分布输出）在大规模系统中尚未得到验证，需要评估其作为经典热力学实验平台的可行性

Method: 实验性地定量评估Gibbs采样保真度，跨越三个数量级的系统规模，探索耦合强度、系统大小、退火时间和D-wave硬件架构的广泛参数空间

Result: 发现朴素假设的有效温度标度定律需要不可忽略的、耦合无关的偏移量，该偏移量在不同机器和参数范围内保持稳健；采样集合推断的物理温度与设备名义低温之间存在系统差异

Conclusion: 系统评估了量子退火器作为经典热力学实验平台的可行性，修正了先前假设，并提供了物理基础的温度测量框架来为未来热力学实验基准测试这些机器

Abstract: Quantum annealers are emerging as programmable, dynamical experimental platforms for probing strongly correlated spin systems. Yet key thermal assumptions, chiefly a Gibbs-distributed output ensemble, remain unverified in the large-scale regime. Here, we experimentally and quantitatively assess Gibbs sampling fidelity across system sizes spanning over three orders of magnitude. We explore a wide parameter space of coupling strengths, system sizes, annealing times, and D-wave hardware architectures. We find that the naively assumed scaling law for the effective temperature requires a non-negligible, coupling-independent offset that is robust across machines and parameter regimes, quantifying residual non-thermal effects that still conform to an effective Gibbs description. These non-idealities are further reflected in a systematic discrepancy between the physical temperature inferred from the sampled ensemble and the nominal cryogenic temperature of the device. Our results systematically assess the viability of quantum annealers as experimental platforms for probing classical thermodynamics, correct previous assumptions, and provide a physically grounded thermometry framework to benchmark these machines for future thermodynamic experiments.

</details>


### [27] [Magic of the Well: assessing quantum resources of fluid dynamics data](https://arxiv.org/abs/2512.03177)
*Antonio Francesco Mello,Mario Collura,E. Miles Stoudenmire,Ryan Levy*

Main category: quant-ph

TL;DR: 该研究分析了二维不可压缩剪切流模拟数据集在量子计算中的资源需求，发现剪切宽度能区分资源高效和资源密集型区域，网格分辨率和符号结构对资源需求有重要影响。


<details>
  <summary>Details</summary>
Motivation: 研究动机是评估计算流体动力学（CFD）模拟数据集在量子计算框架下的资源需求，为开发可扩展的量子启发方法提供指导。通过分析纠缠和非稳定子性等量子资源，了解不同流态下CFD模拟的计算复杂性。

Method: 使用矩阵乘积态（MPS）编码函数来测量纠缠和非稳定子性，分析二维周期性不可压缩剪切流模拟生成的数据集。通过不同初始条件和流态，评估稳定子求解器和张量网络求解器在CFD模拟中面临的复杂性。

Result: 研究发现：1）特定初始条件下，剪切宽度能区分资源高效和资源密集型区域；2）纠缠和非稳定子性两种资源在时间上呈现定性相似的变化趋势；3）网格分辨率和符号结构对编码状态的资源含量有决定性影响。

Conclusion: 该研究为流体动力学中可扩展的量子启发方法开发提供了有用指导，表明通过分析量子资源需求可以优化CFD模拟的计算策略，特别是在不同流态和初始条件下的资源分配。

Abstract: We investigate the quantum resource requirements of a dataset generated from simulations of two-dimensional, periodic, incompressible shear flow, aimed at training machine learning models. By measuring entanglement and non-stabilizerness on MPS-encoded functions, we estimate the computational complexity encountered by a stabilizer or a tensor network solver applied to Computational Fluid Dynamics (CFD) simulations across different flow regimes. Our analysis reveals that, under specific initial conditions, the shear width identifies a transition between resource-efficient and resource-intensive regimes for non-trivial evolution. Furthermore, we find that the two resources qualitatively track each other in time, and that the mesh resolution along with the sign structure play a crucial role in determining the resource content of the encoded state. These findings offer useful guidelines for the development of scalable, quantum-inspired approaches to fluid dynamics.

</details>


### [28] [In Situ Quantum Analog Pulse Characterization via Structured Signal Processing](https://arxiv.org/abs/2512.03193)
*Yulong Dong,Christopher Kang,Murphy Yuezhen Niu*

Main category: quant-ph

TL;DR: 提出了一种基于量子信号处理（QSP）的脉冲轨迹原位学习算法，用于模拟量子模拟器的连续脉冲控制校准，避免传统方法因逻辑级分段增加导致的性能退化。


<details>
  <summary>Details</summary>
Motivation: 模拟量子模拟器需要高保真的时变脉冲控制来实现精确模拟，但现有的校准方案主要针对数字门表征设计，无法直接扩展到连续脉冲轨迹的学习。

Method: 将量子信号处理（QSP）框架扩展到时变脉冲分析，结合逻辑级模拟-数字映射范式，直接从时间序传播子的查询中重建平滑脉冲，无需中间电路测量或额外演化。

Result: 通过理论分析和数值模拟验证，该方法在SPAM和退极化误差下具有高精度、强效率和鲁棒性，为模拟量子模拟器提供了轻量级且最优的验证协议，能够检测主要硬件故障。

Conclusion: 该方法克服了传统基于Trotter分解方法的可扩展性问题，为模拟量子模拟器的脉冲控制校准提供了有效的解决方案，支持连续脉冲轨迹的原位学习。

Abstract: Analog quantum simulators can directly emulate time-dependent Hamiltonian dynamics, enabling the exploration of diverse physical phenomena such as phase transitions, quench dynamics, and non-equilibrium processes. Realizing accurate analog simulations requires high-fidelity time-dependent pulse control, yet existing calibration schemes are tailored to digital gate characterization and cannot be readily extended to learn continuous pulse trajectories. We present a characterization algorithm for in situ learning of pulse trajectories by extending the Quantum Signal Processing (QSP) framework to analyze time-dependent pulses. By combining QSP with a logical-level analog-digital mapping paradigm, our method reconstructs a smooth pulse directly from queries of the time-ordered propagator, without requiring mid-circuit measurements or additional evolution. Unlike conventional Trotterization-based methods, our approach avoids unscalable performance degradation arising from accumulated local truncation errors as the logical-level segmentation increases. Through rigorous theoretical analysis and extensive numerical simulations, we demonstrate that our method achieves high accuracy with strong efficiency and robustness against SPAM as well as depolarizing errors, providing a lightweight and optimal validation protocol for analog quantum simulators capable of detecting major hardware faults.

</details>


### [29] [Excess work in counterdiabatic driving](https://arxiv.org/abs/2512.03274)
*Lucas P. Kamizaki,Marcus V. S. Bonança*

Main category: quant-ph

TL;DR: 该论文提出了一种新方法来量化反绝热驱动的能量成本，通过重新解释反绝热哈密顿量参数，使瞬时超额功不为零，从而能够评估封闭量子系统控制过程中的能量消耗。


<details>
  <summary>Details</summary>
Motivation: 反绝热驱动方法长期以来似乎没有能量成本，这挑战了量化其所需能量的任务。需要找到一种方法来评估使用反绝热方法控制封闭量子系统的能量成本。

Method: 从Mandelstam-Tamm边界出发，提出重新解释反绝热哈密顿量参数，使瞬时超额功不为零，从而量化能量成本。使用Landau-Zener模型进行验证。

Result: 反绝热驱动的加速与总哈密顿量本征态之间的能量扩散相关，这必然伴随着这些本征态之间的跃迁。通过重新解释参数，超额功可以成为量化这些跃迁能量成本的指标。

Conclusion: 通过重新解释反绝热哈密顿量参数，超额功可以作为量化反绝热驱动能量成本的有效工具，解决了该方法看似无能量成本的长期挑战。

Abstract: Many years have passed since the conception of the quintessential method of shortcut to adiabaticity known as counterdiabatic driving (or transitionless quantum driving). Yet, this method appears to be energetically cost-free and thus continually challenges the task of quantifying the amount of energy it demands to be accomplished. This paper proposes that the energy cost of controlling a closed quantum system using the counterdiabatic method can also be assessed using the instantaneous excess work during the process and related quantities, as the time-averaged excess work. Starting from the Mandelstam-Tamm bound for driven dynamics, we have shown that the speed-up of counterdiabatic driving is linked with the spreading of energy between the eigenstates of the total Hamiltonian, which is necessarily accompanied by transitions between these eigenstates. Nonetheless, although excess work can be used to quantify energetically these transitions, it is well known that the excess work is zero throughout the entire process under counterdiabatic driving. To recover the excess work as an energetic cost quantifier for counterdiabatic driving, we will propose a different interpretation of the parameters of the counterdiabatic Hamiltonian, leading to an excess work different from zero. We have illustrated our findings with the Landau-Zener model.

</details>


### [30] [Quench dynamics of the quantum XXZ chain with staggered interactions: Exact results and simulations on digital quantum computers](https://arxiv.org/abs/2512.03341)
*Ching-Tai Huang,Yu-Cheng Lin,Ferenc Igloi*

Main category: quant-ph

TL;DR: 研究量子S=1/2 XXZ反铁磁链在平带极限下的淬火动力学，通过交换完全二聚化链的奇偶键强度，在贝尔基中推导精确时间演化态，获得纠缠熵和Loschmidt回波的解析解，并在IBM-Q量子设备上进行数值实验验证。


<details>
  <summary>Details</summary>
Motivation: 研究具有交错和各向异性相互作用的量子XXZ反铁磁链在平带极限下的淬火动力学，旨在理解量子多体系统中的非平衡动力学行为，特别是纠缠熵和Loschmidt回波等关键物理量的精确解析描述。

Method: 采用淬火协议交换完全二聚化链的奇偶键强度，在贝尔基中推导任意偶数系统尺寸的精确时间依赖态。获得冯·诺依曼熵和二阶Rényi纠缠熵的闭式表达，计算Loschmidt回波和返回率函数。在IBM-Q量子设备上进行两种数值实验：Hadamard测试估计贝尔基展开系数，以及无Trotter误差的时间演化电路结合随机泡利测量。

Result: 获得了纠缠熵和Loschmidt回波的精确解析表达式，确定了各向异性参数控制动力学可观测量周期性的精确条件。在有限链中识别了Loschmidt零点。量子实验结果显示，对于小系统，纠缠熵和Loschmidt回波的估计与精确结果吻合良好。

Conclusion: 成功解析研究了XXZ反铁磁链的淬火动力学，获得了关键物理量的精确解，并通过量子计算实验验证了理论结果。该方法为量子多体系统非平衡动力学的研究提供了有效的解析和实验框架。

Abstract: We investigate quench dynamics in the quantum $S=1/2$ XXZ antiferromagnetic chain with staggered and anisotropic interactions in the flat-band limit. Our quench protocol interchanges the odd- and even-bond strengths of a fully dimerized chain, enabling us to derive exact time-dependent states for arbitrary even system sizes by working in the Bell basis. We obtain closed-form, size-independent expressions for the von Neumann and second-order Rényi entanglement entropies. We further calculate exact Loschmidt echoes and the corresponding return rate functions across various anisotropies and system sizes, and identify Loschmidt zeros in finite chains. Our analysis reveals the precise conditions on the anisotropy parameter that govern the periodicity of the dynamical observables. In addition to the analytic study, we perform two types of numerical experiments on IBM-Q quantum devices. First, we use the Hadamard test to estimate the Bell-basis expansion coefficients and reconstruct the dynamical states, achieving accurate entanglement entropies and the Loschmidt echo for small systems. Second, we implement Trotter-error-free time-evolution circuits combined with randomized Pauli measurements. Post-processing via statistical correlations and classical shadows yields reliable estimates of the second-order Rényi entanglement entropy and the Loschmidt echo, showing satisfactory agreement with exact results.

</details>


### [31] [Hybridized-Mode Parametric Amplifier in Kinetic-Inductance Circuits](https://arxiv.org/abs/2512.03362)
*Danial Davoudi,Abdul Mohamed,Shabir Barzanjeh*

Main category: quant-ph

TL;DR: 该论文展示了一种基于耦合动力学电感谐振器的双模参量放大器，相比传统约瑟夫森结放大器具有更高饱和功率、更宽带宽和磁不敏感性，适用于量子测量应用。


<details>
  <summary>Details</summary>
Motivation: 约瑟夫森结放大器虽然已成为超导量子电路的标准，但其存在磁敏感性、有限饱和功率和亚开尔文工作温度限制等问题，需要开发替代的非线性平台。

Method: 使用NbTiN和NbN薄膜制造一对电容耦合的克尔非线性谐振器，利用材料的分布式克尔非线性实现非简并四波混频放大，并通过耦合模理论模型分析泵浦诱导的混合模式变化。

Result: 实现了接近40 dB的增益，增益带宽积达6.9 MHz，1-dB压缩功率比最先进的约瑟夫森放大器高2-3个数量级，NbN器件表现出更大的克尔系数和更优的增益带宽性能。

Conclusion: 耦合动力学电感谐振器为宽带、高功率、磁不敏感的量子极限放大提供了稳健平台，为超导量子比特、自旋系综、量子点等微波量子技术的先进读出提供了可扩展途径。

Abstract: Parametric amplification is essential for quantum measurement, enabling the amplification of weak microwave signals with minimal added noise. While Josephson-junction-based amplifiers have become standard in superconducting quantum circuits, their magnetic sensitivity, limited saturation power, and sub-kelvin operating requirements motivate the development of alternative nonlinear platforms. Here we demonstrate a two-mode kinetic-inductance parametric amplifier based on a pair of capacitively coupled Kerr-nonlinear resonators fabricated from NbTiN and NbN thin films. The distributed Kerr nonlinearity of these materials enables nondegenerate four-wave-mixing amplification with gains approaching 40 dB, gain-bandwidth products up to 6.9 MHz, and 1-dB compression powers two to three orders of magnitude higher than those of state-of-the-art Josephson amplifiers. A coupled-mode theoretical model accurately captures the pump-induced modification of the hybridized modes and quantitatively reproduces the observed signal and idler responses. The NbN device exhibits a significantly larger Kerr coefficient and superior gain-bandwidth performance, highlighting the advantages of high-kinetic-inductance materials. Our results establish coupled kinetic-inductance resonators as a robust platform for broadband, high-power, and magnetically resilient quantum-limited amplification, offering a scalable route for advanced readout in superconducting qubits, spin ensembles, quantum dots, and other microwave-quantum technologies.

</details>


### [32] [Engineering photonic dispersion relation and atomic dynamics in waveguide QED setup via long-range hoppings](https://arxiv.org/abs/2512.03423)
*Weijun Cheng,Da-Wei Wang,Yang Xue,Zhihai Wang,Liantuan Xiao*

Main category: quant-ph

TL;DR: 该论文研究了一种通过长程跳跃耦合谐振器波导实现线性色散关系的方法，用于精确控制原子动力学，并展示了其在定向原子辐射和吸收方面的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 光子波导中非平凡色散关系的工程化设计对于精确控制原子动力学具有重要价值，但目前缺乏统一的框架来模拟具有任意色散关系的原子-环境耦合。

Method: 通过精心设计谐振器之间的j阶最近邻（JNN）跳跃耦合，构建具有手性特征的线性色散关系，分析高斯波包在波导中的传播保真度来量化线性程度。

Result: 成功实现了线性色散关系，并证明这种耦合谐振器波导可作为实现定向原子辐射和吸收的多功能平台，同时通过定制的JNN跳跃也能实现二次和三次等更一般的色散关系。

Conclusion: 该研究为模拟具有任意色散关系的原子-环境耦合提供了一个统一框架，展示了耦合谐振器波导在精确控制原子动力学方面的强大潜力。

Abstract: Non-trivial dispersion relations engineered in photonic waveguide for the precise control of atomic dynamics has recently attracted considerable attention. Here, we study a system in which atoms are coupled to one-dimensional coupled-resonator waveguides with long-range hoppings. By carefully engineering the jth-order nearest neighbor (JNN) hoppings between resonators, we construct linear dispersion relations with the chiral characteristic. To quantify the degree of linearity, we analyze the propagation fidelities of Gaussian wave packets in these waveguides. Furthermore, we demonstrate that such coupled-resonator waveguides can serve as versatile platforms for enabling directional atomic radiation and absorption. Beyond linear dispersion relations, more general forms, including quadratic and cubic relations, can also be achieved through tailored JNN-hoppings. Our study thus provides a unified framework for simulating atom-environment couplings with arbitrary dispersion relations.

</details>


### [33] [Quantum Encrypted Control of Networked Systems](https://arxiv.org/abs/2512.03434)
*Zihao Ren,Daniel Quevedo,Salah Sukkarieh,Guodong Shi*

Main category: quant-ph

TL;DR: 量子加密控制框架：利用量子通信为网络控制系统提供高效加密，通过量子密钥分发增强安全性，对密钥错误具有强鲁棒性，相比经典加密方案显著降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统加密控制方案在密钥错误时可能崩溃，且计算复杂度高。量子技术虽然当前成熟度有限，但能以非平凡且原则性的方式集成到控制系统中，提供更强的安全性和性能优势。

Method: 1. 利用传感器与执行器之间的量子通道生成相同密钥；2. 基于量子密钥开发状态反馈线性系统的加密-解密架构；3. 分析量子状态误差对闭环稳定性的影响；4. 采用量化技术处理有限通信比特场景；5. 基于随机量化器实现量子密钥的隐私保护。

Result: 1. 建立了量子固有噪声的临界阈值，低于该阈值可保证稳定性；2. 量子加密控制对密钥缺陷表现出强鲁棒性（经典方案在单个密钥比特错误时可能崩溃）；3. 在降低计算复杂度和提高密钥错误恢复能力方面获得实质性性能增益；4. 确保对多种窃听源的安全性。

Conclusion: 量子技术以非平凡且原则性的方式集成到控制系统中，即使在其当前成熟度水平下，也能在确保安全性的同时，显著降低计算复杂度并提高对密钥错误的恢复能力，为网络控制系统提供高效加密控制框架。

Abstract: Encrypted control has been extensively studied to ensure the confidentiality of system states and control inputs for networked control systems. This paper presents a computationally efficient encrypted control framework for networked systems enabled by quantum communication. A quantum channel between sensors and actuators is used to generate identical secret keys, whose security is further enhanced through quantum key distribution. These keys enable lightweight encryption and decryption while preserving confidentiality and control accuracy. We develop a novel encryption-decryption architecture for state-feedback control of linear systems based on quantum keys, and characterize the impact of quantum state errors on closed-loop stability. In particular, we establish the existence of a critical threshold on intrinsic quantum noise below which stability is guaranteed. In contrast to classical encrypted control schemes, which may collapse under a single key-bit error, the proposed quantum encrypted control exhibits strong robustness to key imperfections. We further adopt quantization techniques to address the scenarios with limited communication bits in practical situations, and implement privacy protection for quantum keys based on a stochastic quantizer. These results demonstrate that integrating quantum technologies into control systems in a nontrivial and principled manner, even at their current level of maturity, can yield substantial performance gains in reducing computational complexity and improving resilience to key errors while ensuring security against multiple eavesdropping sources.

</details>


### [34] [Beyond Lindblad Dynamics: Rigorous Guarantees for Thermal and Ground State Preservation under System Bath Interactions](https://arxiv.org/abs/2512.03457)
*Ke Wang,Zhiyan Ding*

Main category: quant-ph

TL;DR: 该论文证明系统-浴相互作用模型在量子热态和基态制备中具有高效性和鲁棒性，突破了传统弱耦合Lindblad极限的限制，即使在累积耦合强度保持常数而非趋近于零时，仍能准确制备目标态。


<details>
  <summary>Details</summary>
Motivation: 现有分析依赖于弱耦合Lindblad极限，需要O(ε)耦合强度才能达到ε精度，导致混合速度缓慢。本文旨在证明即使在远超出这一机制的情况下，准确的状态制备仍然是可能的。

Method: 引入新技术控制Dyson展开的所有阶次，并分析相关的多维算子傅里叶变换。通过理论证明和数值模拟（在TFIM和Hubbard模型上）验证系统-浴相互作用框架的鲁棒性。

Result: 证明即使累积耦合强度保持常数而非趋近于零，诱导的量子通道仍能近似固定目标态。这些界限显著改进了先前结果，数值模拟进一步证实了系统-浴相互作用框架在弱耦合和强耦合机制下的鲁棒性。

Conclusion: 系统-浴相互作用模型在量子热态和基态制备中具有超越传统弱耦合极限的效率和鲁棒性，为量子模拟和量子计算中的状态制备提供了更强大的理论框架。

Abstract: We establish new theoretical results demonstrating the efficiency and robustness of system bath interaction models for quantum thermal and ground state preparation. Unlike existing analyses, which relies on the weak coupling Lindblad limit and require $O(ε)$ coupling strengths for $ε$ accuracy, leading to slow mixing, we rigorously show that accurate state preparation remains possible far beyond this regime. In particular, even when the cumulative coupling strength remains constant rather than vanishing, the induced quantum channel still approximately fixes the target state. Our proof introduces new techniques for controlling all orders of the Dyson expansion and for analyzing the associated multidimensional operator Fourier transforms. These bounds substantially improve upon prior results, and numerical simulations on the TFIM and Hubbard models further confirm the robustness of the system bath interaction framework across both weak and strong coupling regimes.

</details>


### [35] [Complex Wigner entropy and Fisher control of negativity in an oval quantum billiard](https://arxiv.org/abs/2512.03505)
*Kyu-Won Park,Jongin Jeong*

Main category: quant-ph

TL;DR: 提出基于复熵的维格纳负性框架，应用于椭圆量子台球中的避免交叉现象，通过虚部熵度量相空间非经典性，并建立柯西-施瓦茨界限限制维格纳负性变化速率。


<details>
  <summary>Details</summary>
Motivation: 需要量化量子系统中的非经典特征，特别是维格纳函数负性作为相空间非经典性的关键指标。传统实值熵度量无法捕捉维格纳负性的复杂特性，需要发展新框架来分析和量化避免交叉等量子现象中的非经典行为。

Method: 开发复熵框架：将吉布斯-香农泛函扩展为复值，其实部对应传统熵，虚部与维格纳负性体积成正比。引入符号分解分离总负权重及其相空间分布，定义负通道费希尔信息来量化负瓣随控制参数变化的敏感性。建立柯西-施瓦茨界限限制虚部熵变化速率。

Result: 在椭圆量子台球中，避免交叉区域显示出增强的维格纳负性和放大的负通道费希尔响应，为模式杂交提供了清晰的相空间特征。复熵框架成功量化了量子系统中的非经典性变化。

Conclusion: 复熵框架为维格纳负性提供了系统的量化方法，通过虚部熵和负通道费希尔信息有效表征相空间非经典性。该构造具有普适性，可扩展到其他波混沌和介观系统，为量子非经典性的相空间分析提供了新工具。

Abstract: We develop a complex-entropy framework for Wigner negativity and apply it to avoided crossings in an oval quantum billiard. For a real Wigner function the Gibbs--Shannon functional becomes complex; its imaginary part, proportional to the Wigner-negative volume, serves as an entropy-like measure of phase-space nonclassicality. A sign-resolved decomposition separates the total negative weight from its phase-space distribution and defines a negative-channel Fisher information that quantifies how sensitively the negative lobe reshapes as a control parameter is varied. This structure yields a Cauchy--Schwarz bound that limits how rapidly the imaginary entropy, and hence the Wigner negativity, can change with the parameter. In the oval billiard, avoided crossings display enhanced negativity and an amplified negative-channel Fisher response, providing a clear phase-space signature of mode hybridization. The construction is generic and extends to other wave-chaotic and mesoscopic systems with phase-space representations.

</details>


### [36] [Edge bits in average symmetry protected topological mixed state](https://arxiv.org/abs/2512.03530)
*Yoshihito Kuno*

Main category: quant-ph

TL;DR: 研究平均对称性保护拓扑（ASPT）混合态中的边缘比特，该态受一个强Z2对称性和一个弱（平均）Z2对称性保护。通过簇模型和Choi映射，探讨边缘比特的一般特征，并数值研究其在不同退相干和微扰相互作用下的行为及鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究平均对称性保护拓扑（ASPT）混合态中的边缘比特特性，探索其在退相干和微扰作用下的行为，并与纯对称性保护拓扑（SPT）态进行类比。

Method: 基于簇模型，采用Choi映射方法，使用算子空间互信息（OSMI）来追踪两个边缘之间的量子关联流动，数值研究边缘比特在不同退相干和微扰相互作用下的行为。

Result: 即使在ASPT区域，初始的边缘到边缘关联仍能保持有限部分，边缘比特展现出鲁棒性，对称性分数化现象得以保留。

Conclusion: ASPT混合态中的边缘比特具有鲁棒性，即使在退相干和微扰作用下，边缘关联仍能部分保持，这为理解ASPT态的特性提供了重要见解。

Abstract: Edge bit in an average symmetry protected topological (ASPT) mixed state is studied. The state is protected by one strong $Z_2$ and one weak (average) $Z_2$ symmetries. As analogous objects of pure symmetry protected topological (SPT) states, the ASPT possesses edge bits. In particular, the analogous operator response exists, that is, symmetry fractionalization. The fractionalization preserves the presence of the ASPT in the bulk, and the fractionalized edge operators acting on the edge bits of the ASPT. %analogous to the ones in the pure SPTs. In this work, based on the cluster model and by employing Choi mapping, we discuss generic features of the edge bits and numerically clarify the behavior of the edge bits and their robustness for varying decoherence and perturbative interactions. By using an operator-space mutual information (OSMI), we track the flow of quantum correlations between the two edges. Remarkably, even in the ASPT regime, a finite portion of the initial edge-to-edge correlation survives.

</details>


### [37] [Quantum Hash Function Based on Spectral Properties of Graphs and Discrete Walker Dynamics](https://arxiv.org/abs/2512.03581)
*Mohana Priya Thinesh Kumar,Pranavishvar Hariprakash*

Main category: quant-ph

TL;DR: 提出量子图哈希算法QGH-256，通过消息诱导图的量子相位估计生成256位高熵指纹，具有抗量子攻击特性


<details>
  <summary>Details</summary>
Motivation: 开发一种基于量子计算的哈希算法，利用图论和量子相位估计技术，为后量子密码学提供结构丰富的哈希基础，解决传统哈希算法在量子计算时代的潜在脆弱性

Method: 1) 将输入消息映射到n×n环面网格上的加权图；2) 使用量子相位估计提取图拉普拉斯矩阵的相位谱；3) 在叠加态而非特征向量上执行相位估计，确保所有特征分量贡献；4) 将谱特征转换为256位摘要

Result: 成功实现QGH-256在4×4环面网格上，该尺寸在碰撞率和执行时间之间取得平衡，使用Qiskit实现并通过种子状态向量模拟器获得稳定无噪声结果

Conclusion: QGH-256算法通过结合图论和量子计算，生成具有强敏感性和结构丰富性的哈希指纹，为后量子哈希提供了可行方案，在较小网格上实现平衡性能

Abstract: We present Quantum Graph Hash (QGH-256), a novel quantum spectral hashing algorithm that generates high-entropy fingerprints from message-induced graphs. Each input message is mapped to a weighted graph via a discrete random walk on an n X n toroidal grid, where the walk dynamics determine the edge weights. Quantum Phase Estimation (QPE) is then used to extract the phase spectrum of the graph Laplacian. Unlike standard QPE settings, the phase estimation is performed with respect to a superposition state (a uniform superposition over all node basis states) rather than an eigenvector, ensuring that all eigencomponents contribute to the resulting spectrum. This yields spectral features that distinguish even co-spectral but non-isomorphic message-induced graphs. The final spectral fingerprint is converted into a 256-bit digest, producing a compact representation of the input. As the fingerprint encodes both spectral and dynamical properties of the message-induced graph, the resulting hash exhibits strong sensitivity to input perturbations and provides a structurally rich foundation for post-quantum hashing. To demonstrate the feasibility of the approach, we implement QGH-256 on a 4 X 4 toroidal grid, chosen empirically: smaller grids exhibit collisions, whereas larger grids significantly increase execution time. The entire pipeline is implemented in Qiskit, and we use a seeded statevector simulator to obtain stable, noise-free results.

</details>


### [38] [Energy-Scaled Zero-Noise Extrapolation for Gottesman-Kitaev-Preskill Code](https://arxiv.org/abs/2512.03583)
*Gui-Zhong Luo,Matthew Otten*

Main category: quant-ph

TL;DR: 提出ES-ZNE协议，通过调节GKP码的平均光子数作为可调噪声参数，外推测量结果到理想无限能量极限，以缓解有限压缩对GKP码性能的限制。


<details>
  <summary>Details</summary>
Motivation: GKP码的性能受限于当前实验平台的有限压缩能力，需要一种方法来规避这种硬件需求，提升近态玻色量子处理器的性能。

Method: 引入能量缩放零噪声外推(ES-ZNE)协议，使用GKP码的平均光子数作为可调有效噪声参数，在可访问的有限能量下测量逻辑可观测量，基于代码渐近误差缩放的假设外推到理想无限能量极限。

Result: 通过模拟纯损耗信道下的GKP量子比特，证明ES-ZNE成功缓解了有限能量误差，在浅噪声区域恢复了理想期望值；通过计算去除有限能量编码产生的伪影，揭示了理想GKP码的内在性能，发现了误差阈值。

Conclusion: ES-ZNE作为一种实用的软件策略，通过采样开销换取高压缩等物理资源需求，能够增强近态玻色量子处理器的性能。

Abstract: The performance of Gottesman-Kitaev-Preskill (GKP) codes, an approach to hardware-efficient quantum error correction, is limited by the finite squeezing capabilities of current experimental platforms. To circumvent this hardware demand, we introduce Energy-Scaled Zero-Noise Extrapolation (ES-ZNE), a quantum error mitigation protocol that uses the mean photon number of the GKP code as a tunable effective noise parameter. The protocol measures logical observables at a series of accessible finite energies and extrapolates the results to the ideal, infinite-energy limit using an ansatz based on the code's asymptotic error scaling. Through simulating a GKP qubit under a pure-loss channel, we demonstrate that ES-ZNE successfully mitigates finite-energy errors, recovering the ideal expectation values (within numerical uncertainty) in the shallow-noise regime. Furthermore, by computationally removing artifacts arising from the finite-energy encoding, our method characterizes the intrinsic performance of the ideal GKP code, revealing a sharp error threshold beyond which the code's corrective power diminishes. These results establish ES-ZNE as a practical, software-based strategy for enhancing the performance of near-term bosonic quantum processors, trading sampling overhead for demanding physical resources like high squeezing.

</details>


### [39] [Experimental quantum voting using photonic GHZ states](https://arxiv.org/abs/2512.03659)
*Francis Marcellino,Mingsong Wu,Rob Thew*

Main category: quant-ph

TL;DR: 实验实现了一个基于量子GHZ态的四方选举协议，确保包括中央机构在内的任何人都无法获知投票者的偏好选择


<details>
  <summary>Details</summary>
Motivation: 量子通信协议利用量子系统的独特性质实现超越经典系统的安全性和匿名性保证，选举是需要这种强保证的重要应用场景

Method: 实验实现了Centrone等人提出的选举协议，生成并分发四部分GHZ态，记录投票者的投票意图

Result: 成功进行了四方选举，生成的GHZ态保真度约89%，投票意图记录成功率约87%

Conclusion: 该实验展示了量子选举协议的可行性，实现了投票者偏好的完全保密，即使中央机构也无法获知

Abstract: Quantum communication protocols seek to leverage the unique properties of quantum systems for coordination or communication tasks, usually with guarantees of security or anonymity that exceed what is possible classically. One promising domain of application is elections, where strong such guarantees are essential to ensure legitimacy. We experimentally implement a recently proposed election protocol from Centrone et al. such that no one, including a potential central authority, can know the preferred candidate of any voter other than themself. We conduct a four-party election, generating and distributing four-partite GHZ states with $\approx 89\%$ fidelity and successfully recording voters' intentions $\approx 87\%$ of the time.

</details>


### [40] [Direct Equivalence between Dynamics of Quantum Walks and Coupled Classical Oscillators](https://arxiv.org/abs/2512.03681)
*Lilith Zschetzsche,Refik Mansuroglu,András Molnár,Norbert Schuch*

Main category: quant-ph

TL;DR: 本文建立了连续时间量子行走与谐振子系统之间的直接映射，为量子计算提供了新的算法转换框架。


<details>
  <summary>Details</summary>
Motivation: 连续时间量子行走和谐振子系统都是BQP完全问题，但之前仅通过BQP完全性间接联系。本文旨在建立两者之间的直接、透明映射，以更好地利用两种计算范式的优势。

Method: 提出了一种直接映射方法，能够保持底层图结构、初始化、读取和高效预言访问等特性，实现两种问题之间的低开销转换。

Result: 成功建立了量子行走与谐振子系统之间的透明映射，该映射具有结构保持、低时空开销、支持非BQP完全子集转换、算法直接翻译等优势。

Conclusion: 该映射为量子算法设计提供了新视角，使得量子行走算法可直接转换为谐振子系统算法，反之亦然，并为谐振子系统问题的BQP完全性提供了更透明的证明方法。

Abstract: Continuous time quantum walks on exponentially large, sparse graphs form a powerful paradigm for quantum computing: On the one hand, they can be efficiently simulated on a quantum computer. On the other hand, they are themselves BQP-complete, providing an alternative framework for thinking about quantum computing -- a perspective which has indeed led to a number of novel algorithms and oracle problems. Recently, simulating the dynamics of a system of harmonic oscillators (that is, masses and springs) was set forth as another BQP-complete problem defined on exponentially large, sparse graphs. In this work, we establish a direct and transparent mapping between these two classes of problems. As compared to linking the two classes of problems via their BQP-completeness, our mapping has several desirable features: It is transparent, in that it respects the structure of the problem, including the geometry of the underlying graph, initialization, read-out, and efficient oracle access, resulting in low overhead in terms of both space and time; it allows to map also between restricted subsets of instances of both problems which are not BQP-complete; it provides a recipe to directly translate any quantum algorithm designed in the quantum walk paradigm to harmonic oscillators (and vice versa); and finally, it provides an alternative, transparent way to prove BQP-completeness of the harmonic oscillator problem by mapping it to BQP-completeness construction for the quantum walk problem (or vice versa).

</details>


### [41] [Distributed Quantum Computing with Fan-Out Operations and Qudits: the Case of Distributed Global Gates (a Preliminary Study)](https://arxiv.org/abs/2512.03685)
*Seng W. Loke*

Main category: quant-ph

TL;DR: 该论文探讨了在分布式量子计算中如何利用多体纠缠资源（如GHZ态）和四维量子比特（qudits）来实现分布式扇出操作和电路压缩，特别关注全局门（全局Mølmer-Sørensen门）的实现，这对分布式量子计算具有挑战性。


<details>
  <summary>Details</summary>
Motivation: 分布式量子计算通常依赖于纠缠对和分布式双量子比特门，但多体纠缠资源（如GHZ态）可以在单次操作中实现节点间的多体纠缠，避免使用多个纠缠对构建多体纠缠态。论文旨在探索这些资源在分布式扇出操作和电路压缩中的应用，特别是针对具有挑战性的全局门实现。

Method: 研究利用多体纠缠资源（如GHZ态）实现分布式扇出操作，同时考虑使用四维量子比特（qudits）进行分布式量子电路压缩。特别关注如何通过这些技术实现涉及全局量子比特-量子比特相互作用（全局Mølmer-Sørensen门）的电路，这些电路在分布式量子计算中具有挑战性。

Result: 论文展示了多体纠缠资源和四维量子比特在分布式量子计算中的潜在优势，特别是在实现全局门方面。这些方法可能通过减少电路深度来提高计算效率，并且在某些量子硬件（如囚禁离子量子计算机）中可以高效执行。

Conclusion: 该研究为分布式量子计算中的极端情况（全局量子比特-量子比特相互作用）提供了新的视角，对未来的量子电路编译和量子数据中心设计具有重要启示。多体纠缠资源和四维量子比特的应用可能为分布式量子计算带来更高效的实现方案。

Abstract: Much recent work on distributed quantum computing have focused on the use of entangled pairs and distributed two qubit gates. But there has also been work on efficient schemes for achieving multipartite entanglement between nodes in a single shot, removing the need to generate multipartite entangled states using many entangled pairs. This paper looks at how multipartite entanglement resources (e.g., GHZ states) can be useful for distributed fan-out operations; we also consider the use of qudits of dimension four for distributed quantum circuit compression. In particular, we consider how such fan-out operations and qudits can be used to implement circuits which are challenging for distributed quantum computation, involving pairwise qubit interactions, i.e., what has been called global gates (a.k.a. global Mølmer-Sørensen gates). Such gates have been explored to possibly yield more efficient computations via reduced circuit depth, and can be carried out efficiently in some types of quantum hardware (e.g., trapped-ion quantum computers); we consider this as an exploration of an ``extreme'' case for distribution given the global qubit-qubit interactions. We also conclude with some implications for future work on quantum circuit compilation and quantum data centre design.

</details>


### [42] [Sympathetic Cooling of Levitated Optomechanics through Nonreciprocal Coupling](https://arxiv.org/abs/2512.03690)
*Jialin Li,Guangyu Zhang,Zhang-qi Yin*

Main category: quant-ph

TL;DR: 提出一种基于非厄米相互作用的悬浮纳米颗粒光力学冷却方案，通过非互易耦合实现比传统腔冷却更低的声子占据数


<details>
  <summary>Details</summary>
Motivation: 传统腔辅助冷却受限于腔耗散和环境噪声，限制了可达到的最低温度，需要新的冷却机制来突破这一限制

Method: 通过两个悬浮纳米颗粒之间的非互易耦合实现非厄米光力学冷却，其中一个颗粒被光学腔直接冷却，另一个通过非厄米相互作用间接冷却

Result: 增加非互易性可以增强定向能量转移，使目标颗粒达到比传统腔冷却更低的声子占据数

Conclusion: 该研究展示了由非厄米相互作用驱动的新冷却机制，为实现可控能量流和深度冷却提供了理论指导，为量子控制和传感技术的发展铺平道路

Abstract: Optomechanical cooling of levitated nanoparticles has become an essential topic in modern quantum physics, providing a platform for exploring macroscopic quantum phenomena and high-precision sensing. However, conventional cavity-assisted cooling is fundamentally constrained by cavity dissipation and environmental noise, limiting the attainable minimum temperature. In this work, we propose a non-Hermitian optomechanical cooling scheme through nonreciprocal coupling between two levitated nanoparticles, where one particle is directly cooled by an optical cavity and the other is cooled indirectly through a non-Hermitian interaction. Both analytical solutions and numerical simulations reveal that increasing nonreciprocity enhances directional energy transfer, enabling the target particle to reach a lower phonon occupation than is achievable in conventional cavity cooling. This study demonstrates a new cooling mechanism driven by non-Hermitian interactions, offering theoretical guidance for realizing controllable energy flow and deep cooling in levitated optomechanical systems, and paving the way for future developments in quantum control and sensing technologies.

</details>


### [43] [Geometrical structure of the Wigner flow information quantifiers and hyperbolic stability in the phase-space framework](https://arxiv.org/abs/2512.03717)
*Alex E. Bernardini*

Main category: quant-ph

TL;DR: 从Weyl-Wigner框架的相空间微分几何结构推导出平稳性、经典性、纯度和涡旋性的量化指标，并将其与经典和量子修正哈密顿方程的双曲稳定性联系起来，通过分析高斯量子系综的平衡稳定性参数，识别Wigner流驱动的信息量化指标。


<details>
  <summary>Details</summary>
Motivation: 建立相空间几何结构与哈密顿非线性动力学稳定性之间的对应关系，量化量子涨落对相空间涡旋性出现的影响，从而分析哈密顿系统的平衡和稳定性特性。

Method: 在Weyl-Wigner框架下，从相空间微分几何结构推导量化指标，分析自治常微分方程系统的平衡状态，将Wigner流特性与相空间双曲稳定性边界联系起来，对量子高斯系综获得解析的平衡稳定性参数表达式。

Result: 建立了Wigner流性质与相空间双曲稳定性边界之间的对应关系，获得了量子高斯系综的平衡稳定性参数解析表达式，识别了由Wigner流驱动的信息量化指标，并通过Harper-like系统的应用验证了方法的有效性。

Conclusion: 该方法为识别量子涨落对相空间涡旋性出现的影响提供了自洽的分析框架，能够量化哈密顿非线性动力学的平衡和稳定性特性，为理解量子修正对经典系统稳定性的影响提供了新视角。

Abstract: Quantifiers of stationarity, classicality, purity and vorticity are derived from phase-space differential geometrical structures within the Weyl-Wigner framework, after which they are related to the hyperbolic stability of classical and quantum-modified Hamiltonian (non-linear) equations of motion. By examining the equilibrium regime produced by such an autonomous system of ordinary differential equations, a correspondence between Wigner flow properties and hyperbolic stability boundaries in the phase-space is identified. Explicit analytical expressions for equilibrium-stability parameters are obtained for quantum Gaussian ensembles, wherein information quantifiers driven by Wigner currents are identified. Illustrated by an application to a Harper-like system, the results provide a self-contained analysis for identifying the influence of quantum fluctuations associated to the emergence of phase-space vorticity in order to quantify equilibrium and stability properties of Hamiltonian non-linear dynamics.

</details>


### [44] [Non-Gaussian Dissipative Quantum Thermometry Beyond Gaussian Bounds](https://arxiv.org/abs/2512.03735)
*Pritam Chattopadhyay*

Main category: quant-ph

TL;DR: 该论文建立了开放量子系统中温度传感的量子费希尔信息解析界限，揭示了非高斯量子态在短时耗散演化下相对于高斯态的线性时间增强优势。


<details>
  <summary>Details</summary>
Motivation: 开放量子系统中温度传感的基本计量极限尚未完全解决，特别是非高斯量子资源的作用。需要明确在何种条件下非高斯探针能够超越高斯态，以及这种优势的具体表现形式。

Method: 通过聚焦于由时间局域主方程支配的短时区域，推导出量子费希尔信息的解析界限。采用精确数值模拟验证理论分析，并将结果映射到电路量子电动力学等实验可访问平台。

Result: 发现了Fock态特有的线性时间量子费希尔信息增强，与高斯探针固有的较弱二次标度形成对比。在相同能量约束下，非高斯探针能够决定性超越高斯态。

Conclusion: 该研究不仅阐明了非高斯性在量子测温中的优势，还为在噪声量子技术中利用这种优势规划了现实路径，为非高斯量子资源在精密测量中的应用提供了理论基础。

Abstract: The fundamental metrological limits of temperature sensing in open quantum systems remain largely unresolved, particularly regarding the role of non-Gaussian quantum resources. In this letter, we establish analytic bounds on the quantum Fisher information (QFI) for temperature estimation using non-Gaussian states undergoing dissipative bosonic evolution. By focusing on the short-time regime governed by a time-local master equation, we derive precise scaling laws that elucidate when and how non-Gaussian probes decisively outperform Gaussian states under identical energy constraints. Our analysis uncovers a distinct linear-in-time QFI enhancement unique to Fock states, in contrast to the inherently weaker, quadratic scaling of Gaussian probes. These theoretical insights are substantiated through exact numerical simulations and mapped onto experimentally accessible platforms such as circuit QED. Our results not only clarify the quantum thermometric advantage of non-Gaussianity but also chart a realistic pathway toward harnessing it in noisy quantum technologies.

</details>


### [45] [Quantum Max Cut for complete tripartite graphs](https://arxiv.org/abs/2512.03740)
*Tea Štrekelj*

Main category: quant-ph

TL;DR: 本文解决了小局部维度(d≤3)下完全三部图的量子最大d-割问题


<details>
  <summary>Details</summary>
Motivation: d-QMC问题是经典Max-d-Cut问题的量子类比，是2-局域哈密顿量问题的特例。近年来通过研究d-QMC哈密顿量的代数结构取得进展，本文在此基础上进一步研究。

Method: 基于d-QMC哈密顿量的代数结构方法，针对完全三部图，在小局部维度(d≤3)下求解该问题。

Result: 成功解决了d≤3情况下完全三部图的量子最大d-割问题。

Conclusion: 本文扩展了d-QMC问题的求解范围，为小局部维度的完全三部图提供了解决方案，推进了量子优化问题的研究。

Abstract: The Quantum Max-$d$-Cut ($d$-QMC) problem is a special instance of a $2$-local Hamiltonian problem, representing the quantum analog of the classical Max-$d$-Cut problem. The $d$-QMC problem seeks the largest eigenvalue of a Hamiltonian defined on a graph with $n$ vertices, where edges correspond to swap operators acting on $(\mathbb{C}^d)^{\otimes n}$. In recent years, progress has been made by investigating the algebraic structure of the $d$-QMC Hamiltonian. Building on this approach, this article solves the $d$-QMC problem for complete tripartite graphs for small local dimensions, $d \le 3$.

</details>


### [46] [Widefield Quantum Sensor for Vector Magnetic Field Imaging of Micromagnetic Structures](https://arxiv.org/abs/2512.03748)
*Orlando D. Cunha,Filipe Camarneiro,João P. Silva,Hariharan Nhalil,Ariel Zaig,Lior Klein,Jana B. Nieder*

Main category: quant-ph

TL;DR: 该研究开发了一种基于氮空位中心的宽场向量磁力计，实现了对微米尺度磁结构的快速、高分辨率向量磁场成像。


<details>
  <summary>Details</summary>
Motivation: 许多自旋电子学、磁存储和神经形态器件依赖于空间变化的磁场。现有探针要么提供纳米级分辨率但扫描速度慢，要么提供宽场成像但向量灵敏度有限或材料受限。需要一种实用、可扩展的工具来对复杂磁器件进行常规向量分辨成像。

Method: 改造商用宽场显微镜，实现相机兼容的脉冲光学检测磁共振协议。通过解析四个NV取向的塞曼位移，重建微制造坡莫合金结构产生的杂散场向量。

Result: 实现了≈0.52μm的空间分辨率，视场83μm×83μm，峰值灵敏度(828±142)nT/√Hz，采集时间仅需几分钟。成功重建了具有多个稳定剩磁状态的微结构杂散场向量。

Conclusion: 脉冲宽场NV磁力计已成为实用且可扩展的工具，可用于常规复杂磁器件的向量分辨成像，为相关领域提供了重要的表征手段。

Abstract: Many spintronic, magnetic-memory, and neuromorphic devices rely on spatially varying magnetic fields. Quantitatively imaging these fields with full vector information over extended areas remains a major challenge. Existing probes either offer nanoscale resolution at the cost of slow scanning, or widefield imaging with limited vector sensitivity or material constraints. Quantum sensing with nitrogen-vacancy (NV) centers in diamond promises to bridge this gap, but a practical camera-based vector magnetometry implementation on relevant microstructures has not been demonstrated. Here we adapt a commercial widefield microscope to implement a camera-compatible pulsed optically detected magnetic resonance protocol to reconstruct stray-field vectors from microscale devices. By resolving the Zeeman shifts of the four NV orientations, we reconstruct the stray-field vector generated by microfabricated permalloy structures that host multiple stable remanent states. Our implementation achieves a spatial resolution of $\approx 0.52 ~μ\mathrm{m}$ across an $83~μ\mathrm{m} \times 83~μ\mathrm{m}$ field of view and a peak sensitivity of $ (828 \pm 142)~\mathrm{nT\,Hz^{-1}}$, with acquisition times of only a few minutes. These results establish pulsed widefield NV magnetometry on standard microscopes as a practical and scalable tool for routine vector-resolved imaging of complex magnetic devices.

</details>


### [47] [An end-to-end quantum algorithm for nonlinear fluid dynamics with bounded quantum advantage](https://arxiv.org/abs/2512.03758)
*David Jennings,Kamil Korzekwa,Matteo Lostaglio,Richard Ashworth,Emanuele Marsili,Stephen Rolston*

Main category: quant-ph

TL;DR: 本文分析了量子计算在计算流体动力学(CFD)中的应用，指出现有Carleman嵌入方法存在严重瓶颈，提出了一种新的不可压缩格子玻尔兹曼方程算法，并发现量子优势仅在特定条件下有限存在。


<details>
  <summary>Details</summary>
Motivation: 探索量子计算机是否能在计算流体动力学(CFD)模拟中实现加速，特别是针对现有基于Carleman嵌入方法的量子算法提案进行批判性分析，并开发能克服这些瓶颈的新算法。

Method: 首先系统分析现有Carleman嵌入方法的瓶颈（收敛性、时间步长要求、条件数缩放、数据提取效率），然后开发新的不可压缩格子玻尔兹曼方程量子算法，进行详细的算法复杂度分析，包括门计数估计和数值研究。

Result: 发现现有Carleman方法存在严重瓶颈，新算法在高误差容忍度下对特定观测值可能保持适度量子优势。给出了雷诺数缩放的下界估计，数值研究表明实际加速可能低于理论上限。

Conclusion: 量子计算在CFD领域可以实现小规模但非平凡的量子优势，但需要更多严格的端到端量子算法开发。现有方法的瓶颈需要被克服，新算法为这一方向提供了有希望的途径。

Abstract: Computational fluid dynamics (CFD) is a cornerstone of classical scientific computing, and there is growing interest in whether quantum computers can accelerate such simulations. To date, the existing proposals for fault-tolerant quantum algorithms for CFD have almost exclusively been based on the Carleman embedding method, used to encode nonlinearities on a quantum computer. In this work, we begin by showing that these proposals suffer from a range of severe bottlenecks that negate conjectured quantum advantages: lack of convergence of the Carleman method, prohibitive time-stepping requirements, unfavorable condition number scaling, and inefficient data extraction. With these roadblocks clearly identified, we develop a novel algorithm for the incompressible lattice Boltzmann equation that circumvents these obstacles, and then provide a detailed analysis of our algorithm, including all potential sources of algorithmic complexity, as well as gate count estimates. We find that for an end-to-end problem, a modest quantum advantage may be preserved for selected observables in the high-error-tolerance regime. We lower bound the Reynolds number scaling of our quantum algorithm in dimension $D$ at Kolmogorov microscale resolution with $O(\mathrm{Re}^{\frac{3}{4}(1+\frac{D}{2})} \times q_M)$, where $q_M$ is a multiplicative overhead for data extraction with $q_M = O(\mathrm{Re}^{\frac{3}{8}})$ for the drag force. This upper bounds the scaling improvement over classical algorithms by $O(\mathrm{Re}^{\frac{3D}{8}})$. However, our numerical investigations suggest a lower speedup, with a scaling estimate of $O(\mathrm{Re}^{1.936} \times q_M)$ for $D=2$. Our results give robust evidence that small, but nontrivial, quantum advantages can be achieved in the context of CFD, and motivate the need for additional rigorous end-to-end quantum algorithm development.

</details>


### [48] [Metrological Sensitivity beyond Gaussian Limits with Cubic Phase States](https://arxiv.org/abs/2512.03769)
*Jiajie Guo,Shuheng Liu,Boxuan Jing,Qiongyi He,Manuel Gessner*

Main category: quant-ph

TL;DR: 立方相位态作为连续变量量子计算的关键非高斯资源，在量子计量学中展现出超越高斯态的相位传感灵敏度优势，且对损耗和噪声具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 探索立方相位态在量子计量学中的应用潜力，研究其是否能够超越高斯态在相位传感方面的性能限制，为量子增强精密测量提供新的非高斯资源。

Method: 分析立方相位态在量子计量中的性能，研究其相位传感灵敏度与高斯态的比较，探索最优测量策略，并评估不同实验制备方案的效果。

Result: 立方相位态在相同平均光子数下，相位传感灵敏度超越所有高斯态；仅需中等初始压缩即可达到最优灵敏度；非高斯优势对损耗和探测噪声具有鲁棒性；多个实验相关制备方案可超越高斯极限，部分甚至达到立方相位态的灵敏度水平。

Conclusion: 立方相位态是超越高斯极限的量子增强精密测量的有前景资源，为量子计量学提供了新的非高斯工具，具有实际应用潜力。

Abstract: Cubic phase states provide the essential non-Gaussian resource for continuous-variable quantum computing. We show that they also offer significant potential for quantum metrology, surpassing the phase-sensing sensitivity of all Gaussian states at equal average photon number. Optimal sensitivity requires only moderate initial squeezing, and the non-Gaussian advantage remains robust against loss and detection noise. We identify optimal measurement strategies and show that several experimentally relevant preparation schemes surpass Gaussian limits, in some cases reaching the sensitivity of cubic phase states. Our results establish cubic phase states as a promising resource for quantum-enhanced precision measurements beyond Gaussian limits.

</details>


### [49] [Quantum Algorithm for Searching for the Longest Segment and the Largest Empty Rectangle](https://arxiv.org/abs/2512.03788)
*Kamil Khadiev,Vladislav Remidovskii,Timur Bikmullin,Aliya Khadieva*

Main category: quant-ph

TL;DR: 该论文提出了针对二维地图中最大空矩形搜索问题的量子算法，包括最大空正方形和固定宽度矩形，实现了相对于经典算法的二次加速。


<details>
  <summary>Details</summary>
Motivation: 在二维地图中搜索最大空矩形是一个重要的计算几何问题，经典算法需要较高的查询复杂度。量子计算有望为这类问题提供显著的加速。

Method: 提出量子算法解决最大空正方形和固定宽度矩形问题，使用量子查询技术优化搜索过程。

Result: 量子算法查询复杂度：正方形为$\tilde{O}(n^{1.5})$，固定宽度$d$矩形为$\tilde{O}(n\sqrt{d})$；一维版本为$O(\sqrt{n}\log n\log\log n)$。相比经典下界实现了二次加速。

Conclusion: 量子算法在最大空矩形搜索问题上实现了显著的查询复杂度改进，为计算几何问题提供了量子加速的新范例。

Abstract: In the paper, we consider the problem of searching for the Largest empty rectangle in a 2D map, and the one-dimensional version of the problem is the problem of searching for the largest empty segment. We present a quantum algorithm for the Largest Empty Square problem and the Largest Empty Rectangle of a fixed width $d$ for $n\times n$-rectangular map. Query complexity of the algorithm is $\tilde{O}(n^{1.5})$ for the square case, and $\tilde{O}(n\sqrt{d})$ for the rectangle with a fixed width $d$ case, respectively. At the same time, the lower bounds for the classical case are $Ω(n^2)$, and $Ω(nd)$, respectively. The Quantum algorithm for the one-dimensional version of the problem has $O(\sqrt{n}\log n\log\log n)$ query complexity. The quantum lower bound for the problem is $Ω(\sqrt{n})$ which is almost equal to the upper bound up to a log factor. The classical lower bound is $Ω(n)$. So, we obtain the quadratic speed-up for the problem.

</details>


### [50] [Solution of the Electric Field Integral Equation Using a Hybrid Quantum-Classical Scheme: Investigation of Accuracy and Efficiency](https://arxiv.org/abs/2512.03808)
*Rui Chen,Teng-Yang Ma,Meng-Han Dou,Chao-Fu Wang*

Main category: quant-ph

TL;DR: 提出混合量子-经典方案求解三维电磁散射问题，通过双层迭代策略结合量子算法降低计算复杂度


<details>
  <summary>Details</summary>
Motivation: 传统经典求解器在处理大规模电磁问题时面临内存瓶颈，量子计算具有并行化优势和低存储复杂度，但现有量子算法可求解的矩阵方程规模有限

Method: 采用混合量子-经典方案：先设计预处理线性系统，然后使用双层迭代策略，外层构建小维度子空间矩阵方程，内层使用量子算法（HHL和VQLS）求解小系统

Result: 混合VQLS-经典方案的计算复杂度低于传统经典快速求解器，表明该方案在分析大规模电磁问题方面更有前景

Conclusion: 混合量子-经典方案首次成功应用于三维任意形状导体电磁散射分析，通过双层迭代策略有效结合量子算法优势，为解决大规模电磁问题提供了有前景的新途径

Abstract: Conventional classical solvers are commonly used for solving matrix equation systems resulting from the discretization of SIEs in computational electromagnetics (CEM). However, the memory requirement would become a bottleneck for classical computing as the electromagentic problems become much larger. As an alternative, quantum computing has a natural "parallelization" advantage with much lower storage complexity due to the superposition and entanglement in quantum mechanics. Even though several quantum algorithms have been applied for the SIEs-based methods in the literature, the size of the matrix equation systems solvable using them is still limited. In this work, we use a hybrid quantum-classical scheme to solve the EFIE for analyzing electromagentic scattering from three-dimensional (3D) perfect electrically conducting objects with arbitrary shapes in CEM for the first time. Instead of directly solving the original EFIE matrix equation system using the quantum algorithms, the hybrid scheme first designs the preconditioned linear system and then uses a double-layer iterative strategy for its solution, where the external iteration layer builds subspace matrix equation systems with smaller dimension and the internal iteration layer solves the smaller systems using the quantum algorithms. Two representative quantum algorithms, HHL and VQLS, are considered in this work, which are executed on the quantum simulator and quantum computer platforms. We present the theoretical time complexity analysis of the hybrid quantum-classical scheme and perform numerical experiments to investigate the accuracy and efficiency of the hybrid scheme. The results show that the computational complexity of the hybrid VQLS-classical scheme is lower than the conventional fast solvers in classical computing, which indicates the hybrid scheme is more promising for analyzing large-scale electromagnetic problems.

</details>


### [51] [Density of states of quantum systems from free probability theory: a brief overview](https://arxiv.org/abs/2512.03850)
*Keun-Young Kim,Kuntal Pal*

Main category: quant-ph

TL;DR: 本文综述了利用自由概率理论计算量子系统和随机矩阵哈密顿量态密度的方法，包括自由加性卷积的应用、成功案例、局限性，以及基于从属公式的微扰方案。


<details>
  <summary>Details</summary>
Motivation: 量子系统和随机矩阵哈密顿量的态密度计算是重要的理论问题。传统方法往往计算复杂，而自由概率理论提供了一种简化方法，能够从已知分量算子的态密度推导出总哈密顿量的态密度。

Method: 1. 使用自由概率理论中的自由加性卷积：当哈密顿量可表示为两个非对易算子的和，且假设它们相互自由时，可以从分量算子的已知态密度得到总哈密顿量的态密度。
2. 开发基于从属公式的微扰方案：利用柯西变换的从属公式，获得态密度的近似解析表达式。

Result: 该方法在许多相互作用量子系统和随机矩阵模型中能提供相当准确的态密度近似。文中回顾了文献中该方法表现良好的例子，如Rosenzweig-Porter随机矩阵系综和具有在位无序的Anderson模型。

Conclusion: 自由概率理论为计算量子系统和随机矩阵哈密顿量的态密度提供了有效的近似方法，但在某些情况下可能存在局限性。基于从属公式的微扰方案可以进一步改进近似精度，为各种模型提供解析表达式。

Abstract: We provide a brief overview of approaches for calculating the density of states of quantum systems and random matrix Hamiltonians using the tools of free probability theory. For a given Hamiltonian of a quantum system or a generic random matrix Hamiltonian, which can be written as a sum of two non-commutating operators, one can obtain an expression for the density of states of the Hamiltonian from the known density of states of the two component operators by assuming that these operators are mutually free and by using the free additive convolution. In many examples of interacting quantum systems and random matrix models, this procedure is known to provide a reasonably accurate approximation to the exact numerical density of states. We review some of the examples that are known in the literature where this procedure works very well, and also discuss some of the limitations of this method in situations where the free probability approximation fails to provide a sufficiently accurate description of the exact density of states. Subsequently, we describe a perturbation scheme that can be developed from the subordination formulas for the Cauchy transform of the density of states and use it to obtain approximate analytical expressions for the density of states in various models, such as the Rosenzweig-Porter random matrix ensemble and the Anderson model with on-site disorder.

</details>


### [52] [Modelling the Impact of Device Imperfections on Electron Shuttling in SiMOS devices](https://arxiv.org/abs/2512.03853)
*Jack J. Turner,Christian W. Binder,Guido Burkard,Andrew J. Fisher*

Main category: quant-ph

TL;DR: 通过3D模拟研究SiMOS器件中的传送带电荷穿梭，发现低栅压时多层栅结构导致传送带模式崩溃为桶队模式，增加限制可恢复传送带操作，但界面缺陷会引发轨道激发


<details>
  <summary>Details</summary>
Motivation: Si/SiGe系统已实现高保真电子穿梭，但Si/SiO2 (SiMOS) 系统仍处于早期阶段，需要研究SiMOS器件中传送带电荷穿梭的实际性能

Method: 对真实SiMOS器件进行完整3D模拟，求解泊松方程和含时薛定谔方程，考虑不同穿梭速度和栅压，分析氧化物界面粗糙度、栅极制造缺陷和传输路径上的电荷缺陷

Result: 低栅压时多层栅结构的额外氧化物屏蔽导致传送带穿梭崩溃为桶队模式并引发轨道激发；增加限制可恢复传送带操作，对界面粗糙度、栅极错位和氧化物中埋入的电荷缺陷具有鲁棒性；但Si/SiO2界面缺陷会引发显著轨道激发，低偏压下正电荷缺陷甚至能捕获电子

Conclusion: 确定了SiMOS架构中可靠电荷传输的关键挑战和操作区间，为SiMOS量子器件设计提供了重要指导

Abstract: Extensive theoretical and experimental work has established high-fidelity electron shuttling in Si/SiGe systems, whereas demonstrations in Si/SiO2 (SiMOS) remain at an early stage. To help address this, we perform full 3D simulations of conveyor-belt charge shuttling in a realistic SiMOS device, building on earlier 2D modelling. We solve the Poisson and time-dependent Schrodinger equations for varying shuttling speeds and gate voltages, focusing on potential pitfalls of typical SiMOS devices such as oxide-interface roughness, gate fabrication imperfections, and charge defects along the transport path. The simulations reveal that for low clavier-gate voltages, the additional oxide screening in multi-layer gate architectures causes conveyor-belt shuttling to collapse to the bucket-brigade mode, inducing considerable orbital excitation in the process. Increasing the confinement restores conveyor-belt operation, which we find to be robust against interface roughness, gate misalignment, and charge defects buried in the oxide. However, our results indicate that defects located at the Si/SiO2-interface can induce considerable orbital excitation. For lower conveyor gate biases, positive defects in the transport channel can even capture passing electrons. Hence we identify key challenges and find operating regimes for reliable charge transport in SiMOS architectures.

</details>


### [53] [Polylogarithmic-Depth Quantum Algorithm for Simulating the Extended Hubbard Model on a Two-Dimensional Lattice Using the Fast Multipole Method](https://arxiv.org/abs/2512.03898)
*Yu Wang,Martina Nibbi,Maxine Luo,Isabel Nha Minh Le,Yanbin Chen,J. Ignacio Cirac,Christian Mendl*

Main category: quant-ph

TL;DR: 提出一种基于快速多极方法的量子算法，用于高效模拟二维扩展哈伯德模型的时间演化，电路深度随系统规模呈多对数增长。


<details>
  <summary>Details</summary>
Motivation: 二维扩展哈伯德模型能捕捉关键物理现象，但由于存在长程相互作用，传统模拟方法面临挑战，需要开发高效的量子算法来解决这一问题。

Method: 受快速多极方法启发，通过分层粗粒化盒子近似处理成对相互作用；利用二维中性原子量子计算的最新进展，支持长程门和穿梭等非局域操作。

Result: 单次Trotter步的电路深度随系统规模呈多对数（polylogarithmic）增长，相比传统方法显著提高了模拟效率。

Conclusion: 该算法为模拟具有长程相互作用的二维扩展哈伯德模型提供了一种高效的量子计算方法，有望在量子计算平台上实现大规模物理系统的模拟。

Abstract: The extended Hubbard model on a two-dimensional lattice captures key physical phenomena, but is challenging to simulate due to the presence of long-range interactions. In this work, we present an efficient quantum algorithm for simulating the time evolution of this model. Our approach, inspired by the fast multipole method, approximates pairwise interactions by interactions between hierarchical levels of coarse-graining boxes. We discuss how to leverage recent advances in two-dimensional neutral atom quantum computing, supporting non-local operations such as long-range gates and shuttling. The resulting circuit depth for a single Trotter step scales polylogarithmically with system size.

</details>


### [54] [Experimental Quantum Electronic Voting](https://arxiv.org/abs/2512.03924)
*Nicolas Laurent-Puig,Matilde Baroni,Federico Centrone,Eleni Diamanti*

Main category: quant-ph

TL;DR: 实验演示了基于GHZ态量子态的电子投票协议，无需选举机构，具有信息论安全性，支持最多8个选民和16个候选人的选举场景


<details>
  <summary>Details</summary>
Motivation: 随着计算能力的发展，经典投票方案面临信息泄露风险，需要最高级别的安全性和隐私保护，特别是在民主社会的电子投票应用中

Method: 利用GHZ态量子态的独特性质，构建无需选举机构的电子投票协议，实验基于高性能GHZ态源，实现两种场景：4个选民2个候选人的隐私增强配置，以及8个选民16个候选人的选举场景

Result: 成功实验演示了信息论安全的电子投票协议，实现了原理验证，特别适合组织内部或小规模政府环境的安全董事会级别选举

Conclusion: 量子信息协议为电子投票提供了信息论安全性和隐私保护，无需依赖选举机构，为民主社会的安全投票提供了有前景的解决方案

Abstract: Quantum information protocols offer significant advantages in properties such as security, anonymity, and privacy for communication and computing tasks. An application where guaranteeing the highest possible security and privacy is critical for democratic societies is electronic voting. As computational power continues to evolve, classical voting schemes may become increasingly vulnerable to information leakage. In this work, we present the experimental demonstration of an information-theoretically secure and efficient electronic voting protocol that, crucially, does not rely on election authorities, leveraging the unique properties of quantum states. Our experiment is based on a high-performance source of Greenberger-Horne-Zeilinger (GHZ) states and realizes a proof-of-principle implementation of the protocol in two scenarios: a configuration with four voters and two candidates employing privacy enhancement techniques and an election scenario supporting up to eight voters and sixteen candidates. The latter is particularly well-suited for secure board-level elections within organizations or small-scale governmental contexts.

</details>


### [55] [Towards Quantum Stochastic Optimization for Energy Systems under Uncertainty: Joint Chance Constraints with Quantum Annealing](https://arxiv.org/abs/2512.03925)
*David Ribes,Tatiana Gonzalez Grandon*

Main category: quant-ph

TL;DR: 量子退火平台在机会约束机组组合问题中的应用评估：混合量子经典求解器在大规模场景下具有竞争力，但当前量子退火器因硬件限制无法处理随机问题


<details>
  <summary>Details</summary>
Motivation: 现代电力系统中可再生能源和波动负荷带来的不确定性使得随机优化不可或缺，但机会约束机组组合问题随着场景数量增加计算复杂度急剧上升，量子计算被认为是突破这种扩展性障碍的潜在途径

Method: 将机会约束机组组合问题重新表述为混合整数线性规划，使用DWave混合量子经典求解器和Gurobi进行求解，同时测试了QUBO重新表述方法

Result: 混合求解器在严格运行时间限制下对大规模场景集（实验中达15,000个）具有竞争力，而Gurobi在较小规模案例上表现更优；QUBO重新表述因当前退火器硬件限制无法处理随机机组组合问题，确定性案例也受到嵌入开销影响

Conclusion: 研究明确了混合量子经典方法在哪些情况下已经可以处理机会约束机组组合问题，以及当前量子退火器在哪些方面仍然存在根本性限制，为量子计算在电力系统优化中的应用提供了实用指导

Abstract: Uncertainty is fundamental in modern power systems, where renewable generation and fluctuating demand make stochastic optimization indispensable. The chance constrained unit commitment problem (UCP) captures this uncertainty but rapidly becomes computationally challenging as the number of scenarios grows. Quantum computing has been proposed as a potential route to overcome such scaling barriers. In this work, we evaluate the applicability of quantum annealing platforms to the chance constrained UCP. Focusing on a scenario approximation, we reformulated the problem as a mixed integer linear program and solved it using DWave hybrid quantum classical solver alongside Gurobi. The hybrid solver proved competitive under strict runtime limits for large scenario sets (15,000 in our experiments), while Gurobi remained superior on smaller cases. QUBO reformulations were also tested, but current annealers cannot accommodate stochastic UCPs due to hardware limits, and deterministic cases suffered from embedding overhead. Our study delineates where chance constrained UCPs can already be addressed with hybrid quantum classical methods, and where current quantum annealers remain fundamentally limited.

</details>


### [56] [Rethinking Collapse: Coupling Quantum States to Classical Bits with quasi-probabilities](https://arxiv.org/abs/2512.03929)
*Dagomir Kaszlikowski,Pawel Kurzynski*

Main category: quant-ph

TL;DR: 提出在修正的框架体系下用量子测量公式化，其中量子系统（单量子比特）直接耦合到经典测量比特，通过准双随机过程实现测量坍缩。


<details>
  <summary>Details</summary>
Motivation: 传统冯·诺依曼测量链需要无限耦合，本文旨在绕过这一复杂过程，通过将测量寄存器视为经典系统，同时通过准双随机结构捕捉测量的非经典特性。

Method: 将量子比特表示为两个经典比特的正概率分布p(aa')，测量装置用经典比特α描述，测量相互作用用准双随机过程S(bb'β|aa'α)建模，该过程作用于联合初始状态产生坍缩状态。

Result: 该方法能够产生正确的量子力学概率p(β)的测量结果β，成功实现了量子测量过程的公式化，避免了无限耦合链的复杂性。

Conclusion: 通过将量子系统直接耦合到经典测量比特，并采用准双随机过程，可以在经典框架内捕捉量子测量的本质特性，为量子测量问题提供了新的理论框架。

Abstract: We propose a formulation of quantum measurement within a modified framework of frames, in which a quantum system - a single qubit - is directly coupled to a classical measurement bit. The qubit is represented as a positive probability distribution over two classical bits, a and a', denoted by p(aa'). The measurement apparatus is described by a classical bit $α= \pm 1$, initialized in the pure distribution $p(α) = \frac{1}{2}(1 + α)$. The measurement interaction is modeled by a quasi-bistochastic process $ S(bb'β\mid aa'α)$ - a bistochastic map that may include negative transition probabilities, while acting on an entirely positive state space. When this process acts on the joint initial state $p(aa')p(α)$, it produces a collapsed state $p(bb'\midβ)$, yielding the measurement outcome $β$ with the correct quantum-mechanical probability $p(β)$. This approach bypasses the von Neumann chain of infinite couplings by treating the measurement register classically, while capturing the nonclassical nature of measurement through the quasi-bistochastic structure of the interaction.

</details>


### [57] [Phase-space open-systems dynamics of second-order nonlinear interactions with pulsed quantum light](https://arxiv.org/abs/2512.03933)
*Emanuel Hubenschmid,Victor Rueskov Christiansen*

Main category: quant-ph

TL;DR: 提出广义布洛赫-弥赛亚分解(GBMD)框架，用于高效计算宽带多模量子脉冲在二阶非线性相互作用中的输入输出关系，特别适用于输入输出模式数不同的开放量子系统。


<details>
  <summary>Details</summary>
Motivation: 宽带多模量子脉冲在二阶非线性相互作用中的理论描述非常复杂，因为基础相空间维度巨大。然而在许多情况下，非线性相互作用前后只有少数宽带（时间）模式是相关的。需要一种高效框架来计算非线性元件输入输出量子态之间的关系。

Method: 提出广义布洛赫-弥赛亚分解(GBMD)，将描述简化为相等数量的输入输出模式。GBMD能够通过将缩减输入量子脉冲的重新缩放维格纳函数与多元高斯相空间函数进行卷积，来计算输出态的多模维格纳函数。

Result: 以THz频率区的两个示例输入态（单宽带模式中的福克态和双模压缩真空态）为例，研究卷积和纠缠断裂导致的热化对输出维格纳函数的影响，通过计算输出维格纳函数的冯·诺依曼熵进行分析。

Conclusion: 该方法可用于优化宽带量子态的放大或频率转换，为超快时间尺度上光学量子态的生成和表征开辟了新途径。

Abstract: The theoretical description of broadband, multimode quantum pulses undergoing a second-order $χ^{(2)}$-nonlinear interaction can be quite intricate, due to the large dimensionality of the underlying phase space. However, in many cases only a few broadband (temporal) modes are relevant before and after the nonlinear interaction. Here we present an efficient framework to calculate the relation between the quantum states at the input and output of a nonlinear element in their respective relevant modes. Since the number of relevant input and output modes may differ, resulting in an open quantum system, we introduce the generalized Bloch-Messiah decomposition (GBMD), reducing the description to an equal number of input and output modes. The GBMD enables us to calculate the multimode Wigner function of the output state by convolving the rescaled Wigner function of the reduced input quantum pulse with a multivariate Gaussian phase-space function. We expand on this result by considering two examples input states: A Fock state in a single broadband mode and a two-mode squeezed vacuum, both in the THz-frequency regime, up-converted to a single output broadband mode of optical frequencies. We investigate the effect, the convolution and thermalization due to entanglement breakage have on the output Wigner function by calculating the von Neumann entropy of the output Wigner function. The methods presented here can be used to optimize the amplification or frequency conversion of broadband quantum states, opening an avenue to the generation and characterization of optical quantum states on ultrafast time scales.

</details>


### [58] [Thermodynamics of an Open $\mathcal{PT-}$Symmetric Quantum System](https://arxiv.org/abs/2512.03935)
*Baibhab Bose,Devvrat Tiwari,Subhashish Banerjee*

Main category: quant-ph

TL;DR: 该论文研究了PT对称哈密顿量系统的遍历性，在闭系统和开放系统中分析了能量提取能力，并检验了热力学定律的适用性。


<details>
  <summary>Details</summary>
Motivation: 研究PT对称量子系统的遍历性（ergotropy），即系统能够提取的最大功，特别是在非厄米哈密顿量背景下，分析开放系统中热力学定律的适用性。

Method: 对于满足特定反对易关系的PT对称哈密顿量子类，找到厄米基矢张成双正交能量本征矢，利用修正投影算符计算广义密度矩阵，获得闭系统遍历性；在开放系统场景下研究不同非厄米性机制下的遍历性。

Result: 建立了PT对称系统遍历性的计算框架，分析了开放系统中不同非厄米性机制对能量提取能力的影响，验证了热力学三定律在PT对称开放系统中的一致性。

Conclusion: PT对称量子系统在适当框架下可以定义和计算遍历性，开放系统中热力学定律仍然适用，为非厄米量子系统的能量提取和热力学性质提供了理论基础。

Abstract: For a subclass of a general $\mathcal{PT}-$symmetric Hamiltonian obeying anti-commutation relation with its conjugate, a Hermitian basis is found that spans the bi-orthonormal energy eigenvectors. Using the modified projectors constructed from these eigenvectors, the generalized density matrix of the $\mathcal{PT}-$symmetric evolution is calculated, and subsequently, ergotropy for a closed system is obtained. The $\mathcal{PT}-$symmetric system, in an open system scenario, is studied to understand ergotropy under different regimes of non-Hermiticity of the Hamiltonian. The consistency of the three laws of thermodynamics for the $\mathcal{PT}-$symmetric system in an open system scenario is also analyzed.

</details>


### [59] [Image Theory for the Single Bounce Quantum Gravimeter](https://arxiv.org/abs/2512.03953)
*Joachim Guyomard,Serge Reynaud,Pierre Cladé*

Main category: quant-ph

TL;DR: 本文为单反弹量子重力计建立了图像理论，通过连续能量基展开描述物质波包的自由落体和量子反弹，更清晰地解释量子干涉起源，并提供参数空间探索新工具，讨论自由落体加速度测量的预期精度。


<details>
  <summary>Details</summary>
Motivation: 为最近提出的单反弹量子重力计建立理论框架，以更清晰地理解量子干涉现象的物理起源，并为实验参数优化和测量精度评估提供理论工具。

Method: 采用连续能量基展开方法描述物质波包的自由落体和量子反弹过程，结合半经典估计分析量子干涉现象，开发参数空间探索的新理论工具。

Result: 建立了单反弹量子重力计的图像理论，提供了量子干涉起源的清晰物理解释，开发了参数空间分析工具，并评估了自由落体加速度测量的预期精度。

Conclusion: 该理论框架为单反弹量子重力计提供了完整的图像描述，不仅阐明了量子干涉的物理机制，还为实验设计和精度优化提供了重要理论指导。

Abstract: We develop an image theory for the recently proposed single-bounce quantum gravimeter. Free fall and quantum bounce of a matter wave-packet are described through decompositions over a basis of continuous energies. This leads to a much clearer interpretation of the origin of quantum interferences, associated to semi-classical estimations. We then give new tools to explore the space of parameters, and discuss the expected accuracy of the free-fall acceleration measurement.

</details>


### [60] [Entanglement Detection with Rotationally Covariant Measurements - From Compton Scattering to Lemonade](https://arxiv.org/abs/2512.03984)
*Marlene Funck,Ilija Funk,Tizian Schmidt,René Schwonnek*

Main category: quant-ph

TL;DR: 该研究提出了一种基于旋转对称性测量设备的偏振光子纠缠检测方法，推导了POVM表示，建立了量子信息参数r，并展示了柠檬苏打水散射实验可用于纠缠检测。


<details>
  <summary>Details</summary>
Motivation: 量子纠缠的准确高效检测是量子信息科学的核心挑战。研究旨在解决仅具有旋转对称性的测量设备如何检测偏振光子纠缠的问题。

Method: 推导了旋转对称性测量设备的显式POVM表示，建立了量子信息参数r；给出了康普顿散射中Klein-Nishina公式的POVM表述；开发了基于SDP的纠缠认证方法；分析了半设备无关场景；研究了EPR导引在单边对称约束下的认证；进行了旋转协变展示实验，分析偏振光在软饮料中的散射。

Result: 建立了旋转对称性测量设备的量子信息分类参数r；证明了虽然贝尔不等式违反在旋转协变测量中不可能，但EPR导引仍可在单边对称约束下认证；实验表明柠檬苏打水基探测器适用于纠缠检测。

Conclusion: 该研究为旋转对称性测量设备下的纠缠检测提供了系统框架，展示了实际材料（如柠檬苏打水）在量子信息处理中的潜在应用价值。

Abstract: The accurate and efficient detection of quantum entanglement remains a central challenge in quantum information science. In this work, we study the detection of entanglement of polarized photons for measurement devices that are solely specified by rotational symmetry. We derive explicit positive operator valued measures (POVMs) showing that from a quantum information perspective any such setting is classified by one real measurable parameter r. In Particular, we give a POVM formulation of the Klein--Nishina formula for Compton scattering of polarized photons. We provide an SDP-based entanglement certification method that operates on the full measured statistics and gives tight bounds, also considering semi-device independent scenarios. Furthermore, we show that, while Bell violations are impossible with rotationally covariant measurements, EPR steering can still be certified under one-sided symmetry constraints. Finally, we present a rotationally covariant showcase experiment, analyzing the scattering of polarized optical light in a selection of soft drinks. Our results suggest that lemonade-based detectors are suitable for entanglement detection.

</details>


### [61] [Fully quantum theory of strong-field driven tunable entangled multi-photon states in HHG](https://arxiv.org/abs/2512.03987)
*Sebastián de-la-Peña,Heiko Appel,Angel Rubio,Ofer Neufeld*

Main category: quant-ph

TL;DR: 本文开发了首个完整的量子理论来描述高次谐波产生中的纠缠现象，解决了先前理论无法准确预测纠缠特征的局限，并与实验数据首次达成定性一致。


<details>
  <summary>Details</summary>
Motivation: 量子高次谐波产生能够产生高光子数纠缠态，但现有理论（基于非相互作用的经典轨迹系综或微扰理论）无法正确描述纠缠等量子特性，存在理论层面的争议。

Method: 开发了完整的量子理论，精确求解光-物质相互作用哈密顿量，用于评估不同谐波发射光子之间的纠缠。首次考虑了经典自由度（如焦平均）对纠缠测量的影响。

Result: 理论首次与实验达成定性一致：R纠缠参数随激光功率增加而减小（对于阈下谐波）。发现纠缠随驱动功率振荡并呈现局部非经典极大值结构，且阈上谐波纠缠也呈现类似振荡行为。焦平均显著影响纠缠测量结果。

Conclusion: 该工作建立了探索高次谐波产生中纠缠特征的最先进理论框架，为分析和工程化XUV及超快区域中"真正量子"的多光子态铺平了道路，特别是在复杂物质系统中。

Abstract: Quantum high-harmonic generation (HHG) is a growing field of research with capabilities of providing high photon-number entangled states of light. However, there is an open debate regarding the theory level required for correctly describing the quantum aspects of HHG emission, such as squeezing or entanglement. Previous approaches have employed non-interacting classical ensembles of trajectories, or perturbation theory utilizing the classical trajectories as a starting point, missing out key entanglement features. In this Letter, we develop a full quantum theory for entanglement measures in HHG solving exactly the light-matter interaction Hamiltonian and employ it for evaluating the entanglement between emitted photons of different harmonics. For the first time, we reach qualitative agreement of theory with recent experiments showing that the R entanglement parameter decreases with increasing laser power for below-threshold harmonics. Our results indicate that fine-tuning the laser power could enhance HHG entanglement features, which are observed to oscillate with the driving power and exhibit local non-classical maxima structures. Similarly, our theory predicts that the oscillatory behavior of entanglement observed for below-threshold harmonics also appears for entanglement involving above-threshold harmonics. We also show that the long-range behavior of driven electronic trajectories can qualitatively change the resulting entanglement. Lastly, we show that focal averaging over classical degrees of freedom, which has thus far been ignored in quantum HHG theories, plays a key role in entanglement measures and can change the qualitative behavior of observables. Our work establishes the state-of-the art in exploring entanglement features in HHG, and paves way for analysis and engineering of 'truly-quantum' multi-photon states in the XUV and ultrafast regime for more complex matter systems.

</details>


### [62] [TARA Test-by-Adaptive-Ranks for Quantum Anomaly Detection with Conformal Prediction Guarantees](https://arxiv.org/abs/2512.04016)
*Davut Emre Tasar,Ceren Ocal Tasar*

Main category: quant-ph

TL;DR: TARA框架结合了保形预测和序列鞅测试，为量子异常检测提供分布无关的有效性保证，解决了现有量子密钥分发认证方法在有限样本和对抗场景下缺乏严格统计保证的问题。


<details>
  <summary>Details</summary>
Motivation: 量子密钥分发安全依赖于区分真实量子关联与经典窃听者模拟的能力，但现有认证方法在有限样本条件和对抗场景下缺乏严格的统计保证。需要开发具有分布无关有效性保证的量子异常检测框架。

Method: 提出了TARA框架，结合保形预测和序列鞅测试。包含两种方法：TARA-k基于Kolmogorov-Smirnov校准对抗局部隐变量零分布；TARA-m使用投注鞅进行流式检测，实现实时监控。理论证明在（上下文条件）可交换性下，保形p值保持均匀分布，即使对于强上下文量子数据也有效。

Result: 在IBM Torino（超导，CHSH=2.725）和IonQ Forte Enterprise（囚禁离子，CHSH=2.716）量子处理器上验证了跨平台鲁棒性，实现了高于经典CHSH界限2的36%安全边际。发现同分布校准会使检测性能虚高44个百分点，表明先前使用标准训练测试分割的量子认证研究可能系统性地高估了对抗鲁棒性。

Conclusion: TARA框架为量子认证提供了具有严格统计保证的分布无关方法，揭示了量子认证中同分布校准可能导致性能虚高的重要方法学问题，对量子认证和将分布无关方法应用于非经典数据的更广泛领域具有重要影响。

Abstract: Quantum key distribution (QKD) security fundamentally relies on the ability to distinguish genuine quantum correlations from classical eavesdropper simulations, yet existing certification methods lack rigorous statistical guarantees under finite-sample conditions and adversarial scenarios. We introduce TARA (Test by Adaptive Ranks), a novel framework combining conformal prediction with sequential martingale testing for quantum anomaly detection that provides distribution-free validity guarantees. TARA offers two complementary approaches. TARA k, based on Kolmogorov Smirnov calibration against local hidden variable (LHV) null distributions, achieving ROC AUC = 0.96 for quantum-classical discrimination. And TARA-m, employing betting martingales for streaming detection with anytime valid type I error control that enables real time monitoring of quantum channels. We establish theoretical guarantees proving that under (context conditional) exchangeability, conformal p-values remain uniformly distributed even for strongly contextual quantum data, confirming that quantum contextuality does not break conformal prediction validity a result with implications beyond quantum certification to any application of distribution-free methods to nonclassical data. Extensive validation on both IBM Torino (superconducting, CHSH = 2.725) and IonQ Forte Enterprise (trapped ion, CHSH = 2.716) quantum processors demonstrates cross-platform robustness, achieving 36% security margins above the classical CHSH bound of 2. Critically, our framework reveals a methodological concern affecting quantum certification more broadly: same-distribution calibration can inflate detection performance by up to 44 percentage points compared to proper cross-distribution calibration, suggesting that prior quantum certification studies using standard train test splits may have systematically overestimated adversarial robustness.

</details>


### [63] [Thermalization from quenching in coupled oscillators](https://arxiv.org/abs/2512.04028)
*M. Harinarayanan,Karthik Rajeev*

Main category: quant-ph

TL;DR: 提出一种有限时间协议，无需宏观热浴即可将量子谐振子从其基态热化。该方法使用第二个谐振子作为有效环境，通过突然改变频率和耦合实现热化。


<details>
  <summary>Details</summary>
Motivation: 在量子热力学实验和态制备中，需要快速、可控的热化方法。传统方法需要宏观热浴，而本文旨在开发一种无需宏观热浴的有限时间热化协议。

Method: 使用第二个谐振子作为有效环境，通过突然改变两个谐振子的频率和它们之间的耦合（sudden quenches）来实现热化。由于系统的高斯性质，热化条件简化为三个可解方程。

Result: 获得了精确解析解（针对一组离散温度）和数值解（针对其他情况）。任何目标温度都可以以任意精度近似，但需要在速度和精度之间权衡。协议简单，适用于实验。

Conclusion: 该协议为量子热力学实验和态制备提供了一种快速、可控的热化工具，无需宏观热浴，具有实际应用潜力。

Abstract: We introduce a finite-time protocol that thermalizes a quantum harmonic oscillator, initially in its ground state, without requiring a macroscopic bath. The method uses a second oscillator as an effective environment and implements sudden quenches of the oscillator frequencies and coupling. Owing to the Gaussian nature of the dynamics, the thermalization condition reduces to three solvable equations, yielding exact analytic solutions for a dense discrete set of temperatures and numerical solutions in all other cases. Any target temperature can be approximated with arbitrary precision, with a trade-off between speed and accuracy. The simplicity of the protocol makes it a promising tool for rapid, controlled thermalization in quantum thermodynamics experiments and state preparation.

</details>


### [64] [Closing the problem of which causal structures of up to six total nodes have a classical-quantum gap](https://arxiv.org/abs/2512.04058)
*Shashaank Khanna,Matthew Pusey,Roger Colbeck*

Main category: quant-ph

TL;DR: 该论文研究了最多6个节点的因果结构中唯一未解决的案例，证明了存在经典方法无法实现的量子关联，从而完成了6节点以下因果结构中量子非经典性的完整分类。


<details>
  <summary>Details</summary>
Motivation: 贝尔不等式的发现表明存在经典方法无法实现的量子关联，这对量子力学基础理论和实际应用都有重要意义。虽然贝尔的结果最初在简单的二分因果结构中证明，但类似结果在其他因果结构中也得到了展示。本研究旨在解决最多6个节点的因果结构中唯一未解决的问题：是否存在量子关联无法通过经典方法实现。

Method: 作者通过引入对关联的额外限制条件来研究目标因果结构。这种方法涉及在特定因果结构中施加约束条件，以证明量子关联的存在性。论文还使用其他因果结构进一步说明了该方法的应用。

Result: 在研究的因果结构中，作者成功证明了存在经典方法无法实现的量子关联。这一结果完成了最多6个节点的因果结构中量子非经典性的完整分类，填补了该领域的重要空白。

Conclusion: 该研究解决了最多6个节点因果结构中量子非经典性的最后一个开放问题，证明了在所有这类结构中，都存在经典方法无法实现的量子关联。这一成果完善了量子关联在简单因果结构中的理论框架，并为理解量子非经典性提供了新的方法视角。

Abstract: The discovery of Bell that there exist quantum correlations that cannot be reproduced classically is one of the most important in the foundations of quantum mechanics, as well as having practical implications. Bell's result was originally proven in a simple bipartite causal structure, but analogous results have also been shown in further causal structures. Here we study the only causal structure with six or fewer nodes in which the question of whether or not there exist quantum correlations that cannot be achieved classically was open. In this causal structure we show that such quantum correlations exist using a method that involves imposing additional restrictions on the correlations. This hence completes the picture of which causal structures of up to six nodes support non-classical quantum correlations. We also provide further illustrations of our method using other causal structures.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [65] [Physics-Informed Machine Learning for Steel Development: A Computational Framework and CCT Diagram Modelling](https://arxiv.org/abs/2512.03050)
*Peter Hedström,Victor Lamelas Cubero,Jón Sigurdsson,Viktor Österberg,Satish Kolli,Joakim Odqvist,Ziyong Hou,Wangzhong Mu,Viswanadh Gowtham Arigela*

Main category: cs.LG

TL;DR: 提出一个结合物理洞察与机器学习的计算框架，用于开发钢的物理信息连续冷却转变(CCT)模型，该模型在4100个图上训练，能高效生成CCT图并准确预测相变温度和相分类。


<details>
  <summary>Details</summary>
Motivation: 机器学习在材料科学中主要支持基于第一性原理数据的新化合物发现和制造过程优化，但将通用ML框架应用于复杂工业材料如钢仍具挑战。关键障碍是准确捕捉化学成分、工艺参数与微观结构和性能之间的复杂关系。

Method: 引入结合物理洞察与机器学习的计算框架，开发物理信息连续冷却转变(CCT)模型。模型在4100个CCT图上训练，验证采用文献和实验数据。

Result: 模型计算效率高，生成含100条冷却曲线的完整CCT图仅需5秒。在合金钢中表现出强泛化能力：所有相的相分类F1分数超过88%；相变温度回归中，除贝氏体(MAE 27°C)外，所有相的MAE低于20°C。

Conclusion: 该框架可扩展为通用数字孪生平台，结合补充模拟工具和针对性实验，将支持加速材料设计工作流程。

Abstract: Machine learning (ML) has emerged as a powerful tool for accelerating the computational design and production of materials. In materials science, ML has primarily supported large-scale discovery of novel compounds using first-principles data and digital twin applications for optimizing manufacturing processes. However, applying general-purpose ML frameworks to complex industrial materials such as steel remains a challenge. A key obstacle is accurately capturing the intricate relationship between chemical composition, processing parameters, and the resulting microstructure and properties. To address this, we introduce a computational framework that combines physical insights with ML to develop a physics-informed continuous cooling transformation (CCT) model for steels. Our model, trained on a dataset of 4,100 diagrams, is validated against literature and experimental data. It demonstrates high computational efficiency, generating complete CCT diagrams with 100 cooling curves in under 5 seconds. It also shows strong generalizability across alloy steels, achieving phase classification F1 scores above 88% for all phases. For phase transition temperature regression, it attains mean absolute errors (MAE) below 20 °C across all phases except bainite, which shows a slightly higher MAE of 27 °C. This framework can be extended with additional generic and customized ML models to establish a universal digital twin platform for heat treatment. Integration with complementary simulation tools and targeted experiments will further support accelerated materials design workflows.

</details>


### [66] [Mitigating hallucinations and omissions in LLMs for invertible problems: An application to hardware logic design automation](https://arxiv.org/abs/2512.03053)
*Andrew S. Cassidy,Guillaume Garreau,Jay Sivagnaname,Mike Grassi,Bernard Brezzo,John V. Arthur,Dharmendra S. Modha*

Main category: cs.LG

TL;DR: 论文提出一种利用LLM进行无损编码解码的方法，用于可逆问题（如逻辑条件表到HDL代码的转换），通过双向验证来减少LLM的幻觉和遗漏问题。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在代码生成任务中常见的幻觉和遗漏问题，特别是在硬件设计等关键领域，需要确保生成的代码准确无误。

Method: 采用无损编码-解码方法：1）用LLM将源域数据（如逻辑条件表）无损编码到目标域（如HDL代码）；2）再用LLM将生成的代码解码回源域；3）比较原始和重建的源数据来验证准确性。

Result: 使用7种不同LLM生成二维网络芯片路由器的完整HDL代码（13个单元，1500-2000行代码），通过重建验证显著提高了生成质量，不仅能确认正确生成的逻辑，还能检测错误生成的逻辑，甚至帮助开发者发现设计规范错误。

Conclusion: 无损编码-解码方法能有效缓解LLM的幻觉和遗漏问题，显著提高硬件设计等可逆问题中的生产力和代码质量，同时为开发者提供错误检测能力。

Abstract: We show for invertible problems that transform data from a source domain (for example, Logic Condition Tables (LCTs)) to a destination domain (for example, Hardware Description Language (HDL) code), an approach of using Large Language Models (LLMs) as a lossless encoder from source to destination followed by as a lossless decoder back to the source, comparable to lossless compression in information theory, can mitigate most of the LLM drawbacks of hallucinations and omissions. Specifically, using LCTs as inputs, we generate the full HDL for a two-dimensional network-on-chip router (13 units, 1500-2000 lines of code) using seven different LLMs, reconstruct the LCTs from the auto-generated HDL, and compare the original and reconstructed LCTs. This approach yields significant productivity improvements, not only confirming correctly generated LLM logic and detecting incorrectly generated LLM logic but also assisting developers in finding design specification errors.

</details>


### [67] [Energy-Efficient Federated Learning via Adaptive Encoder Freezing for MRI-to-CT Conversion: A Green AI-Guided Research](https://arxiv.org/abs/2512.03054)
*Ciro Benito Raggio,Lucia Migliorelli,Nils Skupien,Mathias Krohmer Zabaleta,Oliver Blanck,Francesco Cicone,Giuseppe Lucio Cascini,Paolo Zaffino,Maria Francesca Spadea*

Main category: cs.LG

TL;DR: 提出一种面向绿色AI的自适应层冻结策略，用于联邦学习中的MRI到CT转换任务，在保持模型性能的同时减少23%的能耗和碳排放


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽然能促进医疗平等，但其高资源需求会排除计算基础设施有限的机构，加剧医疗不平等。需要开发节能的联邦学习方法，使更多机构能够参与

Method: 提出自适应层冻结策略：基于轮次间编码器权重的相对差异监控，选择性冻结编码器权重；采用基于耐心的机制，仅在更新持续较小时才进行冻结；使用CodeCarbon库跟踪能耗和碳排放

Result: 相比未冻结的对照方法，训练时间、总能耗和CO2eq排放减少达23%；MRI-to-CT转换性能保持稳定，MAE仅有小幅变化；5种架构中3种无显著差异，2种有显著改进

Conclusion: 该工作为满足临床需求同时确保气候、社会和经济可持续性的深度学习框架提供了新范式，为推进AI驱动医疗中的隐私、公平和正义奠定了基础

Abstract: Federated Learning (FL) holds the potential to advance equality in health by enabling diverse institutions to collaboratively train deep learning (DL) models, even with limited data. However, the significant resource requirements of FL often exclude centres with limited computational infrastructure, further widening existing healthcare disparities. To address this issue, we propose a Green AI-oriented adaptive layer-freezing strategy designed to reduce energy consumption and computational load while maintaining model performance. We tested our approach using different federated architectures for Magnetic Resonance Imaging (MRI)-to-Computed Tomography (CT) conversion. The proposed adaptive strategy optimises the federated training by selectively freezing the encoder weights based on the monitored relative difference of the encoder weights from round to round. A patience-based mechanism ensures that freezing only occurs when updates remain consistently minimal. The energy consumption and CO2eq emissions of the federation were tracked using the CodeCarbon library. Compared to equivalent non-frozen counterparts, our approach reduced training time, total energy consumption and CO2eq emissions by up to 23%. At the same time, the MRI-to-CT conversion performance was maintained, with only small variations in the Mean Absolute Error (MAE). Notably, for three out of the five evaluated architectures, no statistically significant differences were observed, while two architectures exhibited statistically significant improvements. Our work aligns with a research paradigm that promotes DL-based frameworks meeting clinical requirements while ensuring climatic, social, and economic sustainability. It lays the groundwork for novel FL evaluation frameworks, advancing privacy, equity and, more broadly, justice in AI-driven healthcare.

</details>


### [68] [Physics-informed self-supervised learning for predictive modeling of coronary artery digital twins](https://arxiv.org/abs/2512.03055)
*Xiaowu Sun,Thabo Mahendiran,Ortal Senouf,Denise Auberson,Bernard De Bruyne,Stephane Fournier,Olivier Muller,Pascal Frossard,Emmanuel Abbe,Dorina Thanou*

Main category: cs.LG

TL;DR: PINS-CAD：基于物理信息自监督学习的框架，通过预训练图神经网络预测冠脉压力和血流，无需计算流体动力学或标注数据，在临床数据上微调后能预测心血管事件，优于传统风险评分。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病是全球主要死因，冠心病是最常见形式，需要早期风险预测。传统3D冠脉数字孪生依赖计算密集的计算流体动力学，可扩展性有限；数据驱动方法受限于标注数据稀缺和缺乏生理先验知识。

Method: 提出PINS-CAD物理信息自监督学习框架：预训练图神经网络于20万个合成冠脉数字孪生，基于1D Navier-Stokes方程和压降定律预测压力和血流，无需CFD或标注数据；然后在635名患者的多中心FAME2研究临床数据上微调。

Result: 在预测未来心血管事件方面达到AUC 0.73，优于临床风险评分和数据驱动基线；生成空间分辨的压力和血流储备分数曲线，提供可解释的生物标志物；物理信息预训练提高了样本效率并产生生理有意义的表示。

Conclusion: 通过将物理先验嵌入几何深度学习，PINS-CAD将常规血管造影转化为无模拟、生理感知的框架，实现可扩展的预防性心脏病学。

Abstract: Cardiovascular disease is the leading global cause of mortality, with coronary artery disease (CAD) as its most prevalent form, necessitating early risk prediction. While 3D coronary artery digital twins reconstructed from imaging offer detailed anatomy for personalized assessment, their analysis relies on computationally intensive computational fluid dynamics (CFD), limiting scalability. Data-driven approaches are hindered by scarce labeled data and lack of physiological priors. To address this, we present PINS-CAD, a physics-informed self-supervised learning framework. It pre-trains graph neural networks on 200,000 synthetic coronary digital twins to predict pressure and flow, guided by 1D Navier-Stokes equations and pressure-drop laws, eliminating the need for CFD or labeled data. When fine-tuned on clinical data from 635 patients in the multicenter FAME2 study, PINS-CAD predicts future cardiovascular events with an AUC of 0.73, outperforming clinical risk scores and data-driven baselines. This demonstrates that physics-informed pretraining boosts sample efficiency and yields physiologically meaningful representations. Furthermore, PINS-CAD generates spatially resolved pressure and fractional flow reserve curves, providing interpretable biomarkers. By embedding physical priors into geometric deep learning, PINS-CAD transforms routine angiography into a simulation-free, physiology-aware framework for scalable, preventive cardiology.

</details>


### [69] [ATHENA: Agentic Team for Hierarchical Evolutionary Numerical Algorithms](https://arxiv.org/abs/2512.03476)
*Juan Diego Toscano,Daniel T. Chen,George Em Karniadakis*

Main category: cs.LG

TL;DR: ATHENA是一个自主实验室框架，通过知识驱动的HENA循环（建模为上下文赌博机问题）管理端到端计算研究生命周期，在科学计算和科学机器学习中实现超人性能，验证误差达10^{-14}。


<details>
  <summary>Details</summary>
Motivation: 解决科学计算和科学机器学习中理论概念化与计算实现之间的差距，这是一个主要瓶颈。当前需要超越标准自动化的系统，能够自主进行数学分析、诊断和优化。

Method: 引入ATHENA框架，核心是HENA循环（分层进化数值算法），建模为上下文赌博机问题。系统作为在线学习者分析先前试验，从组合空间中选择结构动作，通过专家蓝图（如通用逼近、物理信息约束）指导，将动作转换为可执行代码以生成科学奖励。结合混合符号-数值工作流（如PINNs与FEM耦合）。

Result: 在科学计算中自主识别数学对称性以获得精确解析解，在基础模型失败时推导稳定数值求解器。在科学机器学习中执行深度诊断处理不适定问题。框架实现超人性能，验证误差达到10^{-14}。通过"人在回路"协作干预，结果可提高一个数量级。

Conclusion: ATHENA代表了从实现机制到方法创新的范式转变，加速科学发现。它超越了标准自动化，能够自主进行复杂的科学推理和问题解决，同时支持人机协作以弥补系统局限性。

Abstract: Bridging the gap between theoretical conceptualization and computational implementation is a major bottleneck in Scientific Computing (SciC) and Scientific Machine Learning (SciML). We introduce ATHENA (Agentic Team for Hierarchical Evolutionary Numerical Algorithms), an agentic framework designed as an Autonomous Lab to manage the end-to-end computational research lifecycle. Its core is the HENA loop, a knowledge-driven diagnostic process framed as a Contextual Bandit problem. Acting as an online learner, the system analyzes prior trials to select structural `actions' ($A_n$) from combinatorial spaces guided by expert blueprints (e.g., Universal Approximation, Physics-Informed constraints). These actions are translated into executable code ($S_n$) to generate scientific rewards ($R_n$). ATHENA transcends standard automation: in SciC, it autonomously identifies mathematical symmetries for exact analytical solutions or derives stable numerical solvers where foundation models fail. In SciML, it performs deep diagnosis to tackle ill-posed formulations and combines hybrid symbolic-numeric workflows (e.g., coupling PINNs with FEM) to resolve multiphysics problems. The framework achieves super-human performance, reaching validation errors of $10^{-14}$. Furthermore, collaborative ``human-in-the-loop" intervention allows the system to bridge stability gaps, improving results by an order of magnitude. This paradigm shift focuses from implementation mechanics to methodological innovation, accelerating scientific discovery.

</details>


### [70] [Delta Sampling: Data-Free Knowledge Transfer Across Diffusion Models](https://arxiv.org/abs/2512.03056)
*Zhidong Gao,Zimeng Pan,Yuhang Yao,Chenyue Xie,Wei Wei*

Main category: cs.LG

TL;DR: Delta Sampling (DS) 是一种在推理时实现不同架构基础模型间知识迁移的方法，无需原始训练数据，通过利用模型预测差异来指导新基础模型的去噪过程。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型生态系统中的适配组件（如LoRA、LyCORIS、ControlNet）与特定基础模型紧密耦合，当基础模型升级（如从SD 1.x到2.x）时难以重用，因为模型参数和架构发生了重大变化。

Method: Delta Sampling (DS) 在推理时操作，利用基础模型适配前后的预测差异（delta），然后将这个差异用于指导新基础模型的去噪过程，实现跨不同架构基础模型的知识迁移。

Result: 在不同SD版本上的评估表明，DS在不同采样策略下都能一致地改善创建期望效果（如视觉风格、语义概念和结构）的能力，证明了其作为即插即用知识迁移机制的有效性。

Conclusion: DS为基于扩散的图像合成提供了一种有效的、即插即用的知识迁移机制，能够解决适配组件与特定基础模型紧密耦合的问题，实现跨不同架构模型的知识重用。

Abstract: Diffusion models like Stable Diffusion (SD) drive a vibrant open-source ecosystem including fully fine-tuned checkpoints and parameter-efficient adapters such as LoRA, LyCORIS, and ControlNet. However, these adaptation components are tightly coupled to a specific base model, making them difficult to reuse when the base model is upgraded (e.g., from SD 1.x to 2.x) due to substantial changes in model parameters and architecture. In this work, we propose Delta Sampling (DS), a novel method that enables knowledge transfer across base models with different architectures, without requiring access to the original training data. DS operates entirely at inference time by leveraging the delta: the difference in model predictions before and after the adaptation of a base model. This delta is then used to guide the denoising process of a new base model. We evaluate DS across various SD versions, demonstrating that DS achieves consistent improvements in creating desired effects (e.g., visual styles, semantic concepts, and structures) under different sampling strategies. These results highlight DS as an effective, plug-and-play mechanism for knowledge transfer in diffusion-based image synthesis. Code:~ https://github.com/Zhidong-Gao/DeltaSampling

</details>


### [71] [Quantum-Classical Physics-Informed Neural Networks for Solving Reservoir Seepage Equations](https://arxiv.org/abs/2512.03923)
*Xiang Rao,Yina Liu,Yuxuan Shen*

Main category: cs.LG

TL;DR: 提出一种结合量子电路与经典网络的混合物理信息神经网络（QCPINN），用于求解油藏渗流偏微分方程，相比传统PINNs参数更少、精度更高。


<details>
  <summary>Details</summary>
Motivation: 传统数值方法存在网格依赖误差和计算成本高的问题，经典物理信息神经网络（PINNs）在参数效率、高维表达和强非线性拟合方面存在瓶颈。需要开发更高效的求解方法。

Method: 提出离散变量（DV）-电路量子-经典物理信息神经网络（QCPINN），将经典预处理/后处理网络与DV量子核心集成，利用量子叠加和纠缠增强高维特征映射，同时嵌入物理约束确保解的一致性。测试了三种量子电路拓扑结构（级联、交叉网格、交替）。

Result: QCPINNs在三种典型油藏渗流模型中均实现了高预测精度且参数少于经典PINNs。交替拓扑在非均质单相流和两相BL方程模拟中表现最佳，级联拓扑在对流-扩散-吸附耦合的组分流中表现最优。

Conclusion: 验证了QCPINN在油藏工程应用中的可行性，弥合了量子计算研究与油气工程工业实践之间的差距。

Abstract: Solving partial differential equations (PDEs) for reservoir seepage is critical for optimizing oil and gas field development and predicting production performance. Traditional numerical methods suffer from mesh-dependent errors and high computational costs, while classical Physics-Informed Neural Networks (PINNs) face bottlenecks in parameter efficiency, high-dimensional expression, and strong nonlinear fitting. To address these limitations, we propose a Discrete Variable (DV)-Circuit Quantum-Classical Physics-Informed Neural Network (QCPINN) and apply it to three typical reservoir seepage models for the first time: the pressure diffusion equation for heterogeneous single-phase flow, the nonlinear Buckley-Leverett (BL) equation for two-phase waterflooding, and the convection-diffusion equation for compositional flow considering adsorption. The QCPINN integrates classical preprocessing/postprocessing networks with a DV quantum core, leveraging quantum superposition and entanglement to enhance high-dimensional feature mapping while embedding physical constraints to ensure solution consistency. We test three quantum circuit topologies (Cascade, Cross-mesh, Alternate) and demonstrate through numerical experiments that QCPINNs achieve high prediction accuracy with fewer parameters than classical PINNs. Specifically, the Alternate topology outperforms others in heterogeneous single-phase flow and two-phase BL equation simulations, while the Cascade topology excels in compositional flow with convection-dispersion-adsorption coupling. Our work verifies the feasibility of QCPINN for reservoir engineering applications, bridging the gap between quantum computing research and industrial practice in oil and gas engineering.

</details>


### [72] [Dynamical Properties of Tokens in Self-Attention and Effects of Positional Encoding](https://arxiv.org/abs/2512.03058)
*Duy-Tung Pham,An The Nguyen,Viet-Hoang Tran,Nhan-Phu Chung,Xin T. Tong,Tan M. Nguyen,Thieu N. Vo*

Main category: cs.LG

TL;DR: 研究预训练Transformer中token的动态特性，分析其连续时间极限的动力学系统，提出改进Transformer架构的简单方法


<details>
  <summary>Details</summary>
Motivation: 探索预训练Transformer模型中token的动态特性，理解token随时间移动的规律，以及如何利用这些特性改进Transformer模型

Method: 分析预训练模型的连续时间极限动力学系统，研究token收敛或发散的条件，考察绝对位置编码和旋转位置编码对动态机制的影响

Result: 提出了比先前工作更广泛、更适用于实际模型的充分条件，发现收敛情景会损害模型性能，提出了缓解绝对和旋转位置编码中收敛行为的简单架构改进

Conclusion: 研究结果为改进Transformer模型提供了理论基础和设计原则，提出的简单架构改进能有效缓解收敛行为对性能的不利影响

Abstract: This paper investigates the dynamical properties of tokens in pre-trained Transformer models and explores their application to improving Transformers. To this end, we analyze the dynamical system governing the continuous-time limit of the pre-trained model and characterize the asymptotic behavior of its solutions. Specifically, we characterize when tokens move closer to or farther from one another over time, depending on the model parameters. We provide sufficient conditions, based on these parameters, to identify scenarios where tokens either converge to zero or diverge to infinity. Unlike prior works, our conditions are broader in scope and more applicable to real-world models. Furthermore, we investigate how different forms of positional encoding -- specifically absolute and rotary -- affect these dynamical regimes. Empirical evidence reveals that the convergence scenario adversely impacts model performance. Motivated by these insights, we propose simple refinements to Transformer architectures that mitigate convergence behavior in models with absolute or rotary positional encoding. These findings support theoretical foundations and design principles for improving Transformer models.

</details>


### [73] [Safe and Sustainable Electric Bus Charging Scheduling with Constrained Hierarchical DRL](https://arxiv.org/abs/2512.03059)
*Jiaju Qi,Lei Lei,Thorsteinn Jonsson,Dusit Niyato*

Main category: cs.LG

TL;DR: 提出一种安全的分层深度强化学习框架，用于解决多源不确定性下的电动公交车充电调度问题，通过DAC-MAPPO-Lagrangian算法实现成本最小化和安全运行。


<details>
  <summary>Details</summary>
Motivation: 电动公交车与光伏等可再生能源结合是实现低碳公共交通的重要途径，但在实际运行中面临光伏发电不确定性、动态电价、可变行驶时间和有限充电设施等多重挑战，需要优化充电调度以最小化运营成本并确保电池不耗尽的安全运行。

Method: 将问题建模为带约束的马尔可夫决策过程，提出DAC-MAPPO-Lagrangian分层深度强化学习算法：高层采用集中式PPO-Lagrangian学习安全充电桩分配策略，低层采用MAPPO-Lagrangian在CTDE范式下学习分散式充电功率决策。

Result: 基于真实数据的实验表明，该方法在成本最小化和安全合规性方面优于现有基线方法，同时保持了快速的收敛速度。

Conclusion: 提出的安全分层深度强化学习框架能有效解决多源不确定性下的电动公交车充电调度问题，为可持续公共交通系统提供了有前景的解决方案。

Abstract: The integration of Electric Buses (EBs) with renewable energy sources such as photovoltaic (PV) panels is a promising approach to promote sustainable and low-carbon public transportation. However, optimizing EB charging schedules to minimize operational costs while ensuring safe operation without battery depletion remains challenging - especially under real-world conditions, where uncertainties in PV generation, dynamic electricity prices, variable travel times, and limited charging infrastructure must be accounted for. In this paper, we propose a safe Hierarchical Deep Reinforcement Learning (HDRL) framework for solving the EB Charging Scheduling Problem (EBCSP) under multi-source uncertainties. We formulate the problem as a Constrained Markov Decision Process (CMDP) with options to enable temporally abstract decision-making. We develop a novel HDRL algorithm, namely Double Actor-Critic Multi-Agent Proximal Policy Optimization Lagrangian (DAC-MAPPO-Lagrangian), which integrates Lagrangian relaxation into the Double Actor-Critic (DAC) framework. At the high level, we adopt a centralized PPO-Lagrangian algorithm to learn safe charger allocation policies. At the low level, we incorporate MAPPO-Lagrangian to learn decentralized charging power decisions under the Centralized Training and Decentralized Execution (CTDE) paradigm. Extensive experiments with real-world data demonstrate that the proposed approach outperforms existing baselines in both cost minimization and safety compliance, while maintaining fast convergence speed.

</details>


### [74] [A Large Scale Heterogeneous Treatment Effect Estimation Framework and Its Applications of Users' Journey at Snap](https://arxiv.org/abs/2512.03060)
*Jing Pan,Li Shi,Paul Lo*

Main category: cs.LG

TL;DR: 提出大规模工业级HTE/CATE估计框架，利用数亿Snapchat用户实验数据，通过跨实验整合发现潜在用户特征，实现稳定的大规模处理效应估计


<details>
  <summary>Details</summary>
Motivation: 传统方法假设处理效应对所有用户相同，但实际中用户对广告等干预的反应存在异质性。需要大规模框架来准确估计异质性处理效应，以更好地理解用户特征和优化广告策略

Method: 开发工业级HTE估计框架，包括实验选择、基础学习器设计和增量训练等核心组件。利用数百个实验的数亿Snapchat用户数据，通过跨实验整合发现潜在用户特征

Result: 框架成功发现先前无法测量的潜在用户特征，产生稳定的处理效应估计。应用包括用户对广告的影响性和敏感性分析。在线A/B测试显示，使用影响性分数进行定向广告的效果提升超过典型显著水平的6倍

Conclusion: 该大规模HTE框架能够有效估计异质性处理效应，发现潜在用户特征，并在实际应用中显著提升广告定向效果，为工业级因果推断提供了可行方案

Abstract: Heterogeneous Treatment Effect (HTE) and Conditional Average Treatment Effect (CATE) models relax the assumption that treatment effects are the same for every user. We present a large scale industrial framework for estimating HTE using experimental data from hundreds of millions of Snapchat users. By combining results across many experiments, the framework uncovers latent user characteristics that were previously unmeasurable and produces stable treatment effect estimates at scale.
  We describe the core components that enabled this system, including experiment selection, base learner design, and incremental training. We also highlight two applications: user influenceability to ads and user sensitivity to ads. An online A/B test using influenceability scores for targeting showed an improvement on key business metrics that is more than six times larger than what is typically considered significant.

</details>


### [75] [Globally optimized SVD compression of LLMs via Fermi-function-based rank selection and gauge fixing](https://arxiv.org/abs/2512.03062)
*Roman Rausch,David Jansen,Sukhbinder Singh,Román Orús*

Main category: cs.LG

TL;DR: 提出两种基于物理启发的改进方法用于LLM的SVD压缩：FermiGrad通过费米函数将离散截断转为连续优化确定全局最优层秩；PivGa利用参数化中的规范自由度对低秩因子进行无损压缩。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型计算资源需求高，低秩分解（如SVD）是LLM压缩的有前景方法，但存在层秩选择和参数冗余等实际障碍。

Method: 1) FermiGrad：基于梯度下降算法，使用费米函数将离散奇异值截断松弛为连续优化，确定全局最优层秩；2) PivGa：利用低秩因子参数化中的规范自由度，对低秩因子进行无损压缩。

Result: 未在摘要中明确说明具体结果，但提出的两种方法旨在解决SVD压缩中的层秩选择和参数冗余问题。

Conclusion: 通过物理启发的改进方法，可以更有效地进行LLM的SVD压缩，解决现有方法中的实际障碍。

Abstract: Large Language Models (LLMs) are very demanding in terms of their computational resources. Low-rank decompositions of LLM weights, e.g. via Singular Value Decomposition (SVD), is a promising approach for LLM compression, but presents several practical hurdles, e.g. selecting appropriate layer-wise ranks and getting rid of its parameter redundancy. In this work, we present two physics-inspired improvements to SVD LLM compression: (1) \textbf{FermiGrad}, a gradient-descent algorithm that determines globally optimal layer-wise ranks by relaxing the discrete singular-value truncation into a continuous optimization using the Fermi function; (2) \textbf{PivGa}, an additional \textit{lossless} compression of the low-rank factors that exploits the intrinsic gauge freedom in their parametrization.

</details>


### [76] [Optimizing Life Sciences Agents in Real-Time using Reinforcement Learning](https://arxiv.org/abs/2512.03065)
*Nihir Chadderwala*

Main category: cs.LG

TL;DR: 提出一个结合AWS Strands Agents与Thompson Sampling上下文bandits的框架，让AI代理仅从用户反馈中学习最优决策策略，在生命科学领域实现15-30%的用户满意度提升。


<details>
  <summary>Details</summary>
Motivation: 生命科学领域的生成式AI代理面临关键挑战：如何为从简单事实性问题到复杂机制推理的多样化查询确定最优方法。传统方法依赖固定规则或昂贵的标注训练数据，都无法适应变化条件或用户偏好。

Method: 结合AWS Strands Agents与Thompson Sampling上下文bandits的框架，通过用户反馈学习优化三个关键维度：生成策略选择（直接生成 vs. 思维链）、工具选择（文献搜索、药物数据库等）和领域路由（药理学、分子生物学、临床专家）。

Result: 在生命科学查询的实证评估中，相比随机基线实现15-30%的用户满意度提升，在20-30个查询后出现清晰的学习模式。

Conclusion: 该方法无需真实标签，能持续适应用户偏好，为代理AI系统中的探索-利用困境提供了原则性解决方案。

Abstract: Generative AI agents in life sciences face a critical challenge: determining the optimal approach for diverse queries ranging from simple factoid questions to complex mechanistic reasoning. Traditional methods rely on fixed rules or expensive labeled training data, neither of which adapts to changing conditions or user preferences. We present a novel framework that combines AWS Strands Agents with Thompson Sampling contextual bandits to enable AI agents to learn optimal decision-making strategies from user feedback alone. Our system optimizes three key dimensions: generation strategy selection (direct vs. chain-of-thought), tool selection (literature search, drug databases, etc.), and domain routing (pharmacology, molecular biology, clinical specialists). Through empirical evaluation on life science queries, we demonstrate 15-30\% improvement in user satisfaction compared to random baselines, with clear learning patterns emerging after 20-30 queries. Our approach requires no ground truth labels, adapts continuously to user preferences, and provides a principled solution to the exploration-exploitation dilemma in agentic AI systems.

</details>


### [77] [Hierarchical clustering of complex energy systems using pretopology](https://arxiv.org/abs/2512.03069)
*Loup-Noe Levy,Jeremie Bosom,Guillaume Guerard,Soufian Ben Amor,Marc Bui,Hai Tran*

Main category: cs.LG

TL;DR: 使用预拓扑学建模能源消费剖面，开发基于预拓扑空间特性的多准则分层分类算法，实现建筑能耗的自动化分类与优化管理


<details>
  <summary>Details</summary>
Motivation: 针对大规模分布式建筑能耗管理的需求，传统逐栋审计方法成本高、耗时长，需要开发自动化方法来建立有效的能耗推荐系统

Method: 采用预拓扑学建模能耗剖面，开发基于预拓扑空间特性的多准则分层分类算法，并实现为Python库。使用三个数据集进行验证：二维空间点集、生成的时间序列和400个真实能耗站点的消费时间序列

Result: 算法在点数据集上能根据位置和大小识别聚类；在生成的时间序列上使用皮尔逊相关系数，调整兰德指数(ARI)达到1，表明完美聚类效果

Conclusion: 预拓扑学和多准则分层分类算法能有效建模和分类大规模建筑能耗剖面，为自动化能耗管理推荐系统提供可行解决方案

Abstract: This article attempts answering the following problematic: How to model and classify energy consumption profiles over a large distributed territory to optimize the management of buildings' consumption?
  Doing case-by-case in depth auditing of thousands of buildings would require a massive amount of time and money as well as a significant number of qualified people. Thus, an automated method must be developed to establish a relevant and effective recommendations system.
  To answer this problematic, pretopology is used to model the sites' consumption profiles and a multi-criterion hierarchical classification algorithm, using the properties of pretopological space, has been developed in a Python library.
  To evaluate the results, three data sets are used: A generated set of dots of various sizes in a 2D space, a generated set of time series and a set of consumption time series of 400 real consumption sites from a French Energy company.
  On the point data set, the algorithm is able to identify the clusters of points using their position in space and their size as parameter. On the generated time series, the algorithm is able to identify the time series clusters using Pearson's correlation with an Adjusted Rand Index (ARI) of 1.

</details>


### [78] [Mixed Data Clustering Survey and Challenges](https://arxiv.org/abs/2512.03070)
*Guillaume Guerard,Sonia Djebali*

Main category: cs.LG

TL;DR: 提出基于预拓扑空间的混合数据聚类方法，解决大数据环境下数值与分类变量混合数据的聚类挑战。


<details>
  <summary>Details</summary>
Motivation: 大数据时代需要处理数值和分类变量混合的异构数据，传统聚类方法难以有效处理这种复杂性，需要专门针对混合数据的聚类方法。

Method: 基于预拓扑空间理论开发新的聚类方法，能够处理混合数据类型，并与经典数值聚类算法和现有预拓扑方法进行基准测试。

Result: 通过基准测试评估了所提方法的性能和有效性，验证了其在大数据范式下的适用性。

Conclusion: 基于预拓扑空间的聚类方法为解决混合数据聚类问题提供了有效途径，特别是在需要可解释性和层次结构的应用场景中。

Abstract: The advent of the big data paradigm has transformed how industries manage and analyze information, ushering in an era of unprecedented data volume, velocity, and variety. Within this landscape, mixed-data clustering has become a critical challenge, requiring innovative methods that can effectively exploit heterogeneous data types, including numerical and categorical variables. Traditional clustering techniques, typically designed for homogeneous datasets, often struggle to capture the additional complexity introduced by mixed data, underscoring the need for approaches specifically tailored to this setting. Hierarchical and explainable algorithms are particularly valuable in this context, as they provide structured, interpretable clustering results that support informed decision-making. This paper introduces a clustering method grounded in pretopological spaces. In addition, benchmarking against classical numerical clustering algorithms and existing pretopological approaches yields insights into the performance and effectiveness of the proposed method within the big data paradigm.

</details>


### [79] [PretopoMD: Pretopology-based Mixed Data Hierarchical Clustering](https://arxiv.org/abs/2512.03071)
*Loup-Noe Levy,Guillaume Guerard,Sonia Djebali,Soufian Ben Amor*

Main category: cs.LG

TL;DR: 提出一种基于预拓扑的新算法，无需降维即可聚类混合数据，使用析取范式构建可定制逻辑规则，实现可解释的层次聚类。


<details>
  <summary>Details</summary>
Motivation: 传统聚类方法在处理混合数据时通常需要降维，这会损失数据完整性。现有方法在聚类可解释性方面存在不足，需要一种能直接从原始数据构建有意义且可解释的聚类的方法。

Method: 基于预拓扑的算法，利用析取范式构建可定制的逻辑规则和可调超参数，支持用户定义的层次聚类构建，直接从原始数据中形成聚类而不需要降维。

Result: 通过层次树状图分析和聚类指标比较，该方法在准确性和可解释性方面表现出优越性能，能有效构建有意义的聚类，解决了聚类数据可解释性问题。

Conclusion: 该工作通过避免传统降维技术和创新使用逻辑规则，在混合数据聚类领域做出了重要贡献，既增强了聚类形成又提高了聚类清晰度。

Abstract: This article presents a novel pretopology-based algorithm designed to address the challenges of clustering mixed data without the need for dimensionality reduction. Leveraging Disjunctive Normal Form, our approach formulates customizable logical rules and adjustable hyperparameters that allow for user-defined hierarchical cluster construction and facilitate tailored solutions for heterogeneous datasets. Through hierarchical dendrogram analysis and comparative clustering metrics, our method demonstrates superior performance by accurately and interpretably delineating clusters directly from raw data, thus preserving data integrity. Empirical findings highlight the algorithm's robustness in constructing meaningful clusters and reveal its potential in overcoming issues related to clustered data explainability. The novelty of this work lies in its departure from traditional dimensionality reduction techniques and its innovative use of logical rules that enhance both cluster formation and clarity, thereby contributing a significant advancement to the discourse on clustering mixed data.

</details>


### [80] [Model-Agnostic Fairness Regularization for GNNs with Incomplete Sensitive Information](https://arxiv.org/abs/2512.03074)
*Mahdi Tavassoli Kejani,Fadi Dornaika,Jean-Michel Loubes*

Main category: cs.LG

TL;DR: 提出一种模型无关的公平正则化框架，用于处理图神经网络中敏感属性部分可用的现实场景，在保持分类性能的同时显著减少偏见。


<details>
  <summary>Details</summary>
Motivation: 现有公平感知的GNN方法假设训练期间所有节点的敏感属性完全可用，但这在现实中因隐私和数据收集限制而难以实现。需要解决敏感属性部分可用场景下的公平性问题。

Method: 提出一种模型无关的公平正则化框架，将平等机会和统计奇偶性作为可微正则化项整合到目标函数中，适用于敏感属性仅部分可用的场景。

Result: 在五个真实世界基准数据集上的实验表明，该方法在关键公平性指标上显著减少偏见，同时保持竞争力的节点分类性能，在公平性-准确性权衡方面优于基线模型。

Conclusion: 该框架有效解决了敏感属性部分可用场景下的GNN公平性问题，实现了良好的公平性-准确性平衡，为实际应用提供了可行的解决方案。

Abstract: Graph Neural Networks (GNNs) have demonstrated exceptional efficacy in relational learning tasks, including node classification and link prediction. However, their application raises significant fairness concerns, as GNNs can perpetuate and even amplify societal biases against protected groups defined by sensitive attributes such as race or gender. These biases are often inherent in the node features, structural topology, and message-passing mechanisms of the graph itself. A critical limitation of existing fairness-aware GNN methods is their reliance on the strong assumption that sensitive attributes are fully available for all nodes during training--a condition that poses a practical impediment due to privacy concerns and data collection constraints. To address this gap, we propose a novel, model-agnostic fairness regularization framework designed for the realistic scenario where sensitive attributes are only partially available. Our approach formalizes a fairness-aware objective function that integrates both equal opportunity and statistical parity as differentiable regularization terms. Through a comprehensive empirical evaluation across five real-world benchmark datasets, we demonstrate that the proposed method significantly mitigates bias across key fairness metrics while maintaining competitive node classification performance. Results show that our framework consistently outperforms baseline models in achieving a favorable fairness-accuracy trade-off, with minimal degradation in predictive accuracy. The datasets and source code will be publicly released at https://github.com/mtavassoli/GNN-FC.

</details>


### [81] [Risk-Entropic Flow Matching](https://arxiv.org/abs/2512.03078)
*Vahid R. Ramezani,Benjamin Englard*

Main category: cs.LG

TL;DR: 论文提出将倾斜风险（tilted risk）应用于流匹配（Flow Matching），通过log-exponential变换改进标准平方损失，以更好地捕捉数据流形的几何结构和少数分支。


<details>
  <summary>Details</summary>
Motivation: 标准流匹配（FM）使用均方误差损失，将所有到达同一时空点的速度目标压缩为单一条件均值，忽略了高阶条件信息（方差、偏度、多模态），这些信息编码了数据流形的精细几何结构和少数分支。

Method: 将标准风险敏感（log-exponential）变换应用于条件FM损失，得到倾斜风险损失，该损失是每个时空点上有意义的条件熵FM目标的上界。对梯度进行小阶展开得到两个可解释的一阶修正：FM残差的协方差预处理和偏好非对称或稀有分支的偏尾项。

Result: 在专门设计用于探测模糊性和尾部的合成数据上，风险敏感损失在统计指标上优于标准整流FM，并能更忠实地恢复几何结构。

Conclusion: 倾斜风险损失为流匹配提供了一种改进方法，能够更好地捕捉数据流形的精细几何特征和少数分支，解决了标准平方损失忽略高阶条件信息的问题。

Abstract: Tilted (entropic) risk, obtained by applying a log-exponential transform to a base loss, is a well established tool in statistics and machine learning for emphasizing rare or high loss events while retaining a tractable optimization problem. In this work, our aim is to interpret its structure for Flow Matching (FM). FM learns a velocity field that transports samples from a simple source distribution to data by integrating an ODE. In rectified FM, training pairs are obtained by linearly interpolating between a source sample and a data sample, and a neural velocity field is trained to predict the straight line displacement using a mean squared error loss. This squared loss collapses all velocity targets that reach the same space-time point into a single conditional mean, thereby ignoring higher order conditional information (variance, skewness, multi-modality) that encodes fine geometric structure about the data manifold and minority branches. We apply the standard risk-sensitive (log-exponential) transform to the conditional FM loss and show that the resulting tilted risk loss is a natural upper-bound on a meaningful conditional entropic FM objective defined at each space-time point. Furthermore, we show that a small order expansion of the gradient of this conditional entropic objective yields two interpretable first order corrections: covariance preconditioning of the FM residual, and a skew tail term that favors asymmetric or rare branches. On synthetic data designed to probe ambiguity and tails, the resulting risk-sensitive loss improves statistical metrics and recovers geometric structure more faithfully than standard rectified FM.

</details>


### [82] [ALARM: Automated MLLM-Based Anomaly Detection in Complex-EnviRonment Monitoring with Uncertainty Quantification](https://arxiv.org/abs/2512.03101)
*Congjing Zhang,Feng Lin,Xinyi Zhao,Pei Guo,Wei Li,Lin Chen,Chaoyue Zhao,Shuai Huang*

Main category: cs.LG

TL;DR: ALARM是一个基于多模态大语言模型的视觉异常检测框架，集成了不确定性量化与质量保证技术，在复杂环境中实现可靠决策


<details>
  <summary>Details</summary>
Motivation: 在复杂环境中，异常通常具有高度上下文相关性和模糊性，因此不确定性量化成为MLLM视觉异常检测系统成功的关键能力

Method: ALARM框架将不确定性量化与推理链、自我反思和MLLM集成等质量保证技术相结合，基于严格的概率推理流程和计算过程设计

Result: 在真实世界的智能家居基准数据和伤口图像分类数据上进行广泛实证评估，显示ALARM具有优越性能，并在不同领域具有通用适用性

Conclusion: ALARM框架通过集成不确定性量化与质量保证技术，为复杂环境中的视觉异常检测提供了可靠决策支持，具有跨领域通用性

Abstract: The advance of Large Language Models (LLMs) has greatly stimulated research interest in developing multi-modal LLM (MLLM)-based visual anomaly detection (VAD) algorithms that can be deployed in complex environments. The challenge is that in these complex environments, the anomalies are sometimes highly contextual and also ambiguous, and thereby, uncertainty quantification (UQ) is a crucial capacity for an MLLM-based VAD system to succeed. In this paper, we introduce our UQ-supported MLLM-based VAD framework called ALARM. ALARM integrates UQ with quality-assurance techniques like reasoning chain, self-reflection, and MLLM ensemble for robust and accurate performance and is designed based on a rigorous probabilistic inference pipeline and computational process. Extensive empirical evaluations are conducted using the real-world smart-home benchmark data and wound image classification data, which shows ALARM's superior performance and its generic applicability across different domains for reliable decision-making.

</details>


### [83] [Dynamic Correction of Erroneous State Estimates via Diffusion Bayesian Exploration](https://arxiv.org/abs/2512.03102)
*Yiwei Shi,Hongnan Ma,Mengyue Yang,Cunjia Liu,Weiru Liu*

Main category: cs.LG

TL;DR: 提出扩散驱动的贝叶斯探索框架，用于实时纠正早期状态估计错误，解决粒子滤波中的后验支持不变性问题。


<details>
  <summary>Details</summary>
Motivation: 在应急响应等高风险应用中，基于有限或偏差信息的早期状态估计可能与现实严重不符，导致灾难性后果。传统粒子滤波在平稳引导下存在后验支持不变性问题，即使有新证据也无法纠正错误信念。

Method: 提出扩散驱动的贝叶斯探索框架：通过熵正则化采样和协方差缩放扩散扩展后验支持，使用Metropolis-Hastings检查验证提议并保持推理对意外证据的自适应性。

Result: 在危险气体定位任务中，当先验正确时与强化学习和规划基线相当；在先验错误时显著优于传统SMC扰动和基于RL的方法，并提供理论保证解决S-PSI问题。

Conclusion: 该框架能够原则性地实时纠正早期状态估计错误，打破后验支持不变性锁定，同时保持统计严谨性，适用于高风险决策场景。

Abstract: In emergency response and other high-stakes societal applications, early-stage state estimates critically shape downstream outcomes. Yet, these initial state estimates-often based on limited or biased information-can be severely misaligned with reality, constraining subsequent actions and potentially causing catastrophic delays, resource misallocation, and human harm. Under the stationary bootstrap baseline (zero transition and no rejuvenation), bootstrap particle filters exhibit Stationarity-Induced Posterior Support Invariance (S-PSI), wherein regions excluded by the initial prior remain permanently unexplorable, making corrections impossible even when new evidence contradicts current beliefs. While classical perturbations can in principle break this lock-in, they operate in an always-on fashion and may be inefficient. To overcome this, we propose a diffusion-driven Bayesian exploration framework that enables principled, real-time correction of early state estimation errors. Our method expands posterior support via entropy-regularized sampling and covariance-scaled diffusion. A Metropolis-Hastings check validates proposals and keeps inference adaptive to unexpected evidence. Empirical evaluations on realistic hazardous-gas localization tasks show that our approach matches reinforcement learning and planning baselines when priors are correct. It substantially outperforms classical SMC perturbations and RL-based methods under misalignment, and we provide theoretical guarantees that DEPF resolves S-PSI while maintaining statistical rigor.

</details>


### [84] [Detecting AI Hallucinations in Finance: An Information-Theoretic Method Cuts Hallucination Rate by 92%](https://arxiv.org/abs/2512.03107)
*Mainak Singha*

Main category: cs.LG

TL;DR: ECLIPSE框架通过结合语义熵估计与困惑度分解，检测LLM幻觉，在金融QA数据集上达到0.89 AUC，显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型会产生流畅但无依据的幻觉回答，这限制了其在高风险领域的部署。需要一种能够检测幻觉的机制。

Method: 提出ECLIPSE框架，将幻觉视为模型语义熵与可用证据容量之间的不匹配。结合多样本聚类的熵估计和新的困惑度分解方法，测量模型如何使用检索到的证据。

Result: 在金融QA数据集上，ECLIPSE达到0.89 ROC AUC和0.90平均精度，显著优于仅使用语义熵的基线（AUC 0.50）。实验证明ECLIPSE依赖于校准的token级不确定性。

Conclusion: ECLIPSE是一个有效的幻觉检测框架，其效果依赖于token级概率校准，证据利用是幻觉检测的核心。需要在更多领域和自然幻觉上进行验证。

Abstract: Large language models (LLMs) produce fluent but unsupported answers - hallucinations - limiting safe deployment in high-stakes domains. We propose ECLIPSE, a framework that treats hallucination as a mismatch between a model's semantic entropy and the capacity of available evidence. We combine entropy estimation via multi-sample clustering with a novel perplexity decomposition that measures how models use retrieved evidence. We prove that under mild conditions, the resulting entropy-capacity objective is strictly convex with a unique stable optimum. We evaluate on a controlled financial question answering dataset with GPT-3.5-turbo (n=200 balanced samples with synthetic hallucinations), where ECLIPSE achieves ROC AUC of 0.89 and average precision of 0.90, substantially outperforming a semantic entropy-only baseline (AUC 0.50). A controlled ablation with Claude-3-Haiku, which lacks token-level log probabilities, shows AUC dropping to 0.59 with coefficient magnitudes decreasing by 95% - demonstrating that ECLIPSE is a logprob-native mechanism whose effectiveness depends on calibrated token-level uncertainties. The perplexity decomposition features exhibit the largest learned coefficients, confirming that evidence utilization is central to hallucination detection. We position this work as a controlled mechanism study; broader validation across domains and naturally occurring hallucinations remains future work.

</details>


### [85] [E-valuator: Reliable Agent Verifiers with Sequential Hypothesis Testing](https://arxiv.org/abs/2512.03109)
*Shuvom Sadhuka,Drew Prinster,Clara Fannjiang,Gabriele Scalia,Aviv Regev,Hanchen Wang*

Main category: cs.LG

TL;DR: e-valuator：将任意黑盒验证器分数转换为具有可证明误报率控制的决策规则，用于在线监控AI代理轨迹


<details>
  <summary>Details</summary>
Motivation: 现有AI代理验证器（如LLM法官和过程奖励模型）虽然能提供启发式评分，但缺乏正确性保证，无法可靠判断代理是否会产生成功输出

Method: 将区分成功与失败轨迹的问题构建为顺序假设检验问题，基于e-processes开发顺序假设检验，在代理轨迹的每一步保持统计有效性

Result: 在六个数据集和三个代理上，e-valuator相比其他策略提供更强的统计功效和更好的误报率控制，并能快速终止问题轨迹以节省tokens

Conclusion: e-valuator提供了轻量级、模型无关的框架，将验证器启发式方法转换为具有统计保证的决策规则，使能部署更可靠的代理系统

Abstract: Agentic AI systems execute a sequence of actions, such as reasoning steps or tool calls, in response to a user prompt. To evaluate the success of their trajectories, researchers have developed verifiers, such as LLM judges and process-reward models, to score the quality of each action in an agent's trajectory. Although these heuristic scores can be informative, there are no guarantees of correctness when used to decide whether an agent will yield a successful output. Here, we introduce e-valuator, a method to convert any black-box verifier score into a decision rule with provable control of false alarm rates. We frame the problem of distinguishing successful trajectories (that is, a sequence of actions that will lead to a correct response to the user's prompt) and unsuccessful trajectories as a sequential hypothesis testing problem. E-valuator builds on tools from e-processes to develop a sequential hypothesis test that remains statistically valid at every step of an agent's trajectory, enabling online monitoring of agents over arbitrarily long sequences of actions. Empirically, we demonstrate that e-valuator provides greater statistical power and better false alarm rate control than other strategies across six datasets and three agents. We additionally show that e-valuator can be used for to quickly terminate problematic trajectories and save tokens. Together, e-valuator provides a lightweight, model-agnostic framework that converts verifier heuristics into decisions rules with statistical guarantees, enabling the deployment of more reliable agentic systems.

</details>


### [86] [Beyond Additivity: Sparse Isotonic Shapley Regression toward Nonlinear Explainability](https://arxiv.org/abs/2512.03112)
*Jialai She*

Main category: cs.LG

TL;DR: SISR框架统一解决Shapley值两大挑战：通过单调变换恢复可加性，同时施加L0稀疏约束提高高维计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统Shapley值面临两大问题：1) 假设可加性，但现实世界数据分布（非高斯、重尾、特征依赖）常违反此假设，导致归因失真；2) 高维稀疏解释需要先计算密集Shapley值再阈值处理，计算成本高且可能不一致。

Method: 提出Sparse Isotonic Shapley Regression (SISR)框架：同时学习单调变换恢复可加性（无需闭式指定），并施加L0稀疏约束。使用Pool-Adjacent-Violators进行高效保序回归，归一化硬阈值进行支持选择。

Result: SISR能在多种场景下恢复真实变换，在高噪声下实现强支持恢复。实验表明，在回归、逻辑回归和树集成中，SISR能稳定归因，正确过滤无关特征，而标准Shapley值存在严重排序和符号失真。

Conclusion: SISR通过统一非线性变换估计与稀疏性追求，推进了非线性可解释性前沿，提供了理论坚实且实用的归因框架，首次证明无关特征和特征间依赖可导致真实收益变换显著偏离线性。

Abstract: Shapley values, a gold standard for feature attribution in Explainable AI, face two primary challenges. First, the canonical Shapley framework assumes that the worth function is additive, yet real-world payoff constructions--driven by non-Gaussian distributions, heavy tails, feature dependence, or domain-specific loss scales--often violate this assumption, leading to distorted attributions. Secondly, achieving sparse explanations in high dimensions by computing dense Shapley values and then applying ad hoc thresholding is prohibitively costly and risks inconsistency. We introduce Sparse Isotonic Shapley Regression (SISR), a unified nonlinear explanation framework. SISR simultaneously learns a monotonic transformation to restore additivity--obviating the need for a closed-form specification--and enforces an L0 sparsity constraint on the Shapley vector, enhancing computational efficiency in large feature spaces. Its optimization algorithm leverages Pool-Adjacent-Violators for efficient isotonic regression and normalized hard-thresholding for support selection, yielding implementation ease and global convergence guarantees. Analysis shows that SISR recovers the true transformation in a wide range of scenarios and achieves strong support recovery even in high noise. Moreover, we are the first to demonstrate that irrelevant features and inter-feature dependencies can induce a true payoff transformation that deviates substantially from linearity. Experiments in regression, logistic regression, and tree ensembles demonstrate that SISR stabilizes attributions across payoff schemes, correctly filters irrelevant features while standard Shapley values suffer severe rank and sign distortions. By unifying nonlinear transformation estimation with sparsity pursuit, SISR advances the frontier of nonlinear explainability, providing a theoretically grounded and practical attribution framework.

</details>


### [87] [Temporal Graph Neural Networks for Early Anomaly Detection and Performance Prediction via PV System Monitoring Data](https://arxiv.org/abs/2512.03114)
*Srijani Mukherjee,Laurent Vuillon,Liliane Bou Nassif,Stéphanie Giroux-Julien,Hervé Pabiou,Denys Dutykh,Ionnasis Tsanakas*

Main category: cs.LG

TL;DR: 提出一种基于时序图神经网络的方法，利用环境参数预测光伏系统输出功率并检测异常


<details>
  <summary>Details</summary>
Motivation: 随着光伏系统快速增长，需要先进的性能监测和异常检测方法来确保最优运行

Method: 使用时序图神经网络，基于关键光伏系统参数（辐照度、模块温度、环境温度）之间的图结构时序关系来预测电功率输出

Result: 基于法国里昂屋顶户外设施收集的数据，包括光伏模块功率测量和气象参数

Conclusion: 时序图神经网络方法能够有效预测光伏输出功率并检测异常，为光伏系统性能监测提供新方案

Abstract: The rapid growth of solar photovoltaic (PV) systems necessitates advanced methods for performance monitoring and anomaly detection to ensure optimal operation. In this study, we propose a novel approach leveraging Temporal Graph Neural Network (Temporal GNN) to predict solar PV output power and detect anomalies using environmental and operational parameters. The proposed model utilizes graph-based temporal relationships among key PV system parameters, including irradiance, module and ambient temperature to predict electrical power output. This study is based on data collected from an outdoor facility located on a rooftop in Lyon (France) including power measurements from a PV module and meteorological parameters.

</details>


### [88] [Real-Time Structural Health Monitoring with Bayesian Neural Networks: Distinguishing Aleatoric and Epistemic Uncertainty for Digital Twin Frameworks](https://arxiv.org/abs/2512.03115)
*Hanbin Cho,Jecheon Yu,Hyeonbin Moon,Jiyoung Yoon,Junhyeong Lee,Giyoung Kim,Jinhyoung Park,Seunghwa Ryu*

Main category: cs.LG

TL;DR: 提出一个结合PCA、贝叶斯神经网络和哈密顿蒙特卡洛的结构健康监测框架，能从稀疏应变测量重建全场应变分布并量化不确定性，支持可靠决策。


<details>
  <summary>Details</summary>
Motivation: 结构健康监测需要实时分析传感器数据，但获取空间分辨的全场随机和认知不确定性以支持可信决策是主要挑战。

Method: 集成PCA、贝叶斯神经网络和哈密顿蒙特卡洛推理，将稀疏应变计测量映射到主成分模态，重建全场应变分布并进行不确定性量化。

Result: 通过碳纤维增强聚合物试件的循环四点弯曲试验验证，实现准确应变场重建（R平方值>0.9），同时产生实时不确定性场。

Conclusion: 该框架推进了结构健康监测向可信数字孪生部署和风险感知结构诊断的发展，通过联合考虑两种不确定性场支持可靠决策。

Abstract: Reliable real-time analysis of sensor data is essential for structural health monitoring (SHM) of high-value assets, yet a major challenge is to obtain spatially resolved full-field aleatoric and epistemic uncertainties for trustworthy decision-making. We present an integrated SHM framework that combines principal component analysis (PCA), a Bayesian neural network (BNN), and Hamiltonian Monte Carlo (HMC) inference, mapping sparse strain gauge measurements onto leading PCA modes to reconstruct full-field strain distributions with uncertainty quantification. The framework was validated through cyclic four-point bending tests on carbon fiber reinforced polymer (CFRP) specimens with varying crack lengths, achieving accurate strain field reconstruction (R squared value > 0.9) while simultaneously producing real-time uncertainty fields. A key contribution is that the BNN yields robust full-field strain reconstructions from noisy experimental data with crack-induced strain singularities, while also providing explicit representations of two complementary uncertainty fields. Considered jointly in full-field form, the aleatoric and epistemic uncertainty fields make it possible to diagnose at a local level, whether low-confidence regions are driven by data-inherent issues or by model-related limitations, thereby supporting reliable decision-making. Collectively, the results demonstrate that the proposed framework advances SHM toward trustworthy digital twin deployment and risk-aware structural diagnostics.

</details>


### [89] [Mitigating Intra- and Inter-modal Forgetting in Continual Learning of Unified Multimodal Models](https://arxiv.org/abs/2512.03125)
*Xiwen Wei,Mustafa Munir,Radu Marculescu*

Main category: cs.LG

TL;DR: MoDE提出模态解耦专家架构，通过隔离模态特定更新和知识蒸馏，解决统一多模态生成模型中的模态间遗忘问题，在多个基准测试中优于现有持续学习方法。


<details>
  <summary>Details</summary>
Motivation: 统一多模态生成模型在持续学习新任务时存在严重的灾难性遗忘问题，包括模态内遗忘和模态间遗忘。虽然模态内遗忘已有研究，但模态间遗忘尚未被充分探索。本文旨在识别并解决这一关键问题。

Method: 提出模态解耦专家架构，通过隔离模态特定更新来缓解模态梯度冲突，并利用知识蒸馏防止灾难性遗忘和保留预训练能力。该方法明确解耦模态以防止干扰。

Result: 在多样化基准测试中，MoDE显著缓解了模态间和模态内遗忘，在统一多模态生成设置中优于先前的持续学习基线方法。

Conclusion: MoDE通过模态解耦和知识蒸馏有效解决了统一多模态生成模型中的模态间遗忘问题，为多模态持续学习提供了轻量级、可扩展的解决方案。

Abstract: Unified Multimodal Generative Models (UMGMs) unify visual understanding and image generation within a single autoregressive framework. However, their ability to continually learn new tasks is severely hindered by catastrophic forgetting, both within a modality (intra-modal) and across modalities (inter-modal). While intra-modal forgetting has been studied in prior continual learning (CL) work, inter-modal forgetting remains largely unexplored. In this paper, we identify and empirically validate this phenomenon in UMGMs and provide a theoretical explanation rooted in gradient conflict between modalities. To address both intra- and inter-modal forgetting, we propose Modality-Decoupled Experts (MoDE), a lightweight and scalable architecture that isolates modality-specific updates to mitigate the gradient conflict and leverages knowledge distillation to prevent catastrophic forgetting and preserve pre-trained capabilities. Unlike previous CL methods that remain modality-coupled and suffer from modality gradient conflict, MoDE explicitly decouples modalities to prevent interference. Experiments across diverse benchmarks demonstrate that MoDE significantly mitigates both inter- and intra-modal forgetting, outperforming prior CL baselines in unified multimodal generation settings. Codes will be publicly available: https://github.com/Christina200/MoDE-official.git

</details>


### [90] [Atomic Diffusion Models for Small Molecule Structure Elucidation from NMR Spectra](https://arxiv.org/abs/2512.03127)
*Ziyu Xiong,Yichi Zhang,Foyez Alauddin,Chu Xin Cheng,Joon Soo An,Mohammad R. Seyedsayamdost,Ellen D. Zhong*

Main category: cs.LG

TL;DR: ChefNMR：基于原子扩散模型的端到端框架，仅从1D NMR谱和化学式直接预测未知分子结构，在天然产物结构解析中准确率超过65%


<details>
  <summary>Details</summary>
Motivation: NMR谱解析是确定小分子结构的关键技术，但当前仍需要大量人工操作和专业领域知识，过程耗时且依赖专家经验。需要开发自动化工具来加速分子发现过程。

Method: 将结构解析构建为条件生成问题，采用基于非等变transformer架构的原子扩散模型。构建了包含超过111,000个天然产物的模拟1D NMR谱数据集来训练模型。

Result: ChefNMR在挑战性天然产物化合物结构预测中达到超过65%的准确率，超越了现有方法。代码已在GitHub开源。

Conclusion: 该工作在小分子结构自动解析这一重大挑战上迈出了重要一步，展示了深度学习在加速分子发现方面的潜力，为天然产物和临床治疗药物的发现提供了强大的自动化工具。

Abstract: Nuclear Magnetic Resonance (NMR) spectroscopy is a cornerstone technique for determining the structures of small molecules and is especially critical in the discovery of novel natural products and clinical therapeutics. Yet, interpreting NMR spectra remains a time-consuming, manual process requiring extensive domain expertise. We introduce ChefNMR (CHemical Elucidation From NMR), an end-to-end framework that directly predicts an unknown molecule's structure solely from its 1D NMR spectra and chemical formula. We frame structure elucidation as conditional generation from an atomic diffusion model built on a non-equivariant transformer architecture. To model the complex chemical groups found in natural products, we generated a dataset of simulated 1D NMR spectra for over 111,000 natural products. ChefNMR predicts the structures of challenging natural product compounds with an unsurpassed accuracy of over 65%. This work takes a significant step toward solving the grand challenge of automating small-molecule structure elucidation and highlights the potential of deep learning in accelerating molecular discovery. Code is available at https://github.com/ml-struct-bio/chefnmr.

</details>


### [91] [Contrastive Deep Learning for Variant Detection in Wastewater Genomic Sequencing](https://arxiv.org/abs/2512.03158)
*Adele Chinda,Richmond Azumah,Hemanth Demakethepalli Venkateswara*

Main category: cs.LG

TL;DR: 提出基于VQ-VAE的无监督病毒变异检测框架，用于废水基因组监测，无需参考基因组或变异标签，在SARS-CoV-2数据上取得高准确率。


<details>
  <summary>Details</summary>
Motivation: 废水基因组监测面临计算挑战：高测序噪声、低病毒覆盖率、片段化读取、缺乏变异标注。传统基于参考的变异检测方法难以处理新突变且计算资源需求大。

Method: 使用向量量化变分自编码器（VQ-VAE）框架，从k-mer标记化序列学习离散基因组模式码本。扩展基础架构：加入掩码重建预训练增强对缺失数据的鲁棒性，对比学习获得高判别性嵌入。

Result: 在约10万条SARS-CoV-2废水测序数据上，VQ-VAE达到99.52%平均标记级准确率和56.33%精确序列匹配率，码本利用率19.73%（512个码中101个活跃）。对比微调显著改善聚类：64维嵌入Silhouette分数提升35%（0.31到0.42），128维提升42%（0.31到0.44）。

Conclusion: 该无参考框架为基因组监测提供了可扩展、可解释的方法，可直接应用于公共卫生监控，解决了传统方法的局限性。

Abstract: Wastewater-based genomic surveillance has emerged as a powerful tool for population-level viral monitoring, offering comprehensive insights into circulating viral variants across entire communities. However, this approach faces significant computational challenges stemming from high sequencing noise, low viral coverage, fragmented reads, and the complete absence of labeled variant annotations. Traditional reference-based variant calling pipelines struggle with novel mutations and require extensive computational resources. We present a comprehensive framework for unsupervised viral variant detection using Vector-Quantized Variational Autoencoders (VQ-VAE) that learns discrete codebooks of genomic patterns from k-mer tokenized sequences without requiring reference genomes or variant labels. Our approach extends the base VQ-VAE architecture with masked reconstruction pretraining for robustness to missing data and contrastive learning for highly discriminative embeddings. Evaluated on SARS-CoV-2 wastewater sequencing data comprising approximately 100,000 reads, our VQ-VAE achieves 99.52% mean token-level accuracy and 56.33% exact sequence match rate while maintaining 19.73% codebook utilization (101 of 512 codes active), demonstrating efficient discrete representation learning. Contrastive fine-tuning with different projection dimensions yields substantial clustering improvements: 64-dimensional embeddings achieve +35% Silhouette score improvement (0.31 to 0.42), while 128-dimensional embeddings achieve +42% improvement (0.31 to 0.44), clearly demonstrating the impact of embedding dimensionality on variant discrimination capability. Our reference-free framework provides a scalable, interpretable approach to genomic surveillance with direct applications to public health monitoring.

</details>


### [92] [Plantain: Plan-Answer Interleaved Reasoning](https://arxiv.org/abs/2512.03176)
*Anthony Liang,Jonathan Berant,Adam Fisch,Abhimanyu Goyal,Kalpesh Krishna,Jacob Eisenstein*

Main category: cs.LG

TL;DR: 论文提出交错推理(IR)方法，让语言模型在推理过程中交替生成中间响应，替代传统的"先思考后回答"模式，从而减少用户感知延迟并允许早期干预。


<details>
  <summary>Details</summary>
Motivation: 传统推理模型在生成最终答案前需要长时间"思考"，期间不给用户任何提示，导致用户无法判断推理是否正确或及时纠正错误前提，浪费用户时间。相比之下，人类对话中会进行轻量级的增量确认以确保双方理解一致。

Method: 提出交错推理(IR)方法，模型在推理过程中交替生成中间响应。进一步提出Plantain（计划-思考-答案交错）方法，首先生成明确的逐步执行计划作为第一个中间响应，允许用户干预并为后续推理步骤提供早期反馈。

Result: Plantain在多个具有挑战性的数学推理和编程基准测试中，pass@1指标提高了约6%，同时相对于"先思考后回答"基线，首次响应时间减少了60%以上。

Conclusion: 交错推理方法能够显著改善用户体验，减少感知延迟，同时提高任务性能，使语言模型能够像人类一样进行增量确认和早期干预。

Abstract: Reasoning models often spend a significant amount of time thinking before they generate a visible response. In the meantime, they do not give the user any hints as to whether their reasoning is on the right track, and do not give the user any recourse to stop and correct them if their reasoning is flawed. This creates a frustrating, but unfortunately common, experience: the user's time is wasted while the model reasons from a false premise that could have easily been corrected. In contrast, human speakers typically perform lightweight, incremental grounding acts to ensure that participants in the conversation are on the same page; here we ask if language models can learn to leverage a similar type of behavior? With this motivation, we propose interleaved reasoning (IR), in which the model alternates between thinking and surfacing intermediate responses, as an alternative to the standard "think-then-answer" approach. By providing useful information to the user earlier, IR reduces perceived latency, the time a user waits for an initial output, without compromising the quality of the final response. We further introduce a specialization of interleaved reasoning, Plantain (Plan-Thought-Answer Interleaving), where the first intermediate response is an explicit, step-by-step plan for executing the task. This plan-first strategy allows for user intervention and early feedback for subsequent reasoning steps. We demonstrate that Plantain yields an ~6% improvement in pass@1 across several challenging math reasoning and coding benchmarks, while reducing time-to-first-response by over 60% relative to think-then-answer baselines.

</details>


### [93] [Neighborhood density estimation using space-partitioning based hashing schemes](https://arxiv.org/abs/2512.03187)
*Aashi Jindal*

Main category: cs.LG

TL;DR: FiRE/FiRE.1用于单细胞RNA测序数据中罕见细胞亚群的快速检测，Enhash用于流数据中的概念漂移检测，两者均表现出优越性能


<details>
  <summary>Details</summary>
Motivation: 解决大规模单细胞RNA测序数据中罕见细胞亚群检测的挑战，以及流数据中概念漂移检测的效率问题

Method: FiRE/FiRE.1使用基于草图的算法，Enhash使用投影哈希的集成学习方法

Result: FiRE/FiRE.1在罕见细胞检测上优于现有技术，Enhash在各种漂移类型中在时间和准确度上具有竞争力

Conclusion: 提出的两种方法分别在单细胞数据分析和流数据概念漂移检测中表现出高效和优越性能

Abstract: This work introduces FiRE/FiRE.1, a novel sketching-based algorithm for anomaly detection to quickly identify rare cell sub-populations in large-scale single-cell RNA sequencing data. This method demonstrated superior performance against state-of-the-art techniques. Furthermore, the thesis proposes Enhash, a fast and resource-efficient ensemble learner that uses projection hashing to detect concept drift in streaming data, proving highly competitive in time and accuracy across various drift types.

</details>


### [94] [Scaling Internal-State Policy-Gradient Methods for POMDPs](https://arxiv.org/abs/2512.03204)
*Douglas Aberdeen,Jonathan Baxter*

Main category: cs.LG

TL;DR: 本文提出了几种改进算法，用于在无限时域设置中学习具有记忆的策略，包括已知环境模型时的直接学习和通过模拟学习，并在大型POMDP问题上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 策略梯度方法在部分可观测环境中学习行动机制方面受到关注，但在需要记忆的情况下效果不佳。本文旨在改进学习具有记忆的策略的算法。

Method: 开发了多种改进算法：当环境模型已知时直接学习策略，否则通过模拟学习。这些算法专门针对无限时域设置中需要记忆的策略。

Result: 在大型POMDP问题上进行了比较测试，包括噪声机器人导航和多智能体问题，验证了算法的有效性。

Conclusion: 提出的改进算法能够有效学习需要记忆的策略，在部分可观测环境中表现出更好的性能，特别是在无限时域设置下。

Abstract: Policy-gradient methods have received increased attention recently as a mechanism for learning to act in partially observable environments. They have shown promise for problems admitting memoryless policies but have been less successful when memory is required. In this paper we develop several improved algorithms for learning policies with memory in an infinite-horizon setting -- directly when a known model of the environment is available, and via simulation otherwise. We compare these algorithms on some large POMDPs, including noisy robot navigation and multi-agent problems.

</details>


### [95] [A Multi-Agent, Policy-Gradient approach to Network Routing](https://arxiv.org/abs/2512.03211)
*Nigel Tao,Jonathan Baxter,Lex Weaver*

Main category: cs.LG

TL;DR: OLPOMDP算法应用于网络路由问题，多个分布式路由器代理学习协作行为，无需显式通信，通过奖励塑形显著提升收敛速度。


<details>
  <summary>Details</summary>
Motivation: 网络路由是一个分布式决策问题，具有数值性能指标（如平均包传输时间）。传统方法可能无法实现分布式代理之间的有效协作，需要探索强化学习方法来解决这一挑战。

Method: 使用OLPOMDP（一种策略梯度强化学习算法），应用于模拟网络路由场景。多个分布式路由器作为代理，通过奖励塑形技术（明确惩罚次优行为模式）来引导学习过程。

Result: 分布式路由器代理成功学习到协作行为，无需显式通信；避免了仅对个体有利但对整体性能有害的行为；奖励塑形显著提高了算法的收敛速度。

Conclusion: OLPOMDP算法能有效解决网络路由的分布式决策问题，实现代理间的协作优化。奖励塑形是提升学习效率的关键技术，为分布式系统优化提供了有前景的方法。

Abstract: Network routing is a distributed decision problem which naturally admits numerical performance measures, such as the average time for a packet to travel from source to destination. OLPOMDP, a policy-gradient reinforcement learning algorithm, was successfully applied to simulated network routing under a number of network models. Multiple distributed agents (routers) learned co-operative behavior without explicit inter-agent communication, and they avoided behavior which was individually desirable, but detrimental to the group's overall performance. Furthermore, shaping the reward signal by explicitly penalizing certain patterns of sub-optimal behavior was found to dramatically improve the convergence rate.

</details>


### [96] [Perch 2.0 transfers 'whale' to underwater tasks](https://arxiv.org/abs/2512.03219)
*Andrea Burns,Lauren Harrell,Bart van Merriënboer,Vincent Dumoulin,Jenny Hamer,Tom Denton*

Main category: cs.LG

TL;DR: Perch 2.0生物声学基础模型在海洋哺乳动物音频任务上通过少样本迁移学习表现出色，优于其他预训练模型。


<details>
  <summary>Details</summary>
Motivation: Perch 2.0虽然训练数据中几乎不包含海洋哺乳动物音频，但需要评估其在海洋哺乳动物和水下音频任务上的迁移学习能力，以验证其作为基础模型的通用性。

Method: 使用Perch 2.0生成的嵌入进行线性探测（linear probing），通过少样本迁移学习评估其在海洋哺乳动物分类任务上的性能，并与多个开源生物声学模型进行比较。

Result: Perch 2.0的嵌入在少样本迁移学习中表现出持续的高性能，在大多数任务上优于其他嵌入模型，包括多物种鲸鱼模型、Perch 1.0、SurfPerch、AVES-bio、BirdAVES和Birdnet V2.3。

Conclusion: Perch 2.0模型生成的嵌入在开发海洋哺乳动物分类的线性分类器时，特别是在标记样本较少的情况下，是推荐的选择，因为它具有出色的少样本迁移学习能力。

Abstract: Perch 2.0 is a supervised bioacoustics foundation model pretrained on 14,597 species, including birds, mammals, amphibians, and insects, and has state-of-the-art performance on multiple benchmarks. Given that Perch 2.0 includes almost no marine mammal audio or classes in the training data, we evaluate Perch 2.0 performance on marine mammal and underwater audio tasks through few-shot transfer learning. We perform linear probing with the embeddings generated from this foundation model and compare performance to other pretrained bioacoustics models. In particular, we compare Perch 2.0 with previous multispecies whale, Perch 1.0, SurfPerch, AVES-bio, BirdAVES, and Birdnet V2.3 models, which have open-source tools for transfer-learning and agile modeling. We show that the embeddings from the Perch 2.0 model have consistently high performance for few-shot transfer learning, generally outperforming alternative embedding models on the majority of tasks, and thus is recommended when developing new linear classifiers for marine mammal classification with few labeled examples.

</details>


### [97] [SPARK: Stepwise Process-Aware Rewards for Reference-Free Reinforcement Learning](https://arxiv.org/abs/2512.03244)
*Salman Rahman,Sruthi Gorantla,Arpit Gupta,Swastik Roy,Nanyun Peng,Yang Liu*

Main category: cs.LG

TL;DR: SPARK框架通过三阶段方法训练生成式过程奖励模型，无需昂贵的人工标注或参考答案，在数学推理任务上超越基于真实答案的监督方法。


<details>
  <summary>Details</summary>
Motivation: 过程奖励模型（PRMs）需要密集的步骤级标注或参考答案，成本高昂且限制了其应用。需要开发无需参考答案或人工标注的方法来训练有效的PRMs。

Method: 三阶段框架：1）生成模型产生多样解，验证模型通过并行扩展（自一致性）和序列扩展（元批判）评估；2）用验证输出作为合成数据微调生成式PRMs；3）将PRM与思维链验证结合作为RL奖励信号，并引入格式约束防止奖励攻击。

Result: 在ProcessBench上达到67.5 F1，优于参考答案监督的66.4和GPT-4o的61.9。在六个数学推理基准上平均准确率47.4%，优于基于真实答案的RLVR（43.9%）。

Conclusion: SPARK实现了无需参考答案的强化学习训练，性能超越基于真实答案的方法，为缺乏可验证答案或参考答案的领域开辟了新可能性。

Abstract: Process reward models (PRMs) that provide dense, step-level feedback have shown promise for reinforcement learning, yet their adoption remains limited by the need for expensive step-level annotations or ground truth references. We propose SPARK: a three-stage framework where in the first stage a generator model produces diverse solutions and a verifier model evaluates them using parallel scaling (self-consistency) and sequential scaling (meta-critique). In the second stage, we use these verification outputs as synthetic training data to fine-tune generative process reward models, which subsequently serve as reward signals during training. We show that aggregating multiple independent verifications at the step level produces training data for process reward models that surpass ground-truth outcome supervision, achieving 67.5 F1 on ProcessBench (a benchmark for identifying erroneous steps in mathematical reasoning) compared to 66.4 for reference-guided training and 61.9 for GPT-4o. In the final stage, we apply our generative PRM with chain-of-thought verification (PRM-CoT) as the reward model in RL experiments on mathematical reasoning, and introduce format constraints to prevent reward hacking. Using Qwen2.5-Math-7B, we achieve 47.4% average accuracy across six mathematical reasoning benchmarks, outperforming ground-truth-based RLVR (43.9%). Our work enables reference-free RL training that exceeds ground-truth methods, opening new possibilities for domains lacking verifiable answers or accessible ground truth.

</details>


### [98] [Too Late to Recall: Explaining the Two-Hop Problem in Multimodal Knowledge Retrieval](https://arxiv.org/abs/2512.03276)
*Constantin Venhoff,Ashkan Khakzar,Sonia Joseph,Philip Torr,Neel Nanda*

Main category: cs.LG

TL;DR: 研究发现视觉语言模型（VLM）在事实回忆任务上表现下降，原因是实体表示形成过晚，无法有效利用LLM已有的知识回忆机制。通过早期实体解析可以恢复性能。


<details>
  <summary>Details</summary>
Motivation: 许多VLM在事实回忆任务上表现不如其LLM骨干模型，这引发了一个问题：多模态微调在将LLM现有机制扩展到视觉输入方面到底有多有效？需要探究VLM事实回忆能力下降的根本原因。

Method: 1. 对14种不同架构、规模和训练设置的VLM进行事实回忆任务基准测试；2. 使用归因修补、激活修补和探测技术分析高低性能模型；3. 提出两种性能恢复方法：从LLM骨干修补实体表示和使用思维链提示。

Result: 14个VLM中有11个表现出事实回忆性能下降。性能下降的VLM因为实体表示形成过晚，无法有效利用LLM已有的知识回忆机制；而高性能VLM能早期解析实体表示从而重用现有机制。两种恢复方法都能有效提升性能。

Conclusion: 早期实体解析的速度是决定VLM能否有效利用预训练LLM机制的关键因素。机制分析可以解释和揭示多模态对齐中的系统性失败，为改进VLM设计提供了重要见解。

Abstract: Training vision language models (VLMs) aims to align visual representations from a vision encoder with the textual representations of a pretrained large language model (LLM). However, many VLMs exhibit reduced factual recall performance compared to their LLM backbones, raising the question of how effective multimodal fine-tuning is at extending existing mechanisms within the LLM to visual inputs. We argue that factual recall based on visual inputs requires VLMs to solve a two-hop problem: (1) forming entity representations from visual inputs, and (2) recalling associated factual knowledge based on these entity representations. By benchmarking 14 VLMs with various architectures (LLaVA, Native, Cross-Attention), sizes (7B-124B parameters), and training setups on factual recall tasks against their original LLM backbone models, we find that 11 of 14 models exhibit factual recall degradation. We select three models with high and two models with low performance degradation, and use attribution patching, activation patching, and probing to show that degraded VLMs struggle to use the existing factual recall circuit of their LLM backbone, because they resolve the first hop too late in the computation. In contrast, high-performing VLMs resolve entity representations early enough to reuse the existing factual recall mechanism. Finally, we demonstrate two methods to recover performance: patching entity representations from the LLM backbone into the VLM, and prompting with chain-of-thought reasoning. Our results highlight that the speed of early entity resolution critically determines how effective VLMs are in using preexisting LLM mechanisms. More broadly, our work illustrates how mechanistic analysis can explain and unveil systematic failures in multimodal alignment.

</details>


### [99] [BlendedNet++: A Large-Scale Blended Wing Body Aerodynamics Dataset and Benchmark](https://arxiv.org/abs/2512.03280)
*Nicholas Sung,Steven Spreizer,Mohamed Elrefaie,Matthew C. Jones,Faez Ahmed*

Main category: cs.LG

TL;DR: BlendedNet++：一个包含12,000+混合翼身飞机几何形状的大规模空气动力学数据集和基准测试，提供集成力和表面场数据，用于标准化前向代理预测和基于扩散模型的逆向设计任务。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习空气动力学代理模型面临大型场解析数据集稀缺的问题，限制了精确点预测和可重复逆向设计的进展。需要统一的数据集和基准来促进该领域的研究。

Method: 创建包含12,000+独特几何形状的混合翼身飞机数据集，每个几何在单一飞行条件下进行稳态RANS CFD模拟。建立前向代理基准测试六种模型架构，并实现基于条件扩散模型的逆向设计任务，与基于梯度的优化方法进行对比。

Result: 提供了包含12,490个空气动力学结果的大规模数据集，包含集成力/力矩系数和密集表面场数据。建立了统一的前向和逆向协议，为不同架构和优化范式提供了公平、可重复的比较基准。

Conclusion: BlendedNet++为场级空气动力学和逆向设计提供了可重复研究的催化剂，通过发布数据集、分割、基准和脚本，将促进该领域的公平比较和进步。

Abstract: Despite progress in machine learning-based aerodynamic surrogates, the scarcity of large, field-resolved datasets limits progress on accurate pointwise prediction and reproducible inverse design for aircraft. We introduce BlendedNet++, a large-scale aerodynamic dataset and benchmark focused on blended wing body (BWB) aircraft. The dataset contains over 12,000 unique geometries, each simulated at a single flight condition, yielding 12,490 aerodynamic results for steady RANS CFD. For every case, we provide (i) integrated force/moment coefficients CL, CD, CM and (ii) dense surface fields of pressure and skin friction coefficients Cp and (Cfx, Cfy, Cfz). Using this dataset, we standardize a forward-surrogate benchmark to predict pointwise fields across six model families: GraphSAGE, GraphUNet, PointNet, a coordinate Transformer (Transolver-style), a FiLMNet (coordinate MLP with feature-wise modulation), and a Graph Neural Operator Transformer (GNOT). Finally, we present an inverse design task of achieving a specified lift-to-drag ratio under fixed flight conditions, implemented via a conditional diffusion model. To assess performance, we benchmark this approach against gradient-based optimization on the same surrogate and a diffusion-optimization hybrid that first samples with the conditional diffusion model and then further optimizes the designs. BlendedNet++ provides a unified forward and inverse protocol with multi-model baselines, enabling fair, reproducible comparison across architectures and optimization paradigms. We expect BlendedNet++ to catalyze reproducible research in field-level aerodynamics and inverse design; resources (dataset, splits, baselines, and scripts) will be released upon acceptance.

</details>


### [100] [Multi-Frequency Federated Learning for Human Activity Recognition Using Head-Worn Sensors](https://arxiv.org/abs/2512.03287)
*Dario Fenoglio,Mohan Li,Davide Casnici,Matias Laporte,Shkurta Gashi,Silvia Santini,Martin Gjoreski,Marc Langheinrich*

Main category: cs.LG

TL;DR: 提出多频联邦学习用于头戴设备的人体活动识别，解决隐私问题和设备采样频率差异


<details>
  <summary>Details</summary>
Motivation: 传统HAR依赖集中式用户数据，存在隐私问题；不同设备采样频率不同，需要跨设备联合学习

Method: 提出多频联邦学习框架，支持隐私保护机器学习，允许不同采样频率设备共同学习模型

Result: 在两个数据集上相比频率特定方法有改进，展示了多频联邦学习在HAR任务中的潜力

Conclusion: 多频联邦学习是头戴设备HAR的有前景方向，代码已公开供进一步研究

Abstract: Human Activity Recognition (HAR) benefits various application domains, including health and elderly care. Traditional HAR involves constructing pipelines reliant on centralized user data, which can pose privacy concerns as they necessitate the uploading of user data to a centralized server. This work proposes multi-frequency Federated Learning (FL) to enable: (1) privacy-aware ML; (2) joint ML model learning across devices with varying sampling frequency. We focus on head-worn devices (e.g., earbuds and smart glasses), a relatively unexplored domain compared to traditional smartwatch- or smartphone-based HAR. Results have shown improvements on two datasets against frequency-specific approaches, indicating a promising future in the multi-frequency FL-HAR task. The proposed network's implementation is publicly available for further research and development.

</details>


### [101] [ASPEN: An Adaptive Spectral Physics-Enabled Network for Ginzburg-Landau Dynamics](https://arxiv.org/abs/2512.03290)
*Julian Evan Chrisnanto,Nurfauzi Fadillah,Yulison Herry Chrisnanto*

Main category: cs.LG

TL;DR: ASPEN是一种新型物理信息神经网络架构，通过自适应谱层解决标准PINN在求解刚性、多尺度非线性PDE时的频谱偏差问题，成功应用于复杂的Ginzburg-Landau方程。


<details>
  <summary>Details</summary>
Motivation: 标准PINN在处理刚性、多尺度和非线性偏微分方程时存在严重局限性，主要原因是多层感知机的固有频谱偏差无法充分表示高频分量，导致求解失败。

Method: 提出自适应谱物理使能网络（ASPEN），在网络输入阶段集成具有可学习傅里叶特征的自适应谱层，使模型能够在训练过程中动态调整其谱基，高效学习解所需的精确频率内容。

Result: 在复杂的Ginzburg-Landau方程上，标准PINN完全失败并产生非物理振荡，而ASPEN成功求解，预测解与高分辨率真实解视觉上无法区分，中位物理残差低至5.10×10^-3，并能正确捕捉涌现的物理特性。

Conclusion: 通过引入自适应谱基，ASPEN为复杂动力系统提供了稳健且物理一致的求解器，为标准PINN失败的挑战性物理领域开辟了新的机器学习应用选项。

Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful, mesh-free paradigm for solving partial differential equations (PDEs). However, they notoriously struggle with stiff, multi-scale, and nonlinear systems due to the inherent spectral bias of standard multilayer perceptron (MLP) architectures, which prevents them from adequately representing high-frequency components. In this work, we introduce the Adaptive Spectral Physics-Enabled Network (ASPEN), a novel architecture designed to overcome this critical limitation. ASPEN integrates an adaptive spectral layer with learnable Fourier features directly into the network's input stage. This mechanism allows the model to dynamically tune its own spectral basis during training, enabling it to efficiently learn and represent the precise frequency content required by the solution. We demonstrate the efficacy of ASPEN by applying it to the complex Ginzburg-Landau equation (CGLE), a canonical and challenging benchmark for nonlinear, stiff spatio-temporal dynamics. Our results show that a standard PINN architecture catastrophically fails on this problem, diverging into non-physical oscillations. In contrast, ASPEN successfully solves the CGLE with exceptional accuracy. The predicted solution is visually indistinguishable from the high-resolution ground truth, achieving a low median physics residual of 5.10 x 10^-3. Furthermore, we validate that ASPEN's solution is not only pointwise accurate but also physically consistent, correctly capturing emergent physical properties, including the rapid free energy relaxation and the long-term stability of the domain wall front. This work demonstrates that by incorporating an adaptive spectral basis, our framework provides a robust and physically-consistent solver for complex dynamical systems where standard PINNs fail, opening new options for machine learning in challenging physical domains.

</details>


### [102] [Adaptive Regime-Switching Forecasts with Distribution-Free Uncertainty: Deep Switching State-Space Models Meet Conformal Prediction](https://arxiv.org/abs/2512.03298)
*Echo Diyun LU,Charles Findling,Marianne Clausel,Alessandro Leite,Wei Gong,Pierric Kersaudy*

Main category: cs.LG

TL;DR: 该论文提出了一种结合深度切换状态空间模型与自适应共形推理的方法，为非平稳时间序列中的切换机制提供分布自由的预测不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 时间序列中的机制转换经常破坏平稳性，使得校准的不确定性与点预测精度同等重要。需要为机制切换预测提供分布自由的、具有有限样本保证的不确定性量化方法。

Method: 将深度切换状态空间模型与自适应共形推理（ACI）及其聚合变体（AgACI）相结合。还引入了统一的共形包装器，可应用于S4、MC-Dropout GRU、稀疏高斯过程、变化点局部模型等强序列基线，在非平稳性和模型误设下提供在线预测区间。

Result: 在合成和真实数据集上，共形化预测器实现了接近名义覆盖率的预测区间，同时保持竞争性的准确性，并通常提高了区间效率。

Conclusion: 该方法能够为机制切换时间序列预测提供具有有限样本边际保证的分布自由不确定性量化，在非平稳环境下实现可靠的预测区间覆盖。

Abstract: Regime transitions routinely break stationarity in time series, making calibrated uncertainty as important as point accuracy. We study distribution-free uncertainty for regime-switching forecasting by coupling Deep Switching State Space Models with Adaptive Conformal Inference (ACI) and its aggregated variant (AgACI). We also introduce a unified conformal wrapper that sits atop strong sequence baselines including S4, MC-Dropout GRU, sparse Gaussian processes, and a change-point local model to produce online predictive bands with finite-sample marginal guarantees under nonstationarity and model misspecification. Across synthetic and real datasets, conformalized forecasters achieve near-nominal coverage with competitive accuracy and generally improved band efficiency.

</details>


### [103] [HydroDCM: Hydrological Domain-Conditioned Modulation for Cross-Reservoir Inflow Prediction](https://arxiv.org/abs/2512.03300)
*Pengfei Hu,Fan Ming,Xiaoxue Han,Chang Lu,Yue Ning,Dan Lu*

Main category: cs.LG

TL;DR: 提出HydroDCM框架，通过元数据构建伪域标签指导对抗学习，结合轻量级条件层实现跨水库流量预测的领域泛化与特定位置适应


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在水库流量预测中面临领域偏移问题，传统领域泛化方法难以处理水文系统中每个水库的独特流入模式和空间元数据的间接影响

Method: 使用水库空间元数据构建伪域标签指导对抗学习提取不变特征，推理时通过轻量级条件层结合目标水库元数据进行特征适应

Result: 在科罗拉多河上游流域30个真实水库上的实验表明，该方法在多域条件下显著优于现有领域泛化基线，且计算高效

Conclusion: HydroDCM框架成功解决了水文系统中多域领域泛化问题，通过元数据引导的对抗学习和轻量级适应层实现了泛化能力与特定位置适应的平衡

Abstract: Deep learning models have shown promise in reservoir inflow prediction, yet their performance often deteriorates when applied to different reservoirs due to distributional differences, referred to as the domain shift problem. Domain generalization (DG) solutions aim to address this issue by extracting domain-invariant representations that mitigate errors in unseen domains. However, in hydrological settings, each reservoir exhibits unique inflow patterns, while some metadata beyond observations like spatial information exerts indirect but significant influence. This mismatch limits the applicability of conventional DG techniques to many-domain hydrological systems. To overcome these challenges, we propose HydroDCM, a scalable DG framework for cross-reservoir inflow forecasting. Spatial metadata of reservoirs is used to construct pseudo-domain labels that guide adversarial learning of invariant temporal features. During inference, HydroDCM adapts these features through light-weight conditioning layers informed by the target reservoir's metadata, reconciling DG's invariance with location-specific adaptation. Experiment results on 30 real-world reservoirs in the Upper Colorado River Basin demonstrate that our method substantially outperforms state-of-the-art DG baselines under many-domain conditions and remains computationally efficient.

</details>


### [104] [Robust Tabular Foundation Models](https://arxiv.org/abs/2512.03307)
*Matthew Peroni,Franck Le,Vadim Sheinin*

Main category: cs.LG

TL;DR: RTFM提出了一种针对表格基础模型的对抗训练框架，通过参数化生成器分布来强调对模型具有挑战性的数据集，从而提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 表格基础模型(TFMs)的发展显示出超越传统ML方法的潜力，但现有研究主要关注设计高质量的数据生成器先验。本文发现参数化生成器分布可以实现对抗鲁棒性视角，通过强调对模型具有挑战性的数据集来提升性能。

Method: 提出RTFM框架：1) 引入最优性间隙度量，即TFM性能与XGBoost、CatBoost、Random Forests等强基线最佳可达性能之间的差异；2) 采用模型无关的对抗训练框架，在训练过程中调整生成器以强调对模型具有挑战性的数据集。

Result: 在TabPFN V2分类器上应用RTFM，基准性能得到提升：相比原始TabPFN和其他基线算法，平均归一化AUC提升高达6%，且仅需不到10万个额外的合成数据集。

Conclusion: RTFM展示了仅使用合成数据进行针对性对抗训练和微调表格基础模型的新方向，为提升TFM性能提供了有前景的方法。

Abstract: The development of tabular foundation models (TFMs) has accelerated in recent years, showing strong potential to outperform traditional ML methods for structured data. A key finding is that TFMs can be pretrained entirely on synthetic datasets, opening opportunities to design data generators that encourage desirable model properties. Prior work has mainly focused on crafting high-quality priors over generators to improve overall pretraining performance. Our insight is that parameterizing the generator distribution enables an adversarial robustness perspective: during training, we can adapt the generator to emphasize datasets that are particularly challenging for the model. We formalize this by introducing an optimality gap measure, given by the difference between TFM performance and the best achievable performance as estimated by strong baselines such as XGBoost, CatBoost, and Random Forests. Building on this idea, we propose Robust Tabular Foundation Models (RTFM), a model-agnostic adversarial training framework. Applied to the TabPFN V2 classifier, RTFM improves benchmark performance, with up to a 6% increase in mean normalized AUC over the original TabPFN and other baseline algorithms, while requiring less than 100k additional synthetic datasets. These results highlight a promising new direction for targeted adversarial training and fine-tuning of TFMs using synthetic data alone.

</details>


### [105] [Retrofitting Earth System Models with Cadence-Limited Neural Operator Updates](https://arxiv.org/abs/2512.03309)
*Aniruddha Bora,Shixuan Zhang,Khemraj Shukla,Bryce Harrop,George Em. Karniadakis,L. Ruby Leung*

Main category: cs.LG

TL;DR: 提出一种基于算子学习的在线偏差校正框架，通过U-Net架构将模型状态映射为偏差校正趋势，在E3SM地球系统模型运行时实时应用，实现长期稳定且可扩展的混合建模。


<details>
  <summary>Details</summary>
Motivation: 传统数据同化的偏差校正方法在模型自由运行时效果有限，地球系统模型存在分辨率低、参数化不完善、初始状态和强迫场不确定等问题，需要新的方法来改进模型预测能力。

Method: 开发基于U-Net的算子学习框架，包括Inception U-Net (IUNet)和多尺度网络(M&M)两种架构，结合多种上采样和感受野设计来捕捉多尺度非线性特征。使用两年E3SM模拟数据（向ERA5再分析数据逼近）进行训练，在线集成到E3SM中实时应用偏差校正趋势。

Result: 两种架构在离线测试中都优于标准U-Net基线，表明功能丰富性而非参数数量决定性能。在线混合E3SM运行中，M&M在变量和垂直层次上提供最一致的偏差减少。ML增强配置在多年代模拟中保持稳定且计算可行。

Conclusion: 该框架强调长期稳定性、可移植性和更新频率限制，展示了表达性ML算子在学习结构化跨尺度关系和改进传统地球系统模型方面的实用性，为可扩展混合建模提供了实用途径。

Abstract: Coarse resolution, imperfect parameterizations, and uncertain initial states and forcings limit Earth-system model (ESM) predictions. Traditional bias correction via data assimilation improves constrained simulations but offers limited benefit once models run freely. We introduce an operator-learning framework that maps instantaneous model states to bias-correction tendencies and applies them online during integration. Building on a U-Net backbone, we develop two operator architectures Inception U-Net (IUNet) and a multi-scale network (M\&M) that combine diverse upsampling and receptive fields to capture multiscale nonlinear features under Energy Exascale Earth System Model (E3SM) runtime constraints. Trained on two years E3SM simulations nudged toward ERA5 reanalysis, the operators generalize across height levels and seasons. Both architectures outperform standard U-Net baselines in offline tests, indicating that functional richness rather than parameter count drives performance. In online hybrid E3SM runs, M\&M delivers the most consistent bias reductions across variables and vertical levels. The ML-augmented configurations remain stable and computationally feasible in multi-year simulations, providing a practical pathway for scalable hybrid modeling. Our framework emphasizes long-term stability, portability, and cadence-limited updates, demonstrating the utility of expressive ML operators for learning structured, cross-scale relationships and retrofitting legacy ESMs.

</details>


### [106] [Cache What Lasts: Token Retention for Memory-Bounded KV Cache in LLMs](https://arxiv.org/abs/2512.03324)
*Ngoc Bui,Shubham Sharma,Simran Lamba,Saumitra Mishra,Rex Ying*

Main category: cs.LG

TL;DR: TRIM-KV：一种通过学习令牌内在重要性来管理KV缓存的新方法，使用轻量级保留门预测保留分数，在内存受限时淘汰低分令牌，显著提升长序列推理效率。


<details>
  <summary>Details</summary>
Motivation: 长序列LLM推理中，自注意力的二次计算成本和不断增长的KV缓存成为核心瓶颈。现有方法如量化、卸载或启发式KV淘汰要么协调成本高，要么依赖不可靠的重要性代理。

Method: 提出TRIM-KV方法，通过轻量级保留门学习每个令牌在创建时的内在重要性。每个门预测一个随时间衰减的标量保留分数，反映令牌对特定层和头的长期效用。当内存预算超限时淘汰低分令牌，确保缓存始终包含最关键令牌。通过蒸馏和容量损失高效训练，仅需微调门且推理开销可忽略。

Result: 在数学推理（GSM8K、MATH-500、AIME24）、程序生成（LongProc）、对话长记忆基准（LongMemEval）和长上下文理解（LongBench和SCBench）上，TRIM-KV始终优于强淘汰和可学习检索基线，尤其在低内存场景下。在某些设置中甚至超越全缓存模型，表明选择性保留可作为正则化形式，抑制无信息令牌的噪声。

Conclusion: TRIM-KV通过学习令牌内在重要性有效管理KV缓存，显著提升长序列推理效率。保留分数与人类直觉一致，自然恢复启发式策略如sink tokens、滑动窗口和要点压缩。保留分数还提供了层和头特定角色的洞察，为LLM可解释性开辟新路径。

Abstract: Memory and computation remain core bottlenecks in long-horizon LLM inference due to the quadratic cost of self-attention and the ever-growing key-value (KV) cache. Existing strategies for memory-bounded inference, such as quantization, offloading, or heuristic KV eviction, either incur high orchestration costs or rely on unreliable attention-based proxies of importance. We propose TRIM-KV, a novel approach that learns each token's intrinsic importance at creation time via a lightweight retention gate. Each gate predicts a scalar retention score that decays over time, reflecting the long-term utility of the token for a specific layer and head. Tokens with low scores are evicted when the memory budget is exceeded, ensuring that the cache always contains the most critical tokens. TRIM-KV is trained efficiently through distillation from a frozen LLM combined with a capacity loss, requiring only gate fine-tuning and adding negligible inference overhead. Across mathematical reasoning (GSM8K, MATH-500, AIME24), procedural generation (LongProc), conversational long-memory benchmarks (LongMemEval), and long-context understanding (LongBench and SCBench), TRIM-KV consistently outperforms strong eviction and learnable retrieval baselines, especially in low-memory regimes. Remarkably, it even surpasses full-cache models in some settings, showing that selective retention can serve as a form of regularization, suppressing noise from uninformative tokens. Qualitative analyses further reveal that learned retention scores align with human intuition, naturally recovering heuristics such as sink tokens, sliding windows, and gist compression without explicit design. Beyond efficiency, retention scores provide insights into layer- and head-specific roles, suggesting a new path toward LLM interpretability.

</details>


### [107] [Single-Round Scalable Analytic Federated Learning](https://arxiv.org/abs/2512.03336)
*Alan T. L. Bacellar,Mustafa Munir,Felipe M. G. França,Priscila M. V. Lima,Radu Marculescu,Lizy K. John*

Main category: cs.LG

TL;DR: SAFLe框架通过引入结构化头部和稀疏分组嵌入，实现了可扩展的非线性表达能力，同时保持了单轮联邦学习的优势，在联邦视觉任务中建立了新的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习面临通信开销大和异构数据性能下降两大挑战。现有的分析方法(AFL)虽然提供单轮解决方案，但仅限于线性模型；而非线性方法(如DeepAFL)虽能恢复准确性，却牺牲了单轮优势。需要打破这种权衡。

Method: 提出SAFLe框架，通过引入结构化头部（分桶特征）和稀疏分组嵌入来实现可扩展的非线性表达能力。关键创新是证明这种非线性架构在数学上等价于高维线性回归，从而能够使用AFL的单次不变聚合定律。

Result: SAFLe在联邦学习分析框架中建立了新的最先进性能，在所有基准测试中显著优于线性AFL和多轮DeepAFL的准确性，展示了联邦视觉任务的高效可扩展解决方案。

Conclusion: SAFLe成功打破了联邦学习中单轮解决方案与非线性能之间的权衡，通过数学等价性证明实现了既高效又准确的非线性联邦学习框架，为联邦视觉应用提供了实用解决方案。

Abstract: Federated Learning (FL) is plagued by two key challenges: high communication overhead and performance collapse on heterogeneous (non-IID) data. Analytic FL (AFL) provides a single-round, data distribution invariant solution, but is limited to linear models. Subsequent non-linear approaches, like DeepAFL, regain accuracy but sacrifice the single-round benefit. In this work, we break this trade-off. We propose SAFLe, a framework that achieves scalable non-linear expressivity by introducing a structured head of bucketed features and sparse, grouped embeddings. We prove this non-linear architecture is mathematically equivalent to a high-dimensional linear regression. This key equivalence allows SAFLe to be solved with AFL's single-shot, invariant aggregation law. Empirically, SAFLe establishes a new state-of-the-art for analytic FL, significantly outperforming both linear AFL and multi-round DeepAFL in accuracy across all benchmarks, demonstrating a highly efficient and scalable solution for federated vision.

</details>


### [108] [Breaking Determinism: Stochastic Modeling for Reliable Off-Policy Evaluation in Ad Auctions](https://arxiv.org/abs/2512.03354)
*Hongseon Yeom,Jaeyoul Shin,Soojin Min,Jeongmin Yoon,Seunghak Yu,Dongyeop Kang*

Main category: cs.LG

TL;DR: 提出首个确定性广告拍卖的离策略评估框架，利用出价景观模型近似倾向得分，实现稳定反事实评估，显著减少在线A/B测试成本和风险。


<details>
  <summary>Details</summary>
Motivation: 在线A/B测试消耗大量工程资源且存在收入损失风险，而传统离策略评估方法在确定性广告拍卖中不适用，因为最高出价者获胜导致非获胜广告曝光概率为零。

Method: 重新利用出价景观模型近似倾向得分，推导稳健的近似倾向分数，使自归一化逆倾向评分等稳定估计器能在确定性拍卖环境中进行反事实评估。

Result: 在AuctionNet仿真基准和大型工业平台2周在线A/B测试中验证，CTR预测达到92%平均方向准确率，显著优于参数基线，与在线结果高度一致。

Conclusion: 这是首个实用且经验证的确定性拍卖环境可靠离策略评估框架，为昂贵且高风险的在线实验提供了高效替代方案。

Abstract: Online A/B testing, the gold standard for evaluating new advertising policies, consumes substantial engineering resources and risks significant revenue loss from deploying underperforming variations. This motivates the use of Off-Policy Evaluation (OPE) for rapid, offline assessment. However, applying OPE to ad auctions is fundamentally more challenging than in domains like recommender systems, where stochastic policies are common. In online ad auctions, it is common for the highest-bidding ad to win the impression, resulting in a deterministic, winner-takes-all setting. This results in zero probability of exposure for non-winning ads, rendering standard OPE estimators inapplicable. We introduce the first principled framework for OPE in deterministic auctions by repurposing the bid landscape model to approximate the propensity score. This model allows us to derive robust approximate propensity scores, enabling the use of stable estimators like Self-Normalized Inverse Propensity Scoring (SNIPS) for counterfactual evaluation. We validate our approach on the AuctionNet simulation benchmark and against 2-weeks online A/B test from a large-scale industrial platform. Our method shows remarkable alignment with online results, achieving a 92\% Mean Directional Accuracy (MDA) in CTR prediction, significantly outperforming the parametric baseline. MDA is the most critical metric for guiding deployment decisions, as it reflects the ability to correctly predict whether a new model will improve or harm performance. This work contributes the first practical and validated framework for reliable OPE in deterministic auction environments, offering an efficient alternative to costly and risky online experiments.

</details>


### [109] [A2G-QFL: Adaptive Aggregation with Two Gains in Quantum Federated learning](https://arxiv.org/abs/2512.03363)
*Shanika Iroshi Nanayakkara,Shiva Raj Pokhrel*

Main category: cs.LG

TL;DR: 提出A2G框架，通过几何增益和QoS增益双调节机制，解决量子联邦学习中客户端质量不均、量子隐形传态保真度随机、设备不稳定等问题，提升异构噪声环境下的性能。


<details>
  <summary>Details</summary>
Motivation: 量子增强的异构经典网络中的联邦学习面临客户端质量不均、量子隐形传态保真度随机、设备不稳定以及局部与全局模型几何不匹配等问题，导致性能显著下降。经典聚合规则假设欧几里得拓扑和均匀通信可靠性，不适合新兴的量子联邦系统。

Method: 提出A2G（自适应聚合双增益）框架，包含几何增益调节几何混合，以及基于量子隐形传态保真度、延迟和不稳定性计算的QoS增益调节客户端重要性。开发A2G更新规则，在平滑性和有界方差假设下建立收敛保证，并证明A2G可退化为FedAvg、QoS感知平均和基于流形的聚合等特例。

Result: 在量子经典混合测试平台上的实验表明，A2G在异构和噪声条件下提高了稳定性和准确性。

Conclusion: A2G框架通过双增益机制有效解决了量子联邦学习中的异构性和噪声问题，为量子增强的联邦学习系统提供了鲁棒的聚合方案。

Abstract: Federated learning (FL) deployed over quantum enabled and heterogeneous classical networks faces significant performance degradation due to uneven client quality, stochastic teleportation fidelity, device instability, and geometric mismatch between local and global models. Classical aggregation rules assume euclidean topology and uniform communication reliability, limiting their suitability for emerging quantum federated systems. This paper introduces A2G (Adaptive Aggregation with Two Gains), a dual gain framework that jointly regulates geometric blending through a geometry gain and modulates client importance using a QoS gain derived from teleportation fidelity, latency, and instability. We develop the A2G update rule, establish convergence guarantees under smoothness and bounded variance assumptions, and show that A2G recovers FedAvg, QoS aware averaging, and manifold based aggregation as special cases. Experiments on a quantum classical hybrid testbed demonstrate improved stability and higher accuracy under heterogeneous and noisy conditions.

</details>


### [110] [MAGE-ID: A Multimodal Generative Framework for Intrusion Detection Systems](https://arxiv.org/abs/2512.03375)
*Mahdi Arab Loodaricheh,Mohammad Hossein Manshaei,Anita Raja*

Main category: cs.LG

TL;DR: MAGE-ID是一个基于扩散的多模态攻击生成框架，用于入侵检测系统数据增强，通过联合训练Transformer和CNN编码器，将表格流量特征与图像转换相结合，提升数据平衡性和检测性能。


<details>
  <summary>Details</summary>
Motivation: 现代入侵检测系统面临异构网络流量、不断演变的网络威胁以及良性流量与攻击流量之间严重数据不平衡的挑战。现有生成模型局限于单模态，无法捕捉跨域依赖关系。

Method: 提出MAGE-ID（多模态攻击生成器），这是一个基于扩散的生成框架，通过统一的潜在先验将表格流量特征与其转换后的图像耦合。联合训练基于Transformer和CNN的变分编码器与EDM风格去噪器，实现平衡且连贯的多模态合成。

Result: 在CIC-IDS-2017和NSL-KDD数据集上的评估显示，MAGE-ID在保真度、多样性和下游检测性能方面显著优于TabSyn和TabDDPM，证明了其多模态IDS数据增强的有效性。

Conclusion: MAGE-ID通过多模态生成方法有效解决了入侵检测中的数据不平衡问题，为异构网络环境下的威胁检测提供了更强大的数据增强解决方案。

Abstract: Modern Intrusion Detection Systems (IDS) face severe challenges due to heterogeneous network traffic, evolving cyber threats, and pronounced data imbalance between benign and attack flows. While generative models have shown promise in data augmentation, existing approaches are limited to single modalities and fail to capture cross-domain dependencies. This paper introduces MAGE-ID (Multimodal Attack Generator for Intrusion Detection), a diffusion-based generative framework that couples tabular flow features with their transformed images through a unified latent prior. By jointly training Transformer and CNN-based variational encoders with an EDM style denoiser, MAGE-ID achieves balanced and coherent multimodal synthesis. Evaluations on CIC-IDS-2017 and NSL-KDD demonstrate significant improvements in fidelity, diversity, and downstream detection performance over TabSyn and TabDDPM, highlighting the effectiveness of MAGE-ID for multimodal IDS augmentation.

</details>


### [111] [UniQL: Unified Quantization and Low-rank Compression for Adaptive Edge LLMs](https://arxiv.org/abs/2512.03383)
*Hung-Yueh Chiang,Chi-Chih Chang,Yu-Chen Lu,Chien-Yu Lin,Kai-Chiang Wu,Mohamed S. Abdelfattah,Diana Marculescu*

Main category: cs.LG

TL;DR: UniQL是一个统一的边缘LLM后训练量化和低秩压缩框架，支持在设备上配置剪枝率，实现4-5.7倍内存减少和2.7-3.4倍吞吐提升，精度损失在5%以内。


<details>
  <summary>Details</summary>
Motivation: 在移动平台上部署大语言模型面临内存有限和计算资源受限的挑战，设备工作负载直接影响资源可用性，增加了模型部署的不确定性。

Method: 提出统一的后训练量化和低秩压缩框架，包含高效结构化权重排序（加速20倍）、量化感知SVD、SSM状态感知权重排序、融合RoPE内核等技术，支持Transformers、SSMs和混合模型。

Result: 量化剪枝模型实现4-5.7倍内存减少和2.7-3.4倍吞吐提升，在15%剪枝率下精度损失控制在5%以内，支持Llama3、Qwen2.5、Mamba2、Nemotron-H和Bamba-v2等多种模型。

Conclusion: UniQL为边缘LLM部署提供高效解决方案，在云端单次工作流完成权重排序、微调和量化，同时支持设备端高达35%的可配置剪枝率，平衡了模型压缩与精度保持。

Abstract: Deploying large language model (LLM) models on mobile platforms faces significant challenges due to the limited memory and shared computational resources of the device. Resource availability may be an issue as it is directly impacted by the current device workload, adding to the uncertainty of model deployment. We introduce UniQL, a unified post-training quantization and low-rank compression framework with on-device configurable pruning rates for edge LLMs. UniQL is a general framework that integrates quantization and low-rank compression for Transformers, State Space Models (SSMs), and hybrid models to support diverse edge applications. In our proposed joint framework, we introduce an efficient structured weight-sorting method that speeds up computation by 20x, quantization-aware singular value decomposition (SVD) to minimize quantization errors, state-aware weight sorting for SSMs, and a fused rotary positional embedding (RoPE) kernel for pruned models. Our framework performs weight-sorting, fine-tuning, and quantization in the cloud in a single-pass workflow, while enabling on-device configurable pruning rates up to 35%. Our experiments show that quantized and pruned models achieve a memory reduction of 4x-5.7x and a token-throughput improvement of 2.7x-3.4x, maintaining accuracy within 5% of the original models at 15% pruning across Transformers (Llama3 and Qwen2.5), SSMs (Mamba2), and hybrid models (Nemotron-H and Bamba-v2). The code and quantized models are available at: https://github.com/enyac-group/UniQL.

</details>


### [112] [Tuning-Free Structured Sparse Recovery of Multiple Measurement Vectors using Implicit Regularization](https://arxiv.org/abs/2512.03393)
*Lakshmi Jayalal,Sheetal Kalyani*

Main category: cs.LG

TL;DR: 提出一种基于隐式正则化的免调参框架，用于多测量向量(MMV)中的联合稀疏信号恢复，无需信号稀疏度或噪声方差等先验知识。


<details>
  <summary>Details</summary>
Motivation: 传统MMV方法如M-OMP和M-FOCUSS需要仔细的参数调整或对信号稀疏度和噪声方差的先验知识，这在实际应用中存在局限性。

Method: 通过过参数化引入隐式正则化，将估计矩阵重新参数化为因子，分离共享行支持与个体向量条目。对标准最小二乘目标应用梯度下降，优化动态自动促进期望的行稀疏结构。

Result: 理论证明：在足够小且平衡的初始化下，优化动态呈现"动量效应"，真实支持中的行范数增长显著快于其他行，保证解轨迹收敛到理想化的行稀疏解。实验结果表明性能与现有方法相当。

Conclusion: 提出了一种免调参的MMV信号恢复框架，通过隐式正则化自动实现行稀疏性，无需先验信息，性能与需要调参的传统方法相当。

Abstract: Recovering jointly sparse signals in the multiple measurement vectors (MMV) setting is a fundamental problem in machine learning, but traditional methods like multiple measurement vectors orthogonal matching pursuit (M-OMP) and multiple measurement vectors FOCal Underdetermined System Solver (M-FOCUSS) often require careful parameter tuning or prior knowledge of the sparsity of the signal and/or noise variance. We introduce a novel tuning-free framework that leverages Implicit Regularization (IR) from overparameterization to overcome this limitation. Our approach reparameterizes the estimation matrix into factors that decouple the shared row-support from individual vector entries. We show that the optimization dynamics inherently promote the desired row-sparse structure by applying gradient descent to a standard least-squares objective on these factors. We prove that with a sufficiently small and balanced initialization, the optimization dynamics exhibit a "momentum-like" effect, causing the norms of rows in the true support to grow significantly faster than others. This formally guarantees that the solution trajectory converges towards an idealized row-sparse solution. Additionally, empirical results demonstrate that our approach achieves performance comparable to established methods without requiring any prior information or tuning.

</details>


### [113] [VS-Graph: Scalable and Efficient Graph Classification Using Hyperdimensional Computing](https://arxiv.org/abs/2512.03394)
*Hamed Poursiami,Shay Snyder,Guojing Cong,Thomas Potok,Maryam Parsa*

Main category: cs.LG

TL;DR: VS-Graph：一种基于向量符号架构的图学习框架，通过尖峰扩散机制和关联消息传递，在保持HDC高效性的同时接近GNN的表达能力，实现450倍训练加速且性能相当。


<details>
  <summary>Details</summary>
Motivation: 图神经网络(GNN)在图分类任务中表现优异但计算成本高，限制了其在资源受限设备上的部署。超维计算(HDC)虽然轻量高效，但现有HDC方法在预测性能上难以匹敌GNN。需要一种既能保持HDC效率又能接近GNN表达能力的解决方案。

Method: 提出VS-Graph框架：1) 尖峰扩散机制：用于拓扑驱动的节点识别；2) 关联消息传递方案：在高维向量空间内实现多跳邻域聚合。整个方法无需基于梯度的优化或反向传播。

Result: 在MUTAG和DD等标准基准测试中，比之前的HDC基线提升4-5%准确率；与GNN基线相比，在多个数据集上性能相当或更优；训练速度提升高达450倍；即使在超向量维度降至D=128时仍保持高准确率。

Conclusion: VS-Graph成功缩小了HDC效率与消息传递表达能力之间的差距，为在边缘和神经形态硬件上实现超高效执行铺平了道路，展示了在保持高性能的同时实现显著计算加速的潜力。

Abstract: Graph classification is a fundamental task in domains ranging from molecular property prediction to materials design. While graph neural networks (GNNs) achieve strong performance by learning expressive representations via message passing, they incur high computational costs, limiting their scalability and deployment on resource-constrained devices. Hyperdimensional Computing (HDC), also known as Vector Symbolic Architectures (VSA), offers a lightweight, brain-inspired alternative, yet existing HDC-based graph methods typically struggle to match the predictive performance of GNNs. In this work, we propose VS-Graph, a vector-symbolic graph learning framework that narrows the gap between the efficiency of HDC and the expressive power of message passing. VS-Graph introduces a Spike Diffusion mechanism for topology-driven node identification and an Associative Message Passing scheme for multi-hop neighborhood aggregation entirely within the high-dimensional vector space. Without gradient-based optimization or backpropagation, our method achieves competitive accuracy with modern GNNs, outperforming the prior HDC baseline by 4-5% on standard benchmarks such as MUTAG and DD. It also matches or exceeds the performance of the GNN baselines on several datasets while accelerating the training by a factor of up to 450x. Furthermore, VS-Graph maintains high accuracy even with the hypervector dimensionality reduced to D=128, demonstrating robustness under aggressive dimension compression and paving the way for ultra-efficient execution on edge and neuromorphic hardware.

</details>


### [114] [Full-Stack Alignment: Co-Aligning AI and Institutions with Thick Models of Value](https://arxiv.org/abs/2512.03399)
*Joe Edelman,Tan Zhi-Xuan,Ryan Lowe,Oliver Klingefjord,Vincent Wang-Mascianica,Matija Franklin,Ryan Othniel Kearns,Ellie Hain,Atrisha Sarkar,Michiel Bakker,Fazl Barez,David Duvenaud,Jakob Foerster,Iason Gabriel,Joseph Gubbels,Bryce Goodman,Andreas Haupt,Jobst Heitzig,Julian Jara-Ettinger,Atoosa Kasirzadeh,James Ravi Kirkpatrick,Andrew Koh,W. Bradley Knox,Philipp Koralus,Joel Lehman,Sydney Levine,Samuele Marro,Manon Revel,Toby Shorin,Morgan Sutherland,Michael Henry Tessler,Ivan Vendrov,James Wilken-Smith*

Main category: cs.LG

TL;DR: 论文提出"全栈对齐"概念，认为仅对齐AI系统与操作者意图不足以保证良好社会结果，需要同时对齐AI系统和塑造它们的机构与人类价值观，并提出"厚价值模型"作为解决方案。


<details>
  <summary>Details</summary>
Motivation: 当前AI对齐方法存在局限：即使AI系统完美对齐其操作组织的意图，如果该组织的目标与其他机构和个体目标不一致，仍可能导致不良社会结果。现有价值表示方法（如效用函数、偏好排序、非结构化文本）难以有效区分价值观与其他信号、支持规范性推理和建模集体利益。

Method: 提出"厚价值模型"方法，结构化表示价值观和规范，使系统能够区分持久价值观与短暂偏好、建模个体选择的社会嵌入性、进行规范性推理并将价值观应用于新领域。在五个领域展示该方法：AI价值管理、规范性能力代理、双赢谈判系统、意义保留经济机制和民主监管机构。

Result: 论文展示了厚价值模型在五个具体应用领域的可行性，表明这种方法能够解决当前价值表示方法的局限性，支持更有效的AI对齐和机构对齐。

Conclusion: 需要全栈对齐——同时对齐AI系统和塑造它们的机构与人类价值观，而厚价值模型是实现这一目标的关键方法，能够支持区分价值观与偏好、建模社会嵌入性和规范性推理，从而促进更好的社会结果。

Abstract: Beneficial societal outcomes cannot be guaranteed by aligning individual AI systems with the intentions of their operators or users. Even an AI system that is perfectly aligned to the intentions of its operating organization can lead to bad outcomes if the goals of that organization are misaligned with those of other institutions and individuals. For this reason, we need full-stack alignment, the concurrent alignment of AI systems and the institutions that shape them with what people value. This can be done without imposing a particular vision of individual or collective flourishing. We argue that current approaches for representing values, such as utility functions, preference orderings, or unstructured text, struggle to address these and other issues effectively. They struggle to distinguish values from other signals, to support principled normative reasoning, and to model collective goods. We propose thick models of value will be needed. These structure the way values and norms are represented, enabling systems to distinguish enduring values from fleeting preferences, to model the social embedding of individual choices, and to reason normatively, applying values in new domains. We demonstrate this approach in five areas: AI value stewardship, normatively competent agents, win-win negotiation systems, meaning-preserving economic mechanisms, and democratic regulatory institutions.

</details>


### [115] [Better World Models Can Lead to Better Post-Training Performance](https://arxiv.org/abs/2512.03400)
*Prakhar Gupta,Henry Conklin,Sarah-Jane Leslie,Andrew Lee*

Main category: cs.LG

TL;DR: 研究显式世界建模目标如何影响Transformer在不同训练阶段的内在表示和下游能力，使用2x2x2魔方任务，发现显式世界建模能产生更线性可解码和因果可操控的状态表示，并提升强化学习后训练效果


<details>
  <summary>Details</summary>
Motivation: 探索显式世界建模目标对Transformer内部表示和下游能力的影响，特别是在不同训练阶段如何影响模型的状态表示质量和后续强化学习性能

Method: 使用2x2x2魔方作为控制环境，比较标准下一个token预测与两种显式世界建模策略：(i)状态预测预训练和(ii)状态预测+下一个token联合目标，然后应用Group Relative Policy Optimization进行后训练，使用线性探针和因果干预评估表示质量

Result: 显式世界建模产生更线性可解码和因果可操控的状态表示，改进的状态表示能显著提升GRPO后训练效果，特别是在更难的魔方状态上表现更佳

Conclusion: 锐化状态表示可以提升序列规划任务的后训练效果，显式世界建模有助于改善Transformer的内部表示质量和下游任务性能

Abstract: In this work we study how explicit world-modeling objectives affect the internal representations and downstream capability of Transformers across different training stages. We use a controlled 2x2x2 Rubik's Cube and ask: (1) how does explicitly pretraining a world model affect the model's latent representations, and (2) how does world-model quality affect the model's performance after reinforcement learning post-training? We compare standard next-token prediction to two explicit world-modeling strategies -- (i) state-prediction pretraining and (ii) a joint state-prediction + next-token objective -- and assess task performance after Group Relative Policy Optimization (GRPO) is applied as post-training. We evaluate the representation quality with linear probes and causal interventions. We find that explicit world-modeling yields more linearly decodable and causally steerable state representations. More importantly, we find that improved state representations lead to higher gains for GRPO, especially on harder cube states. Our results indicate that sharpening state representations can improve the effectiveness of post-training for sequence-planning tasks.

</details>


### [116] [GaussDetect-LiNGAM:Causal Direction Identification without Gaussianity test](https://arxiv.org/abs/2512.03428)
*Ziyi Ding,Xiao-Ping Zhang*

Main category: cs.LG

TL;DR: 提出GaussDetect-LiNGAM方法，通过利用前向模型噪声的高斯性与反向模型残差独立性之间的等价关系，无需显式高斯性检验即可进行双变量因果发现。


<details>
  <summary>Details</summary>
Motivation: 传统LiNGAM方法依赖脆弱且对样本敏感的高斯性检验，这限制了其在实际应用中的可靠性和可访问性。需要一种更稳健的方法来避免这些检验。

Method: 基于理论证明：在线性、无环和外生性假设下，前向模型噪声的高斯性等价于反向模型中回归变量与残差的独立性。利用这一等价关系，用稳健的核基独立性检验替代高斯性检验。

Result: 实验验证了理论等价性，表明GaussDetect-LiNGAM在不同噪声类型和样本量下保持高一致性，同时减少了每个决策所需的检验次数（TPD）。

Conclusion: 该方法提高了因果推断的效率和实际应用性，使LiNGAM在现实场景中更加可访问和可靠。

Abstract: We propose GaussDetect-LiNGAM, a novel approach for bivariate causal discovery that eliminates the need for explicit Gaussianity tests by leveraging a fundamental equivalence between noise Gaussianity and residual independence in the reverse regression. Under the standard LiNGAM assumptions of linearity, acyclicity, and exogeneity, we prove that the Gaussianity of the forward-model noise is equivalent to the independence between the regressor and residual in the reverse model. This theoretical insight allows us to replace fragile and sample-sensitive Gaussianity tests with robust kernel-based independence tests. Experimental results validate the equivalence and demonstrate that GaussDetect-LiNGAM maintains high consistency across diverse noise types and sample sizes, while reducing the number of tests per decision (TPD). Our method enhances both the efficiency and practical applicability of causal inference, making LiNGAM more accessible and reliable in real-world scenarios.

</details>


### [117] [Grokked Models are Better Unlearners](https://arxiv.org/abs/2512.03437)
*Yuanbang Liang,Yang Li*

Main category: cs.LG

TL;DR: 研究发现，在模型完成"顿悟"（grokking）阶段后进行机器遗忘，比在早期停止时进行遗忘更有效，能实现更高效、更稳定、副作用更小的数据移除。


<details>
  <summary>Details</summary>
Motivation: 探索"顿悟"（grokking）这一延迟泛化现象是否有助于机器遗忘，即在不完全重新训练的情况下移除特定数据的影响。

Method: 比较在顿悟前后应用标准遗忘方法的效果，在视觉任务（CNN/ResNet在CIFAR、SVHN、ImageNet）和语言任务（Transformer在TOFU风格设置）上进行实验。

Result: 从顿悟后的检查点开始遗忘，相比早期停止的模型，能实现：(1) 更高效的遗忘（达到目标遗忘水平需要更少的更新），(2) 更少的附带损害（在保留数据和测试集上的性能下降更小），(3) 更稳定的更新（跨种子的变化更小）。

Conclusion: 顿悟后的模型学习到更模块化的表示，减少了遗忘子集和保留子集之间的梯度对齐，从而促进了选择性遗忘。何时训练模型（顿悟前vs后）是改进现有遗忘方法的正交杠杆。

Abstract: Grokking-delayed generalization that emerges well after a model has fit the training data-has been linked to robustness and representation quality. We ask whether this training regime also helps with machine unlearning, i.e., removing the influence of specified data without full retraining. We compare applying standard unlearning methods before versus after the grokking transition across vision (CNNs/ResNets on CIFAR, SVHN, and ImageNet) and language (a transformer on a TOFU-style setup). Starting from grokked checkpoints consistently yields (i) more efficient forgetting (fewer updates to reach a target forget level), (ii) less collateral damage (smaller drops on retained and test performance), and (iii) more stable updates across seeds, relative to early-stopped counterparts under identical unlearning algorithms. Analyses of features and curvature further suggest that post-grokking models learn more modular representations with reduced gradient alignment between forget and retain subsets, which facilitates selective forgetting. Our results highlight when a model is trained (pre- vs. post-grokking) as an orthogonal lever to how unlearning is performed, providing a practical recipe to improve existing unlearning methods without altering their algorithms.

</details>


### [118] [Multi-Modal Opinion Integration for Financial Sentiment Analysis using Cross-Modal Attention](https://arxiv.org/abs/2512.03464)
*Yujing Liu,Chen Yang*

Main category: cs.LG

TL;DR: 提出用于金融情感分析的端到端深度学习框架，整合时效性意见和流行性意见两种模态，通过跨模态注意力机制显著提升分类准确率


<details>
  <summary>Details</summary>
Motivation: 现有方法难以有效整合多样化的意见模态并捕捉模态间的细粒度交互，而金融情感分析对市场预测和风险评估至关重要

Method: 使用BERT进行特征嵌入，提出金融多头交叉注意力机制促进不同意见模态间的信息交换，通过transformer层优化特征，采用多模态因子双线性池化进行情感分类

Result: 在覆盖837家公司的综合数据集上达到83.5%的准确率，比BERT+Transformer基线方法提升21%

Conclusion: 该框架能够支持更准确的金融决策和风险管理，展示了整合不同意见模态在金融情感分析中的潜力

Abstract: In recent years, financial sentiment analysis of public opinion has become increasingly important for market forecasting and risk assessment. However, existing methods often struggle to effectively integrate diverse opinion modalities and capture fine-grained interactions across them. This paper proposes an end-to-end deep learning framework that integrates two distinct modalities of financial opinions: recency modality (timely opinions) and popularity modality (trending opinions), through a novel cross-modal attention mechanism specifically designed for financial sentiment analysis. While both modalities consist of textual data, they represent fundamentally different information channels: recency-driven market updates versus popularity-driven collective sentiment. Our model first uses BERT (Chinese-wwm-ext) for feature embedding and then employs our proposed Financial Multi-Head Cross-Attention (FMHCA) structure to facilitate information exchange between these distinct opinion modalities. The processed features are optimized through a transformer layer and fused using multimodal factored bilinear pooling for classification into negative, neutral, and positive sentiment. Extensive experiments on a comprehensive dataset covering 837 companies demonstrate that our approach achieves an accuracy of 83.5%, significantly outperforming baselines including BERT+Transformer by 21 percent. These results highlight the potential of our framework to support more accurate financial decision-making and risk management.

</details>


### [119] [Bayesian Event-Based Model for Disease Subtype and Stage Inference](https://arxiv.org/abs/2512.03467)
*Hongtao Hao,Joseph L. Austerweil*

Main category: cs.LG

TL;DR: BEBMS（贝叶斯事件基础模型子类型变体）在疾病进展子类型分析中显著优于SuStaIn，在排序、分期和子类型分配任务上表现更好，且与阿尔茨海默病科学共识更一致。


<details>
  <summary>Details</summary>
Motivation: 慢性疾病在不同患者中的进展方式存在差异，通常存在少量进展子类型。SuStaIn模型被广泛用于识别疾病子类型，但其性能稳健性需要评估。本研究旨在开发更稳健的贝叶斯模型来改进疾病进展子类型分析。

Method: 开发了BEBMS（贝叶斯事件基础模型子类型变体），通过合成数据实验在不同程度的模型误设下比较BEBMS与SuStaIn的性能，并在真实世界阿尔茨海默病数据集上应用两种方法。

Result: BEBMS在排序、分期和子类型分配任务上显著优于SuStaIn。在阿尔茨海默病数据应用中，BEBMS的结果比SuStaIn更符合该疾病进展的科学共识。

Conclusion: BEBMS作为SuStaIn的贝叶斯改进版本，在疾病进展子类型分析中表现出更好的性能和稳健性，为疾病异质性研究提供了更可靠的建模框架。

Abstract: Chronic diseases often progress differently across patients. Rather than randomly varying, there are typically a small number of subtypes for how a disease progresses across patients. To capture this structured heterogeneity, the Subtype and Stage Inference Event-Based Model (SuStaIn) estimates the number of subtypes, the order of disease progression for each subtype, and assigns each patient to a subtype from primarily cross-sectional data. It has been widely applied to uncover the subtypes of many diseases and inform our understanding of them. But how robust is its performance? In this paper, we develop a principled Bayesian subtype variant of the event-based model (BEBMS) and compare its performance to SuStaIn in a variety of synthetic data experiments with varied levels of model misspecification. BEBMS substantially outperforms SuStaIn across ordering, staging, and subtype assignment tasks. Further, we apply BEBMS and SuStaIn to a real-world Alzheimer's data set. We find BEBMS has results that are more consistent with the scientific consensus of Alzheimer's disease progression than SuStaIn.

</details>


### [120] [SweetDeep: A Wearable AI Solution for Real-Time Non-Invasive Diabetes Screening](https://arxiv.org/abs/2512.03471)
*Ian Henriques,Lynda Elhassar,Sarvesh Relekar,Denis Walrave,Shayan Hassantabar,Vishu Ghanakota,Adel Laoui,Mahmoud Aich,Rafia Tir,Mohamed Zerguine,Samir Louafi,Moncef Kimouche,Emmanuel Cosson,Niraj K Jha*

Main category: cs.LG

TL;DR: SweetDeep是一个轻量级神经网络，使用三星Galaxy Watch 7在自由生活条件下收集的生理和人口统计数据，以82.5%的准确率检测2型糖尿病。


<details>
  <summary>Details</summary>
Motivation: 2型糖尿病全球发病率上升，需要可扩展且经济高效的筛查方法。现有诊断方法（生化检测）具有侵入性和成本高的缺点。虽然可穿戴设备已用于疾病检测探索，但先前研究仅限于受控环境。

Method: 开发了SweetDeep紧凑神经网络，使用来自欧盟和MENA地区285名（糖尿病和非糖尿病）参与者的数据。数据通过三星Galaxy Watch 7在自由生活条件下收集6天，每人每天多个2分钟传感器记录，总计约20个记录/人。模型参数少于3,000个，采用三折交叉验证。

Result: 患者级准确率达到82.5%（宏F1分数82.1%，敏感性79.7%，特异性84.6%），预期校准误差5.5%。当模型对低置信度预测（少于10%）选择弃权时，剩余患者的准确率提升至84.5%。

Conclusion: 结合工程特征与轻量级架构可以在真实世界可穿戴设备环境中实现准确、快速且可泛化的2型糖尿病检测，为可扩展的糖尿病筛查提供了有前景的解决方案。

Abstract: The global rise in type 2 diabetes underscores the need for scalable and cost-effective screening methods. Current diagnosis requires biochemical assays, which are invasive and costly. Advances in consumer wearables have enabled early explorations of machine learning-based disease detection, but prior studies were limited to controlled settings. We present SweetDeep, a compact neural network trained on physiological and demographic data from 285 (diabetic and non-diabetic) participants in the EU and MENA regions, collected using Samsung Galaxy Watch 7 devices in free-living conditions over six days. Each participant contributed multiple 2-minute sensor recordings per day, totaling approximately 20 recordings per individual. Despite comprising fewer than 3,000 parameters, SweetDeep achieves 82.5% patient-level accuracy (82.1% macro-F1, 79.7% sensitivity, 84.6% specificity) under three-fold cross-validation, with an expected calibration error of 5.5%. Allowing the model to abstain on less than 10% of low-confidence patient predictions yields an accuracy of 84.5% on the remaining patients. These findings demonstrate that combining engineered features with lightweight architectures can support accurate, rapid, and generalizable detection of type 2 diabetes in real-world wearable settings.

</details>


### [121] [Joint Progression Modeling (JPM): A Probabilistic Framework for Mixed-Pathology Progression](https://arxiv.org/abs/2512.03475)
*Hongtao Hao,Joseph L. Austerweil*

Main category: cs.LG

TL;DR: JPM是一个概率框架，用于从横断面数据推断混合神经退行性疾病的联合进展，将单疾病轨迹视为部分排序并构建联合进展先验，相比单疾病EBM基线提高了约21%的排序准确性。


<details>
  <summary>Details</summary>
Motivation: 标准事件模型（EBMs）假设每个个体只有单一疾病，但神经退行性疾病中混合病理很常见，需要能够处理多种疾病同时进展的模型。

Method: 提出联合进展模型（JPM），将单疾病轨迹视为部分排序，构建联合进展先验，研究了四种变体（Pairwise、Bradley-Terry、Plackett-Luce、Mallows），分析了校准性、分离性和锐度三个属性。

Result: 所有JPM变体都具有校准性，分离性接近完美；锐度因变体而异，可通过输入部分排序的简单特征预测；在合成实验中，JPM比强EBM基线（SA-EBM）提高了约21%的排序准确性；在NACC数据中，Mallows变体和基线模型的结果与AD和VaD混合病理进展的先前文献更一致。

Conclusion: JPM是处理混合神经退行性疾病进展的有效框架，能够从横断面数据中准确推断联合疾病进展，为理解复杂病理相互作用提供了新工具。

Abstract: Event-based models (EBMs) infer disease progression from cross-sectional data, and standard EBMs assume a single underlying disease per individual. In contrast, mixed pathologies are common in neurodegeneration. We introduce the Joint Progression Model (JPM), a probabilistic framework that treats single-disease trajectories as partial rankings and builds a prior over joint progressions. We study several JPM variants (Pairwise, Bradley-Terry, Plackett-Luce, and Mallows) and analyze three properties: (i) calibration -- whether lower model energy predicts smaller distance to the ground truth ordering; (ii) separation -- the degree to which sampled rankings are distinguishable from random permutations; and (iii) sharpness -- the stability of sampled aggregate rankings. All variants are calibrated, and all achieve near-perfect separation; sharpness varies by variant and is well-predicted by simple features of the input partial rankings (number and length of rankings, conflict, and overlap). In synthetic experiments, JPM improves ordering accuracy by roughly 21 percent over a strong EBM baseline (SA-EBM) that treats the joint disease as a single condition. Finally, using NACC, we find that the Mallows variant of JPM and the baseline model (SA-EBM) have results that are more consistent with prior literature on the possible disease progression of the mixed pathology of AD and VaD.

</details>


### [122] [Modal Logical Neural Networks](https://arxiv.org/abs/2512.03491)
*Antonin Sulc*

Main category: cs.LG

TL;DR: 提出Modal Logical Neural Networks (MLNNs)，一个结合深度学习与模态逻辑形式语义的神经符号框架，能够进行必然性和可能性推理。


<details>
  <summary>Details</summary>
Motivation: 需要将深度学习与形式逻辑推理相结合，特别是模态逻辑中的必然性和可能性概念，以创建可微分的"逻辑护栏"系统。

Method: 基于Kripke语义，引入专门处理模态运算符$\Box$和$\Diamond$的神经元，这些神经元在一组可能世界上操作。框架允许用户固定世界间的可达关系以强制执行已知规则，或通过神经网络参数化学习逻辑系统的关系结构。

Result: 在四个案例研究中展示了MLNNs的应用：语法护栏、未知的公理检测、多智能体认知信任、以及自然语言谈判中的建设性欺骗检测。实验表明强制执行或学习可达关系可以提高逻辑一致性和可解释性。

Conclusion: MLNNs提供了一个灵活的端到端可微分框架，能够同时执行演绎推理和学习逻辑结构，增强了神经符号系统的逻辑一致性和可解释性。

Abstract: We propose Modal Logical Neural Networks (MLNNs), a neurosymbolic framework that integrates deep learning with the formal semantics of modal logic, enabling reasoning about necessity and possibility. Drawing on Kripke semantics, we introduce specialized neurons for the modal operators $\Box$ and $\Diamond$ that operate over a set of possible worlds, enabling the framework to act as a differentiable ``logical guardrail.'' The architecture is highly flexible: the accessibility relation between worlds can either be fixed by the user to enforce known rules or, as an inductive feature, be parameterized by a neural network. This allows the model to optionally learn the relational structure of a logical system from data while simultaneously performing deductive reasoning within that structure.
  This versatile construction is designed for flexibility. The entire framework is differentiable from end to end, with learning driven by minimizing a logical contradiction loss. This not only makes the system resilient to inconsistent knowledge but also enables it to learn nonlinear relationships that can help define the logic of a problem space. We illustrate MLNNs on four case studies: grammatical guardrailing, axiomatic detection of the unknown, multi-agent epistemic trust, and detecting constructive deception in natural language negotiation. These experiments demonstrate how enforcing or learning accessibility can increase logical consistency and interpretability without changing the underlying task architecture.

</details>


### [123] [Physics-Driven Learning Framework for Tomographic Tactile Sensing](https://arxiv.org/abs/2512.03512)
*Xuanxuan Yang,Xiuyang Zhang,Haofeng Chen,Gang Ma,Xiaojie Wang*

Main category: cs.LG

TL;DR: PhyDNN：一种将EIT前向模型嵌入学习目标的物理驱动深度重建框架，用于提高电阻抗断层扫描触觉传感的准确性和物理合理性。


<details>
  <summary>Details</summary>
Motivation: 电阻抗断层扫描（EIT）因其布线简单和形状灵活性而成为大面积触觉传感的有吸引力的解决方案，但其非线性逆问题通常会导致严重的伪影和不准确的接触重建。

Method: 提出PhyDNN框架，将EIT前向模型直接嵌入学习目标，通过联合最小化预测与真实电导率图之间的差异并强制与正向PDE的一致性，减少深度网络的黑盒性质。设计可微分前向算子网络来准确近似非线性EIT响应，实现快速物理引导训练。

Result: 在16电极软传感器上的大量仿真和真实触觉实验表明，PhyDNN在重建接触形状、位置和压力分布方面始终优于NOSER、TV和标准DNN，产生更少的伪影、更清晰的边界和更高的度量分数。

Conclusion: PhyDNN通过将物理模型嵌入深度学习框架，提高了电阻抗断层扫描触觉传感的重建质量和物理合理性，为高质量断层触觉传感提供了有效解决方案。

Abstract: Electrical impedance tomography (EIT) provides an attractive solution for large-area tactile sensing due to its minimal wiring and shape flexibility, but its nonlinear inverse problem often leads to severe artifacts and inaccurate contact reconstruction. This work presents PhyDNN, a physics-driven deep reconstruction framework that embeds the EIT forward model directly into the learning objective. By jointly minimizing the discrepancy between predicted and ground-truth conductivity maps and enforcing consistency with the forward PDE, PhyDNN reduces the black-box nature of deep networks and improves both physical plausibility and generalization. To enable efficient backpropagation, we design a differentiable forward-operator network that accurately approximates the nonlinear EIT response, allowing fast physics-guided training. Extensive simulations and real tactile experiments on a 16-electrode soft sensor show that PhyDNN consistently outperforms NOSER, TV, and standard DNNs in reconstructing contact shape, location, and pressure distribution. PhyDNN yields fewer artifacts, sharper boundaries, and higher metric scores, demonstrating its effectiveness for high-quality tomographic tactile sensing.

</details>


### [124] [Adaptive sampling using variational autoencoder and reinforcement learning](https://arxiv.org/abs/2512.03525)
*Adil Rasheed,Mikael Aleksander Jansen Shahly,Muhammad Faisal Aftab*

Main category: cs.LG

TL;DR: 提出自适应稀疏感知框架，结合变分自编码器先验与强化学习进行序列测量选择，优于传统压缩感知、最优传感器布局和生成模型方法。


<details>
  <summary>Details</summary>
Motivation: 传统压缩感知依赖通用基和随机测量，效率和质量受限；最优传感器布局使用历史数据但固定线性基无法适应非线性或样本特定变化；生成模型压缩感知使用深度生成先验但仍采用次优随机采样。

Method: 提出自适应稀疏感知框架，将变分自编码器先验与强化学习耦合，实现序列测量选择。强化学习根据当前测量结果自适应选择下一个最优测量位置。

Result: 实验表明该方法在稀疏测量重建方面优于压缩感知、最优传感器布局和生成模型重建方法。

Conclusion: 通过结合变分自编码器先验与强化学习的自适应测量选择，能够显著提升稀疏感知的重建质量和效率。

Abstract: Compressed sensing enables sparse sampling but relies on generic bases and random measurements, limiting efficiency and reconstruction quality. Optimal sensor placement uses historcal data to design tailored sampling patterns, yet its fixed, linear bases cannot adapt to nonlinear or sample-specific variations. Generative model-based compressed sensing improves reconstruction using deep generative priors but still employs suboptimal random sampling. We propose an adaptive sparse sensing framework that couples a variational autoencoder prior with reinforcement learning to select measurements sequentially. Experiments show that this approach outperforms CS, OSP, and Generative model-based reconstruction from sparse measurements.

</details>


### [125] [Parameter-Efficient Augment Plugin for Class-Incremental Learning](https://arxiv.org/abs/2512.03537)
*Zhiming Xu,Baile Xu,Jian Zhao,Furao Shen,Suorong Yang*

Main category: cs.LG

TL;DR: 本文提出了一种名为DLC的插件扩展范式，用于非预训练的类增量学习场景。通过将特征提取器作为基础模型，为每个任务使用LoRA注入任务特定残差，并通过轻量级加权单元聚合表示，在仅增加4%参数的情况下实现了8%的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 现有的类增量学习方法存在遗忘问题或稳定性-可塑性困境，而扩展方法虽然准确率更高但需要大量参数增加。需要一种既高效又有效的增量学习解决方案。

Method: 提出DLC（Deployment of extra LoRA Components）插件扩展范式：1）将基于回放或知识蒸馏训练的特征提取器作为基础模型；2）为每个任务使用LoRA（低秩适应）在基础模型的深层注入任务特定残差；3）推理时聚合带有任务特定残差的表示；4）引入轻量级加权单元来减轻非目标LoRA插件的干扰。

Result: 在ImageNet-100数据集上，仅使用标准ResNet-18的4%参数，DLC模型实现了8%的准确率显著提升。在固定内存预算下超越了最先进的方法。

Conclusion: DLC作为一种即插即用的增强方法，能够高效扩展基础方法，在类增量学习中实现了参数效率和准确率的良好平衡。

Abstract: Existing class-incremental learning (CIL) approaches based on replay or knowledge distillation are often constrained by forgetting or the stability-plasticity dilemma. Some expansion-based approaches could achieve higher accuracy. However, they always require significant parameter increases. In this paper, we propose a plugin extension paradigm termed the Deployment of extra LoRA Components (DLC) for non-pre-trained CIL scenarios.We treat the feature extractor trained through replay or distillation as a base model with rich knowledge. For each task, we use Low-Rank Adaptation (LoRA) to inject task-specific residuals into the base model's deep layers. During inference, representations with task-specific residuals are aggregated to produce classification predictions. To mitigate interference from non-target LoRA plugins, we introduce a lightweight weighting unit. This unit learns to assign importance scores to different LoRA-tuned representations. Like downloadable contents in software, our method serves as a plug-and-play enhancement that efficiently extends the base methods. Remarkably, on the large-scale ImageNet-100, with merely 4 % of the parameters of a standard ResNet-18, our DLC model achieves a significant 8 % improvement in accuracy, demonstrating exceptional efficiency. Moreover, it could surpass state-of-the-art methods under the fixed memory budget.

</details>


### [126] [Towards Irreversible Machine Unlearning for Diffusion Models](https://arxiv.org/abs/2512.03564)
*Xun Yuan,Zilong Zhao,Jiayu Li,Aryan Pasikhani,Prosanta Gope,Biplab Sikdar*

Main category: cs.LG

TL;DR: 本文提出针对扩散模型微调式遗忘方法的重新学习攻击(DiMRA)，并开发了基于记忆的遗忘方法(DiMUM)来增强鲁棒性


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成合成图像方面表现出色，但存在安全、隐私和版权问题，需要机器遗忘技术来让模型忘记特定训练数据。现有基于微调的遗忘方法虽然高效，但存在安全漏洞

Method: 1) 提出DiMRA攻击：在无遗忘元素先验知识的情况下，通过优化辅助数据集来逆转遗忘过程；2) 提出DiMUM方法：通过记忆替代数据/特征来替换目标遗忘内容，防止生成敏感元素

Result: 实验证明DiMRA能有效逆转现有最先进的微调式遗忘方法，揭示了这类技术的脆弱性。DiMUM在保持扩散模型生成性能的同时，显著增强了对DiMRA攻击的鲁棒性

Conclusion: 基于微调的扩散模型遗忘方法存在被重新学习攻击的风险，需要更鲁棒的解决方案。DiMUM通过记忆替代内容的方法提供了更安全的遗忘机制

Abstract: Diffusion models are renowned for their state-of-the-art performance in generating synthetic images. However, concerns related to safety, privacy, and copyright highlight the need for machine unlearning, which can make diffusion models forget specific training data and prevent the generation of sensitive or unwanted content. Current machine unlearning methods for diffusion models are primarily designed for conditional diffusion models and focus on unlearning specific data classes or features. Among these methods, finetuning-based machine unlearning methods are recognized for their efficiency and effectiveness, which update the parameters of pre-trained diffusion models by minimizing carefully designed loss functions. However, in this paper, we propose a novel attack named Diffusion Model Relearning Attack (DiMRA), which can reverse the finetuning-based machine unlearning methods, posing a significant vulnerability of this kind of technique. Without prior knowledge of the unlearning elements, DiMRA optimizes the unlearned diffusion model on an auxiliary dataset to reverse the unlearning, enabling the model to regenerate previously unlearned elements. To mitigate this vulnerability, we propose a novel machine unlearning method for diffusion models, termed as Diffusion Model Unlearning by Memorization (DiMUM). Unlike traditional methods that focus on forgetting, DiMUM memorizes alternative data or features to replace targeted unlearning data or features in order to prevent generating such elements. In our experiments, we demonstrate the effectiveness of DiMRA in reversing state-of-the-art finetuning-based machine unlearning methods for diffusion models, highlighting the need for more robust solutions. We extensively evaluate DiMUM, demonstrating its superior ability to preserve the generative performance of diffusion models while enhancing robustness against DiMRA.

</details>


### [127] [When, How Long and How Much? Interpretable Neural Networks for Time Series Regression by Learning to Mask and Aggregate](https://arxiv.org/abs/2512.03578)
*Florent Forest,Amaury Wei,Olga Fink*

Main category: cs.LG

TL;DR: MAGNETS是一个用于时间序列外生回归任务的可解释神经网络架构，它通过学习一组可理解的概念来实现透明预测，无需概念标注。


<details>
  <summary>Details</summary>
Motivation: 当前时间序列外生回归模型虽然预测性能强，但通常是黑盒模型，难以理解驱动决策的时间模式。现有的后验可解释性技术产生粗糙、嘈杂或不稳定的解释，而固有的可解释方法需要概念标注、无法捕捉特征交互、表达能力有限且难以扩展到高维数据。

Method: 提出MAGNETS架构，通过学习一组紧凑的人类可理解概念（无需标注），每个概念对应基于掩码的聚合操作，选择相关输入特征并揭示何时重要。预测通过这些概念的透明加法组合形成。

Result: MAGNETS能够提供清晰的可解释性，明确显示哪些特征驱动预测以及它们在序列中何时重要，同时保持预测性能。

Conclusion: MAGNETS解决了现有可解释时间序列回归方法的局限性，通过无监督学习概念和透明加法结构，实现了既准确又可解释的时间序列预测。

Abstract: Time series extrinsic regression (TSER) refers to the task of predicting a continuous target variable from an input time series. It appears in many domains, including healthcare, finance, environmental monitoring, and engineering. In these settings, accurate predictions and trustworthy reasoning are both essential. Although state-of-the-art TSER models achieve strong predictive performance, they typically operate as black boxes, making it difficult to understand which temporal patterns drive their decisions. Post-hoc interpretability techniques, such as feature attribution, aim to to explain how the model arrives at its predictions, but often produce coarse, noisy, or unstable explanations. Recently, inherently interpretable approaches based on concepts, additive decompositions, or symbolic regression, have emerged as promising alternatives. However, these approaches remain limited: they require explicit supervision on the concepts themselves, often cannot capture interactions between time-series features, lack expressiveness for complex temporal patterns, and struggle to scale to high-dimensional multivariate data.
  To address these limitations, we propose MAGNETS (Mask-and-AGgregate NEtwork for Time Series), an inherently interpretable neural architecture for TSER. MAGNETS learns a compact set of human-understandable concepts without requiring any annotations. Each concept corresponds to a learned, mask-based aggregation over selected input features, explicitly revealing both which features drive predictions and when they matter in the sequence. Predictions are formed as combinations of these learned concepts through a transparent, additive structure, enabling clear insight into the model's decision process.

</details>


### [128] [Optimal Transportation and Alignment Between Gaussian Measures](https://arxiv.org/abs/2512.03579)
*Sanjit Dandapanthula,Aleksandr Podkopaev,Shiva Prasad Kasiviswanathan,Aaditya Ramdas,Ziv Goldfeld*

Main category: cs.LG

TL;DR: 该论文为高斯分布下的最优传输和Gromov-Wasserstein对齐提供了全面的闭式解，解决了文献中的多个空白，并应用于知识蒸馏和异构聚类。


<details>
  <summary>Details</summary>
Motivation: 最优传输和Gromov-Wasserstein对齐在数据科学中应用广泛，但计算成本高昂。现有方法主要依赖高斯分布在二次成本下的闭式解，但文献中仍存在多个未解决的问题，限制了其应用范围。

Method: 1. 针对可分希尔伯特空间上非中心高斯分布的IGW对齐，给出了闭式表达式（需通过酉算子优化）；2. 当至少一个高斯分布中心化时，提供完全闭式解；3. 将高斯多边际OT问题简化为可处理的优化问题，并提出使用秩缺陷约束的高效算法。

Result: 1. 推导了非中心高斯IGW对齐的闭式表达式及上下界；2. 获得了中心化高斯IGW对齐的完全闭式解；3. 提出了高斯IGW重心问题的解析解；4. 开发了高效的多边际OT算法。

Conclusion: 该工作填补了高斯分布下OT和GW对齐的理论空白，提供了实用的闭式解和高效算法，成功应用于知识蒸馏和异构聚类任务，扩展了这些几何框架的实际应用范围。

Abstract: Optimal transport (OT) and Gromov-Wasserstein (GW) alignment provide interpretable geometric frameworks for comparing, transforming, and aggregating heterogeneous datasets -- tasks ubiquitous in data science and machine learning. Because these frameworks are computationally expensive, large-scale applications often rely on closed-form solutions for Gaussian distributions under quadratic cost. This work provides a comprehensive treatment of Gaussian, quadratic cost OT and inner product GW (IGW) alignment, closing several gaps in the literature to broaden applicability. First, we treat the open problem of IGW alignment between uncentered Gaussians on separable Hilbert spaces by giving a closed-form expression up to a quadratic optimization over unitary operators, for which we derive tight analytic upper and lower bounds. If at least one Gaussian measure is centered, the solution reduces to a fully closed-form expression, which we further extend to an analytic solution for the IGW barycenter between centered Gaussians. We also present a reduction of Gaussian multimarginal OT with pairwise quadratic costs to a tractable optimization problem and provide an efficient algorithm to solve it using a rank-deficiency constraint. To demonstrate utility, we apply our results to knowledge distillation and heterogeneous clustering on synthetic and real-world datasets.

</details>


### [129] [Federated Learning and Trajectory Compression for Enhanced AIS Coverage](https://arxiv.org/abs/2512.03584)
*Thomas Gräupl,Andreas Reisenbauer,Marcel Hecko,Anil Rasouli,Anita Graser,Melitta Dragaschnig,Axel Weissenfeld,Gilles Dejaegere,Mahmoud Sakr*

Main category: cs.LG

TL;DR: VesselEdge系统利用联邦学习和带宽受限轨迹压缩技术，将船舶转变为移动传感器，通过扩展AIS覆盖范围来增强海上态势感知能力。


<details>
  <summary>Details</summary>
Motivation: 解决海上AIS覆盖范围有限的问题，提高海上态势感知能力，特别是在低带宽连接环境下实现实时异常检测和高效数据传输。

Method: 系统结合M3fed联邦学习模型和BWC-DR-A轨迹压缩算法，将船舶转变为移动传感器，优先传输异常数据，在带宽受限条件下优化数据传输。

Result: 初步结果显示VesselEdge能有效提高AIS覆盖范围和态势感知能力，使用历史数据验证了系统的有效性。

Conclusion: VesselEdge系统通过联邦学习和轨迹压缩技术，成功扩展了AIS覆盖范围，增强了海上态势感知，为低带宽环境下的实时异常检测提供了可行解决方案。

Abstract: This paper presents the VesselEdge system, which leverages federated learning and bandwidth-constrained trajectory compression to enhance maritime situational awareness by extending AIS coverage. VesselEdge transforms vessels into mobile sensors, enabling real-time anomaly detection and efficient data transmission over low-bandwidth connections. The system integrates the M3fed model for federated learning and the BWC-DR-A algorithm for trajectory compression, prioritizing anomalous data. Preliminary results demonstrate the effectiveness of VesselEdge in improving AIS coverage and situational awareness using historical data.

</details>


### [130] [Observation-driven correction of numerical weather prediction for marine winds](https://arxiv.org/abs/2512.03606)
*Matteo Peduto,Qidong Yang,Jonathan Giezendanner,Devis Tuia,Sherrie Wang*

Main category: cs.LG

TL;DR: 该论文提出了一种基于Transformer的深度学习架构，通过同化最新观测数据来修正全球天气预报系统(GFS)的风场输出，显著提高了海洋风场预报精度。


<details>
  <summary>Details</summary>
Motivation: 海洋风场预报对航行安全、船舶路线规划和能源运营至关重要，但由于海洋观测数据稀疏、异构且时间变化大，准确预报仍然具有挑战性。

Method: 将风场预报重新定义为观测信息驱动的数值天气预报(NWP)模型修正。提出Transformer架构，通过掩码和基于集合的注意力机制处理不规则观测数据，使用交叉注意力结合最新观测-预报对，采用循环时间嵌入和坐标感知位置表示实现单次推理。

Result: 在大西洋区域使用ICOADS观测数据评估，模型在所有48小时预报时效内均降低了GFS 10米风场RMSE，1小时预报改进45%，48小时预报改进13%。在海岸线和航线等观测密集区域改进最显著。

Conclusion: 该方法提供了一种实用、低延迟的后处理方案，能够学习修正系统性预报误差，兼容多种观测平台，可同时生成站点特定预测和区域网格产品。

Abstract: Accurate marine wind forecasts are essential for safe navigation, ship routing, and energy operations, yet they remain challenging because observations over the ocean are sparse, heterogeneous, and temporally variable. We reformulate wind forecasting as observation-informed correction of a global numerical weather prediction (NWP) model. Rather than forecasting winds directly, we learn local correction patterns by assimilating the latest in-situ observations to adjust the Global Forecast System (GFS) output. We propose a transformer-based deep learning architecture that (i) handles irregular and time-varying observation sets through masking and set-based attention mechanisms, (ii) conditions predictions on recent observation-forecast pairs via cross-attention, and (iii) employs cyclical time embeddings and coordinate-aware location representations to enable single-pass inference at arbitrary spatial coordinates. We evaluate our model over the Atlantic Ocean using observations from the International Comprehensive Ocean-Atmosphere Data Set (ICOADS) as reference. The model reduces GFS 10-meter wind RMSE at all lead times up to 48 hours, achieving 45% improvement at 1-hour lead time and 13% improvement at 48-hour lead time. Spatial analyses reveal the most persistent improvements along coastlines and shipping routes, where observations are most abundant. The tokenized architecture naturally accommodates heterogeneous observing platforms (ships, buoys, tide gauges, and coastal stations) and produces both site-specific predictions and basin-scale gridded products in a single forward pass. These results demonstrate a practical, low-latency post-processing approach that complements NWP by learning to correct systematic forecast errors.

</details>


### [131] [CoGraM: Context-sensitive granular optimization method with rollback for robust model fusion](https://arxiv.org/abs/2512.03610)
*Julius Lenz*

Main category: cs.LG

TL;DR: CoGraM是一种用于联邦学习和分布式学习中神经网络合并的多阶段、上下文敏感、基于损失的迭代优化方法，相比权重平均和Fisher合并等方法能显著提升合并网络的准确性


<details>
  <summary>Details</summary>
Motivation: 联邦学习和分布式学习中需要在不重新训练的情况下合并神经网络，但现有方法如权重平均或Fisher合并存在精度损失和不稳定的问题

Method: CoGraM是一种多阶段、上下文敏感、基于损失的迭代优化方法，通过跨层、神经元和权重级别的优化，对齐决策与损失差异和阈值，并通过回滚机制防止有害更新

Result: CoGraM能够显著改善合并后的网络性能，解决了Fisher等方法的弱点

Conclusion: CoGraM为联邦学习和分布式学习中的神经网络合并提供了一种更有效和稳定的优化方法

Abstract: Merging neural networks without retraining is central to federated and distributed learning. Common methods such as weight averaging or Fisher merging often lose accuracy and are unstable across seeds. CoGraM (Contextual Granular Merging) is a multi-stage, context-sensitive, loss-based, and iterative optimization method across layers, neurons, and weight levels that aligns decisions with loss differences and thresholds and prevents harmful updates through rollback. CoGraM is an optimization method that addresses the weaknesses of methods such as Fisher and can significantly improve the merged network.

</details>


### [132] [The promising potential of vision language models for the generation of textual weather forecasts](https://arxiv.org/abs/2512.03623)
*Edward C. C. Steele,Dinesh Mane,Emilio Monti,Luis Orus,Rebecca Chantrill-Cheyette,Matthew Couch,Kirstine I. Dale,Simon Eaton,Govindarajan Rangarajan,Amir Majlesi,Steven Ramsdale,Michael Sharpe,Craig Smith,Jonathan Smith,Rebecca Yates,Holly Ellis,Charles Ewen*

Main category: cs.LG

TL;DR: 使用视觉语言模型从视频编码的网格天气数据直接生成航运天气预报文本，探索多模态基础模型在气象服务中的新应用


<details>
  <summary>Details</summary>
Motivation: 尽管多模态基础模型具有巨大潜力，但在气象产品和服务生成方面的应用仍处于起步阶段。为了加速该领域的探索和采用，研究如何利用这些模型提升气象服务的生产效率和创新

Method: 采用视觉语言模型，将视频编码的网格天气数据作为输入，直接生成经典的航运天气预报文本

Result: 早期结果显示，这种方法在提升生产效率和促进服务创新方面展现出有前景的可扩展技术机会

Conclusion: 这项研究为气象企业及其他领域展示了利用多模态基础模型增强生产效率和推动服务创新的新途径

Abstract: Despite the promising capability of multimodal foundation models, their application to the generation of meteorological products and services remains nascent. To accelerate aspiration and adoption, we explore the novel use of a vision language model for writing the iconic Shipping Forecast text directly from video-encoded gridded weather data. These early results demonstrate promising scalable technological opportunities for enhancing production efficiency and service innovation within the weather enterprise and beyond.

</details>


### [133] [Conditional updates of neural network weights for increased out of training performance](https://arxiv.org/abs/2512.03653)
*Jan Saynisch-Wagner,Saran Rajendran Sari*

Main category: cs.LG

TL;DR: 提出一种增强神经网络在训练数据与应用数据不相似时性能的方法，通过权重异常检测、回归建模和权重外推实现时空和跨域外推


<details>
  <summary>Details</summary>
Motivation: 解决神经网络在训练数据与应用数据不相似时的性能问题，包括分布外问题、模式变化和机制转变等挑战

Method: 三步骤方法：1) 在训练数据子集上重训练网络并记录权重异常；2) 选择合理预测因子并建立预测因子与权重异常的回归关系；3) 将权重外推到应用数据，从而外推神经网络

Result: 在气候科学三个用例中展示了方法的有效性，成功实现了时间、空间和跨域的外推

Conclusion: 该方法能够有效增强神经网络在训练数据与应用数据不相似时的性能，为处理分布外问题提供了新思路

Abstract: This study proposes a method to enhance neural network performance when training data and application data are not very similar, e.g., out of distribution problems, as well as pattern and regime shifts. The method consists of three main steps: 1) Retrain the neural network towards reasonable subsets of the training data set and note down the resulting weight anomalies. 2) Choose reasonable predictors and derive a regression between the predictors and the weight anomalies. 3) Extrapolate the weights, and thereby the neural network, to the application data. We show and discuss this method in three use cases from the climate sciences, which include successful temporal, spatial and cross-domain extrapolations of neural networks.

</details>


### [134] [Cyclical Temporal Encoding and Hybrid Deep Ensembles for Multistep Energy Forecasting](https://arxiv.org/abs/2512.03656)
*Salim Khazem,Houssam Kanso*

Main category: cs.LG

TL;DR: 提出统一的深度学习框架，结合循环时间编码与混合LSTM-CNN架构，用于多步能源预测，通过实验验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 准确的电力消费预测对需求管理和智能电网运营至关重要。现有方法在整合时间编码、日历特征和混合架构方面存在不足，需要统一的框架来提升预测精度。

Method: 1. 使用正弦余弦编码系统转换日历属性，保持周期结构；2. 通过相关性分析评估预测相关性；3. 构建集成模型：LSTM处理长期季节性效应，CNN捕捉短期局部模式，MLP回归器作为元学习器针对每个预测时域专门优化。

Result: 在一年全国消费数据集上进行实验，包括消融分析（有/无循环编码和日历特征）和与文献基线的比较。混合模型在所有七个预测时域上均取得一致改进，RMSE和MAE均低于单个架构和先前方法。

Conclusion: 循环时间表示与互补深度学习结构的结合具有显著优势。这是首个在统一短期能源预测框架中联合评估时间编码、日历特征和混合集成架构的工作。

Abstract: Accurate electricity consumption forecasting is essential for demand management and smart grid operations. This paper introduces a unified deep learning framework that integrates cyclical temporal encoding with hybrid LSTM-CNN architectures to enhance multistep energy forecasting. We systematically transform calendar-based attributes using sine cosine encodings to preserve periodic structure and evaluate their predictive relevance through correlation analysis. To exploit both long-term seasonal effects and short-term local patterns, we employ an ensemble model composed of an LSTM, a CNN, and a meta-learner of MLP regressors specialized for each forecast horizon. Using a one year national consumption dataset, we conduct an extensive experimental study including ablation analyses with and without cyclical encodings and calendar features and comparisons with established baselines from the literature. Results demonstrate consistent improvements across all seven forecast horizons, with our hybrid model achieving lower RMSE and MAE than individual architectures and prior methods. These findings confirm the benefit of combining cyclical temporal representations with complementary deep learning structures. To our knowledge, this is the first work to jointly evaluate temporal encodings, calendar-based features, and hybrid ensemble architectures within a unified short-term energy forecasting framework.

</details>


### [135] [Dynamically Scaled Activation Steering](https://arxiv.org/abs/2512.03661)
*Alex Ferrando,Xavier Suau,Jordi Gonzàlez,Pau Rodriguez*

Main category: cs.LG

TL;DR: DSAS是一个动态缩放激活引导框架，它自适应地调节现有引导方法的强度，只在检测到不良行为时进行干预，从而在毒性缓解和模型效用之间实现更好的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有激活引导方法对所有输入统一应用干预，当引导不必要时会降低模型性能。需要一种能自适应调节引导强度的方法，只在必要时进行干预。

Method: DSAS将"何时引导"与"如何引导"解耦，在生成时计算上下文相关的缩放因子，选择性地调整任何引导方法的强度。该方法可以与引导函数联合端到端优化。

Result: DSAS与现有引导方法结合时，能持续改进帕累托前沿，在毒性缓解和效用保持之间实现更好的权衡。应用于文本到图像扩散模型时，能有效调节特定概念。

Conclusion: DSAS是一个通用、高效的激活引导框架，能以最小的计算开销自适应调节引导强度，同时提高可解释性，识别哪些标记需要引导以及引导程度。

Abstract: Activation steering has emerged as a powerful method for guiding the behavior of generative models towards desired outcomes such as toxicity mitigation. However, most existing methods apply interventions uniformly across all inputs, degrading model performance when steering is unnecessary. We introduce Dynamically Scaled Activation Steering (DSAS), a method-agnostic steering framework that decouples when to steer from how to steer. DSAS adaptively modulates the strength of existing steering transformations across layers and inputs, intervening strongly only when undesired behavior is detected. At generation time, DSAS computes context-dependent scaling factors that selectively adjust the strength of any steering method. We also show how DSAS can be jointly optimized end-to-end together with the steering function. When combined with existing steering methods, DSAS consistently improves the Pareto front with respect to steering alone, achieving a better trade-off between toxicity mitigation and utility preservation. We further demonstrate DSAS's generality by applying it to a text-to-image diffusion model, showing how adaptive steering allows the modulation of specific concepts. Finally, DSAS introduces minimal computational overhead while improving interpretability, pinpointing which tokens require steering and by how much.

</details>


### [136] [Feature-aware Modulation for Learning from Temporal Tabular Data](https://arxiv.org/abs/2512.03678)
*Hao-Run Cai,Han-Jia Ye*

Main category: cs.LG

TL;DR: 提出了一种特征感知的时间调制机制，通过调整特征的统计属性来应对表格数据中的时间分布偏移，平衡模型的鲁棒性和适应性。


<details>
  <summary>Details</summary>
Motivation: 表格机器学习在现实部署中面临时间分布偏移的挑战，静态模型假设固定映射但缺乏适应性，自适应模型可能过度拟合瞬态模式，需要在鲁棒性和适应性之间取得平衡。

Method: 提出特征感知的时间调制机制，通过分析特征语义（特别是客观和主观含义）随时间演变引入概念漂移，利用特征转换策略缓解不同时间阶段特征表示的差异，将特征表示条件化于时间上下文，调制统计属性如尺度和偏度。

Result: 基准评估验证了该方法在处理表格数据时间偏移方面的有效性，通过跨时间对齐特征语义，实现了轻量级但强大的适应性，有效平衡了泛化能力和适应性。

Conclusion: 特征感知的时间调制机制能够有效处理表格数据中的时间分布偏移问题，通过调整特征统计属性来对齐跨时间的特征语义，在保持模型鲁棒性的同时实现适应性。

Abstract: While tabular machine learning has achieved remarkable success, temporal distribution shifts pose significant challenges in real-world deployment, as the relationships between features and labels continuously evolve. Static models assume fixed mappings to ensure generalization, whereas adaptive models may overfit to transient patterns, creating a dilemma between robustness and adaptability. In this paper, we analyze key factors essential for constructing an effective dynamic mapping for temporal tabular data. We discover that evolving feature semantics-particularly objective and subjective meanings-introduce concept drift over time. Crucially, we identify that feature transformation strategies are able to mitigate discrepancies in feature representations across temporal stages. Motivated by these insights, we propose a feature-aware temporal modulation mechanism that conditions feature representations on temporal context, modulating statistical properties such as scale and skewness. By aligning feature semantics across time, our approach achieves a lightweight yet powerful adaptation, effectively balancing generalizability and adaptability. Benchmark evaluations validate the effectiveness of our method in handling temporal shifts in tabular data.

</details>


### [137] [Quantum Topological Graph Neural Networks for Detecting Complex Fraud Patterns](https://arxiv.org/abs/2512.03696)
*Mohammad Doost,Mohammad Manthouri*

Main category: cs.LG

TL;DR: QTGNN是一个用于大规模金融网络欺诈检测的量子拓扑图神经网络框架，整合了量子嵌入、变分图卷积和拓扑数据分析，在NISQ设备上实现稳定训练，并在金融数据集上优于经典和量子基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统欺诈检测方法难以捕捉大规模金融交易网络中的复杂动态和结构异常，需要结合量子计算、图神经网络和拓扑数据分析来提升检测性能。

Method: 1. 量子数据嵌入与纠缠增强；2. 变分量子图卷积与非线性能量；3. 高阶拓扑不变量提取；4. 混合量子-经典异常学习与自适应优化；5. 基于拓扑归因的可解释决策；6. NISQ硬件优化（电路简化和图采样）。

Result: 在PaySim和Elliptic等金融数据集上的模拟实验表明，QTGNN在ROC-AUC、精确率和误报率等指标上优于经典和量子基线方法。消融研究验证了量子嵌入、拓扑特征、非线性通道和混合学习各组件的重要性。

Conclusion: QTGNN为金融欺诈检测提供了一个理论可靠、可解释且实用的解决方案，成功融合了量子机器学习、图论和拓扑分析，为NISQ时代的大规模金融网络分析开辟了新途径。

Abstract: We propose a novel QTGNN framework for detecting fraudulent transactions in large-scale financial networks. By integrating quantum embedding, variational graph convolutions, and topological data analysis, QTGNN captures complex transaction dynamics and structural anomalies indicative of fraud. The methodology includes quantum data embedding with entanglement enhancement, variational quantum graph convolutions with non-linear dynamics, extraction of higher-order topological invariants, hybrid quantum-classical anomaly learning with adaptive optimization, and interpretable decision-making via topological attribution. Rigorous convergence guarantees ensure stable training on noisy intermediate-scale quantum (NISQ) devices, while stability of topological signatures provides robust fraud detection. Optimized for NISQ hardware with circuit simplifications and graph sampling, the framework scales to large transaction networks. Simulations on financial datasets, such as PaySim and Elliptic, benchmark QTGNN against classical and quantum baselines, using metrics like ROC-AUC, precision, and false positive rate. An ablation study evaluates the contributions of quantum embeddings, topological features, non-linear channels, and hybrid learning. QTGNN offers a theoretically sound, interpretable, and practical solution for financial fraud detection, bridging quantum machine learning, graph theory, and topological analysis.

</details>


### [138] [Unlocking the Invisible Urban Traffic Dynamics under Extreme Weather: A New Physics-Constrained Hamiltonian Learning Algorithm](https://arxiv.org/abs/2512.03744)
*Xuhui Lin,Qiuchen Lu*

Main category: cs.LG

TL;DR: 提出一种基于物理约束哈密顿学习的算法，通过结构不可逆性检测和能量景观重构，识别城市交通系统在极端天气后的隐藏结构损伤，解决了传统表面指标无法检测"虚假恢复"的问题。


<details>
  <summary>Details</summary>
Motivation: 当前城市交通系统韧性评估方法依赖表面恢复指标，无法检测隐藏的结构损伤，存在"虚假恢复"问题——即交通指标恢复正常但系统动力学永久退化。

Method: 开发物理约束哈密顿学习算法，结合结构不可逆性检测和能量景观重构：提取低维状态表示，通过物理约束优化识别准哈密顿结构，通过能量景观比较量化结构变化。

Result: 应用于伦敦2021年极端降雨事件分析，发现表面指标完全恢复，但算法检测到64.8%的结构损伤被传统监测方法遗漏。

Conclusion: 该框架为主动结构风险评估提供工具，使基础设施投资能够基于真实的系统健康状态而非误导性的表面指标。

Abstract: Urban transportation systems face increasing resilience challenges from extreme weather events, but current assessment methods rely on surface-level recovery indicators that miss hidden structural damage. Existing approaches cannot distinguish between true recovery and "false recovery," where traffic metrics normalize, but the underlying system dynamics permanently degrade. To address this, a new physics-constrained Hamiltonian learning algorithm combining "structural irreversibility detection" and "energy landscape reconstruction" has been developed. Our approach extracts low-dimensional state representations, identifies quasi-Hamiltonian structures through physics-constrained optimization, and quantifies structural changes via energy landscape comparison. Analysis of London's extreme rainfall in 2021 demonstrates that while surface indicators were fully recovered, our algorithm detected 64.8\% structural damage missed by traditional monitoring. Our framework provides tools for proactive structural risk assessment, enabling infrastructure investments based on true system health rather than misleading surface metrics.

</details>


### [139] [Universally Converging Representations of Matter Across Scientific Foundation Models](https://arxiv.org/abs/2512.03750)
*Sathya Edamadaka,Soojung Yang,Ju Li,Rafael Gómez-Bombarelli*

Main category: cs.LG

TL;DR: 研究发现近60个科学模型（涵盖字符串、图、3D原子和蛋白质模态）在化学系统中具有高度对齐的表征，表明基础模型学习到了物理现实的共同底层表示，但当前模型仍受训练数据和归纳偏置限制。


<details>
  <summary>Details</summary>
Motivation: 理解不同模态和架构的机器学习模型是否学习到相似的物质内部表征，这对于构建能够可靠泛化到训练域之外的科学基础模型至关重要。虽然语言和视觉领域已观察到表征收敛现象，但在科学领域尚未系统探索。

Method: 研究分析了近60个科学模型（涵盖字符串、图、3D原子和蛋白质模态）的表征对齐情况，通过比较不同数据集训练的模型在小分子上的表征相似性，以及机器学习原子间势能在性能提升过程中的表征收敛情况。

Result: 1. 不同数据集训练的模型在小分子上具有高度相似的表征；2. 机器学习原子间势能随性能提升在表征空间收敛；3. 发现两种不同机制：在类似训练输入上，高性能模型紧密对齐，弱模型在表征空间发散到局部最优；在完全不同结构上，几乎所有模型都坍缩到低信息表征。

Conclusion: 科学模型确实学习到了物理现实的共同底层表示，但当前模型仍受训练数据和归纳偏置限制，尚未编码真正的通用结构。表征对齐可作为科学基础模型通用性的定量基准，有助于追踪物质通用表征的出现，并选择跨模态、物质域和科学任务转移性最佳的模型。

Abstract: Machine learning models of vastly different modalities and architectures are being trained to predict the behavior of molecules, materials, and proteins. However, it remains unclear whether they learn similar internal representations of matter. Understanding their latent structure is essential for building scientific foundation models that generalize reliably beyond their training domains. Although representational convergence has been observed in language and vision, its counterpart in the sciences has not been systematically explored. Here, we show that representations learned by nearly sixty scientific models, spanning string-, graph-, 3D atomistic, and protein-based modalities, are highly aligned across a wide range of chemical systems. Models trained on different datasets have highly similar representations of small molecules, and machine learning interatomic potentials converge in representation space as they improve in performance, suggesting that foundation models learn a common underlying representation of physical reality. We then show two distinct regimes of scientific models: on inputs similar to those seen during training, high-performing models align closely and weak models diverge into local sub-optima in representation space; on vastly different structures from those seen during training, nearly all models collapse onto a low-information representation, indicating that today's models remain limited by training data and inductive bias and do not yet encode truly universal structure. Our findings establish representational alignment as a quantitative benchmark for foundation-level generality in scientific models. More broadly, our work can track the emergence of universal representations of matter as models scale, and for selecting and distilling models whose learned representations transfer best across modalities, domains of matter, and scientific tasks.

</details>


### [140] [Origin-Conditional Trajectory Encoding: Measuring Urban Configurational Asymmetries through Neural Decomposition](https://arxiv.org/abs/2512.03755)
*Stephen Law,Tao Yang,Nanjiang Chen,Xuhui Lin*

Main category: cs.LG

TL;DR: 提出条件轨迹编码器，联合学习时空表征并保留起点依赖的不对称性，用于量化城市导航中的认知不平等


<details>
  <summary>Details</summary>
Motivation: 当前城市轨迹分析方法存在碎片化：轨迹学习忽略空间上下文，空间嵌入方法忽略时间动态；缺乏联合训练、起点无关处理忽略导航方向不对称性、过度依赖辅助数据而非基本几何特征

Method: 条件轨迹编码器框架，使用双向LSTM处理可见性比和曲率等几何特征，以可学习的起点嵌入为条件，通过对比学习将表征分解为共享城市模式和起点特定特征

Result: 在六个合成城市和北京西城区的真实数据验证表明，城市形态会产生系统性认知不平等；为城市规划者提供评估体验公平性的量化工具

Conclusion: 该框架为城市规划者提供评估体验公平性的量化工具，为建筑师提供布局决策的认知影响洞察，并为导航系统实现起点感知分析

Abstract: Urban analytics increasingly relies on AI-driven trajectory analysis, yet current approaches suffer from methodological fragmentation: trajectory learning captures movement patterns but ignores spatial context, while spatial embedding methods encode street networks but miss temporal dynamics. Three gaps persist: (1) lack of joint training that integrates spatial and temporal representations, (2) origin-agnostic treatment that ignores directional asymmetries in navigation ($A \to B \ne B \to A$), and (3) over-reliance on auxiliary data (POIs, imagery) rather than fundamental geometric properties of urban space. We introduce a conditional trajectory encoder that jointly learns spatial and movement representations while preserving origin-dependent asymmetries using geometric features. This framework decomposes urban navigation into shared cognitive patterns and origin-specific spatial narratives, enabling quantitative measurement of cognitive asymmetries across starting locations. Our bidirectional LSTM processes visibility ratio and curvature features conditioned on learnable origin embeddings, decomposing representations into shared urban patterns and origin-specific signatures through contrastive learning. Results from six synthetic cities and real-world validation on Beijing's Xicheng District demonstrate that urban morphology creates systematic cognitive inequalities. This provides urban planners quantitative tools for assessing experiential equity, offers architects insights into layout decisions' cognitive impacts, and enables origin-aware analytics for navigation systems.

</details>


### [141] [Deep Unfolding: Recent Developments, Theory, and Design Guidelines](https://arxiv.org/abs/2512.03768)
*Nir Shlezinger,Santiago Segarra,Yi Zhang,Dvir Avrahami,Zohar Davidov,Tirza Routtenberg,Yonina C. Eldar*

Main category: cs.LG

TL;DR: 深度展开是一种将迭代优化算法转换为结构化可训练机器学习架构的框架，旨在结合传统优化的理论保证与机器学习的数据驱动能力。


<details>
  <summary>Details</summary>
Motivation: 传统优化方法虽然具有可解释性和理论保证，但通常需要代理目标函数、精心调参且计算延迟高；而机器学习虽具有强大的数据驱动建模能力，但缺乏优化驱动推理所需的结构、透明性和效率。深度展开旨在桥接这两个范式。

Method: 通过系统地将迭代优化算法转换为结构化、可训练的机器学习架构，提出了四种代表性的深度展开设计范式，并讨论了由其迭代性质产生的独特训练方案。

Result: 建立了展开优化器的收敛性和泛化保证理论，并通过比较定性和实证研究说明了其在复杂性、可解释性和鲁棒性方面的相对权衡。

Conclusion: 深度展开为优化和机器学习提供了统一的视角，通过将优化求解器转换为机器学习模型，实现了理论保证与数据驱动能力的结合，在信号处理等领域具有重要应用价值。

Abstract: Optimization methods play a central role in signal processing, serving as the mathematical foundation for inference, estimation, and control. While classical iterative optimization algorithms provide interpretability and theoretical guarantees, they often rely on surrogate objectives, require careful hyperparameter tuning, and exhibit substantial computational latency. Conversely, machine learning (ML ) offers powerful data-driven modeling capabilities but lacks the structure, transparency, and efficiency needed for optimization-driven inference. Deep unfolding has recently emerged as a compelling framework that bridges these two paradigms by systematically transforming iterative optimization algorithms into structured, trainable ML architectures. This article provides a tutorial-style overview of deep unfolding, presenting a unified perspective of methodologies for converting optimization solvers into ML models and highlighting their conceptual, theoretical, and practical implications. We review the foundations of optimization for inference and for learning, introduce four representative design paradigms for deep unfolding, and discuss the distinctive training schemes that arise from their iterative nature. Furthermore, we survey recent theoretical advances that establish convergence and generalization guarantees for unfolded optimizers, and provide comparative qualitative and empirical studies illustrating their relative trade-offs in complexity, interpretability, and robustness.

</details>


### [142] [Forensic Activity Classification Using Digital Traces from iPhones: A Machine Learning-based Approach](https://arxiv.org/abs/2512.03786)
*Conor McCarthy,Jan Peter van Zandwijk,Marcel Worring,Zeno Geradts*

Main category: cs.LG

TL;DR: 基于智能手机和智能手表传感器数据，开发机器学习方法将数字痕迹转化为不同身体活动的似然比，用于法医调查中的活动识别和时间线重建。


<details>
  <summary>Details</summary>
Motivation: 智能手机和智能手表在日常生活中的普及提供了丰富的用户行为信息，特别是手机内置运动传感器产生的数字痕迹，为法医调查人员了解个人身体活动提供了机会。

Method: 提出基于机器学习的方法，将数字痕迹转化为不同身体活动的似然比(LR)，使用新数据集NFI_FARED（包含四种iPhone的19种活动标签数据），并扩展方法以同时分析多个活动或活动组，创建活动时间线。

Result: 在171个可能的活动配对中，该方法能够为167个配对产生有用的似然比系统，成功区分不同活动类型。数据集和所有代码已公开以促进进一步研究。

Conclusion: 该方法能够有效利用智能手机传感器数据进行法医调查中的活动识别，为调查早期和后期阶段提供支持，公开数据集和代码有助于推动该领域研究。

Abstract: Smartphones and smartwatches are ever-present in daily life, and provide a rich source of information on their users' behaviour. In particular, digital traces derived from the phone's embedded movement sensors present an opportunity for a forensic investigator to gain insight into a person's physical activities. In this work, we present a machine learning-based approach to translate digital traces into likelihood ratios (LRs) for different types of physical activities. Evaluating on a new dataset, NFI\_FARED, which contains digital traces from four different types of iPhones labelled with 19 activities, it was found that our approach could produce useful LR systems to distinguish 167 out of a possible 171 activity pairings. The same approach was extended to analyse likelihoods for multiple activities (or groups of activities) simultaneously and create activity timelines to aid in both the early and latter stages of forensic investigations. The dataset and all code required to replicate the results have also been made public to encourage further research on this topic.

</details>


### [143] [Adaptive Identification and Modeling of Clinical Pathways with Process Mining](https://arxiv.org/abs/2512.03787)
*Francesco Vitale,Nicola Mazzocca*

Main category: cs.LG

TL;DR: 提出基于过程挖掘的两阶段临床路径建模方法，通过一致性检查扩展知识库，针对疾病变体或组合创建更具体的模型


<details>
  <summary>Details</summary>
Motivation: 临床路径的手动建模困难且难以反映不同疾病变体或组合的最佳实践，需要自动化方法来扩展和优化临床路径知识库

Method: 两阶段过程挖掘方法：第一阶段从历史数据中提取治疗过程模型；第二阶段将新数据与参考模型进行一致性检查，根据结果扩展知识库

Result: 使用Synthea数据集验证，方法能以95.62%的AUC精度扩展临床路径知识库，同时保持67.11%的弧度简洁性

Conclusion: 该方法能有效扩展临床路径知识库，为不同疾病变体和组合提供更具体的治疗模型，提高临床路径的适应性和实用性

Abstract: Clinical pathways are specialized healthcare plans that model patient treatment procedures. They are developed to provide criteria-based progression and standardize patient treatment, thereby improving care, reducing resource use, and accelerating patient recovery. However, manual modeling of these pathways based on clinical guidelines and domain expertise is difficult and may not reflect the actual best practices for different variations or combinations of diseases. We propose a two-phase modeling method using process mining, which extends the knowledge base of clinical pathways by leveraging conformance checking diagnostics. In the first phase, historical data of a given disease is collected to capture treatment in the form of a process model. In the second phase, new data is compared against the reference model to verify conformance. Based on the conformance checking results, the knowledge base can be expanded with more specific models tailored to new variants or disease combinations. We demonstrate our approach using Synthea, a benchmark dataset simulating patient treatments for SARS-CoV-2 infections with varying COVID-19 complications. The results show that our method enables expanding the knowledge base of clinical pathways with sufficient precision, peaking to 95.62% AUC while maintaining an arc-degree simplicity of 67.11%.

</details>


### [144] [EfficientECG: Cross-Attention with Feature Fusion for Efficient Electrocardiogram Classification](https://arxiv.org/abs/2512.03804)
*Hanhui Deng,Xinglin Li,Jie Luo,Zhanpeng Jin,Di Wu*

Main category: cs.LG

TL;DR: 本文提出EfficientECG模型，一种基于EfficientNet的轻量级心电图分类模型，能够准确处理高频长序列多导联ECG数据，并通过跨注意力机制融合多特征（如性别、年龄）。


<details>
  <summary>Details</summary>
Motivation: 心电图是重要的诊断信号，但现有ECG模型误诊率高。本文旨在开发深度学习技术来有效管理和分析ECG数据，构建准确快速的诊断模型，减轻医疗工作者负担。

Method: 首先设计EfficientECG模型，基于EfficientNet构建轻量级ECG分类模型，能处理高频长序列多导联数据。然后提出基于跨注意力的特征融合模型，用于分析包含多特征（性别、年龄）的多导联ECG数据。

Result: 在代表性ECG数据集上的评估验证了模型在精度、多特征融合和轻量化方面的优越性，优于现有最先进方法。

Conclusion: 提出的深度学习方法能自动提取ECG特征，通过端到端训练构建准确快速的诊断模型，有效降低误诊率并减轻医疗负担。

Abstract: Electrocardiogram is a useful diagnostic signal that can detect cardiac abnormalities by measuring the electrical activity generated by the heart. Due to its rapid, non-invasive, and richly informative characteristics, ECG has many emerging applications. In this paper, we study novel deep learning technologies to effectively manage and analyse ECG data, with the aim of building a diagnostic model, accurately and quickly, that can substantially reduce the burden on medical workers. Unlike the existing ECG models that exhibit a high misdiagnosis rate, our deep learning approaches can automatically extract the features of ECG data through end-to-end training. Specifically, we first devise EfficientECG, an accurate and lightweight classification model for ECG analysis based on the existing EfficientNet model, which can effectively handle high-frequency long-sequence ECG data with various leading types. On top of that, we next propose a cross-attention-based feature fusion model of EfficientECG for analysing multi-lead ECG data with multiple features (e.g., gender and age). Our evaluations on representative ECG datasets validate the superiority of our model against state-of-the-art works in terms of high precision, multi-feature fusion, and lightweights.

</details>


### [145] [Deep Reinforcement Learning for Dynamic Algorithm Configuration: A Case Study on Optimizing OneMax with the (1+($λ$,$λ$))-GA](https://arxiv.org/abs/2512.03805)
*Tai Nguyen,Phong Le,André Biedenkapp,Carola Doerr,Nguyen Dang*

Main category: cs.LG

TL;DR: 本文系统研究了深度强化学习在动态算法配置中的应用，针对(1+(λ,λ))-GA在OneMax问题上的种群规模参数控制，揭示了DDQN和PPO面临的可扩展性下降和学习不稳定性挑战，并提出自适应奖励偏移机制解决探索不足问题。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习在动态算法配置中展现出潜力，但实际应用面临挑战且需要大量领域专业知识。本文旨在通过系统研究深度RL算法在DAC中的表现，识别并解决关键问题，提升RL在算法配置中的有效性和效率。

Method: 以控制(1+(λ,λ))-GA在OneMax实例上的种群规模参数为案例，系统分析DDQN和PPO两种深度RL算法。针对发现的探索不足问题，提出自适应奖励偏移机制；针对规划视野覆盖问题，采用无折扣学习策略。同时分析PPO的超参数依赖性。

Result: 研究发现DDQN和PPO存在可扩展性下降和学习不稳定性两大挑战，根源在于探索不足和规划视野覆盖问题。自适应奖励偏移机制有效解决了探索不足问题，无需实例特定超参数调优。DDQN配合该策略在样本效率上比先前DAC方法提升数个数量级，性能接近理论推导策略。

Conclusion: 深度RL在DAC中面临可扩展性和稳定性挑战，但通过针对性解决方案可以克服。自适应奖励偏移机制显著提升DDQN性能，而PPO存在根本性方差问题需要重新设计。研究为RL在算法配置中的实际应用提供了重要见解和方法。

Abstract: Dynamic Algorithm Configuration (DAC) studies the efficient identification of control policies for parameterized optimization algorithms. Numerous studies have leveraged the robustness of decision-making in Reinforcement Learning (RL) to address the optimization challenges in algorithm configuration. However, applying RL to DAC is challenging and often requires extensive domain expertise. We conduct a comprehensive study of deep-RL algorithms in DAC through a systematic analysis of controlling the population size parameter of the (1+($λ$,$λ$))-GA on OneMax instances. Our investigation of DDQN and PPO reveals two fundamental challenges that limit their effectiveness in DAC: scalability degradation and learning instability. We trace these issues to two primary causes: under-exploration and planning horizon coverage, each of which can be effectively addressed through targeted solutions. To address under-exploration, we introduce an adaptive reward shifting mechanism that leverages reward distribution statistics to enhance DDQN agent exploration, eliminating the need for instance-specific hyperparameter tuning and ensuring consistent effectiveness across different problem scales. In dealing with the planning horizon coverage problem, we demonstrate that undiscounted learning effectively resolves it in DDQN, while PPO faces fundamental variance issues that necessitate alternative algorithmic designs. We further analyze the hyperparameter dependencies of PPO, showing that while hyperparameter optimization enhances learning stability, it consistently falls short in identifying effective policies across various configurations. Finally, we demonstrate that DDQN equipped with our adaptive reward shifting strategy achieves performance comparable to theoretically derived policies with vastly improved sample efficiency, outperforming prior DAC approaches by several orders of magnitude.

</details>


### [146] [Log Probability Tracking of LLM APIs](https://arxiv.org/abs/2512.03816)
*Timothée Chauvin,Erwan Le Merrer,François Taïani,Gilles Tredan*

Main category: cs.LG

TL;DR: 提出一种基于对数概率统计测试的低成本LLM API监控方法，仅需单个token输出即可检测模型微小变化，比现有方法敏感1000倍


<details>
  <summary>Details</summary>
Motivation: LLM API用户期望模型保持一致性以保证下游应用可靠性和研究可复现性，但现有审计方法成本过高无法定期监控广泛可用的LLM API，导致模型更新在实践中基本未被监控

Method: 利用LLM对数概率的非确定性特性，基于每个token对数概率平均值的简单统计测试，仅需请求单个token输出即可进行成本效益高的连续监控

Result: 该方法能检测小至单个微调步骤的变化，比现有方法更敏感且成本降低1000倍，并引入TinyChange基准来衡量审计方法对小型现实模型变化的敏感性

Conclusion: LLM对数概率可用于实现经济高效的连续API监控，解决了现有审计方法成本过高的问题，为模型一致性监控提供了实用解决方案

Abstract: When using an LLM through an API provider, users expect the served model to remain consistent over time, a property crucial for the reliability of downstream applications and the reproducibility of research. Existing audit methods are too costly to apply at regular time intervals to the wide range of available LLM APIs. This means that model updates are left largely unmonitored in practice. In this work, we show that while LLM log probabilities (logprobs) are usually non-deterministic, they can still be used as the basis for cost-effective continuous monitoring of LLM APIs. We apply a simple statistical test based on the average value of each token logprob, requesting only a single token of output. This is enough to detect changes as small as one step of fine-tuning, making this approach more sensitive than existing methods while being 1,000x cheaper. We introduce the TinyChange benchmark as a way to measure the sensitivity of audit methods in the context of small, realistic model changes.

</details>


### [147] [Transmit Weights, Not Features: Orthogonal-Basis Aided Wireless Point-Cloud Transmission](https://arxiv.org/abs/2512.03819)
*Junlin Chang,Yubo Han,Hnag Yue,John S Thompson,Rongke Liu*

Main category: cs.LG

TL;DR: 提出基于深度联合信源信道编码的3D点云语义无线传输框架，通过预测接收端语义正交特征池的组合权重实现紧凑表示和鲁棒重建，在带宽受限场景下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 深度传感器的普及降低了点云获取门槛，但点云数据量大，传统传输方法在带宽受限时性能下降。需要一种能适应不同带宽和信噪比条件的语义感知传输方案。

Method: 1) 基于DeepJSCC的语义传输框架，发送端预测接收端语义正交特征池的组合权重而非原始特征；2) 基于折叠的解码器将2D网格变形为3D点云，保持流形连续性和几何保真度；3) 使用Chamfer距离和正交正则化进行训练。

Result: 在ModelNet40数据集上测试，高带宽时与SEPT性能相当，带宽受限时明显优于SEPT，在PSNR和Chamfer距离指标上均有持续改进。消融实验证实正交化和折叠先验的有效性。

Conclusion: 提出的语义无线传输框架通过正交特征池和折叠解码器，实现了点云的高效鲁棒传输，特别在带宽受限场景下表现出色，为点云通信提供了新思路。

Abstract: The widespread adoption of depth sensors has substantially lowered the barrier to point-cloud acquisition. This letter proposes a semantic wireless transmission framework for three dimension (3D) point clouds built on Deep Joint Source - Channel Coding (DeepJSCC). Instead of sending raw features, the transmitter predicts combination weights over a receiver-side semantic orthogonal feature pool, enabling compact representations and robust reconstruction. A folding-based decoder deforms a 2D grid into 3D, enforcing manifold continuity while preserving geometric fidelity. Trained with Chamfer Distance (CD) and an orthogonality regularizer, the system is evaluated on ModelNet40 across varying Signal-to-Noise Ratios (SNRs) and bandwidths. Results show performance on par with SEmantic Point cloud Transmission (SEPT) at high bandwidth and clear gains in bandwidth-constrained regimes, with consistent improvements in both Peak Signal-to-Noise Ratio (PSNR) and CD. Ablation experiments confirm the benefits of orthogonalization and the folding prior.

</details>


### [148] [DVPO: Distributional Value Modeling-based Policy Optimization for LLM Post-Training](https://arxiv.org/abs/2512.03847)
*Dingwei Zhu,Zhiheng Xi,Shihan Dou,Yuhui Wang,Sixian Li,Junjie Ye,Honglin Guo,Shichun Liu,Chenhao Huang,Yajie Yang,Junlin Shang,Senjie Jin,Ming Zhang,Jiazheng Zhang,Caishuang Huang,Yunke Zhang,Demei Yan,Yuran Wang,Tao Gui*

Main category: cs.LG

TL;DR: DVPO是一个结合条件风险理论和分布价值建模的新RL框架，用于LLM后训练，通过token级价值分布和不对称风险正则化来平衡鲁棒性和泛化性


<details>
  <summary>Details</summary>
Motivation: 现实世界部署中常存在噪声或不完整的监督信号，现有方法（如RFQI、CQL、PPO、GRPO）要么忽略泛化性，要么产生过于保守的策略，导致在不同真实场景中表现不均

Method: DVPO结合条件风险理论与分布价值建模，学习token级价值分布提供细粒度监督，并应用不对称风险正则化：收缩下尾抑制噪声负偏差，扩展上尾保持探索多样性

Result: 在多轮对话、数学推理和科学问答的广泛实验中，DVPO在噪声监督下持续优于PPO、GRPO和基于鲁棒Bellman的PPO

Conclusion: DVPO展示了在现实世界LLM后训练中的潜力，通过平衡鲁棒性和泛化性来应对噪声监督挑战

Abstract: Reinforcement learning (RL) has shown strong performance in LLM post-training, but real-world deployment often involves noisy or incomplete supervision. In such settings, complex and unreliable supervision signals can destabilize training and harm generalization. While existing approaches such as worst-case optimization (e.g., RFQI, CQL) and mean-based methods (e.g., PPO, GRPO) can improve stability, they often overlook generalization and may produce overly conservative policies, leading to uneven performance across diverse real scenarios. To this end, we introduce DVPO (Distributional Value Modeling with Risk-aware Policy Optimization), a new RL framework that combines conditional risk theory with distributional value modeling to better balance robustness and generalization. DVPO learns token-level value distributions to provide fine-grained supervision, and applies an asymmetric risk regularization to shape the distribution tails: it contracts the lower tail to dampen noisy negative deviations, while expanding the upper tail to preserve exploratory diversity. Across extensive experiments and analysis in multi-turn dialogue, math reasoning, and scientific QA, DVPO consistently outperforms PPO, GRPO, and robust Bellman-based PPO under noisy supervision, showing its potential for LLM post-training in the real-world.

</details>


### [149] [Scalable Decision Focused Learning via Online Trainable Surrogates](https://arxiv.org/abs/2512.03861)
*Gaetano Signorelli,Michele Lombardi*

Main category: cs.LG

TL;DR: 提出一种基于无偏估计的代理损失函数加速方法，用于决策聚焦学习，减少训练时昂贵的内层求解器调用，同时保持解质量。


<details>
  <summary>Details</summary>
Motivation: 决策支持系统需要解决复杂的优化问题，传统训练的估计器可能导致次优解。决策聚焦学习使用实际决策成本作为损失函数可以解决这个问题，但训练时计算代价高昂，可扩展性差。

Method: 提出一种加速方法，用高效的代理损失函数替代昂贵的损失函数评估。该方法基于无偏估计器，减少虚假局部最优的风险，并能提供局部置信度信息，在需要时可切换到备用方法。代理函数设计为黑盒设置，可以补偿优化模型中的简化，并在成本计算中考虑补救措施。

Result: 该方法显著减少了昂贵的内层求解器调用次数，同时解的质量与其他最先进技术相当。

Conclusion: 提出的基于无偏估计的代理损失函数方法有效解决了决策聚焦学习的可扩展性问题，在保持解质量的同时大幅降低了计算成本。

Abstract: Decision support systems often rely on solving complex optimization problems that may require to estimate uncertain parameters beforehand. Recent studies have shown how using traditionally trained estimators for this task can lead to suboptimal solutions. Using the actual decision cost as a loss function (called Decision Focused Learning) can address this issue, but with a severe loss of scalability at training time. To address this issue, we propose an acceleration method based on replacing costly loss function evaluations with an efficient surrogate. Unlike previously defined surrogates, our approach relies on unbiased estimators reducing the risk of spurious local optima and can provide information on its local confidence allowing one to switch to a fallback method when needed. Furthermore, the surrogate is designed for a black-box setting, which enables compensating for simplifications in the optimization model and account- ing for recourse actions during cost computation. In our results, the method reduces costly inner solver calls, with a solution quality comparable to other state-of-the-art techniques.

</details>


### [150] [Hyperdimensional Computing for Sustainable Manufacturing: An Initial Assessment](https://arxiv.org/abs/2512.03864)
*Danny Hoang,Anandkumar Patel,Ruimen Chen,Rajiv Malhotra,Farhad Imani*

Main category: cs.LG

TL;DR: 研究比较了智能加工中AI模型的能耗，引入超维计算(HDC)作为替代方案，在保持精度的同时大幅降低能耗和计算时间


<details>
  <summary>Details</summary>
Motivation: 智能制造虽能提高效率，但AI模型的能耗可能抵消这些收益。需要寻找既能保持精度又能大幅降低能耗的AI解决方案

Method: 利用原位传感预测智能加工的几何质量，比较常见AI模型的能耗、精度和速度。引入超维计算(HDC)作为替代方案进行对比分析

Result: HDC在保持与传统模型相当精度的同时，训练能耗降低200倍，推理能耗降低175-1000倍；训练时间减少200倍，推理时间减少300-600倍

Conclusion: 超维计算(HDC)在智能加工中展现出巨大潜力，能够实现高精度预测的同时显著降低能耗和计算时间，为节能智能制造提供了有前景的解决方案

Abstract: Smart manufacturing can significantly improve efficiency and reduce energy consumption, yet the energy demands of AI models may offset these gains. This study utilizes in-situ sensing-based prediction of geometric quality in smart machining to compare the energy consumption, accuracy, and speed of common AI models. HyperDimensional Computing (HDC) is introduced as an alternative, achieving accuracy comparable to conventional models while drastically reducing energy consumption, 200$\times$ for training and 175 to 1000$\times$ for inference. Furthermore, HDC reduces training times by 200$\times$ and inference times by 300 to 600$\times$, showcasing its potential for energy-efficient smart manufacturing.

</details>


### [151] [Automatic Attack Discovery for Few-Shot Class-Incremental Learning via Large Language Models](https://arxiv.org/abs/2512.03882)
*Haidong Kang,Wei Wu,Hanling Wang*

Main category: cs.LG

TL;DR: 本文提出ACraft方法，利用大语言模型自动生成针对少样本类增量学习（FSCIL）的攻击方法，无需人工专家参与，显著超越传统攻击方法效果。


<details>
  <summary>Details</summary>
Motivation: 少样本类增量学习（FSCIL）是一个具有挑战性的持续学习范式，但现有研究主要关注提升FSCIL性能，而忽视了其安全性问题。传统人工设计的攻击方法（如PGD、FGSM）要么无法有效攻击基础类，要么依赖大量专家知识导致成本高昂，因此需要专门针对FSCIL的攻击方法。

Method: 提出ACraft方法：1）利用大语言模型（LLMs）自动发现针对FSCIL的最优攻击方法，无需人工专家参与；2）引入基于近端策略优化（PPO）的强化学习来优化LLMs与FSCIL之间的推理过程，通过建立正反馈使LLMs在下一代生成更好的攻击方法。

Result: 在主流的基准测试中，ACraft方法显著降低了最先进FSCIL方法的性能，大幅超越人工专家设计的攻击方法，同时保持了最低的攻击成本。

Conclusion: 本文首次系统研究了FSCIL的安全性问题，提出的ACraft方法能够自动生成针对FSCIL的有效攻击，为FSCIL的安全性评估提供了新工具，并揭示了该领域的安全脆弱性。

Abstract: Few-shot class incremental learning (FSCIL) is a more realistic and challenging paradigm in continual learning to incrementally learn unseen classes and overcome catastrophic forgetting on base classes with only a few training examples. Previous efforts have primarily centered around studying more effective FSCIL approaches. By contrast, less attention was devoted to thinking the security issues in contributing to FSCIL. This paper aims to provide a holistic study of the impact of attacks on FSCIL. We first derive insights by systematically exploring how human expert-designed attack methods (i.e., PGD, FGSM) affect FSCIL. We find that those methods either fail to attack base classes, or suffer from huge labor costs due to relying on huge expert knowledge. This highlights the need to craft a specialized attack method for FSCIL. Grounded in these insights, in this paper, we propose a simple yet effective ACraft method to automatically steer and discover optimal attack methods targeted at FSCIL by leveraging Large Language Models (LLMs) without human experts. Moreover, to improve the reasoning between LLMs and FSCIL, we introduce a novel Proximal Policy Optimization (PPO) based reinforcement learning to optimize learning, making LLMs generate better attack methods in the next generation by establishing positive feedback. Experiments on mainstream benchmarks show that our ACraft significantly degrades the performance of state-of-the-art FSCIL methods and dramatically beyond human expert-designed attack methods while maintaining the lowest costs of attack.

</details>


### [152] [Probabilistic Foundations of Fuzzy Simplicial Sets for Nonlinear Dimensionality Reduction](https://arxiv.org/abs/2512.03899)
*Janis Keck,Lukas Silvester Barth,Fatemeh,Fahimi,Parvaneh Joharinad,Jürgen Jost*

Main category: cs.LG

TL;DR: 该论文提出了一个概率框架，将模糊单纯集解释为单纯集上概率测度的边际，为UMAP等降维方法提供了统一的概率理论基础。


<details>
  <summary>Details</summary>
Motivation: 模糊单纯集在降维和流形学习中很重要（如UMAP），但其基于代数拓扑的定义缺乏清晰的概率解释，与这些领域常用的理论框架脱节。

Method: 引入一个框架，将模糊单纯集解释为单纯集上概率测度的边际，表明UMAP的模糊权重源于在随机尺度上采样Vietoris-Rips滤过的生成模型，得到成对距离的累积分布函数。

Result: 该框架连接了模糊单纯集与面偏序集上的概率模型，阐明了Kullback-Leibler散度与模糊交叉熵的关系，通过底层单纯集的布尔运算恢复了标准t-范数和t-余范数。

Conclusion: 概率视角为模糊单纯集提供了统一的概率理论基础，明确了UMAP在该框架中的角色，并能系统推导新的降维方法，如使用Čech滤过和三重采样的UMAP推广。

Abstract: Fuzzy simplicial sets have become an object of interest in dimensionality reduction and manifold learning, most prominently through their role in UMAP. However, their definition through tools from algebraic topology without a clear probabilistic interpretation detaches them from commonly used theoretical frameworks in those areas. In this work we introduce a framework that explains fuzzy simplicial sets as marginals of probability measures on simplicial sets. In particular, this perspective shows that the fuzzy weights of UMAP arise from a generative model that samples Vietoris-Rips filtrations at random scales, yielding cumulative distribution functions of pairwise distances. More generally, the framework connects fuzzy simplicial sets to probabilistic models on the face poset, clarifies the relation between Kullback-Leibler divergence and fuzzy cross-entropy in this setting, and recovers standard t-norms and t-conorms via Boolean operations on the underlying simplicial sets. We then show how new embedding methods may be derived from this framework and illustrate this on an example where we generalize UMAP using Čech filtrations with triplet sampling. In summary, this probabilistic viewpoint provides a unified probabilistic theoretical foundation for fuzzy simplicial sets, clarifies the role of UMAP within this framework, and enables the systematic derivation of new dimensionality reduction methods.

</details>


### [153] [Density-Informed VAE (DiVAE): Reliable Log-Prior Probability via Density Alignment Regularization](https://arxiv.org/abs/2512.03928)
*Michele Alessi,Alessio Ansuini,Alex Rodriguez*

Main category: cs.LG

TL;DR: DiVAE是一种轻量级VAE正则化器，通过将VAE对数先验概率与数据估计的对数密度对齐，改善潜在空间与数据空间密度的匹配，提升分布对齐、先验覆盖和OOD不确定性校准。


<details>
  <summary>Details</summary>
Motivation: 标准VAE将潜在变量匹配到简单先验分布（如高斯分布），忽略了数据空间中的密度结构。这导致潜在空间不能很好地反映数据分布，影响模型的可解释性和OOD检测性能。

Method: DiVAE在ELBO中添加了一个鲁棒的、精度加权的惩罚项，使VAE对数先验概率与从数据估计的对数密度对齐。该方法鼓励编码器按数据空间密度比例分配后验质量，并在先验可学习时推动先验向高密度区域移动。

Result: 在合成数据集上，DiVAE改善了潜在对数密度与真实分布的匹配、提高了先验覆盖度、并获得了更好的OOD不确定性校准。在MNIST上，DiVAE改善了先验与外部密度估计的对齐，提供了更好的可解释性，并提升了可学习先验的OOD检测性能。

Conclusion: DiVAE是一种计算开销可忽略的轻量级正则化方法，通过将VAE先验与数据密度对齐，显著改善了潜在空间表示的质量、可解释性和OOD检测能力。

Abstract: We introduce Density-Informed VAE (DiVAE), a lightweight, data-driven regularizer that aligns the VAE log-prior probability $\log p_Z(z)$ with a log-density estimated from data. Standard VAEs match latents to a simple prior, overlooking density structure in the data-space. DiVAE encourages the encoder to allocate posterior mass in proportion to data-space density and, when the prior is learnable, nudges the prior toward high-density regions. This is realized by adding a robust, precision-weighted penalty to the ELBO, incurring negligible computational overhead. On synthetic datasets, DiVAE (i) improves distributional alignment of latent log-densities to its ground truth counterpart, (ii) improves prior coverage, and (iii) yields better OOD uncertainty calibration. On MNIST, DiVAE improves alignment of the prior with external estimates of the density, providing better interpretability, and improves OOD detection for learnable priors.

</details>


### [154] [Technical Report on Text Dataset Distillation](https://arxiv.org/abs/2512.03967)
*Keith Ando Ogawa,Bruno Lopes Yamamoto,Lucas Lauton de Alcantara,Victor Zacarias,Edson Bollis,Lucas Pellicer,Rosimeire Pereira Costa,Anna Helena Reali Costa,Artur Jordao*

Main category: cs.LG

TL;DR: 本文综述了文本数据集蒸馏领域的发展历程，从最初借鉴视觉领域方法到形成独立研究方向，涵盖关键里程碑、主要方法、当前挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 文本数据集蒸馏研究相对视觉领域较少，但文本模态的特殊性（如离散性）带来了独特挑战，需要专门的研究方法。随着大语言模型的发展，如何高效压缩文本数据集以降低训练成本变得日益重要。

Method: 综述了文本数据集蒸馏的主要方法：1）早期借鉴视觉领域的技术；2）使用Transformer模型的蒸馏方法；3）生成离散合成文本的技术；4）扩展到超过10亿参数的仅解码器模型。

Result: 文本数据集蒸馏领域已取得显著进展，形成了独立的研究分支，但仍处于成熟阶段，在基准标准化、处理文本离散性、复杂任务处理等方面仍有改进空间。

Conclusion: 文本数据集蒸馏是一个有前景但仍在发展的领域，需要更多标准化基准、更好的离散文本处理方法、复杂任务支持以及实际应用案例来推动其成熟。

Abstract: In the vision domain, dataset distillation arises as a technique to condense a large dataset into a smaller synthetic one that exhibits a similar result in the training process. While image data presents an extensive literature of distillation methods, text dataset distillation has fewer works in comparison. Text dataset distillation initially grew as an adaptation of efforts from the vision universe, as the particularities of the modality became clear obstacles, it rose into a separate branch of research. Several milestones mark the development of this area, such as the introduction of methods that use transformer models, the generation of discrete synthetic text, and the scaling to decoder-only models with over 1B parameters. Despite major advances in modern approaches, the field remains in a maturing phase, with room for improvement on benchmarking standardization, approaches to overcome the discrete nature of text, handling complex tasks, and providing explicit examples of real-world applications. In this report, we review past and recent advances in dataset distillation for text, highlighting different distillation strategies, key contributions, and general challenges.

</details>


### [155] [Guided Flow Policy: Learning from High-Value Actions in Offline Reinforcement Learning](https://arxiv.org/abs/2512.03973)
*Franki Nguimatsia Tiofack,Théotime Le Hellard,Fabian Schramm,Nicolas Perrin-Gilbert,Justin Carpentier*

Main category: cs.LG

TL;DR: GFP通过耦合多步流匹配策略与蒸馏单步行动器，使用加权行为克隆专注于复制数据集中的高价值动作，而非盲目模仿所有状态-动作对，在离线强化学习中实现了最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有离线强化学习方法通常使用行为正则化来保持策略接近数据集分布，但这些方法无法区分高价值和低价值动作，导致性能受限。

Method: 提出引导流策略(GFP)，耦合多步流匹配策略与蒸馏单步行动器。行动器通过加权行为克隆引导流策略专注于复制数据集中的高价值动作，流策略则约束行动器保持与数据集最佳转移对齐的同时最大化价值函数。

Result: 在OGBench、Minari和D4RL基准测试的144个状态和像素任务中实现了最先进的性能，特别是在次优数据集和挑战性任务上取得了显著提升。

Conclusion: GFP通过行动器和流策略的相互引导机制，有效区分并专注于高价值动作，克服了传统行为正则化的局限性，在离线强化学习中取得了优异性能。

Abstract: Offline reinforcement learning often relies on behavior regularization that enforces policies to remain close to the dataset distribution. However, such approaches fail to distinguish between high-value and low-value actions in their regularization components. We introduce Guided Flow Policy (GFP), which couples a multi-step flow-matching policy with a distilled one-step actor. The actor directs the flow policy through weighted behavior cloning to focus on cloning high-value actions from the dataset rather than indiscriminately imitating all state-action pairs. In turn, the flow policy constrains the actor to remain aligned with the dataset's best transitions while maximizing the critic. This mutual guidance enables GFP to achieve state-of-the-art performance across 144 state and pixel-based tasks from the OGBench, Minari, and D4RL benchmarks, with substantial gains on suboptimal datasets and challenging tasks. Webpage: https://simple-robotics.github.io/publications/guided-flow-policy/

</details>


### [156] [Training-Free Policy Violation Detection via Activation-Space Whitening in LLMs](https://arxiv.org/abs/2512.03994)
*Oren Rachmil,Roy Betser,Itay Gershon,Omer Hofman,Nitay Yakoby,Yuval Meron,Idan Yankelev,Asaf Shabtai,Yuval Elovici,Roman Vainshtein*

Main category: cs.LG

TL;DR: 提出一种无需训练的高效方法，将政策违规检测视为分布外检测问题，通过白化技术处理隐藏激活，使用欧几里得范数作为合规分数，在政策基准上达到SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在敏感领域（法律、金融、医疗）的部署，组织需要可靠机制检测内部政策违规，现有方法（如护栏、LLM-as-a-judge、微调）存在延迟高、可解释性差、缺乏对组织政策细微差别的捕捉能力等问题。

Method: 将政策违规检测视为分布外检测问题，采用白化技术对模型隐藏激活进行线性变换以去相关和标准化，在变换空间中使用欧几里得范数作为合规分数，仅需政策文本和少量示例样本。

Result: 在具有挑战性的政策基准上取得了最先进的结果，超越了现有护栏和微调推理模型，方法轻量且易于部署。

Conclusion: 为组织提供了一个实用且统计基础的政策感知监督框架，推进了可部署AI治理的广泛目标，代码已开源。

Abstract: Aligning proprietary large language models (LLMs) with internal organizational policies has become an urgent priority as organizations increasingly deploy LLMs in sensitive domains such as legal support, finance, and medical services. Beyond generic safety filters, enterprises require reliable mechanisms to detect policy violations within their regulatory and operational frameworks, where breaches can trigger legal and reputational risks. Existing content moderation frameworks, such as guardrails, remain largely confined to the safety domain and lack the robustness to capture nuanced organizational policies. LLM-as-a-judge and fine-tuning approaches, though flexible, introduce significant latency and lack interpretability. To address these limitations, we propose a training-free and efficient method that treats policy violation detection as an out-of-distribution (OOD) detection problem. Inspired by whitening techniques, we apply a linear transformation to decorrelate the model's hidden activations and standardize them to zero mean and unit variance, yielding near-identity covariance matrix. In this transformed space, we use the Euclidean norm as a compliance score to detect policy violations. The method requires only the policy text and a small number of illustrative samples, which makes it light-weight and easily deployable. On a challenging policy benchmark, our approach achieves state-of-the-art results, surpassing both existing guardrails and fine-tuned reasoning models. This work provides organizations with a practical and statistically grounded framework for policy-aware oversight of LLMs, advancing the broader goal of deployable AI governance. Code is available at: https://tinyurl.com/policy-violation-detection

</details>


### [157] [Physics-Embedded Gaussian Process for Traffic State Estimation](https://arxiv.org/abs/2512.04004)
*Yanlin Chen,Kehua Chen,Yinhai Wang*

Main category: cs.LG

TL;DR: 提出PEGP框架，将交通流物理模型嵌入高斯过程中，解决低渗透率稀疏观测下的交通状态估计问题，相比纯数据驱动或纯物理模型方法有更好表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限：纯数据驱动方法缺乏物理解释且稀疏数据下泛化差；纯物理模型难以整合不确定性和捕捉真实交通复杂性；现有物理嵌入方法依赖惩罚调参且缺乏不确定性校准，对模型误设敏感。

Method: 提出物理嵌入高斯过程(PEGP)框架，设计两个基于经典交通流模型(LWR和ARZ)的多输出核函数，通过线性化微分算子的显式应用构建，将物理结构作为硬约束而非软约束。

Result: 在HighD和NGSIM数据集上实验显示，PEGP相比非物理基线有持续改进：PEGP-ARZ在稀疏观测下更可靠，PEGP-LWR在密集观测下误差更低。消融研究显示PEGP-ARZ残差更符合物理且产生可解释的不确定性，PEGP-LWR残差更正交且产生近似恒定方差场。

Conclusion: PEGP框架成功整合物理先验和不确定性量化，为交通状态估计提供可靠支持，解决了现有方法在稀疏观测、不确定性校准和模型鲁棒性方面的不足。

Abstract: Traffic state estimation (TSE) becomes challenging when probe-vehicle penetration is low and observations are spatially sparse. Pure data-driven methods lack physical explanations and have poor generalization when observed data is sparse. In contrast, physical models have difficulty integrating uncertainties and capturing the real complexity of traffic. To bridge this gap, recent studies have explored combining them by embedding physical structure into Gaussian process. These approaches typically introduce the governing equations as soft constraints through pseudo-observations, enabling the integration of model structure within a variational framework. However, these methods rely heavily on penalty tuning and lack principled uncertainty calibration, which makes them sensitive to model mis-specification. In this work, we address these limitations by presenting a novel Physics-Embedded Gaussian Process (PEGP), designed to integrate domain knowledge with data-driven methods in traffic state estimation. Specifically, we design two multi-output kernels informed by classic traffic flow models, constructed via the explicit application of the linearized differential operator. Experiments on HighD, NGSIM show consistent improvements over non-physics baselines. PEGP-ARZ proves more reliable under sparse observation, while PEGP-LWR achieves lower errors with denser observation. Ablation study further reveals that PEGP-ARZ residuals align closely with physics and yield calibrated, interpretable uncertainty, whereas PEGP-LWR residuals are more orthogonal and produce nearly constant variance fields. This PEGP framework combines physical priors, uncertainty quantification, which can provide reliable support for TSE.

</details>


### [158] [Diagonalizing the Softmax: Hadamard Initialization for Tractable Cross-Entropy Dynamics](https://arxiv.org/abs/2512.04006)
*Connall Garrod,Jonathan P. Keating,Christos Thrampoulidis*

Main category: cs.LG

TL;DR: 本文分析了交叉熵损失在多类分类中的优化动力学，首次证明梯度流在两层线性神经网络上收敛到神经坍缩几何，并提出了Hadamard初始化对角化softmax算子的关键技术。


<details>
  <summary>Details</summary>
Motivation: 现有理论通常用平方损失替代交叉熵损失或限于凸模型，无法捕捉交叉熵损失的真实优化动态。交叉熵损失与平方损失产生根本不同的动态，而凸线性模型无法捕捉非凸优化的复杂性。

Method: 分析一个规范的两层线性神经网络，使用标准基向量作为输入。构建显式Lyapunov函数证明全局收敛性，关键发现是Hadamard初始化能够对角化softmax算子，冻结权重矩阵的奇异向量，将动态完全简化为奇异值。

Result: 首次证明梯度流在交叉熵损失下收敛到神经坍缩几何，尽管非凸景观中存在虚假临界点。Hadamard初始化技术为分析交叉熵训练动态开辟了新途径。

Conclusion: 该工作深入刻画了多类交叉熵优化动态，超越了凸机制，为理解神经网络训练中的交叉熵损失提供了理论基础，所提出的技术可推广到更广泛的设置。

Abstract: Cross-entropy (CE) training loss dominates deep learning practice, yet existing theory often relies on simplifications, either replacing it with squared loss or restricting to convex models, that miss essential behavior. CE and squared loss generate fundamentally different dynamics, and convex linear models cannot capture the complexities of non-convex optimization. We provide an in-depth characterization of multi-class CE optimization dynamics beyond the convex regime by analyzing a canonical two-layer linear neural network with standard-basis vectors as inputs: the simplest non-convex extension for which the implicit bias remained unknown. This model coincides with the unconstrained features model used to study neural collapse, making our work the first to prove that gradient flow on CE converges to the neural collapse geometry. We construct an explicit Lyapunov function that establishes global convergence, despite the presence of spurious critical points in the non-convex landscape. A key insight underlying our analysis is an inconspicuous finding: Hadamard Initialization diagonalizes the softmax operator, freezing the singular vectors of the weight matrices and reducing the dynamics entirely to their singular values. This technique opens a pathway for analyzing CE training dynamics well beyond our specific setting considered here.

</details>


### [159] [Efficient Public Verification of Private ML via Regularization](https://arxiv.org/abs/2512.04008)
*Zoë Ruha Bell,Anvith Thudi,Olive Franzese-McLaughlin,Nicolas Papernot,Shafi Goldwasser*

Main category: cs.LG

TL;DR: 提出首个差分隐私随机凸优化算法，其隐私保证验证成本远低于训练成本，显著减少大规模数据集上的验证开销


<details>
  <summary>Details</summary>
Motivation: 当前差分隐私算法的验证成本与训练成本相当，数据提供者和公众缺乏高效验证DP保证的方法，需要降低验证成本

Method: 通过私有化最小化一系列正则化目标，仅使用标准DP组合边界，获得紧致的隐私-效用权衡

Result: 实现了近最优的隐私-效用权衡，且验证成本远低于训练成本，显著减少大规模数据集验证开销

Conclusion: 设计了首个DP-SCO算法，其DP验证成本比训练成本更低，为大规模数据集上的DP验证提供了实用解决方案

Abstract: Training with differential privacy (DP) provides a guarantee to members in a dataset that they cannot be identified by users of the released model. However, those data providers, and, in general, the public, lack methods to efficiently verify that models trained on their data satisfy DP guarantees. The amount of compute needed to verify DP guarantees for current algorithms scales with the amount of compute required to train the model. In this paper we design the first DP algorithm with near optimal privacy-utility trade-offs but whose DP guarantees can be verified cheaper than training. We focus on DP stochastic convex optimization (DP-SCO), where optimal privacy-utility trade-offs are known. Here we show we can obtain tight privacy-utility trade-offs by privately minimizing a series of regularized objectives and only using the standard DP composition bound. Crucially, this method can be verified with much less compute than training. This leads to the first known DP-SCO algorithm with near optimal privacy-utility whose DP verification scales better than training cost, significantly reducing verification costs on large datasets.

</details>


### [160] [Domain Feature Collapse: Implications for Out-of-Distribution Detection and Solutions](https://arxiv.org/abs/2512.04034)
*Hong Yang,Devroop Kar,Qi Yu,Alex Ororbia,Travis Desell*

Main category: cs.LG

TL;DR: 监督学习在单域数据上会导致域特征坍缩，丢弃所有域特定信息，从而在OOD检测中产生灾难性失败。通过信息论分析解释了这一现象，并提出域过滤方法解决该问题。


<details>
  <summary>Details</summary>
Motivation: 解释为什么最先进的OOD检测方法在单域数据集训练时会表现出灾难性失败。这是一个令人困惑的经验现象，需要理论解释。

Method: 使用信息论框架分析，证明监督学习在单域数据上会导致域特征坍缩(I(x_d; z)=0)。引入Domain Bench基准测试，通过域过滤方法保持I(x_d; z)>0来验证理论。

Result: 理论分析表明单域训练会完全丢弃域特定信息，导致OOD检测失败(如MNIST上仅53% FPR@95)。实验证明通过域过滤保持域信息可以解决该问题。

Conclusion: 单域监督学习存在根本性限制，会导致域特征坍缩，从而在OOD检测中失败。这项工作解释了经验现象，揭示了窄域学习的局限性，对迁移学习和模型微调有广泛影响。

Abstract: Why do state-of-the-art OOD detection methods exhibit catastrophic failure when models are trained on single-domain datasets? We provide the first theoretical explanation for this phenomenon through the lens of information theory. We prove that supervised learning on single-domain data inevitably produces domain feature collapse -- representations where I(x_d; z) = 0, meaning domain-specific information is completely discarded. This is a fundamental consequence of information bottleneck optimization: models trained on single domains (e.g., medical images) learn to rely solely on class-specific features while discarding domain features, leading to catastrophic failure when detecting out-of-domain samples (e.g., achieving only 53% FPR@95 on MNIST). We extend our analysis using Fano's inequality to quantify partial collapse in practical scenarios. To validate our theory, we introduce Domain Bench, a benchmark of single-domain datasets, and demonstrate that preserving I(x_d; z) > 0 through domain filtering (using pretrained representations) resolves the failure mode. While domain filtering itself is conceptually straightforward, its effectiveness provides strong empirical evidence for our information-theoretic framework. Our work explains a puzzling empirical phenomenon, reveals fundamental limitations of supervised learning in narrow domains, and has broader implications for transfer learning and when to fine-tune versus freeze pretrained models.

</details>


### [161] [MarkTune: Improving the Quality-Detectability Trade-off in Open-Weight LLM Watermarking](https://arxiv.org/abs/2512.04044)
*Yizhou Zhao,Zhiwei Steven Wu,Adam Block*

Main category: cs.LG

TL;DR: MarkTune是一种针对开源权重语言模型的水印嵌入框架，通过基于策略的微调将水印信号作为奖励，在保持文本质量的同时提升水印检测能力。


<details>
  <summary>Details</summary>
Motivation: 开源权重语言模型给水印技术带来挑战，因为一旦模型权重公开，传统的推理时干预方法无法强制执行。现有方法如GaussMark需要在模型权重上进行微小修改，但为了达到与推理时水印相当的检测能力，通常需要牺牲生成质量。

Method: MarkTune是一个理论上有原则的、基于策略的微调框架，将GaussMark水印信号作为奖励，同时通过正则化防止文本质量下降。该方法在模型的表示空间中进行更细粒度的、水印感知的权重更新。

Result: MarkTune显著改善了GaussMark的质量-检测能力权衡，将开源模型的水印性能推近到推理时水印的水平。该方法对改写和微调攻击具有鲁棒性，并展现出强大的泛化能力：在一个数据集上微调的模型在未见数据集上仍保持显著的水印检测能力。

Conclusion: MarkTune为在开源权重语言模型中嵌入鲁棒、高质量水印提供了一种通用策略，解决了开源模型水印的核心挑战。

Abstract: Watermarking aims to embed hidden signals in generated text that can be reliably detected when given access to a secret key. Open-weight language models pose acute challenges for such watermarking schemes because the inference-time interventions that dominate contemporary approaches cannot be enforced once model weights are public. Existing watermaking techniques for open-weight models, such as the recently proposed GaussMark, typically rely on small modifications to model weights, which can yield signals detectable to those equipped with a secret key, but achieving detection power comparable to inference-time watermarks generally requires weight perturbations that noticeably reduce generation quality. We introduce MarkTune, a theoretically principled, on-policy fine-tuning framework that treats the GaussMark signal as a reward while simultaneously regularizing against degradation in text quality. We derive MarkTune as an improvement on GaussMark and demonstrate that MarkTune consistently improves the quality-detectability trade-off over GaussMark by steering finer-grained, watermark-aware weight updates within the model's representation space while preserving generation quality. Empirically, we show that MarkTune pushes the quality-detectability frontier of GaussMark close to that of inference-time watermarking, remains robust to paraphrasing and fine-tuning attacks, and exhibits strong generalization: a model fine-tuned on one dataset retains substantial watermark detection power on unseen datasets. Together, these results establish MarkTune as a general strategy for embedding robust, high-quality watermarks into open-weight LMs.

</details>


### [162] [Convergence for Discrete Parameter Updates](https://arxiv.org/abs/2512.04051)
*Paul Wilson,Fabio Zanasi,George Constantinides*

Main category: cs.LG

TL;DR: 提出一种离散更新规则的量化训练方法，避免对连续更新进行量化，为具有固有离散结构的模型开辟高效训练新途径。


<details>
  <summary>Details</summary>
Motivation: 现代深度学习模型需要巨大的计算资源，量化训练通过低比特整数表示训练组件来应对这一问题，但现有方法通常依赖于对实值更新进行离散化。

Method: 引入离散更新规则方法，避免对连续更新进行量化设计，为这类离散方案建立收敛保证，并提出多项式更新规则作为具体实例。

Result: 建立了离散更新方案的收敛保证，并通过实证评估支持了多项式更新规则的有效性。

Conclusion: 这种离散更新视角为高效训练开辟了新途径，特别适用于具有固有离散结构的模型。

Abstract: Modern deep learning models require immense computational resources, motivating research into low-precision training. Quantised training addresses this by representing training components in low-bit integers, but typically relies on discretising real-valued updates. We introduce an alternative approach where the update rule itself is discrete, avoiding the quantisation of continuous updates by design. We establish convergence guarantees for a general class of such discrete schemes, and present a multinomial update rule as a concrete example, supported by empirical evaluation. This perspective opens new avenues for efficient training, particularly for models with inherently discrete structure.

</details>


### [163] [Eval Factsheets: A Structured Framework for Documenting AI Evaluations](https://arxiv.org/abs/2512.04062)
*Florian Bordes,Candace Ross,Justine T Kao,Evangelia Spiliopoulou,Adina Williams*

Main category: cs.LG

TL;DR: Eval Factsheets：一个用于系统化记录AI系统评估方法的框架，通过五个维度的分类和问卷方法，旨在提高评估的透明度、可复现性和可比性。


<details>
  <summary>Details</summary>
Motivation: 当前AI评估方法缺乏系统化的文档标准，而数据集和模型已有Datasheets和Model Cards等结构化文档框架。评估方法的快速扩散带来了可复现性、透明度和决策制定方面的挑战。

Method: 提出了Eval Factsheets框架，通过五个基本维度（Context、Scope、Structure、Method、Alignment）组织评估特征，并实现为包含强制性和推荐性文档元素的实用问卷。

Result: 通过多个基准测试的案例研究证明，Eval Factsheets能够有效捕捉从传统基准测试到LLM-as-judge方法的各种评估范式，同时保持一致性和可比性。

Conclusion: 希望Eval Factsheets能被纳入现有和新发布的评估框架中，从而带来更高的透明度和可复现性，解决当前评估方法缺乏系统文档标准的问题。

Abstract: The rapid proliferation of benchmarks has created significant challenges in reproducibility, transparency, and informed decision-making. However, unlike datasets and models -- which benefit from structured documentation frameworks like Datasheets and Model Cards -- evaluation methodologies lack systematic documentation standards. We introduce Eval Factsheets, a structured, descriptive framework for documenting AI system evaluations through a comprehensive taxonomy and questionnaire-based approach. Our framework organizes evaluation characteristics across five fundamental dimensions: Context (Who made the evaluation and when?), Scope (What does it evaluate?), Structure (With what the evaluation is built?), Method (How does it work?) and Alignment (In what ways is it reliable/valid/robust?). We implement this taxonomy as a practical questionnaire spanning five sections with mandatory and recommended documentation elements. Through case studies on multiple benchmarks, we demonstrate that Eval Factsheets effectively captures diverse evaluation paradigms -- from traditional benchmarks to LLM-as-judge methodologies -- while maintaining consistency and comparability. We hope Eval Factsheets are incorporated into both existing and newly released evaluation frameworks and lead to more transparency and reproducibility.

</details>


### [164] [Fare Comparison App of Uber, Ola and Rapido](https://arxiv.org/abs/2512.04065)
*Ashlesha Gopinath Sawant,Sahil S. Jadhav,Vidhan R. Jain,Shriraj S. Jagtap,Prachi Jadhav,Soham Jadhav,Ichha Raina*

Main category: cs.LG

TL;DR: 开发了一个网约车比价网站，通过API获取Ola、Uber、Rapido的实时价格，为用户提供最优选择。


<details>
  <summary>Details</summary>
Motivation: 用户在选择网约车服务时难以找到最经济高效的选项，需要透明化的比价工具来优化出行决策。

Method: 构建Web应用程序，使用Python后端通过API获取不同平台的实时价格数据，结合Android Studio模拟器、Appium和位置比较技术解决数据获取难题。

Result: 成功开发了能够实时比较Ola、Uber、Rapido价格的比价系统，为用户提供最优出行选择。

Conclusion: 该项目提高了网约车服务的透明度，增强了用户体验和出行效率，解决了多平台比价的技术挑战。

Abstract: In todays increasing world, it is very important to have good hailing services like Ola, Uber, and Rapido as it is very essential for our daily transportation. Users often face difficulties in choosing the most appropriate and efficient ride that would lead to both cost-effective and would take us to our destination in less time. This project provides you with the web application that helps you to select the most beneficial ride for you by providing users with the fare comparison between Ola, Uber, Rapido for the destination entered by the user. The backend is use to fetch the data, providing users with the fare comparison for the ride and finally providing with the best option using Python. This research paper also addresses the problem and challenges faced in accessing the data using APIs, Android Studios emulator, Appium and location comparison. Thus, the aim of the project is to provide transparency to the users in ride-hailing services and increase efficiency and provide users with better experience.

</details>


### [165] [Learning Steerable Clarification Policies with Collaborative Self-play](https://arxiv.org/abs/2512.04068)
*Jonathan Berant,Maximillian Chen,Adam Fisch,Reza Aghajani,Fantine Huot,Mirella Lapata,Jacob Eisenstein*

Main category: cs.LG

TL;DR: 训练可调控的不确定性管理策略：通过自博弈学习AI助手在模糊查询时何时猜测、枚举或澄清，策略可根据成本参数调整行为


<details>
  <summary>Details</summary>
Motivation: AI助手处理模糊查询时需要智能的不确定性管理策略，但现有方法缺乏根据上下文（如用户偏好、设备模态）灵活调整的能力，例如在小屏幕或语音场景下枚举多个意图会显得笨拙

Method: 使用自博弈训练可调控策略：两个智能体分别模拟用户和AI助手，生成包含模糊查询的对话；模型输入澄清问题和生成单词的成本参数，通过强化自训练（ReST）最大化成本惩罚后的准确率奖励

Result: 训练出的策略能根据提供的成本参数可预测地调整行为，获得更高的奖励和准确率；方法还能泛化到训练时未见过的成本数值

Conclusion: 通过自博弈和强化自训练可以学习到可调控的不确定性管理策略，使AI助手能根据上下文成本灵活选择响应方式，并具有良好的泛化能力

Abstract: To handle underspecified or ambiguous queries, AI assistants need a policy for managing their uncertainty to determine (a) when to guess the user intent and answer directly, (b) when to enumerate and answer multiple possible intents, and (c) when to ask a clarifying question. However, such policies are contextually dependent on factors such as user preferences or modality. For example, enumerating multiple possible user intentions is cumbersome on small screens or in a voice setting. In this work, we propose to train steerable policies for managing this uncertainty using self-play. Given two agents, one simulating a user and the other an AI assistant, we generate conversations where the user issues a potentially ambiguous query, and the assistant needs to determine how to respond. Importantly, the model takes as input the numerical cost of each clarification question, and each generated word, and is asked to take the action that will maximize its final reward, which is the cost-penalized accuracy. We use Reinforced Self-Training (ReST) to train our model to achieve high reward and show this leads to a steerable policy that changes its behavior predictably conditioned on the provided costs, leading to higher reward and accuracy. Moreover, our procedure also generalizes to numerical cost values that were unobserved at training time.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [166] [A high-order regularized delta-Chebyshev method for computing spectral densities](https://arxiv.org/abs/2512.03149)
*Jinjing Yi,Daniel Massatt,Andrew Horning,Mitchell Luskin,J. H. Pixley,Jason Kaye*

Main category: physics.comp-ph

TL;DR: 提出一种计算谱密度的高阶delta-Chebyshev方法，用于计算紧束缚模型稀疏哈密顿量的局域态密度，相比传统KPM方法具有高阶收敛性


<details>
  <summary>Details</summary>
Motivation: 传统Chebyshev核多项式方法(KPM)在计算谱密度时收敛速度有限，需要一种能快速收敛到热力学极限的高精度方法，特别是对于光滑谱密度情况

Method: 提出高阶delta-Chebyshev方法，作为KPM的变体，使用高阶精确的δ函数近似，计算步骤与KPM相同但通过廉价后处理实现高阶精度

Result: 方法在石墨烯和扭转双层石墨烯的紧束缚模型中应用，在非奇异点处实现了局域态密度的高阶收敛

Conclusion: 高阶delta-Chebyshev方法为计算稀疏哈密顿量的谱密度提供了高效高精度的数值工具，特别适用于光滑谱密度情况

Abstract: We introduce a numerical method for computing spectral densities, and apply it to the evaluation of the local density of states (LDOS) of sparse Hamiltonians derived from tight-binding models. The approach, which we call the high-order delta-Chebyshev method, can be viewed as a variant of the popular regularized Chebyshev kernel polynomial method (KPM), but it uses a high-order accurate approximation of the $δ$-function to achieve rapid convergence to the thermodynamic limit for smooth spectral densities. The costly computational steps are identical to those for KPM, with high-order accuracy achieved by an inexpensive post-processing procedure. We apply the algorithm to tight-binding models of graphene and twisted bilayer graphene, demonstrating high-order convergence to the LDOS at non-singular points.

</details>


### [167] [Consistent Projection of Langevin Dynamics: Preserving Thermodynamics and Kinetics in Coarse-Grained Models](https://arxiv.org/abs/2512.03706)
*Vahid Nateghi,Lara Neureither,Selma Moqvist,Carsten Hartmann,Simon Olsson,Feliks Nüske*

Main category: physics.comp-ph

TL;DR: 提出了一种基于投影的粗粒化方法，用于一般欠阻尼朗之万动力学，结合生成器扩展动态模态分解和热力学插值，能够准确捕捉全空间模型的热力学和动力学特性。


<details>
  <summary>Details</summary>
Motivation: 粗粒化对于复杂多尺度系统（如生物分子构象动力学）的高效建模和模拟至关重要。需要开发能够准确捕捉热力学和动力学特性的粗粒化方法。

Method: 1. 基于Zwanzig投影方法推导欠阻尼朗之万动力学的闭式粗粒化表达式；2. 使用生成器扩展动态模态分解（gEDMD）建模粗粒化动力学并评估其动力学特性；3. 结合热力学插值（TI）在不同热力学状态间转换样本，避免重复数值模拟。

Result: 在二维模型系统中验证，该方法能够准确捕捉全空间模型的热力学和动力学特性，包括跃迁时间尺度等。

Conclusion: 提出的投影基粗粒化框架结合gEDMD和热力学插值，为复杂多尺度系统的粗粒化建模提供了有效方法，能够准确描述系统的热力学和动力学行为。

Abstract: Coarse graining (CG) is an important task for efficient modeling and simulation of complex multi-scale systems, such as the conformational dynamics of biomolecules. This work presents a projection-based coarse-graining formalism for general underdamped Langevin dynamics. Following the Zwanzig projection approach, we derive a closed-form expression for the coarse grained dynamics. In addition, we show how the generator Extended Dynamic Mode Decomposition (gEDMD) method, which was developed in the context of Koopman operator methods, can be used to model the CG dynamics and evaluate its kinetic properties, such as transition timescales. Finally, we combine our approach with thermodynamic interpolation (TI), a generative approach to transform samples between thermodynamic conditions, to extend the scope of the approach across thermodynamic states without repeated numerical simulations. Using a two-dimensional model system, we demonstrate that the proposed method allows to accurately capture the thermodynamic and kinetic properties of the full-space model.

</details>


### [168] [Comparing time and frequency domain numerical methods with Born-Rytov approximations for far-field electromagnetic scattering from single biological cells](https://arxiv.org/abs/2512.03858)
*Cael Warner*

Main category: physics.comp-ph

TL;DR: Born-Rytov近似方法在估计生物细胞有效折射率方面与FDTD和DDA方法进行比较，在酵母菌远场散射模式上表现更好


<details>
  <summary>Details</summary>
Motivation: 比较不同数值方法在电磁散射建模中的表现，特别是针对生物细胞的有效折射率估计，以确定最实用的计算方法

Method: 使用Born-Rytov近似、解析方法、Yee-lattice FDTD和离散偶极子近似(DDA)四种方法，分别对球体电磁散射和酵母菌断层重建进行模拟比较

Result: 与商业FDTD软件相比，Born-Rytov散射近似和离散偶极子近似在酵母菌远场光散射模式上表现出更好的一致性

Conclusion: Born-Rytov近似和DDA方法在生物细胞远场散射建模中具有优势，为从弹性光散射模式直接估计细胞干质量、体积和内部形态提供了实用工具

Abstract: The Born-Rytov approximation estimates effective refractive index of biological cells from measurements of scattered light intensity, polarization and phase. Effective refractive index is useful for estimating a biological cell's dry mass, volume, and internal morphology directly from its elastic light scattering pattern. This work compares the Born-Rytov approximation with analytical, Yee-lattice finite-difference time-domain, and discrete-dipole approximations to Maxwell's equations in the cases of electromagnetic scattering from a sphere and a tomographic reconstruction of Saccharomyces cerevisiae. Practical advantages and limitations of each numerical method are compared for modeling electromagnetic scattering of both near-field intensity and the far-field projected intensity, in terms of accuracy, memory, and compute time. When compared with a commercial software implementation of the Yee-lattice finite-difference time domain method, the Born-Rytov scattering approximation and discrete dipole approximation show better agreement with the far-field light scattering pattern from Saccharomyces cerevisiae.

</details>


### [169] [Refining Machine Learning Potentials through Thermodynamic Theory of Phase Transitions](https://arxiv.org/abs/2512.03974)
*Paul Fuchs,Julija Zavadlav*

Main category: physics.comp-ph

TL;DR: 提出一种通过自上而下学习微调机器学习势函数的方法，直接修正预测错误的相变温度以匹配实验数据，显著提高相图预测精度。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习势函数由于参考数据不足和系统性偏差，预测的相变温度与实验值存在数百开尔文的显著偏差，需要微调以提高实际应用中的准确性。

Method: 采用自上而下学习策略，利用可微分轨迹重加权算法最小化相在实验目标压力和温度下的自由能差异，直接修正预测错误的相变温度。

Result: 该方法能准确修正纯钛在高达5 GPa压力范围内的相图，与实验参考值匹配在十分之一开尔文内，并改善了液态扩散常数。

Conclusion: 该方法具有模型无关性，适用于多组分系统的固-固和固-液相变，兼容其他实验性质的自上而下训练，是实现高精度应用特定和基础机器学习势函数的重要步骤。

Abstract: Foundational Machine Learning Potentials can resolve the accuracy and transferability limitations of classical force fields. They enable microscopic insights into material behavior through Molecular Dynamics simulations, which can crucially expedite material design and discovery. However, insufficiently broad and systematically biased reference data affect the predictive quality of the learned models. Often, these models exhibit significant deviations from experimentally observed phase transition temperatures, in the order of several hundred kelvins. Thus, fine-tuning is necessary to achieve adequate accuracy in many practical problems. This work proposes a fine-tuning strategy via top-down learning, directly correcting the wrongly predicted transition temperatures to match the experimental reference data. Our approach leverages the Differentiable Trajectory Reweighting algorithm to minimize the free energy differences between phases at the experimental target pressures and temperatures. We demonstrate that our approach can accurately correct the phase diagram of pure Titanium in a pressure range of up to 5 GPa, matching the experimental reference within tenths of kelvins and improving the liquid-state diffusion constant. Our approach is model-agnostic, applicable to multi-component systems with solid-solid and solid-liquid transitions, and compliant with top-down training on other experimental properties. Therefore, our approach can serve as an essential step towards highly accurate application-specific and foundational machine learning potentials.

</details>


### [170] [Predicting parameters of a model cuprate superconductor using machine learning](https://arxiv.org/abs/2512.04024)
*V. A. Ulitko,D. N. Yasinskaya,S. A. Bezzubin,A. A. Koshelev,Y. D. Panov*

Main category: physics.comp-ph

TL;DR: 使用深度学习（特别是U-Net架构）解决铜氧化物超导体模型哈密顿量的逆问题：根据相图预测模型参数，验证了机器学习在凝聚态物理复杂模型分析中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 多参数模型相图计算的计算复杂度限制了根据实验数据选择对应参数的能力，需要解决从相图反推模型参数的逆问题。

Method: 比较了三种深度学习架构（VGG、ResNet和U-Net），其中U-Net被调整用于回归任务。使用平均场近似计算的大量相图数据集进行训练，然后用半经典热浴算法的蒙特卡洛模拟数据进行验证。

Result: U-Net模型表现最佳，能准确预测所有考虑的哈密顿量参数。预测精度低的区域对应于相图中的参数不敏感区域，这有助于提取物理可解释的模式并验证参数对系统的重要性。

Conclusion: 研究证实了机器学习在分析凝聚态物理中复杂物理模型方面的应用潜力，特别是通过深度学习解决逆问题的方法。

Abstract: The computational complexity of calculating phase diagrams for multi-parameter models significantly limits the ability to select parameters that correspond to experimental data. This work presents a machine learning method for solving the inverse problem - forecasting the parameters of a model Hamiltonian for a cuprate superconductor based on its phase diagram. A comparative study of three deep learning architectures was conducted: VGG, ResNet, and U-Net. The latter was adapted for regression tasks and demonstrated the best performance. Training the U-Net model was performed on an extensive dataset of phase diagrams calculated within the mean-field approximation, followed by validation on data obtained using a semi-classical heat bath algorithm for Monte Carlo simulations. It is shown that the model accurately predicts all considered Hamiltonian parameters, and areas of low prediction accuracy correspond to regions of parametric insensitivity in the phase diagrams. This allows for the extraction of physically interpretable patterns and validation of the significance of parameters for the system. The results confirm the promising potential of applying machine learning to analyze complex physical models in condensed matter physics.

</details>
