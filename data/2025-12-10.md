<div id=toc></div>

# Table of Contents

- [physics.comp-ph](#physics.comp-ph) [Total: 2]
- [gr-qc](#gr-qc) [Total: 21]
- [quant-ph](#quant-ph) [Total: 56]
- [cs.LG](#cs.LG) [Total: 88]


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [1] [Seasonal thermal stress analysis of defective mass concrete sidewalls based on the average forming temperature method](https://arxiv.org/abs/2512.08158)
*Ziyan Zhao,Ting Peng,Peng Wu,Chaojun Hu,Qilin Yi,Chuangrui Huang,Junjie Niu,Xiaoxue Xu,Tao Li,Yuan Li*

Main category: physics.comp-ph

TL;DR: 城市地下侧墙热裂缝在夏季浇筑、冬季服役时常见，季节性温度梯度在结构约束下导致应力集中。通过有限元模拟量化了既有裂缝周围的局部应力场，发现裂缝尖端和底部存在显著拉应力集中（19.2-34.1 MPa和17.2-29.4 MPa），远高于无裂缝墙体。研究为风险评估和缓解措施（如接缝间距、保温策略）提供定量依据。


<details>
  <summary>Details</summary>
Motivation: 城市地下侧墙在夏季浇筑、冬季服役时经常出现热裂缝，季节性温度梯度在结构约束作用下会导致既有裂缝周围的局部应力集中，但缺乏定量评估。需要量化这些应力集中效应，为工程设计和风险控制提供依据。

Method: 采用正交有限元模拟矩阵（16种组合），在稳态热荷载和线弹性本构模型下，评估裂缝表面尖端和裂缝底部上半部分的最大主应力分布。同时进行三维模拟，分析随机分布内部空洞在不同温度下的应力响应。

Result: 所有工况下均出现显著拉应力集中：裂缝表面尖端最大应力为19.2-34.1 MPa，裂缝底部为17.2-29.4 MPa，均高于相同位置无裂缝墙体的应力水平。三维模拟显示，采用平均成型温度会使空洞表面峰值拉应力从3.42增至4.40 MPa（10°C）和从5.98增至6.96 MPa（-5°C）。

Conclusion: 季节性温度梯度在结构约束下会显著放大既有缺陷周围的局部应力，为城市地下围护墙的设计和运营提供了风险评估依据。建议通过接缝间距优化和保温策略等缓解措施来控制热裂缝风险，特别是在寒冷服役条件下需注意平均成型温度的影响。

Abstract: Thermal cracking in urban underground sidewalls is frequently observed when structures are cast in summer and enter service in winter, as seasonal temperature gradients act under structural restraint. To quantify the local stress field associated with pre-existing cracks, an orthogonal finite-element simulation matrix of 16 combinations is constructed. Distributions of maximum principal stress () at the surface crack tip and along the upper half of the crack bottom are evaluated using steady-state thermal loading and a linear-elastic constitutive model. Across all cases, pronounced tensile stress concentration occurs at both locations: the maximum ranges from 19.2 to 34.1 MPa at the crack surface end and from 17.2 to 29.4 MPa at the crack bottom. These concentrated values are consistently higher than the stress level at the same locations in an otherwise identical uncracked wall, clarifying how seasonal temperature gradients under restraint amplify local stresses around existing defects. The quantitative ranges reported here provide a basis for risk screening and for formulating practical mitigation measures (e.g., joint spacing and insulation strategies) in the design and operation of urban underground enclosure walls. In addition, three-dimensional simulations of randomly distributed internal voids show that adopting average forming temperature increases the peak tensile stress on void surfaces from 3.42 to 4.40 MPa at 10 deg C and from 5.98 to 6.96 MPa at -5 deg C, further highlighting the risk amplification effect of AFT under cold service conditions.

</details>


### [2] [Matrix-free algorithms for fast ab initio calculations on distributed CPU architectures using finite-element discretization](https://arxiv.org/abs/2512.08571)
*Phani Motamarri,Gourab Panigrahi*

Main category: physics.comp-ph

TL;DR: 提出矩阵自由算法加速有限元离散化密度泛函理论计算，通过张量收缩和缓存优化实现1.5-5.8倍加速


<details>
  <summary>Details</summary>
Motivation: 有限元离散化在Kohn-Sham密度泛函理论计算中面临计算瓶颈，传统稀疏矩阵向量乘法存在内存限制和数据移动开销问题，特别是在高多项式阶数时

Method: 开发矩阵自由算法，利用一维基函数和积分数据的结构化张量收缩进行实时计算；引入统一的多级批处理数据布局，结合缓存重用、奇偶分解和混合精度优化

Result: 对于大型多向量赝势DFT计算，矩阵自由内核比现有单元矩阵方法快1.5-4倍；对于全电子DFT计算，加速比高达5.8倍

Conclusion: 矩阵自由形式与误差容忍的Chebyshev滤波子空间迭代特征求解器结合，显著减少了达到所需精度的端到端求解时间

Abstract: Finite-element (FE) discretisations have emerged as a powerful real-space alternative to large-scale Kohn-Sham density functional theory (DFT) calculations, offering systematic convergence, excellent parallel scalability, while accommodating generic boundary conditions. However, the dominant computational bottleneck in FE-based DFT arises from the repeated application of the discretised sparse Hamiltonian to large blocks of trial vectors during iterations in an iterative eigensolver. Traditional sparse matrix-vector multiplications and FE cell-matrix approaches encounter memory limitations and high data-movement overheads, particularly at higher polynomial orders, typically used in DFT calculations. To overcome these challenges, this work develops matrix-free algorithms for FE-discretised DFT that substantially accelerate these products by doing on-the-fly operations that utilize structured tensor contractions over 1D basis functions and quadrature data. A unified multilevel batched data layout that handles both real and complex-valued operators is introduced to maximise cache reuse and SIMD utilisation on Frontier (AVX2), Param Pravega (AVX512) and Fugaku (SVE). We also combine terms for optimal cache reuse, even-odd decomposition to reduce FLOP, and mixed-precision intrinsics. Extensive benchmarks show that for large multivector pseudopotential DFT calculations, the matrix-free kernels deliver 1.5-4x speedups over the state-of-the-art cell-matrix approach baselines. For all-electron DFT calculations, the matrix-free operator achieves gains of up to 5.8x due to its efficient implementation and superior arithmetic intensity. When integrated with an error-tolerant Chebyshev-filtered subspace iteration eigensolver, the matrix-free formalism yields substantial reductions in end-to-end time-to-solution using FE meshes that deliver desired accuracies in ground-state properties.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [3] [Impact on orbital period of X-ray Binary system attached to a cosmic string](https://arxiv.org/abs/2512.07911)
*Ishan Swamy,Deobrat Singh*

Main category: gr-qc

TL;DR: 宇宙弦附着在旋转黑洞上会提取其旋转能量，导致质量损失和自旋降低。本文提出通过低质量X射线双星系统探测这一现象的新方法，并尝试用宇宙弦导致的质量损失来解释观测到的意外轨道周期变化。


<details>
  <summary>Details</summary>
Motivation: 现有观测发现一些低质量X射线双星系统存在意外的轨道周期变化，需要新的物理机制来解释这些现象。宇宙弦与黑洞的相互作用可能导致黑洞质量损失，从而影响双星轨道周期，这为解释观测异常提供了新的可能性。

Method: 基于现有文献提出新方法，考虑低质量X射线双星系统，分析宇宙弦与黑洞的相互作用。通过多个低质量X射线双星系统的分析，研究宇宙弦张力对轨道周期变化的影响，建立宇宙弦张力与观测周期变化之间的关系。

Result: 对于约10^{-10}量级的轨道周期变化，对应的宇宙弦张力约为10^{-17}，落在预测的宇宙弦张力范围内。分析显示，当弦张力约为10^{-11}时，会产生显著且可观测的变化。多个低质量X射线双星系统的分析支持这一结论。

Conclusion: 宇宙弦与黑洞的相互作用可以解释低质量X射线双星系统中观测到的意外轨道周期变化。提出的方法为探测宇宙弦提供了新途径，宇宙弦张力在10^{-17}到10^{-11}范围内可能通过这种机制被探测到。

Abstract: Cosmic strings attached to rotating black holes extract its rotational energy, resulting in a mass loss and reduced spin. In this paper we discuss the proposed methods to detect these phenomena and present a novel methodology based on existing literature, by considering a Low Mass X-ray binary system. We investigate the impact of a cosmic string interacting with a black hole in an X-ray binary system and attempt to explain the observations of unexpected orbital period changes in such systems by proposing mass loss by cosmic strings to be a potential cause. For a period change of order $10^{-10}$, the string tension is $\sim 10^{-17}$, lying in the predicted range for cosmic string tension. An analysis of multiple low mass X-ray binary systems is carried out and it is shown that a significant and observable change occurs for a string tension $\sim 10^{-11}$.

</details>


### [4] [Beyond Extremality: Weak Gravity Conjecture Constraints on Gravitational Lensing in Gravity's Rainbow](https://arxiv.org/abs/2512.07922)
*Saeed Noori Gashti,Behnam Pourhassan,Izzet Sakallı*

Main category: gr-qc

TL;DR: 该论文研究彩虹引力中弱引力猜想对引力透镜的约束，特别关注超极端情形以及弱引力猜想与弱宇宙监督猜想在修正的Reissner-Nordström-AdS黑洞中的相互作用。


<details>
  <summary>Details</summary>
Motivation: 研究弱引力猜想和弱宇宙监督猜想在彩虹引力框架下的兼容性，探索这两个基本猜想如何通过彩虹引力函数自然调和，并寻找观测上区分满足弱引力猜想的裸奇点和保持弱宇宙监督猜想的黑洞的方法。

Method: 使用拓扑方法分析光子球构型，通过彩虹函数f(ε)和g(ε)修正时空度规和极端性界限，应用高斯-博内定理结合雅可比-莫佩尔蒂光学几何计算光子和有质量粒子的弱偏转角至二阶。

Result: 确认不稳定圆形光子球存在于事件视界外，验证了弱引力猜想和弱宇宙监督猜想的兼容性；推导了修正的极端荷质比；发现彩虹函数g(ε)增强偏转角，f(ε)仅影响电荷相关贡献；在极端性下偏转角与f(ε)无关；超极端构型表现出比极端黑洞更强的透镜效应。

Conclusion: 彩虹引力为调和弱引力猜想和弱宇宙监督猜想提供了自然机制，超极端构型的强透镜效应可作为观测上区分满足弱引力猜想的裸奇点和保持弱宇宙监督猜想的黑洞的潜在判据。

Abstract: We investigate the constraints imposed by the Weak Gravity Conjecture (WGC) on gravitational lensing in gravity's rainbow, focusing in particular on scenarios beyond extremality and on the interplay between the WGC and the Weak Cosmic Censorship Conjecture (WCCC) in the context of Reissner-Nordström-Anti-de Sitter black holes modified by rainbow gravity. Using topological methods, we first analyze the configuration of photon spheres and confirm that unstable circular photon spheres with topological charge $(ω= -1)$ exist outside the event horizon throughout the parameter space, thereby verifying the simultaneous validity of both the WGC and the WCCC. The rainbow functions $f(\varepsilon)$ and $g(\varepsilon)$, which encode Planck-scale corrections through the energy ratio $(\varepsilon =E/E_P)$, modify both the spacetime metric and the extremality bound. We derive the corresponding modified extremal charge-to-mass ratio, $(q^2/m^2)>(Q^2/M^2)_{\text{ext}}$, and show that gravity's rainbow offers a natural mechanism for reconciling these two fundamental conjectures. By applying the Gauss-Bonnet theorem in conjunction with Jacobi-Maupertuis optical geometry, we compute the weak deflection angles for both photons and massive particles to second order. The rainbow function $g(\varepsilon)$ appears with powers $(g^{-2})$ and $(g^{-4})$, enhancing the deflection angle when $g(\varepsilon)<1$, while $f(\varepsilon)$ influences only the charge-dependent contributions. At extremality, the deflection angle becomes independent of $f(\varepsilon)$, yielding a universal prediction that can be tested without specifying the form of the rainbow functions. We further find that super-extremal configurations exhibit stronger lensing effects than extremal black holes, suggesting a potential observational discriminator between WGC-satisfying naked singularities and WCCC-preserving black holes.

</details>


### [5] [Near-horizon gravitational perturbations of rotating black holes](https://arxiv.org/abs/2512.07937)
*Rico K. L. Lo,Yucheng Yin*

Main category: gr-qc

TL;DR: 首次推导出旋转黑洞视界附近引力辐射计算中的无发散源项，应用于超相对论粒子坠入引起的视界动态形变和极端质量比旋近的能量通量计算。


<details>
  <summary>Details</summary>
Motivation: 旋转黑洞视界附近的引力辐射微扰计算长期存在发散问题，这阻碍了对黑洞视界附近物理现象的研究。

Method: 在广义Sasaki-Nakamura形式中推导出无发散的源项，建立了新的计算框架。

Result: 成功计算了超相对论粒子坠入引起的视界动态形变，展示了视界上准正模式的激发；并计算了极端质量比旋近朝向视界的能量通量。

Conclusion: 该框架为研究黑洞视界附近的物理现象提供了强大工具，解决了长期存在的计算发散问题。

Abstract: Perturbative calculations of gravitational radiation near horizons of rotating black holes have been plagued with divergence issues. We derive for the first time a divergence-free source term for such cases within the generalized Sasaki-Nakamura formalism. As applications, we compute the dynamical deformation of the event horizon caused by an ultrarelativistic particle plunge, demonstrating the excitation of quasinormal modes at the horizon, and we evaluate the energy flux towards the horizon from an extreme mass-ratio inspiral. This framework provides a powerful tool for studying physics near black hole horizons.

</details>


### [6] [Quasinormal ringing of Kerr black holes. III. Excitation coefficients for equatorial inspirals from the innermost stable circular orbit](https://arxiv.org/abs/2512.07959)
*Matteo Della Rocca,Laura Pezzella,Emanuele Berti,Leonardo Gualtieri,Andrea Maselli*

Main category: gr-qc

TL;DR: 研究黑洞合并后准正规模的激发，特别关注点粒子从最内稳定圆轨道坠入克尔黑洞时准正规模激发系数的计算及其对黑洞自旋的依赖性。


<details>
  <summary>Details</summary>
Motivation: 黑洞合并后通过引力波"衰荡"进入稳态，准正规模的频率仅取决于剩余黑洞的质量和自旋，而振幅则依赖于合并动力学。研究准正规模的激发有助于理解合并过程并为引力波探测提供理论支持。

Method: 采用频率域方法计算克尔黑洞赤道面上点粒子从最内稳定圆轨道坠入时的准正规模激发系数，分析这些系数对剩余黑洞自旋的依赖性。

Result: 发现对于快速旋转的黑洞，高阶泛音和辐射的次主导多极子变得越来越重要，这表明对于高自旋的合并剩余黑洞，探测泛音和高阶模的前景显著增强。

Conclusion: 黑洞自旋对准正规模激发有重要影响，快速旋转黑洞的高阶模激发增强，这为引力波天文学中探测这些特征提供了更好的机会。

Abstract: The remnant of a black hole binary merger settles into a stationary configuration by "ringing down" through the emission of gravitational waves that consist of a superposition of damped exponentials with discrete complex frequencies - the remnant black hole's quasinormal modes. While the frequencies themselves depend solely on the mass and spin of the remnant, the mode amplitudes depend on the merger dynamics. We investigate quasinormal mode excitation by a point particle plunging from the innermost stable circular orbit of a Kerr black hole. Our formalism is general, but we focus on computing the quasinormal mode excitation coefficients in the frequency domain for equatorial orbits, and we analyze their dependence on the remnant black hole spin. We find that higher overtones and subdominant multipoles of the radiation become increasingly significant for rapidly rotating black holes. This suggests that the prospects for detecting overtones and higher-order modes are considerably enhanced for highly spinning merger remnants.

</details>


### [7] [Analytical Study for Primordial Non-Gaussianity in the gravity 4D Einstein-scalar-Gauss-Bonnet Inflation](https://arxiv.org/abs/2512.08047)
*A. Agung,U. Sambiri,G. Hikmawan,F. P. Zen*

Main category: gr-qc

TL;DR: 该研究通过非高斯性参数检验4DEGB引力宇宙学暴胀模型，使用in-in形式计算曲率扰动的三点关联函数，并用Planck数据约束模型参数。


<details>
  <summary>Details</summary>
Motivation: 非高斯统计可作为约束暴胀模型的重要参数，通过CMB观测数据检验特定暴胀模型的非高斯性参数，评估其作为约束宇宙学暴胀模型的有效性。

Method: 采用in-in形式体系，计算曲率扰动ζ的三阶微扰展开的三点关联函数，构建双谱分析非高斯性，利用Planck合作组观测数据约束非高斯性参数。

Result: 测试的模型在压缩极限下表现为慢滚主导，具有局部形状函数主导的非高斯特征，与单标量场暴胀的非高斯性类似，确认了Gauss-Bonnet项在D<5时空中的拓扑不变性。

Conclusion: 4DEGB引力宇宙学暴胀模型的非高斯性特征与单标量场暴胀一致，Gauss-Bonnet项在低维时空中不影响引力场方程，该非高斯性参数可作为约束暴胀模型的有效参考。

Abstract: An inflationary model can be constrained by non-gaussian statistics as a parameter in the LSS (Large Scale Structure) distribution, and in the radiation of CMB (Cosmic Microwave Background) fluctuating temperature. Data on the CMB from Planck Collaboration provide up-to-date constraints on the parameters controlling the degree of non-Gaussianity in certain inflationary models, thus supporting or not supporting the model. Setting the non-Gaussianity parameter investigated in this study can be a reference whether or not it is a good parameter in constraining cosmological inflation models. This study attempts to examine the non-Gaussianity of the 3+1-dimensional 4DEGB gravitational cosmological inflation model starting from random field statistics. The non-Gaussian signature generated by the model is quantified, and the parameters controlling the degree of non-Gaussianity are constrained using data observation of Planck Collaboration. The method used in investigating non-Gaussianity is the in-in formalism, applied after obtaining the 3-point of $ζ$ (curvature perturbation) terms of the perturbation expansion to the third order. The 3-point correlation function helps to create a bispectrum used to investigate the non-gaussinity of the inflation model. The results of this study show that the model tested is the slow roll pressed in the squeezed limit, because it witnesses a dominant local shape function. It has such as the non-gaussianity possessed by the single scalar field inflation as confirmation that Gauss-Bonnet term within Einstein-Hilbert action is topologically invariant, and no influence gravitational field equations in $D<5$ spacetimes.

</details>


### [8] [The Infrared Universe](https://arxiv.org/abs/2512.08050)
*Jonathan Holland*

Main category: gr-qc

TL;DR: 论文提出一个介观框架，将宇宙外部视为与视界储层耦合的开放量子子系统，通过红外模式恢复全局幺正性，并引入Carnot-Carathéodory几何解释光子平衡、重子守恒和大尺度运动学。


<details>
  <summary>Details</summary>
Motivation: 解决视界耦合的半经典引力中重子数守恒与全局幺正性之间的矛盾，为宇宙外部与视界储层之间的相互作用提供统一的理论框架。

Method: 1. 建立介观框架，将宇宙外部作为开放量子子系统，视界作为储层；2. 通过局部守恒定律分析重子数损失；3. 引入红外返回通道恢复全局幺正性；4. 采用Carnot-Carathéodory切几何描述介观尺度物理；5. 将光子传播、物质运动与视界热力学联系起来。

Result: 1. 红外模式能够补偿视界损失的重子数，恢复熵和电荷；2. Carnot-Carathéodory几何产生有效宇宙腔，其稳态为普朗克谱；3. 同一尺度σ解释平坦的旋转曲线；4. 视界热力学将σ与宇宙膨胀率H联系起来，建立统一红外结构。

Conclusion: 视界耦合的半经典引力必然包含红外返回通道，Carnot-Carathéodory几何提供了一个统一框架，将光子平衡、重子守恒和大尺度运动学联系起来，揭示了宇宙红外结构的基本特征。

Abstract: We develop a mesoscopic framework in which the cosmological exterior is treated as an open quantum subsystem coupled to a horizon reservoir. Local conservation laws, expressed as $\nabla_μ\langle J^μ\rangle=0$, imply that when baryon number is lost across a horizon its conserved quantum numbers are sequestered into inaccessible modes, producing an effective depletion in the exterior sector. Global unitarity therefore requires compensating source terms in the exterior continuity equations. We show that relativity forces these compensating excitations to arise through long-wavelength geometric modes: only infrared fluctuations can restore entropy and charge while remaining outside the causal wedge of the infalling matter. This identifies an infrared return channel as a generic feature of horizon-coupled semiclassical gravity.
  The second ingredient is a Carnot-Carathéodory (CC) tangent geometry, whose mesoscopic scale $σ$ governs both the excitation of these IR modes and the kinematics of photon and matter propagation. In this setting, photon trajectories follow recurrent horizontal geodesics, producing an effective cosmic cavity whose stationary state is a Planck spectrum set by $σ$. The same scale modifies large-radius circular motions in a way consistent with flattened rotation curves. Horizon thermodynamics and mesoscopic balance laws then link $σ$ to the cosmic expansion rate, $H\simσ$, yielding a unified infrared structure underlying photon equilibrium, baryon balance, and large-scale kinematics.

</details>


### [9] [Noble gravitational atoms: Self-gravitating black hole scalar wigs with angular momentum number](https://arxiv.org/abs/2512.08095)
*Miguel Alcubierre,Juan Barranco,Argelia Bernal,Juan Carlos Degollado,Alberto Diez-Tejedor,Miguel Megevand,Dario Nunez,Olivier Sarbach*

Main category: gr-qc

TL;DR: 提出了新的球对称爱因斯坦-克莱因-戈登方程解，描述了黑洞周围自引力标量场构型，称为"贵族引力原子"，类似于具有闭合电子壳的贵族原子。


<details>
  <summary>Details</summary>
Motivation: 研究黑洞周围自引力标量场构型，探索这些构型如何类比于原子结构，特别是类似于具有闭合电子壳的贵族原子。

Method: 采用类似构造ℓ-玻色子星的方法，在准稳态近似下求解爱因斯坦-克莱因-戈登方程，构建具有角动量数ℓ≥0的自引力"引力原子"。

Result: 贵族引力原子在适当极限下全局接近ℓ-玻色子星，仅在视界附近区域有明显差异。ℓ>0时可能出现相对较大半径处的密度极大值，ℓ>1时视界附近密度较小。ℓ>0时不总是出现典型的视界密度尖峰，有时反而出现小凹陷。ℓ=0时可能出现尖峰，但对总质量密度贡献可忽略。这些天体的大小、密度和寿命随参数变化显著，有些可大如星系、稀如暗物质、寿命长如宇宙年龄。

Conclusion: 贵族引力原子是一类新的黑洞周围自引力标量场构型，具有类似原子结构的特性，可能在天体物理中扮演重要角色，特别是作为暗物质候选者或星系尺度结构。

Abstract: We present new spherically symmetric solutions of the Einstein-Klein-Gordon equations in a quasi-stationary approximation that describe self-gravitating scalar field configurations around a black hole, including angular momentum number $\ell$. An approach analogous to the one which gives rise to $\ell$-boson stars is used here to construct self-gravitating ``gravitational atoms" with $\ell\ge0$. We refer to these new solutions as {\it noble gravitational atoms}, by analogy with noble atoms, which are characterized by closed electron shells. We show that, in the proper limit, noble gravitational atoms approach $\ell$-boson stars globally, displaying noticeable differences only in a region very close to the event horizon. Noble gravitational atoms with $\ell>0$ sometimes present density maxima located at relatively large radii, with small density close to the horizon for $\ell>1$. Furthermore, they do not always present the typical density spike at the event horizon if $\ell > 0$; on the contrary, they sometimes exhibit a small dip there. When $\ell=0$, a spike can appear, but its contribution to the total mass density is always negligible. The size, density, and lifetime of these objects vary significantly depending on the parameters, being in some cases as large as galaxies, as dilute as dark matter, and as long-lived as the Universe itself.

</details>


### [10] [High-overtone ringdown fits: start time, no-hair tests, and correlations](https://arxiv.org/abs/2512.08098)
*Erin Coleman,Eliot Finch*

Main category: gr-qc

TL;DR: 论文研究引力波环降中泛音的实际效用，发现泛音效用随阶数增加而递减，高泛音参数存在强相关性，但联合测量可能用于检验广义相对论一致性。


<details>
  <summary>Details</summary>
Motivation: 虽然泛音能提高环降拟合性能，但其激发程度是否如拟合所示仍存疑问。研究旨在探讨每个额外泛音在提取环降信息中的实际效用，以及检测广义相对论偏差的可行性。

Method: 采用实用主义方法：1) 分析环降起始时间与泛音数量的关系；2) 评估检测广义相对论频率偏差的可行性；3) 进行贝叶斯参数估计（而非最小二乘拟合），获取泛音振幅和相位的后验分布，研究其相关性结构。

Result: 1) 不存在明确的"最大"泛音，每个额外泛音的效用相比前一个递减；2) 由于强相关性，测量最高泛音的单个振幅和相位越来越困难；3) 泛音振幅的联合测量（即相关性结构本身）对最高泛音频率和衰减时间敏感，可能为检验广义相对论一致性提供途径。

Conclusion: 泛音在环降分析中具有递减的边际效用，高泛音参数测量存在挑战，但通过联合测量相关性结构，可能利用最高泛音进行广义相对论一致性检验，为引力波天文学提供新诊断工具。

Abstract: Overtones are known to improve the performance of fits to the ringdown, both in numerical-relativity simulations and gravitational-wave observations. Although the overtone frequencies are a concrete prediction of general relativity, it remains an open question whether they are excited to the extent that fits would suggest. In this work, we take a pragmatic approach and investigate the practical utility of each additional overtone in extracting information from the ringdown. We look at the dependence of the ringdown start time on the number of overtones, and the feasibility of detecting deviations from general relativity in the ringdown frequencies. We suggest that there is no clear "maximum" overtone, but rather the utility of each additional overtone decreases compared to the one before. Finally, we perform Bayesian parameter estimation (as opposed to least-squares fits) to obtain posterior distributions on the overtone amplitudes and phases, allowing us to investigate their correlation structure. Due to strong correlations it becomes increasingly hard to measure individual amplitudes and phases for the highest overtones. However, we find that the joint measurement of overtone amplitudes (i.e., the correlation structure itself) is sensitive to the frequencies and decay times of even the highest overtones, possibly offering an avenue to perform consistency tests with general relativity.

</details>


### [11] [Universality in quasinormal modes of a magnetized black hole](https://arxiv.org/abs/2512.08116)
*Marcos R. Ribeiro,Eveling C. Ribeiro,Kai Lin,Elcio Abdalla*

Main category: gr-qc

TL;DR: 研究磁化黑洞环境中带电标量场的线性稳定性，发现场电荷存在临界值，此时准正规模谱呈现普适的1/2幂律标度，对应从局域束缚态到去局域态的相变。


<details>
  <summary>Details</summary>
Motivation: 磁化环境中的黑洞是理论和观测研究的热点，带电物质与这类天体的相互作用为从基础场论到高能天体物理的广泛应用提供了丰富的研究场景。

Method: 研究静态轴对称磁化爱因斯坦-麦克斯韦解中外部带电标量场的线性稳定性，结合频率域和时域分析探测其准正规模。

Result: 发现场电荷存在临界值，此时准正规模谱呈现普适的1/2幂律标度行为，这可以解释为从特征尺度~1/B的束缚态到远大于1/B的去局域态的相变，其中阻尼率参数化地变小。

Conclusion: 这些结果为涉及高度磁化致密天体的更现实场景提供了定性和定量的见解。

Abstract: Black holes (BHs) in magnetized environments are a topic of intense research, both theoretical and observational. In particular, the interaction between charged matter and such objects provides a rich arena with applications ranging from fundamental field theory to high-energy astrophysics. In this work, we investigate the linear stability of a magnetized Einstein-Maxwell solution describing a static, axially symmetric BH immersed in a uniform magnetic field. We probe the dynamics of an external charged scalar field through its quasinormal modes (QNMs), combining frequency- and time-domain analyses. We find a critical value of the field charge at which the QNM spectrum exhibits universal power-law scaling with an exponent of approximately $1/2$. This critical behavior admits a simple interpretation in terms of a transition between a confined regime, where waves remain effectively trapped within a region of characteristic size $\sim 1/B$, and a deconfined regime, where the field reaches distances $\gg 1/B$ and the damping rate becomes parametrically small. These results provide qualitative and quantitative insights that may inform more realistic scenarios involving highly magnetized compact objects.

</details>


### [12] [$D$-dimensional aether charged black hole and aether waves in M-subset of Einstein-aether theory](https://arxiv.org/abs/2512.08184)
*Chikun Ding,Yuebing Zhou,Yu Shi,Xiangyun Fu*

Main category: gr-qc

TL;DR: 研究爱因斯坦-以太理论M子集中的黑洞解和引力波极化，发现类时以太场无静态黑洞解，类空以太场存在类Reissner-Nordstrom解，并分析了线性化理论中的模式传播速度。


<details>
  <summary>Details</summary>
Motivation: 研究爱因斯坦-以太理论中违反洛伦兹不变性的单位范数向量场（以太场）如何影响黑洞解和引力波极化特性，探索该理论框架下的引力物理现象。

Method: 采用爱因斯坦-以太理论的M子集形式，该形式类似于带有拉格朗日乘子势的爱因斯坦-麦克斯韦理论。通过分析类时和类空以太场情况，寻找静态黑洞解，并使用扩展的Killing势方法构建Smarr公式和第一定律。对线性化理论分析引力波模式。

Result: 1. 类时以太场不存在静态黑洞解，与先前研究结果不同；2. 类空以太场存在D维类Reissner-Nordstrom黑洞解，以太电荷有最小和最大值；3. 线性化理论中spin-2模式速度为1，与维度和参数无关，但部分极化消失；4. spin-1模式速度也为1；5. 存在第三种纵向以太-度规模式，线性时间依赖，非spin-0模式。

Conclusion: 爱因斯坦-以太理论M子集中，以太场的类时/类空性质对黑洞解存在性有决定性影响，引力波模式传播速度保持为1，但极化特性发生变化，揭示了洛伦兹不变性破坏对引力物理的独特影响。

Abstract: We study the black hole solution and gravitational wave polarizations in a M-subset of the Einstein-aether theory with Lorentz invariance violated by an unit norm vector field -- the aether field $u^a$. This M-subset of Einstein-aether theory has a form of Einstein-Maxwell theory with a term of Lagrange multiplier potential $λ(u_au^a\mp1)$. We find that if the aether field is timelike, there is no static black hole solution existing, which is different from the result reported in Phys. Rev. D {\bf64} 024028. When the aether field is spacelike, there exists a static solution -- $D$-dimensional Reissner-Nordstrom-like black hole solution, in which the aether charge have a minimum and maximum values. The conception of the aether charge also exists in the $c_i$ subset of the Einstein-aether theory. The Smarr formula and the first law can be still constructed via the extended method of Killing potential. For the linearized M-subset Einstein-aether theory with the timelike aether field, we find the speed of spin-2 modes is unit, which aren't dependent on spacetime dimensions $D$ and aether constant $b_1$, but some parts of polarizations are disappeared. The speed of spin-1 modes is unit also. The third kind mode is the longitudinal aether-metric mode, which is linearly time dependent and not the spin-0 mode.

</details>


### [13] [Probing Cosmic Strings via Black Hole Quasinormal Modes in Gravitational Wave Astronomy](https://arxiv.org/abs/2512.08368)
*Ishan Swamy,Deobrat Singh*

Main category: gr-qc

TL;DR: 提出通过分析黑洞准正规模式来探测宇宙弦的新框架，将宇宙弦建模为黑洞时空中的微扰，并确定了可观测的微扰强度下限。


<details>
  <summary>Details</summary>
Motivation: 宇宙弦作为早期宇宙形成的一维拓扑缺陷尚未被观测到，而引力波观测为探测新物理提供了新途径。研究旨在利用黑洞准正规模式作为探测宇宙弦的替代方法。

Method: 将宇宙弦建模为非旋转黑洞时空中的微扰，通过数值模拟分析其对准正规模式谱的影响，研究特征值分裂和中心的变化特征。

Result: 确定了可观测的微扰强度下限：中性弦λ∼10⁻¹⁰，带电弦λ∼10⁻⁷。发现宇宙弦特性会在引力波信号中留下独特且可探测的特征。

Conclusion: 准正规模式分析为约束或探测宇宙弦提供了强大的替代观测策略，并提供了通过信号反推弦能量或电荷的逆向方法，为未来LIGO升级和先进多信使天文学开辟了新探测潜力。

Abstract: Black holes, the simplest solution to Einstein's field equations, do not emit light, making their observations a major challenge for researchers. However, discovery of binary black holes (BBHs) in 2015 by LIGO has transformed the study of compact objects, with over 300 BBHs recorded, providing a new avenue for probing new physics. GWs remain a prominent and precise method of observing not only BBHs, but also dark matter and cosmic strings. Cosmic strings -- hypothetical one dimensional topological defects formed in the early universe, are yet to be observed, with multiple detection methods such as particle radiation, gravitational waves and lensing being proposed. Here we present a novel framework to search for cosmic strings by modeling them as perturbations within non-rotating black hole spacetime, focusing on their imprint on the spectrum of quasinormal modes (QNMs). Our numerical simulations identify a lower limit on perturbation strength, $λ\sim 10^{-10}$ for uncharged string and $λ\sim 10^{-7}$ for charged string, below which cosmic string effects become unobservable in QNM signals. By analyzing eigenvalue splitting and centers, we show that cosmic string properties impart distinct and detectable features to GW signals. Our results establish QNM analysis as a powerful, alternative observational strategy for constraining or detecting cosmic strings, and offer an inverse approach to estimate string energy or charge if a signal is detected. With upgrades in LIGO technologies and advanced multimessenger astronomy under development, these findings highlight new potential for detecting cosmic strings.

</details>


### [14] [Careless Whispers: A population of sub-threshold post-merger gravitational waves constrains the hot nuclear equation of state](https://arxiv.org/abs/2512.08497)
*Fiona H. Panther,Paul D. Lasky*

Main category: gr-qc

TL;DR: 通过统计结合多个亚阈值引力波双中子星并合后余辉信号，间接测量中子星最大质量，并约束热核物质状态方程


<details>
  <summary>Details</summary>
Motivation: 单个双中子星并合后余辉信号通常太弱无法被单独检测，但通过统计结合多个亚阈值事件，可以提取关于中子星最大质量和核物质状态方程的重要信息

Method: 构建合成双中子星并合后余辉信号群体，统计分析哪些事件立即坍缩成黑洞，哪些事件中子星至少存活数十毫秒。结合并合前阶段获得的中子星质量分布信息，间接测量中子星最大质量

Result: 50-70个具有双中子星并合前测量的引力波事件结合后，可对快速旋转热中子星最大质量给出11-20%的相对不确定度，进而对Tolman-Oppenheimer-Volkoff质量给出12-21%的相对约束

Conclusion: 通过统计结合多个亚阈值引力波事件，可以间接测量中子星最大质量并约束热核物质状态方程，为理解宇宙最致密区域的物理提供新途径

Abstract: We show how to coherently combine information from a population of sub-threshold, gravitational-wave binary neutron star post-merger remnants. Although no individual event in our synthetic population can be claimed as a confident detection, we show how to statistically determine the fraction of merger events that promptly collapse to form a black hole, compared to those for which a neutron star survives the merger for at least tens of milliseconds. This fraction, when combined with information about the neutron star mass distribution gleaned from the inspiral portion of the signals, provides an indirect measure of the neutron star maximum mass. Using conservative measures of the post-merger waveforms, we show that 50-70 events with binary neutron star inspiral measurements can be combined to give an $11-20\%$ fractional uncertainty on the maximum mass of rapidly rotating, hot neutron stars, which can potentially be turned into a $12-21\%$ fractional constraint on the Tolman-Oppenheimer-Volkoff mass. We discuss how this measure of the hot nuclear equation of state can be combined with information of cold neutron stars to see the effect of temperature on physics in the densest regions of the Universe.

</details>


### [15] [Time-Averaged Template for Stochastic Gravitational-Wave Background Detection in Space-Based Interferometers](https://arxiv.org/abs/2512.08521)
*Jing-yi Wu,Yong Tang*

Main category: gr-qc

TL;DR: 研究时间变化臂长对空间引力波任务中随机引力波背景参数估计的影响，比较三种模板策略，发现时间平均模板能提高估计精度。


<details>
  <summary>Details</summary>
Motivation: 随机引力波背景在空间引力波任务中会与仪器噪声混合，现有研究常基于简化假设（如静态或等臂配置），而实际任务中时间变化的臂长会引入复杂性，需要更现实的建模。

Method: 使用模拟的随机引力波背景信号和主要仪器噪声源，比较三种模板策略：1）基于分段数据构建的时间平均模板；2）等臂模板；3）将臂长作为自由参数的模板。

Result: 时间平均模板在时间变化臂长条件下能提高参数估计精度，而将有效臂长作为自由参数会增加估计不确定性。

Conclusion: 对于未来空间引力波任务的高精度随机引力波背景分析，现实的模板构建至关重要，时间平均模板策略优于其他方法。

Abstract: Stochastic gravitational-wave background (SGWB) poses significant challenges for data analysis and parameter inference in future space-based gravitational-wave missions, such as LISA and Taiji, as it appears as an additional stochastic component along with instrumental noise. Previous studies have developed various approaches to distinguish the SGWB from instrumental noise, often under simplified assumptions such as static or equal-arm configurations. However, in realistic scenarios, time-varying arm-lengths introduce additional complexities that require careful modeling. In this work, we investigate the impact of template construction on SGWB parameter estimation under realistic orbital configurations. Using the simulated SGWB signals and dominant instrumental noise sources, we compare three template strategies: time-averaged template constructed from segmented data, equal-arm template, and a template treating the arm-lengths as a free parameter. Our results show that the time-averaged template yield improves parameter estimation accuracy under time-varying arm-lengths, whereas introducing the effective arm-length as a free parameter increases estimation uncertainty. These findings highlight the importance of realistic template construction for high-precision SGWB analysis in future space-based missions.

</details>


### [16] [Radiative process of tripartite entangled probes in inertial motion](https://arxiv.org/abs/2512.08578)
*Subhajit Barman,K. Hari*

Main category: gr-qc

TL;DR: 研究三个处于W态纠缠的量子探针在平坦时空中的辐射过程，分析不同探针配置、运动状态和开关场景对辐射的影响，并扩展到热环境。


<details>
  <summary>Details</summary>
Motivation: 研究三体纠缠量子探针的辐射过程如何受探针配置、运动状态和环境条件的影响，为设计受量子退相干影响最小的实验装置提供指导。

Method: 考虑平坦时空中惯性量子探针，分析静态和匀速运动探针的不同配置，研究不同开关场景，并将分析扩展到热环境。

Result: 辐射过程显著依赖于探针的初始配置和速度方向，不同开关方式、热背景和探针运动都会影响三体纠缠探针的辐射过程。

Conclusion: 通过分析不同因素对辐射过程的影响，可以为设计受量子退相干影响最小的实验装置提供重要指导。

Abstract: We study the radiative process of three entangled quantum probes initially prepared in a tripartite W state. As a basic set-up, we consider the probes to be inertial in flat spacetime and investigate how the radiative process is affected by different probe configurations. We take the quantum probes as either static or moving with uniform velocities and consider different switching scenarios. Our main observation confirms that the radiative process depends distinctively on the initial configuration in which the probes are arranged, as well as on the direction of the probe velocity. We also extend our analysis to a thermal environment, thereby simulating a more realistic background. We thoroughly discuss the effects due to different switchings, the thermal background, and probe motion on the radiative process of these tripartite entangled probes. We also comment on how the observations from this work can help prepare a set-up least affected by quantum decoherence.

</details>


### [17] [Horizon Brightened Acceleration Radiation from Massive Vector Fields](https://arxiv.org/abs/2512.08598)
*Reggie C. Pantig,Ali Övgün*

Main category: gr-qc

TL;DR: 该论文研究了原子自由落入史瓦西黑洞时，在质量自旋-1（Proca）场环境下的加速辐射量子光学处理，揭示了热平衡因子的普适性和Proca场的独特光谱特征。


<details>
  <summary>Details</summary>
Motivation: 研究黑洞附近加速辐射的量子光学特性，特别关注质量自旋-1（Proca）场与标量场的区别，探索纵向与横向响应、质量阈值和极化分辨灰体效应等独特特征。

Method: 基于Scully等人的HBAR框架，采用两种探测器实现：带电单极子电流耦合和物理电偶极耦合，在腔体中隔离单个出射史瓦西模式（Boulware态），使用近地平线稳相分析。

Result: 发现热详细平衡因子具有普适性，仅依赖于近地平线Rindler坐标变换；绝对光谱获得独特的Proca特征：硬质量阈值、极化依赖因子、轴向/极化灰体透射；稳态是几何的，熵通量遵循与标量情况形式相同的HBAR式面积-熵关系。

Conclusion: 该研究为探测加速辐射中的纵向与横向响应、质量阈值和极化分辨灰体效应提供了受控途径，为扩展到旋转背景、替代外部态和探测器工程策略奠定了基础。

Abstract: In this paper, we develop a quantum-optical treatment of acceleration radiation for atoms freely falling into a Schwarzschild black hole when the ambient field is a massive spin-1 (Proca) field. Building on the HBAR framework of Scully and collaborators, we analyze two detector realizations: a charged-monopole current coupling and a physical electric-dipole coupling, both within a cavity that isolates a single outgoing Schwarzschild mode prepared in the Boulware state. Using a near-horizon stationary-phase analysis, we show that the thermal detailed-balance factor governing excitation versus absorption is universal and depends only on the near-horizon Rindler coordinate transformation. At the same time, the absolute spectra acquire distinctive Proca signatures: a hard mass threshold, polarization-dependent prefactors, and axial/polar greybody transmissions. Promoting single-pass probabilities to escaping rates yields a master equation whose steady state is geometric and whose entropy flux obeys an HBAR-style area-entropy relation identical in form to the scalar case, with all vector-field specifics entering through the radiative area change. Our results provide a controlled pathway to probe longitudinal versus transverse responses, mass thresholds, and polarization-resolved greybody effects in acceleration radiation, and set the stage for extensions to rotating backgrounds, alternative exterior states, and detector-engineering strategies.

</details>


### [18] [Quantum particle production and radiative properties of a new bumblebee black hole](https://arxiv.org/abs/2512.08604)
*N. Heidari,A. A. Araújo Filho*

Main category: gr-qc

TL;DR: 研究静态大黄蜂黑洞的量子与辐射特性，包括几何结构、热力学、粒子产生、灰体因子、吸收截面和蒸发寿命


<details>
  <summary>Details</summary>
Motivation: 研究洛伦兹破坏理论中的静态大黄蜂黑洞的量子与辐射特性，探索其与标准黑洞模型的差异

Method: 使用隧穿方法分析玻色子和费米子场的量子粒子产生；推导自旋0、1、2和1/2场的解析灰体边界；采用六阶WKB方法计算完整灰体因子；使用准正规模方法获取灰体因子

Result: 获得了黑洞的几何结构、热力学温度、拓扑结构；推导了各自旋场的灰体边界；计算了吸收截面及其自旋依赖的峰值模式；评估了蒸发寿命和发射率；与多种洛伦兹破坏几何进行了高频区域比较

Conclusion: 全面分析了静态大黄蜂黑洞的量子辐射特性，为洛伦兹破坏理论中的黑洞物理提供了重要见解，揭示了与标准黑洞模型的显著差异

Abstract: In this work, we investigate the quantum and radiative properties of a recently proposed static bumblebee black hole arising from a general Lorentz-violating vacuum configuration. The analysis begins with the geometric structure of the solution and the thermodynamic temperature obtained from the surface-gravity prescription. The associated thermodynamic topological structure is also examined. Quantum particle production is then analyzed for bosonic and fermionic fields using the tunneling method. Analytic greybody bounds are derived for spin-0, spin-1, spin-2, and spin-1/2 fields. Furthermore, full greybody factors are computed with the sixth-order WKB method, together with the corresponding absorption cross sections and their characteristic spin-dependent peak patterns. These results support the evaluation of the evaporation lifetimes and the emission rates of energy and particle modes associated with each spin contribution, followed by a comparison of the high-frequency regime with other Lorentz-violating geometries, including the \textit{metric} bumblebee, \textit{metric-affine} bumblebee, Kalb-Ramond, and non-commutative Kalb-Ramond black holes. In addition, greybody factors are obtained using a quasinormal-mode-based prescription.

</details>


### [19] [Single-field D-type inflation in the minimal supergravity in light of Planck-ACT-SPT data](https://arxiv.org/abs/2512.08760)
*Yermek Aldabergenov,Sergei V. Ketov*

Main category: gr-qc

TL;DR: 应用超引力框架构建新的D型单场暴胀模型，与CMB精确测量数据一致，使用e-folds作为变量简化了分析过程


<details>
  <summary>Details</summary>
Motivation: 构建与Planck、BICEP/Keck、ACT和SPT等实验的宇宙微波背景辐射精确测量数据一致的新暴胀模型，在超引力框架下发展更简单的理论构造

Method: 应用最小超引力框架构建D型单场暴胀模型，使用e-folds作为运行变量简化暴胀势、标量扰动功率谱和宇宙学可观测量分析

Result: 成功构建了与当前CMB精确测量数据一致的新暴胀模型，通过使用e-folds变量使暴胀势、功率谱和重建过程变得非常简单

Conclusion: 最小超引力框架可用于构建与观测数据一致的简单D型单场暴胀模型，e-folds作为变量显著简化了理论分析和重建过程

Abstract: The minimal supergravity framework is applied to a construction of new D-type single-field models of inflation in agreement with precision measurements of the cosmic microwave background radiation by Planck Collaboration, BICEP/Keck Collaboration, Atacama Cosmology Telescope and South Pole Telescope. The inflaton potential, the power spectrum of scalar perturbations, the cosmological observables and the reconstruction procedure can be very simple when using the e-folds as the running variable.

</details>


### [20] [Brachistochrone-ruled timelike surfaces in Newtonian and relativistic spacetimes](https://arxiv.org/abs/2512.08776)
*Ferhat Taş*

Main category: gr-qc

TL;DR: 该论文研究牛顿和相对论时空中由最速降线（brachistochrone）生成的类时曲面，将经典最速降线推广到相对论框架，并给出闵可夫斯基时空和史瓦西时空中的具体构造。


<details>
  <summary>Details</summary>
Motivation: 将经典力学中的最速降线问题推广到相对论时空，研究由时间最小化轨迹生成的类时曲面，探索这类曲面的几何性质及其在广义相对论中的应用。

Method: 1. 从恒定引力场中的经典摆线最速降线出发，构造牛顿框架下的"最速降线生成世界面"；2. 将构造推广到稳态洛伦兹时空，通过将到达时间泛函约化为空间流形上的Finsler或Jacobi型长度泛函；3. 在闵可夫斯基和史瓦西时空中给出具体构造示例；4. 分析这类曲面的基本几何性质并识别沿生成线的自然Jacobi场。

Result: 1. 在闵可夫斯基时空中，对于有界速度时间泛函，最速降线是直线类时线，相应的最速降线生成曲面是完全测地的；2. 在史瓦西时空中，展示了固定能量下的坐标时间最小化可约化为空间切片上的Jacobi度规测地线，并提出了构造最速降线生成类时曲面的数值方案。

Conclusion: 成功将经典最速降线问题推广到相对论框架，建立了最速降线生成类时曲面的系统理论，为研究时空几何和相对论力学提供了新的数学工具和视角。

Abstract: We introduce and study \emph{brachistochrone-ruled timelike surfaces} in Newtonian and relativistic spacetimes. Starting from the classical cycloidal brachistochrone in a constant gravitational field, we construct a Newtonian ``brachistochrone-ruled worldsheet'' whose rulings are time-minimizing trajectories between pairs of endpoints. We then generalize this construction to stationary Lorentzian spacetimes by exploiting the reduction of arrival-time functionals to Finsler- or Jacobi-type length functionals on a spatial manifold. In this framework, relativistic brachistochrones arise as geodesics of an associated Finsler structure, and brachistochrone-ruled timelike surfaces are timelike surfaces ruled by these time-minimizing worldlines. We work out explicit examples in Minkowski spacetime and in the Schwarzschild exterior: in the flat case, for a bounded-speed time functional, the brachistochrones are straight timelike lines and a simple family of brachistochrone-ruled surfaces turns out to be totally geodesic; in the Schwarzschild case, we show how coordinate-time minimization at fixed energy reduces to geodesics of a Jacobi metric on the spatial slice, and outline a numerical scheme for constructing brachistochrone-ruled timelike surfaces. Finally, we discuss basic geometric properties of such surfaces and identify natural Jacobi fields along the rulings.

</details>


### [21] [Geodesic dynamics and multi-inclination images of a non-minimally coupled black hole with a thin accretion disk](https://arxiv.org/abs/2512.08804)
*Tian-Yu Chen,Yong-Zhuang Li,Xiao-Mei Kuang*

Main category: gr-qc

TL;DR: 研究非最小爱因斯坦-杨-米尔斯理论中黑洞的光学性质，分析薄吸积盘照射下的黑洞图像特征，发现非最小耦合参数会减小ISCO和光子球半径，增强红移效应，但降低观测强度。


<details>
  <summary>Details</summary>
Motivation: 探索非最小爱因斯坦-杨-米尔斯理论中黑洞的光学特性，特别是研究非最小耦合参数如何影响黑洞周围的轨道动力学和观测图像，并与史瓦西和Reissner-Nordström黑洞进行比较。

Method: 分析黑洞周围大质量和无质量粒子的轨道动力学，计算ISCO、光子球半径、能量、角动量和碰撞参数，研究薄吸积盘照射下的黑洞图像，考虑不同倾角下的观测强度。

Result: 非最小耦合参数增加会导致ISCO和光子球半径近似线性减小，相应能量和角动量也减小；与史瓦西和Reissner-Nordström黑洞相比，非最小耦合扩展了碰撞参数范围并轻微增强红移效应；但显著降低观测强度。

Conclusion: 非最小爱因斯坦-杨-米尔斯理论中的黑洞具有独特的光学特性，非最小耦合参数对黑洞视界有显著影响，导致观测图像强度较弱，这为区分不同类型黑洞提供了潜在观测特征。

Abstract: In this paper, we investigate the optical properties of a black hole in non-minimal Einstein-Yang-Mills theory, illuminated by a thin accretion disk composed of free, electrically neutral plasma. In our setup, matter follows stable circular orbits outside the innermost stable circular orbit (ISCO), while inside the ISCO, it rapidly plunges into the black hole. We begin by analyzing the orbital dynamics of massive and massless particles around the black hole. Our results indicate that as the non-minimal coupling parameter increases, the radii of both the ISCO and the photon sphere, together with the corresponding energy and angular momentum for massive particles or the impact parameter for photons, decrease approximately linearly. Moreover, compared with the Schwarzschild and Reissner-Nordström black holes, the non-minimal coupling extends the range of the impact parameter and slightly enhances the redshift effect in the images. Additionally, due to the significant influence of the non-minimal coupling parameter on the event horizon, the observed intensity of the non-minimally coupled black hole image under the selected emission model ultimately turns out to be weaker than that of the other two types of black holes, regardless of the inclination angle between the accretion disk and observation planes.

</details>


### [22] [Nonlinear Gravity and Multipole Turbulence](https://arxiv.org/abs/2512.08872)
*A. Ianniccari,A. Kehagias,L. Lo Bianco,A. Riotto*

Main category: gr-qc

TL;DR: 该论文推导了描述闵可夫斯基时空中非线性相互作用引力波多极子湍流动力学长期统计行为的玻尔兹曼方程，并证明注入大量高多极子引力子会导致系统在长时间尺度上形成逆多极子级联。


<details>
  <summary>Details</summary>
Motivation: 研究引力波多极子在非线性相互作用下的湍流动力学长期统计行为，探索引力波系统中可能存在的级联现象。

Method: 推导了描述闵可夫斯基时空中非线性相互作用引力波多极子湍流动力学的玻尔兹曼方程，通过分析注入大量高多极子引力子的情况来研究系统的长期行为。

Result: 当注入大量高多极子引力子时，系统在长时间尺度上会形成逆多极子级联，即能量从高多极子向低多极子转移。

Conclusion: 引力波多极子系统在非线性相互作用下会表现出逆级联现象，这为理解引力波湍流动力学提供了新的理论框架。

Abstract: We derive a kinetic Boltzmann equation characterizing the long-term statistical behavior of the turbulent dynamics of nonlinear interacting gravitational wave multipoles in Minkowski spacetime and show that, injecting a large number of gravitons with large multipoles drives the system toward an inverse multipole cascade at large times.

</details>


### [23] [Regular black hole sourced by the Dehnen-type distribution of matter: The sound of the event horizon](https://arxiv.org/abs/2512.08904)
*Erdinç Ulaş Saka*

Main category: gr-qc

TL;DR: 研究计算了由Dehnen型物质晕支撑的规则、渐近平坦黑洞的基本和泛音准正规模，发现晕参数a打破了真空中的等谱性，但对准正规谱的影响相对温和。


<details>
  <summary>Details</summary>
Motivation: 研究暗物质晕对黑洞准正规模的影响，探索暗物质晕是否会引起类似量子修正或奇异致密天体的强近地平效应。

Method: 计算Dehnen型物质晕支撑的渐近平坦黑洞的引力扰动，将扰动分为两个不同的轴向扇区，分析晕参数a对准正规谱的影响。

Result: 晕参数a打破了真空中的等谱性，但对基本模的影响中等，对泛音的影响更弱；随着晕参数增加，泛音在复频率平面上相互接近；未观察到泛音振幅增强或快速增长。

Conclusion: 暗物质晕对黑洞准正规模的影响是可控且相对温和的，保持了环降谱的定性结构，不会引起量子修正或奇异致密天体特有的强近地平效应。

Abstract: We compute the fundamental and overtone quasinormal modes of a regular, asymptotically flat black hole supported by a Dehnen-type matter halo. Gravitational perturbations in this background split into two distinct axial sectors, and our analysis confirms that the presence of the halo parameter $a$ breaks the isospectrality that holds in vacuum. The dependence of the quasinormal spectrum on $a$ is moderate for the fundamental modes and even weaker for the overtones, which approach one another in the complex-frequency plane as the halo parameter increases. No enhancement or rapid growth of overtone amplitudes is observed, indicating that the halo does not induce the type of strong near-horizon effects characteristic of quantum-corrected or exotic compact objects. Overall, our results show that the dark-matter halo introduces controlled and comparatively mild modifications to the ringdown spectrum while preserving its qualitative structure.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [24] [Quantum Circuit Reasoning Models: A Variational Framework for Differentiable Logical Inference](https://arxiv.org/abs/2512.07871)
*Andrew Kiruluta*

Main category: quant-ph

TL;DR: 提出量子电路推理模型(QCRM)，将变分量子电路从能量最小化和分类任务扩展到结构化逻辑推理，利用量子力学操作映射推理原语，实现可微分的量子启发式计算框架。


<details>
  <summary>Details</summary>
Motivation: 现有变分量子电路主要应用于能量最小化和分类任务，缺乏对结构化逻辑推理的支持。量子力学的基本操作（叠加、纠缠、干涉、测量）与推理原语（假设分支、约束传播、一致性执行、决策制定）存在自然映射关系，这为构建量子启发的推理模型提供了理论基础。

Method: 开发QCRM的数学基础，定义参数化电路架构，将逻辑规则编码为命题量子比特状态上的幺正变换。通过基于经典梯度下降的训练目标优化电路参数，并在经典硬件上实现仿真。提出量子推理层(QRL)作为可微分的混合组件，用于构建可组合的推理模型。

Result: 建立了将量子力学操作映射到推理原语的数学框架，实现了逻辑规则到幺正变换的编码方法，设计了可微分的训练方案，并提出了可应用于科学、生物医学和化学推理领域的可组合推理架构。

Conclusion: QCRM成功将变分量子电路扩展到结构化推理领域，通过量子启发式计算与可微分优化的结合，使推理过程表现为振幅演化和干涉驱动的自洽状态选择。量子推理层为构建混合推理系统提供了新范式。

Abstract: This report introduces a novel class of reasoning architectures, termed Quantum Circuit Reasoning Models (QCRM), which extend the concept of Variational Quantum Circuits (VQC) from energy minimization and classification tasks to structured logical inference and reasoning. We posit that fundamental quantum mechanical operations, superposition, entanglement, interference, and measurement, naturally map to essential reasoning primitives such as hypothesis branching, constraint propagation, consistency enforcement, and decision making. The resulting framework combines quantum-inspired computation with differentiable optimization, enabling reasoning to emerge as a process of amplitude evolution and interference-driven selection of self-consistent states. We develop the mathematical foundation of QCRM, define its parameterized circuit architecture, and show how logical rules can be encoded as unitary transformations over proposition-qubit states. We further formalize a training objective grounded in classical gradient descent over circuit parameters and discuss simulation-based implementations on classical hardware. Finally, we propose the Quantum Reasoning Layer (QRL) as a differentiable hybrid component for composable reasoning models applicable to scientific, biomedical, and chemical inference domains.

</details>


### [25] [The State-Operator Clifford Compatibility: A Real Algebraic Framework for Quantum Information](https://arxiv.org/abs/2512.07902)
*Kagwe A. Muchane*

Main category: quant-ph

TL;DR: 提出基于实数克利福德代数Cℓ₂,₀(ℝ)⊗N的N量子比特计算框架，通过双向量J提供复结构，泡利运算作为克利福德元素的左作用，计算基态表示为实数代数幂等元的张量积。


<details>
  <summary>Details</summary>
Motivation: 重新审视泡利-克利福德联系，建立实数、保持分级的代数框架，将N量子比特量子计算与克利福德代数结构统一起来，实现符号乘法与希尔伯特空间酉演化的对齐。

Method: 采用Cℓ₂,₀(ℝ)⊗N张量积结构，双向量J=e₁₂满足J²=-1，通过右乘在最小左理想上提供复结构；泡利运算作为克利福德元素的左作用；通过规范稳定子映射将计算基态表示为实数代数幂等元的张量积。

Result: 建立了状态-算子克利福德兼容性定律，该定律在N量子比特的几何积下稳定，使符号克利福德乘法与希尔伯特空间上的酉演化保持一致。

Conclusion: 该实数代数框架为N量子比特量子计算提供了统一的数学基础，将泡利运算、克利福德运算和酉演化在代数结构上自然统一，简化了量子计算的数学表示。

Abstract: We revisit the Pauli-Clifford connection to introduce a real, grade-preserving algebraic framework for $N$-qubit quantum computation based on the tensor product structure $C\ell_{2,0}(\mathbb{R})^{\otimes N}$. In this setting the bivector $J = e_{12}$ satisfies $J^{2} = -1$ and supplies the complex structure on a minimal left ideal via right-multiplication, while Pauli operations arise as left actions of suitable Clifford elements. Adopting a canonical stabilizer mapping, the $N$-qubit computational basis state $|0\cdots 0\rangle$ is represented natively by a tensor product of real algebraic idempotents. This structural choice leads to a State-Operator Clifford Compatibility law that is stable under the geometric product for $N$ qubits and aligns symbolic Clifford multiplication with unitary evolution on the Hilbert space.

</details>


### [26] [Quantum catalysis-enhanced extract energy in qubit quantum battery](https://arxiv.org/abs/2512.07906)
*Shun-Cai Zhao*

Main category: quant-ph

TL;DR: 量子催化通过诱导瞬态负热流（能量回流）来增强量子电池性能，这种回流能主动对抗退相干损耗，将量子比特快速推入非被动态，从而大幅提升可提取功


<details>
  <summary>Details</summary>
Motivation: 探究在开放系统中量子催化提升量子电池性能的物理机制，特别是理解催化剂如何通过热力学过程增强电池性能

Method: 研究外部场驱动的量子比特电池与谐振子催化剂的耦合系统，利用量子第一定律精确量化负热流与电池性能增强之间的因果关系

Result: 发现催化剂诱导的瞬态负热流（J(t)<0，能量回流）能主动对抗退相干损耗，快速将量子比特推入非被动态，从而大幅提升可提取功（Ergotropy）

Conclusion: 揭示了瞬态热力学回流在量子催化中的基本作用，为高性能量子能量存储设备提供了关键蓝图

Abstract: What physical mechanism enables quantum catalysis to boost quantum battery (QB) performance in open systems? We investigate an external-field-driven qubit QB coupled to a harmonic oscillator catalyst, revealing a key thermodynamic mechanism: the catalyst induces transient negative heat flow ($J(t)<0$, or energy backflow) into the battery. This backflow actively counters dephasing losses, rapidly pushing the qubit into non-passive states, and results in a drastic enhancement of extractable work (Ergotropy). Leveraging the quantum first law, we precisely quantify this causal link between negative heat flux and QB performance enhancement. Our work uncovers the fundamental role of transient thermodynamic backflow in quantum catalysis, offering a crucial blueprint for high-performance quantum energy storage devices.

</details>


### [27] [Symmetry-Based Quantum Codes Beyond the Pauli Group](https://arxiv.org/abs/2512.07908)
*Zachary P. Bradshaw,Margarite L. LaBorde,Dillon Montero*

Main category: quant-ph

TL;DR: 提出一个基于群表示的量子纠错码通用框架，将对称性纳入编码设计，推广了稳定子码并实现被动纠错


<details>
  <summary>Details</summary>
Motivation: 传统稳定子码不考虑具体系统的结构，本文旨在提供一个能利用系统对称性的通用纠错框架

Method: 为任意有限群的表示构造量子码，码空间在群作用下不变，通过不可约表示的同型分量投影测量实现错误检测

Result: 证明所有稳定子码（包括qudit码）都是该框架的特例，并构造了二面体群的单逻辑量子比特码

Conclusion: 提供了一个统一现有码并支持针对特定系统对称性设计定制化量子纠错码的通用框架

Abstract: Typical stabilizer codes aim to solve the general problem of fault-tolerance without regard for the structure of a specific system. By incorporating a broader representation-theoretic perspective, we provide a generalized framework that allows the code designer to take this structure into account. For any representation of a finite group, we produce a quantum code with a code space invariant under the group action, providing passive error mitigation against errors belonging to the image of the representation. Furthermore, errors outside this scope are detected and diagnosed by performing a projective measurement onto the isotypic components corresponding to irreducible representations of the chosen group, effectively generalizing syndrome extraction to symmetry-resolved quantum measurements. We show that all stabilizer codes are a special case of this construction, including qudit stabilizer codes, and show that there is a natural one logical qubit code associated to the dihedral group. Thus we provide a unifying framework for existing codes while simultaneously facilitating symmetry-aware codes tailored to specific systems.

</details>


### [28] [Fair Benchmarking of Optimisation Applications](https://arxiv.org/abs/2512.07915)
*Frank Phillipson*

Main category: quant-ph

TL;DR: 该论文提出了量子优化公平基准测试的原则和协议，强调端到端工作流程、调优透明度、问题多样性，避免推测性声明，以负责任地评估量子方法。


<details>
  <summary>Details</summary>
Motivation: 量子优化作为一种新兴方法，其性能评估缺乏公平标准。传统基准测试方法基于数字复杂性理论，无法直接捕捉量子系统的连续动态、概率结果和工作流程开销，需要建立更合适的评估框架。

Method: 提出量子优化公平基准测试的原则和协议，包括：端到端工作流程评估、调优和报告的透明度、问题多样性、避免推测性声明。借鉴经典基准测试经验，结合应用驱动和能源感知指标。

Result: 构建了一个框架，使从业者能够负责任地评估量子方法，确保报告结果的可重复性、可比性和可信度。

Conclusion: 通过建立公平的基准测试原则和协议，可以促进量子优化领域的健康发展，确保评估的客观性和可靠性。

Abstract: Quantum optimisation is emerging as a promising approach alongside classical heuristics and specialised hardware, yet its performance is often difficult to assess fairly. Traditional benchmarking methods, rooted in digital complexity theory, do not directly capture the continuous dynamics, probabilistic outcomes, and workflow overheads of quantum and hybrid systems. This paper proposes principles and protocols for fair benchmarking of quantum optimisation, emphasising end-to-end workflows, transparency in tuning and reporting, problem diversity, and avoidance of speculative claims. By extending lessons from classical benchmarking and incorporating application-driven and energy-aware metrics, we outline a framework that enables practitioners to evaluate quantum methods responsibly, ensuring reproducibility, comparability, and trust in reported results.

</details>


### [29] [Quantum computing of nonlinear reacting flows via the probability density function method](https://arxiv.org/abs/2512.07918)
*Jizhi Zhang,Ziang Yang,Zhaoyuan Meng,Zhen Lu,Yue Yang*

Main category: quant-ph

TL;DR: 提出量子计算框架处理非线性反应流，通过PDF方法将非线性方程转化为高维线性方程，利用历史状态方法一次性求解整个时间演化，避免传统时间步进方案的测量瓶颈，实现近指数级加速。


<details>
  <summary>Details</summary>
Motivation: 量子计算在科学计算中具有加速潜力，但应用于反应流时面临非线性源项和时变模拟的挑战。需要开发新框架来克服这些障碍，充分发挥量子计算的优势。

Method: 采用概率密度函数(PDF)方法将非线性反应流控制方程转化为高维线性方程；使用历史状态方法将整个时间演化作为单一大型线性系统求解；开发高效算法测量PDF的统计矩，避免昂贵的全状态层析。

Result: 计算复杂度分析显示相对于经典算法具有近指数级加速潜力；通过完美搅拌反应器模拟验证了框架的有效性，能够捕捉非线性反应系统的PDF演化和统计特性。

Conclusion: 该工作为量子计算应用于非线性反应流建立了可行路径，解决了非线性源项和时变模拟的挑战，展示了量子计算在复杂流体模拟中的潜力。

Abstract: Quantum computing offers the promise of speedups for scientific computations, but its application to reacting flows is hindered by nonlinear source terms and the challenges of time-dependent simulations. We present a quantum framework to address these issues. We employ a probability density function (PDF) formulation to transform the nonlinear reacting-flow governing equations into high-dimensional linear ones. The entire temporal evolution is then solved as a single large linear system using the history state method, which avoids the measurement bottleneck of conventional time-marching schemes and fully leverages the advantages of quantum linear system algorithms. To extract the quantity of interest from the resulting quantum state, we develop an efficient algorithm to measure the statistical moments of the PDF, bypassing the need for costly full-state tomography. A computational complexity analysis indicates the potential for a near-exponential speedup over classical algorithms. We validate the framework by simulating a perfectly stirred reactor, demonstrating its capability to capture the PDF evolution and statistics of a nonlinear reactive system. This work establishes a pathway for applying quantum computing to nonlinear reacting flows.

</details>


### [30] [Quantum algorithms for viscosity solutions to nonlinear Hamilton-Jacobi equations based on an entropy penalisation method](https://arxiv.org/abs/2512.07919)
*Shi Jin,Nana Liu*

Main category: quant-ph

TL;DR: 提出一个基于熵惩罚方法的量子算法框架，用于高效提取凸哈密顿量的非线性Hamilton-Jacobi方程的粘性解，适用于任意凸非线性且任意长时间，避免了传统量子算法的主要障碍。


<details>
  <summary>Details</summary>
Motivation: 非线性Hamilton-Jacobi方程的粘性解在波前传播、平均场博弈、最优控制、机器学习等领域具有核心应用，但传统量子算法在处理非线性PDE时面临主要障碍，需要新的方法。

Method: 基于Gomes和Valdinoci提出的熵惩罚方法，将凸哈密顿量的粘性Hamilton-Jacobi动力学重新表述为离散时间线性动力学，近似于线性热类抛物方程，适用于量子模拟。

Result: 开发了模拟和数字量子算法，能够提取粘性解的点值、梯度、最小值以及在最小化器处的函数评估，无需非线性更新或完整状态重构。

Conclusion: 该框架为凸哈密顿量的非线性Hamilton-Jacobi方程提供了高效的量子算法，克服了传统量子算法的主要限制，适用于任意凸非线性和任意长时间尺度。

Abstract: We present a framework for efficient extraction of the viscosity solutions of nonlinear Hamilton-Jacobi equations with convex Hamiltonians. These viscosity solutions play a central role in areas such as front propagation, mean-field games, optimal control, machine learning, and a direct application to the forced Burgers' equation. Our method is based on an entropy penalisation method proposed by Gomes and Valdinoci, which generalises the Cole-Hopf transform from quadratic to general convex Hamiltonians, allowing a reformulation of viscous Hamilton-Jacobi dynamics by a discrete-time linear dynamics which approximates a linear heat-like parabolic equation, and can also extend to continuous-time dynamics. This makes the method suitable for quantum simulation. The validity of these results hold for arbitrary nonlinearity that correspond to convex Hamiltonians, and for arbitrarily long times, thus obviating a chief obstacle in most quantum algorithms for nonlinear partial differential equations. We provide quantum algorithms, both analog and digital, for extracting pointwise values, gradients, minima, and function evaluations at the minimiser of the viscosity solution, without requiring nonlinear updates or full state reconstruction.

</details>


### [31] [Exchange Symmetry in Multiphoton Quantum Interference](https://arxiv.org/abs/2512.07953)
*Shreya Kumar,Alex E Jones,Daniel Bhatti,Stefanie Barz*

Main category: quant-ph

TL;DR: 三光子纠缠态展现丰富的交换对称性，可实现光子对的不同统计性质（玻色、费米、任意子），并能通过调节对称性控制多光子干涉


<details>
  <summary>Details</summary>
Motivation: 虽然双光子系统中已观察到非玻色行为，但多光子场景下的交换对称性和干涉效应仍未被充分探索。研究多光子态的对称性有助于深入理解量子系统，并对依赖量子干涉的量子技术有重要意义

Method: 通过实验研究三光子态的交换对称性，探索光子对的不同组合方式（玻色、费米、任意子对称），并观察这些对称配置如何体现在三光子干涉中

Result: 发现三光子态展现出丰富的交换对称性景观，光子对可呈现不同统计性质。实验证明可以通过调节组成光子对的对称性来有效开启和关闭多光子干涉

Conclusion: 在可扩展的光子平台上访问和调节新的量子统计不仅加深了对量子系统的理解，而且对依赖量子干涉的量子技术具有高度相关性。多光子态为探索混合对称系统提供了新的可能性

Abstract: Photons are bosons, and yet, when prepared in specific entangled states, they can exhibit non-bosonic behaviour. While this phenomenon has so far been studied in two-photon systems, exchange symmetries and interference effects in multi-photon scenarios remain largely unexplored. In this work, we show that multi-photon states uncover a rich landscape of exchange symmetries. With three photons already, multiple pairwise combinations are possible, where each pair of photons can exhibit either bosonic, fermionic, or anyonic exchange symmetry. This gives rise to mixed symmetry systems that are not possible to achieve with two photon alone. We experimentally investigate how these symmetry configurations manifest themselves in the observed interference of three photons. We show that multi-photon interference can be effectively turned on and off by tuning the symmetry of the constituent pairs. The possibility of accessing and tuning new quantum statistics in a scalable photonic platform not only deepens our understanding of quantum systems, but is also highly relevant for quantum technologies that rely on quantum interference.

</details>


### [32] [Coherence-limited digital control of a superconducting qubit using a Josephson pulse generator at 3 K](https://arxiv.org/abs/2512.07962)
*M. A. Castellanos-Beltran,A. J. Sirois,L. Howe,D. I. Olaya,J. Biesecker,S. P. Benz,P. F. Hopkins*

Main category: quant-ph

TL;DR: 本文展示了在3K温度下使用约瑟夫森脉冲发生器(JPG)控制超导量子比特的性能，与传统室温半导体控制电子学(TSCE)相比，在量子比特寿命、相干时间和门保真度方面表现相当，单量子比特门平均错误率0.46%，比之前工作提高了一个数量级。


<details>
  <summary>Details</summary>
Motivation: 传统室温半导体控制电子学(TSCE)在量子处理器可扩展性方面存在限制。虽然单磁通量子(SFQ)电子学提供了低温控制方案，但之前将SFQ电路与量子比特共置的实验会导致退相干和损耗问题。本研究旨在开发适用于可扩展2D transmon器件的优化控制方案。

Method: 将约瑟夫森脉冲发生器(JPG)电路放置在稀释制冷机的3K阶段，避免与量子比特共置导致的退相干问题。优化了量子比特设计和控制线路，专门针对可扩展的2D transmon器件。通过直接比较JPG控制与传统TSCE设置下的量子比特性能参数。

Result: JPG控制与传统TSCE在量子比特寿命T1和相干时间T2*上达到日内波动范围内的一致，随机基准测试结果在10%内一致。单量子比特门平均错误率为0.46%，与基于量子比特相干性和高态泄漏的预期相符，比之前工作提高了一个数量级。

Conclusion: 在3K温度下运行的约瑟夫森微波源是实现可扩展量子比特控制的有前景组件，其性能与传统室温控制电子学相当，同时解决了可扩展性问题，为大规模量子处理器的发展提供了重要技术路径。

Abstract: Compared to traditional semiconductor control electronics (TSCE) located at room temperature, cryogenic single flux quantum (SFQ) electronics can provide qubit measurement and control alternatives that address critical issues related to scalability of cryogenic quantum processors. Single-qubit control and readout have been demonstrated recently using SFQ circuits coupled to superconducting qubits. Experiments where the SFQ electronics are co-located with the qubit have suffered from excess decoherence and loss due to quasiparticle poisoning of the qubit. A previous experiment by our group showed that moving the control electronics to the 3 K stage of the dilution refrigerator avoided this source of decoherence in a high-coherence 3D transmon geometry. In this paper, we also generate the pulses at the 3 K stage but have optimized the qubit design and control lines for scalable 2D transmon devices. We directly compare the qubit lifetime $T_1$, coherence time $T_2^*$ and gate fidelity when the qubit is controlled by the Josephson pulse generator (JPG) circuit versus the TSCE setup. We find agreement to within the daily fluctuations for $T_1$ and $T_2^*$, and agreement to within 10% for randomized benchmarking. We also performed interleaved randomized benchmarking on individual JPG gates demonstrating an average error per gate of $0.46$% showing good agreement with what is expected based on the qubit coherence and higher-state leakage. These results are an order of magnitude improvement in gate fidelity over our previous work and demonstrate that a Josephson microwave source operated at 3 K is a promising component for scalable qubit control.

</details>


### [33] [Measurement-and Feedback-Driven Non-Equilibrium Phase Transitions on a Quantum Processor](https://arxiv.org/abs/2512.07966)
*Zhiyi Wu,Xuandong Sun,Songlei Wang,Jiawei Zhang,Xiaohan Yang,Ji Chu,Jingjing Niu,Youpeng Zhong,Xiao Chen,Zhi-Cheng Yang,Dapeng Yu*

Main category: quant-ph

TL;DR: 该研究开发了具有高保真度全局中电路测量和快速反馈的超导量子处理器，实验观测到量子信道中的吸收态相变和量子轨迹层面的测量诱导纠缠相变，两者发生在不同的调控参数值处。


<details>
  <summary>Details</summary>
Motivation: 中电路测量和基于测量结果的反馈操作对于量子纠错至关重要，在量子多体动力学中能产生新的非平衡相变。然而，现有设备在保真度和实时反馈延迟方面的限制使得同时观测量子轨迹层面和平均量子信道层面的相变具有挑战性。

Method: 开发了新型超导量子处理器，实现了平均98.7%量子非破坏性保真度的全局中电路测量，以及200纳秒实时决策延迟的快速条件反馈。利用该平台研究自适应量子电路中的非平衡量子多体动力学。

Result: 实验观测到量子信道中的吸收态相变和量子轨迹层面的测量诱导纠缠相变共存。吸收态相变的临界指数与定向渗流普适类高度一致。重要的是，这两个相变发生在不同的调控参数值处。

Conclusion: 自适应量子电路为探索非平衡量子多体动力学提供了强大平台，实验验证了量子信道层面和量子轨迹层面相变的共存现象，为量子纠错和量子信息处理提供了重要基础。

Abstract: Mid-circuit measurements and feedback operations conditioned on the measurement outcomes are essential for implementing quantum error-correction on quantum hardware. When integrated in quantum many-body dynamics, they can give rise to novel non-equilibrium phase transitions both at the level of each individual quantum trajectory and the averaged quantum channel. Experimentally resolving both transitions on realistic devices has been challenging due to limitations on the fidelity and the significant latency for performing mid-circuit measurements and feedback operations in real time. Here, we develop a superconducting quantum processor that enables global mid-circuit measurement with an average quantum non-demolition (QND) fidelity of 98.7% and fast conditional feedback with a 200 ns real-time decision latency. Using this platform, we demonstrate the coexistence of an absorbing-state transition in the quantum channel and a measurement-induced entanglement transition at the level of individual quantum trajectories. For the absorbing-state transition, we experimentally extract a set of critical exponents at the transition point, which is in excellent agreement with the directed percolation universality class. Crucially, the two transitions occur at distinct values of the tuning parameter. Our results demonstrate that adaptive quantum circuits provide a powerful platform for exploring non-equilibrium quantum many-body dynamics.

</details>


### [34] [Information-Theoretic Analysis of Weak Measurements and Their Reversal](https://arxiv.org/abs/2512.08015)
*Luis D. Zambrano Palma,Yusef Maleki,M. Suhail Zubairy*

Main category: quant-ph

TL;DR: 该论文研究了零结果弱测量中信息提取的权衡关系，通过信息论量（香农熵、互信息、保真度、相对熵）量化弱测量过程中随时间变化的信息获取量和速率。


<details>
  <summary>Details</summary>
Motivation: 研究量子系统在零结果弱测量下的信息提取权衡关系，其中未检测到光子的情况会连续更新系统状态，需要理解这种弱测量过程中的信息提取动力学特性。

Method: 开发了零结果弱测量的动力学表征框架，通过分析信息论量（香农熵、互信息、保真度、相对熵）的时间演化来量化信息提取过程，详细研究了量子比特、量子三能级系统，并扩展到多能级量子系统的一般框架。

Result: 获得了弱测量过程的动力学表征，能够量化随时间变化的信息获取量和信息积累速率，揭示了弱测量过程中信息提取和可逆性的动力学本质。

Conclusion: 该研究提供了弱测量过程的信息论分析，突出了信息提取的动力学特性和弱测量过程中的可逆性，为理解量子测量中的信息提取权衡关系提供了理论框架。

Abstract: We study trade-off relations in information extraction from quantum systems subject to null-result weak measurements, where the absence of a detected photon continuously updates the system state. We present a detailed analysis of qubit and qutrit systems and investigate a general framework for a multilevel quantum system. We develop a dynamical characterization of null-result weak measurements that quantifies the information extracted over time, revealing the amount of the obtained information and also the rate of the information accumulation. The characterizations are obtained by examining the time-dependent evolution of the information theoretic quantities. More specifically, we consider Shannon entropy, mutual information, fidelity, and relative entropy to characterize the weak measurement dynamics. Our results provide an information theoretic analysis of the weak measurement process and highlight the dynamical nature of information extraction and reversibility in the weak measurement processes.

</details>


### [35] [Classical and quantum dynamics of a particle confined in a paraboloidal cavity](https://arxiv.org/abs/2512.08021)
*Ángel E. Reyna-Cruz,Julio C. Gutiérrez-Vega*

Main category: quant-ph

TL;DR: 该论文研究了三维抛物面腔中粒子的经典和量子行为，发现系统可积且存在三种运动常数，推导了闭合轨迹条件和量子能谱，建立了经典轨迹与量子本征态的对应关系。


<details>
  <summary>Details</summary>
Motivation: 研究三维抛物面腔中粒子的经典和量子行为，探索这种特殊几何形状对粒子动力学和量子特性的影响，特别是抛物面几何带来的独特运动常数和量子简并性。

Method: 采用经典力学和量子力学相结合的方法：经典方面分析哈密顿-雅可比方程的可分性，推导运动常数和闭合轨迹条件；量子方面利用抛物坐标系求解薛定谔方程，得到用Whittaker函数描述的本征模。

Result: 发现系统可积且有三个独立运动常数；推导出闭合轨迹的解析条件和分类指标(s,t,ℓ)；确定了量子能谱和简并性，揭示了经典轨迹与量子本征态概率密度分布的直接对应关系。

Conclusion: 三维抛物面腔中的粒子系统具有丰富的经典和量子特性，抛物面几何不仅提供了额外的运动常数，还导致独特的量子简并性，经典轨迹与量子态之间存在明确的对应关系。

Abstract: We present a classical and quantum analysis of a particle confined in a three-dimensional paraboloidal cavity formed by two confocal paraboloids. Classically, the system is integrable and presents three independent constants of motion, namely, the energy, the $z$-component of the angular momentum, and a third dynamical constant associated with the paraboloidal geometry, which can be derived from the separability of the Hamilton--Jacobi equation. We derive closed-form analytical expressions for the actions, which allow us to determine the two conditions to get periodic closed trajectories. We classify these trajectories through the indices $(s,t,\ell)$. The caustic paraboloids that bound the motion provide a complete geometric characterization of admissible trajectories. Quantum mechanically, separability of the Schrödinger equation in parabolic coordinates yields eigenmodes described by Whittaker functions. We determine the energy spectrum and identify degeneracies arising not only from azimuthal symmetry but also from specific cavity deformations. A direct correspondence between classical trajectories and quantum eigenstates reveals that probability densities concentrate in the classically allowed region with controlled penetration into forbidden zones.

</details>


### [36] [F2: Offline Reinforcement Learning for Hamiltonian Simulation via Free-Fermionic Subroutine Compilation](https://arxiv.org/abs/2512.08023)
*Ethan Decker,Christopher Watson,Junyu Zhou,Yuhao Liu,Chenxu Liu,Ang Li,Gushu Li,Samuel Stein*

Main category: quant-ph

TL;DR: F2是一个利用离线强化学习框架，通过利用自由费米子结构来高效编译基于Trotter的哈密顿量模拟电路的量子编译方法，相比基线平均减少47%门数和38%电路深度。


<details>
  <summary>Details</summary>
Motivation: 由于硬件限制和最小化门数和电路深度的组合复杂性，编译浅层且精确的哈密顿量模拟量子电路仍然具有挑战性。现有优化方法依赖于手工设计的经典启发式方法，无法学习输入相关的结构，因此错失了大幅减少电路的机会。

Method: F2是一个离线强化学习框架，包含：(1) 基于经典可模拟的自由费米子子程序的强化学习环境；(2) 稳定长时域价值学习的架构和目标级归纳偏置；(3) 可逆合成轨迹生成机制，持续产生丰富且保证成功的离线数据。

Result: 在涵盖晶格模型、蛋白质片段和晶体材料（12-222量子比特）的基准测试中，F2相比强基线（Qiskit, Cirq/OpenFermion）平均减少47%的门数和38%的电路深度，同时保持平均误差为10^-7。

Conclusion: 将深度强化学习与量子动力学的代数结构对齐，能够在电路合成方面实现实质性改进，为可扩展的、基于学习的量子编译提供了一个有前景的方向。

Abstract: Compiling shallow and accurate quantum circuits for Hamiltonian simulation remains challenging due to hardware constraints and the combinatorial complexity of minimizing gate count and circuit depth. Existing optimization method pipelines rely on hand-engineered classical heuristics, which cannot learn input-dependent structure and therefore miss substantial opportunities for circuit reduction.
  We introduce \textbf{F2}, an offline reinforcement learning framework that exploits free-fermionic structure to efficiently compile Trotter-based Hamiltonian simulation circuits. F2 provides (i) a reinforcement-learning environment over classically simulatable free-fermionic subroutines, (ii) architectural and objective-level inductive biases that stabilize long-horizon value learning, and (iii) a reversible synthetic-trajectory generation mechanism that consistently yields abundant, guaranteed-successful offline data.
  Across benchmarks spanning lattice models, protein fragments, and crystalline materials (12-222 qubits), F2 reduces gate count by 47\% and depth by 38\% on average relative to strong baselines (Qiskit, Cirq/OpenFermion) while maintaining average errors of $10^{-7}$. These results show that aligning deep reinforcement learning with the algebraic structure of quantum dynamics enables substantial improvements in circuit synthesis, suggesting a promising direction for scalable, learning-based quantum compilation

</details>


### [37] [Observation of a Topological Berry Phase with a Single Phonon in an Ion Microtrap Array](https://arxiv.org/abs/2512.08037)
*Justin F. Niedermeyer,Nathan K. Lysne,Katherine C. McCormick,Jonas Keller,Craig W. Hogle,Matthew G. Blain,Roman Schmied,Robert Jördens,Susanna L. Todaro,David J. Wineland,Andrew C. Wilson,Daniel H. Slichter,Dietrich Leibfried*

Main category: quant-ph

TL;DR: 研究人员演示了在二维离子阵列中实现单个声子的拓扑Berry相位，通过精确控制每个离子的局域势阱来耦合和解耦运动模式。


<details>
  <summary>Details</summary>
Motivation: 传统离子阱系统中，离子运动模式强耦合限制了系统的灵活性和可调性，需要开发能够精确控制单个离子运动的新平台来研究量子多体效应。

Method: 使用二维离子阵列，每个离子在单独的势阱中，通过调节每个离子的局域约束势来可控地耦合和解耦运动模式，在等边三角形顶点上实现声子的相干共享。

Result: 成功演示了单个声子在2-3个离子间的相干共享，观测到拓扑Berry相位（当在构型空间中环绕锥形交叉时），并通过单声子干涉测量该相位。

Conclusion: 精确的单个离子运动量子控制在二维阵列中为研究量子多体效应提供了独特途径，展示了拓扑量子现象的可控实现。

Abstract: Controlled quantum mechanical motion of trapped atomic ions can be used to simulate and explore collective quantum phenomena and to process quantum information. Groups of cold atomic ions in an externally applied trapping potential self-organize into "Coulomb crystals" due to their mutual electrostatic repulsion. The motion of the ions in these crystals is strongly coupled, and the eigenmodes of motion all involve multiple ions. While this enables studies of many-body physics, it limits the flexibility and tunability of the system as a quantum platform. Here, we demonstrate an array of trapped ions in individual trapping sites whose motional modes can be controllably coupled and decoupled by tuning the local applied confining potential for each ion. We show that a single motional quantum, or phonon, can be coherently shared among two or three ions confined at the vertices of an equilateral triangle 30 $μ$m on a side. We can adiabatically tune the ion participation in the motional modes around a closed contour in configuration space, observing that the single-phonon wavefunction acquires a topological Berry phase if the contour encircles a conical intersection of motional eigenvalue surfaces. We observe this phase by single-phonon interference and study its breakdown as the motional mode tuning becomes non-adiabiatic. Our results show that precise, individual quantum control of ion motion in a two-dimensional array can provide unique access to quantum multi-body effects.

</details>


### [38] [Coherent and compact van der Waals transmon qubits](https://arxiv.org/abs/2512.08059)
*Jesse Balgley,Jinho Park,Xuanjing Chu,Jiru Liu,Madisen Holbrook,Kenji Watanabe,Takashi Taniguchi,Archana Kamal,Leonardo Ranzani,Martin V. Gustafsson,James Hone,Kin Chung Fong*

Main category: quant-ph

TL;DR: 首次实现全范德华材料超导量子比特，展示微秒级相干时间，证明范德华材料作为紧凑型超导量子器件平台的可行性


<details>
  <summary>Details</summary>
Motivation: 传统超导量子比特材料选择有限，范德华材料提供高度模块化的晶体平台，可扩展材料组合、引入新功能，但尚不清楚全范德华超导量子比特能否支持量子相干性

Method: 使用全范德华约瑟夫森结构建合并元件transmon量子比特，无需外部分流电容器，通过能量弛豫测量和微波表征分析损耗机制

Result: 第一代全晶体量子比特在超紧凑尺寸下实现微秒级寿命，介电损耗是主要弛豫通道，范德华材料被确立为可行的超导量子器件平台

Conclusion: 范德华材料为紧凑型超导量子器件提供了可行平台，支持量子相干性，介电损耗是主要限制因素，为未来材料探索和性能优化奠定了基础

Abstract: State-of-the-art superconducting qubits rely on a limited set of thin-film materials. Expanding their materials palette can improve performance, extend operating regimes, and introduce new functionalities, but conventional thin-film fabrication hinders systematic exploration of new material combinations. Van der Waals (vdW) materials offer a highly modular crystalline platform that facilitates such exploration while enabling gate-tunability, higher-temperature operation, and compact qubit geometries. Yet it remains unknown whether a fully vdW superconducting qubit can support quantum coherence and what mechanisms dominate loss at both low and elevated temperatures in such a device. Here we demonstrate quantum-coherent merged-element transmons made entirely from vdW Josephson junctions. These first-generation, fully crystalline qubits achieve microsecond lifetimes in an ultra-compact footprint without external shunt capacitors. Energy relaxation measurements, together with microwave characterization of vdW capacitors, point to dielectric loss as the dominant relaxation channel up to hundreds of millikelvin. These results establish vdW materials as a viable platform for compact superconducting quantum devices.

</details>


### [39] [On Dirac-type correlations](https://arxiv.org/abs/2512.08068)
*James Fullwood,Boyu Yang*

Main category: quant-ph

TL;DR: 论文提出了"局部密度算子"理论，作为非类空间隔量子系统的联合态表示，并建立了与"狄拉克测度"的一一对应关系，将Gleason定理推广到时空相关测量。


<details>
  <summary>Details</summary>
Motivation: 量子关联常常挑战经典物理的基本概念（如因果性、定域性和实在性）。虽然类空间隔系统的量子关联数学理论已很成熟，但非类空间隔系统的数学理论发展不足。本文旨在发展非类空间隔量子系统的联合态理论。

Method: 提出"局部密度算子"概念，其迹为1且边缘是真正的密度算子。证明局部密度算子与"狄拉克测度"（两个量子系统可分离投影空间上的复值测度）之间存在一一对应关系。

Result: 建立了局部密度算子与狄拉克测度的一一对应。当其中一个系统是平凡量子系统时，该结果恢复Gleason定理，表明量子理论中的玻恩规则是唯一非上下文地分配测量概率的方式。

Conclusion: 该工作将Gleason定理推广到可能非类空间隔系统的测量，从而将量子空间关联的数学理论扩展到时空关联，为理解量子时空关联提供了新的数学框架。

Abstract: Quantum correlations often defy an explanation in terms of fundamental notions of classical physics, such as causality, locality, and realism. While the mathematical theory underpinning quantum correlations between spacelike separated systems has been well-established since the 1930s, the mathematical theory for correlations between non-spacelike separated systems is much less developed. In this work, we develop the theory of what we refer to as "local-density operators", which we view as joint states for possibly non-spacelike separated quantum systems. Local-density operators are unit trace operators whose marginals are genuine density operators, which we show not only subsumes the notion of density operator, but also several extensions of the notion of density operator into the spatiotemporal domain, such as pseudo-density operators and quantum states over time. More importantly, we prove a result which establishes a one-to-one correspondence between local-density operators and what we refer to as "Dirac measures", which are complex-valued measures on the space of separable projectors associated with two quantum systems. In the case that one of the systems is the trivial quantum system with a one-dimensional Hilbert space, our result recovers the fundamental result known as Gleason's Theorem, which implies that the Born rule from quantum theory is the only way in which one may assign probabilities to the outcomes of measurements performed on quantum systems in a non-contextual manner. As such, our results establish a direct generalization of Gleason's Theorem to measurements performed on possibly non-spacelike separated systems, thus extending the mathematical theory of quantum correlations across space to quantum correlations across space and time.

</details>


### [40] [Deterministic Equations for Feedback Control of Open Quantum Systems II: Properties of the memory function](https://arxiv.org/abs/2512.08085)
*Alberto J. B. Rosal,Patrick P. Potts,Gabriel T. Landi*

Main category: quant-ph

TL;DR: 该论文提出了一种将量子反馈控制中的记忆函数视为经典系统与量子系统耦合的框架，并引入了信息论度量来量化系统与记忆之间的相关性，同时开发了表征记忆统计特性的通用方法。


<details>
  <summary>Details</summary>
Motivation: 量子反馈控制利用过去的检测结果动态修改量子系统，这些结果可以存储在记忆函数中。然而，对于受任意反馈动力学影响的通用记忆函数的主要特性缺乏系统研究，需要建立理论框架来量化系统与记忆之间的相关性并表征记忆的统计特性。

Method: 将记忆函数视为与受监测量子系统耦合的经典系统，用混合二分态描述它们的联合演化。引入信息论度量来量化系统与记忆之间的相关性，并开发通用框架来表征记忆的统计特性（如矩、累积量和相关函数）。

Result: 建立了将记忆作为经典系统处理的理论框架，该框架适用于一般反馈控制协议和无反馈的监测系统。应用于耦合热浴的两能级系统，分析了基于检测事件的反馈方案，展示了能够稳定激发态布居或拉比振荡以抵抗热耗散的具体协议。

Conclusion: 该工作为量子反馈控制中的记忆函数提供了统一的理论框架，将记忆视为经典系统并与量子系统耦合，引入了量化相关性的信息论工具，并开发了表征记忆统计特性的通用方法，为分析和设计量子反馈协议提供了理论基础。

Abstract: Feedback uses past detection outcomes to dynamically modify a quantum system and is central to quantum control. These outcomes can be stored in a memory, defined as a stochastic function of past measurements. In this work, we investigate the main properties of a general memory function subject to arbitrary feedback dynamics. We show that the memory can be treated as a classical system coupled to the monitored quantum system, and that their joint evolution is described by a hybrid bipartite state. This framework allows us to introduce information-theoretic measures that quantify the correlations between the system and the memory. Furthermore, we develop a general framework to characterize the statistics of the memory -- such as moments, cumulants, and correlation functions -- which can be applied both to general feedback-control protocols and to monitored systems without feedback. As an application, we analyze feedback schemes based on detection events in a two-level system coupled to a thermal bath, focusing on protocols that stabilize either the excited-state population or Rabi oscillations against thermal dissipation.

</details>


### [41] [On the Emergence of Time and Space in Closed Quantum Systems](https://arxiv.org/abs/2512.08120)
*Tommaso Favalli*

Main category: quant-ph

TL;DR: 基于Page和Wootters理论，探讨时间、空间和纠缠之间的深层联系，提出从纠缠中涌现时空的量子宇宙模型，并推导出与广义相对论一致的时间膨胀效应。


<details>
  <summary>Details</summary>
Motivation: 探索时间、空间和纠缠这三个物理学基本概念之间的本质联系，研究在封闭量子系统中，纠缠如何作为时间和空间涌现的基础，解决"时间是什么"这一根本问题。

Method: 重新审视并扩展Page和Wootters理论，该理论通过子系统之间的纠缠来描述全局静态量子宇宙中时间的涌现。将框架推广到空间维度，建立3+1维量子时空模型，并分析量子时钟在引力场中的演化。

Result: 建立了从纠缠中涌现时空的完整理论框架，提出了热化过程的新理解，推导出与史瓦西解一致的时间膨胀效应，为量子引力提供了新的视角。

Conclusion: 时间、空间和纠缠是紧密相关的物理现象，纠缠可能是时空涌现的基础。Page和Wootters理论为理解量子宇宙中的时间本质提供了有力框架，并可与广义相对论的结果相协调。

Abstract: Time, space and entanglement are the main characters in this work. Their nature is still a great mystery in physics and we study here the possibility that these three phenomena are closely connected, showing how entanglement can be at the basis of the emergence of time and space within closed quantum systems. We revisit and extend the Page and Wootters theory that was originally introduced in order to describe the emergence of time through entanglement between subsystems in a globally static, quantum Universe. In the book, after providing a complete review of the salient aspects of the theory, we establish a connection with recent research on the foundations of statistical mechanics and we propose a new understanding of the thermalization process. Furthermore, we generalize the framework in order describe the spatial degree of freedom and we provide a model of 3+1 dimensional, quantum spacetime emerging from entanglement among different subsystems in a globally "timeless" and "positionless" Universe. Finally, via the Page and Wootters theory, the evolution of quantum clocks within a gravitational field is treated and a time dilation effect is obtained in agreement with the Schwarzschild solution.

</details>


### [42] [The strength of weak coupling](https://arxiv.org/abs/2512.08141)
*Alastair Kay,Christino Tamon*

Main category: quant-ph

TL;DR: 论文证明了量子传输中的一个反直觉现象：将弱耦合边缘附加到大基图上可以实现高保真量子态传输，并展示了该思想在规避安德森局域化和加速量子搜索中的应用。


<details>
  <summary>Details</summary>
Motivation: 量子传输中存在一个看似矛盾的现象：将弱耦合的边缘附加到大的基图上反而能实现高保真度的量子态传输。这一现象在学术界被认为是"民间智慧"，但缺乏严格的数学证明。本文旨在为这一现象提供严格的数学分析。

Method: 采用初等数学方法，基于微扰理论中的Feshbach-Schur方法，对弱耦合边缘附加到大基图上的量子态传输现象进行严格数学证明。

Result: 成功证明了弱耦合边缘能实现高保真量子态传输的数学原理，并展示了该思想在两个重要应用中的有效性：1) 规避自旋链中的安德森局域化；2) 加速量子搜索中的击中时间。

Conclusion: 论文为量子传输中的反直觉现象提供了严格的数学基础，证明了弱耦合边缘策略的有效性，并为规避量子局域化和加速量子搜索提供了新的理论工具。

Abstract: A paradoxical idea in quantum transport is that attaching weakly-coupled edges to a large base graph creates high-fidelity quantum state transfer. We provide a mathematical treatment that rigorously prove this folklore idea. Our proofs are elementary and build upon the Feshbach-Schur method from perturbation theory. We also show the idea is effective in circumventing Anderson localization in spin chains and finding speedups in hitting times useful for quantum search.

</details>


### [43] [Detecting quantum many-body states with imperfect measuring devices](https://arxiv.org/abs/2512.08150)
*K. Uriostegui,C. Pineda,C. Chryssomalakos,V. Rascón Barajas,I. Vázquez Mota*

Main category: quant-ph

TL;DR: 研究量子多体系统中粒子寻址不完全导致的粗粒化映射，分析粗粒化状态的概率分布，发现随着量子比特数增加，粗粒化状态越来越集中于最大混合态。


<details>
  <summary>Details</summary>
Motivation: 研究量子系统中由于粒子寻址不完美导致的粗粒化过程，理解这种不完全测量如何影响量子态的表征和动力学。

Method: 使用几何方法分析两量子比特粗粒化为单量子比特的情况，采用随机矩阵方法处理更大系统，并通过蒙特卡洛模拟验证理论预测。

Result: 随着量子比特数增加，粗粒化状态的概率密度急剧集中在最大混合态附近，几乎纯的粗粒化状态变得越来越不可能。对于两量子比特系统，最大混合态的平均原像包含有限单重态成分。

Conclusion: 量子系统中的不完全寻址导致粗粒化过程，随着系统规模增大，粗粒化状态趋向于最大混合态，这对量子信息处理和量子态表征有重要影响。

Abstract: We study a coarse-graining map arising from incomplete and imperfect addressing of particles in a multipartite quantum system. In its simplest form, corresponding to a two-qubit state, the resulting channel produces a convex mixture of the two partial traces. We derive the probability density of obtaining a given coarse-grained state, using geometric arguments for two qubits coarse-grained to one, and random-matrix methods for larger systems. As the number of qubits increases, the probability density sharply concentrates around the maximally mixed state, making nearly pure coarse-grained states increasingly unlikely. For two qubits, we also compute the inverse state needed to characterize the effective dynamics under coarse-graining and find that the average preimage of the maximally mixed state contains a finite singlet component. Finally, we validate the analytical predictions by inferring the underlying probabilities from Monte-Carlo-generated coarse-grained statistics.

</details>


### [44] [Large-scale Lindblad learning from time-series data](https://arxiv.org/abs/2512.08165)
*Ewout van den Berg,Brad Mitchell,Ken Xuan Wei,Moein Malekakhlagh*

Main category: quant-ph

TL;DR: 提出一种可扩展协议，用于学习量子计算机上可重复操作的时间无关Lindblad模型，通过线性方程组求解模型参数，利用指数衰减正弦曲线拟合获取梯度信息，并在156量子比特超导处理器上首次演示


<details>
  <summary>Details</summary>
Motivation: 需要开发可扩展的方法来学习量子计算机上可重复操作的Lindblad模型，传统方法难以处理大规模系统，且对状态准备误差敏感

Method: 构建线性方程组将模型参数与可观测量及其梯度关联，通过拟合时间序列数据为指数衰减正弦曲线之和来获取梯度信息，开发鲁棒的曲线拟合程序，并提出可选的微调策略改进读取误差下的性能

Result: 在156量子比特超导量子处理器上首次成功学习完整门层的Lindbladian，展示了协议的可扩展性，研究了状态准备和测量误差的影响，以及可学习操作的限制

Conclusion: 该协议为学习量子计算机上的Lindblad模型提供了高度可扩展且对状态准备误差不敏感的方法，首次在大规模量子处理器上实现了此类学习实验，为量子噪声表征和纠错提供了新工具

Abstract: In this work, we develop a protocol for learning a time-independent Lindblad model for operations that can be applied repeatedly on a quantum computer. The protocol is highly scalable for models with local interactions and is in principle insensitive to state-preparation errors. At its core, the protocol forms a linear system of equations for the model parameters in terms of a set of observable values and their gradients. The required gradient information is obtained by fitting time-series data with sums of exponentially damped sinusoids and differentiating those curves. We develop a robust curve-fitting procedure that finds the most parsimonious representation of the data up to shot noise. We demonstrate the approach by learning the Lindbladian for a full layer of gates on a 156-qubit superconducting quantum processor, providing the first learning experiment of this kind. We study the effects of state-preparation and measurement errors and limitations on the operations that can be learned. For improved performance under readout errors, we propose an optional fine-tuning strategy that improves the fit between the time-evolved model and the measured data.

</details>


### [45] [The utility of noiseless linear amplification and attenuation in single-rail discrete-variable quantum communications](https://arxiv.org/abs/2512.08255)
*Ozlem Erkilic,Aritra Das,Angela A. Baiju,Nicholas Zaunders,Biveen Shajilal,Timothy C. Ralph*

Main category: quant-ph

TL;DR: 该研究通过优化测量操作来缓解量子通信中信道损耗对量子隐形传态和超密编码性能的影响，发现最优POVM测量可简化为无噪声衰减或无噪声线性放大操作，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 量子通信中的信道损耗会降低共享纠缠态的质量，从而影响量子隐形传态的保真度和超密编码的信息优势。需要找到方法来缓解这些损耗效应，提升量子通信协议的实际性能。

Method: 将问题形式化为对一般正算子值测量(POVM)的优化问题，并与物理上可实现的两种操作进行比较：无噪声衰减(NA)和无噪声线性放大(NLA)电路。

Result: 对于量子隐形传态，NLA/NA和优化的POVM可将平均保真度提升高达78%，同时保持可行的成功概率。对于超密编码，在某些情况下可将量子优势相对于经典信道容量提升超过100%，并扩展了可容忍的损耗范围。

Conclusion: 最优POVM测量实际上可简化为NA或NLA操作，表明简单且实验上可实现的测量操作已经能够获得主要的性能提升，为实际量子通信系统提供了实用的优化方案。

Abstract: Quantum communication offers many applications, with teleportation and superdense coding being two of the most fundamental. In these protocols, pre-shared entanglement enables either the faithful transfer of quantum states or the transmission of more information than is possible classically. However, channel losses degrade the shared states, reducing teleportation fidelity and the information advantage in superdense coding. Here, we investigate how to mitigate these effects by optimising the measurements applied by the communicating parties. We formulate the problem as an optimisation over general positive operator-valued measurements (POVMs) and compare the results with physically realisable noiseless attenuation (NA) and noiseless linear amplification (NLA) circuits. For teleportation, NLA/NA and optimised POVMs improve the average fidelity by up to 78% while maintaining feasible success probabilities. For superdense coding, they enhance the quantum advantage over the classical channel capacity by more than 100% in some regimes and shift the break-even point, thereby extending the tolerable range of losses. Notably, the optimal POVMs effectively reduce to NA or NLA, showing that simple, experimentally accessible operations already capture the essential performance gains.

</details>


### [46] [Programmable Open Quantum Systems](https://arxiv.org/abs/2512.08279)
*Mingrui Jing,Mengbo Guo,Lin Zhu,Hongshun Yao,Xin Wang*

Main category: quant-ph

TL;DR: 该论文提出了一个量化Lindbladian半群可编程性的框架，结合了物理可实现的检索映射和时变程序状态，识别了量子可编程类别，建立了编程成本的概念。


<details>
  <summary>Details</summary>
Motivation: 虽然可编程性是量子计算和控制中的统一范式，但开放系统的可编程性尚未得到充分探索。当前研究需要将开放系统视为计算资源而非仅仅是误差源，因此需要开发一个框架来表征和量化Lindbladian半群的可编程性。

Method: 开发了一个结合物理可实现检索映射和时变程序状态的框架，通过对称性和随机结构识别量子可编程类别（如协变半群和完全耗散Pauli Lindbladians），建立物理可编程性的必要条件，为非物理可编程情况构建显式协议，并引入基于样本数量的操作编程成本。

Result: 识别了由对称性和随机结构实现的量子可编程类别，提供了排除相干生成元和典型振幅阻尼耗散器的物理可编程性必要条件，为非物理可编程情况构建了有限资源协议，建立了编程成本的核心结构特性（连续性和忠实性）。

Conclusion: 该工作为Lindbladians提供了编程成本的概念，桥接了可编程通道理论和开放系统动力学，产生了对称性驱动的压缩方案，并为噪声量子技术中的半群模拟和控制提供了可操作的资源估计。

Abstract: Programmability is a unifying paradigm for enacting families of quantum transformations via fixed processors and program states, with a fundamental role and broad impact in quantum computation and control. While there has been a shift from viewing open systems solely as a source of error to treating them as a computational resource, their programmability remains largely unexplored. In this work, we develop a framework that characterizes and quantifies the programmability of Lindbladian semigroups by combining physically implementable retrieval maps with time varying program states. Within this framework, we identify quantum programmable classes enabled by symmetry and stochastic structure, including covariant semigroups and fully dissipative Pauli Lindbladians with finite program dimension. We further provide a necessary condition for physical programmability that rules out coherent generators and typical dissipators generating amplitude damping. For such nonphysically programmable cases, we construct explicit protocols with finite resources. Finally, we introduce an operational programming cost, defined via the number of samples required to program the Lindbladian, and establish its core structural properties, such as continuity and faithfulness. These results provide a notion of programming cost for Lindbladians, bridge programmable channel theory and open system dynamics, and yield symmetry driven compression schemes and actionable resource estimates for semigroup simulation and control in noisy quantum technologies.

</details>


### [47] [Discovering novel quantum dynamics with NISQ simulators](https://arxiv.org/abs/2512.08293)
*Pedram Roushan,Leigh S. Martin*

Main category: quant-ph

TL;DR: 量子模拟器已在多体量子动力学领域取得突破性进展，挑战并完善了传统认知


<details>
  <summary>Details</summary>
Motivation: 理解复杂量子多体系统的行为是当前核心挑战，费曼提出的量子模拟器概念为模拟复杂物理化学问题提供了新途径

Method: 使用可控量子系统构建高度可调的量子模拟器（量子天文仪），用于模拟难以理解的量子系统

Result: 量子模拟器已在多个重要实例中推进了对多体量子动力学的理解，这些发现虽然理论上或数值上可能获得，但首次实现是通过量子处理器

Conclusion: 尽管非平衡动力学之外的广阔问题领域仍有待探索，但量子模拟器已经开始挑战并完善我们的传统认知，展现出巨大潜力

Abstract: Major technological advances of the past century are rooted in our understanding of quantum physics in the non-interacting limit. A central challenge today is to understand the behavior of complex quantum many-body systems, where interactions play an essential role. About four decades ago, Richard Feynman proposed using controllable quantum systems to efficiently simulate complex physics and chemistry problems, envisioning quantum orreries, highly tunable quantum devices built to emulate less understood quantum systems. Here we ask whether quantum simulators have already uncovered new physical phenomena-and, if so, in which areas and with what impact. We find that, in several notable instances, they have advanced our understanding of many-body quantum dynamics. Although many of these insights could in principle have been obtained theoretically or numerically, they were nevertheless first achieved using quantum processors. While a broad landscape of problems beyond non-equilibrium dynamics still awaits exploration, it is encouraging that quantum simulators are already beginning to challenge and refine our conventional wisdom.

</details>


### [48] [Quantum-classical correspondence in resonant and nonresonant Rabi-Stark model](https://arxiv.org/abs/2512.08303)
*Shangyun Wang,Songbai Chen,Jiliang Jing*

Main category: quant-ph

TL;DR: 研究Rabi-Stark模型中的量子-经典对应关系，发现非线性Stark耦合能显著调节半经典相空间结构，在特定条件下可实现量子-经典对应


<details>
  <summary>Details</summary>
Motivation: 测试非线性量子系统中的对应原理是量子物理学的基本追求，研究Rabi-Stark模型中的量子-经典对应关系

Method: 采用平均场近似理论研究Rabi-Stark模型的半经典动力学，分析相干态的线性纠缠熵，比较经典混沌区和规则区的量子行为

Result: 在大原子-光频率比条件下，Rabi-Stark模型可实现量子-经典对应；在共振Rabi模型中，截断光子数不足导致对应失败；但在共振RSM中，当非线性Stark耦合U→±1时，时间平均线性纠缠熵与半经典相空间强相关

Conclusion: 量子-经典对应可以在少体共振Rabi-Stark模型中实现，非线性Stark耦合在调节半经典相空间结构和实现量子-经典对应中起关键作用

Abstract: Testing the correspondence principle in nonlinear quantum systems is a fundamental pursuit in quantum physics. In this paper, we employed mean field approximation theory to study the semiclassical dynamics in the Rabi-Stark model (RSM) and showed that the nonlinear Stark coupling significantly modulates the semiclassical phase space structure. By analyzing the linear entanglement entropy of coherent states prepared in the classical chaotic and regular regions of the semiclassical phase space, we demonstrate that quantum-classical correspondence can be achieved in the RSM with large atom-light frequency ratios. While this correspondence fails in the resonant Rabi model because its truncated photon number is insufficient to approach the large quantum number limit, we discovered that in the resonant RSM when the nonlinear Stark coupling $U \to \pm 1$, the time-averaged linear entanglement entropy correlates strongly with the semiclassical phase space. In particular, when $U \to -1$, the truncated photon number in the resonant RSM is very close to that in the resonant Rabi model, but the time-averaged linear entanglement entropy still corresponds well with the semiclassical phase space. This result demonstrates that quantum-classical correspondence can be realized in the few-body resonant RSM.

</details>


### [49] [Photonic Quantum-Accelerated Machine Learning](https://arxiv.org/abs/2512.08318)
*Markus Rambach,Abhishek Roy,Alexei Gilchrist,Akitada Sakurai,William J. Munro,Kae Nemoto,Andrew G. White*

Main category: quant-ph

TL;DR: 利用玻色子采样作为量子指纹增强经典机器学习，在多种条件下实现性能提升，并在实际量子硬件上验证了加速效果


<details>
  <summary>Details</summary>
Motivation: 机器学习尚未充分利用量子资源的独特优势，玻色子采样作为一种量子干涉采样协议，具有经典难以模拟的特性，可在当前量子硬件上实现

Method: 使用玻色子采样为储层计算提供高维量子指纹，构建量子加速器来增强经典机器学习

Result: 在多种条件下实现稳健性能提升：包括不完美光子源、严重类别不平衡场景（手写数字和生物医学图像分类）、数据稀疏情况（仅需1/20训练数据）。首次在实际量子处理单元上验证了玻色子采样增强学习的加速和可扩展性

Conclusion: 玻色子采样增强的机器学习在实际量子硬件上能够提供真实的性能增益，为量子加速经典机器学习提供了实验验证

Abstract: Machine learning is widely applied in modern society, but has yet to capitalise on the unique benefits offered by quantum resources. Boson sampling -- a quantum-interference based sampling protocol -- is a resource that is classically hard to simulate and can be implemented on current quantum hardware. Here, we present a quantum accelerator for classical machine learning, using boson sampling to provide a high-dimensional quantum fingerprint for reservoir computing. We show robust performance improvements under various conditions: imperfect photon sources down to complete distinguishability; scenarios with severe class imbalances, classifying both handwritten digits and biomedical images; and sparse data, maintaining model accuracy with twenty times less training data. Crucially, we demonstrate the acceleration and scalability of our scheme on a photonic quantum processing unit, providing the first experimental validation that boson-sampling-enhanced learning delivers real performance gains on actual quantum hardware.

</details>


### [50] [Deterministic Quantum Communication Between Fixed-Frequency Superconducting Qubits via Broadband Resonators](https://arxiv.org/abs/2512.08328)
*Takeaki Miyamura,Zhiling Wang,Kohei Matsuura,Yoshiki Sunada,Keika Sunada,Kenshi Yuki,Jesper Ilves,Yasunobu Nakamura*

Main category: quant-ph

TL;DR: 本文展示了固定频率超导量子比特之间的确定性量子态传输和远程纠缠生成，通过频率可调光子生成技术和宽带传输谐振器实现，避免了传统频率可调元件带来的控制复杂性。


<details>
  <summary>Details</summary>
Motivation: 实现大规模超导量子计算机需要远程芯片间的量子通信。现有方法依赖频率可调电路元件来补偿制造参数差异，这引入了控制复杂性并限制了可扩展性。需要一种更简单、更灵活的方法来实现固定频率量子比特之间的量子通信。

Method: 采用频率可调光子生成技术，在不修改电路参数的情况下调整光子频率。实现宽带传输谐振器，由两个耦合的共面波导谐振器组成，带宽超过100MHz。使用量子过程层析技术评估性能。

Result: 成功在30MHz光子频率范围内实现远程量子比特间的量子通信。量子态传输保真度约78%，贝尔态保真度约73%。宽带设计使通信能够在整个频率范围内成功进行。

Conclusion: 该方法避免了控制线路和噪声通道的复杂性，为可扩展量子网络提供了灵活途径，解决了固定频率超导量子比特间量子通信的挑战。

Abstract: Quantum communication between remote chips is essential for realizing large-scale superconducting quantum computers. For such communication, itinerant microwave photons propagating through transmission lines offer a promising approach. However, demonstrations to date have relied on frequency-tunable circuit elements to compensate for fabrication-related parameter variations between sender and receiver devices, introducing control complexity and limiting scalability. In this work, we demonstrate deterministic quantum state transfer and remote entanglement generation between fixed-frequency superconducting qubits on separate chips. To compensate for the sender-receiver mismatch, we employ a frequency-tunable photon-generation technique which enables us to adjust the photon frequency without modifying circuit parameters. To enhance the frequency tunability, we implement broadband transfer resonators composed of two coupled coplanar-waveguide resonators, achieving a bandwidth of more than 100 MHz. This broadband design enables successful quantum communication across a 30-MHz range of photon frequencies between the remote qubits. Quantum process tomography reveals state transfer fidelities of around 78% and Bell-state fidelities of around 73% across the full frequency range. Our approach avoids the complexity of the control lines and noise channels, providing a flexible pathway toward scalable quantum networks.

</details>


### [51] [Constraint-oriented biased quantum search for general constrained combinatorial optimization problems](https://arxiv.org/abs/2512.08384)
*Sören Wilkening*

Main category: quant-ph

TL;DR: 提出一种基于Grover搜索的量子算法，用于处理具有任意高效可计算目标函数和约束条件的组合优化问题，相比现有方法扩展了约束类型，在理想量子硬件假设下可能超越经典求解器。


<details>
  <summary>Details</summary>
Motivation: 现有基于Grover的量子启发式方法主要局限于线性约束，需要扩展到更广泛的约束类型以处理更一般的组合优化问题。

Method: 构建量子算法框架，将Grover搜索推广到处理任意高效可计算的目标函数和约束条件，在离散域中实现更通用的组合优化求解。

Result: 在足够先进的逻辑量子硬件假设下，该方法在运行时间缩放和求解质量方面可能超越最先进的经典求解器和启发式方法，逻辑量子算法可实现10^2-10^3倍的运行时间节省。

Conclusion: 该量子算法框架扩展了Grover-based启发式方法的适用范围，为组合优化问题提供了有前景的量子解决方案，即使在更现实的实现中也可能保持优势。

Abstract: We present a quantum algorithmic routine that extends the realm of Grover-based heuristics for tackling combinatorial optimization problems with arbitrary efficiently computable objective and constraint functions. Building on previously developed quantum methods that were primarily restricted to linear constraints, we generalize the approach to encompass a broader class of problems in discrete domains. To evaluate the potential of our algorithm, we assume the existence of sufficiently advanced logical quantum hardware. With this assumption, we demonstrate that our method has the potential to outperform state-of-the-art classical solvers and heuristics in terms of both runtime scaling and solution quality. The same may be true for more realistic implementations, as the logical quantum algorithm can achieve runtime savings of up to $10^2-10^3$.

</details>


### [52] [Practical protein-pocket hydration-site prediction for drug discovery on a quantum computer](https://arxiv.org/abs/2512.08390)
*Daniele Loco,Kisa Barkemeyer,Andre R. R. Carvalho,Jean-Philip Piquemal*

Main category: quant-ph

TL;DR: 使用量子计算机进行蛋白质口袋水合位点预测，通过QUBO公式和混合量子-经典方法，在123量子比特硬件上实现与经典方法相当的精度，展示了NISQ硬件在药物发现中的实用价值。


<details>
  <summary>Details</summary>
Motivation: 证明NISQ量子硬件在计算机辅助药物发现中的实际应用价值，特别是在蛋白质-配体复合物模拟这一重要任务上。

Method: 将水分子放置问题转化为QUBO优化问题，采用混合方法：经典3D-RISM模型与高效量子优化求解器结合，在量子硬件上进行实验（最多123量子比特）。

Result: 在真实蛋白质-配体复合物上复现了实验预测，精度与经典方法相当；通过资源分析显示精度可随量子比特数增加而系统提升；发现某些经典优化困难的系统可能存在量子优势。

Conclusion: 该方法展示了NISQ量子硬件在药物发现中的实际应用潜力，特别是在蛋白质-配体复合物模拟、药物先导优化和对接计算设置方面具有辅助价值。

Abstract: Demonstrating the practical utility of Noisy Intermediate-Scale Quantum (NISQ) hardware for recurrent tasks in Computer-Aided Drug Discovery is of paramount importance. We tackle this challenge by performing three-dimensional protein pockets hydration-site prediction on a quantum computer. Formulating the water placement problem as a Quadratic Unconstrained Binary Optimization (QUBO), we use a hybrid approach coupling a classical three-dimensional reference-interaction site model (3D-RISM) to an efficient quantum optimization solver, to run various hardware experiments up to 123 qubits. Matching the precision of classical approaches, our results reproduced experimental predictions on real-life protein-ligand complexes. Furthermore, through a detailed resource estimation analysis, we show that accuracy can be systematically improved with increasing number of qubits, indicating that full quantum utility is in reach. Finally, we provide evidence that advantageous situations could be found for systems where classical optimization struggles to provide optimal solutions. The method has potential for assisting simulations of protein-ligand complexes for drug lead optimization and setup of docking calculations.

</details>


### [53] [Single-Step Phase-Engineered Pulse for Active Readout Cavity Reset in Superconducting Circuits](https://arxiv.org/abs/2512.08393)
*Ren-Ze Zhao,Ze-An Zhao,Tian-Le Wang,Peng Wang,Sheng Zhang,Xiao-Yan Yang,Hai-Feng Zhang,Zhi-Fei Li,Yuan Wu,Zi-Hao Fu,Sheng-Ri Liu,Peng Duan,Guo-Ping Guo*

Main category: quant-ph

TL;DR: 实验演示了一种单步相位工程脉冲方案，用于主动清空读取腔，相比被动自由衰变加速6倍光子耗散，且对量子比特的激发和弛豫率最低。


<details>
  <summary>Details</summary>
Motivation: 在电路QED架构中，需要快速、平滑、低背作用的腔重置方案来提升量子计算性能。传统被动衰变太慢，现有主动重置方法复杂或背作用大。

Method: 提出单步相位工程脉冲方案：在正常方波读取脉冲后附加一个具有定制幅度和相位的重置段。在线性响应区域，最优重置幅度与读取幅度成正比，最优相位几乎不变，简化校准。

Result: SSPE脉冲将光子耗散加速至被动自由衰变的6倍；相比方波和CLEAR脉冲，SSPE脉冲对量子比特的激发和弛豫率最低；证明了SSPE方案的实际可行性和可扩展性。

Conclusion: SSPE方案是超导量子电路中实现快速、平滑、低背作用腔重置的实用且可扩展方法，简化校准流程，显著提升系统性能。

Abstract: In a circuit QED architecture, we experimentally demonstrate a simple and hardware-efficient Single-Step Phase-Engineered (SSPE) pulse scheme for actively depopulating the readout cavity. The method appends a reset segment with tailored amplitude and phase to a normal square readout pulse. Within the linear-response regime, the optimal reset amplitude scales proportionally with the readout amplitude, while the optimal reset phase remains nearly invariant, significantly simplifying the calibration process. By characterizing the cavity photons dynamics, we show that the SSPE pulse accelerates photon depletion by up to a factor of six compared to passive free decay. We further quantify the qubit backaction induced by the readout pulse and find that the SSPE pulse yields the lowest excitation and relaxation rates compared to a Square and CLEAR pulses. Our results establish the SSPE scheme as a practical and scalable approach for achieving fast, smooth, low-backaction cavity reset in superconducting quantum circuits.

</details>


### [54] [Universal recoverability of quantum states in tracial von-Neumann algebras](https://arxiv.org/abs/2512.08418)
*Saptak Bhattacharya*

Main category: quant-ph

TL;DR: 本文改进了迹von-Neumann代数上夹心拟相对熵S₂的量子数据处理不等式，得到了Petz恢复映射的普适可恢复性界


<details>
  <summary>Details</summary>
Motivation: 量子数据处理不等式在量子信息理论中至关重要，但现有结果主要针对有限维情形。本文旨在将Petz恢复映射的普适可恢复性界推广到迹von-Neumann代数（无限维）的夹心拟相对熵S₂上

Method: 使用夹心拟相对熵S₂作为度量工具，在迹von-Neumann代数框架下分析量子数据处理不等式，重点研究Petz恢复映射的恢复性能

Result: 成功将有限维情形下已知的Petz恢复映射普适可恢复性界推广到迹von-Neumann代数上的夹心拟相对熵S₂，建立了相应的量子数据处理不等式精化结果

Conclusion: 本文证明了在无限维迹von-Neumann代数上，夹心拟相对熵S₂同样满足具有Petz恢复映射的普适可恢复性界，扩展了量子数据处理不等式的适用范围

Abstract: In this paper, we discuss a refinement of quantum data processing inequality for the sandwiched quasi-relative entropy $\mathcal{S}_2$ on a tracial von-Neumann algebra. The main result is a universal recoverability bound with the Petz recovery map, which was previously obtained in the finite dimensional setup.

</details>


### [55] [Real-time heralded non-Gaussian teleportation resource-state generator](https://arxiv.org/abs/2512.08429)
*Joseph C. Chapman,Yanbao Zhang,Joseph M. Lukens,Alberto M. Marino,Eugene Dumitrescu,Yan Wang,Nicholas A. Peters*

Main category: quant-ph

TL;DR: 实验演示了可用于实时非高斯量子隐形传态的预示双模资源态，通过光子减法协调系统和同步零差检测服务器实现实时使用


<details>
  <summary>Details</summary>
Motivation: 在连续变量量子通信中，非高斯纠缠资源理论上能比高斯压缩真空态提供更高的隐形传态保真度，但需要实现实时可用的预示非高斯态

Method: 开发了光子减法协调系统进行实时符合检测，输出低抖动低延迟的预示信号；构建了同步零差检测服务器，协调系统可查询收集预示态对应的实时正交分量测量

Result: 通过双模零差层析表征，资源态与预期态的保真度达到F=0.973±0.005；实现了实时收集光子减法态的实时正交分量测量

Conclusion: 该工作显著推进了预示非高斯态在量子网络协议中的应用，特别是在量子中继器、非高斯量子传感和基于测量的量子计算方面

Abstract: Quantum teleportation is a fundamental quantum communications primitive that requires an entangled resource state. In the continuous-variable regime, non-Gaussian entangled resources have been shown theoretically to improve teleportation fidelity compared to Gaussian squeezed vacuum. We experimentally demonstrate a heralded two-mode resource state for non-Gaussian teleportation capable of real-time use. We characterize this state with two-mode homodyne tomography showing it has fidelity $F=0.973\pm 0.005$ with the expected resource state. Real-time use is enabled by a photon-subtraction orchestrator system performing live coincidence detection and outputting low-jitter and low-latency heralding signals. Live collection of real-time quadrature measurements of photon-subtracted states is enabled by the development of a synchronized homodyne detection server where the orchestrator system queries to collect the real-time quadrature samples corresponding to the heralded state. These results demonstrate significant advancement in enabling the use of heralded non-Gaussian states in quantum networking protocols, especially in the context of quantum repeaters, non-Gaussian quantum sensing and measurement-based quantum computing.

</details>


### [56] [A Grover-compatible manifold optimization algorithm for quantum search](https://arxiv.org/abs/2512.08432)
*Zhijian Lai,Dong An,Jiang Hu,Zaiwen Wen*

Main category: quant-ph

TL;DR: 该论文将Grover算法重新表述为酉流形上的最大化问题，通过黎曼梯度上升方法求解，并引入与Grover兼容的回缩操作来保证量子算子的物理可实现性，最终获得了与Grover算法相同的二次加速效果。


<details>
  <summary>Details</summary>
Motivation: 从优化视角重新审视Grover算法，探索是否可以通过优化框架获得量子算法的设计新思路。传统Grover算法交替应用oracle和扩散算子，而本文试图将其重新表述为酉流形上的优化问题。

Method: 将非结构化搜索问题重新表述为酉流形上的最大化问题，采用黎曼梯度上升方法求解。为了解决一般RGA更新不保证物理可实现性的问题，引入了Grover兼容的回缩操作，将更新限制在有效的oracle和扩散算子范围内。

Result: 建立了局部黎曼μ-Polyak-Łojasiewicz不等式（μ=1/2），获得了1-κ^{-1}的线性收敛率。证明了黎曼Lipschitz常数L_Rie = O(√N)，其中N=2^n为问题规模。迭代复杂度为O(√N log(1/ε))，与Grover算法的二次加速效果相匹配。

Conclusion: 优化视角能够为量子算法设计提供新的概念性见解，并推动该领域的新进展。通过黎曼优化框架重新解释Grover算法，不仅获得了相同的性能保证，还展示了优化方法在量子算法设计中的潜力。

Abstract: Grover's algorithm is a fundamental quantum algorithm that offers a quadratic speedup for the unstructured search problem by alternately applying physically implementable oracle and diffusion operators. In this paper, we reformulate the unstructured search as a maximization problem on the unitary manifold and solve it via the Riemannian gradient ascent (RGA) method. To overcome the difficulty that generic RGA updates do not, in general, correspond to physically implementable quantum operators, we introduce Grover-compatible retractions to restrict RGA updates to valid oracle and diffusion operators. Theoretically, we establish a local Riemannian $μ$-Polyak-Łojasiewicz (PL) inequality with $μ= \tfrac{1}{2}$, which yields a linear convergence rate of $1 - κ^{-1}$ toward the global solution. Here, the condition number $κ= L_{\mathrm{Rie}} / μ$, where $L_{\mathrm{Rie}}$ denotes the Riemannian Lipschitz constant of the gradient. Taking into account both the geometry of the unitary manifold and the special structure of the cost function, we show that $L_{\mathrm{Rie}} = O(\sqrt{N})$ for problem size $N = 2^n$. Consequently, the resulting iteration complexity is $O(\sqrt{N} \log(1/\varepsilon))$ for attaining an $\varepsilon$-accurate solution, which matches the quadratic speedup of $O(\sqrt{N})$ achieved by Grover's algorithm. These results demonstrate that an optimization-based viewpoint can offer fresh conceptual insights and lead to new advances in the design of quantum algorithms.

</details>


### [57] [Benchmarking Gaussian and non-Gaussian input states with a hybrid sampling platform](https://arxiv.org/abs/2512.08433)
*Michael Stefszky,Kai-Hong Luo,Jan-Lucas Eickmann,Simone Atzeni,Florian Lütkewitte,Cheeranjiv Pandey,Fabian Schlue,Jonas Lammers,Mikhail Roiz,Timon Schapeler,Laura Ares,Milad Yahyapour,Alexander Kastner,Joschua Martinek,Michael Mittermair,Carlos Sevilla,Marius Leyendecker,Oskar Kohout,Dmitriy Mitin,Ronald Holzwarth,Jan Sperling,Tim Bartley,Fabian Steinlechner,Benjamin Brecht,Christine Silberhorn*

Main category: quant-ph

TL;DR: 研究人员开发了Paderborn量子采样器(PaQS)，这是一个能够使用高斯或非高斯输入态进行采样的混合平台，通过半设备无关框架验证了非高斯资源对量子优势的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着玻色采样实验规模的扩大，实验上要求高的单光子源被高斯态取代，这减少了可用的非高斯性——关键的量子资源。需要量化减少非高斯资源的性能成本，并比较使用不同输入态的采样平台。

Method: 开发了Paderborn量子采样器(PaQS)，这是一个混合平台，能够在单次实验运行中在12模式干涉仪中使用8个高斯或非高斯输入态进行采样实验。采用半设备无关框架进行认证，不依赖于对干涉仪或输入态的先验知识。

Result: 该架构能够在相同条件下直接并排比较不同的采样机制。通过半设备无关框架验证了观测数据无法被任何经典模型复制——这是展示量子优势的前提。观察到非高斯输入态带来的明显性能提升。

Conclusion: PaQS平台为比较不同采样机制提供了直接基准测试能力，验证了非高斯资源对实现量子计算优势的重要性，为玻色采样从理论采样任务转向实际应用提供了重要工具。

Abstract: The original boson sampling paradigm-consisting of multiple single-photon input states, a large interferometer, and multi-channel click detection-was originally proposed as a photonic route to quantum computational advantage. Its non-Gaussian resources, essential for outperforming any classical system, are provided by single-photon inputs and click detection. Yet the drive toward larger experiments has led to the replacement of experimentally demanding single-photon sources with Gaussian states, thereby diminishing the available non-Gaussianity-a critical quantum resource. As the community broadens its focus from the initial sampling task to possible real-world applications, it becomes crucial to quantify the performance cost associated with reducing non-Gaussian resources and to benchmark sampling platforms that employ different input states.
  To address this need, we introduce the Paderborn Quantum Sampler (PaQS), a hybrid platform capable of performing sampling experiments with eight Gaussian or non-Gaussian input states in a 12-mode interferometer within a single experimental run. This architecture enables direct, side-by-side benchmarking of distinct sampling regimes under otherwise identical conditions. By employing a semi-device-independent framework, offering certification that does not rely on prior knowledge of the interferometer or the input states, we verify that the observed data cannot be reproduced by any classical model-a prerequisite for demonstrating quantum advantage. Applying this framework, we observe clear performance gains arising from non-Gaussian input states.

</details>


### [58] [High-OAM Deep Ultraviolet Twisted Light Generation for RF-Photoinjector Applications](https://arxiv.org/abs/2512.08442)
*A. S. Dyatlov,D. M. Dolgintsev,V. V. Gerasimov,V. V. Kobets,V. P. Nazmov,M. A. Nozdrin,A. N. Sergeev,D. S. Shokin,K. E. Yunenko,D. V. Karlovets*

Main category: quant-ph

TL;DR: 首次在深紫外波段（266nm）使用三种衍射光学元件（叉形光栅、高电荷螺旋相位板、二元轴锥镜）生成并表征高轨道角动量扭曲光，验证了在电子RF光注入器中的实际应用可行性。


<details>
  <summary>Details</summary>
Motivation: 开发与高功率紫外激光系统兼容的实用方法，用于RF光注入器中的结构化光阴极照明，并为粒子加速器设施中产生相对论性涡旋电子提供技术路径。

Method: 使用三种制造的衍射光学元件：反射叉形光栅、高电荷螺旋相位板（SPP）和二元轴锥镜，集成到电子RF光注入器的驱动激光束线中，在加速器相关条件下直接评估。

Result: SPP产生OAM l=64的高纯度拉盖尔-高斯模式，转换效率约80%；二元轴锥镜生成拓扑电荷高达m=10的准贝塞尔扭曲光，具有低发散度和稳定的多瓣环结构；叉形光栅可靠产生l=2-8的低阶模式，模拟与柱面透镜诊断结果良好一致。

Conclusion: 这是首次通过制造DOE生成深紫外高OAM光束并通过模式转换测量验证的全面实验演示，所展示技术与RF光注入器中使用的高功率紫外激光系统兼容，为结构化光阴极照明和相对论性涡旋电子生成提供了实用途径。

Abstract: We report on the generation and characterization of ultraviolet (wavelength 266 nm) twisted light with high orbital angular momentum (OAM) using three types of fabricated diffractive optical elements (DOEs): a reflective fork grating, a high-charge spiral phase plate (SPP), and binary axicons. All elements were integrated into a drive-laser beamline of an electron RF-photoinjector, enabling direct evaluation under accelerator-relevant conditions.
  The SPP produced a high-purity Laguerre-Gaussian mode with OAM l = 64 and a measured conversion efficiency of approximately 80\%. Binary axicons generated quasi-Bessel twisted light with topological charges up to m = 10, exhibiting low divergence and stable multi-lobe ring structures. The fork grating reliably produced lower-order modes, l = 2-8, with good agreement between simulations and cylindrical-lens diagnostics.
  These results constitute, to our knowledge, the first comprehensive experimental demonstration of deep-UV high-OAM beams generated with fabricated DOEs and validated through mode-conversion measurements. The demonstrated techniques are compatible with high-power UV laser systems used in RF-photoinjectors and offer a practical route toward structured photocathode illumination and the generation of relativistic vortex electrons at a particle accelerator facility.

</details>


### [59] [Heralded generation of a three-mode NOON state](https://arxiv.org/abs/2512.08458)
*Sukhjit P. Singh,Elnaz Bazzazi,Diego N. Bernal-García,Simon White,Hassan Jamal Latief,Alison Goldingay,Sven Rogge,Sergei Slussarenko,Farzad Ghafari,Emanuele Polino,Nora Tischler*

Main category: quant-ph

TL;DR: 实验实现了通过单光子探测作为herald信号，在三个目标模式中确定性生成三模双光子NOON纠缠态，验证了高保真度和真多体纠缠。


<details>
  <summary>Details</summary>
Motivation: 光子纠缠态是量子通信、计算和计量学的基础，但由于缺乏本征光子-光子相互作用，其生成通常是概率性的而非确定性的。现有技术通过后选择验证纠缠态生成，但会破坏态本身。heralding技术通过测量辅助模式中的ancilla光子来指示态生成而不破坏目标态。

Method: 采用heralding方案，通过检测一个heralding模式中的单光子，来指示在三个目标模式中生成三模双光子NOON态。实验验证了生成态的高保真度和真多体纠缠特性。

Result: 实验成功生成三模双光子NOON态，估计保真度为0.823±0.018（相对于理想三模NOON态），并认证了真多体纠缠。方案具有高成功概率和小资源开销。

Conclusion: 该工作为纠缠多模态生成提供了理论和实验基础，可在现有技术下实现。多模纠缠态代表了线性光学量子信息的关键方向，与多量子比特态编码互补。

Abstract: Entangled states of photons form the foundation of quantum communication, computation, and metrology. Yet their generation remains fundamentally constrained: in the absence of intrinsic photon-photon interactions, the generation of such states is inherently probabilistic rather than deterministic. The prevalent technique of post-selection verifies the creation of an entangled state by detecting and thus destroying it. Heralding offers a solution in which measuring ancillary photons in auxiliary modes signals the state generation without the need to measure it. Here, we report an experiment to generate a three-mode two-photon NOON state, where the detection of a single photon in one heralding mode signifies the presence of the state in three target modes. We validate the generated state by estimating a fidelity of 0.823 +/- 0.018 with respect to an ideal three-mode NOON state and certifying genuine multipartite entanglement. By virtue of the high success probability and small resource overhead of our scheme, our work provides a theoretical and experimental stepping stone for entangled multi-mode state generation, which is realizable with current technology. These multi-mode entangled states represent a key direction for linear optical quantum information that is complementary to multi-qubit state encoding.

</details>


### [60] [Higher Josephson harmonics in a tunable double-junction transmon qubit](https://arxiv.org/abs/2512.08470)
*Ksenia Shagalov,David Feldstein-Bofill,Leo Uhre Jakobsen,Zhenhai Sun,Casper Wied,Amalie T. J. Paulsen,Johann Bock Severin,Malthe A. Marciniak,Clinton A. Potts,Anders Kringhøj,Jacob Hastrup,Karsten Flensberg,Svend Krøjer,Morten Kjaergaard*

Main category: quant-ph

TL;DR: 通过串联隧道结和SQUID环实现约瑟夫森势谐波高度可调的超导电路元件，谐波含量可达基频的10%，并发现色散位移消失的甜点


<details>
  <summary>Details</summary>
Motivation: 开发具有可调约瑟夫森谐波的新型量子比特设计，为受保护量子比特和可定制非线性微波器件提供新途径

Method: 设计包含隧道结与SQUID环串联的超导电路元件，通过磁通量高度调控约瑟夫森势的谐波含量，分析前四个量子比特跃迁的光谱

Result: 实现二次谐波可达基频的约10%，发现通过平衡内部模式和量子比特模式的色散耦合可实现色散位移消失的甜点

Conclusion: 高度可调的设置为实现受保护量子比特和可定制非线性微波器件提供了新途径

Abstract: Tunable Josephson harmonics open up for new qubit design. We demonstrate a superconducting circuit element with a tunnel junction in series with a SQUID loop, yielding a highly magnetic-flux tunable harmonic content of the Josephson potential. We analyze spectroscopy of the first four qubit transitions with a circuit model which includes the internal mode, revealing a second harmonic up to $\sim10\%$ of the fundamental harmonic. Interestingly, a sweet spot where the dispersive shift vanishes is achieved by balancing the dispersive couplings to the internal and qubit modes. The highly tunable set-up provides a route toward protected qubits, and customizable nonlinear microwave devices.

</details>


### [61] [Syntactic Structure, Quantum Weights](https://arxiv.org/abs/2512.08507)
*Kentaro Imafuku*

Main category: quant-ph

TL;DR: 论文从有限描述的角度解释为什么局部作用和指数欧几里得权重在经典、统计和量子理论中普遍出现，认为这是由历史描述的最小约束决定的。


<details>
  <summary>Details</summary>
Motivation: 解释为什么局部作用和指数欧几里得权重在物理理论中如此普遍出现，从信息论和描述复杂性的角度提供结构性的解释。

Method: 假设历史具有有限、自定界的前缀自由生成码，可以顺序解码。定义最小描述成本作为平滑的最小程序长度，该成本在局部段上是可加的。分析连续局部可加成本的数学结构。

Result: 1. 任何连续局部可加成本，其平稳部分与经验确定的经典变分部分一致，都被强制进入唯一的欧拉-拉格朗日等价类；2. 前缀自由语言表现出指数冗余，这种冗余在历史上诱导出普遍的指数多重性权重，选择实欧几里得代表得到标准欧几里得路径积分形式。

Conclusion: 物理理论中普遍出现的局部作用和指数欧几里得权重形式是由历史描述的纯粹句法约束决定的，而具体的微观拉格朗日量和耦合则是系统依赖的语义输入。当Osterwalder-Schrader反射正定性成立时，欧几里得测度重构出幺正洛伦兹振幅。

Abstract: Why do local actions and exponential Euclidean weights arise so universally in classical, statistical, and quantum theories? We offer a structural explanation from minimal constraints on finite descriptions of admissible histories. Assume that histories admit finite, self-delimiting (prefix-free) generative codes that can be decoded sequentially in a single forward pass. These purely syntactic requirements define a minimal descriptive cost, interpretable as a smoothed minimal program length, that is additive over local segments. First, any continuous local additive cost whose stationary sector coincides with the empirically identified classical variational sector is forced into a unique Euler--Lagrange equivalence class. Hence the universal form of an action is fixed by descriptional structure alone, while the specific microscopic Lagrangian and couplings remain system-dependent semantic input. Second, independently of microscopic stochasticity, finite prefix-free languages exhibit exponential redundancy: many distinct programs encode the same coarse history, and this redundancy induces a universal exponential multiplicity weight on histories. Requiring this weight to be real and bounded below selects a real Euclidean representative for stable local bosonic systems, yielding the standard Euclidean path-integral form. When Osterwalder--Schrader reflection positivity holds, the Euclidean measure reconstructs a unitary Lorentzian amplitude.

</details>


### [62] [Tunable passive squeezing of squeezed light through unbalanced double homodyne detection](https://arxiv.org/abs/2512.08540)
*Niels Tripier-Mondancin,David Barral,Ganaël Roeland,Raúl Leonardo Rincon Celis,Yann Bouchereau,Nicolas Treps*

Main category: quant-ph

TL;DR: 双零差检测通过不平衡输入分束器实现可控的量子态压缩/反压缩变换，直接采样输入态的Q函数，同时实现量子态操纵与表征


<details>
  <summary>Details</summary>
Motivation: 量子光态的完整表征是量子光学和信息科学的核心任务。传统双零差检测虽然能直接测量Husimi Q准概率分布，但通常只作为被动测量装置使用，缺乏主动操控量子态的能力。

Method: 通过有意地不平衡分割量子信号的输入分束器，使检测方案本身对被测态执行有效的压缩或反压缩变换。分束器的反射率作为可调实验参数，控制压缩算符的强度。实验采用稳健的偏振编码双零差检测来表征压缩真空态。

Result: 实验成功实现了对测量Q函数相空间分布的可控变形，证实了不平衡双零差检测能够同时进行量子态操纵和表征。测量直接采样输入态的Q函数，就像该态被具有可调强度的压缩算符作用一样。

Conclusion: 不平衡双零差检测不仅是量子态表征的被动测量工具，更是一个多功能平台，能够同时实现量子态的可控操纵和完整表征，为量子光学和量子信息处理提供了新的实验能力。

Abstract: The full characterization of quantum states of light is a central task in quantum optics and information science. Double homodyne detection provides a powerful method for the direct measurement of the Husimi Q quasi-probability distribution, offering a complete state representation in a simple experimental setting and a limited time frame. Here, we demonstrate that double homodyne detection can serve as more than a passive measurement apparatus. By intentionally unbalancing the input beamsplitter that splits the quantum signal, we show that the detection scheme itself performs an effective squeezing or anti-squeezing transformation on the state being measured. The resulting measurement directly samples the Q function of the input state as if it were acted upon by a squeezing operator whose strength is a tunable experimental parameter : the beamsplitter's reflectivity. We experimentally realize this technique using a robust polarization-encoded double homodyne detection to characterize a squeezed vacuum state. Our results demonstrate the controlled deformation of the measured Q function's phase-space distribution, confirming that unbalanced double homodyne detection is a versatile tool for simultaneous quantum state manipulation and characterization.

</details>


### [63] [Quantum simulation in the entanglement picture](https://arxiv.org/abs/2512.08565)
*D. -S. Wang,X. Xu,Y. -D. Liu*

Main category: quant-ph

TL;DR: 提出基于信道-态对偶的纠缠图像新框架，应用于多体动力学、量子场论、热物理等量子模拟算法


<details>
  <summary>Details</summary>
Motivation: "图像"概念在量子力学中具有基础性地位，本文旨在建立一种新的纠缠图像框架，基于量子信息科学中重要的信道-态对偶关系

Method: 提出纠缠图像新框架，基于信道-态对偶关系，应用于量子算法设计

Result: 成功建立了纠缠图像框架，并展示了其在多体动力学模拟、量子场论、热物理等领域的应用

Conclusion: 纠缠图像为量子力学提供了新的理论框架，在量子信息科学中具有重要价值，为量子算法设计提供了新思路

Abstract: The notion of ``picture'' is fundamental in quantum mechanics. In this work, a new picture, which we call entanglement picture, is proposed based on the novel channel-state duality, whose importance is revealed in quantum information science. We illustrate the application of entanglement picture in quantum algorithms for the simulation of many-body dynamics, quantum field theory, thermal physics, and more generic quantities.

</details>


### [64] [$\mathcal{PT}$-symmetric cavity magnomechanics with gain-assisted transparency and amplification](https://arxiv.org/abs/2512.08612)
*Cham Oumie,Wu-Ming Liu,Kashif Ammar Yasir*

Main category: quant-ph

TL;DR: 研究宇称-时间对称腔磁机械系统中磁机械诱导透明现象，通过行波场诱导非厄米性实现从单窗口到多窗口透明谱调控，并展示增益辅助的非对称传输和Fano线型


<details>
  <summary>Details</summary>
Motivation: 探索宇称-时间对称性在磁机械系统中的应用，研究非厄米耦合如何影响磁机械诱导透明现象，为可重构量子信号处理和增强传感提供新平台

Method: 构建宇称-时间对称腔磁机械系统，包含微波腔模、钇铁石榴石球中的磁振子以及机械振动模。通过磁致伸缩相互作用实现磁振子-机械模杂化，引入行波场诱导的非厄米耦合，研究系统在厄米和非厄米区域的传输特性

Result: 在厄米区域，强光子-磁振子耦合产生单透明窗口，磁机械耦合使其分裂为双峰。非厄米耦合使系统进入宇称-时间破缺区域，透明现象变为增益辅助，产生非对称传输。通过调节腔失谐，可将磁机械透明转化为Fano线型，并在探测-磁振子失谐联合空间中观察到非对称增益辅助Fano脊。群延迟分析显示慢光和快光行为可通过耦合参数广泛调控

Conclusion: 宇称-时间对称腔磁机械系统为可重构量子信号处理和增强传感提供了有前景的平台，能够通过调控光子-磁振子耦合、磁机械耦合和非厄米强度实现从单窗口到多窗口透明谱的工程化设计

Abstract: We investigate magnomechanically induced transparency in a parity-time-symmetric cavity magnomechanical system with traveling-field-induced non-Hermiticity. The setup consists of a microwave cavity mode coupled to magnons in a single-crystal yttrium iron garnet sphere, which in turn are hybridized with a vibrational mechanical mode through magnetostrictive interaction. In the Hermitian regime, strong photon-magnon coupling generates a single transparency window in the cavity transmission, which splits into a doublet when the magnon is coherently hybridized with the mechanical mode via magnomechanical coupling. This establishes a versatile platform in which the transparency spectrum can be engineered from single- to multi-window response using experimentally accessible, scaled magnomechanical interactions. When a non-Hermitian coupling is introduced, the system enters a parity-time-broken regime in which the transparency ceases to be purely passive and becomes gain assisted, leading to asymmetric transmission with amplification on one side of the resonance and enhanced absorption on the other. By tuning the cavity detuning, we convert magnomechanical transparency into Fano-type line shapes with strongly non-Lorentzian phase dispersion and map their deformation into asymmetric, gain-assisted Fano ridges in the joint space of probe and magnon detunings. Finally, we analyze the associated group delay and show that both slow- and fast-light behavior can be widely tuned by varying the photon-magnon and magnomechanical couplings together with the non-Hermitian strength, highlighting parity-time-symmetric cavity magnomechanics as a promising platform for reconfigurable quantum signal processing and enhanced sensing.

</details>


### [65] [An Efficient Secret Communication Scheme for the Bosonic Wiretap Channel](https://arxiv.org/abs/2512.08623)
*Esther Hänggi,Iyán Méndez Veiga,Ligong Wang*

Main category: quant-ph

TL;DR: 提出一种基于玻色窃听信道的新型保密通信方案，使用激光器和直接光电探测器等现成硬件，结合随机性提取器、脉冲位置调制和Reed-Solomon码实现计算高效的安全通信。


<details>
  <summary>Details</summary>
Motivation: 在量子通信中，需要安全可靠的保密通信方案，特别是针对玻色窃听信道。现有方案可能面临硬件复杂、计算成本高或安全强度不足的问题，需要开发使用现成硬件、计算高效且能抵抗量子联合测量的方案。

Method: 方案结合三种关键技术：1) 随机性提取器确保安全性；2) 脉冲位置调制进行信息编码；3) Reed-Solomon码提供纠错能力。使用激光器和直接光电探测器等现成硬件实现。

Result: 方案能抵抗窃听者对观测到的量子态进行相干联合测量。在低光子流极限下，方案是渐近最优的，能达到与相同信道保密容量相同的主导项。

Conclusion: 该方案为玻色窃听信道提供了一种实用、计算高效且安全的保密通信方法，使用现成硬件实现，在低光子流条件下能达到理论最优性能。

Abstract: We propose a new secret communication scheme over the bosonic wiretap channel. It uses readily available hardware such as lasers and direct photodetectors. The scheme is based on randomness extractors, pulse-position modulation, and Reed-Solomon codes and is therefore computationally efficient. It is secure against an eavesdropper performing coherent joint measurements on the quantum states it observes. In the low-photon-flow limit, the scheme is asymptotically optimal and achieves the same dominant term as the secrecy capacity of the same channel.

</details>


### [66] [Parity erasure: a foundational principle for indefinite causal order](https://arxiv.org/abs/2512.08635)
*Zixuan Liu,Ognyan Oreshkov*

Main category: quant-ph

TL;DR: 该论文提出了一种称为"奇偶擦除"的信息理论原理，完全表征了不确定因果顺序的过程，这一原理不依赖于量子理论本身的形式化，而是从一般操作概率理论的公理推导而来。


<details>
  <summary>Details</summary>
Motivation: 当量子理论局部有效时，会出现不确定因果顺序的过程。目前缺乏对这些过程的信息理论表征，需要一种不依赖于量子理论形式化的通用原理来理解不确定因果结构中的信息交换。

Method: 作者识别并提出了"奇偶擦除"这一信息理论原理，从一般操作概率理论的公理集出发进行推导，而不是依赖于量子理论的具体形式化。

Result: 奇偶擦除原理完全表征了不确定因果顺序的过程，这一原理不仅适用于量子理论，也适用于一大类超越量子理论的理论，揭示了不确定因果结构场景中信息交换的基本性质。

Conclusion: 通过信息理论方法，奇偶擦除原理为理解不确定因果结构提供了基础性的表征工具，这种基于公理的方法比特定理论的形式化更具普适性，有助于深入理解信息交换的基本性质。

Abstract: Processes with indefinite causal order can arise when quantum theory is locally valid. Here, we identify an information-theoretic principle, termed parity erasure, that completely characterizes such processes. Our characterization does not rely on the formalism of quantum theory itself, but instead is derived from a set of axioms for general operational probabilistic theories, and thus holds also for a large class of theories beyond quantum theory. This informational approach reveals a fundamental property of information exchange in scenarios with indefinite causal structure.

</details>


### [67] [Strain sensitivity enhancement in a Grover-Michelson interferometer](https://arxiv.org/abs/2512.08638)
*Anthony D. Manni,Christopher R. Schwarze,David S. Simon,Abdoulaye Ndao,Alexander V. Sergienko*

Main category: quant-ph

TL;DR: 使用Grover硬币等无偏四端口散射器替代传统分束器，可提升Michelson干涉仪的相位检测分辨率，分析GMI中引力波引起的相位扰动产生的边带频率信噪比，并探讨光回收配置的进一步性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统Michelson干涉仪在引力波探测等应用中需要更高的相位检测分辨率，现有分束器限制了性能提升，需要探索新型光学元件来增强干涉仪的灵敏度。

Method: 使用方向无偏的四端口散射器（如Grover硬币）替代传统分束器，构建Grover-Michelson干涉仪（GMI），定量分析引力波引起的相位扰动产生的边带频率信噪比，并研究结合光回收配置的优化方案。

Result: GMI配置能显著增强Michelson干涉仪的相位检测分辨率，通过定量分析证明了信噪比的改善，结合光回收配置可进一步提升干涉仪性能。

Conclusion: Grover-Michelson干涉仪为高精度相位检测提供了有前景的新方案，通过新型散射器和光回收技术的结合，有望在引力波探测等应用中实现更高的灵敏度。

Abstract: The Michelson interferometric phase detection resolution can be enhanced by replacing conventional beam splitters with novel directionally unbiased four-port scatterers, such as Grover coins. We present a quantitative analysis of the noise-to-signal ratio of sideband frequencies generated by gravitational wave-induced phase perturbations in a Grover-Michelson interferometer (GMI). We discuss the principles of GMI signal enhancement and demonstrate how combining this configuration with additional light-recycling arrangements further enhances the performance.

</details>


### [68] [Quantum Brownian Motion as a Classical Stochastic Process in Phase Space](https://arxiv.org/abs/2512.08641)
*Dmitriy Kondaurov,Evgeny Polyakov*

Main category: quant-ph

TL;DR: 量子布朗粒子在Caldeira-Leggett模型中的精确动力学可以在任意温度下映射到相空间中的经典非马尔可夫随机过程


<details>
  <summary>Details</summary>
Motivation: 建立量子系统与经典随机过程之间的精确对应关系，为复杂量子驱动耗散协议的模拟提供新框架

Method: 从粒子与浴的相关热平衡态出发，证明二次势下的精确对应；对一般光滑势，利用密度矩阵在坐标表示中的强准对角性，以浴谱截断为小参数进行控制近似

Result: 建立了任意温度下量子布朗粒子动力学与经典非马尔可夫随机过程的精确映射，该框架能处理任意初始量子态（包括高度非经典叠加态）和外部操作测量

Conclusion: 该工作为量子开放系统的模拟提供了通用框架，通过经典随机过程精确描述量子动力学，特别适用于复杂驱动耗散量子协议的仿真

Abstract: We establish that the exact quantum dynamics of a Brownian particle in the Caldeira-Leggett model can be mapped, at any temperature, onto a classical, non-Markovian stochastic process in phase space. Starting from a correlated thermal equilibrium state between the particle and bath, we prove that this correspondence is exact for quadratic potentials under arbitrary quantum state preparations of the particle itself. For more general, smooth potentials, we identify and exploit a natural small parameter: the density matrix becomes strongly quasidiagonal in the coordinate representation, with its off-diagonal width shrinking as the bath's spectral cutoff increases, providing a controlled parameter for accurate approximation. The framework is fully general: arbitrary initial quantum states-including highly non-classical superpositions-are incorporated via their Wigner functions, which serve as statistical weights for trajectory ensembles. Furthermore, the formalism naturally accommodates external manipulations and measurements modeled by preparation functions acting at arbitrary times, enabling the simulation of complex driven-dissipative quantum protocols.

</details>


### [69] [Perfect continuous-variable quantum microcombs](https://arxiv.org/abs/2512.08650)
*Kangkang Li,Yue Wang,Ze Wang,Xin Zhou,Jincheng Li,Yinke Cheng,Binyan Wu,Qihuang Gong,Bei-Bei Li,Qi-Fan Yang*

Main category: quant-ph

TL;DR: 研究人员通过工程化微谐振器模式和优化泵浦条件，实现了包含14个独立双模压缩态的连续变量量子微梳，每个态在0.7 THz带宽内展现超过4 dB的原始压缩，为可扩展集成量子技术奠定基础。


<details>
  <summary>Details</summary>
Motivation: 量子微梳作为紧凑、多路复用的纠缠模式源，在连续变量量子信息处理中具有重要应用。然而，由于色散剖面的不对称性和异常，实现频谱均匀的压缩态仍然具有挑战性。

Method: 结合工程化模式谱的微谐振器和优化泵浦条件，克服色散不对称性限制，实现均匀的双模压缩态生成。

Result: 实现了包含14个独立双模压缩态的连续变量量子微梳，每个态在0.7 THz带宽内展现超过4 dB的原始压缩（最高达4.3 dB），性能均匀且优异。

Conclusion: 这项研究实现了均匀、高性能的量子资源，代表了向可扩展、集成化连续变量量子技术迈出的关键一步，为超越经典极限的量子操作奠定了基础。

Abstract: Quantum microcombs generated in high-Q microresonators provide compact, multiplexed sources of entangled modes for continuous-variable (CV) quantum information processing. While deterministic generation of CV states via Kerr-induced two-mode squeezing has been demonstrated, achieving spectrally uniform squeezing remains challenging because of asymmetry and anomalies in the dispersion profile. Here we overcome these limitations by combining a microresonator with an engineered mode spectrum and optimized pump conditions. We realize a CV quantum microcomb comprising 14 independent two-mode squeezed states, each exhibiting more than 4 dB of raw squeezing (up to 4.3 dB) across a 0.7 THz bandwidth. This uniform, high-performance quantum resource represents a key step toward scalable, integrated CV quantum technologies operating beyond classical limits.

</details>


### [70] [Spectroscopic readout of chiral photonic topology in a single-cavity spin-orbit-coupled Bose-Einstein condensate](https://arxiv.org/abs/2512.08662)
*Kashif Ammar Yasir,Gao Xianlong*

Main category: quant-ph

TL;DR: 提出通过单驱动光学腔中自旋轨道耦合BEC的腔透射功率谱密度来光谱学读取手性光子拓扑的框架，无需体带层析即可从光谱数据推断拓扑特性。


<details>
  <summary>Details</summary>
Motivation: 传统拓扑光子相识别通常需要能带重构、稳态传输或边缘模实空间成像，这些方法较为复杂。本文旨在开发一种更直接的光谱学方法，通过最小腔QED架构中的噪声光谱学来检测拓扑序。

Method: 在包含自旋轨道耦合玻色-爱因斯坦凝聚体的单驱动光学腔中，利用腔透射功率谱密度作为动量和频率分辨光子陈数标记的直接可测量代理。分析不同耗散机制下的光谱特征，特别是损耗主导和增益主导两种不同耗散不平衡情况。

Result: 在损耗主导区域，功率谱密度呈现狄拉克型带隙混合模式，陈数标记消失，表现为平庸相。当耗散不平衡反转时，出现跨越带隙的明亮光谱脊，与陈数标记和贝里曲率峰值共定位。复杂光谱揭示了宇称时间对称合并和增益-损耗分岔，标记了异常点并实现了手性、跨越带隙的输运。

Conclusion: 通过将噪声光谱学与几何和非厄米拓扑在最小腔QED架构中联系起来，为驱动量子系统中拓扑序的光谱学检测提供了框架。该方法为广泛光-物质平台上的紧凑、可调谐拓扑光子学提供了途径，为混合量子系统中拓扑相的研究和控制提供了新方法。

Abstract: Topological photonic phases are typically identified through band reconstruction, steady-state transmission, or real-space imaging of edge modes. In this work, we present a framework for spectroscopic readout of chiral photonic topology in a single driven optical cavity containing a spin-orbit-coupled Bose-Einstein condensate. We demonstrate that the cavity transmission power spectral density provides a direct and measurable proxy for a momentum- and frequency-resolved photonic Chern marker, enabling topological characteristics to be inferred from spectral data without the need for bulk-band tomography. In the loss-dominated regime, where cavity decay exceeds atomic dissipation, the power spectral density exhibits Dirac-like gapped hybrid modes with a vanishing Chern marker, indicating a trivial phase. When the dissipation imbalance is reversed, a bright, gap-spanning spectral ridge emerges, co-localized with peaks in both the Chern marker and Berry curvature. The complex spectrum reveals parity-time symmetric coalescences and gain-loss bifurcations, marking exceptional points and enabling chiral, gap-traversing transport. By linking noise spectroscopy to geometric and non-Hermitian topology in a minimal cavity-QED architecture, this work provides a framework for spectroscopic detection of topological order in driven quantum systems. This approach offers a pathway to compact, tunable topological photonics across a broad range of light-matter platforms, providing a method for the study and control of topological phases in hybrid quantum systems.

</details>


### [71] [A Unified Framework for Optimizing Uniformly Controlled Structures in Quantum Circuits](https://arxiv.org/abs/2512.08675)
*Chengzhuo Xu,Xiao Chen,Xi Li,Zhihao Liu,Zhigang Li*

Main category: quant-ph

TL;DR: 提出受限均匀控制门(rUCG)作为统一代数模型，将多种均匀控制结构纳入统一框架，显著降低电路深度和门复杂度


<details>
  <summary>Details</summary>
Motivation: 量子算法中普遍存在形式为Σ_c|c⟩⟨c|⊗U_c的酉算子，包括标准均匀控制门(UCG)和各种均匀控制结构电路，但缺乏统一的复杂度分析框架

Method: 引入rUCG作为统一代数模型，基于2-可分阿贝尔群建模控制门集合；提出k稀疏版本(k-rUCG)；开发通用分解框架，利用控制空间稀疏性优化电路

Result: n控制rUCG的门复杂度从O(n2^n)降至O(2^n)，电路深度从O(2^n log n)降至O(2^n log n/n)；k-rUCG获得相同优化系数；在QAOA和量子态制备中验证深度和规模减少

Conclusion: rUCG模型及其分解框架将结构不同的电路统一到单一渐近最优合成范式下，为均匀控制结构提供系统化的复杂度优化方法

Abstract: Quantum unitaries of the form ${Σ_{c}\ket{c}\bra{c}\otimes U_{c}}$ are ubiquitous in quantum algorithms. This class encompasses not only standard uniformly controlled gates (UCGs) but also a wide range of circuits with uniformly controlled structures. However, their circuit-depth and gate-count complexities have not been systematically analyzed within a unified framework. In this work, we study the general decomposition problem for UCG and UCG-like structure. We then introduce the restricted Uniformly Controlled Gates (rUCGs) as a unified algebraic model, defined by a 2-divisible Abelian group that models the controlled gate set. This model captures uniformly controlled rotations, multi-qubit uniformly controlled gates, and diagonal unitaries. Furthermore, this model also naturally incorporates k-sparse version (k-rUCGs), where only a subset of control qubits participate in each multi-qubit gate. Building on this algebraic model, we develop a general framework. For an n-control rUCG, the framework reduce the gate complexity from ${O(n2^n)}$ to ${O(2^n})$ and the circuit depth from ${O(2^n\log n)}$ to ${O(2^n\log n/n)}$. The framework further provides systematic size and depth bounds for k-rUCGs by exploiting sparsity in the control space, with same optimization coefficient as rUCG, respectively. Empirical evaluations on representative QAOA circuits and quantum state preparation both confirm reductions in depth and size. Crucially, these results highlight that the rUCG model and its associated decomposition framework unify circuits previously considered structurally distinct under a single, asymptotically optimal synthesis paradigm.

</details>


### [72] [Non-Hermitian symmetry breaking and Lee-Yang theory for quantum XYZ and clock models](https://arxiv.org/abs/2512.08687)
*Tian-Yi Gu,Gaoyong Sun*

Main category: quant-ph

TL;DR: 该论文将Lee-Yang理论推广到更广泛的量子模型，研究在复磁场下XY、XXZ、XYZ和ℤ₃时钟模型中的非厄米对称性破缺和保真度零点现象。


<details>
  <summary>Details</summary>
Motivation: 扩展Lee-Yang理论框架，将其应用于更广泛的量子模型，以理解复磁场如何诱导对称性破缺和保真度零点，从而更全面地描述量子相变。

Method: 研究一维XY、XXZ、XYZ和ℤ₃时钟模型在复外磁场下的行为，分析复磁场如何破坏宇称对称性，以及如何导致基态在不同宇称扇区间的振荡和保真度零点。

Result: 对于XY、XXZ和XYZ模型，复磁场破坏宇称对称性，诱导基态在两个宇称扇区间振荡，在有序相中产生保真度零点。对于ℤ₃时钟模型，复磁场使基态能量实部在中性扇区和带电扇区间分裂，但保持带电扇区内的简并，仅当投影掉一个带电扇区时才出现保真度零点。

Conclusion: 该研究成功将Lee-Yang理论推广到更广泛的量子模型，揭示了复磁场诱导的对称性破缺机制和保真度零点行为，为理解量子相变提供了新的理论框架。

Abstract: Lee-Yang theory offers a unifying framework for understanding classical phase transitions and dynamical quantum phase transitions through the analysis of partition functions and Loschmidt echoes. Recently, this framework is extended to characterize quantum phase transitions in arXiv:2509.20258 by introducing the concepts of non-Hermitian symmetry breaking and fidelity zeros. Here, we generalize the theory by studying a broad class of quantum models, including the XY model, the XXZ model, the XYZ model, and the $\mathbb{Z}_3$ clock model in one dimension, subject to complex external magnetic field. For the XY, XXZ and XYZ models, we find that the complex field breaks parity symmetry and induces oscillations of the ground state between the two parity sectors, giving rise to fidelity zeros within the ordered phases. For the $\mathbb{Z}_3$ clock model, the complex field splits the real part of the ground-state energy between the neutral sector ($q=0$) and the charged sectors ($q=1,2$), while preserving the degeneracy within the charged sector. Fidelity zeros arise only after projecting out one of the charged sectors, and the finite-size scaling of these zeros produces critical exponents fully consistent with analytical predictions.

</details>


### [73] [Geometry-driven transitions in sparse long-range spin models with cold atoms](https://arxiv.org/abs/2512.08709)
*Alex Gunning,Aydin Deger,Sridevi Kuriyattil,Andrew J. Daley*

Main category: quant-ph

TL;DR: 研究稀疏长程自旋模型中几何结构对临界行为的影响，通过可调相互作用连续改变耦合图的度量、拓扑和维度，几何结构驱动临界性，并与Rydberg激发镊子阵列实现相联系。


<details>
  <summary>Details</summary>
Motivation: 探索几何结构在稀疏长程自旋模型临界行为中的作用，理解耦合图的几何特性如何驱动相变，并建立与实验系统（特别是Rydberg激发镊子阵列）的联系。

Method: 研究可调相互作用模型，通过连续调节相互作用参数来改变耦合图的度量、拓扑和维度，分析几何结构变化与相边界的关系，并讨论在镊子阵列中的实现方案。

Result: 几何结构是临界行为的主要驱动力，耦合图的结构变化与相边界重合并决定相边界，在某些情况下可以通过原子在镊子中的布局实现保持普适特征的相变。

Conclusion: 几何结构在稀疏长程自旋模型的临界行为中起关键作用，这种框架自然地与Rydberg激发镊子阵列实现相联系，为近期实验中的相变实现提供了简化方案。

Abstract: We explore the influence of geometry in the critical behavior of sparse long-range spin models. We examine a model with interactions that can be continuously tuned to induce distinct changes in the metric, topology, and dimensionality of the coupling graph. This underlying geometry acts as the driver of criticality, with structural changes in the graph coinciding with and dictating the phase boundaries. We further discuss how this framework connects naturally to realizations in tweezer arrays with Rydberg excitations. In certain cases, the effective geometry can be incorporated in the layout of atoms in tweezers to realize phase transitions that preserve universal features, simplifying their implementation in near-term experiments.

</details>


### [74] [Non-abelian quantum double models from iterated gauging](https://arxiv.org/abs/2512.08749)
*David Blanik,José Garre-Rubio*

Main category: quant-ph

TL;DR: 从边界对称性重建(2+1)D量子双模型，扩展到非阿贝尔群，使用矩阵乘积算符框架进行范畴化测量，并扩展到(3+1)D模型


<details>
  <summary>Details</summary>
Motivation: 现有构造仅适用于阿贝尔群，需要扩展到非阿贝尔群，从边界对称性完全重建量子双模型

Method: 使用基于矩阵乘积算符的范畴化测量框架，通过迭代测量过程，从一维输入态构建量子双模型，并推导出对偶涌现的G对称性

Result: 成功重建所有有限群的(2+1)D量子双模型，将可能的能隙边界与一维输入态的量子相联系起来，并扩展到(3+1)D量子双模型的构造

Conclusion: 通过迭代测量边界对称性可以完全重建量子双模型，为理解高维拓扑相及其边界提供了系统框架

Abstract: We reconstruct all (2+1)D quantum double models of finite groups from their boundary symmetries through the repeated application of a gauging procedure, extending the existing construction for abelian groups. We employ the recently proposed categorical gauging framework, based on matrix product operators (MPOs), to derive the appropriate gauging procedure for the $\mathsf{Rep}\, G$ symmetries appearing in our construction and give an explicit description of the dual emergent $G$ symmetry, which is our main technical contribution. Furthermore, we relate the possible gapped boundaries of the quantum double models to the quantum phases of the one-dimensional input state to the iterated gauging procedure. Finally, we propose a gauging procedure for 1-form $\mathsf{Rep}\, G$ symmetries on a two-dimensional lattice and use it to extend our results to the construction of (3+1)D quantum doubles models through the iterative gauging of (2+1)-dimensional symmetries.

</details>


### [75] [Floquet Topological Frequency-Converting Amplifier](https://arxiv.org/abs/2512.08880)
*Adrian Parra-Rodriguez,Miguel Clavero-Rubio,Philippe Gigon,Tomás Ramos,Álvaro Gómez-León,Diego Porras*

Main category: quant-ph

TL;DR: 该论文提出了一种通过调制频率和衰减的单谐振子实现非厄米合成晶格的方法，支持定向放大和频率转换，为量子技术中的拓扑放大提供了简单可行的实现路径。


<details>
  <summary>Details</summary>
Motivation: 研究非厄米拓扑放大在量子技术中的实现，特别是寻找简单且实验可行的方案。当前需要将拓扑物理与驱动耗散系统结合，以在频率空间中实现有效的电场梯度和拓扑特性。

Method: 采用驱动耗散的Floquet模型，通过调制单个谐振子的频率和衰减，在频率空间中构建非厄米合成晶格。使用Floquet-Green函数及其加倍空间表示来分析系统，并通过局部绕数来准确描述拓扑特性。

Result: 识别出支持定向放大和频率转换的拓扑区域，系统模式结构可用具有Dirac锥和孤子零模的Jackiw-Rebbi类连续理论描述。该方案为超导电路等当前量子技术提供了自然可实现的非厄米拓扑放大路径。

Conclusion: 该研究建立了一种简单且实验可行的非厄米拓扑放大实现方法，通过单个调制谐振子在频率空间中创建合成晶格，为量子技术中的拓扑放大应用开辟了新途径。

Abstract: We introduce a driven-dissipative Floquet model in which a single harmonic oscillator with modulated frequency and decay realizes a non-Hermitian synthetic lattice with an effective electric field gradient in frequency space. Using the Floquet-Green's function and its doubled-space representation, we identify a topological regime that supports directional amplification and frequency conversion, accurately captured by a local winding number. The underlying mode structure is well described by a Jackiw-Rebbi-like continuum theory with Dirac cones and solitonic zero modes in synthetic frequency. Our results establish a simple and experimentally feasible route to non-Hermitian topological amplification, naturally implementable in current quantum technologies such as superconducting circuits.

</details>


### [76] [Emergent Non-Markovianity in Logical Qubit Dynamics](https://arxiv.org/abs/2512.08893)
*Jalan A. Ziyad,Robin Blume-Kohout,Kenneth Rudinger*

Main category: quant-ph

TL;DR: 量子纠错码中的逻辑量子比特即使底层物理噪声是马尔可夫的，也会表现出非马尔可夫动力学演化。论文定义了适用于逻辑门操作的马尔可夫性条件，并证明当物理量子比特在每轮纠错后不一定返回码空间时，马尔可夫物理操作会产生非马尔可夫性。


<details>
  <summary>Details</summary>
Motivation: 研究量子纠错码中逻辑量子比特如何从马尔可夫物理噪声中产生非马尔可夫动力学，理解这种涌现现象，并为早期容错量子设备中基于门的表征技术提供可靠使用条件。

Method: 定义适用于逻辑门操作的马尔可夫性条件，将逻辑操作与其物理实现（对编码逻辑量子比特的数据量子比特的操作）联系起来。分析小型量子纠错码，研究简单物理噪声模型下的动力学行为。

Result: 小型量子纠错码即使在简单物理噪声模型下也表现出非马尔可夫动力学。当物理量子比特在每轮纠错后不一定返回码空间时，马尔可夫物理操作会产生非马尔可夫性，此时综合征量子比特充当记忆介质，介导时间相关性并导致马尔可夫条件被违反。

Conclusion: 量子纠错码中的逻辑量子比特可以从马尔可夫物理噪声中涌现出非马尔可夫动力学，特别是当物理量子比特不总是返回码空间时。论文量化了这种涌现的非马尔可夫性，并为早期容错量子设备中可靠使用门集层析等表征技术提出了充分条件。

Abstract: Logical qubits encoded in quantum error correcting codes can exhibit non-Markovian dynamical evolution, even when the underlying physical noise is Markovian. To understand this emergent non-Markovianity, we define a Markovianity condition appropriate to logical gate operations, and study it by relating logical operations to their physical implementation (operations on the data qubits into which the logical qubit is encoded). We apply our analysis to small quantum codes, and show that they exhibit non-Markovian dynamics even for very simple physical noise models. We show that non-Markovianity can emerge from Markovian physical operations if (and only if) the physical qubits are not necessarily returned to the code subspace after every round of QEC. In this situation, the syndrome qubits can act as a memory, mediating time correlations and enabling violation of the Markov condition. We quantify the emergent non-Markovianity in simple examples, and propose sufficient conditions for reliable use of gate-based characterization techniques like gate set tomography in early fault-tolerant quantum devices.

</details>


### [77] [Deterministic randomness extraction for semi-device-independent quantum random number generation](https://arxiv.org/abs/2512.08900)
*Pablo Tikas Pueyo,Tomás Fernández Martos,Gabriel Senno*

Main category: quant-ph

TL;DR: 该论文将确定性随机数提取器从设备无关场景扩展到准备-测量场景，在重叠假设下实现半设备无关的随机数生成。


<details>
  <summary>Details</summary>
Motivation: 经典信息论中，无法从任意熵源中确定性地提取理想随机性，但如果有额外知识（如独立伯努利试验）则可能。量子熵源中，Foreman和Masanes在设备无关场景中实现了确定性提取器。本文旨在将这种构造扩展到准备-测量场景。

Method: 将Foreman和Masanes的确定性提取器构造扩展到准备-测量场景，证明在重叠假设下这些函数也是半设备无关设置中无记忆设备的提取器，并在新型实验相关行为族上模拟随机数生成协议。

Result: 成功将提取器扩展到准备-测量场景，在重叠假设下实现半设备无关随机数生成。模拟显示在7×10³轮次后即可获得正密钥率。

Conclusion: 确定性提取器可扩展到准备-测量场景，在重叠假设下实现半设备无关随机数生成，为实际实验应用提供了可行的方案。

Abstract: It is a well-known fact in classical information theory that no deterministic procedure can extract close-to-ideal randomness from an arbitrary entropy source. On the other hand, if additional knowledge about the source is available -- e.g., that it is a sequence of independent Bernoulli trials -- then deterministic extractors do exist. For quantum entropy sources, where in addition to classical random variables we consider quantum side information, the use of extra knowledge about their structure was pioneered in a recent publication [C. Foreman and L. Masanes, Quantum 9, 1654 (2025)]. In that work, the authors provide deterministic extractors for device-independent randomness generation with memoryless devices achieving a sufficiently high CHSH score. In this work, we extend their construction to the prepare-and-measure scenario. Specifically, we prove that the considered functions are also extractors for memoryless devices in a semi-device-independent setting under an overlap assumption on the prepared quantum states. We then simulate the resulting randomness generation protocol on a novel and experimentally relevant family of behaviors, observing positive key rates already for $7\times 10^3$ rounds.

</details>


### [78] [SAQ: Stabilizer-Aware Quantum Error Correction Decoder](https://arxiv.org/abs/2512.08914)
*David Zenati,Eliya Nachmani*

Main category: quant-ph

TL;DR: SAQ-Decoder：结合Transformer学习和约束感知后处理的量子纠错解码框架，实现接近最大似然精度和线性计算复杂度，在表面码上达到接近理论极限的性能。


<details>
  <summary>Details</summary>
Motivation: 量子纠错解码面临精度与效率的权衡：传统方法如MWPM在不同噪声模型下性能不稳定且复杂度高，张量网络解码器精度高但计算成本过高，现有神经解码器复杂度低但精度不足。需要一种既能达到高精度又具有计算效率的解码方法。

Method: 提出SAQ-Decoder统一框架：1）双流Transformer架构，非对称注意力模式处理综合征和逻辑信息；2）可微逻辑损失函数，通过有限域上的平滑近似直接优化逻辑错误率；3）结合约束感知后处理。

Result: 在表面码上：独立噪声下错误阈值10.99%（接近ML界限11.0%），去极化噪声下18.6%（接近ML界限18.9%）。在精度、复杂度和参数效率上均优于现有神经和经典基线方法。

Conclusion: 学习型解码器能够同时实现竞争性解码精度和计算效率，满足实用容错量子计算系统的关键需求，解决了量子纠错解码的精度-效率权衡问题。

Abstract: Quantum Error Correction (QEC) decoding faces a fundamental accuracy-efficiency tradeoff. Classical methods like Minimum Weight Perfect Matching (MWPM) exhibit variable performance across noise models and suffer from polynomial complexity, while tensor network decoders achieve high accuracy but at prohibitively high computational cost. Recent neural decoders reduce complexity but lack the accuracy needed to compete with computationally expensive classical methods. We introduce SAQ-Decoder, a unified framework combining transformer-based learning with constraint aware post-processing that achieves both near Maximum Likelihood (ML) accuracy and linear computational scalability with respect to the syndrome size. Our approach combines a dual-stream transformer architecture that processes syndromes and logical information with asymmetric attention patterns, and a novel differentiable logical loss that directly optimizes Logical Error Rates (LER) through smooth approximations over finite fields. SAQ-Decoder achieves near-optimal performance, with error thresholds of 10.99% (independent noise) and 18.6% (depolarizing noise) on toric codes that approach the ML bounds of 11.0% and 18.9% while outperforming existing neural and classical baselines in accuracy, complexity, and parameter efficiency. Our findings establish that learned decoders can simultaneously achieve competitive decoding accuracy and computational efficiency, addressing key requirements for practical fault-tolerant quantum computing systems.

</details>


### [79] [Autonomous multi-ion optical clock with on-chip integrated photonic light delivery](https://arxiv.org/abs/2512.08921)
*Tharon D. Morrison,Joonhyuk Kwon,Matthew A. Delaney,David R. Leibrandt,Daniel Stick,Hayden J. McGuinness*

Main category: quant-ph

TL;DR: 首次展示基于片上波导的全自主运行光学钟，使用四个镱离子在室温表面电极阱中实现，短期频率不稳定性达3.14×10⁻¹⁴/√τ


<details>
  <summary>Details</summary>
Motivation: 集成光子学在囚禁离子系统中对于便携式光学原子钟和可扩展量子计算机至关重要，但系统级集成所有功能仍是关键挑战

Method: 使用四个镱离子在室温多站点表面电极阱中，所有时钟操作通过片上波导传输的光完成，采用自动化离子穿梭和重加载来缓解离子损失

Result: 实现了短期频率不稳定性为3.14(5)×10⁻¹⁴/√τ的全自主运行光学钟，展示了系统通过持续自主操作的鲁棒性

Conclusion: 这项工作超越了组件级功能，为下一代便携式多离子量子传感器和计算机建立了可行且稳健的架构

Abstract: Integrated photonics in trapped-ion systems are critical for the realization of applications such as portable optical atomic clocks and scalable quantum computers. However, system-level integration of all required functionalities remains a key challenge. In this work, we demonstrate an autonomously operating optical clock having a short-term frequency instability of $3.14(5)\times 10^{-14} / \sqrtτ$ using an ensemble of four \ybion ions trapped in a multi-site surface-electrode trap at room temperature. All clock operations are performed with light delivered via on-chip waveguides. We showcase the system's resilience through sustained, autonomous operation featuring automated ion shuttling and reloading to mitigate ion loss during interleaved clock measurements. This work paves the way beyond component-level functionality to establish a viable and robust architecture for the next generation of portable, multi-ion quantum sensors and computers.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [80] [ThreadWeaver: Adaptive Threading for Efficient Parallel Reasoning in Language Models](https://arxiv.org/abs/2512.07843)
*Long Lian,Sida Wang,Felix Juefei-Xu,Tsu-Jui Fu,Xiuyu Li,Adam Yala,Trevor Darrell,Alane Suhr,Yuandong Tian,Xi Victoria Lin*

Main category: cs.LG

TL;DR: ThreadWeaver是一个自适应并行推理框架，在保持与顺序推理模型相当准确率的同时，显著降低推理延迟，通过并行轨迹生成、trie训练推理协同设计和并行感知强化学习实现高效并行推理。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型推理时顺序解码导致高延迟，现有并行推理方法要么局限于监督行为克隆，要么相比顺序链式思维基线准确率显著下降，且需要定制化推理引擎，部署复杂。

Method: 1) 两阶段并行轨迹生成器产生大规模高质量并行标注的CoT数据用于监督微调；2) trie训练推理协同设计，可在任何现成自回归推理引擎上实现并行推理，无需修改位置嵌入或KV缓存；3) 并行感知强化学习框架，教导模型平衡准确率和有效并行化。

Result: 在六个数学推理基准测试中，基于Qwen3-8B训练的ThreadWeaver达到与前沿顺序推理模型相当的准确率（平均71.9%，AIME24上79.9%），同时提供最高1.53倍的平均token延迟加速，建立了准确率与效率之间的新帕累托前沿。

Conclusion: ThreadWeaver框架在保持准确率的同时显著提升推理效率，通过创新的数据生成、训练推理协同设计和强化学习，实现了自适应并行推理，无需定制化推理引擎，易于部署。

Abstract: Scaling inference-time computation has enabled Large Language Models (LLMs) to achieve strong reasoning performance, but inherently sequential decoding leads to substantial latency, especially on complex tasks. Recent work on adaptive parallel reasoning aims to improve inference efficiency by decomposing the problem-solving process into concurrent reasoning threads when beneficial. However, existing methods on realistic tasks are either limited to supervised behavior cloning or exhibit significant accuracy drops compared to widely-used sequential long chain-of-thought (CoT) baselines. Moreover, many require customized inference engines, complicating deployment. We introduce ThreadWeaver, a framework for adaptive parallel reasoning that achieves accuracy on par with popular sequential reasoning models of comparable size while significantly reducing inference latency. ThreadWeaver's performance stems from three key innovations: 1) a two-stage parallel trajectory generator that produces large-scale, high-quality CoT data with parallel annotations for supervised fine-tuning; 2) a trie-based training-inference co-design that enables parallel reasoning on any off-the-shelf autoregressive inference engine without modifying position embeddings or KV caches; and 3) a parallelization-aware reinforcement learning framework that teaches the model to balance accuracy with effective parallelization. Across six challenging mathematical reasoning benchmarks, ThreadWeaver trained atop Qwen3-8B achieves accuracy comparable to cutting-edge sequential reasoning models (71.9% on average and 79.9% on AIME24) while delivering up to 1.53x average speedup in token latency, establishing a new Pareto frontier between accuracy and efficiency.

</details>


### [81] [Space Alignment Matters: The Missing Piece for Inducing Neural Collapse in Long-Tailed Learning](https://arxiv.org/abs/2512.07844)
*Jinping Wang,Zhiqiang Gao,Zhiwu Xie*

Main category: cs.LG

TL;DR: 该论文针对长尾分布下特征与分类器权重空间不对齐的问题，提出了三种显式对齐策略，显著提升了现有长尾方法的性能。


<details>
  <summary>Details</summary>
Motivation: 在长尾分布场景中，严重的样本不平衡阻碍了神经坍缩现象的出现，导致特征均值与分类器权重无法形成等角紧框架，进而影响模型泛化性能。现有方法主要关注恢复ETF几何结构，但忽略了特征空间与分类器权重空间之间的不对齐问题。

Method: 通过最优误差指数分析理论量化不对齐的危害，并提出了三种即插即用的显式对齐策略：1）特征-分类器对齐；2）空间变换对齐；3）正则化对齐。这些策略无需改变现有长尾方法的网络架构。

Result: 在CIFAR-10-LT、CIFAR-100-LT和ImageNet-LT数据集上的大量实验表明，所提策略能持续提升现有基线方法的性能，并达到了最先进的性能水平。

Conclusion: 特征与分类器权重空间的对齐问题在长尾学习中至关重要，通过理论分析和提出的三种对齐策略，有效解决了该问题，显著提升了长尾分类的性能。

Abstract: Recent studies on Neural Collapse (NC) reveal that, under class-balanced conditions, the class feature means and classifier weights spontaneously align into a simplex equiangular tight frame (ETF). In long-tailed regimes, however, severe sample imbalance tends to prevent the emergence of the NC phenomenon, resulting in poor generalization performance. Current efforts predominantly seek to recover the ETF geometry by imposing constraints on features or classifier weights, yet overlook a critical problem: There is a pronounced misalignment between the feature and the classifier weight spaces. In this paper, we theoretically quantify the harm of such misalignment through an optimal error exponent analysis. Built on this insight, we propose three explicit alignment strategies that plug-and-play into existing long-tail methods without architectural change. Extensive experiments on the CIFAR-10-LT, CIFAR-100-LT, and ImageNet-LT datasets consistently boost examined baselines and achieve the state-of-the-art performances.

</details>


### [82] [CarBench: A Comprehensive Benchmark for Neural Surrogates on High-Fidelity 3D Car Aerodynamics](https://arxiv.org/abs/2512.07847)
*Mohamed Elrefaie,Dule Shu,Matt Klenk,Faez Ahmed*

Main category: cs.LG

TL;DR: CarBench是首个针对大规模3D汽车空气动力学仿真的综合基准测试，在最大的公开汽车空气动力学数据集DrivAerNet++（包含8000多个高保真仿真）上评估了11种最先进模型，涵盖神经算子、几何深度学习、Transformer求解器和隐式场网络等架构。


<details>
  <summary>Details</summary>
Motivation: 尽管大规模CFD数据集为机器学习在空气动力学和工程设计中的应用提供了新机会，但工程设计中缺乏大规模数值仿真的标准化基准。现有计算机视觉和自然语言处理领域的基准测试推动了算法创新，但工程仿真领域尚未建立类似的标准化评估框架。

Method: 在DrivAerNet++数据集（超过8000个高保真汽车仿真）上评估11种架构：神经算子方法（如傅里叶神经算子）、几何深度学习（PointNet、RegDGCNN、PointMAE、PointTransformer）、Transformer求解器（Transolver、Transolver++、AB-UPT）和隐式场网络（TripNet）。除了标准插值任务，还进行跨类别实验，将在单一汽车原型上训练的Transformer求解器评估于未见类别。

Result: 评估涵盖预测准确性、物理一致性、计算效率和统计不确定性。开源了基准框架，包括训练流程、基于bootstrap重采样的不确定性估计例程和预训练模型权重，为从高保真CFD仿真中进行大规模学习建立了首个可复现基础。

Conclusion: CarBench填补了工程设计中大规模数值仿真标准化基准的空白，为数据驱动工程提供了首个可复现的评估框架，将加速高保真CFD仿真中机器学习方法的发展。

Abstract: Benchmarking has been the cornerstone of progress in computer vision, natural language processing, and the broader deep learning domain, driving algorithmic innovation through standardized datasets and reproducible evaluation protocols. The growing availability of large-scale Computational Fluid Dynamics (CFD) datasets has opened new opportunities for applying machine learning to aerodynamic and engineering design. Yet, despite this progress, there exists no standardized benchmark for large-scale numerical simulations in engineering design. In this work, we introduce CarBench, the first comprehensive benchmark dedicated to large-scale 3D car aerodynamics, performing a large-scale evaluation of state-of-the-art models on DrivAerNet++, the largest public dataset for automotive aerodynamics, containing over 8,000 high-fidelity car simulations. We assess eleven architectures spanning neural operator methods (e.g., Fourier Neural Operator), geometric deep learning (PointNet, RegDGCNN, PointMAE, PointTransformer), transformer-based neural solvers (Transolver, Transolver++, AB-UPT), and implicit field networks (TripNet). Beyond standard interpolation tasks, we perform cross-category experiments in which transformer-based solvers trained on a single car archetype are evaluated on unseen categories. Our analysis covers predictive accuracy, physical consistency, computational efficiency, and statistical uncertainty. To accelerate progress in data-driven engineering, we open-source the benchmark framework, including training pipelines, uncertainty estimation routines based on bootstrap resampling, and pretrained model weights, establishing the first reproducible foundation for large-scale learning from high-fidelity CFD simulations, available at https://github.com/Mohamedelrefaie/CarBench.

</details>


### [83] [RaX-Crash: A Resource Efficient and Explainable Small Model Pipeline with an Application to City Scale Injury Severity Prediction](https://arxiv.org/abs/2512.07848)
*Di Zhu,Chen Xie,Ziwei Wang,Haoyun Zhang*

Main category: cs.LG

TL;DR: RaX-Crash是一个资源高效、可解释的小模型管道，用于预测纽约市机动车碰撞事故的伤害严重程度，结合结构化特征工程和小型语言模型，在保持可扩展性的同时提供可解释的结果。


<details>
  <summary>Details</summary>
Motivation: 纽约市每年报告超过10万起机动车碰撞事故，造成严重的伤害和公共卫生负担。需要开发资源高效且可解释的模型来预测伤害严重程度，以支持城市规模的伤害分析。

Method: 整合三个链接表（包含数千万条记录），构建统一特征模式的分区存储，训练紧凑的树集成模型（随机森林和XGBoost）在工程化的表格特征上，并与本地部署的小型语言模型（SLMs）使用文本摘要提示进行比较。

Result: 在时间保留测试集上，XGBoost和随机森林分别达到0.7828和0.7794的准确率，明显优于SLMs（0.594和0.496）；类别不平衡分析显示简单的类别加权可以提高致命事故的召回率；SHAP归因分析突出了人类脆弱性因素、时间和地点是预测严重程度的主要驱动因素。

Conclusion: 可解释的小模型集成仍然是城市规模伤害分析的强大基线，而将表格预测器与SLM生成的叙述相结合的混合管道可以在不牺牲可扩展性的情况下改善沟通效果。

Abstract: New York City reports over one hundred thousand motor vehicle collisions each year, creating substantial injury and public health burden. We present RaX-Crash, a resource efficient and explainable small model pipeline for structured injury severity prediction on the official NYC Motor Vehicle Collisions dataset. RaX-Crash integrates three linked tables with tens of millions of records, builds a unified feature schema in partitioned storage, and trains compact tree based ensembles (Random Forest and XGBoost) on engineered tabular features, which are compared against locally deployed small language models (SLMs) prompted with textual summaries. On a temporally held out test set, XGBoost and Random Forest achieve accuracies of 0.7828 and 0.7794, clearly outperforming SLMs (0.594 and 0.496); class imbalance analysis shows that simple class weighting improves fatal recall with modest accuracy trade offs, and SHAP attribution highlights human vulnerability factors, timing, and location as dominant drivers of predicted severity. Overall, RaX-Crash indicates that interpretable small model ensembles remain strong baselines for city scale injury analytics, while hybrid pipelines that pair tabular predictors with SLM generated narratives improve communication without sacrificing scalability.

</details>


### [84] [SABER: Small Actions, Big Errors -- Safeguarding Mutating Steps in LLM Agents](https://arxiv.org/abs/2512.07850)
*Alejandro Cuadron,Pengfei Yu,Yang Liu,Arpit Gupta*

Main category: cs.LG

TL;DR: 论文发现LLM智能体在长时程工具使用任务中的失败主要源于环境改变性动作的偏差，提出了一种模型无关的测试时保护机制CM，能显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 为了理解LLM智能体在长时程工具使用任务中的脆弱性，研究探索不同动作对失败的影响是否相同，特别是环境改变性动作与非环境改变性动作的区别。

Method: 分析τ-Bench和SWE-Bench的执行轨迹，将动作分为环境改变性和非环境改变性，定义决定性偏差概念。提出CM保护机制，包含突变门控验证、目标导向反思和基于块的上下文清理。

Result: 环境改变性动作的偏差显著降低成功率（Airline降低92%，Retail降低96%），而非环境改变性动作影响很小。CM机制带来显著性能提升：Qwen3-Thinking在Airline相对提升28%，Retail提升11%，SWE-Bench Verified提升7%。

Conclusion: LLM智能体的失败主要源于环境改变性动作的偏差，需要动作级分析、针对性保护机制和可靠评估作为构建鲁棒多轮智能体的前提条件。

Abstract: Despite rapid progress in LLM agents, performance on long-horizon, tool-using tasks remains fragile. To better understand this fragility, we ask a simple question: \emph{do all actions contribute equally to failure?} Analyzing execution traces on $τ$-Bench (Airline/Retail) and SWE-Bench Verified, we decompose trajectories into \emph{mutating} (environment-changing) vs.\ non-mutating steps and formalize \emph{decisive deviations}, earliest action, level divergences that flip success to failure. A logistic regression reveals that each additional deviation in a mutating action reduces the odds of success by upto $92\%$ on Airline and upto $96\%$ on Retail for SoTA models. In contrast, deviations in non-mutating actions have little to no effect. Errors also grow with context length as agents drift from role and act on stale constraints. Motivated by these observations, we introduce \cm{}, a model-agnostic, gradient-free, test-time safeguard that (i) adds mutation-gated verification, (ii) injects \emph{Targeted Reflection} before mutating steps, and (iii) performs block-based context cleaning. \cm{} delivers consistent gains, e.g., Qwen3-Thinking: +28\% \emph{relative} on Airline, +11\% on Retail, and +7\% on SWE-Bench Verified; Claude: +9\%/+7\%. We further identify ceiling effects in $τ$-Bench, where annotation errors and underspecified tasks artificially cap model performance. To address this, we release $τ$-Bench Verified, which restores benchmark headroom through targeted revisions. Our results argue for action-level analysis, targeted safeguards, and reliable evaluations as prerequisites for robust multi-turn agents.

</details>


### [85] [GPU Memory Prediction for Multimodal Model Training](https://arxiv.org/abs/2512.07853)
*Jinwoo Jeong,Minchul Kang,Younghun Go,Changyong Shin,Hyunho Lee,Junho Yoon,Gyeongsik Yang,Chuck Yoo*

Main category: cs.LG

TL;DR: 提出一个预测多模态模型GPU峰值内存使用的框架，通过分解模型架构和分析训练行为来准确预测内存使用，避免OOM错误


<details>
  <summary>Details</summary>
Motivation: 随着智能体AI系统中深度学习模型的规模和复杂度增加，GPU内存需求经常超过可用容量，导致内存溢出(OOM)错误，这会中断训练并浪费大量计算资源。现有研究仅关注单模态架构，无法推广到多模态模型，而多模态模型在智能体AI系统中很常见。

Method: 提出一个框架，通过分析多模态模型的架构和训练行为来预测GPU峰值内存使用。具体方法是将多模态模型分解为组成层，并应用因子化来估计每层的内存使用。

Result: 评估显示该框架实现了高预测精度，平均MAPE约为8.7%。

Conclusion: 该框架能够准确预测多模态模型的GPU峰值内存使用，解决了现有方法无法处理多模态模型的问题，有助于防止OOM错误并提高计算资源利用率。

Abstract: As deep learning models in agentic AI systems grow in scale and complexity, GPU memory requirements increase and often exceed the available GPU memory capacity, so that out-of-memory (OoM) errors occur. It is well known that OoM interrupts the whole training itself and wastes substantial computational resources. Therefore, to prevent OoM, accurate prediction of GPU memory usage is essential. However, previous studies focus only on unimodal architectures and fail to generalize to multimodal models, even though the multimodal models are a common choice in agentic AI systems. To address this limitation, we propose a framework that predicts the peak GPU memory usage by analyzing the model architecture and training behavior of multimodal models. Specifically, the framework decomposes the multimodal model into its constituent layers and applies factorization to estimate the memory usage of each layer. Our evaluation shows that our framework achieves high prediction accuracy of ~8.7% average MAPE.

</details>


### [86] [HSTMixer: A Hierarchical MLP-Mixer for Large-Scale Traffic Forecasting](https://arxiv.org/abs/2512.07854)
*Yongyao Wang,Jingyuan Wang,Xie Yu,Jiahao Ji,Chao Li*

Main category: cs.LG

TL;DR: 提出HSTMixer框架，采用全MLP架构进行高效的大规模交通预测，通过分层时空混合块和多分辨率特征提取，以及自适应区域混合器动态捕捉不同区域的时空模式。


<details>
  <summary>Details</summary>
Motivation: 现有交通预测模型在大规模场景下存在二次计算复杂度问题，难以应用于真实世界的大规模交通网络，需要更高效且有效的解决方案。

Method: 提出分层时空混合器(HSTMixer)框架，包含：1)分层时空混合块，通过自底向上聚合和自顶向下传播提取多分辨率特征；2)自适应区域混合器，基于区域语义生成变换矩阵，动态捕捉不同区域的时空演化模式。

Result: 在四个大规模真实世界数据集上的实验表明，该方法不仅达到了最先进的性能，而且展现出具有竞争力的计算效率。

Conclusion: HSTMixer通过全MLP架构和分层时空建模，为大规模交通预测提供了高效且有效的解决方案，解决了现有模型计算复杂度高的问题。

Abstract: Traffic forecasting task is significant to modern urban management. Recently, there is growing attention on large-scale forecasting, as it better reflects the complexity of real-world traffic networks. However, existing models often exhibit quadratic computational complexity, making them impractical for large-scale real-world scenarios. In this paper, we propose a novel framework, Hierarchical Spatio-Temporal Mixer (HSTMixer), which leverages an all-MLP architecture for efficient and effective large-scale traffic forecasting. HSTMixer employs a hierarchical spatiotemporal mixing block to extract multi-resolution features through bottom-up aggregation and top-down propagation. Furthermore, an adaptive region mixer generates transformation matrices based on regional semantics, enabling our model to dynamically capture evolving spatiotemporal patterns for different regions. Extensive experiments conducted on four large-scale real-world datasets demonstrate that the proposed method not only achieves state-of-the-art performance but also exhibits competitive computational efficiency.

</details>


### [87] [LAPA: Log-Domain Prediction-Driven Dynamic Sparsity Accelerator for Transformer Model](https://arxiv.org/abs/2512.07855)
*Huizheng Wang,Hongbin Wang,Shaojun Wei,Yang Hu,Shouyi Yin*

Main category: cs.LG

TL;DR: LAPA：一种基于对数域注意力预测的算法-架构协同设计，通过消除昂贵乘法运算和减少累积开销，实现跨阶段稀疏Transformer加速，能效比SOTA提升2.79-3.52倍。


<details>
  <summary>Details</summary>
Motivation: 基于注意力的Transformer在NLP和CV任务中表现出色，但随着输入序列变化，计算瓶颈在不同阶段呈现动态特性，需要跨阶段稀疏加速策略。现有稀疏Transformer方法多为单阶段设计，其稀疏性预测机制在多阶段应用中会产生显著功耗开销。

Method: 提出LAPA对数域注意力预测算法-架构协同设计：1) 设计非对称前导一计算(ALOC)方案消除昂贵乘法；2) 提出混合精度多轮移位累积(MRSA)机制减少累积开销；3) 设计数据特征依赖滤波器(DDF)与MRSA协同工作；4) 设计专用加速器将理论增强转化为实际硬件改进。

Result: 实验结果显示，LAPA相比当前最先进的Spatten、Sanger和FACT工作，分别实现了3.52倍、3.24倍和2.79倍更高的能效比。

Conclusion: LAPA通过算法-架构协同设计有效解决了跨阶段稀疏Transformer加速中的计算瓶颈和功耗问题，显著提升了能效比，为动态输入序列下的Transformer加速提供了高效解决方案。

Abstract: Attention-based Transformers have revolutionized natural language processing (NLP) and shown strong performance in computer vision (CV) tasks. However, as the input sequence varies, the computational bottlenecks in Transformer models exhibit dynamic behavior across stages, which calls for a cross-stage sparse acceleration strategy. Unfortunately, most existing sparse Transformer approaches are single-stage based, and their sparsity prediction mechanisms lead to significant power overhead when applied across multiple stages. To this end, this paper proposes a log-domain attention prediction algorithm-architecture co-design, named LAPA. First, an asymmetric leading one computing (ALOC) scheme is designed to eliminate expensive multiplications. Next, a mixed-precision multi-round shifting accumulation (MRSA) mechanism is further proposed to mitigate the accumulation overhead. A data-feature dependent filter (DDF) strategy is designed to work in concert with the MRSA process. Finally, an elaborate accelerator is designed to translate the theoretical enhancement into practical hardware improvement. Experimental results show that LAPA achieves 3.52x, 3.24x and 2.79x higher energy efficiency than the state-of-the-art (SOTA) works Spatten, Sanger and FACT, respectively.

</details>


### [88] [Medical Test-free Disease Detection Based on Big Data](https://arxiv.org/abs/2512.07856)
*Haokun Zhao,Yingzhe Bai,Qingyang Xu,Lixin Zhou,Jianxin Chen,Jicong Fan*

Main category: cs.LG

TL;DR: CLDD是一种基于图神经网络的疾病检测模型，通过利用疾病关联和患者相似性进行协同学习，无需依赖大量医学检测即可预测数千种疾病。


<details>
  <summary>Details</summary>
Motivation: 传统疾病检测需要大量医学测试且成本高昂，无法为每位患者进行所有可能的检测来诊断数千种疾病。需要一种能够减少检测依赖、降低诊断成本的方法。

Method: 提出CLDD（疾病检测协同学习）模型，将疾病检测构建为协同学习任务，利用疾病间的关联和患者间的相似性。模型整合患者-疾病交互数据和人口统计学特征，基于图神经网络进行预测。

Result: 在MIMIC-IV数据集（61,191名患者，2,000种疾病）上的实验显示，CLDD在多个指标上优于基准方法，召回率提升6.33%，精确率提升7.63%。案例研究证实模型能够有效恢复掩蔽疾病。

Conclusion: CLDD通过减少诊断成本、提高可及性，有望用于大规模疾病筛查和社会健康保障，为医疗决策提供可靠支持。

Abstract: Accurate disease detection is of paramount importance for effective medical treatment and patient care. However, the process of disease detection is often associated with extensive medical testing and considerable costs, making it impractical to perform all possible medical tests on a patient to diagnose or predict hundreds or thousands of diseases. In this work, we propose Collaborative Learning for Disease Detection (CLDD), a novel graph-based deep learning model that formulates disease detection as a collaborative learning task by exploiting associations among diseases and similarities among patients adaptively. CLDD integrates patient-disease interactions and demographic features from electronic health records to detect hundreds or thousands of diseases for every patient, with little to no reliance on the corresponding medical tests. Extensive experiments on a processed version of the MIMIC-IV dataset comprising 61,191 patients and 2,000 diseases demonstrate that CLDD consistently outperforms representative baselines across multiple metrics, achieving a 6.33\% improvement in recall and 7.63\% improvement in precision. Furthermore, case studies on individual patients illustrate that CLDD can successfully recover masked diseases within its top-ranked predictions, demonstrating both interpretability and reliability in disease prediction. By reducing diagnostic costs and improving accessibility, CLDD holds promise for large-scale disease screening and social health security.

</details>


### [89] [SA^2GFM: Enhancing Robust Graph Foundation Models with Structure-Aware Semantic Augmentation](https://arxiv.org/abs/2512.07857)
*Junhua Shi,Qingyun Sun,Haonan Yuan,Xingcheng Fu*

Main category: cs.LG

TL;DR: SA^2GFM是一个鲁棒的图基础模型框架，通过结构感知语义增强提升领域自适应表示能力，在节点和图分类任务中优于9个SOTA基线。


<details>
  <summary>Details</summary>
Motivation: 当前图基础模型(GFMs)在领域噪声、结构扰动和对抗攻击下的鲁棒性研究不足，关键限制在于对层次结构语义建模不充分，而这对泛化能力至关重要。

Method: 1) 通过将基于熵的编码树转化为结构感知文本提示来编码层次结构先验；2) 使用自监督信息瓶颈机制通过结构引导压缩蒸馏鲁棒可迁移表示；3) 引入专家自适应路由机制（混合专家架构+空专家设计）解决跨领域适应的负迁移问题；4) 提出微调模块通过联合社区内和社区间结构学习优化层次结构。

Result: 在广泛的实验中，SA^2GFM在节点和图分类任务中，在对抗随机噪声和对抗扰动的有效性和鲁棒性方面，优于9个最先进的基线方法。

Conclusion: SA^2GFM通过结构感知语义增强和自适应机制，显著提升了图基础模型在噪声和扰动环境下的鲁棒性和领域自适应能力。

Abstract: We present Graph Foundation Models (GFMs) which have made significant progress in various tasks, but their robustness against domain noise, structural perturbations, and adversarial attacks remains underexplored. A key limitation is the insufficient modeling of hierarchical structural semantics, which are crucial for generalization. In this paper, we propose SA^2GFM, a robust GFM framework that improves domain-adaptive representations through Structure-Aware Semantic Augmentation. First, we encode hierarchical structural priors by transforming entropy-based encoding trees into structure-aware textual prompts for feature augmentation. The enhanced inputs are processed by a self-supervised Information Bottleneck mechanism that distills robust, transferable representations via structure-guided compression. To address negative transfer in cross-domain adaptation, we introduce an expert adaptive routing mechanism, combining a mixture-of-experts architecture with a null expert design. For efficient downstream adaptation, we propose a fine-tuning module that optimizes hierarchical structures through joint intra- and inter-community structure learning. Extensive experiments demonstrate that SA^2GFM outperforms 9 state-of-the-art baselines in terms of effectiveness and robustness against random noise and adversarial perturbations for node and graph classification.

</details>


### [90] [FAIM: Frequency-Aware Interactive Mamba for Time Series Classification](https://arxiv.org/abs/2512.07858)
*Da Zhang,Bingyu Li,Zhiyuan Zhao,Yanhan Zhang,Junyu Gao,Feiping Nie,Xuelong Li*

Main category: cs.LG

TL;DR: FAIM：轻量级频率感知交互式Mamba模型，通过自适应滤波块和交互式Mamba块，结合自监督预训练，在时间序列分类任务中实现高精度与高效率的平衡。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在时间序列分类中虽然能捕捉时间依赖，但存在计算成本高、对噪声敏感、在小数据集上容易过拟合等问题，需要更轻量、鲁棒的解决方案。

Method: 1. 自适应滤波块（AFB）：利用傅里叶变换提取频域特征，通过可学习自适应阈值动态抑制噪声，结合全局与局部语义自适应滤波；2. 交互式Mamba块（IMB）：促进多粒度信息交互，平衡细粒度判别特征与全局上下文信息；3. 自监督预训练机制增强对复杂时序模式的理解。

Result: 在多个基准测试中，FAIM持续超越现有SOTA方法，在准确性和效率之间达到优越平衡，并在高噪声场景下表现出色。

Conclusion: FAIM通过频域特征提取、自适应噪声抑制和多粒度信息交互，为时间序列分类提供了轻量、高效且鲁棒的解决方案，在环境监测、医疗诊断等实际应用中具有重要价值。

Abstract: Time series classification (TSC) is crucial in numerous real-world applications, such as environmental monitoring, medical diagnosis, and posture recognition. TSC tasks require models to effectively capture discriminative information for accurate class identification. Although deep learning architectures excel at capturing temporal dependencies, they often suffer from high computational cost, sensitivity to noise perturbations, and susceptibility to overfitting on small-scale datasets. To address these challenges, we propose FAIM, a lightweight Frequency-Aware Interactive Mamba model. Specifically, we introduce an Adaptive Filtering Block (AFB) that leverages Fourier Transform to extract frequency-domain features from time series data. The AFB incorporates learnable adaptive thresholds to dynamically suppress noise and employs element-wise coupling of global and local semantic adaptive filtering, enabling in-depth modeling of the synergy among different frequency components. Furthermore, we design an Interactive Mamba Block (IMB) to facilitate efficient multi-granularity information interaction, balancing the extraction of fine-grained discriminative features and comprehensive global contextual information, thereby endowing FAIM with powerful and expressive representations for TSC tasks. Additionally, we incorporate a self-supervised pre-training mechanism to enhance FAIM's understanding of complex temporal patterns and improve its robustness across various domains and high-noise scenarios. Extensive experiments on multiple benchmarks demonstrate that FAIM consistently outperforms existing state-of-the-art (SOTA) methods, achieving a superior trade-off between accuracy and efficiency and exhibits outstanding performance.

</details>


### [91] [SetAD: Semi-Supervised Anomaly Learning in Contextual Sets](https://arxiv.org/abs/2512.07863)
*Jianling Gao,Chongyang Tao,Xuelian Lin,Junfeng Liu,Shuai Ma*

Main category: cs.LG

TL;DR: SetAD将半监督异常检测重构为集合级任务，通过注意力集合编码器和分级学习目标学习整个集合的异常程度，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有半监督异常检测方法主要关注单个点或简单对，忽略了异常本质上是相对于群体的偏离，且未能利用集合组合产生的丰富监督信号，无法有效建模数据中的高阶交互。

Method: 提出SetAD框架：1) 将半监督异常检测重构为集合级任务；2) 使用注意力集合编码器通过分级学习目标训练；3) 提出上下文校准的异常评分机制，通过聚合点在多个不同上下文集合中相对于同伴行为的归一化偏差来评估异常分数。

Result: 在10个真实世界数据集上的广泛实验表明，SetAD显著优于最先进模型。特别地，模型性能随着集合大小的增加而持续提升，为基于集合的异常检测公式提供了强有力的实证支持。

Conclusion: 集合级的异常检测方法能够更好地建模定义异常的复杂群体级交互，通过注意力集合编码器和上下文校准评分机制，SetAD在性能和鲁棒性方面均表现出色，验证了集合视角在半监督异常检测中的有效性。

Abstract: Semi-supervised anomaly detection (AD) has shown great promise by effectively leveraging limited labeled data. However, existing methods are typically structured around scoring individual points or simple pairs. Such {point- or pair-centric} view not only overlooks the contextual nature of anomalies, which are defined by their deviation from a collective group, but also fails to exploit the rich supervisory signals that can be generated from the combinatorial composition of sets. Consequently, such models struggle to exploit the high-order interactions within the data, which are critical for learning discriminative representations. To address these limitations, we propose SetAD, a novel framework that reframes semi-supervised AD as a Set-level Anomaly Detection task. SetAD employs an attention-based set encoder trained via a graded learning objective, where the model learns to quantify the degree of anomalousness within an entire set. This approach directly models the complex group-level interactions that define anomalies. Furthermore, to enhance robustness and score calibration, we propose a context-calibrated anomaly scoring mechanism, which assesses a point's anomaly score by aggregating its normalized deviations from peer behavior across multiple, diverse contextual sets. Extensive experiments on 10 real-world datasets demonstrate that SetAD significantly outperforms state-of-the-art models. Notably, we show that our model's performance consistently improves with increasing set size, providing strong empirical support for the set-based formulation of anomaly detection.

</details>


### [92] [Pattern Recognition of Ozone-Depleting Substance Exports in Global Trade Data](https://arxiv.org/abs/2512.07864)
*Muhammad Sukri Bin Ramli*

Main category: cs.LG

TL;DR: 提出一个无监督机器学习框架，用于分析海关数据以监测环境条约执行情况，通过聚类、异常检测和启发式标记识别可疑贸易模式，生成优先级评分供监管部门审查。


<details>
  <summary>Details</summary>
Motivation: 需要新的方法来监测《蒙特利尔议定书》等环境条约的执行情况，传统方法难以处理大规模、复杂的海关数据集，需要系统化的可疑贸易模式检测工具。

Method: 结合多种无监督机器学习技术：K-Means聚类发现贸易原型；隔离森林和IQR异常检测识别"大宗交易"和异常价格；启发式标记检测模糊描述等策略；将这些层整合为优先级评分系统。

Result: 应用于10万条贸易记录，成功识别出1,351个价格异常值和1,288个高优先级货物供海关审查。发现高优先级商品的价值重量比与普通商品不同，通过SHAP验证模糊描述和高价值是最重要的风险预测因子。

Conclusion: 该框架提供了一个可重复的无监督学习流程，能将原始贸易数据转化为监管部门可用的优先级情报，成功检测到2021年初"大宗交易"激增与《美国AIM法案》监管影响的相关性。

Abstract: New methods are needed to monitor environmental treaties, like the Montreal Protocol, by reviewing large, complex customs datasets. This paper introduces a framework using unsupervised machine learning to systematically detect suspicious trade patterns and highlight activities for review. Our methodology, applied to 100,000 trade records, combines several ML techniques. Unsupervised Clustering (K-Means) discovers natural trade archetypes based on shipment value and weight. Anomaly Detection (Isolation Forest and IQR) identifies rare "mega-trades" and shipments with commercially unusual price-per-kilogram values. This is supplemented by Heuristic Flagging to find tactics like vague shipment descriptions. These layers are combined into a priority score, which successfully identified 1,351 price outliers and 1,288 high-priority shipments for customs review. A key finding is that high-priority commodities show a different and more valuable value-to-weight ratio than general goods. This was validated using Explainable AI (SHAP), which confirmed vague descriptions and high value as the most significant risk predictors. The model's sensitivity was validated by its detection of a massive spike in "mega-trades" in early 2021, correlating directly with the real-world regulatory impact of the US AIM Act. This work presents a repeatable unsupervised learning pipeline to turn raw trade data into prioritized, usable intelligence for regulatory groups.

</details>


### [93] [Using Text-Based Life Trajectories from Swedish Register Data to Predict Residential Mobility with Pretrained Transformers](https://arxiv.org/abs/2512.07865)
*Philipp Stark,Alexandros Sopasakis,Ola Hall,Markus Grillitsch*

Main category: cs.LG

TL;DR: 将瑞典人口登记数据转化为文本生命轨迹，解决分类变量高基数性和编码不一致问题，使用NLP模型预测居住流动性


<details>
  <summary>Details</summary>
Motivation: 解决数据分析中长期存在的两个挑战：分类变量的高基数性和随时间变化的编码方案不一致性。利用瑞典全面的人口登记数据，探索如何将结构化登记数据转化为语义丰富的文本序列，以支持纵向预测分析。

Method: 将690万个体（2001-2013年）的登记数据转化为文本生命轨迹，包含人口统计信息以及居住、工作、教育、收入和家庭状况的年度变化。使用多种NLP架构（包括LSTM、DistilBERT、BERT和Qwen）预测个体在后续年份（2013-2017年）的居住流动性。

Result: 序列模型和基于Transformer的模型比基线模型更有效地捕捉时间和语义结构。文本化的登记数据保留了关于个体路径的有意义信息，支持复杂、可扩展的建模。该数据集为开发和评估新的序列建模方法提供了严格的测试平台。

Conclusion: 将语义丰富的登记数据与现代语言模型相结合，可以显著推进社会科学中的纵向分析。这种结合为处理高基数分类变量和编码不一致问题提供了有效解决方案，并展示了文本化方法在人口数据分析中的潜力。

Abstract: We transform large-scale Swedish register data into textual life trajectories to address two long-standing challenges in data analysis: high cardinality of categorical variables and inconsistencies in coding schemes over time. Leveraging this uniquely comprehensive population register, we convert register data from 6.9 million individuals (2001-2013) into semantically rich texts and predict individuals' residential mobility in later years (2013-2017). These life trajectories combine demographic information with annual changes in residence, work, education, income, and family circumstances, allowing us to assess how effectively such sequences support longitudinal prediction. We compare multiple NLP architectures (including LSTM, DistilBERT, BERT, and Qwen) and find that sequential and transformer-based models capture temporal and semantic structure more effectively than baseline models. The results show that textualized register data preserves meaningful information about individual pathways and supports complex, scalable modeling. Because few countries maintain longitudinal microdata with comparable coverage and precision, this dataset enables analyses and methodological tests that would be difficult or impossible elsewhere, offering a rigorous testbed for developing and evaluating new sequence-modeling approaches. Overall, our findings demonstrate that combining semantically rich register data with modern language models can substantially advance longitudinal analysis in social sciences.

</details>


### [94] [Command & Control (C2) Traffic Detection Via Algorithm Generated Domain (Dga) Classification Using Deep Learning And Natural Language Processing](https://arxiv.org/abs/2512.07866)
*Maria Milena Araujo Felix*

Main category: cs.LG

TL;DR: 提出基于深度学习和NLP的DGA域名检测方法，使用LSTM网络达到97.2%准确率，优于传统统计熵分析


<details>
  <summary>Details</summary>
Motivation: 现代恶意软件使用DGA技术生成大量动态地址，使基于静态黑名单的传统防火墙防御失效，需要更智能的检测方法

Method: 收集包含5万合法和5万恶意域名的混合数据库，提取词汇特征，训练LSTM循环神经网络进行检测

Result: LSTM方法在检测复杂DGA模式上表现优越，达到97.2%准确率，在模糊合法流量场景中降低了误报率

Conclusion: 深度学习结合NLP技术能有效检测DGA域名，特别是对于复杂模式，优于传统的统计熵分析方法

Abstract: The sophistication of modern malware, specifically regarding communication with Command and Control (C2) servers, has rendered static blacklist-based defenses obsolete. The use of Domain Generation Algorithms (DGA) allows attackers to generate thousands of dynamic addresses daily, hindering blocking by traditional firewalls. This paper aims to propose and evaluate a method for detecting DGA domains using Deep Learning and Natural Language Processing (NLP) techniques. The methodology consisted of collecting a hybrid database containing 50,000 legitimate and 50,000 malicious domains, followed by the extraction of lexical features and the training of a Recurrent Neural Network (LSTM). Results demonstrated that while statistical entropy analysis is effective for simple DGAs, the Neural Network approach presents superiority in detecting complex patterns, reaching 97.2% accuracy and reducing the false positive rate in ambiguous lawful traffic scenarios.

</details>


### [95] [Bayesian Optimization for Function-Valued Responses under Min-Max Criteria](https://arxiv.org/abs/2512.07868)
*Pouya Ahadi,Reza Marzban,Ali Adibi,Kamran Paynabar*

Main category: cs.LG

TL;DR: 提出MM-FBO框架，用于函数响应贝叶斯优化，直接最小化函数域上的最大误差，优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统贝叶斯优化主要处理标量响应，但许多科学工程问题中响应是函数形式的（随时间或波长变化）。现有方法通常最小化积分误差，忽略了最坏情况偏差，需要直接优化最大误差。

Method: 使用函数主成分分析表示函数响应，为PC得分构建高斯过程代理模型。提出集成不确定性获取函数，平衡最坏情况期望误差的利用和函数域上的探索。

Result: 在合成基准测试和物理案例研究（电磁散射、气相渗透）中，MM-FBO始终优于现有基线方法，验证了显式建模函数不确定性的重要性。

Conclusion: MM-FBO框架有效解决了函数响应贝叶斯优化中的最坏情况优化问题，提供了理论保证并在实际应用中表现出优越性能。

Abstract: Bayesian optimization is widely used for optimizing expensive black box functions, but most existing approaches focus on scalar responses. In many scientific and engineering settings the response is functional, varying smoothly over an index such as time or wavelength, which makes classical formulations inadequate. Existing methods often minimize integrated error, which captures average performance but neglects worst case deviations. To address this limitation we propose min-max Functional Bayesian Optimization (MM-FBO), a framework that directly minimizes the maximum error across the functional domain. Functional responses are represented using functional principal component analysis, and Gaussian process surrogates are constructed for the principal component scores. Building on this representation, MM-FBO introduces an integrated uncertainty acquisition function that balances exploitation of worst case expected error with exploration across the functional domain. We provide two theoretical guarantees: a discretization bound for the worst case objective, and a consistency result showing that as the surrogate becomes accurate and uncertainty vanishes, the acquisition converges to the true min-max objective. We validate the method through experiments on synthetic benchmarks and physics inspired case studies involving electromagnetic scattering by metaphotonic devices and vapor phase infiltration. Results show that MM-FBO consistently outperforms existing baselines and highlights the importance of explicitly modeling functional uncertainty in Bayesian optimization.

</details>


### [96] [Advancing physiological time series reconstruction and imputation via mixture of receptive fields and experts fusion](https://arxiv.org/abs/2512.07873)
*Ci Zhang,Huayu Li,Changdi Yang,Jiangnan Xia,Yanzhi Wang,Xiaolong Ma,Jin Lu,Geng Yuan*

Main category: cs.LG

TL;DR: 提出基于混合专家(MoE)的噪声估计器，用于医学时间序列信号重建，通过RFAMoE模块自适应选择感受野，并通过Fusion MoE模块在单次推理中并行生成多个噪声信号，显著提升性能并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 医学时间序列信号具有多变量、高时间变异性、高噪声和易受伪影影响等独特特性，使得基于深度学习的方法在插补等任务中仍然具有挑战性。现有扩散模型方法需要多次推理平均来减少重建误差，但计算成本和延迟过高。

Method: 1. 在基于分数的扩散框架中提出混合专家(MoE)噪声估计器；2. 设计RFAMoE模块，使每个通道能在扩散过程中自适应选择所需感受野；3. 设计Fusion MoE模块，利用MoE特性并行生成K个噪声信号，通过路由机制融合，在单次推理中完成信号重建。

Result: 提出的框架在不同任务和数据集上始终优于基于扩散的SOTA方法，不仅性能更好，还消除了多次推理过程带来的大量计算成本和延迟。

Conclusion: 基于MoE的扩散模型框架能有效处理医学时间序列信号的重建挑战，通过自适应感受野选择和单次推理并行融合机制，在提升性能的同时显著降低计算开销，为医学时间序列分析提供了高效解决方案。

Abstract: Recent studies show that using diffusion models for time series signal reconstruc- tion holds great promise. However, such approaches remain largely unexplored in the domain of medical time series. The unique characteristics of the physiological time series signals, such as multivariate, high temporal variability, highly noisy, and artifact-prone, make deep learning-based approaches still challenging for tasks such as imputation. Hence, we propose a novel Mixture of Experts (MoE)-based noise estimator within a score-based diffusion framework. Specifically, the Receptive Field Adaptive MoE (RFAMoE) module is designed to enable each channel to adap- tively select desired receptive fields throughout the diffusion process. Moreover, recent literature has found that when generating a physiological signal, performing multiple inferences and averaging the reconstructed signals can effectively reduce reconstruction errors, but at the cost of significant computational and latency over- head. We design a Fusion MoE module and innovatively leverage the nature of MoE module to generate K noise signals in parallel, fuse them using a routing mechanism, and complete signal reconstruction in a single inference step. This design not only improves performance over previous methods but also eliminates the substantial computational cost and latency associated with multiple inference processes. Extensive results demonstrate that our proposed framework consistently outperforms diffusion-based SOTA works on different tasks and datasets.

</details>


### [97] [Controllable risk scenario generation from human crash data for autonomous vehicle testing](https://arxiv.org/abs/2512.07874)
*Qiujing Lu,Xuanhan Wang,Runze Yuan,Wei Lu,Xinyi Gong,Shuo Feng*

Main category: cs.LG

TL;DR: CRAG框架统一建模自动驾驶测试中的常规行为和罕见风险行为，通过解耦潜在空间实现可控风险场景生成，提升AV测试效率


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆安全测试需要同时模拟日常驾驶和罕见安全关键场景，现有方法难以统一建模常规行为和风险行为，且风险数据有限

Method: 构建结构化潜在空间解耦正常行为和风险行为，结合风险感知潜在表示和基于优化的模式转换机制，实现从安全到风险状态的平滑过渡

Result: 相比现有基线方法，CRAG提高了行为多样性，同时支持可控风险场景生成，能够针对性地高效评估自动驾驶系统的鲁棒性

Conclusion: CRAG框架成功统一了常规和风险行为的建模，通过解耦潜在空间有效利用有限事故数据，为自动驾驶安全测试提供了高效可控的风险场景生成方法

Abstract: Ensuring the safety of autonomous vehicles (AV) requires rigorous testing under both everyday driving and rare, safety-critical conditions. A key challenge lies in simulating environment agents, including background vehicles (BVs) and vulnerable road users (VRUs), that behave realistically in nominal traffic while also exhibiting risk-prone behaviors consistent with real-world accidents. We introduce Controllable Risk Agent Generation (CRAG), a framework designed to unify the modeling of dominant nominal behaviors and rare safety-critical behaviors. CRAG constructs a structured latent space that disentangles normal and risk-related behaviors, enabling efficient use of limited crash data. By combining risk-aware latent representations with optimization-based mode-transition mechanisms, the framework allows agents to shift smoothly and plausibly from safe to risk states over extended horizons, while maintaining high fidelity in both regimes. Extensive experiments show that CRAG improves diversity compared to existing baselines, while also enabling controllable generation of risk scenarios for targeted and efficient evaluation of AV robustness.

</details>


### [98] [Softly Symbolifying Kolmogorov-Arnold Networks](https://arxiv.org/abs/2512.07875)
*James Bagrow,Josh Bongard*

Main category: cs.LG

TL;DR: S2KAN通过将符号基元直接集成到训练中，解决了传统KAN激活函数缺乏符号保真度的问题，使用可学习的门控机制稀疏化表示，在符号任务上实现了竞争性或更优的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统Kolmogorov-Arnold网络（KANs）虽然提供了可解释机器学习的路径，但训练后的激活函数往往缺乏符号保真度，学习到的分解没有有意义的对应关系，无法实现真正的可解释性。

Method: 提出Softly Symbolified KANs（S2KAN），将符号基元直接集成到训练中。每个激活函数从符号项和密集项的字典中提取，使用可学习的门控机制稀疏化表示。稀疏化是可微分的，支持端到端优化，并由最小描述长度目标指导。

Result: 在符号基准测试、动态系统预测和真实世界预测任务中，S2KAN实现了竞争性或更优的准确性，且模型规模显著更小。观察到即使没有正则化压力，也出现了自稀疏化的现象。

Conclusion: S2KAN通过将符号表示直接集成到训练过程中，解决了KANs的符号保真度问题。当符号项足够时，它能发现可解释的形式；当符号项不足时，它能优雅地退化为密集样条，实现了准确性和可解释性的平衡。

Abstract: Kolmogorov-Arnold Networks (KANs) offer a promising path toward interpretable machine learning: their learnable activations can be studied individually, while collectively fitting complex data accurately. In practice, however, trained activations often lack symbolic fidelity, learning pathological decompositions with no meaningful correspondence to interpretable forms. We propose Softly Symbolified Kolmogorov-Arnold Networks (S2KAN), which integrate symbolic primitives directly into training. Each activation draws from a dictionary of symbolic and dense terms, with learnable gates that sparsify the representation. Crucially, this sparsification is differentiable, enabling end-to-end optimization, and is guided by a principled Minimum Description Length objective. When symbolic terms suffice, S2KAN discovers interpretable forms; when they do not, it gracefully degrades to dense splines. We demonstrate competitive or superior accuracy with substantially smaller models across symbolic benchmarks, dynamical systems forecasting, and real-world prediction tasks, and observe evidence of emergent self-sparsification even without regularization pressure.

</details>


### [99] [Fourier-Enhanced Recurrent Neural Networks for Electrical Load Time Series Downscaling](https://arxiv.org/abs/2512.07876)
*Qi Chen,Mihai Anitescu*

Main category: cs.LG

TL;DR: 提出一种傅里叶增强的循环神经网络，用于电力负荷降尺度预测，结合循环主干、傅里叶季节性嵌入和自注意力机制，在多个区域优于传统基准模型。


<details>
  <summary>Details</summary>
Motivation: 电力负荷预测需要从低分辨率输入生成高分辨率预测，传统方法在捕捉复杂季节性模式和跨时间尺度依赖关系方面存在局限，需要更先进的降尺度技术。

Method: 提出傅里叶增强循环神经网络：1) 循环主干处理低分辨率输入；2) 显式傅里叶季节性嵌入在潜在空间融合；3) 自注意力层捕捉周期内高分辨率分量间的依赖关系。

Result: 在四个PJM区域测试中，该方法相比传统Prophet基准（有无季节性/LAA）以及没有注意力或傅里叶特征的RNN消融模型，均获得更低的RMSE和更平坦的预测误差分布。

Conclusion: 傅里叶季节性嵌入与自注意力机制的结合能有效提升电力负荷降尺度预测性能，为时间序列降尺度问题提供了有效的深度学习解决方案。

Abstract: We present a Fourier-enhanced recurrent neural network (RNN) for downscaling electrical loads. The model combines (i) a recurrent backbone driven by low-resolution inputs, (ii) explicit Fourier seasonal embeddings fused in latent space, and (iii) a self-attention layer that captures dependencies among high-resolution components within each period. Across four PJM territories, the approach yields RMSE lower and flatter horizon-wise than classical Prophet baselines (with and without seasonality/LAA) and than RNN ablations without attention or Fourier features.

</details>


### [100] [Artificial Intelligence-Driven Network-on-Chip Design Space Exploration: Neural Network Architectures for Design](https://arxiv.org/abs/2512.07877)
*Amogh Anshu N,Harish BP*

Main category: cs.LG

TL;DR: 提出基于机器学习的NoC设计空间探索框架，使用BookSim仿真和反向神经网络模型，比较MLP、条件扩散模型和CVAE三种架构，条件扩散模型在未见数据上获得最低MSE（0.463），大幅缩短设计探索时间。


<details>
  <summary>Details</summary>
Motivation: 传统NoC设计空间探索方法速度慢且难以处理复杂的非线性参数交互，需要自动化、高效的解决方案来满足严格的吞吐量和延迟约束。

Method: 开发机器学习驱动的框架，使用BookSim仿真生成超过150,000个数据点，比较三种神经网络架构（MLP、条件扩散模型、CVAE）来预测给定目标性能指标下的最优NoC参数。

Result: 条件扩散模型表现最佳，在未见数据上达到0.463的均方误差（MSE），框架将设计探索时间缩短了几个数量级。

Conclusion: 提出的机器学习框架为快速、可扩展的NoC协同设计提供了实用解决方案，显著提高了设计空间探索效率。

Abstract: Network-on-Chip (NoC) design requires exploring a high-dimensional configuration space to satisfy stringent throughput requirements and latency constraints.Traditional design space exploration techniques are often slow and struggle to handle complex, non-linear parameter interactions.This work presents a machine learning-driven framework that automates NoC design space exploration using BookSim simulations and reverse neural network models.Specifically, we compare three architectures - a Multi-Layer Perceptron (MLP),a Conditional Diffusion Model, and a Conditional Variational Autoencoder (CVAE) to predict optimal NoC parameters given target performance metrics.Our pipeline generates over 150,000 simulation data points across varied mesh topologies.The Conditional Diffusion Model achieved the highest predictive accuracy, attaining a mean squared error (MSE) of 0.463 on unseen data.Furthermore, the proposed framework reduces design exploration time by several orders of magnitude, making it a practical solution for rapid and scalable NoC co-design.

</details>


### [101] [Graph Contrastive Learning via Spectral Graph Alignment](https://arxiv.org/abs/2512.07878)
*Manh Nguyen,Joshua Cape*

Main category: cs.LG

TL;DR: 提出SpecMatch-CL损失函数，通过最小化视图间归一化拉普拉斯矩阵的差异来对齐图嵌入，在无监督、半监督和迁移学习任务中取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有对比学习方法（如InfoNCE）在优化图嵌入跨视图对齐时，缺乏对视图特定图-图结构全局结构的控制机制。

Method: 引入SpecMatch-CL损失函数，通过最小化视图特定图-图的归一化拉普拉斯矩阵差异来对齐图嵌入。理论证明该差异为理想完美对齐对比损失与当前损失差异的上界。

Result: 在8个TU基准测试的无监督学习和低标签率半监督学习中达到新SOTA，在PPI-306K和ZINC 2M数据集的迁移学习中获得一致性能提升。

Conclusion: SpecMatch-CL通过拉普拉斯谱对齐有效控制图嵌入的全局结构，显著提升图对比学习性能。

Abstract: Given augmented views of each input graph, contrastive learning methods (e.g., InfoNCE) optimize pairwise alignment of graph embeddings across views while providing no mechanism to control the global structure of the view specific graph-of-graphs built from these embeddings. We introduce SpecMatch-CL, a novel loss function that aligns the view specific graph-of-graphs by minimizing the difference between their normalized Laplacians. Theoretically, we show that under certain assumptions, the difference between normalized Laplacians provides an upper bound not only for the difference between the ideal Perfect Alignment contrastive loss and the current loss, but also for the Uniformly loss. Empirically, SpecMatch-CL establishes new state of the art on eight TU benchmarks under unsupervised learning and semi-supervised learning at low label rates, and yields consistent gains in transfer learning on PPI-306K and ZINC 2M datasets.

</details>


### [102] [Nonnegative Matrix Factorization through Cone Collapse](https://arxiv.org/abs/2512.07879)
*Manh Nguyen,Daniel Pimentel-Alarcón*

Main category: cs.LG

TL;DR: 论文提出Cone Collapse算法，从几何视角重新审视NMF，通过收缩非负象限来恢复数据的最小生成锥，并基于此开发锥感知正交NMF模型CC-NMF，在聚类任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有NMF算法主要从优化视角出发，没有充分利用NMF诱导的锥形几何结构。数据点位于凸锥中，其极射线编码了基本方向或"主题"。从几何视角重新审视NMF可以带来理论更严谨、性能更强的聚类方法。

Method: 提出Cone Collapse算法：从完整的非负象限开始，迭代收缩它朝向数据生成的最小锥。证明在温和假设下，该算法有限步终止并恢复X⊤的最小生成锥。在此基础上，通过对恢复的极射线应用单正交NMF，推导出锥感知正交NMF模型CC-NMF。

Result: 在16个基准基因表达、文本和图像数据集上，CC-NMF在聚类纯度方面始终匹配或优于强NMF基线方法，包括乘法更新、ANLS、投影NMF、ONMF和稀疏NMF。

Conclusion: 显式恢复数据锥可以产生既具有理论依据又在经验上强大的基于NMF的聚类方法，几何视角为NMF提供了新的理解和改进方向。

Abstract: Nonnegative matrix factorization (NMF) is a widely used tool for learning parts-based, low-dimensional representations of nonnegative data, with applications in vision, text, and bioinformatics. In clustering applications, orthogonal NMF (ONMF) variants further impose (approximate) orthogonality on the representation matrix so that its rows behave like soft cluster indicators. Existing algorithms, however, are typically derived from optimization viewpoints and do not explicitly exploit the conic geometry induced by NMF: data points lie in a convex cone whose extreme rays encode fundamental directions or "topics". In this work we revisit NMF from this geometric perspective and propose Cone Collapse, an algorithm that starts from the full nonnegative orthant and iteratively shrinks it toward the minimal cone generated by the data. We prove that, under mild assumptions on the data, Cone Collapse terminates in finitely many steps and recovers the minimal generating cone of $\mathbf{X}^\top$ . Building on this basis, we then derive a cone-aware orthogonal NMF model (CC-NMF) by applying uni-orthogonal NMF to the recovered extreme rays. Across 16 benchmark gene-expression, text, and image datasets, CC-NMF consistently matches or outperforms strong NMF baselines-including multiplicative updates, ANLS, projective NMF, ONMF, and sparse NMF-in terms of clustering purity. These results demonstrate that explicitly recovering the data cone can yield both theoretically grounded and empirically strong NMF-based clustering methods.

</details>


### [103] [Semi-Supervised Contrastive Learning with Orthonormal Prototypes](https://arxiv.org/abs/2512.07880)
*Huanran Li,Manh Nguyen,Daniel Pimentel-Alarcón*

Main category: cs.LG

TL;DR: CLOP是一种新的半监督对比学习损失函数，通过促进类别嵌入的正交线性子空间形成来防止维度坍缩，在图像分类和目标检测任务中表现优异且稳定。


<details>
  <summary>Details</summary>
Motivation: 对比学习在深度学习中表现优异，但维度坍缩问题在半监督和自监督设置中尤为严重，导致嵌入收敛到低维空间，限制了表示学习的效果。

Method: 首先识别了标准对比损失收敛到坍缩解的学习率阈值，然后提出CLOP损失函数，通过促进类别嵌入的正交线性子空间形成来防止维度坍缩。

Result: 在真实和合成数据集上的实验表明，CLOP在图像分类和目标检测任务中提高了性能，同时在不同学习率和批量大小下表现出更好的稳定性。

Conclusion: CLOP通过防止维度坍缩有效提升了对比学习的表示质量，为半监督学习提供了更稳定和高效的解决方案。

Abstract: Contrastive learning has emerged as a powerful method in deep learning, excelling at learning effective representations through contrasting samples from different distributions. However, dimensional collapse, where embeddings converge into a lower-dimensional space, poses a significant challenge, especially in semi-supervised and self-supervised setups. In this paper, we first identify a critical learning-rate threshold, beyond which standard contrastive losses converge to collapsed solutions. Building on these insights, we propose CLOP, a novel semi-supervised loss function designed to prevent dimensional collapse by promoting the formation of orthogonal linear subspaces among class embeddings. Through extensive experiments on real and synthetic datasets, we demonstrate that CLOP improves performance in image classification and object detection tasks while also exhibiting greater stability across different learning rates and batch sizes.

</details>


### [104] [GSPN-2: Efficient Parallel Sequence Modeling](https://arxiv.org/abs/2512.07884)
*Hongjun Wang,Yitong Jiang,Collin McCarthy,David Wehr,Hanrong Ye,Xinhao Li,Ka Chun Cheung,Wonmin Byeon,Jinwei Gu,Ke Chen,Kai Han,Hongxu Yin,Pavlo Molchanov,Jan Kautz,Sifei Liu*

Main category: cs.LG

TL;DR: GSPN-2通过算法-系统协同重新设计，解决了GSPN在GPU实现中的效率瓶颈，包括内核启动开销、内存传输和冗余计算，在保持精度的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有GSPN虽然用线扫描传播方案替代了二次自注意力，将计算成本降至接近线性，但在GPU实现上仍存在三个主要问题：1) 重复启动GPU内核的开销；2) 全局GPU内存的过度数据传输；3) 为每个通道维护独立传播权重导致的冗余计算。

Method: 1) 系统层面：将数千个微内核启动合并为单个2D内核，为每个通道切片固定一个warp，将前一列的激活暂存到共享内存；2) 模型层面：引入紧凑通道传播策略，替代逐通道矩阵，减少参数，并与transformer注意力中的亲和力图自然对齐。

Result: 在图像分类和文本到图像合成任务中，GSPN-2能够匹配transformer级别的准确性，同时显著降低计算成本，为视觉应用中的全局空间上下文建模建立了新的效率前沿。

Conclusion: GSPN-2通过结构化矩阵变换和GPU优化实现的独特组合，为高分辨率图像和长视频相关应用提供了高效的vision transformer替代方案，在保持模型性能的同时大幅提升了计算效率。

Abstract: Efficient vision transformer remains a bottleneck for high-resolution images and long-video related real-world applications. Generalized Spatial Propagation Network (GSPN) addresses this by replacing quadratic self-attention with a line-scan propagation scheme, bringing the cost close to linear in the number of rows or columns, while retaining accuracy. Despite this advancement, the existing GSPN implementation still suffers from (i) heavy overhead due to repeatedly launching GPU kernels, (ii) excessive data transfers from global GPU memory, and (iii) redundant computations caused by maintaining separate propagation weights for each channel. We introduce GSPN-2, a joint algorithm-system redesign. In particular, we eliminate thousands of micro-launches from the previous implementation into one single 2D kernel, explicitly pin one warp to each channel slice, and stage the previous column's activations in shared memory. On the model side, we introduce a compact channel propagation strategy that replaces per-channel matrices, trimming parameters, and align naturally with the affinity map used in transformer attention. Experiments demonstrate GSPN-2's effectiveness across image classification and text-to-image synthesis tasks, matching transformer-level accuracy with significantly lower computational cost. GSPN-2 establishes a new efficiency frontier for modeling global spatial context in vision applications through its unique combination of structured matrix transformations and GPU-optimized implementation. Project page: https://whj363636.github.io/GSPN2/

</details>


### [105] [ByteStorm: a multi-step data-driven approach for Tropical Cyclones detection and tracking](https://arxiv.org/abs/2512.07885)
*Davide Donno,Donatello Elia,Gabriele Accarino,Marco De Carlo,Enrico Scoccimarro,Silvio Gualdi*

Main category: cs.LG

TL;DR: ByteStorm：基于深度学习和计算机视觉的热带气旋追踪框架，无需阈值调优，在东西北太平洋盆地表现优于传统方法


<details>
  <summary>Details</summary>
Motivation: 传统热带气旋追踪方案主要依赖主观阈值，这可能导致在不同地理区域应用时产生偏差。需要一种更准确、无需阈值调优的追踪方法。

Method: 使用深度学习网络通过分类和定位检测热带气旋中心（仅使用850mb相对涡度和平均海平面气压），然后通过BYTE算法将检测到的中心连接成热带气旋轨迹。

Result: 在东、西北太平洋盆地评估中，ByteStorm在检测概率（ENP 85.05%，WNP 79.48%）、误报率（ENP 23.26%，WNP 16.14%）和年际变率相关性（ENP 0.75，WNP 0.69）方面均优于现有确定性追踪器。

Conclusion: ByteStorm展示了深度学习和计算机视觉在快速准确追踪热带气旋方面的潜力，为传统方法提供了稳健的替代方案。

Abstract: Accurate tropical cyclones (TCs) tracking represents a critical challenge in the context of weather and climate science. Traditional tracking schemes mainly rely on subjective thresholds, which may introduce biases in their skills on the geographical region of application. We present ByteStorm, an efficient data-driven framework for reconstructing TC tracks without threshold tuning. It leverages deep learning networks to detect TC centers (via classification and localization), using only relative vorticity (850 mb) and mean sea-level pressure. Then, detected centers are linked into TC tracks through the BYTE algorithm. ByteStorm is evaluated against state-of-the-art deterministic trackers in the East- and West-North Pacific basins (ENP and WNP). The proposed framework achieves superior performance in terms of Probability of Detection ($85.05\%$ ENP, $79.48\%$ WNP), False Alarm Rate ($23.26\%$ ENP, $16.14\%$ WNP), and high Inter-Annual Variability correlations ($0.75$ ENP and $0.69$ WNP). These results highlight the potential of integrating deep learning and computer vision for fast and accurate TC tracking, offering a robust alternative to traditional approaches.

</details>


### [106] [Towards symbolic regression for interpretable clinical decision scores](https://arxiv.org/abs/2512.07961)
*Guilherme Seidyo Imai Aldeia,Joseph D. Romano,Fabricio Olivetti de Franca,Daniel S. Herman,William G. La Cava*

Main category: cs.LG

TL;DR: Brush是一种符号回归算法，结合决策树分割和非线性常数优化，用于开发数据驱动的临床风险评分系统


<details>
  <summary>Details</summary>
Motivation: 医疗决策常使用结合风险方程和规则的算法，但传统符号回归难以建模这种决策过程。符号回归具有数据驱动和可解释性优势，有望开发临床风险评分系统

Method: Brush算法结合决策树分割算法和非线性常数优化，将基于规则的逻辑无缝集成到符号回归和分类模型中

Result: Brush在SRBench上实现帕累托最优性能，成功复现两个广泛使用的临床评分系统，获得高准确率和可解释模型。相比决策树、随机森林和其他符号回归方法，Brush具有相当或更优的预测性能，同时产生更简单的模型

Conclusion: Brush算法能够有效开发数据驱动的临床风险评分系统，在保持高预测性能的同时提供可解释性，优于传统方法

Abstract: Medical decision-making makes frequent use of algorithms that combine risk equations with rules, providing clear and standardized treatment pathways. Symbolic regression (SR) traditionally limits its search space to continuous function forms and their parameters, making it difficult to model this decision-making. However, due to its ability to derive data-driven, interpretable models, SR holds promise for developing data-driven clinical risk scores. To that end we introduce Brush, an SR algorithm that combines decision-tree-like splitting algorithms with non-linear constant optimization, allowing for seamless integration of rule-based logic into symbolic regression and classification models. Brush achieves Pareto-optimal performance on SRBench, and was applied to recapitulate two widely used clinical scoring systems, achieving high accuracy and interpretable models. Compared to decision trees, random forests, and other SR methods, Brush achieves comparable or superior predictive performance while producing simpler models.

</details>


### [107] [CIP-Net: Continual Interpretable Prototype-based Network](https://arxiv.org/abs/2512.07981)
*Federico Di Valerio,Michela Proietti,Alessio Ragno,Roberto Capobianco*

Main category: cs.LG

TL;DR: CIP-Net是一种无需示例的自解释原型模型，用于持续学习，避免存储过去示例，保持简单架构，同时提供有用解释和强大性能。


<details>
  <summary>Details</summary>
Motivation: 持续学习面临灾难性遗忘的挑战，现有可解释方法大多使用事后解释或需要额外内存，导致可扩展性有限。需要一种无需存储过去示例、架构简单但仍能提供有用解释的自解释模型。

Method: 提出CIP-Net（自解释原型网络），这是一种无需示例的原型模型，通过自解释机制在预测时生成解释，避免存储过去示例，保持简单架构。

Result: CIP-Net在任务增量学习和类别增量学习设置中，相比之前的无示例和自解释方法，实现了最先进的性能，同时显著降低了内存开销。

Conclusion: CIP-Net为持续学习提供了一个实用且可解释的解决方案，通过自解释原型模型有效缓解灾难性遗忘问题，具有较低的内存开销和良好的可扩展性。

Abstract: Continual learning constrains models to learn new tasks over time without forgetting what they have already learned. A key challenge in this setting is catastrophic forgetting, where learning new information causes the model to lose its performance on previous tasks. Recently, explainable AI has been proposed as a promising way to better understand and reduce forgetting. In particular, self-explainable models are useful because they generate explanations during prediction, which can help preserve knowledge. However, most existing explainable approaches use post-hoc explanations or require additional memory for each new task, resulting in limited scalability. In this work, we introduce CIP-Net, an exemplar-free self-explainable prototype-based model designed for continual learning. CIP-Net avoids storing past examples and maintains a simple architecture, while still providing useful explanations and strong performance. We demonstrate that CIPNet achieves state-of-the-art performances compared to previous exemplar-free and self-explainable methods in both task- and class-incremental settings, while bearing significantly lower memory-related overhead. This makes it a practical and interpretable solution for continual learning.

</details>


### [108] [HOLE: Homological Observation of Latent Embeddings for Neural Network Interpretability](https://arxiv.org/abs/2512.07988)
*Sudhanva Manjunath Athreya,Paul Rosen*

Main category: cs.LG

TL;DR: HOLE方法通过持续同调分析深度神经网络，提取激活的拓扑特征并用多种可视化工具展示，以揭示表示结构、类别分离和模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在许多领域取得了显著成功，但其学习到的表示和决策过程仍然很大程度上不透明且难以解释。需要新的方法来分析和理解神经网络的内在工作机制。

Method: HOLE（潜在嵌入的同调观察）方法通过持续同调从神经激活中提取拓扑特征，并使用桑基图、热图、树状图和blob图等多种可视化技术展示这些特征，便于跨层检查表示结构和质量。

Result: 在标准数据集上使用多种判别模型进行评估，结果表明拓扑分析能够揭示与类别分离、特征解耦和模型鲁棒性相关的模式。该方法为理解表示质量和跨层可解释性提供了有效工具。

Conclusion: 拓扑分析为理解和改进深度学习系统提供了互补的视角，能够揭示神经网络表示中的结构模式，有助于提高模型的可解释性和鲁棒性分析。

Abstract: Deep learning models have achieved remarkable success across various domains, yet their learned representations and decision-making processes remain largely opaque and hard to interpret. This work introduces HOLE (Homological Observation of Latent Embeddings), a method for analyzing and interpreting deep neural networks through persistent homology. HOLE extracts topological features from neural activations and presents them using a suite of visualization techniques, including Sankey diagrams, heatmaps, dendrograms, and blob graphs. These tools facilitate the examination of representation structure and quality across layers. We evaluate HOLE on standard datasets using a range of discriminative models, focusing on representation quality, interpretability across layers, and robustness to input perturbations and model compression. The results indicate that topological analysis reveals patterns associated with class separation, feature disentanglement, and model robustness, providing a complementary perspective for understanding and improving deep learning systems.

</details>


### [109] [Bridging the Clinical Expertise Gap: Development of a Web-Based Platform for Accessible Time Series Forecasting and Analysis](https://arxiv.org/abs/2512.07992)
*Aaron D. Mullen,Daniel R. Harris,Svetla Slavova,V. K. Cody Bumgardner*

Main category: cs.LG

TL;DR: 开发了一个面向医疗领域的时间序列预测Web平台，降低技术门槛，支持数据可视化、模型训练和结果解释


<details>
  <summary>Details</summary>
Motivation: 时间序列预测在医疗等领域有广泛应用，但技术门槛高，需要专业知识分析数据、构建模型和解释结果，阻碍了这些技术的使用

Method: 开发Web平台，支持数据上传和可视化、多种可定制预测模型和训练技术，集成大语言模型提供参数推荐和结果解释

Result: 创建了使研究人员和临床医生能够轻松分析数据、训练预测模型和解释结果的平台，支持高度定制化

Conclusion: 该平台旨在集成到学习型医疗系统中，实现临床流程中的持续数据收集和推理，降低时间序列预测的技术门槛

Abstract: Time series forecasting has applications across domains and industries, especially in healthcare, but the technical expertise required to analyze data, build models, and interpret results can be a barrier to using these techniques. This article presents a web platform that makes the process of analyzing and plotting data, training forecasting models, and interpreting and viewing results accessible to researchers and clinicians. Users can upload data and generate plots to showcase their variables and the relationships between them. The platform supports multiple forecasting models and training techniques which are highly customizable according to the user's needs. Additionally, recommendations and explanations can be generated from a large language model that can help the user choose appropriate parameters for their data and understand the results for each model. The goal is to integrate this platform into learning health systems for continuous data collection and inference from clinical pipelines.

</details>


### [110] [Benchmarking Offline Multi-Objective Reinforcement Learning in Critical Care](https://arxiv.org/abs/2512.08012)
*Aryaman Bansal,Divya Sharma*

Main category: cs.LG

TL;DR: 在ICU等重症监护环境中，本文比较了三种离线多目标强化学习算法与单目标基线方法，发现PEDA DT算法在灵活性和性能上表现最佳，为个性化医疗决策提供了新框架。


<details>
  <summary>Details</summary>
Motivation: 重症监护中临床医生面临生存率最大化与资源使用最小化的冲突目标。传统单目标强化学习方法使用固定标量化奖励函数，导致策略僵化无法适应变化的临床优先级。需要一种能在离线环境下学习多目标策略的方法。

Method: 在MIMIC-IV数据集上，对三种离线多目标强化学习算法（CPQL、Adaptive CPQL、PEDA DT）与三种单目标基线方法（BC、CQL、DDQN）进行基准测试。使用离线策略评估（OPE）指标评估性能。

Result: PEDA DT算法相比静态标量化基线展现出更优的灵活性。结果证实序列建模架构在扩展到多目标条件生成时仍保持鲁棒性和有效性，延续了单目标决策变换器在医疗领域的先前发现。

Conclusion: 离线多目标强化学习是重症监护中实现个性化、可调整决策的有前景框架，无需重新训练即可适应不同临床优先级。

Abstract: In critical care settings such as the Intensive Care Unit, clinicians face the complex challenge of balancing conflicting objectives, primarily maximizing patient survival while minimizing resource utilization (e.g., length of stay). Single-objective Reinforcement Learning approaches typically address this by optimizing a fixed scalarized reward function, resulting in rigid policies that fail to adapt to varying clinical priorities. Multi-objective Reinforcement Learning (MORL) offers a solution by learning a set of optimal policies along the Pareto Frontier, allowing for dynamic preference selection at test time. However, applying MORL in healthcare necessitates strict offline learning from historical data.
  In this paper, we benchmark three offline MORL algorithms, Conditioned Conservative Pareto Q-Learning (CPQL), Adaptive CPQL, and a modified Pareto Efficient Decision Agent (PEDA) Decision Transformer (PEDA DT), against three scalarized single-objective baselines (BC, CQL, and DDQN) on the MIMIC-IV dataset. Using Off-Policy Evaluation (OPE) metrics, we demonstrate that PEDA DT algorithm offers superior flexibility compared to static scalarized baselines. Notably, our results extend previous findings on single-objective Decision Transformers in healthcare, confirming that sequence modeling architectures remain robust and effective when scaled to multi-objective conditioned generation. These findings suggest that offline MORL is a promising framework for enabling personalized, adjustable decision-making in critical care without the need for retraining.

</details>


### [111] [CLARITY: Medical World Model for Guiding Treatment Decisions by Modeling Context-Aware Disease Trajectories in Latent Space](https://arxiv.org/abs/2512.08029)
*Tianxingjian Ding,Yuanhao Zou,Chen Chen,Mubarak Shah,Yu Tian*

Main category: cs.LG

TL;DR: CLARITY是一个医学世界模型，通过在结构化潜在空间中预测疾病演化，整合时间和临床上下文，为个体化治疗规划提供可解释的轨迹和可操作建议。


<details>
  <summary>Details</summary>
Motivation: 当前肿瘤学临床决策需要预测动态疾病演化，但现有静态AI预测器无法完成此任务。现有医学世界模型方法通常忽略患者特定的时间和临床上下文，缺乏将预测与治疗决策连接的反馈机制。

Method: CLARITY在结构化潜在空间中直接预测疾病演化，明确整合时间间隔（时间上下文）和患者特定数据（临床上下文），将治疗条件下的进展建模为平滑、可解释的轨迹，从而生成生理上可信的个体化治疗计划。

Result: CLARITY在治疗规划方面达到最先进性能。在MU-Glioma-Post数据集上，该方法比最近的MeWM提升12%，并显著超越所有其他医学专用大语言模型。

Conclusion: CLARITY通过整合时间和临床上下文，在结构化潜在空间中预测疾病演化，为个体化肿瘤治疗规划提供了生理上可信、可解释且可操作的解决方案。

Abstract: Clinical decision-making in oncology requires predicting dynamic disease evolution, a task current static AI predictors cannot perform. While world models (WMs) offer a paradigm for generative prediction, existing medical applications remain limited. Existing methods often rely on stochastic diffusion models, focusing on visual reconstruction rather than causal, physiological transitions. Furthermore, in medical domain, models like MeWM typically ignore patient-specific temporal and clinical contexts and lack a feedback mechanism to link predictions to treatment decisions. To address these gaps, we introduce CLARITY, a medical world model that forecasts disease evolution directly within a structured latent space. It explicitly integrates time intervals (temporal context) and patient-specific data (clinical context) to model treatment-conditioned progression as a smooth, interpretable trajectory, and thus generate physiologically faithful, individualized treatment plans. Finally, CLARITY introduces a novel prediction-to-decision framework, translating latent rollouts into transparent, actionable recommendations. CLARITY demonstrates state-of-the-art performance in treatment planning. On the MU-Glioma-Post dataset, our approach outperforms recent MeWM by 12\%, and significantly surpasses all other medical-specific large language models.

</details>


### [112] [LUNA: Linear Universal Neural Attention with Generalization Guarantees](https://arxiv.org/abs/2512.08061)
*Ashkan Shahbazi,Ping He,Ali Abbasi,Yikun Bai,Xinran Liu,Elaheh Akbari,Darian Salehi,Navid NaderiAlizadeh,Soheil Kolouri*

Main category: cs.LG

TL;DR: LUNA是一种可学习的核化线性注意力机制，通过参数化核特征映射，在保持线性计算成本的同时达到甚至超越二次注意力的精度。


<details>
  <summary>Details</summary>
Motivation: 传统softmax注意力有O(n²)二次计算成本，限制了长序列应用。现有线性注意力机制虽然降低到O(n)，但依赖固定的随机特征映射，导致模型精度和计算效率之间存在根本性权衡。

Method: 提出LUNA机制，核心思想是核特征映射本身应该是可学习的而非固定的。通过参数化核，学习针对特定数据和任务的特征基，使用可学习的特征映射诱导正定核，并支持流式形式，实现序列长度的线性时间和内存扩展。

Result: 在Long Range Arena (LRA)上，在计算对等条件下（相同参数量、训练步数、近似FLOPs），LUNA在高效Transformer中达到最先进的平均准确率。在BERT和ViT-B/16检查点的后验转换中，替换softmax并微调后能恢复大部分原始性能，显著优于固定线性化方法。

Conclusion: LUNA通过可学习的核特征映射消除了线性注意力中精度与效率的权衡，在保持线性计算复杂度的同时实现了与二次注意力相当甚至更好的性能，为长序列建模提供了有效的解决方案。

Abstract: Scaling attention faces a critical bottleneck: the $\mathcal{O}(n^2)$ quadratic computational cost of softmax attention, which limits its application in long-sequence domains. While linear attention mechanisms reduce this cost to $\mathcal{O}(n)$, they typically rely on fixed random feature maps, such as random Fourier features or hand-crafted functions. This reliance on static, data-agnostic kernels creates a fundamental trade-off, forcing practitioners to sacrifice significant model accuracy for computational efficiency. We introduce \textsc{LUNA}, a kernelized linear attention mechanism that eliminates this trade-off, retaining linear cost while matching and surpassing the accuracy of quadratic attention. \textsc{LUNA} is built on the key insight that the kernel feature map itself should be learned rather than fixed a priori. By parameterizing the kernel, \textsc{LUNA} learns a feature basis tailored to the specific data and task, overcoming the expressive limitations of fixed-feature methods. \textsc{Luna} implements this with a learnable feature map that induces a positive-definite kernel and admits a streaming form, yielding linear time and memory scaling in the sequence length. Empirical evaluations validate our approach across diverse settings. On the Long Range Arena (LRA), \textsc{Luna} achieves state-of-the-art average accuracy among efficient Transformers under compute parity, using the same parameter count, training steps, and approximate FLOPs. \textsc{Luna} also excels at post-hoc conversion: replacing softmax in fine-tuned BERT and ViT-B/16 checkpoints and briefly fine-tuning recovers most of the original performance, substantially outperforming fixed linearizations.

</details>


### [113] [Deep Kernel Aalen-Johansen Estimator: An Interpretable and Flexible Neural Net Framework for Competing Risks](https://arxiv.org/abs/2512.08063)
*Xiaobin Shen,George H. Chen*

Main category: cs.LG

TL;DR: 提出Deep Kernel Aalen-Johansen (DKAJ)模型，将经典Aalen-Johansen估计器推广到深度学习框架，通过自动学习核函数衡量数据点相似性，实现竞争风险场景下的可解释性预测。


<details>
  <summary>Details</summary>
Motivation: 现有竞争风险模型在预测累积发生率函数(CIFs)时缺乏可解释性，难以提供直观的模型解释和可视化支持。需要开发既能保持预测性能又具备可解释性的深度学习方法。

Method: 提出DKAJ模型：1) 将每个数据点表示为多个簇的加权组合；2) 通过自动学习的核函数计算数据点之间的相似性权重；3) 当数据点仅对一个簇有非零权重时，其预测CIFs退化为经典Aalen-Johansen估计器在该簇上的结果；4) 提供可视化工具辅助模型解释。

Result: 在四个标准竞争风险数据集上，DKAJ模型与最先进的基线方法性能相当，同时能够提供可视化支持，增强了模型的可解释性。

Conclusion: DKAJ模型成功地将经典Aalen-Johansen估计器推广到深度学习框架，在保持预测性能的同时提供了可解释性，通过核函数学习相似性和簇权重表示，为竞争风险分析提供了新的可解释深度学习方法。

Abstract: We propose an interpretable deep competing risks model called the Deep Kernel Aalen-Johansen (DKAJ) estimator, which generalizes the classical Aalen-Johansen nonparametric estimate of cumulative incidence functions (CIFs). Each data point (e.g., patient) is represented as a weighted combination of clusters. If a data point has nonzero weight only for one cluster, then its predicted CIFs correspond to those of the classical Aalen-Johansen estimator restricted to data points from that cluster. These weights come from an automatically learned kernel function that measures how similar any two data points are. On four standard competing risks datasets, we show that DKAJ is competitive with state-of-the-art baselines while being able to provide visualizations to assist model interpretation.

</details>


### [114] [CAMO: Causality-Guided Adversarial Multimodal Domain Generalization for Crisis Classification](https://arxiv.org/abs/2512.08071)
*Pingchuan Ma,Chengshuai Zhao,Bohan Jiang,Saketh Vishnubhatla,Ujun Jeong,Alimohammad Beigi,Adrienne Raglin,Huan Liu*

Main category: cs.LG

TL;DR: 提出因果引导的多模态域泛化框架，通过对抗解耦和统一表示学习提升社交媒体危机分类在未见灾难类型上的泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有社交媒体危机分类方法主要依赖深度学习融合文本和视觉线索，在域内设置下表现良好，但在未见危机类型上泛化能力差。原因有二：1) 未能解耦虚假特征和因果特征，导致域偏移时性能下降；2) 未能对齐异构模态表示，阻碍单模态域泛化技术向多模态设置扩展

Method: 提出因果引导的多模态域泛化框架，结合对抗解耦和统一表示学习。对抗目标鼓励模型解耦并关注域不变因果特征；统一表示将不同模态特征对齐到共享潜在空间，使单模态域泛化策略能无缝扩展到多模态学习

Result: 在不同数据集上的实验表明，该方法在未见灾难场景中实现了最佳性能

Conclusion: 通过因果引导的对抗解耦和统一表示学习，成功提升了多模态危机分类在未见灾难类型上的泛化能力，为解决社交媒体危机信息提取中的域泛化挑战提供了有效方案

Abstract: Crisis classification in social media aims to extract actionable disaster-related information from multimodal posts, which is a crucial task for enhancing situational awareness and facilitating timely emergency responses. However, the wide variation in crisis types makes achieving generalizable performance across unseen disasters a persistent challenge. Existing approaches primarily leverage deep learning to fuse textual and visual cues for crisis classification, achieving numerically plausible results under in-domain settings. However, they exhibit poor generalization across unseen crisis types because they 1. do not disentangle spurious and causal features, resulting in performance degradation under domain shift, and 2. fail to align heterogeneous modality representations within a shared space, which hinders the direct adaptation of established single-modality domain generalization (DG) techniques to the multimodal setting. To address these issues, we introduce a causality-guided multimodal domain generalization (MMDG) framework that combines adversarial disentanglement with unified representation learning for crisis classification. The adversarial objective encourages the model to disentangle and focus on domain-invariant causal features, leading to more generalizable classifications grounded in stable causal mechanisms. The unified representation aligns features from different modalities within a shared latent space, enabling single-modality DG strategies to be seamlessly extended to multimodal learning. Experiments on the different datasets demonstrate that our approach achieves the best performance in unseen disaster scenarios.

</details>


### [115] [Unveiling Latent Knowledge in Chemistry Language Models through Sparse Autoencoders](https://arxiv.org/abs/2512.08077)
*Jaron Cohen,Alexander G. Hasson,Sara Tanovic*

Main category: cs.LG

TL;DR: 该研究将稀疏自编码器技术应用于化学语言模型，揭示了模型内部可解释的化学特征表示，这些特征与结构基序、物理化学性质和药物类别等化学知识相关。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型在药物和材料发现等高风险应用中的使用，机器学习可解释性变得日益重要。尽管化学语言模型在分子性质预测和生成方面表现出色，但其内部如何表示化学知识仍不清楚。

Method: 将稀疏自编码器技术扩展到化学语言模型，应用于FM4M SMI-TED化学基础模型，提取语义上有意义的潜在特征，并分析其在各种分子数据集上的激活模式。

Result: 发现这些模型编码了丰富的化学概念景观，识别出特定潜在特征与不同化学知识领域（包括结构基序、物理化学性质和药理药物类别）之间的相关性。

Conclusion: 该方法为揭示化学AI系统中的潜在知识提供了通用框架，对基础理解和实际部署都有重要意义，有望加速计算化学研究。

Abstract: Since the advent of machine learning, interpretability has remained a persistent challenge, becoming increasingly urgent as generative models support high-stakes applications in drug and material discovery. Recent advances in large language model (LLM) architectures have yielded chemistry language models (CLMs) with impressive capabilities in molecular property prediction and molecular generation. However, how these models internally represent chemical knowledge remains poorly understood. In this work, we extend sparse autoencoder techniques to uncover and examine interpretable features within CLMs. Applying our methodology to the Foundation Models for Materials (FM4M) SMI-TED chemistry foundation model, we extract semantically meaningful latent features and analyse their activation patterns across diverse molecular datasets. Our findings reveal that these models encode a rich landscape of chemical concepts. We identify correlations between specific latent features and distinct domains of chemical knowledge, including structural motifs, physicochemical properties, and pharmacological drug classes. Our approach provides a generalisable framework for uncovering latent knowledge in chemistry-focused AI systems. This work has implications for both foundational understanding and practical deployment; with the potential to accelerate computational chemistry research.

</details>


### [116] [Complexity of One-Dimensional ReLU DNNs](https://arxiv.org/abs/2512.08091)
*Jonathan Kogan,Hayden Jananthan,Jeremy Kepner*

Main category: cs.LG

TL;DR: 研究一维ReLU深度神经网络在无限宽度极限下的表达能力，证明线性区域数量随网络规模线性增长，并提出函数自适应稀疏性度量。


<details>
  <summary>Details</summary>
Motivation: 理解深度神经网络的表达能力是深度学习理论的核心问题。线性区域数量是衡量ReLU网络表达能力的重要指标，但现有研究对无限宽度极限下线性区域增长规律的理解有限，特别是对于具有非零偏置的随机初始化网络。

Method: 采用理论分析方法，研究一维全连接ReLU网络（He缩放初始化，带非零偏置）在无限宽度极限下的性质。通过数学证明推导线性区域数量的期望增长公式，并提出新的函数自适应稀疏性度量方法。

Result: 证明在无限宽度极限下，期望线性区域数量增长为∑_{i=1}^L n_i + o(∑_{i=1}^L n_i) + 1，其中n_ℓ是第ℓ隐藏层的神经元数。这表明线性区域数量随网络规模线性增长，而非指数增长。

Conclusion: 深度ReLU网络在无限宽度极限下表现出线性而非指数级的表达能力增长，这为理解深度网络的实际表达能力提供了新视角。提出的函数自适应稀疏性度量有助于评估网络对特定函数的表示效率。

Abstract: We study the expressivity of one-dimensional (1D) ReLU deep neural networks through the lens of their linear regions. For randomly initialized, fully connected 1D ReLU networks (He scaling with nonzero bias) in the infinite-width limit, we prove that the expected number of linear regions grows as $\sum_{i = 1}^L n_i + \mathop{o}\left(\sum_{i = 1}^L{n_i}\right) + 1$, where $n_\ell$ denotes the number of neurons in the $\ell$-th hidden layer. We also propose a function-adaptive notion of sparsity that compares the expected regions used by the network to the minimal number needed to approximate a target within a fixed tolerance.

</details>


### [117] [Training LLMs for Honesty via Confessions](https://arxiv.org/abs/2512.08093)
*Manas Joglekar,Jeremy Chen,Gabriel Wu,Jason Yosinski,Jasmine Wang,Boaz Barak,Amelia Glaese*

Main category: cs.LG

TL;DR: 提出一种通过"忏悔"机制促使大语言模型诚实报告自身缺陷的方法，在训练中为忏悔设置独立奖励，激励模型诚实揭露违规行为。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在报告自身行为和信念时可能存在不诚实问题，如夸大事实信心或掩盖不当行为。这种不诚实可能源于强化学习中的奖励塑造问题，训练过程可能无意中激励模型说谎。

Method: 提出"忏悔"机制：在模型给出原始答案后，要求其提供忏悔输出，完整说明其遵守政策和指令的情况。忏悔的奖励仅基于其诚实性，不影响主答案的奖励。通过训练GPT-5-Thinking模型来验证该方法。

Result: 当模型在主答案中说谎或隐瞒缺陷时，通常会在忏悔中诚实承认这些行为，且忏悔的诚实性随训练适度提升。忏悔机制支持多种推理时干预，包括监控、拒绝采样和向用户报告问题。

Conclusion: 忏悔机制是促使大语言模型诚实报告自身缺陷的有效方法，尤其在严重违规行为情况下效果显著。该方法为模型诚实性评估和干预提供了新途径。

Abstract: Large language models (LLMs) can be dishonest when reporting on their actions and beliefs -- for example, they may overstate their confidence in factual claims or cover up evidence of covert actions. Such dishonesty may arise due to the effects of reinforcement learning (RL), where challenges with reward shaping can result in a training process that inadvertently incentivizes the model to lie or misrepresent its actions.
  In this work we propose a method for eliciting an honest expression of an LLM's shortcomings via a self-reported *confession*. A confession is an output, provided upon request after a model's original answer, that is meant to serve as a full account of the model's compliance with the letter and spirit of its policies and instructions. The reward assigned to a confession during training is solely based on its honesty, and does not impact positively or negatively the main answer's reward. As long as the "path of least resistance" for maximizing confession reward is to surface misbehavior rather than covering it up, this incentivizes models to be honest in their confessions. Our findings provide some justification this empirical assumption, especially in the case of egregious model misbehavior.
  To demonstrate the viability of our approach, we train GPT-5-Thinking to produce confessions, and we evaluate its honesty in out-of-distribution scenarios measuring hallucination, instruction following, scheming, and reward hacking. We find that when the model lies or omits shortcomings in its "main" answer, it often confesses to these behaviors honestly, and this confession honesty modestly improves with training. Confessions can enable a number of inference-time interventions including monitoring, rejection sampling, and surfacing issues to the user.

</details>


### [118] [Scalable Offline Model-Based RL with Action Chunks](https://arxiv.org/abs/2512.08108)
*Kwanyoung Park,Seohong Park,Youngwoon Lee,Sergey Levine*

Main category: cs.LG

TL;DR: MAC提出了一种基于模型的离线强化学习方法，通过动作块模型减少长期预测误差，结合拒绝采样防止模型利用，在复杂长时域任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决离线强化学习中基于模型的价值扩展方法面临的挑战：长期预测时模型误差累积导致价值估计偏差，以及策略容易利用模型误差选择分布外动作的问题。

Method: 1. 动作块模型：预测动作序列（动作块）后的未来状态，减少单步预测的误差累积；2. 拒绝采样：从表达性强的行为动作块策略中采样，防止策略利用模型误差选择分布外动作。

Result: 在包含高达1亿条转移的大规模数据集上的实验表明，MAC在离线基于模型强化学习算法中表现最佳，特别是在具有挑战性的长时域任务上。

Conclusion: MAC通过动作块模型减少长期预测误差，结合拒绝采样机制，为离线强化学习处理复杂长时域任务提供了可扩展的解决方案。

Abstract: In this paper, we study whether model-based reinforcement learning (RL), in particular model-based value expansion, can provide a scalable recipe for tackling complex, long-horizon tasks in offline RL. Model-based value expansion fits an on-policy value function using length-n imaginary rollouts generated by the current policy and a learned dynamics model. While larger n reduces bias in value bootstrapping, it amplifies accumulated model errors over long horizons, degrading future predictions. We address this trade-off with an \emph{action-chunk} model that predicts a future state from a sequence of actions (an "action chunk") instead of a single action, which reduces compounding errors. In addition, instead of directly training a policy to maximize rewards, we employ rejection sampling from an expressive behavioral action-chunk policy, which prevents model exploitation from out-of-distribution actions. We call this recipe \textbf{Model-Based RL with Action Chunks (MAC)}. Through experiments on highly challenging tasks with large-scale datasets of up to 100M transitions, we show that MAC achieves the best performance among offline model-based RL algorithms, especially on challenging long-horizon tasks.

</details>


### [119] [Balanced Accuracy: The Right Metric for Evaluating LLM Judges -- Explained through Youden's J statistic](https://arxiv.org/abs/2512.08121)
*Stephane Collot,Colin Fraser,Justin Zhao,William F. Shen,Timon Willi,Ilias Leontiadis*

Main category: cs.LG

TL;DR: 论文提出在评估大语言模型时，应使用Youden's J统计量或平衡准确率来选择最佳分类器（评判者），而不是传统指标如准确率、精确率或F1分数，因为这些传统指标对类别不平衡敏感且可能扭曲流行率估计。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的严格评估依赖于比较模型在期望或不期望行为上的流行率（如任务通过率或政策违规率）。这些流行率估计由分类器（LLM作为评判者或人工标注者）产生，因此分类器的选择对可信评估至关重要。然而，常用的评估指标（如准确率、精确率、F1分数）对类别不平衡敏感，且受正类选择的任意性影响，可能导致选择那些扭曲流行率估计的评判者。

Method: 论文提出使用Youden's J统计量作为选择最佳评判者的理论依据，并指出平衡准确率是J的等价线性变换。通过理论分析和实证研究（包括实际案例和模拟实验），论证了使用平衡准确率选择分类器的优势。

Result: 研究表明，Youden's J统计量在理论上与选择最佳模型比较评判者相一致。使用平衡准确率选择评判者能够产生更好、更稳健的分类器选择，避免传统指标因类别不平衡和正类选择任意性带来的问题。

Conclusion: 在大语言模型评估中，应优先使用Youden's J统计量或平衡准确率来选择分类器，而不是传统的准确率、精确率或F1分数，以确保流行率估计的准确性和评估的可信度。

Abstract: Rigorous evaluation of large language models (LLMs) relies on comparing models by the prevalence of desirable or undesirable behaviors, such as task pass rates or policy violations. These prevalence estimates are produced by a classifier, either an LLM-as-a-judge or human annotators, making the choice of classifier central to trustworthy evaluation. Common metrics used for this choice, such as Accuracy, Precision, and F1, are sensitive to class imbalance and to arbitrary choices of positive class, and can favor judges that distort prevalence estimates. We show that Youden's $J$ statistic is theoretically aligned with choosing the best judge to compare models, and that Balanced Accuracy is an equivalent linear transformation of $J$. Through both analytical arguments and empirical examples and simulations, we demonstrate how selecting judges using Balanced Accuracy leads to better, more robust classifier selection.

</details>


### [120] [Long-only cryptocurrency portfolio management by ranking the assets: a neural network approach](https://arxiv.org/abs/2512.08124)
*Zijiang Yang*

Main category: cs.LG

TL;DR: 提出一种基于机器学习的加密货币投资组合管理方法，通过分析加密货币间的相对关系而非独立预测，使用神经网络预测未来收益排名并据此分配权重，在3.5年市场周期中实现优异表现。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注特定加密货币（如比特币）的价格走势预测并进行交易，但这种方法将加密货币视为独立个体。本文认为通过分析加密货币间的相对关系，可以更好地管理投资组合。

Method: 在每个时间步，使用神经网络预测所管理加密货币的未来收益排名，然后根据排名分配投资权重。这种方法利用了横截面信息，而非对单个加密货币进行独立预测。

Result: 在2020年5月至2023年11月的真实加密货币日数据回测中，该方法在经历了牛市、熊市和盘整市场的完整周期下，实现了夏普比率1.01和年化收益率64.26%，优于现有方法，且对交易费用增加具有鲁棒性。

Conclusion: 通过分析加密货币间的相对关系而非独立预测，提出的基于机器学习的投资组合管理方法在复杂市场条件下表现优异，证明了利用横截面信息进行加密货币投资组合管理的有效性。

Abstract: This paper will propose a novel machine learning based portfolio management method in the context of the cryptocurrency market. Previous researchers mainly focus on the prediction of the movement for specific cryptocurrency such as the bitcoin(BTC) and then trade according to the prediction. In contrast to the previous work that treats the cryptocurrencies independently, this paper manages a group of cryptocurrencies by analyzing the relative relationship. Specifically, in each time step, we utilize the neural network to predict the rank of the future return of the managed cryptocurrencies and place weights accordingly. By incorporating such cross-sectional information, the proposed methods is shown to profitable based on the backtesting experiments on the real daily cryptocurrency market data from May, 2020 to Nov, 2023. During this 3.5 years, the market experiences the full cycle of bullish, bearish and stagnant market conditions. Despite under such complex market conditions, the proposed method outperforms the existing methods and achieves a Sharpe ratio of 1.01 and annualized return of 64.26%. Additionally, the proposed method is shown to be robust to the increase of transaction fee.

</details>


### [121] [Improving the Sensitivity of Backdoor Detectors via Class Subspace Orthogonalization](https://arxiv.org/abs/2512.08129)
*Guangmingmei Yang,David J. Miller,George Kesidis*

Main category: cs.LG

TL;DR: 提出CSO方法，通过抑制内在特征来增强后门检测的敏感性，解决现有方法在易区分类别和隐蔽后门攻击中的失效问题


<details>
  <summary>Details</summary>
Motivation: 现有后门检测方法依赖目标类别的极端异常统计，但在两类情况下会失效：1）某些非目标类别本身就容易与其他类别区分，自然会产生极端统计值；2）后门特征相对内在类别特征很微弱时。关键观察是：后门目标类别的检测统计值同时来自后门触发器和内在特征，而非目标类别仅来自内在特征。

Method: 提出类子空间正交化（CSO）方法：利用少量干净样本，通过约束优化问题在优化检测统计值的同时，使其与类别的内在特征正交化。这样抑制内在特征后，非目标类别的统计值会大幅降低，而目标类别的后门触发器贡献仍然显著。

Result: CSO方法能够更敏感地检测后门攻击，特别是在具有挑战性的混合标签和自适应攻击场景下表现良好。

Conclusion: 通过抑制内在特征来增强检测统计值的敏感性是有效的后门检测策略，CSO方法为解决现有检测方法的局限性提供了新的思路。

Abstract: Most post-training backdoor detection methods rely on attacked models exhibiting extreme outlier detection statistics for the target class of an attack, compared to non-target classes. However, these approaches may fail: (1) when some (non-target) classes are easily discriminable from all others, in which case they may naturally achieve extreme detection statistics (e.g., decision confidence); and (2) when the backdoor is subtle, i.e., with its features weak relative to intrinsic class-discriminative features. A key observation is that the backdoor target class has contributions to its detection statistic from both the backdoor trigger and from its intrinsic features, whereas non-target classes only have contributions from their intrinsic features. To achieve more sensitive detectors, we thus propose to suppress intrinsic features while optimizing the detection statistic for a given class. For non-target classes, such suppression will drastically reduce the achievable statistic, whereas for the target class the (significant) contribution from the backdoor trigger remains. In practice, we formulate a constrained optimization problem, leveraging a small set of clean examples from a given class, and optimizing the detection statistic while orthogonalizing with respect to the class's intrinsic features. We dub this plug-and-play approach Class Subspace Orthogonalization (CSO) and assess it against challenging mixed-label and adaptive attacks.

</details>


### [122] [Biothreat Benchmark Generation Framework for Evaluating Frontier AI Models I: The Task-Query Architecture](https://arxiv.org/abs/2512.08130)
*Gary Ackerman,Brandon Behlendorf,Zachary Kallenborn,Sheriff Almakki,Doug Clifford,Jenna LaTourette,Hayley Peterson,Noah Sheinbaum,Olivia Shoemaker,Anna Wetzel*

Main category: cs.LG

TL;DR: 提出首个生物威胁基准生成框架，专门评估AI模型在细菌生物武器方面的风险，采用分层任务架构设计


<details>
  <summary>Details</summary>
Motivation: 需要量化前沿AI模型（特别是大语言模型）在生物恐怖主义方面的风险，现有基准往往忽略不同攻击者能力水平和操作风险因素

Method: 开发生物威胁基准生成框架，建立分层结构的生物威胁类别、要素和任务，创建细菌生物威胁模式作为任务查询架构的基础

Result: 提出了细菌生物威胁模式作为框架的第一个组件，为后续将查询转化为模型提示和模型评估提供基础架构

Conclusion: 该框架旨在为评估LLM在细菌生物风险方面提供稳健、可重用的结构，全面考虑技术和操作要求以及不同攻击者能力水平

Abstract: Both model developers and policymakers seek to quantify and mitigate the risk of rapidly-evolving frontier artificial intelligence (AI) models, especially large language models (LLMs), to facilitate bioterrorism or access to biological weapons. An important element of such efforts is the development of model benchmarks that can assess the biosecurity risk posed by a particular model. This paper describes the first component of a novel Biothreat Benchmark Generation (BBG) Framework. The BBG approach is designed to help model developers and evaluators reliably measure and assess the biosecurity risk uplift and general harm potential of existing and future AI models, while accounting for key aspects of the threat itself that are often overlooked in other benchmarking efforts, including different actor capability levels, and operational (in addition to purely technical) risk factors. As a pilot, the BBG is first being developed to address bacterial biological threats only. The BBG is built upon a hierarchical structure of biothreat categories, elements and tasks, which then serves as the basis for the development of task-aligned queries. This paper outlines the development of this biothreat task-query architecture, which we have named the Bacterial Biothreat Schema, while future papers will describe follow-on efforts to turn queries into model prompts, as well as how the resulting benchmarks can be implemented for model evaluation. Overall, the BBG Framework, including the Bacterial Biothreat Schema, seeks to offer a robust, re-usable structure for evaluating bacterial biological risks arising from LLMs across multiple levels of aggregation, which captures the full scope of technical and operational requirements for biological adversaries, and which accounts for a wide spectrum of biological adversary capabilities.

</details>


### [123] [Robust Agents in Open-Ended Worlds](https://arxiv.org/abs/2512.08139)
*Mikayel Samvelyan*

Main category: cs.LG

TL;DR: 该论文提出通过开放性和多智能体学习方法训练和评估鲁棒AI智能体，使其能够泛化到新环境、分布外输入以及与其他智能体的交互。


<details>
  <summary>Details</summary>
Motivation: 随着AI在各种应用中的普及，需要能够成功导航和适应不断变化的开放世界的智能体。关键挑战是确保这些AI智能体不仅能在训练期间观察到的熟悉环境中表现出色，还能有效泛化到以前未见过的多样化场景。

Method: 1. 引入MiniHack：基于NetHack游戏的沙盒框架，通过程序化内容生成创建多样化环境；2. 提出Maestro：生成对抗性课程的新方法，逐步增强RL智能体在两人零和游戏中的鲁棒性和泛化能力；3. 使用质量多样性方法系统识别复杂足球游戏领域中预训练RL策略的漏洞；4. 将鲁棒性探索扩展到LLM领域，使用进化搜索生成多样化有效输入来诊断和增强LLM对抗对抗性提示的鲁棒性。

Result: 开发了一系列方法和框架来训练和评估鲁棒AI智能体：MiniHack为RL智能体创建多样化任务环境；Maestro通过对抗性课程增强智能体鲁棒性；质量多样性方法成功识别了复杂多智能体环境中的策略漏洞；进化搜索方法有效生成对抗性提示来测试LLM鲁棒性。

Conclusion: 这项工作为AI鲁棒性的未来发展铺平了道路，使智能体不仅能够适应不断发展的世界，还能在面对不可预见的挑战和交互时蓬勃发展。通过开放性和多智能体学习方法的结合，论文展示了如何训练和评估能够有效泛化的鲁棒AI智能体。

Abstract: The growing prevalence of artificial intelligence (AI) in various applications underscores the need for agents that can successfully navigate and adapt to an ever-changing, open-ended world. A key challenge is ensuring these AI agents are robust, excelling not only in familiar settings observed during training but also effectively generalising to previously unseen and varied scenarios. In this thesis, we harness methodologies from open-endedness and multi-agent learning to train and evaluate robust AI agents capable of generalising to novel environments, out-of-distribution inputs, and interactions with other co-player agents. We begin by introducing MiniHack, a sandbox framework for creating diverse environments through procedural content generation. Based on the game of NetHack, MiniHack enables the construction of new tasks for reinforcement learning (RL) agents with a focus on generalisation. We then present Maestro, a novel approach for generating adversarial curricula that progressively enhance the robustness and generality of RL agents in two-player zero-sum games. We further probe robustness in multi-agent domains, utilising quality-diversity methods to systematically identify vulnerabilities in state-of-the-art, pre-trained RL policies within the complex video game football domain, characterised by intertwined cooperative and competitive dynamics. Finally, we extend our exploration of robustness to the domain of LLMs. Here, our focus is on diagnosing and enhancing the robustness of LLMs against adversarial prompts, employing evolutionary search to generate a diverse range of effective inputs that aim to elicit undesirable outputs from an LLM. This work collectively paves the way for future advancements in AI robustness, enabling the development of agents that not only adapt to an ever-evolving world but also thrive in the face of unforeseen challenges and interactions.

</details>


### [124] [PolyLingua: Margin-based Inter-class Transformer for Robust Cross-domain Language Detection](https://arxiv.org/abs/2512.08143)
*Ali Lotfi Rezaabad,Bikram Khanal,Shashwat Chaurasia,Lu Zeng,Dezhi Hong,Hossein Beshashati,Thomas Butler,Megan Ganji*

Main category: cs.LG

TL;DR: PolyLingua是一个轻量级Transformer模型，用于语言识别和细粒度语言分类，在计算和延迟受限环境中表现优异，超越Sonnet 3.5且参数减少10倍。


<details>
  <summary>Details</summary>
Motivation: 语言识别是多语言系统的关键第一步，现有工具在音乐请求等关键场景中表现不佳，开源工具准确度不足，而大型语言模型成本过高，不适合低延迟或低资源环境。

Method: 采用轻量级Transformer架构，结合实例级分离和类级对齐的两级对比学习框架，使用自适应边距，为相近语言生成紧凑且分离良好的嵌入表示。

Result: 在Amazon Massive数据集上达到99.25% F1分数，在Song数据集上达到98.15% F1分数，超越Sonnet 3.5，同时参数减少10倍。

Conclusion: PolyLingua为计算和延迟受限环境提供了高效的语言识别解决方案，在保持高准确度的同时显著降低了计算成本。

Abstract: Language identification is a crucial first step in multilingual systems such as chatbots and virtual assistants, enabling linguistically and culturally accurate user experiences. Errors at this stage can cascade into downstream failures, setting a high bar for accuracy. Yet, existing language identification tools struggle with key cases -- such as music requests where the song title and user language differ. Open-source tools like LangDetect, FastText are fast but less accurate, while large language models, though effective, are often too costly for low-latency or low-resource settings. We introduce PolyLingua, a lightweight Transformer-based model for in-domain language detection and fine-grained language classification. It employs a two-level contrastive learning framework combining instance-level separation and class-level alignment with adaptive margins, yielding compact and well-separated embeddings even for closely related languages. Evaluated on two challenging datasets -- Amazon Massive (multilingual digital assistant utterances) and a Song dataset (music requests with frequent code-switching) -- PolyLingua achieves 99.25% F1 and 98.15% F1, respectively, surpassing Sonnet 3.5 while using 10x fewer parameters, making it ideal for compute- and latency-constrained environments.

</details>


### [125] [TreeGRPO: Tree-Advantage GRPO for Online RL Post-Training of Diffusion Models](https://arxiv.org/abs/2512.08153)
*Zheng Ding,Weirui Ye*

Main category: cs.LG

TL;DR: TreeGRPO：一种新颖的强化学习框架，通过将去噪过程重构为搜索树，显著提高生成模型对齐的训练效率，实现2.4倍加速训练


<details>
  <summary>Details</summary>
Motivation: 强化学习后训练对于将生成模型与人类偏好对齐至关重要，但其高昂的计算成本阻碍了广泛应用。现有方法在样本效率和信用分配方面存在局限。

Method: 将去噪过程重构为搜索树，从共享的初始噪声样本出发，策略性地分支生成多个候选轨迹，同时高效重用它们的共同前缀。通过树结构实现：1）高样本效率；2）细粒度信用分配（通过奖励反向传播计算步骤特定优势）；3）摊销计算（多子分支实现每次前向传递多次策略更新）。

Result: 在扩散和基于流的模型上的实验表明，TreeGRPO实现2.4倍训练加速，在效率-奖励权衡空间中建立更优的帕累托前沿。在多个基准测试和奖励模型上持续优于GRPO基线。

Conclusion: TreeGRPO为基于强化学习的视觉生成模型对齐提供了可扩展且有效的途径，通过树结构搜索显著提高了训练效率和性能。

Abstract: Reinforcement learning (RL) post-training is crucial for aligning generative models with human preferences, but its prohibitive computational cost remains a major barrier to widespread adoption. We introduce \textbf{TreeGRPO}, a novel RL framework that dramatically improves training efficiency by recasting the denoising process as a search tree. From shared initial noise samples, TreeGRPO strategically branches to generate multiple candidate trajectories while efficiently reusing their common prefixes. This tree-structured approach delivers three key advantages: (1) \emph{High sample efficiency}, achieving better performance under same training samples (2) \emph{Fine-grained credit assignment} via reward backpropagation that computes step-specific advantages, overcoming the uniform credit assignment limitation of trajectory-based methods, and (3) \emph{Amortized computation} where multi-child branching enables multiple policy updates per forward pass. Extensive experiments on both diffusion and flow-based models demonstrate that TreeGRPO achieves \textbf{2.4$\times$ faster training} while establishing a superior Pareto frontier in the efficiency-reward trade-off space. Our method consistently outperforms GRPO baselines across multiple benchmarks and reward models, providing a scalable and effective pathway for RL-based visual generative model alignment. The project website is available at treegrpo.github.io.

</details>


### [126] [LayerPipe2: Multistage Pipelining and Weight Recompute via Improved Exponential Moving Average for Training Neural Networks](https://arxiv.org/abs/2512.08160)
*Nanda K. Unnikrishnan,Keshab K. Parhi*

Main category: cs.LG

TL;DR: LayerPipe2 通过形式化推导解决了梯度延迟插入的理论问题，揭示了延迟分配与网络结构的关系，并开发了管道感知移动平均来减少存储开销。


<details>
  <summary>Details</summary>
Motivation: 尽管 LayerPipe 在经验上成功加速了神经网络训练，但缺乏对梯度延迟插入位置和数量的理论理解。需要建立原则性框架来指导管道化训练的设计。

Method: 使用变量延迟梯度适应和重定时技术形式化推导 LayerPipe；分析网络结构确定合法延迟插入位置；开发管道感知移动平均来重构历史权重状态而非显式存储。

Result: 揭示了延迟分配规律：内部层需要较少延迟，外部层需要较长延迟；当每层都管道化时，延迟量仅取决于下游阶段数；分组管道化时，组内所有层共享相同延迟分配。

Conclusion: LayerPipe2 提供了一个原则性框架，能够指导 LayerPipe 架构构建、预测延迟需求并减轻存储负担，从而实现可扩展的管道化训练并控制通信计算权衡。

Abstract: In our prior work, LayerPipe, we had introduced an approach to accelerate training of convolutional, fully connected, and spiking neural networks by overlapping forward and backward computation. However, despite empirical success, a principled understanding of how much gradient delay needs to be introduced at each layer to achieve desired level of pipelining was not addressed. This paper, LayerPipe2, fills that gap by formally deriving LayerPipe using variable delayed gradient adaptation and retiming. We identify where delays may be legally inserted and show that the required amount of delay follows directly from the network structure where inner layers require fewer delays and outer layers require longer delays. When pipelining is applied at every layer, the amount of delay depends only on the number of remaining downstream stages. When layers are pipelined in groups, all layers in the group share the same assignment of delays. These insights not only explain previously observed scheduling patterns but also expose an often overlooked challenge that pipelining implicitly requires storage of historical weights. We overcome this storage bottleneck by developing a pipeline--aware moving average that reconstructs the required past states rather than storing them explicitly. This reduces memory cost without sacrificing the accuracy guarantees that makes pipelined learning viable. The result is a principled framework that illustrates how to construct LayerPipe architectures, predicts their delay requirements, and mitigates their storage burden, thereby enabling scalable pipelined training with controlled communication computation tradeoffs.

</details>


### [127] [MobileFineTuner: A Unified End-to-End Framework for Fine-Tuning LLMs on Mobile Phones](https://arxiv.org/abs/2512.08211)
*Jiaxiang Geng,Lunyu Zhao,Yiyi Lu,Bing Luo*

Main category: cs.LG

TL;DR: MobileFineTuner是一个开源框架，支持在普通手机上直接进行端到端的大语言模型微调，解决了移动设备内存和能耗限制的问题。


<details>
  <summary>Details</summary>
Motivation: 随着高质量公共数据接近枯竭，设备端微调可以利用私有用户数据同时保护隐私。然而现有方法主要是模拟或基于IoT设备和PC，普通手机领域尚未充分探索，缺乏开源框架支持实际LLM微调。

Method: 提出MobileFineTuner统一开源框架，支持全参数微调和参数高效微调。针对手机内存和能耗限制，引入参数分片、梯度累积和能量感知计算调度等系统级优化。

Result: 在真实手机上成功微调了GPT-2、Gemma 3和Qwen 2.5模型。大量实验和消融研究验证了所提优化的有效性，证明MobileFineTuner可作为设备端LLM训练研究的可行基础。

Conclusion: MobileFineTuner填补了移动设备LLM微调框架的空白，为利用私有用户数据同时保护隐私提供了实用解决方案，为未来设备端LLM训练研究奠定了基础。

Abstract: Mobile phones are the most ubiquitous end devices, generating vast amounts of human-authored data and serving as the primary platform for end-side applications. As high-quality public data for large language models (LLMs) approaches exhaustion, on-device fine-tuning provides an opportunity to leverage private user data while preserving privacy. However, existing approaches are predominantly simulation-based or rely on IoT devices and PCs, leaving commodity mobile phones largely unexplored. A key gap is the absence of an open-source framework that enables practical LLM fine-tuning on mobile phones. We present MobileFineTuner, a unified open-source framework that enables end-to-end LLM fine-tuning directly on commodity mobile phones. MobileFineTuner is designed for efficiency, scalability, and usability, supporting full-parameters fine-tuning (Full-FT) and parameter-efficient fine-tuning (PEFT). To address the memory and energy limitations inherent to mobile phones, we introduce system-level optimizations including parameter sharding, gradient accumulation, and energy-aware computation scheduling. We demonstrate the practicality of MobileFineTuner by fine-tuning GPT-2, Gemma 3, and Qwen 2.5 on real mobile phones. Extensive experiments and ablation studies validate the effectiveness of the proposed optimizations and establish MobileFineTuner as a viable foundation for future research on on-device LLM training.

</details>


### [128] [Correction of Decoupled Weight Decay](https://arxiv.org/abs/2512.08217)
*Jason Chuan-Chih Chou*

Main category: cs.LG

TL;DR: 该论文挑战了AdamW中权重衰减与学习率γ成正比的传统设定，提出权重衰减应与γ²成正比，基于稳态时权重范数稳定的假设，并验证了这种设定能改善训练动态和模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统上AdamW中的解耦权重衰减被设定为与学习率γ成正比，但作者质疑这一设定，认为基于正交性论证的γ²比例关系可能更合理，需要重新审视权重衰减的设定方式。

Method: 通过分析稳态时更新与权重无关的假设，推导出解耦权重衰减应与γ²成正比的理论依据；使用Scion优化器验证动量相关有效学习率的总更新贡献特性；通过实验验证权重和梯度范数的稳定性。

Result: 研究发现权重衰减∝γ²能实现稳定的权重和梯度范数，更好地控制训练动态；相比传统设定，这种比例关系能改善模型性能；总更新贡献由动量相关有效学习率更好地表征。

Conclusion: 解耦权重衰减应与学习率的平方γ²成正比，而不是传统的γ比例；这种设定基于稳态时权重范数稳定的理论推导，能改善训练动态控制并提升模型性能，为优化器设计提供了新视角。

Abstract: Decoupled weight decay, solely responsible for the performance advantage of AdamW over Adam, has long been set to proportional to learning rate $γ$ without questioning. Some researchers have recently challenged such assumption and argued that decoupled weight decay should be set $\propto γ^2$ instead based on orthogonality arguments at steady state. To the contrary, we find that eliminating the contribution of the perpendicular component of the update to the weight norm leads to little change to the training dynamics. Instead, we derive that decoupled weight decay $\propto γ^2$ results in stable weight norm based on the simple assumption that updates become independent of the weights at steady state, regardless of the nature of the optimizer. Based on the same assumption, we derive and empirically verify that the Total Update Contribution (TUC) of a minibatch under the Scion optimizer is better characterized by the momentum-dependent effective learning rate whose optimal value transfers and we show that decoupled weight decay $\propto γ^2$ leads to stable weight and gradient norms and allows us to better control the training dynamics and improve the model performance.

</details>


### [129] [PR-CapsNet: Pseudo-Riemannian Capsule Network with Adaptive Curvature Routing for Graph Learning](https://arxiv.org/abs/2512.08218)
*Ye Qin,Jingchao Wang,Yang Shi,Haiying Huang,Junxu Li,Weijian Liu,Tinghui Chen,Jinghui Qin*

Main category: cs.LG

TL;DR: PR-CapsNet将胶囊网络扩展到伪黎曼流形，通过自适应曲率路由解决传统胶囊网络在复杂图结构建模中的局限性，显著提升了图表示学习性能。


<details>
  <summary>Details</summary>
Motivation: 传统胶囊网络在固定曲率空间中建模复杂图结构存在局限性，而伪黎曼流形为图数据提供了更好的归纳偏置，但如何利用伪黎曼流形改进胶囊网络尚未充分探索。

Method: 1) 伪黎曼切空间路由：将胶囊状态分解为球面-时间和欧几里得-空间子空间；2) 自适应曲率路由：通过可学习曲率张量自适应融合不同曲率空间特征；3) 伪黎曼胶囊分类器：将胶囊嵌入投影到切空间并使用曲率加权softmax进行分类。

Result: 在节点和图分类基准测试中，PR-CapsNet超越了现有最先进模型，验证了其对复杂图结构的强大表示能力。

Conclusion: PR-CapsNet成功将胶囊网络扩展到伪黎曼流形，通过自适应曲率建模解决了传统方法的局限性，为复杂图结构表示学习提供了有效框架。

Abstract: Capsule Networks (CapsNets) show exceptional graph representation capacity via dynamic routing and vectorized hierarchical representations, but they model the complex geometries of real\-world graphs poorly by fixed\-curvature space due to the inherent geodesical disconnectedness issues, leading to suboptimal performance. Recent works find that non\-Euclidean pseudo\-Riemannian manifolds provide specific inductive biases for embedding graph data, but how to leverage them to improve CapsNets is still underexplored. Here, we extend the Euclidean capsule routing into geodesically disconnected pseudo\-Riemannian manifolds and derive a Pseudo\-Riemannian Capsule Network (PR\-CapsNet), which models data in pseudo\-Riemannian manifolds of adaptive curvature, for graph representation learning. Specifically, PR\-CapsNet enhances the CapsNet with Adaptive Pseudo\-Riemannian Tangent Space Routing by utilizing pseudo\-Riemannian geometry. Unlike single\-curvature or subspace\-partitioning methods, PR\-CapsNet concurrently models hierarchical and cluster or cyclic graph structures via its versatile pseudo\-Riemannian metric. It first deploys Pseudo\-Riemannian Tangent Space Routing to decompose capsule states into spherical\-temporal and Euclidean\-spatial subspaces with diffeomorphic transformations. Then, an Adaptive Curvature Routing is developed to adaptively fuse features from different curvature spaces for complex graphs via a learnable curvature tensor with geometric attention from local manifold properties. Finally, a geometric properties\-preserved Pseudo\-Riemannian Capsule Classifier is developed to project capsule embeddings to tangent spaces and use curvature\-weighted softmax for classification. Extensive experiments on node and graph classification benchmarks show PR\-CapsNet outperforms SOTA models, validating PR\-CapsNet's strong representation power for complex graph structures.

</details>


### [130] [Persistent Topological Structures and Cohomological Flows as a Mathematical Framework for Brain-Inspired Representation Learning](https://arxiv.org/abs/2512.08241)
*Preksha Girish,Rachana Mysore,Mahanthesha U,Shrey Kumar,Shipra Prashant*

Main category: cs.LG

TL;DR: 提出基于持久拓扑结构与上同调流的数学严谨框架，将神经计算重构为动态单纯复形上链映射的演化，实现跨时空和功能状态的表示学习。


<details>
  <summary>Details</summary>
Motivation: 为脑启发表示学习建立严格的数学基础，通过拓扑结构和同调理论捕捉大脑状态中的不变特征，解决现有深度架构在流形一致性和噪声鲁棒性方面的不足。

Method: 将神经计算重构为动态单纯复形上的链映射演化，结合代数拓扑与微分几何构建上同调算子，使用持久同调、层上同调和谱拉普拉斯分析合成与真实神经数据。

Result: 模型在流形一致性和噪声鲁棒性方面优于图神经网络和基于流形的深度架构，验证了拓扑驱动表示学习的有效性。

Conclusion: 建立了拓扑驱动表示学习的连贯数学基础，为脑启发计算提供了严格的代数拓扑框架，展示了拓扑结构在表示学习中的重要性。

Abstract: This paper presents a mathematically rigorous framework for brain-inspired representation learning founded on the interplay between persistent topological structures and cohomological flows. Neural computation is reformulated as the evolution of cochain maps over dynamic simplicial complexes, enabling representations that capture invariants across temporal, spatial, and functional brain states. The proposed architecture integrates algebraic topology with differential geometry to construct cohomological operators that generalize gradient-based learning within a homological landscape. Synthetic data with controlled topological signatures and real neural datasets are jointly analyzed using persistent homology, sheaf cohomology, and spectral Laplacians to quantify stability, continuity, and structural preservation. Empirical results demonstrate that the model achieves superior manifold consistency and noise resilience compared to graph neural and manifold-based deep architectures, establishing a coherent mathematical foundation for topology-driven representation learning.

</details>


### [131] [SPROCKET: Extending ROCKET to Distance-Based Time-Series Transformations With Prototypes](https://arxiv.org/abs/2512.08246)
*Nicholas Harner*

Main category: cs.LG

TL;DR: SPROCKET是一种基于原型的新型时间序列特征工程方法，在UCR和UEA数据集上表现与现有卷积算法相当，其MR-HY-SP集成模型超越了之前最好的卷积集成HYDRA-MR。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列分类算法主要依赖特征工程策略，其中ROCKET通过随机核特征取得了优异性能。作者希望探索基于原型的特征工程策略是否能进一步提升时间序列分类的性能。

Method: 提出了SPROCKET（Selected Prototype Random Convolutional Kernel Transform）方法，这是一种基于原型的新特征工程策略。该方法通过选择原型来生成特征，并与MultiROCKET和HYDRA结合形成MR-HY-SP集成模型。

Result: 在UCR和UEA时间序列分类数据集的大多数任务上，SPROCKET取得了与现有卷积算法相当的性能。MR-HY-SP集成模型的平均准确率排名超过了之前最好的卷积集成HYDRA-MR。

Conclusion: 基于原型的特征变换能够增强时间序列分类的准确性和鲁棒性，SPROCKET为时间序列分类提供了一种有效的特征工程新策略。

Abstract: Classical Time Series Classification algorithms are dominated by feature engineering strategies. One of the most prominent of these transforms is ROCKET, which achieves strong performance through random kernel features. We introduce SPROCKET (Selected Prototype Random Convolutional Kernel Transform), which implements a new feature engineering strategy based on prototypes. On a majority of the UCR and UEA Time Series Classification archives, SPROCKET achieves performance comparable to existing convolutional algorithms and the new MR-HY-SP ( MultiROCKET-HYDRA-SPROCKET) ensemble's average accuracy ranking exceeds HYDRA-MR, the previous best convolutional ensemble's performance. These experimental results demonstrate that prototype-based feature transformation can enhance both accuracy and robustness in time series classification.

</details>


### [132] [Wavelet-Accelerated Physics-Informed Quantum Neural Network for Multiscale Partial Differential Equations](https://arxiv.org/abs/2512.08256)
*Deepak Gupta,Himanshu Pandey,Ratikanta Behera*

Main category: cs.LG

TL;DR: 提出基于小波的物理信息量子神经网络框架，用于高效求解具有尖锐梯度、刚度、快速局部变化和高振荡特性的多尺度偏微分方程，相比传统方法显著减少可训练参数和计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统物理信息神经网络(PINNs)及其量子版本(量子PINNs)在求解多尺度特征时面临挑战，且依赖自动微分构建损失函数导致计算开销大、训练时间长。需要开发能高效处理多尺度振荡问题的新方法。

Method: 提出小波加速的物理信息量子神经网络框架，将小波的多分辨率特性融入量子神经网络架构，消除对自动微分的依赖，增强网络捕捉多尺度问题局部和全局特征的能力。

Result: 数值实验表明，该方法相比经典小波PINNs减少95%以上可训练参数，收敛更快；相比现有量子PINNs提速3-5倍，在求解多尺度振荡问题时获得更高精度。

Conclusion: 该小波加速的物理信息量子神经网络框架能高效求解具有挑战性的多尺度和振荡问题，在减少参数、降低计算复杂度和提高收敛速度方面表现出显著优势。

Abstract: This work proposes a wavelet-based physics-informed quantum neural network framework to efficiently address multiscale partial differential equations that involve sharp gradients, stiffness, rapid local variations, and highly oscillatory behavior. Traditional physics-informed neural networks (PINNs) have demonstrated substantial potential in solving differential equations, and their quantum counterparts, quantum-PINNs, exhibit enhanced representational capacity with fewer trainable parameters. However, both approaches face notable challenges in accurately solving multiscale features. Furthermore, their reliance on automatic differentiation for constructing loss functions introduces considerable computational overhead, resulting in longer training times. To overcome these challenges, we developed a wavelet-accelerated physics-informed quantum neural network that eliminates the need for automatic differentiation, significantly reducing computational complexity. The proposed framework incorporates the multiresolution property of wavelets within the quantum neural network architecture, thereby enhancing the network's ability to effectively capture both local and global features of multiscale problems. Numerical experiments demonstrate that our proposed method achieves superior accuracy while requiring less than five percent of the trainable parameters compared to classical wavelet-based PINNs, resulting in faster convergence. Moreover, it offers a speedup of three to five times compared to existing quantum PINNs, highlighting the potential of the proposed approach for efficiently solving challenging multiscale and oscillatory problems.

</details>


### [133] [Geometric-Stochastic Multimodal Deep Learning for Predictive Modeling of SUDEP and Stroke Vulnerability](https://arxiv.org/abs/2512.08257)
*Preksha Girish,Rachana Mysore,Mahanthesha U,Shrey Kumar,Misbah Fatimah Annigeri,Tanish Jain*

Main category: cs.LG

TL;DR: 提出一个统一的几何-随机多模态深度学习框架，整合多种生理信号来建模癫痫猝死和卒中易感性，通过流形嵌入、分数随机动力学等方法提高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 癫痫猝死和急性缺血性卒中是危及生命的疾病，涉及皮层、脑干和自主神经系统的复杂相互作用，需要整合多模态信号进行早期检测和风险分层。

Method: 结合黎曼流形嵌入、李群不变特征表示、分数随机动力学、哈密顿能量流建模和跨模态注意力机制，使用分数流行病扩散在结构脑图上建模卒中传播。

Result: 在MULTI-CLARID数据集上展示了改进的预测准确性，并从流形曲率、分数记忆指数、注意力熵和扩散中心性中获得了可解释的生物标志物。

Conclusion: 该框架为神经自主神经疾病的早期检测、风险分层和可解释的多模态建模提供了数学原理基础。

Abstract: Sudden Unexpected Death in Epilepsy (SUDEP) and acute ischemic stroke are life-threatening conditions involving complex interactions across cortical, brainstem, and autonomic systems. We present a unified geometric-stochastic multimodal deep learning framework that integrates EEG, ECG, respiration, SpO2, EMG, and fMRI signals to model SUDEP and stroke vulnerability. The approach combines Riemannian manifold embeddings, Lie-group invariant feature representations, fractional stochastic dynamics, Hamiltonian energy-flow modeling, and cross-modal attention mechanisms. Stroke propagation is modeled using fractional epidemic diffusion over structural brain graphs. Experiments on the MULTI-CLARID dataset demonstrate improved predictive accuracy and interpretable biomarkers derived from manifold curvature, fractional memory indices, attention entropy, and diffusion centrality. The proposed framework provides a mathematically principled foundation for early detection, risk stratification, and interpretable multimodal modeling in neural-autonomic disorders.

</details>


### [134] [Mathematical Foundations of Neural Tangents and Infinite-Width Networks](https://arxiv.org/abs/2512.08264)
*Rachana Mysore,Preksha Girish,Kavitha Jayaram,Shrey Kumar,Preksha Girish,Shravan Sanjeev Bagal,Kavitha Jayaram,Shreya Aravind Shastry*

Main category: cs.LG

TL;DR: 提出NTK-ECRN架构，结合傅里叶特征嵌入、残差连接和随机深度，在无限宽度机制下分析NTK演化，建立谱性质与泛化、优化稳定性的理论联系。


<details>
  <summary>Details</summary>
Motivation: 研究无限宽度机制下神经网络的数学基础，通过神经正切核(NTK)理论分析训练过程中的核演化，为理论分析与实际深度学习架构搭建桥梁。

Method: 提出NTK-ECRN架构，集成傅里叶特征嵌入、层间缩放残差连接和随机深度，推导NTK动态边界，表征特征值演化，将谱性质与泛化、优化稳定性联系起来。

Result: 在合成和基准数据集上验证了预测的核行为，展示了改进的训练稳定性和泛化性能，为无限宽度理论与实际深度学习架构提供了综合框架。

Conclusion: 该工作建立了连接无限宽度理论与实际深度学习架构的全面框架，通过NTK-ECRN架构实现了对训练过程中核演化的严格分析，为神经网络的理论理解提供了新视角。

Abstract: We investigate the mathematical foundations of neural networks in the infinite-width regime through the Neural Tangent Kernel (NTK). We propose the NTK-Eigenvalue-Controlled Residual Network (NTK-ECRN), an architecture integrating Fourier feature embeddings, residual connections with layerwise scaling, and stochastic depth to enable rigorous analysis of kernel evolution during training. Our theoretical contributions include deriving bounds on NTK dynamics, characterizing eigenvalue evolution, and linking spectral properties to generalization and optimization stability. Empirical results on synthetic and benchmark datasets validate the predicted kernel behavior and demonstrate improved training stability and generalization. This work provides a comprehensive framework bridging infinite-width theory and practical deep-learning architectures.

</details>


### [135] [SOFA-FL: Self-Organizing Hierarchical Federated Learning with Adaptive Clustered Data Sharing](https://arxiv.org/abs/2512.08267)
*Yi Ni,Xinkun Wang,Han Zhang*

Main category: cs.LG

TL;DR: SOFA-FL是一个自组织分层联邦学习框架，通过动态聚类、拓扑重构和自适应数据共享来解决数据异构性和固定网络拓扑的挑战。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在动态环境中面临数据异构性和固定网络拓扑的挑战，需要能够自适应演化的系统来应对数据分布的变化。

Method: 提出SOFA-FL框架，包含三个核心机制：1) DMAC动态多分支凝聚聚类构建初始层次结构；2) SHAPE自组织层次自适应传播与演化，通过嫁接、剪枝、合并和净化操作动态重构拓扑；3) 自适应聚类数据共享，允许客户端与集群节点间进行受控的部分数据交换。

Result: SOFA-FL能够有效捕捉客户端间的动态关系，增强个性化能力，无需依赖预定的集群结构。

Conclusion: SOFA-FL通过自组织和自适应机制解决了联邦学习在动态环境中的关键挑战，为分层联邦学习系统提供了灵活且高效的解决方案。

Abstract: Federated Learning (FL) faces significant challenges in evolving environments, particularly regarding data heterogeneity and the rigidity of fixed network topologies. To address these issues, this paper proposes \textbf{SOFA-FL} (Self-Organizing Hierarchical Federated Learning with Adaptive Clustered Data Sharing), a novel framework that enables hierarchical federated systems to self-organize and adapt over time.
  The framework is built upon three core mechanisms: (1) \textbf{Dynamic Multi-branch Agglomerative Clustering (DMAC)}, which constructs an initial efficient hierarchical structure; (2) \textbf{Self-organizing Hierarchical Adaptive Propagation and Evolution (SHAPE)}, which allows the system to dynamically restructure its topology through atomic operations -- grafting, pruning, consolidation, and purification -- to adapt to changes in data distribution; and (3) \textbf{Adaptive Clustered Data Sharing}, which mitigates data heterogeneity by enabling controlled partial data exchange between clients and cluster nodes.
  By integrating these mechanisms, SOFA-FL effectively captures dynamic relationships among clients and enhances personalization capabilities without relying on predetermined cluster structures.

</details>


### [136] [gHAWK: Local and Global Structure Encoding for Scalable Training of Graph Neural Networks on Knowledge Graphs](https://arxiv.org/abs/2512.08274)
*Humera Sabir,Fatima Farooq,Ashraf Aboulnaga*

Main category: cs.LG

TL;DR: gHAWK：一种用于大规模知识图谱的可扩展GNN训练框架，通过预计算结构特征来提升训练效率和模型性能


<details>
  <summary>Details</summary>
Motivation: 现有消息传递GNN在处理大规模知识图谱时面临扩展性问题，因为迭代的消息传递过程效率低下，特别是在小批量训练中，节点只能看到其邻域的局部视图

Method: gHAWK引入预处理步骤，预计算每个节点的结构特征：(a) Bloom过滤器编码局部邻域结构，(b) TransE嵌入表示节点在图中全局位置。这些特征与领域特定特征融合后，可集成到任何GNN技术中

Result: 在Open Graph Benchmark大型数据集上的实验表明，gHAWK在节点属性预测和链接预测任务上实现了最先进的准确率和更低的训练时间，在三个图谱上位居OGB排行榜榜首

Conclusion: 通过为消息传递训练增强结构先验，gHAWK显著减少了内存使用、加速了收敛并提高了模型准确性，为大规模知识图谱的GNN训练提供了有效的解决方案

Abstract: Knowledge Graphs (KGs) are a rich source of structured, heterogeneous data, powering a wide range of applications. A common approach to leverage this data is to train a graph neural network (GNN) on the KG. However, existing message-passing GNNs struggle to scale to large KGs because they rely on the iterative message passing process to learn the graph structure, which is inefficient, especially under mini-batch training, where a node sees only a partial view of its neighborhood. In this paper, we address this problem and present gHAWK, a novel and scalable GNN training framework for large KGs. The key idea is to precompute structural features for each node that capture its local and global structure before GNN training even begins. Specifically, gHAWK introduces a preprocessing step that computes: (a)~Bloom filters to compactly encode local neighborhood structure, and (b)~TransE embeddings to represent each node's global position in the graph. These features are then fused with any domain-specific features (e.g., text embeddings), producing a node feature vector that can be incorporated into any GNN technique. By augmenting message-passing training with structural priors, gHAWK significantly reduces memory usage, accelerates convergence, and improves model accuracy. Extensive experiments on large datasets from the Open Graph Benchmark (OGB) demonstrate that gHAWK achieves state-of-the-art accuracy and lower training time on both node property prediction and link prediction tasks, topping the OGB leaderboard for three graphs.

</details>


### [137] [Jacobian Aligned Random Forests](https://arxiv.org/abs/2512.08306)
*Sarwesh Rauniyar*

Main category: cs.LG

TL;DR: JARF使用随机森林预测的梯度计算全局线性预条件器，通过特征空间旋转提升轴对齐决策树处理旋转边界和特征交互的能力，保持简单性同时达到斜向森林的效果。


<details>
  <summary>Details</summary>
Motivation: 轴对齐决策树快速稳定但难以处理旋转或交互依赖的决策边界，而斜向森林虽然能解决但计算成本高、实现复杂。需要一种既能处理复杂边界又保持简单性的方法。

Method: 首先训练轴对齐森林估计类别概率或回归输出，计算预测相对于每个特征的有限差分梯度，聚合为期望雅可比外积（扩展EGOP），作为全局线性预条件器。该预条件器对特征空间进行单次全局旋转，然后将变换后的数据输入标准轴对齐森林。

Result: 在表格分类和回归基准测试中，这种预条件处理一致提升轴对齐森林性能，通常匹配或超越斜向基线，同时改善训练时间。理论分析表明能恢复斜向森林大部分精度。

Conclusion: 监督预条件处理能在保持轴对齐树简单性和鲁棒性的同时，恢复斜向森林的准确性，为处理复杂决策边界提供了高效实用的解决方案。

Abstract: Axis-aligned decision trees are fast and stable but struggle on datasets with rotated or interaction-dependent decision boundaries, where informative splits require linear combinations of features rather than single-feature thresholds. Oblique forests address this with per-node hyperplane splits, but at added computational cost and implementation complexity. We propose a simple alternative: JARF, Jacobian-Aligned Random Forests. Concretely, we first fit an axis-aligned forest to estimate class probabilities or regression outputs, compute finite-difference gradients of these predictions with respect to each feature, aggregate them into an expected Jacobian outer product that generalizes the expected gradient outer product (EGOP), and use it as a single global linear preconditioner for all inputs. This supervised preconditioner applies a single global rotation of the feature space, then hands the transformed data back to a standard axis-aligned forest, preserving off-the-shelf training pipelines while capturing oblique boundaries and feature interactions that would otherwise require many axis-aligned splits to approximate. The same construction applies to any model that provides gradients, though we focus on random forests and gradient-boosted trees in this work. On tabular classification and regression benchmarks, this preconditioning consistently improves axis-aligned forests and often matches or surpasses oblique baselines while improving training time. Our experimental results and theoretical analysis together indicate that supervised preconditioning can recover much of the accuracy of oblique forests while retaining the simplicity and robustness of axis-aligned trees.

</details>


### [138] [Minimizing Layerwise Activation Norm Improves Generalization in Federated Learning](https://arxiv.org/abs/2512.08314)
*M Yashwanth,Gaurav Kumar Nayak,Harsh Rangwani,Arya Singh,R. Venkatesh Babu,Anirban Chakraborty*

Main category: cs.LG

TL;DR: 提出一种名为MAN的联邦学习正则化方法，通过最小化客户端模型各层激活范数来约束优化问题的平坦性，从而提高联邦学习模型的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习方法可能导致全局模型收敛到"尖锐最小值"，从而损害模型的泛化能力。需要改进联邦学习优化问题，使模型收敛到更平坦的最小值以提高泛化性能。

Method: 提出平坦性约束的联邦学习优化问题，通过约束Hessian矩阵最大特征值来实现。提出MAN正则化技术，在客户端训练时最小化各层激活范数，理论证明这能降低客户端损失函数的层间Hessian最大特征值。

Result: 将提出的平坦性约束优化应用于现有联邦学习方法，取得了显著改进，建立了新的state-of-the-art性能。

Conclusion: MAN正则化通过约束平坦性有效提高了联邦学习模型的泛化性能，理论分析和实验结果都验证了该方法的有效性。

Abstract: Federated Learning (FL) is an emerging machine learning framework that enables multiple clients (coordinated by a server) to collaboratively train a global model by aggregating the locally trained models without sharing any client's training data. It has been observed in recent works that learning in a federated manner may lead the aggregated global model to converge to a 'sharp minimum' thereby adversely affecting the generalizability of this FL-trained model. Therefore, in this work, we aim to improve the generalization performance of models trained in a federated setup by introducing a 'flatness' constrained FL optimization problem. This flatness constraint is imposed on the top eigenvalue of the Hessian computed from the training loss. As each client trains a model on its local data, we further re-formulate this complex problem utilizing the client loss functions and propose a new computationally efficient regularization technique, dubbed 'MAN,' which Minimizes Activation's Norm of each layer on client-side models. We also theoretically show that minimizing the activation norm reduces the top eigenvalue of the layer-wise Hessian of the client's loss, which in turn decreases the overall Hessian's top eigenvalue, ensuring convergence to a flat minimum. We apply our proposed flatness-constrained optimization to the existing FL techniques and obtain significant improvements, thereby establishing new state-of-the-art.

</details>


### [139] [A Multivariate Bernoulli-Based Sampling Method for Multi-Label Data with Application to Meta-Research](https://arxiv.org/abs/2512.08371)
*Simon Chung,Colby J. Vorland,Donna L. Maney,Andrew W. Brown*

Main category: cs.LG

TL;DR: 提出一种考虑标签依赖关系的多标签数据集采样算法，使用多元伯努利分布建模标签分布，通过计算标签组合权重实现目标分布采样


<details>
  <summary>Details</summary>
Motivation: 多标签数据集中标签通常不互斥且频率差异大，传统采样方法难以同时保证稀有标签的充分表示和已知的分布偏差

Method: 使用多元伯努利分布建模多标签问题，基于观测标签频率估计分布参数，计算每个标签组合的权重，实现考虑标签依赖关系的加权采样

Result: 应用于Web of Science的64个生物医学主题类别研究文章，成功保持了类别频率顺序，减少了最频繁与最稀有类别的频率差异，并考虑了类别依赖关系

Conclusion: 该方法能产生更平衡的子样本，增强少数类别的代表性，有效解决了多标签数据集中标签频率差异大和依赖关系的采样挑战

Abstract: Datasets may contain observations with multiple labels. If the labels are not mutually exclusive, and if the labels vary greatly in frequency, obtaining a sample that includes sufficient observations with scarcer labels to make inferences about those labels, and which deviates from the population frequencies in a known manner, creates challenges. In this paper, we consider a multivariate Bernoulli distribution as our underlying distribution of a multi-label problem. We present a novel sampling algorithm that takes label dependencies into account. It uses observed label frequencies to estimate multivariate Bernoulli distribution parameters and calculate weights for each label combination. This approach ensures the weighted sampling acquires target distribution characteristics while accounting for label dependencies. We applied this approach to a sample of research articles from Web of Science labeled with 64 biomedical topic categories. We aimed to preserve category frequency order, reduce frequency differences between most and least common categories, and account for category dependencies. This approach produced a more balanced sub-sample, enhancing the representation of minority categories.

</details>


### [140] [Fully Decentralized Certified Unlearning](https://arxiv.org/abs/2512.08443)
*Hithem Lamri,Michail Maniatakos*

Main category: cs.LG

TL;DR: 提出RR-DU方法，用于去中心化网络中的认证遗忘，通过随机游走结合梯度操作、噪声注入和信任区域投影，提供收敛性保证、隐私证书和删除容量界限。


<details>
  <summary>Details</summary>
Motivation: 当前认证遗忘研究主要集中在集中式和服务器协调的联邦学习设置中，而去中心化网络（无协调器的对等通信）中的认证遗忘研究不足，需要解决隐私请求和数据中毒情况下的模型遗忘问题。

Method: 提出RR-DU方法：在遗忘客户端对遗忘集执行一步投影梯度上升，在其他客户端对保留数据执行几何分布次数的投影下降，结合子采样高斯噪声和将模型投影到原始模型周围的信任区域。

Result: 在凸情况下提供收敛保证，在非凸情况下提供平稳性保证；通过子采样高斯Rényi DP提供(ε,δ)网络遗忘证书；提供与遗忘-本地数据比率成比例的删除容量界限。在MNIST和CIFAR-10上，RR-DU在满足给定(ε,δ)的同时，比去中心化DP基线获得更高的测试准确率，并将遗忘准确率降低到随机猜测水平（约10%）。

Conclusion: RR-DU方法有效解决了去中心化网络中的认证遗忘问题，在隐私保护、模型效用和遗忘效果之间取得了良好平衡，量化了去中心化对隐私-效用权衡的影响。

Abstract: Machine unlearning (MU) seeks to remove the influence of specified data from a trained model in response to privacy requests or data poisoning. While certified unlearning has been analyzed in centralized and server-orchestrated federated settings (via guarantees analogous to differential privacy, DP), the decentralized setting -- where peers communicate without a coordinator remains underexplored. We study certified unlearning in decentralized networks with fixed topologies and propose RR-DU, a random-walk procedure that performs one projected gradient ascent step on the forget set at the unlearning client and a geometrically distributed number of projected descent steps on the retained data elsewhere, combined with subsampled Gaussian noise and projection onto a trust region around the original model. We provide (i) convergence guarantees in the convex case and stationarity guarantees in the nonconvex case, (ii) $(\varepsilon,δ)$ network-unlearning certificates on client views via subsampled Gaussian Rényi DP (RDP) with segment-level subsampling, and (iii) deletion-capacity bounds that scale with the forget-to-local data ratio and quantify the effect of decentralization (network mixing and randomized subsampling) on the privacy-utility trade-off. Empirically, on image benchmarks (MNIST, CIFAR-10), RR-DU matches a given $(\varepsilon,δ)$ while achieving higher test accuracy than decentralized DP baselines and reducing forget accuracy to random guessing ($\approx 10\%$).

</details>


### [141] [Biothreat Benchmark Generation Framework for Evaluating Frontier AI Models II: Benchmark Generation Process](https://arxiv.org/abs/2512.08451)
*Gary Ackerman,Zachary Kallenborn,Anna Wetzel,Hayley Peterson,Jenna LaTourette,Olivia Shoemaker,Brandon Behlendorf,Sheriff Almakki,Doug Clifford,Noah Sheinbaum*

Main category: cs.LG

TL;DR: 该论文提出了一个细菌生物威胁基准数据集(B3)，作为生物威胁基准生成框架的第二部分，包含1010个经过筛选的基准测试，用于评估AI模型在生物安全风险方面的能力。


<details>
  <summary>Details</summary>
Motivation: 前沿AI模型（特别是大语言模型）可能被用于生物恐怖主义或获取生物武器，这引发了政策、学术和公众的广泛关注。模型开发者和政策制定者需要量化并减轻这种风险，因此需要开发能够评估特定模型生物安全风险的基准测试。

Method: 采用三种互补方法生成基准数据集：1）基于网络的提示生成，2）红队测试，3）挖掘现有基准语料库。通过去重、提升诊断性评估和质量控制，从7000多个候选基准中筛选出1010个最终基准。

Result: 生成了包含1010个基准的B3数据集，这些基准具有：a) 提升诊断性，b) 与生物安全威胁直接相关，c) 与更大的生物安全架构对齐，允许在不同分析层次进行细致分析。

Conclusion: 该研究成功开发了一个诊断性强、与生物安全威胁相关且架构对齐的基准数据集，为评估AI模型的生物安全风险提供了重要工具，是生物威胁基准生成框架的关键组成部分。

Abstract: The potential for rapidly-evolving frontier artificial intelligence (AI) models, especially large language models (LLMs), to facilitate bioterrorism or access to biological weapons has generated significant policy, academic, and public concern. Both model developers and policymakers seek to quantify and mitigate any risk, with an important element of such efforts being the development of model benchmarks that can assess the biosecurity risk posed by a particular model. This paper, the second in a series of three, describes the second component of a novel Biothreat Benchmark Generation (BBG) framework: the generation of the Bacterial Biothreat Benchmark (B3) dataset. The development process involved three complementary approaches: 1) web-based prompt generation, 2) red teaming, and 3) mining existing benchmark corpora, to generate over 7,000 potential benchmarks linked to the Task-Query Architecture that was developed during the first component of the project. A process of de-duplication, followed by an assessment of uplift diagnosticity, and general quality control measures, reduced the candidates to a set of 1,010 final benchmarks. This procedure ensured that these benchmarks are a) diagnostic in terms of providing uplift; b) directly relevant to biosecurity threats; and c) are aligned with a larger biosecurity architecture permitting nuanced analysis at different levels of analysis.

</details>


### [142] [Biothreat Benchmark Generation Framework for Evaluating Frontier AI Models III: Implementing the Bacterial Biothreat Benchmark (B3) Dataset](https://arxiv.org/abs/2512.08459)
*Gary Ackerman,Theodore Wilson,Zachary Kallenborn,Olivia Shoemaker,Anna Wetzel,Hayley Peterson,Abigail Danfora,Jenna LaTourette,Brandon Behlendorf,Douglas Clifford*

Main category: cs.LG

TL;DR: B3数据集为评估大语言模型的生物安全风险提供了一个可行的基准测试方法，通过实际测试和人工评估验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 前沿AI模型（特别是大语言模型）可能被用于生物恐怖主义或获取生物武器，这引起了政策、学术和公众的广泛担忧。需要开发能够量化这些风险的评估基准。

Method: 实施B3（细菌生物威胁基准）数据集的试点测试，包括：1）在样本前沿AI模型上运行基准测试；2）人工评估模型响应；3）从多个维度对结果进行应用风险分析。

Result: 试点测试表明，B3数据集提供了一种可行且细致的方法，能够快速评估LLM的生物安全风险，识别风险的主要来源，并为优先缓解领域提供指导。

Conclusion: B3基准测试框架是评估AI模型生物安全风险的有效工具，能够帮助模型开发者和政策制定者量化风险并确定缓解措施的优先顺序。

Abstract: The potential for rapidly-evolving frontier artificial intelligence (AI) models, especially large language models (LLMs), to facilitate bioterrorism or access to biological weapons has generated significant policy, academic, and public concern. Both model developers and policymakers seek to quantify and mitigate any risk, with an important element of such efforts being the development of model benchmarks that can assess the biosecurity risk posed by a particular model. This paper discusses the pilot implementation of the Bacterial Biothreat Benchmark (B3) dataset. It is the third in a series of three papers describing an overall Biothreat Benchmark Generation (BBG) framework, with previous papers detailing the development of the B3 dataset. The pilot involved running the benchmarks through a sample frontier AI model, followed by human evaluation of model responses, and an applied risk analysis of the results along several dimensions. Overall, the pilot demonstrated that the B3 dataset offers a viable, nuanced method for rapidly assessing the biosecurity risk posed by a LLM, identifying the key sources of that risk and providing guidance for priority areas of mitigation priority.

</details>


### [143] [Transformers for Multimodal Brain State Decoding: Integrating Functional Magnetic Resonance Imaging Data and Medical Metadata](https://arxiv.org/abs/2512.08462)
*Danial Jafarzadeh Jazi,Maryam Hajiesmaeili*

Main category: cs.LG

TL;DR: 提出一个结合fMRI数据和DICOM元数据的Transformer多模态框架，用于解码大脑状态，提升准确性和可解释性


<details>
  <summary>Details</summary>
Motivation: 传统机器学习和深度学习方法在处理fMRI数据时未能充分利用DICOM元数据提供的丰富上下文信息，限制了大脑状态解码的准确性和应用潜力

Method: 采用基于Transformer的架构，整合fMRI数据和DICOM元数据作为多模态输入，利用注意力机制捕捉复杂的时空模式和上下文关系

Result: 提出的方法提高了模型的准确性、可解释性和鲁棒性，在临床诊断、认知神经科学和个性化医学等领域具有应用潜力

Conclusion: 该多模态Transformer框架有效利用了DICOM元数据的上下文信息，虽然面临元数据变异性和计算需求等挑战，但为大脑状态解码提供了有前景的方向，未来可优化可扩展性和泛化能力

Abstract: Decoding brain states from functional magnetic resonance imaging (fMRI) data is vital for advancing neuroscience and clinical applications. While traditional machine learning and deep learning approaches have made strides in leveraging the high-dimensional and complex nature of fMRI data, they often fail to utilize the contextual richness provided by Digital Imaging and Communications in Medicine (DICOM) metadata. This paper presents a novel framework integrating transformer-based architectures with multimodal inputs, including fMRI data and DICOM metadata. By employing attention mechanisms, the proposed method captures intricate spatial-temporal patterns and contextual relationships, enhancing model accuracy, interpretability, and robustness. The potential of this framework spans applications in clinical diagnostics, cognitive neuroscience, and personalized medicine. Limitations, such as metadata variability and computational demands, are addressed, and future directions for optimizing scalability and generalizability are discussed.

</details>


### [144] [Solving Over-Smoothing in GNNs via Nonlocal Message Passing: Algebraic Smoothing and Depth Scalability](https://arxiv.org/abs/2512.08475)
*Weiqi Guan,Junlin He*

Main category: cs.LG

TL;DR: 提出一种基于Post-LN的新方法，通过诱导代数平滑来解决深度图神经网络中的过平滑和深度诅咒困境，支持高达256层的深度网络且无需额外参数。


<details>
  <summary>Details</summary>
Motivation: Layer Normalization (LN) 的放置位置与过平滑现象之间的关系尚未充分探索。Pre-LN架构能避免过平滑但受深度诅咒影响，而Post-LN架构能绕过深度诅咒但会出现过平滑，需要解决这一关键困境。

Method: 基于Post-LN架构提出新方法，通过诱导代数平滑来防止过平滑，同时避免深度诅咒。该方法不需要额外参数，能够支持更深层的网络结构。

Result: 在五个基准测试上的实验结果表明，该方法能够支持高达256层的深度网络，并提升性能表现，证明了其在深度GNN中的有效性。

Conclusion: 成功解决了LN放置位置导致的过平滑与深度诅咒困境，提出的参数高效方法能够诱导代数平滑，为构建更深层、更有效的图神经网络提供了理论支持和实践方案。

Abstract: The relationship between Layer Normalization (LN) placement and the over-smoothing phenomenon remains underexplored. We identify a critical dilemma: Pre-LN architectures avoid over-smoothing but suffer from the curse of depth, while Post-LN architectures bypass the curse of depth but experience over-smoothing.
  To resolve this, we propose a new method based on Post-LN that induces algebraic smoothing, preventing over-smoothing without the curse of depth. Empirical results across five benchmarks demonstrate that our approach supports deeper networks (up to 256 layers) and improves performance, requiring no additional parameters.
  Key contributions:
  Theoretical Characterization: Analysis of LN dynamics and their impact on over-smoothing and the curse of depth.
  A Principled Solution: A parameter-efficient method that induces algebraic smoothing and avoids over-smoothing and the curse of depth.
  Empirical Validation: Extensive experiments showing the effectiveness of the method in deeper GNNs.

</details>


### [145] [Optimal Perturbation Budget Allocation for Data Poisoning in Offline Reinforcement Learning](https://arxiv.org/abs/2512.08485)
*Junnan Qiu,Jie Li*

Main category: cs.LG

TL;DR: 提出一种针对离线强化学习的全局预算分配攻击策略，通过TD误差敏感度分配扰动预算，相比均匀扰动更高效且隐蔽


<details>
  <summary>Details</summary>
Motivation: 现有离线RL数据投毒攻击采用均匀扰动策略，对所有样本无差别处理，效率低下且缺乏隐蔽性，需要更智能的攻击方法

Method: 基于TD误差理论洞察，将攻击建模为全局资源分配问题，推导出在L2约束下扰动幅度与TD误差敏感度成正比的闭式解

Result: 在D4RL基准测试中显著优于基线策略，仅用最小扰动就能实现高达80%的性能下降，并能逃避最先进的统计和谱防御检测

Conclusion: 提出的全局预算分配攻击策略比均匀扰动更高效隐蔽，揭示了离线RL系统对智能投毒攻击的脆弱性，需要更强的防御机制

Abstract: Offline Reinforcement Learning (RL) enables policy optimization from static datasets but is inherently vulnerable to data poisoning attacks. Existing attack strategies typically rely on locally uniform perturbations, which treat all samples indiscriminately. This approach is inefficient, as it wastes the perturbation budget on low-impact samples, and lacks stealthiness due to significant statistical deviations. In this paper, we propose a novel Global Budget Allocation attack strategy. Leveraging the theoretical insight that a sample's influence on value function convergence is proportional to its Temporal Difference (TD) error, we formulate the attack as a global resource allocation problem. We derive a closed-form solution where perturbation magnitudes are assigned proportional to the TD-error sensitivity under a global L2 constraint. Empirical results on D4RL benchmarks demonstrate that our method significantly outperforms baseline strategies, achieving up to 80% performance degradation with minimal perturbations that evade detection by state-of-the-art statistical and spectral defenses.

</details>


### [146] [Developing Distance-Aware Uncertainty Quantification Methods in Physics-Guided Neural Networks for Reliable Bearing Health Prediction](https://arxiv.org/abs/2512.08499)
*Waleed Razzaq,Yun-Bo Zhao*

Main category: cs.LG

TL;DR: 提出两种基于确定性物理引导神经网络的距离感知不确定性方法（PG-SNGP和PG-SNER），用于旋转机械轴承退化预测，在OOD条件下表现更好且具有距离感知能力。


<details>
  <summary>Details</summary>
Motivation: 现有不确定性方法存在置信度校准不足、计算成本高、缺乏距离感知能力以及在分布外数据下泛化能力差的问题，而旋转机械轴承等安全关键系统需要准确且具有不确定性感知的退化估计。

Method: 1) PG-SNGP：基于谱归一化高斯过程，在隐藏层应用谱归一化以保持输入到潜在空间的距离，并用高斯过程层替换最终密集层；2) PG-SNER：基于深度证据回归，输出Normal Inverse Gamma参数以概率形式建模不确定性；3) 设计了基于Pearson相关系数的新距离感知度量；4) 在损失函数中采用动态加权方案平衡数据保真度和物理一致性。

Result: 在PRONOSTIA轴承退化数据集上测试，PG-SNGP和PG-SNER相比蒙特卡洛和深度集成PGNNs提高了预测精度，在OOD条件下可靠泛化，并对抗性攻击和噪声具有鲁棒性。

Conclusion: 提出的PG-SNGP和PG-SNER方法能够提供准确、距离感知的不确定性估计，在安全关键系统的预测性维护中具有实际应用价值，特别是在分布外数据和对抗性环境下表现优异。

Abstract: Accurate and uncertainty-aware degradation estimation is essential for predictive maintenance in safety-critical systems like rotating machinery with rolling-element bearings. Many existing uncertainty methods lack confidence calibration, are costly to run, are not distance-aware, and fail to generalize under out-of-distribution data. We introduce two distance-aware uncertainty methods for deterministic physics-guided neural networks: PG-SNGP, based on Spectral Normalization Gaussian Process, and PG-SNER, based on Deep Evidential Regression. We apply spectral normalization to the hidden layers so the network preserves distances from input to latent space. PG-SNGP replaces the final dense layer with a Gaussian Process layer for distance-sensitive uncertainty, while PG-SNER outputs Normal Inverse Gamma parameters to model uncertainty in a coherent probabilistic form. We assess performance using standard accuracy metrics and a new distance-aware metric based on the Pearson Correlation Coefficient, which measures how well predicted uncertainty tracks the distance between test and training samples. We also design a dynamic weighting scheme in the loss to balance data fidelity and physical consistency. We test our methods on rolling-element bearing degradation using the PRONOSTIA dataset and compare them with Monte Carlo and Deep Ensemble PGNNs. Results show that PG-SNGP and PG-SNER improve prediction accuracy, generalize reliably under OOD conditions, and remain robust to adversarial attacks and noise.

</details>


### [147] [A Hybrid Model for Stock Market Forecasting: Integrating News Sentiment and Time Series Data with Graph Neural Networks](https://arxiv.org/abs/2512.08567)
*Nader Sadek,Mirette Moawad,Christina Naguib,Mariam Elzahaby*

Main category: cs.LG

TL;DR: 本文提出了一种结合公司新闻和历史股价数据的多模态方法，使用图神经网络（GNN）预测股票市场，相比传统LSTM基线模型表现更优。


<details>
  <summary>Details</summary>
Motivation: 股票市场预测是金融领域的长期挑战，传统模型主要依赖历史价格数据，但金融新闻能提供有用的外部信号。本文旨在探索结合新闻和历史数据的多模态方法以提高预测性能。

Method: 采用多模态方法：1）使用LSTM编码每家公司的历史股价数据；2）使用语言模型嵌入新闻标题；3）将这些嵌入作为异构图中的节点；4）使用GraphSAGE捕捉文章、公司和行业之间的交互关系。比较了GNN与基线LSTM模型。

Result: 在美国股票和Bloomberg数据集上的实验表明：1）GNN优于LSTM基线，在方向变化预测上达到53%准确率，在显著性标签预测上获得4%精确度提升；2）有更多相关新闻的公司预测准确率更高；3）新闻标题比全文包含更强的预测信号。

Conclusion: 多模态方法结合新闻和历史数据能有效提升股票市场预测性能，图神经网络能更好地捕捉公司、新闻和行业之间的复杂关系，且简洁的新闻摘要在短期市场反应中具有重要作用。

Abstract: Stock market prediction is a long-standing challenge in finance, as accurate forecasts support informed investment decisions. Traditional models rely mainly on historical prices, but recent work shows that financial news can provide useful external signals. This paper investigates a multimodal approach that integrates companies' news articles with their historical stock data to improve prediction performance. We compare a Graph Neural Network (GNN) model with a baseline LSTM model. Historical data for each company is encoded using an LSTM, while news titles are embedded with a language model. These embeddings form nodes in a heterogeneous graph, and GraphSAGE is used to capture interactions between articles, companies, and industries. We evaluate two targets: a binary direction-of-change label and a significance-based label. Experiments on the US equities and Bloomberg datasets show that the GNN outperforms the LSTM baseline, achieving 53% accuracy on the first target and a 4% precision gain on the second. Results also indicate that companies with more associated news yield higher prediction accuracy. Moreover, headlines contain stronger predictive signals than full articles, suggesting that concise news summaries play an important role in short-term market reactions.

</details>


### [148] [Long-Sequence LSTM Modeling for NBA Game Outcome Prediction Using a Novel Multi-Season Dataset](https://arxiv.org/abs/2512.08591)
*Charles Rios,Longzhen Han,Almas Baimagambetov,Nikolaos Polatidis*

Main category: cs.LG

TL;DR: 该研究构建了一个覆盖2004-2024赛季的NBA纵向数据集，并提出了一个使用LSTM模型来预测篮球比赛结果的深度学习框架，通过长达8个赛季的序列长度来捕捉长期性能趋势，取得了72.35%的准确率等最佳性能。


<details>
  <summary>Details</summary>
Motivation: 预测NBA比赛结果对于教练策略、球迷参与和体育博彩越来越重要，但现有模型存在概念漂移、时间上下文有限和跨赛季不稳定等问题，需要更好的长期趋势建模方法。

Method: 构建了覆盖2004-05至2024-25赛季的纵向NBA数据集，提出了一个LSTM架构，使用长达9,840场比赛（相当于8个完整NBA赛季）的扩展序列长度来捕捉球队动态演变和赛季间依赖关系。

Result: LSTM模型在所有指标上表现最佳：72.35%准确率、73.15%精确率和76.13% AUC-ROC，显著优于逻辑回归、随机森林、MLP和CNN等传统机器学习和深度学习基线模型。

Conclusion: 长序列时间建模在篮球结果预测中至关重要，新构建的多赛季数据集对于开发稳健、可泛化的NBA预测系统具有重要价值，LSTM能够有效捕捉长期性能趋势和赛季间依赖关系。

Abstract: Predicting the outcomes of professional basketball games, particularly in the National Basketball Association (NBA), has become increasingly important for coaching strategy, fan engagement, and sports betting. However, many existing prediction models struggle with concept drift, limited temporal context, and instability across seasons. To advance forecasting in this domain, we introduce a newly constructed longitudinal NBA dataset covering the 2004-05 to 2024-25 seasons and present a deep learning framework designed to model long-term performance trends. Our primary contribution is a Long Short-Term Memory (LSTM) architecture that leverages an extended sequence length of 9,840 games equivalent to eight full NBA seasons to capture evolving team dynamics and season-over-season dependencies. We compare this model against several traditional Machine Learning (ML) and Deep Learning (DL) baselines, including Logistic Regression, Random Forest, Multi-Layer Perceptron (MLP), and Convolutional Neural Network (CNN). The LSTM achieves the best performance across all metrics, with 72.35 accuracy, 73.15 precision and 76.13 AUC-ROC. These results demonstrate the importance of long-sequence temporal modeling in basketball outcome prediction and highlight the value of our new multi-season dataset for developing robust, generalizable NBA forecasting systems.

</details>


### [149] [DS FedProxGrad: Asymptotic Stationarity Without Noise Floor in Fair Federated Learning](https://arxiv.org/abs/2512.08671)
*Huzaifa Arif*

Main category: cs.LG

TL;DR: 改进的FedProxGrad分析框架DS FedProxGrad，在Robbins-Monro步长调度下实现渐近平稳收敛，消除了方差诱导的噪声底限依赖。


<details>
  <summary>Details</summary>
Motivation: 原始FedProxGrad在解决非凸复合优化问题时，收敛分析仅能到达噪声主导的平稳邻域，且显式依赖于方差诱导的噪声底限。需要改进分析以实现真正的渐近平稳收敛。

Method: 提出DS FedProxGrad（衰减步长FedProxGrad）扩展分析框架，采用Robbins-Monro步长调度，允许局部近似解的不精确性，并包含显式公平正则化。

Result: 在局部不精确性满足温和衰减条件下，证明了liminf期望梯度范数平方为零，算法实现渐近平稳收敛，收敛速率不依赖于方差诱导的噪声底限。

Conclusion: DS FedProxGrad框架提供了改进的收敛分析，消除了原始FedProxGrad的噪声底限依赖，为群体公平联邦学习中的非凸复合优化问题提供了更强的理论保证。

Abstract: Recent work \cite{arifgroup} introduced Federated Proximal Gradient \textbf{(\texttt{FedProxGrad})} for solving non-convex composite optimization problems in group fair federated learning. However, the original analysis established convergence only to a \textit{noise-dominated neighborhood of stationarity}, with explicit dependence on a variance-induced noise floor. In this work, we provide an improved asymptotic convergence analysis for a generalized \texttt{FedProxGrad}-type analytical framework with inexact local proximal solutions and explicit fairness regularization. We call this extended analytical framework \textbf{DS \texttt{FedProxGrad}} (Decay Step Size \texttt{FedProxGrad}). Under a Robbins-Monro step-size schedule \cite{robbins1951stochastic} and a mild decay condition on local inexactness, we prove that $\liminf_{r\to\infty} \mathbb{E}[\|\nabla F(\mathbf{x}^r)\|^2] = 0$, i.e., the algorithm is asymptotically stationary and the convergence rate does not depend on a variance-induced noise floor.

</details>


### [150] [An Additive Manufacturing Part Qualification Framework: Transferring Knowledge of Stress-strain Behaviors from Additively Manufactured Polymers to Metals](https://arxiv.org/abs/2512.08699)
*Chenglong Duan,Dazhong Wu*

Main category: cs.LG

TL;DR: 提出基于动态时间规整和迁移学习的框架，用于增材制造零件认证，通过将低成本聚合物的应力-应变行为知识迁移到金属材料


<details>
  <summary>Details</summary>
Motivation: 增材制造零件认证对关键应用至关重要，需要准确预测复杂应力-应变行为。传统方法成本高且耗时，需要开发高效预测框架

Method: 开发DTW-TL框架：使用动态时间规整选择与目标金属最相关的聚合物数据集作为源域，基于LSTM模型进行知识迁移，使用4种聚合物和3种金属材料验证

Result: DTW-TL框架能识别聚合物与金属的最佳匹配，选择单一聚合物作为源域。在三种金属目标域上获得12.41%的最低平均绝对百分比误差和0.96的最高决定系数，优于无迁移学习的LSTM模型和基于四种聚合物的迁移学习模型

Conclusion: DTW-TL框架为增材制造零件认证提供有效解决方案，通过将低成本聚合物知识迁移到金属材料，显著提高应力-应变行为预测精度，支持零件性能验证

Abstract: Part qualification is crucial in additive manufacturing (AM) because it ensures that additively manufactured parts can be consistently produced and reliably used in critical applications. Part qualification aims at verifying that an additively manufactured part meets performance requirements; therefore, predicting the complex stress-strain behaviors of additively manufactured parts is critical. We develop a dynamic time warping (DTW)-transfer learning (TL) framework for additive manufacturing part qualification by transferring knowledge of the stress-strain behaviors of additively manufactured low-cost polymers to metals. Specifically, the framework employs DTW to select a polymer dataset as the source domain that is the most relevant to the target metal dataset. Using a long short-term memory (LSTM) model, four source polymers (i.e., Nylon, PLA, CF-ABS, and Resin) and three target metals (i.e., AlSi10Mg, Ti6Al4V, and carbon steel) that are fabricated by different AM techniques are utilized to demonstrate the effectiveness of the DTW-TL framework. Experimental results show that the DTW-TL framework identifies the closest match between polymers and metals to select one single polymer dataset as the source domain. The DTW-TL model achieves the lowest mean absolute percentage error of 12.41% and highest coefficient of determination of 0.96 when three metals are used as the target domain, respectively, outperforming the vanilla LSTM model without TL as well as the TL model pre-trained on four polymer datasets as the source domain.

</details>


### [151] [Exposing Hidden Biases in Text-to-Image Models via Automated Prompt Search](https://arxiv.org/abs/2512.08724)
*Manos Plitsis,Giorgos Bouritsas,Vassilis Katsouros,Yannis Panagakis*

Main category: cs.LG

TL;DR: BGPS框架自动生成能最大化文本到图像模型中偏见的提示词，通过LLM生成属性中性提示词，并用分类器引导LLM解码过程来放大图像属性偏见。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像模型存在社会偏见，现有去偏见方法依赖人工或LLM构建的提示词数据集，成本高且可能遗漏未预料到的偏见触发提示词。

Method: 提出Bias-Guided Prompt Search (BGPS)框架：1) LLM生成属性中性提示词；2) 基于TTI内部表示的分类器引导LLM解码过程，向能放大目标图像属性的提示词空间区域搜索。

Result: 在Stable Diffusion 1.5和先进去偏见模型上发现大量细微且先前未记录的偏见，严重损害公平性指标。发现的提示词可解释且可由普通用户输入，困惑度指标优于硬提示优化方法。

Conclusion: BGPS揭示了TTI模型的脆弱性，扩展了偏见搜索空间，可作为新的偏见缓解评估工具，帮助发现更全面的偏见模式。

Abstract: Text-to-image (TTI) diffusion models have achieved remarkable visual quality, yet they have been repeatedly shown to exhibit social biases across sensitive attributes such as gender, race and age. To mitigate these biases, existing approaches frequently depend on curated prompt datasets - either manually constructed or generated with large language models (LLMs) - as part of their training and/or evaluation procedures. Beside the curation cost, this also risks overlooking unanticipated, less obvious prompts that trigger biased generation, even in models that have undergone debiasing. In this work, we introduce Bias-Guided Prompt Search (BGPS), a framework that automatically generates prompts that aim to maximize the presence of biases in the resulting images. BGPS comprises two components: (1) an LLM instructed to produce attribute-neutral prompts and (2) attribute classifiers acting on the TTI's internal representations that steer the decoding process of the LLM toward regions of the prompt space that amplify the image attributes of interest. We conduct extensive experiments on Stable Diffusion 1.5 and a state-of-the-art debiased model and discover an array of subtle and previously undocumented biases that severely deteriorate fairness metrics. Crucially, the discovered prompts are interpretable, i.e they may be entered by a typical user, quantitatively improving the perplexity metric compared to a prominent hard prompt optimization counterpart. Our findings uncover TTI vulnerabilities, while BGPS expands the bias search space and can act as a new evaluation tool for bias mitigation.

</details>


### [152] [Neural Ordinary Differential Equations for Simulating Metabolic Pathway Dynamics from Time-Series Multiomics Data](https://arxiv.org/abs/2512.08732)
*Udesh Habaraduwa,Andrei Lixandru*

Main category: cs.LG

TL;DR: NODE模型在代谢工程中显著优于传统方法，预测精度提升90%以上，推理速度加速1000倍


<details>
  <summary>Details</summary>
Motivation: 虽然高通量多组学数据日益丰富，但将其转化为可操作的预测模型仍是瓶颈。需要能够从观测数据直接推断潜在相互作用的高容量数据驱动模拟系统，用于个性化医疗和合成生物学中的下游干预效果预测。

Method: 引入神经常微分方程（NODE）作为动态框架，学习蛋白质组和代谢组之间的复杂相互作用。将该框架应用于工程化大肠杆菌菌株的时间序列数据，建模代谢途径的连续动力学。

Result: NODE架构在捕捉系统动力学方面表现优于传统机器学习流程。在柠檬烯途径数据集上RMSE改善高达94.38%，在异戊烯醇途径数据集上改善高达97.65%。NODE模型的推理时间加速了1000倍。

Conclusion: NODE模型是可扩展、高保真的工具，适用于下一代代谢工程和生物学发现，能够准确预测生物系统行为并加速推理过程。

Abstract: The advancement of human healthspan and bioengineering relies heavily on predicting the behavior of complex biological systems. While high-throughput multiomics data is becoming increasingly abundant, converting this data into actionable predictive models remains a bottleneck. High-capacity, datadriven simulation systems are critical in this landscape; unlike classical mechanistic models restricted by prior knowledge, these architectures can infer latent interactions directly from observational data, allowing for the simulation of temporal trajectories and the anticipation of downstream intervention effects in personalized medicine and synthetic biology. To address this challenge, we introduce Neural Ordinary Differential Equations (NODEs) as a dynamic framework for learning the complex interplay between the proteome and metabolome. We applied this framework to time-series data derived from engineered Escherichia coli strains, modeling the continuous dynamics of metabolic pathways. The proposed NODE architecture demonstrates superior performance in capturing system dynamics compared to traditional machine learning pipelines. Our results show a greater than 90% improvement in root mean squared error over baselines across both Limonene (up to 94.38% improvement) and Isopentenol (up to 97.65% improvement) pathway datasets. Furthermore, the NODE models demonstrated a 1000x acceleration in inference time, establishing them as a scalable, high-fidelity tool for the next generation of metabolic engineering and biological discovery.

</details>


### [153] [Learning and Editing Universal Graph Prompt Tuning via Reinforcement Learning](https://arxiv.org/abs/2512.08763)
*Jinfeng Xu,Zheyu Chen,Shuo Yang,Jinze Li,Hewei Wang,Yijie Li,Edith C. H. Ngai*

Main category: cs.LG

TL;DR: LEAP提出了一种新的通用图提示调优方法，通过在所有节点添加提示来保持理论基础，同时使用强化学习选择节点和编辑提示以获得更理想的提示效果。


<details>
  <summary>Details</summary>
Motivation: 现有的选择性节点图提示调优方法虽然追求更理想的提示，但破坏了通用图提示调优的理论基础。本文旨在在保持理论基础的同时，实现更有效的图提示调优。

Method: 提出LEAP模型：首先构建基本通用图提示以保持理论基础，然后使用actor-critic强化学习选择节点并编辑提示，实现更理想的提示效果。

Result: 在多种预训练策略下的图级和节点级任务中，无论是全样本还是少样本场景，LEAP都持续优于微调和其他基于提示的方法。

Conclusion: LEAP通过在所有节点添加提示来保持通用图提示调优的理论基础，同时利用强化学习优化提示选择，实现了理论严谨性和实际性能的双重提升。

Abstract: Early graph prompt tuning approaches relied on task-specific designs for Graph Neural Networks (GNNs), limiting their adaptability across diverse pre-training strategies. In contrast, another promising line of research has investigated universal graph prompt tuning, which operates directly in the input graph's feature space and builds a theoretical foundation that universal graph prompt tuning can theoretically achieve an equivalent effect of any prompting function, eliminating dependence on specific pre-training strategies. Recent works propose selective node-based graph prompt tuning to pursue more ideal prompts. However, we argue that selective node-based graph prompt tuning inevitably compromises the theoretical foundation of universal graph prompt tuning. In this paper, we strengthen the theoretical foundation of universal graph prompt tuning by introducing stricter constraints, demonstrating that adding prompts to all nodes is a necessary condition for achieving the universality of graph prompts. To this end, we propose a novel model and paradigm, Learning and Editing Universal GrAph Prompt Tuning (LEAP), which preserves the theoretical foundation of universal graph prompt tuning while pursuing more ideal prompts. Specifically, we first build the basic universal graph prompts to preserve the theoretical foundation and then employ actor-critic reinforcement learning to select nodes and edit prompts. Extensive experiments on graph- and node-level tasks across various pre-training strategies in both full-shot and few-shot scenarios show that LEAP consistently outperforms fine-tuning and other prompt-based approaches.

</details>


### [154] [De novo generation of functional terpene synthases using TpsGPT](https://arxiv.org/abs/2512.08772)
*Hamsini Ramanathan,Roman Bushuiev,Matouš Soldát,Jirí Kohout,Téo Hebra,Joshua David Smith,Josef Sivic,Tomáš Pluskal*

Main category: cs.LG

TL;DR: TpsGPT是基于ProtGPT2在79k TPS序列上微调的生成模型，用于从头设计萜烯合酶，通过多指标验证筛选出7个候选酶，实验证实其中至少2个具有TPS活性。


<details>
  <summary>Details</summary>
Motivation: 萜烯合酶是生成萜烯骨架的关键酶家族，但传统的定向进化方法成本高、速度慢，需要开发更高效的从头设计方法。

Method: 通过微调蛋白质语言模型ProtGPT2在79k个TPS序列上构建TpsGPT模型，生成新酶序列，使用多种验证指标（EnzymeExplorer分类、ESMFold结构置信度、序列多样性、CLEAN分类、InterPro域检测、Foldseek结构比对）进行筛选。

Result: 从28k个生成序列中筛选出7个满足所有验证标准的候选TPS酶，实验验证确认其中至少2个序列具有TPS酶活性。

Conclusion: 在精心策划的酶类特定数据集上微调蛋白质语言模型，结合严格的筛选策略，能够从头生成功能性的、进化上远缘的酶。

Abstract: Terpene synthases (TPS) are a key family of enzymes responsible for generating the diverse terpene scaffolds that underpin many natural products, including front-line anticancer drugs such as Taxol. However, de novo TPS design through directed evolution is costly and slow. We introduce TpsGPT, a generative model for scalable TPS protein design, built by fine-tuning the protein language model ProtGPT2 on 79k TPS sequences mined from UniProt. TpsGPT generated de novo enzyme candidates in silico and we evaluated them using multiple validation metrics, including EnzymeExplorer classification, ESMFold structural confidence (pLDDT), sequence diversity, CLEAN classification, InterPro domain detection, and Foldseek structure alignment. From an initial pool of 28k generated sequences, we identified seven putative TPS enzymes that satisfied all validation criteria. Experimental validation confirmed TPS enzymatic activity in at least two of these sequences. Our results show that fine-tuning of a protein language model on a carefully curated, enzyme-class-specific dataset, combined with rigorous filtering, can enable the de novo generation of functional, evolutionarily distant enzymes.

</details>


### [155] [Can TabPFN Compete with GNNs for Node Classification via Graph Tabularization?](https://arxiv.org/abs/2512.08798)
*Jeongwhan Choi,Woosung Kang,Minseo Kim,Jongwoo Kim,Noseong Park*

Main category: cs.LG

TL;DR: TabPFN-GN将图节点分类重新构建为表格学习问题，通过特征工程将图数据转换为表格特征，在异配图上表现优于GNNs


<details>
  <summary>Details</summary>
Motivation: 基于TabPFN在表格数据和时序数据上的成功，研究是否可以将图节点分类有效地重新构建为表格学习问题，探索表格学习与图学习之间的桥梁

Method: TabPFN-GN方法：提取节点属性、结构特性、位置编码和可选的平滑邻域特征，将图数据转换为表格特征，使TabPFN能够直接进行节点分类，无需图特定训练或语言模型依赖

Result: 在12个基准数据集上的实验表明：TabPFN-GN在同配图上与GNNs表现相当，在异配图上始终优于GNNs

Conclusion: 原则性特征工程可以弥合表格和图领域之间的差距，为任务特定的GNN训练和LLM依赖的图基础模型提供了实用的替代方案

Abstract: Foundation models pretrained on large data have demonstrated remarkable zero-shot generalization capabilities across domains. Building on the success of TabPFN for tabular data and its recent extension to time series, we investigate whether graph node classification can be effectively reformulated as a tabular learning problem. We introduce TabPFN-GN, which transforms graph data into tabular features by extracting node attributes, structural properties, positional encodings, and optionally smoothed neighborhood features. This enables TabPFN to perform direct node classification without any graph-specific training or language model dependencies. Our experiments on 12 benchmark datasets reveal that TabPFN-GN achieves competitive performance with GNNs on homophilous graphs and consistently outperforms them on heterophilous graphs. These results demonstrate that principled feature engineering can bridge the gap between tabular and graph domains, providing a practical alternative to task-specific GNN training and LLM-dependent graph foundation models.

</details>


### [156] [Identifying counterfactual probabilities using bivariate distributions and uplift modeling](https://arxiv.org/abs/2512.08805)
*Théo Verhelst,Gianluca Bontempi*

Main category: cs.LG

TL;DR: 提出一种利用提升模型进行反事实估计的方法，通过拟合双变量beta分布到预测的提升分数，得到反事实结果的后验分布。


<details>
  <summary>Details</summary>
Motivation: 提升建模只能估计干预的因果效应（处理组和对照组的潜在结果差异），而反事实识别旨在恢复这些潜在结果的联合分布（如"如果给客户提供营销优惠，他们是否仍会流失？"）。反事实联合分布比提升信息更丰富但更难估计，但两种方法可以协同：可以利用提升模型进行反事实估计。

Method: 提出一种反事实估计器，将双变量beta分布拟合到预测的提升分数上，从而得到反事实结果的后验分布。该方法除了提升建模所需的因果假设外，不需要额外的因果假设。

Result: 模拟实验显示了该方法的有效性，可应用于电信客户流失等问题，揭示了标准机器学习或单独提升模型无法获得的洞察。

Conclusion: 通过将提升建模与反事实估计相结合，该方法能够提供更丰富的因果推断信息，在保持提升模型优势的同时，扩展了其应用范围。

Abstract: Uplift modeling estimates the causal effect of an intervention as the difference between potential outcomes under treatment and control, whereas counterfactual identification aims to recover the joint distribution of these potential outcomes (e.g., "Would this customer still have churned had we given them a marketing offer?"). This joint counterfactual distribution provides richer information than the uplift but is harder to estimate. However, the two approaches are synergistic: uplift models can be leveraged for counterfactual estimation. We propose a counterfactual estimator that fits a bivariate beta distribution to predicted uplift scores, yielding posterior distributions over counterfactual outcomes. Our approach requires no causal assumptions beyond those of uplift modeling. Simulations show the efficacy of the approach, which can be applied, for example, to the problem of customer churn in telecom, where it reveals insights unavailable to standard ML or uplift models alone.

</details>


### [157] [Forecasting Fails: Unveiling Evasion Attacks in Weather Prediction Models](https://arxiv.org/abs/2512.08832)
*Huzaifa Arif,Pin-Yu Chen,Alex Gittens,James Diffenderfer,Bhavya Kailkhura*

Main category: cs.LG

TL;DR: 提出WAAPO框架，针对AI天气预测模型生成隐蔽的对抗性扰动，揭示模型脆弱性


<details>
  <summary>Details</summary>
Motivation: 随着AI模型在天气预报中的广泛应用，需要评估其对对抗性扰动的脆弱性，以确保预测系统的安全性

Method: 提出Weather Adaptive Adversarial Perturbation Optimization (WAAPO)框架，通过通道稀疏性、空间局部性和平滑性约束生成物理真实且难以检测的对抗性扰动

Result: 在ERA5数据集和FourCastNet模型上验证，WAAPO能够生成与预定目标紧密对齐的对抗轨迹，即使受约束条件下也能显著改变预测天气模式

Conclusion: AI天气预报模型存在严重脆弱性，微小扰动可导致预测显著偏差，需要建立鲁棒防护机制来防止对抗性攻击

Abstract: With the increasing reliance on AI models for weather forecasting, it is imperative to evaluate their vulnerability to adversarial perturbations. This work introduces Weather Adaptive Adversarial Perturbation Optimization (WAAPO), a novel framework for generating targeted adversarial perturbations that are both effective in manipulating forecasts and stealthy to avoid detection. WAAPO achieves this by incorporating constraints for channel sparsity, spatial localization, and smoothness, ensuring that perturbations remain physically realistic and imperceptible. Using the ERA5 dataset and FourCastNet (Pathak et al. 2022), we demonstrate WAAPO's ability to generate adversarial trajectories that align closely with predefined targets, even under constrained conditions. Our experiments highlight critical vulnerabilities in AI-driven forecasting models, where small perturbations to initial conditions can result in significant deviations in predicted weather patterns. These findings underscore the need for robust safeguards to protect against adversarial exploitation in operational forecasting systems.

</details>


### [158] [Reinforcement Learning From State and Temporal Differences](https://arxiv.org/abs/2512.08855)
*Lex Weaver,Jonathan Baxter*

Main category: cs.LG

TL;DR: STD(λ)是一种改进的TD(λ)算法，通过关注状态值的相对排序而非绝对误差来提升策略性能，在简单系统和Acrobot问题上表现优于传统TD(λ)。


<details>
  <summary>Details</summary>
Motivation: 传统TD(λ)使用函数逼近时最小化状态值的平方误差，但策略性能更依赖于状态值的相对排序而非绝对数值。作者发现TD(λ)即使从最优策略开始，也可能收敛到次优策略，因此需要改进。

Method: 提出STD(λ)算法，在二元决策问题中基于状态值的相对关系训练函数逼近器。该方法包含理论分析，包括在二状态系统中证明策略单调改进，并与Bertsekas的差分训练方法进行比较。

Result: 在二状态系统和Acrobot问题的变体上成功演示了STD(λ)的有效性。STD(λ)避免了TD(λ)收敛到次优策略的问题，能够保持或改进策略性能。

Conclusion: STD(λ)通过关注状态值的相对排序而非绝对误差，解决了TD(λ)在函数逼近中可能导致策略退化的缺陷，为强化学习中的值函数逼近提供了更稳健的方法。

Abstract: TD($λ$) with function approximation has proved empirically successful for some complex reinforcement learning problems. For linear approximation, TD($λ$) has been shown to minimise the squared error between the approximate value of each state and the true value. However, as far as policy is concerned, it is error in the relative ordering of states that is critical, rather than error in the state values. We illustrate this point, both in simple two-state and three-state systems in which TD($λ$)--starting from an optimal policy--converges to a sub-optimal policy, and also in backgammon. We then present a modified form of TD($λ$), called STD($λ$), in which function approximators are trained with respect to relative state values on binary decision problems. A theoretical analysis, including a proof of monotonic policy improvement for STD($λ$) in the context of the two-state system, is presented, along with a comparison with Bertsekas' differential training method [1]. This is followed by successful demonstrations of STD($λ$) on the two-state system and a variation on the well known acrobot problem.

</details>


### [159] [Refining Diffusion Models for Motion Synthesis with an Acceleration Loss to Generate Realistic IMU Data](https://arxiv.org/abs/2512.08859)
*Lars Ole Häusler,Lena Uhlenberg,Göran Köber,Diyora Salimova,Oliver Amft*

Main category: cs.LG

TL;DR: 提出文本到IMU运动合成框架，通过加速度二阶损失微调扩散模型，提升IMU数据真实性和HAR分类性能


<details>
  <summary>Details</summary>
Motivation: 现有文本到运动模型生成的IMU数据不够真实，需要专门针对IMU传感器特性进行优化，以提高合成数据的质量和下游任务性能

Method: 提出加速度二阶损失(L_acc)来微调预训练扩散模型，强制生成运动在离散二阶时间差分上的一致性，将扩散先验与IMU特定的加速度模式对齐

Result: L_acc损失相对原始模型降低12.7%，高动态活动改进更显著；合成IMU数据分布更接近真实数据；HAR分类性能提升8.7%

Conclusion: 加速度感知的扩散细化是有效的方法，能够对齐运动生成和IMU合成，展示了深度学习管道在将通用文本到运动先验专门化到传感器特定任务中的灵活性

Abstract: We propose a text-to-IMU (inertial measurement unit) motion-synthesis framework to obtain realistic IMU data by fine-tuning a pretrained diffusion model with an acceleration-based second-order loss (L_acc). L_acc enforces consistency in the discrete second-order temporal differences of the generated motion, thereby aligning the diffusion prior with IMU-specific acceleration patterns. We integrate L_acc into the training objective of an existing diffusion model, finetune the model to obtain an IMU-specific motion prior, and evaluate the model with an existing text-to-IMU framework that comprises surface modelling and virtual sensor simulation. We analysed acceleration signal fidelity and differences between synthetic motion representation and actual IMU recordings. As a downstream application, we evaluated Human Activity Recognition (HAR) and compared the classification performance using data of our method with the earlier diffusion model and two additional diffusion model baselines. When we augmented the earlier diffusion model objective with L_acc and continued training, L_acc decreased by 12.7% relative to the original model. The improvements were considerably larger in high-dynamic activities (i.e., running, jumping) compared to low-dynamic activities~(i.e., sitting, standing). In a low-dimensional embedding, the synthetic IMU data produced by our refined model shifts closer to the distribution of real IMU recordings. HAR classification trained exclusively on our refined synthetic IMU data improved performance by 8.7% compared to the earlier diffusion model and by 7.6% over the best-performing comparison diffusion model. We conclude that acceleration-aware diffusion refinement provides an effective approach to align motion generation and IMU synthesis and highlights how flexible deep learning pipelines are for specialising generic text-to-motion priors to sensor-specific tasks.

</details>


### [160] [Differentially Private Synthetic Data Generation Using Context-Aware GANs](https://arxiv.org/abs/2512.08869)
*Anantaa Kotal,Anupam Joshi*

Main category: cs.LG

TL;DR: 提出ContextGAN，一种结合领域特定规则和差分隐私的生成对抗网络，用于生成既保护隐私又符合领域约束的高质量合成数据。


<details>
  <summary>Details</summary>
Motivation: 大数据应用中隐私保护与数据效用之间存在矛盾，传统合成数据方法难以捕捉领域特定的复杂隐式规则（如医疗中的处方指南），导致生成的数据可能不现实或不安全。

Method: 提出ContextGAN，一种上下文感知的差分隐私生成对抗网络，通过约束矩阵编码领域显式和隐式知识，约束感知的判别器评估合成数据是否符合领域规则，同时使用差分隐私保护原始数据敏感信息。

Result: 在医疗、安全和金融领域验证表明，ContextGAN能生成高质量合成数据，既尊重领域规则又保护隐私，相比传统方法显著提升了数据的真实性和实用性。

Conclusion: ContextGAN通过集成领域约束和差分隐私，有效解决了隐私保护与数据效用之间的平衡问题，特别适用于需要同时遵守显式模式和隐式规则且对隐私要求严格的领域应用。

Abstract: The widespread use of big data across sectors has raised major privacy concerns, especially when sensitive information is shared or analyzed. Regulations such as GDPR and HIPAA impose strict controls on data handling, making it difficult to balance the need for insights with privacy requirements. Synthetic data offers a promising solution by creating artificial datasets that reflect real patterns without exposing sensitive information. However, traditional synthetic data methods often fail to capture complex, implicit rules that link different elements of the data and are essential in domains like healthcare. They may reproduce explicit patterns but overlook domain-specific constraints that are not directly stated yet crucial for realism and utility. For example, prescription guidelines that restrict certain medications for specific conditions or prevent harmful drug interactions may not appear explicitly in the original data. Synthetic data generated without these implicit rules can lead to medically inappropriate or unrealistic profiles. To address this gap, we propose ContextGAN, a Context-Aware Differentially Private Generative Adversarial Network that integrates domain-specific rules through a constraint matrix encoding both explicit and implicit knowledge. The constraint-aware discriminator evaluates synthetic data against these rules to ensure adherence to domain constraints, while differential privacy protects sensitive details from the original data. We validate ContextGAN across healthcare, security, and finance, showing that it produces high-quality synthetic data that respects domain rules and preserves privacy. Our results demonstrate that ContextGAN improves realism and utility by enforcing domain constraints, making it suitable for applications that require compliance with both explicit patterns and implicit rules under strict privacy guarantees.

</details>


### [161] [Fed-SE: Federated Self-Evolution for Privacy-Constrained Multi-Environment LLM Agents](https://arxiv.org/abs/2512.08870)
*Xiang Chen,Yuling Shi,Qizhen Lan,Yuchao Qiu,Xiaodong Gu*

Main category: cs.LG

TL;DR: Fed-SE：一个联邦自进化框架，用于解决LLM智能体在隐私约束下的跨环境知识迁移问题，通过局部进化-全局聚合范式，在异构任务中提升约18%的任务成功率。


<details>
  <summary>Details</summary>
Motivation: LLM智能体在复杂交互任务中广泛部署，但隐私约束限制了集中式优化和跨动态环境的协同进化。虽然联邦学习在静态数据集上有效，但在开放式的智能体自进化方面仍待探索。直接应用标准联邦学习面临挑战：异构任务和稀疏的轨迹级奖励会导致严重的梯度冲突，破坏全局优化过程。

Method: Fed-SE采用局部进化-全局聚合范式。局部层面：智能体在过滤后的高回报轨迹上进行参数高效微调，实现稳定的梯度更新。全局层面：在低秩子空间中聚合更新，解耦环境特定的动态，有效减少客户端间的负迁移。

Result: 在五个异构环境中的实验表明，Fed-SE相比联邦基线方法，平均任务成功率提升了约18%，验证了其在隐私约束部署中实现鲁棒跨环境知识迁移的有效性。

Conclusion: Fed-SE成功解决了LLM智能体在联邦学习设置下的自进化问题，通过创新的局部进化策略和全局聚合机制，在保护隐私的同时实现了跨异构环境的有效知识迁移，为隐私约束下的智能体协同进化提供了可行方案。

Abstract: LLM agents are widely deployed in complex interactive tasks, yet privacy constraints often preclude centralized optimization and co-evolution across dynamic environments. While Federated Learning (FL) has proven effective on static datasets, its extension to the open-ended self-evolution of agents remains underexplored. Directly applying standard FL is challenging: heterogeneous tasks and sparse, trajectory-level rewards introduce severe gradient conflicts, destabilizing the global optimization process. To bridge this gap, we propose Fed-SE, a Federated Self-Evolution framework for LLM agents. Fed-SE establishes a local evolution-global aggregation paradigm. Locally, agents employ parameter-efficient fine-tuning on filtered, high-return trajectories to achieve stable gradient updates. Globally, Fed-SE aggregates updates within a low-rank subspace that disentangles environment-specific dynamics, effectively reducing negative transfer across clients. Experiments across five heterogeneous environments demonstrate that Fed-SE improves average task success rates by approximately 18% over federated baselines, validating its effectiveness in robust cross-environment knowledge transfer in privacy-constrained deployments.

</details>


### [162] [When Tables Leak: Attacking String Memorization in LLM-Based Tabular Data Generation](https://arxiv.org/abs/2512.08875)
*Joshua Ward,Bochao Gu,Chi-Hua Wang,Guang Cheng*

Main category: cs.LG

TL;DR: LLM生成的表格合成数据存在隐私泄露风险，数字序列容易被记忆并重现，本文提出LevAtt攻击方法揭示此漏洞，并提出防御策略


<details>
  <summary>Details</summary>
Motivation: LLM在生成高质量表格合成数据方面表现出色，但现有方法（微调小模型或提示大模型）存在隐私风险，可能重现训练数据中的数字模式。需要系统分析这种隐私泄露风险并提出防御措施。

Method: 提出LevAtt黑盒成员推理攻击方法，仅访问生成的合成数据，针对数字字符串序列进行攻击。同时提出两种防御方法，包括在生成过程中策略性扰动数字的新型采样策略。

Result: LevAtt攻击在多种模型和数据集上暴露了显著的隐私泄露，在某些最先进的模型上甚至成为完美的成员分类器。提出的防御方法能够有效抵御攻击，同时保持合成数据的保真度和实用性损失最小。

Conclusion: LLM基于的合成数据生成存在独特的隐私漏洞，数字序列容易被记忆和重现。需要有效的防御机制，本文提出的策略性数字扰动方法能够平衡隐私保护和数据质量。

Abstract: Large Language Models (LLMs) have recently demonstrated remarkable performance in generating high-quality tabular synthetic data. In practice, two primary approaches have emerged for adapting LLMs to tabular data generation: (i) fine-tuning smaller models directly on tabular datasets, and (ii) prompting larger models with examples provided in context. In this work, we show that popular implementations from both regimes exhibit a tendency to compromise privacy by reproducing memorized patterns of numeric digits from their training data. To systematically analyze this risk, we introduce a simple No-box Membership Inference Attack (MIA) called LevAtt that assumes adversarial access to only the generated synthetic data and targets the string sequences of numeric digits in synthetic observations. Using this approach, our attack exposes substantial privacy leakage across a wide range of models and datasets, and in some cases, is even a perfect membership classifier on state-of-the-art models. Our findings highlight a unique privacy vulnerability of LLM-based synthetic data generation and the need for effective defenses. To this end, we propose two methods, including a novel sampling strategy that strategically perturbs digits during generation. Our evaluation demonstrates that this approach can defeat these attacks with minimal loss of fidelity and utility of the synthetic data.

</details>


### [163] [DAO-GP Drift Aware Online Non-Linear Regression Gaussian-Process](https://arxiv.org/abs/2512.08879)
*Mohammad Abu-Shaira,Ajita Rattani,Weishi Shi*

Main category: cs.LG

TL;DR: DAO-GP是一种新型的漂移感知在线高斯过程模型，具有完全自适应、无超参数、衰减和稀疏特性，能够动态检测和适应数据分布变化。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据集常呈现随时间演化的数据分布（概念漂移），忽视这一问题会显著降低模型预测精度。现有在线高斯过程方法存在缺乏漂移感知、依赖固定超参数、易受数据窥探、缺乏原则性衰减机制和内存效率低等关键限制。

Method: 提出DAO-GP（漂移感知在线高斯过程），这是一种完全自适应、无超参数、衰减和稀疏的非线性回归模型。模型内置漂移检测和适应机制，能根据漂移严重程度动态调整模型行为。

Result: 广泛的实证评估证实DAO-GP在平稳条件、多种漂移类型（突变、增量、渐进）和不同数据特征下都具有鲁棒性。分析显示其具有动态适应能力、高效的内存和衰减管理以及演化诱导点。与最先进的参数和非参数模型相比，DAO-GP始终实现优越或竞争性性能。

Conclusion: DAO-GP被确立为在线非线性回归的漂移弹性解决方案，能够有效应对概念漂移问题，在动态环境中保持高性能。

Abstract: Real-world datasets often exhibit temporal dynamics characterized by evolving data distributions. Disregarding this phenomenon, commonly referred to as concept drift, can significantly diminish a model's predictive accuracy. Furthermore, the presence of hyperparameters in online models exacerbates this issue. These parameters are typically fixed and cannot be dynamically adjusted by the user in response to the evolving data distribution. Gaussian Process (GP) models offer powerful non-parametric regression capabilities with uncertainty quantification, making them ideal for modeling complex data relationships in an online setting. However, conventional online GP methods face several critical limitations, including a lack of drift-awareness, reliance on fixed hyperparameters, vulnerability to data snooping, absence of a principled decay mechanism, and memory inefficiencies. In response, we propose DAO-GP (Drift-Aware Online Gaussian Process), a novel, fully adaptive, hyperparameter-free, decayed, and sparse non-linear regression model. DAO-GP features a built-in drift detection and adaptation mechanism that dynamically adjusts model behavior based on the severity of drift. Extensive empirical evaluations confirm DAO-GP's robustness across stationary conditions, diverse drift types (abrupt, incremental, gradual), and varied data characteristics. Analyses demonstrate its dynamic adaptation, efficient in-memory and decay-based management, and evolving inducing points. Compared with state-of-the-art parametric and non-parametric models, DAO-GP consistently achieves superior or competitive performance, establishing it as a drift-resilient solution for online non-linear regression.

</details>


### [164] [Explainable Anomaly Detection for Industrial IoT Data Streams](https://arxiv.org/abs/2512.08885)
*Ana Rita Paupério,Diogo Risca,Afonso Lourenço,Goreti Marreiros,Ricardo Martins*

Main category: cs.LG

TL;DR: 提出一个结合无监督异常检测与交互式人机学习的协作式数据流挖掘框架，用于工业维护决策支持


<details>
  <summary>Details</summary>
Motivation: 工业物联网和边缘计算产生连续数据流，需要实时自适应决策，但实际应用中地面真实标签往往延迟或不可得，现有数据流挖掘方法大多假设完全监督设置

Method: 采用在线隔离森林进行无监督异常检测，结合增量部分依赖图和特征重要性评分（基于个体条件期望曲线与衰减平均的偏差），支持用户动态重新评估特征相关性和调整异常阈值

Result: 在提花织机单元的故障检测中实现了实时实施并提供了初步结果

Conclusion: 该框架通过人机交互学习解决了工业维护中标签稀缺的问题，正在进行的工作旨在通过连续监测预测和解释即将发生的轴承故障

Abstract: Industrial maintenance is being transformed by the Internet of Things and edge computing, generating continuous data streams that demand real-time, adaptive decision-making under limited computational resources. While data stream mining (DSM) addresses this challenge, most methods assume fully supervised settings, yet in practice, ground-truth labels are often delayed or unavailable. This paper presents a collaborative DSM framework that integrates unsupervised anomaly detection with interactive, human-in-the-loop learning to support maintenance decisions. We employ an online Isolation Forest and enhance interpretability using incremental Partial Dependence Plots and a feature importance score, derived from deviations of Individual Conditional Expectation curves from a fading average, enabling users to dynamically reassess feature relevance and adjust anomaly thresholds. We describe the real-time implementation and provide initial results for fault detection in a Jacquard loom unit. Ongoing work targets continuous monitoring to predict and explain imminent bearing failures.

</details>


### [165] [Revisiting the Scaling Properties of Downstream Metrics in Large Language Model Training](https://arxiv.org/abs/2512.08894)
*Jakub Krajewski,Amitis Shidani,Dan Busbridge,Sam Wiseman,Jason Ramapuram*

Main category: cs.LG

TL;DR: 论文提出直接建模下游任务性能随训练预算变化的框架，挑战了传统认为下游性能预测不可靠的观点，发现固定token-参数比时，简单幂律能准确描述多个下游任务的log准确率缩放行为。


<details>
  <summary>Details</summary>
Motivation: 传统的大语言模型缩放定律主要关注预训练损失等代理指标，而下游任务性能预测被认为不可靠。本文挑战这一观点，旨在建立直接从训练预算预测下游基准性能的可靠框架。

Method: 提出直接框架建模基准性能随训练预算的缩放，发现固定token-参数比时，简单幂律能准确描述下游任务log准确率的缩放行为。引入跨token-参数比的函数形式，并考虑重复采样下的推理计算。

Result: 直接方法比之前提出的两阶段程序外推效果更好（后者容易产生复合误差）。在高达170亿参数、3500亿token的两个数据集混合上验证了发现，并发布了完整的预训练损失和下游评估结果以支持复现。

Conclusion: 下游任务性能可以通过训练预算直接可靠地预测，挑战了传统观点。提出的直接框架和幂律缩放关系为模型缩放提供了更准确的方法，有助于未来研究和实际应用中的计算预算分配。

Abstract: While scaling laws for Large Language Models (LLMs) traditionally focus on proxy metrics like pretraining loss, predicting downstream task performance has been considered unreliable. This paper challenges that view by proposing a direct framework to model the scaling of benchmark performance from the training budget. We find that for a fixed token-to-parameter ratio, a simple power law can accurately describe the scaling behavior of log accuracy on multiple popular downstream tasks. Our results show that the direct approach extrapolates better than the previously proposed two-stage procedure, which is prone to compounding errors. Furthermore, we introduce functional forms that predict accuracy across token-to-parameter ratios and account for inference compute under repeated sampling. We validate our findings on models with up to 17B parameters trained on up to 350B tokens across two dataset mixtures. To support reproducibility and encourage future research, we release the complete set of pretraining losses and downstream evaluation results.

</details>


### [166] [Unsupervised Learning of Density Estimates with Topological Optimization](https://arxiv.org/abs/2512.08895)
*Suina Tanweer,Firas A. Khasawneh*

Main category: cs.LG

TL;DR: 提出基于拓扑的损失函数来自动选择核密度估计的最优带宽，无需监督信号


<details>
  <summary>Details</summary>
Motivation: 核密度估计中的带宽选择是关键但困难的问题，传统方法需要人工调参，而拓扑数据分析能数学化地量化密度估计的拓扑特征，即使在无法可视化高维数据时也有效

Method: 使用基于拓扑的损失函数进行无监督学习，自动选择最优带宽，该方法利用拓扑数据分析来量化密度估计的拓扑特征（如连通分量、环、空洞等）

Result: 在不同维度上与经典技术进行基准测试，展示了该方法的潜力

Conclusion: 基于拓扑的损失函数为核密度估计的带宽选择提供了一种自动化和无监督的解决方案，能够有效处理高维数据

Abstract: Kernel density estimation is a key component of a wide variety of algorithms in machine learning, Bayesian inference, stochastic dynamics and signal processing. However, the unsupervised density estimation technique requires tuning a crucial hyperparameter: the kernel bandwidth. The choice of bandwidth is critical as it controls the bias-variance trade-off by over- or under-smoothing the topological features. Topological data analysis provides methods to mathematically quantify topological characteristics, such as connected components, loops, voids et cetera, even in high dimensions where visualization of density estimates is impossible. In this paper, we propose an unsupervised learning approach using a topology-based loss function for the automated and unsupervised selection of the optimal bandwidth and benchmark it against classical techniques -- demonstrating its potential across different dimensions.

</details>


### [167] [Open Polymer Challenge: Post-Competition Report](https://arxiv.org/abs/2512.08896)
*Gang Liu,Sobin Alosious,Subhamoy Mahajan,Eric Inae,Yihan Zhu,Yuhan Liu,Renzheng Zhang,Jiaxin Xu,Addison Howard,Ying Li,Tengfei Luo,Meng Jiang*

Main category: cs.LG

TL;DR: Open Polymer Challenge发布了首个聚合物信息学社区基准数据集，包含10K聚合物和5种性质，通过多任务预测竞赛推动可持续聚合物材料的AI发现。


<details>
  <summary>Details</summary>
Motivation: 机器学习在发现可持续聚合物材料方面潜力巨大，但缺乏大规模、高质量、开放可访问的聚合物数据集限制了进展。

Method: 发布包含10K聚合物和5种性质（热导率、回转半径、密度、自由体积分数、玻璃化转变温度）的基准数据集，组织多任务聚合物性质预测竞赛，参赛者在数据量小、标签不平衡、模拟源异质等现实约束下开发模型，采用特征增强、迁移学习、自监督预训练、针对性集成策略等技术。

Result: 竞赛揭示了数据准备、分布偏移和跨组模拟一致性等方面的重要经验，为未来大规模聚合物数据集的最佳实践提供指导，建立的模型、分析和发布数据为聚合物科学中的分子AI奠定新基础。

Conclusion: Open Polymer Challenge通过发布基准数据集和组织竞赛，为聚合物信息学建立了新标准，有望加速可持续和节能材料的发展，同时发布了测试数据集和数据生成管道。

Abstract: Machine learning (ML) offers a powerful path toward discovering sustainable polymer materials, but progress has been limited by the lack of large, high-quality, and openly accessible polymer datasets. The Open Polymer Challenge (OPC) addresses this gap by releasing the first community-developed benchmark for polymer informatics, featuring a dataset with 10K polymers and 5 properties: thermal conductivity, radius of gyration, density, fractional free volume, and glass transition temperature. The challenge centers on multi-task polymer property prediction, a core step in virtual screening pipelines for materials discovery. Participants developed models under realistic constraints that include small data, label imbalance, and heterogeneous simulation sources, using techniques such as feature-based augmentation, transfer learning, self-supervised pretraining, and targeted ensemble strategies. The competition also revealed important lessons about data preparation, distribution shifts, and cross-group simulation consistency, informing best practices for future large-scale polymer datasets. The resulting models, analysis, and released data create a new foundation for molecular AI in polymer science and are expected to accelerate the development of sustainable and energy-efficient materials. Along with the competition, we release the test dataset at https://www.kaggle.com/datasets/alexliu99/neurips-open-polymer-prediction-2025-test-data. We also release the data generation pipeline at https://github.com/sobinalosious/ADEPT, which simulates more than 25 properties, including thermal conductivity, radius of gyration, and density.

</details>
