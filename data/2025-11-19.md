<div id=toc></div>

# Table of Contents

- [physics.comp-ph](#physics.comp-ph) [Total: 2]
- [gr-qc](#gr-qc) [Total: 16]
- [quant-ph](#quant-ph) [Total: 45]
- [cs.LG](#cs.LG) [Total: 89]


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [1] [Statistically controllable microstructure reconstruction framework for heterogeneous materials using sliced-Wasserstein metric and neural networks](https://arxiv.org/abs/2511.14268)
*Zhenchuan Ma,Qizhi Teng,Pengcheng Yan,Lindong Li,Kirill M. Gerke,Marina V. Karsanina,Xiaohai He*

Main category: physics.comp-ph

TL;DR: 提出了一种结合神经网络和切片Wasserstein度量的统计可控微结构重建框架，能够在小样本下实现随机、可控、异质和大尺寸的3D微结构重建。


<details>
  <summary>Details</summary>
Motivation: 异质多孔材料在工程系统中至关重要，微结构表征和重建对于物理性质模拟、结构-性能关系研究及性能提升具有重要意义。需要在小样本下实现更好的可控性和适用性。

Method: 利用局部模式分布进行微结构表征，采用受控采样策略生成满足条件参数的目标分布。基于神经网络的模型建立从输入分布到目标局部模式分布的映射，结合切片Wasserstein度量和梯度优化技术最小化分布距离。

Result: 方法能够在小样本下执行随机和可控重建任务，通过分块策略生成大尺寸3D微结构，引入空间位置掩码可生成空间异质复杂微结构。实验验证了方法的有效性。

Conclusion: 该方法为结构-性能关系研究和材料逆向设计提供了新的见解和可能性，通过可视化、统计度量和物理性质模拟的比较分析证明了其有效性。

Abstract: Heterogeneous porous materials play a crucial role in various engineering systems. Microstructure characterization and reconstruction provide effective means for modeling these materials, which are critical for conducting physical property simulations, structure-property linkage studies, and enhancing their performance across different applications. To achieve superior controllability and applicability with small sample sizes, we propose a statistically controllable microstructure reconstruction framework that integrates neural networks with sliced-Wasserstein metric. Specifically, our approach leverages local pattern distribution for microstructure characterization and employs a controlled sampling strategy to generate target distributions that satisfy given conditional parameters. A neural network-based model establishes the mapping from the input distribution to the target local pattern distribution, enabling microstructure reconstruction. Combinations of sliced-Wasserstein metric and gradient optimization techniques minimize the distance between these distributions, leading to a stable and reliable model. Our method can perform stochastic and controllable reconstruction tasks even with small sample sizes. Additionally, it can generate large-size (e.g. 512 and 1024) 3D microstructures using a chunking strategy. By introducing spatial location masks, our method excels at generating spatially heterogeneous and complex microstructures. We conducted experiments on stochastic reconstruction, controllable reconstruction, heterogeneous reconstruction, and large-size microstructure reconstruction across various materials. Comparative analysis through visualization, statistical measures, and physical property simulations demonstrates the effectiveness, providing new insights and possibilities for research on structure-property linkage and material inverse design.

</details>


### [2] [Stability of Extrinsic Cohesive-Zone Model with Penalty-Based Contact in Explicit Dynamic Fragmentation Simulations](https://arxiv.org/abs/2511.14323)
*Thibault Ghesquière-Diérickx,Jean-François Molinari,Guillaume Anciaux*

Main category: physics.comp-ph

TL;DR: 该论文分析了动态断裂模拟中基于惩罚接触与外部粘聚区模型结合时出现的能量不稳定问题，识别了三种不稳定机制，并提出自适应惩罚策略作为诊断方案。


<details>
  <summary>Details</summary>
Motivation: 由于基于惩罚接触与外部粘聚区模型结合的显式动态模拟在高速应变率下表现出严重的能量不稳定性和人工断裂现象，需要系统分析不稳定源。

Method: 通过二维基准测试，分离并量化三种不稳定机制：初始粘聚刚度发散、粘聚-接触界面刚度跳跃、粘聚软化引入的不连续性。使用解析误差估计、相空间诊断和能量增长指标进行分析。

Result: 研究发现重复的粘聚-接触切换会将每步的小能量误差累积为长期能量漂移。在参数空间中，保持稳定性需要远低于常规限制的时间步长。自适应惩罚策略可消除不连续性并恢复能量守恒，但允许更大的相互穿透。

Conclusion: 惩罚接触方法不适合用于长期、能量一致的断裂模拟，无法获得物理上有意义的断裂统计结果。

Abstract: Dynamic fragmentation simulations are essential for predicting material response at high strain rates, yet explicit dynamic simulations that combine an extrinsic cohesive-zone model (CZM) with penalty-based contact often exhibit severe instabilities. In a two-dimensional benchmark, we observe exponential energy growth and resulting artificial fragmentation under standard contact penalty settings and time step choices, which motivates a systematic analysis of instability sources. Three mechanisms are isolated and quantified: (i) diverging initial cohesive stiffness, which constrains the stable time step; (ii) discontinuous stiffness jumps at the cohesive-contact interface; and (iii) discontinuity introduced by cohesive softening. Analytical error estimates, phase-space diagnostics, and energy growth metrics reveal that repeated cohesive-contact switching can accumulate small per-step energy errors into long-term energy drift. Within the explored parameter space, maintaining stability requires time steps well below the usual limit. To mitigate these energy artifacts, we assess an adaptive penalty strategy that ties the contact stiffness to the evolving cohesive stiffness. This modification eliminates the discontinuity and restores energy conservation, but it allows larger interpenetration, making it suitable as a diagnostic rather than a definitive remedy. Overall, our study identifies the root causes of unphysical energy drift and demonstrates that penalty-based contact is not a viable approach for long-term, energy-consistent fragmentation simulations with physically meaningful fragment statistics.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [3] [Unification of Conformal and Fuzzy Gravities with Internal Interactions - study of their behaviour in low energies and possible signals in the detection of Gravitational Waves](https://arxiv.org/abs/2511.13803)
*Gregory Patellis,Danai Roumelioti,Stelios Stefas,George Zoupanos*

Main category: gr-qc

TL;DR: 该论文基于弯曲流形的切群与流形本身维度不一定相同的原理，以及引力的规范理论表述，提出了将共形引力和模糊引力与内部相互作用统一的理论框架。


<details>
  <summary>Details</summary>
Motivation: 统一共形引力和非对易（模糊）引力与内部相互作用，利用规范理论框架建立统一的引力理论。

Method: 1. 回顾引力的规范理论方法及其微分同胚不变性；2. 在规范理论框架下构建共形引力和非对易引力；3. 通过扩展四维切群实现引力与内部相互作用的统一。

Result: 提出了两种统一方案，并进一步考察了它们在低能下的行为（通过自发对称性破缺）以及相关宇宙弦在引力波中的可能信号。

Conclusion: 通过规范理论框架和切群扩展，成功实现了共形引力与模糊引力同内部相互作用的统一，为研究低能行为和引力波信号提供了理论基础。

Abstract: The Unification of Conformal and Fuzzy gravities with Internal Interactions is based on the following two facts. The first is that the tangent group of a curved manifold and the manifold itself do not necessarily have the same dimensions. The second is that both gravitational theories considered here have been formulated in a gauge theoretic way. Here we would like to start by reviewing the gauge theoretic approach of gravities commenting in particular their diffeomorphism invariance. Then we will review the construction of the Conformal Gravity and the Noncommutative (Fuzzy) Gravity using the gauge theoretic framework. Finally based on an extension of the four-dimensional tangent group we will present the Unification of both Gravities with the Internal Interactions. Both unified schemes will be examined further concerning their behaviour in low energies after suitable spontaneous symmetry breakings as well as the possible signals of the related cosmic strings in the gravitational waves.

</details>


### [4] [Twisting asymptotically-flat spacetimes](https://arxiv.org/abs/2511.13814)
*Marc Geiller,Pujian Mao,Antoine Vincenti*

Main category: gr-qc

TL;DR: 本文扩展了Bondi形式，描述了渐近平坦时空，其中外向零测地线束不是超曲面正交的（即具有非零扭转）。在Newman-Penrose表述中，扭转由横向零二元组中的扭转势源产生，而在度规表述中，该势来自g_ra≠0。作者构建并求解了此类广义线元的爱因斯坦方程，提供了具有非零扭转的渐近平坦时空的Bondi层次结构扩展。


<details>
  <summary>Details</summary>
Motivation: 扩展Bondi形式以处理具有非零扭转的渐近平坦时空，使得代数特殊解（如Kerr-Taub-NUT解）能够以显式有限径向展开形式表示，并具有重复的主零方向。这有助于发展代数特殊解的平坦全息术研究及其扰动分析。

Method: 扩展Bondi形式，构建具有非零扭转的渐近平坦时空的广义线元，安排并求解爱因斯坦方程。在Newman-Penrose表述中分析扭转源，在度规表述中处理g_ra≠0的情况。研究扭转势的Carrollian解释及其产生的额外渐近对称性。

Result: 成功构建了具有非零扭转的渐近平坦时空的Bondi层次结构扩展，包括解空间、通量平衡定律、渐近对称性和变换定律的扭转推广。扭转势具有自然的Carrollian解释作为Ehresmann连接，并产生Carroll提升作为额外渐近对称性。代数特殊解能够以有限径向展开形式表示。

Conclusion: 扩展的Bondi形式为具有非零扭转的渐近平坦时空提供了完整的理论框架，特别适用于代数特殊解的研究。这些结果有望在代数特殊解的平坦全息术发展和扰动研究中找到应用。同时，在三维非零宇宙常数时空中也发现了类似的扭转结构，得到了8维解空间。

Abstract: We extend the Bondi formalism to describe asymptotically-flat spacetimes where the outgoing null geodesic congruence is not hypersurface-orthogonal, i.e. has a non-vanishing twist. In the Newman-Penrose formulation, the twist $\text{Im}(ρ)$ is sourced by a twist potential sitting in the transverse null dyad $(m,\bar{m})$, while in the metric formulation this potential arises from $g_{ra}\neq0$. We explain how to arrange and solve the Einstein equations for such generalized line elements, thereby providing an extension of the Bondi hierarchy to asymptotically-flat spacetimes with non-vanishing twist. We work out the twisting generalizations of all the well-known features pertaining to asymptotically-flat spacetimes in Bondi gauge, such as the solution space, the flux-balance laws, the asymptotic symmetries, and the transformation laws. The twist potential has a natural Carrollian interpretation as an Ehresmann connection, and gives rise to Carroll boosts as extra asymptotic symmetries. One of the advantages of the Bondi gauge with non-vanishing twist is that it allows to write algebraically special solutions in a manifestly finite radial expansion, and with a repeated principal null direction such that $Ψ_0=Ψ_1=0$. This is in particular the case for the Kerr-Taub-NUT solution. The asymptotic symmetries of algebraically special solutions also have a finite radial expansion, which enables to study the supertranslated Schwarzschild solution and its charges quite straightforwardly. We expect that these results will find applications in the development of flat holography for algebraically special solutions and in the study of their perturbations. We also study an analogue of the twist in three-dimensional spacetimes with non-vanishing cosmological constant, and find an 8-dimensional solution space which encompasses and generalizes the existing results in the literature.

</details>


### [5] [Characteristic Decomposition for Relativistic Numerical Simulations: I. Hydrodynamics](https://arxiv.org/abs/2511.13836)
*Saul A. Teukolsky*

Main category: gr-qc

TL;DR: 提出了一种基于准可逆变换的新方法，用于推导广义相对论磁流体动力学(GRMHD)的特征分解，该方法从共动坐标系出发，简化了分解过程。


<details>
  <summary>Details</summary>
Motivation: 当前GRMHD的特征分解形式不适合数值模拟，阻碍了使用最精确的计算方法如全波黎曼解算器。

Method: 基于从共动坐标系（流体流动最简单）的变换，引入准可逆变换的概念，首先在相对论流体动力学中验证该方法。

Result: 成功恢复了相对论流体动力学的已知分解，形式更简化且无需计算机代数；获得了核统计平衡下流体成分演化的新特征分解。

Conclusion: 准可逆变换方法有效简化了特征分解的推导，为后续论文中GRMHD在守恒变量中的完整特征分解奠定了基础。

Abstract: The characteristic decomposition for GRMHD is not known in a form useful for current numerical simulations. This prevents us from using the most accurate known computational methods, such as full-wave Riemann solvers. In this paper, we present a new method of finding decompositions. The method is based on transformations from the comoving frame, where the fluid flow is simplest and the decomposition has been known for a long time. The key innovation we introduce is that of quasi-invertible transformations. In this first paper, we introduce these transformations using the simpler example of relativistic hydrodynamics. We recover the known decomposition for relativistic hydrodynamics in somewhat simpler form than previously derived, and without the need for computer algebra. A new result in this paper is the characteristic decomposition when the the evolution tracks the composition of a fluid in nuclear statistical equilibrium. In Paper II of this series, we apply a quasi-invertible transformation to derive the complete characteristic decomposition for GRMHD in the conserved variables used in simulations.

</details>


### [6] [Characteristic Decomposition for Relativistic Numerical Simulations: II. Magnetohydrodynamics](https://arxiv.org/abs/2511.13837)
*Saul A. Teukolsky*

Main category: gr-qc

TL;DR: 本文推导了GRMHD在坐标框架下的特征分解，使得可以使用全波黎曼求解器等精确计算方法。


<details>
  <summary>Details</summary>
Motivation: 虽然GRMHD在流体共动框架下的特征分解已知，但在模拟坐标框架和守恒变量下的分解一直未知，这限制了使用精确数值方法。

Method: 应用论文I中发展的准可逆变换方法来推导特征分解。

Result: 得到的分解结果比基于早期尝试的预期更简单。

Conclusion: 成功推导出GRMHD在坐标框架下的特征分解，为使用更精确的数值方法奠定了基础。

Abstract: The characteristic decomposition for GRMHD in the comoving frame of the fluid has been known for a long time. However, it has not been known in the coordinate frame of the simulation and in terms of the conserved variables evolved in typical numerical simulations. This paper applies the method of quasi-invertible transformations developed in Paper I to derive this decomposition. Among other benefits, this will allow us to use the most accurate known computational methods, such as full-wave Riemann solvers. The results turn out to be simpler than expected based on earlier attempts.

</details>


### [7] [Extremal isolated horizons of the NUT type](https://arxiv.org/abs/2511.13842)
*Eryk Buk,Denis Dobkowski-Ryłko,Jerzy Lewandowski,Maciej Ossowski*

Main category: gr-qc

TL;DR: 该论文构建了一类新型轴对称极值孤立视界，具有U(1)主纤维丛结构，其中零生成元与纤维横截，并推导了所有内在几何结构。


<details>
  <summary>Details</summary>
Motivation: 研究具有横截纤维丛结构的极值孤立视界，扩展对爱因斯坦方程在视界上解的几何分类。

Method: 在U(1)主纤维丛结构下求解爱因斯坦方程，推导视界的内在几何（二维球面度量和旋转1-形式），并与Plebański-Demiański时空进行嵌入比较。

Result: 获得了极值视界的完整内在几何分类，发现与锥形奇异视界的分类等价，成功嵌入到Plebański-Demiański时空中。

Conclusion: 构建的新类极值孤立视界提供了爱因斯坦方程在具有横截纤维丛结构的视界上的新解，扩展了现有分类体系。

Abstract: We provide a construction of a new class of axisymmetric extremal isolated horizons admitting a structure of U(1)-principal fiber bundle over a two-sphere. In contrast to the previous examples, the null generators are assumed to be transversal to the bundle fibers. We impose the Einstein equations at the horizon and explicitly derive all intrinsic geometries of the extremal horizon, consisting of a two-sphere metric and a rotation 1-form, in the above class. The 2-geometries turn out to be equivalent to the classification of conically singular horizons with product topology. Both the rotating and non-rotating horizons are then embedded in the Plebański-Demiański spacetimes, which naturally admit horizons of this type. Furthermore, we compare our results with previously obtained solutions to the Einstein vacuum extremal horizon equation with cosmological constant and the solution of Petrov type D equation with transversal bundle structure.

</details>


### [8] [Gravitational Atom Spectroscopy](https://arxiv.org/abs/2511.13848)
*Matteo Della Rocca,Thomas F. M. Spieksma,Francisco Duque,Leonardo Gualtieri,Vitor Cardoso*

Main category: gr-qc

TL;DR: 该论文研究了黑洞周围自引力标量场形成的引力原子构型，计算了其准正规模，发现相对于真空情况存在频率偏移，这种偏移可能被当前或未来的引力波探测器探测到。


<details>
  <summary>Details</summary>
Motivation: 研究黑洞周围自引力标量场形成的引力原子构型在足够致密时的准正规模特性，探索其在天体物理环境中的观测意义。

Method: 采用完全相对论性计算，在时间和频率域中计算了引力原子构型的轴向准正规模。

Result: 发现相对于真空情况的频率偏移主要取决于引力原子的致密程度，对于足够致密的构型，这些偏移可能被引力波探测器探测到。

Conclusion: 自引力标量场形成的引力原子构型会产生可观测的准正规模频率偏移，这为通过引力波探测这类天体物理系统提供了可能性。

Abstract: Black holes in our Universe are rarely truly isolated, being instead embedded in astrophysical environments such as plasma or dark matter. A particularly intriguing possibility is that light scalar fields form bound states around black holes, producing extended ''clouds'' known as gravitational atoms. When these clouds become sufficiently compact, the spacetime can no longer be described by a vacuum solution of General Relativity. In this regime, one can construct quasi-stationary, spherically symmetric, self-gravitating scalar gravitational-atom configurations. Here, we explore an observationally relevant aspect of these systems by computing their fundamental quasi-normal mode. We present a fully relativistic calculation of the axial modes in both the time and frequency domains, finding frequency shifts relative to the vacuum case that depends mostly on the compactness of the gravitational atom. For sufficiently compact configurations, these shifts may be detectable by current or future gravitational wave detectors.

</details>


### [9] [Hermitian formulation for mass dimension one fermions: Flat and curved space-times](https://arxiv.org/abs/2511.13951)
*Gabriel Brandão de Gracia,Rodolfo José Bueno Rogerio*

Main category: gr-qc

TL;DR: 本文回顾了Elko旋量的埃尔米特性，提出了基于Elko旋量的相互作用质量维度一费米子的埃尔米特表述，研究了可重整性和允许的相互作用，并将该表述推广到弯曲时空和量子引力背景。


<details>
  <summary>Details</summary>
Motivation: 研究暗物质现象学与引力的联系，需要将埃尔米特表述扩展到弯曲时空背景，并纳入量子引力效应。

Method: 通过路径积分表述建立更基本的结构，推导出Elko对偶，从而将埃尔米特表述推广到弯曲时空和量子引力背景。

Result: 建立了包含弯曲背景时空和量子引力的埃尔米特表述框架，为研究暗物质现象学提供了理论基础。

Conclusion: 埃尔米特表述可以成功扩展到弯曲时空和量子引力背景，为暗物质研究开辟了新途径。

Abstract: Throughout this paper, we conduct our discussion by a partial review of Elko's Hermiticity, introducing the Hermitian formulation for interacting mass dimension one fermions based on Elko spinor. It includes pivotal observations about renormalizability and the study of some allowed interactions. Beyond these points, since dark-matter phenomenology is mainly connected to gravitation, we introduce original remarks on how the Hermitian prescription can be readily generalized to include curved space-time, considering the very definition of the Elko spinor structure. We establish the Elko dual as arising from the path-integral formulation of a more fundamental structure. It enables one to include a curved background space-time and also quantum gravity into our investigations.

</details>


### [10] [Phase Space of SdS Geodesics and using the Cosmological Horizon to Observe a Black Hole](https://arxiv.org/abs/2511.13995)
*Bela Nelson,Allison Powell,Jennie Traschen*

Main category: gr-qc

TL;DR: 在史瓦西-德西特时空中，利用宇宙学视界的蓝移效应可以观测到黑洞视界附近发出的高度红移光子，最佳观测策略是接收者位于宇宙学视界附近并向黑洞移动。


<details>
  <summary>Details</summary>
Motivation: 黑洞视界附近的辐射由于无限红移效应通常无法被观测到，但在具有宇宙学常数的史瓦西-德西特时空中，可以利用宇宙学视界的蓝移效应来补偿这种红移。

Method: 计算了各种加速和测地线观测者的信号频率变化，分析了史瓦西-德西特时空中的径向和圆形测地线，发现了测地线参数空间中的临界曲线。

Result: 找到了观测落入黑洞发射器发出光子的最佳策略：接收者位于宇宙学视界附近并向黑洞移动。对于从最小圆形轨道发射、在最大圆形轨道接收的光子，非零宇宙学常数可将观测增强因子从0提高到3。

Conclusion: 史瓦西-德西特时空中的宇宙学视界蓝移效应为观测黑洞视界附近的辐射提供了新的可能性，突破了传统黑洞观测的限制。

Abstract: Light propagating from near a black hole horizon to the outside world is highly redshifted. In the limit that the emitter passes through the horizon, the redshift becomes infinite. In this sense the near horizon region is unobservable, as emission energies fall below some detectability bound. However, in Schwarzschild de Sitter (SdS) spacetime there is a second, cosmological, horizon due to the positive cosmological constant. Judiciously placed observers can take advantage of the blueshift due to this horizon. The frequency of signals emitted from near the black hole can be shifted back upward to an observable value. This effect is computed for a variety of accelerated and geodesic observers. An analysis of radial and circular geodesics in SdS is a key component of the paper. We find a ``cresting-wave" shaped critical curve in the SdS-geodesic parameter space such that under the curve there are three circular orbits, on the curve there are two orbits, and elsewhere there is one. It is found that the best strategy for observing photons from an emitter falling into the black hole is for the receiver to be near the cosmological horizon and also moving towards the black hole. For photons emitted from the smallest circular orbit and received at the largest circular orbit, the nonzero cosmological constant enhances observations by a factor that varies from zero to three.

</details>


### [11] [Exact, non-singular black holes from a phantom DBI Field as primordial dark matter](https://arxiv.org/abs/2511.14047)
*Tausif Parvez,S. Shankaranarayanan*

Main category: gr-qc

TL;DR: 提出了广义相对论中第一个由Dirac-Born-Infeld标量场驱动的精确、非奇异黑洞解，该解用正则核心取代中心奇点，形成渐近平坦、具有非平凡标量毛的黑洞。


<details>
  <summary>Details</summary>
Motivation: 解决黑洞中心奇点问题，为轻质量原初黑洞作为暗物质候选者提供理论支持，避开传统蒸发约束。

Method: 使用DBI标量场的幻影分支，通过动力学刚度机制（类似于非牛顿流体中的剪切增稠效应）消除奇点。

Result: 成功构建了非奇异黑洞解，黑洞蒸发后形成稳定的、非奇异的极值普朗克尺度遗迹，为轻质量原初黑洞作为暗物质开辟了新的质量窗口。

Conclusion: 该模型提供了一种稳健的奇点消除机制，可通过其独特的标量毛引力波特征进行检验，为原初黑洞暗物质理论提供了新的可能性。

Abstract: We present the first exact, non-singular black hole solution in General Relativity sourced by a Dirac-Born-Infeld (DBI) scalar field. Crucially, the solution is exclusively supported by the phantom branch of the DBI action, dynamically replacing the central singularity with a regular core. The solution is asymptotically flat, possesses non-trivial scalar hair, and replaces the central singularity with a regular 2-sphere. The mechanism for singularity resolution is a dynamical kinetic stiffness -- analogous to shear thickening in non-Newtonian fluids -- which also explains the evasion of classical no-hair theorems. We show these black holes evaporate to a stable, non-singular, extremal Planck-scale relic. This provides a robust mechanism to evade standard evaporation constraints, opening a vast, previously forbidden mass window for light Primordial Black Holes to constitute dark matter. The model is testable via distinctive gravitational-wave signatures from its scalar hair.

</details>


### [12] [A non-local origin for massive gravity and late-time acceleration](https://arxiv.org/abs/2511.14055)
*Susobhan Mandal,S. Shankaranarayanan*

Main category: gr-qc

TL;DR: 本文提出了一种非局域修正引力理论，通过引入R□⁻²R等非局域项，为引力子提供了动力学质量起源，并证明该模型能自然驱动宇宙加速膨胀，同时保持理论在背景和扰动层面的稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决宇宙加速膨胀对广义相对论提出的挑战，探索非局域引力修正作为暗能量问题的替代方案，避免传统标量-张量模型的局限性。

Method: 构建包含R□⁻²R、R^{μν}□⁻²R_{μν}、R^{μνσδ}□⁻²R_{μνσδ}等非局域项的修正引力作用量，在线性化水平上还原为标准Fierz-Pauli作用，进行背景宇宙学的定点分析和宇宙学扰动研究。

Result: 模型具有稳定的de Sitter吸引子，能自然驱动加速膨胀；六个传播自由度无鬼不稳定性；所有大尺度张量模都动态稳定并在加速背景下衰减；与ΛCDM在晚期一致。

Conclusion: 该非局域质量引力扩展模型在背景和扰动层面都具有鲁棒稳定性，为ΛCDM范式提供了独特且一致的理论替代方案，具有不同的引力波极化预测。

Abstract: The accelerated expansion of the universe poses a significant challenge to General Relativity. Non-local modifications to gravity have emerged as a compelling class of theories to address this dark energy puzzle. Building upon earlier proposals, we investigate a specific non-local modified gravity action incorporating terms like $R\Box^{-2}R$, $R^{μν}\Box^{-2}R_{μν}$, $R^{μνσδ}\Box^{-2}R_{μνσδ}$ and demonstrate that it provides a dynamical origin for a massive graviton by reducing to the standard and extended Fierz-Pauli action at the linearized level. A fixed-point analysis of the background cosmology reveals a stable de Sitter attractor, ensuring the model naturally drives accelerated expansion. Crucially, we investigate the cosmological perturbations and show that the theory's six propagating degrees of freedom are free from ghost instabilities. We further demonstrate that all large-scale tensor modes are dynamically stable and decay on the accelerating background. This ghost-free massive gravity extension provides distinct predictions for gravitational wave polarizations and is theoretically consistent with $\mathbf{ΛCDM}$ at late times, positioning it as a unique alternative to scalar-tensor models like $f(R)$ and Galileons. This robust stability at both the background and perturbative levels establishes our model as a consistent and compelling alternative to the standard $Λ$CDM paradigm.

</details>


### [13] [Periodic orbits and their gravitational wave radiations in $γ$-metric](https://arxiv.org/abs/2511.14080)
*Chao Zhang,Tao Zhu*

Main category: gr-qc

TL;DR: 本文研究了gamma度规对周期轨道及其引力波辐射的影响，发现gamma参数偏离1会改变束缚轨道的半径和角动量，从而影响轨道分类和引力波波形特征。


<details>
  <summary>Details</summary>
Motivation: gamma度规是爱因斯坦场方程的静态轴对称真空解，当gamma=1时退化为史瓦西度规。研究gamma参数对周期轨道和引力波的影响，有助于通过引力波观测来约束时空的轴对称偏离。

Method: 通过拓扑数(z,w,v)对周期轨道进行分类，计算不同gamma参数下的轨道半径和角动量变化，并计算代表性周期轨道产生的引力波波形。

Result: gamma≠1会导致轨道分类发生变化，并在引力波波形中产生相位偏移和振幅调制。较大的缩放数会导致波形中出现更复杂的子结构，gamma偏离1会显著改变这些特征。

Conclusion: 通过精确测量极端质量比旋近系统的引力波波形形态，可以约束gamma度规中编码的球对称性偏离。

Abstract: The gamma-metric, also known as Zipoy-Voorhees spacetime, is a static, axially symmetric vacuum solution to Einstein's field equations characterized by two parameters: mass and the deformation parameter gamma. It reduces to the Schwarzschild metric when gamma = 1. In this paper we explore potential signatures of the gamma-metric on periodic orbits and their gravitational-wave radiation. Periodic orbits are classified by a rotational number specified by three topological numbers (z, w, v), each triple corresponding to characteristic zoom-whirl behavior. We show that deviations from gamma=1 alter the radii and angular momentum of bound orbits and thereby shift the (z, w, v) taxonomy. We also compute representative gravitational waveforms for certain periodic orbits and demonstrate that gamma != 1 can induce phase shifts and amplitude modulations correlated with changes in the zoom-whirl structure. In particular, larger zoom numbers lead to increasingly complex substructures in the waveforms, and finite deviations from gamma=1 can significantly modify these features. Our results indicate that precise measurements of waveform morphology from extreme-mass-ratio inspirals may constrain deviations from spherical symmetry encoded in gamma.

</details>


### [14] [Cosmological dynamics of interacting dark matter-dark energy in generalized Rastall gravity](https://arxiv.org/abs/2511.14089)
*Manuel Gonzalez-Espinoza,Ramón Herrera,Giovanni Otalora,Carlos Ríos,Carlos Rodriguez-Benites*

Main category: gr-qc

TL;DR: 本文研究了广义Rastall引力框架下的晚期相互作用宇宙学，通过构建自主动力系统分析了三种相互作用模型，并利用宇宙学观测数据对参数空间进行了约束。


<details>
  <summary>Details</summary>
Motivation: 研究广义Rastall引力中能量-动量张量非守恒自然产生的暗物质与暗能量相互作用，探索晚期宇宙演化动力学。

Method: 将暗区背景演化构建为自主动力系统，定义相互作用项Q₁=αḟ和Q₂=-ḟ(1+α)，研究f∝ρ_m、f∝ρ_de和f∝ρ_m+ρ_de三种相互作用情形，假设暗能量状态方程w_de为常数。

Result: 相空间展现出标准宇宙学动力学：不稳定辐射点、瞬态物质鞍点和稳定的晚期吸引子（加速膨胀）。通过联合似然分析得到了参数在68%和95%置信水平下的边缘估计。

Conclusion: 在广义Rastall引力框架下，暗区相互作用模型能够重现标准宇宙学演化历史，并通过观测数据有效约束了相互作用参数空间。

Abstract: In this work, we investigate late-time interacting cosmologies within the framework of generalized Rastall gravity, where the interaction arises naturally from the non-conservation of the energy-momentum tensor. We formulate the background evolution of the dark sector as an autonomous dynamical system, defining interaction terms $Q_1=α\,\dot{f}$ and $Q_2=-\dot{f}\,(1+α)$, with $α$ a constant parameter and $f$ a time-dependent function. Three interaction cases are studied: $f \propto ρ_m$, $f \propto ρ_{de}$, and $f \propto ρ_m + ρ_{de}$, assuming a constant dark-energy equation of state $w_{de}$. For each scenario, we derive the closed dynamical system in terms of the density parameters $(Ω_{de}, Ω_m)$, identify its fixed points, and analyze their stability across the parameter space. In this context, the phase-space exhibits a standard cosmological dynamics: an unstable radiation point, a transient matter saddle, and a stable late-time attractor with accelerated expansion. In addition, we utilize a joint likelihood analysis with Cosmic Chronometers, PantheonPlus, and DESI data to obtain marginalized parameter estimates at the $68\%$ and $95\%$ confidence levels, constraining the parameter space in each interaction model.

</details>


### [15] [Exotic compact objects in Einstein-Scalar-Maxwell theories](https://arxiv.org/abs/2511.14207)
*Antonio De Felice,Shinji Tsujikawa*

Main category: gr-qc

TL;DR: 在广义相对论的k-essence理论中，通过引入标量场与U(1)规范场的耦合，可以构建无幽灵的静态球对称致密天体，包括电性和磁性致密星，其致密性在0.01到0.1之间。


<details>
  <summary>Details</summary>
Motivation: 传统k-essence理论中，具有正定能量密度的静态球对称致密天体无法避免幽灵问题，需要寻找新的理论框架来构建物理上合理的致密天体。

Method: 将k-essence拉格朗日量扩展到包含U(1)规范场强度F的依赖，采用标量-矢量耦合μ(φ)F的形式，在爱因斯坦-标量-麦克斯韦理论中构建渐近平坦的带电致密星。

Result: 成功构造了电性和磁性致密天体，其能量密度和压力在中心处为零，计算了质量和半径，致密性在0.01-0.1范围内。电性致密天体在所有半径处都无强耦合、幽灵和拉普拉斯不稳定性，而磁性致密天体在中心附近存在强耦合问题。

Conclusion: 通过引入标量场与规范场的耦合，可以规避k-essence理论中的无致密天体定理，构建物理上合理的致密天体，但磁性解存在中心附近的强耦合问题。

Abstract: In k-essence theories within general relativity, where the matter Lagrangian depends on a real scalar field $φ$ and its kinetic term $X$, static and spherically symmetric compact objects with a positive-definite energy density cannot exist without introducing ghosts. We show that this no-go theorem can be evaded when the k-essence Lagrangian is extended to include a dependence on the field strength $F$ of a $U(1)$ gauge field, taking the general form ${\cal L}(φ, X, F)$. In Einstein-scalar-Maxwell theories with a scalar-vector coupling $μ(φ) F$, we demonstrate the existence of asymptotically flat, charged compact stars whose energy density and pressure vanish at the center. With an appropriate choice of the coupling function $μ(φ)$, we construct both electric and magnetic compact objects and derive their metric functions and scalar- and vector-field profiles analytically. We compute their masses and radii, showing that the compactness lies in the range ${\cal O}(0.01)<{\cal C}<{\cal O}(0.1)$. A linear perturbation analysis reveals that electric compact objects are free of strong coupling, ghost, and Laplacian instabilities at all radii for $μ(φ)>0$, while magnetic compact objects suffer from strong coupling near the center.

</details>


### [16] [Static Stellar Phase Transitions in General Relativity and a Generalized Buchdahl Limit](https://arxiv.org/abs/2511.14287)
*Moritz Reintjes,Ruochen Xia*

Main category: gr-qc

TL;DR: 提出了第一个广义相对论中静态球对称爱因斯坦-欧拉方程（TOV方程）的一般构造方法，允许使用不连续和非均匀的密度函数来描述恒星相变。


<details>
  <summary>Details</summary>
Motivation: 研究具有不连续和非均匀密度函数的恒星模型，以描述广义相对论中的恒星相变现象。

Method: 通过识别密度函数的新条件来构造TOV方程的解，确保压力函数在整个恒星范围内有界，并推广了经典的Buchdahl极限。

Result: 获得了有界压力函数的解，提出了存在此类有界压力函数的新必要条件，在均匀密度情况下简化为经典的Buchdahl极限。

Conclusion: 新条件为研究恒星质量-半径关系提供了更一般的框架，能够处理不连续密度分布的情况。

Abstract: We give the first general construction of solutions of the static spherically symmetric Einstein-Euler equations, the Tolman-Oppenheimer-Volkoff (TOV-)equation, with prescribed density functions allowed to be discontinuous and non-uniform; these solutions describe stellar phase transitions in General Relativity. Boundedness of the resulting pressure functions solving the TOV-equations, from the boundary down to the stellar center, is obtained by identifying a novel condition on the prescribed density, in generalization of the classical Buchdahl limit. Moreover, we introduce a new necessary condition for the existence of such bounded pressure functions, which in the special case of a uniform density state reduces to the classical Buchdahl limit on the stellar mass-radius relationship. We present various examples to study the stellar mass-radius relationships resulting from our new conditions.

</details>


### [17] [Cosmological Dynamics in $f(R,L_m,T)$ Modified Gravity](https://arxiv.org/abs/2511.14309)
*V. A. Kshirsagar,A. S. Agrawal,S. A. Kadam,Vishwajeet S. Goswami*

Main category: gr-qc

TL;DR: 本文在f(R,L_m,T)引力理论框架下研究宇宙加速膨胀阶段，通过相空间分析探讨从减速膨胀到加速膨胀的转变过程。


<details>
  <summary>Details</summary>
Motivation: 研究f(R,L_m,T)修正引力理论中的宇宙加速膨胀机制，其中R是Ricci标量，L_m是物质拉格朗日量，T是能量-动量张量的迹。

Method: 采用特定形式的修正引力f(R,L_m,T)=R-μL_mT-γ，通过相空间分析和动力系统技术研究宇宙学解的演化。

Result: 通过相空间图展示了临界点和稳定吸引子的特征，研究了状态方程和减速参数的行为。

Conclusion: 该模型能够描述宇宙从初始减速膨胀到当前加速膨胀的转变过程。

Abstract: In this paper, we investigate the accelerating phase of the Universe within the context of $f(R,L_m,T)$ gravity theory, where $R$, $L_m$, and $T$ represent the Ricci scalar, matter Lagrangian, and the trace of the energy-momentum tensor, respectively. We focus on a particular form of modified gravity defined by $f(R,L_m,T) = R - μL_m T - γ$, with $μ$ and $γ$ being positive constants. The matter sector is characterized by the Lagrangian density $L_m = -ρ$, where $ρ$ denotes the energy density of the cosmological fluid. We conduct an in-depth examination of the model using phase space analysis, thoroughly evaluating the evolution of cosmological solutions with dynamical system techniques. The results is illustrated through graphs in the phase space, the characteristics of critical points and the stable attractors within the proposed modified gravity $f(R,L_m,T)$ cosmological framework. We investigate the transition from the initial decelerating phase of the universe to its current accelerating phase. The behaviour of the EoS, deceleration parameter with the appropriate initial conditions have been investigated.

</details>


### [18] [Dark matter halos and transonic accretion flow](https://arxiv.org/abs/2511.14425)
*Avijit Chowdhury,Gargi Sen,Sayan Chakrabarti,Santabrata Das*

Main category: gr-qc

TL;DR: 本文研究了冷暗物质晕对超大质量黑洞周围热吸积流的影响，发现暗物质晕特别是质量大且致密的暗物质晕能增强吸积盘光度，为探测星系中心致密暗物质环境提供了观测手段。


<details>
  <summary>Details</summary>
Motivation: 理解超大质量黑洞与周围环境的相互作用对认识星系演化至关重要，本研究旨在探索暗物质晕对黑洞吸积过程的影响。

Method: 将时空几何建模为嵌入不同暗物质分布中的黑洞，包括具有中心密度尖峰的分布，研究相对论性、低角动量、无粘性和平流热吸积流的动力学。

Result: 暗物质晕的存在，特别是质量大且致密的暗物质晕，能增强吸积盘的光度，主要贡献来自吸积流的内部区域。

Conclusion: 光度测量可作为探测星系中心预期存在的致密暗物质环境的有效观测手段。

Abstract: The interplay between supermassive black holes (SMBHs) and their surrounding environment is fundamental to understanding galactic evolution. This work investigates the influence of a cold dark matter (DM) halo on the dynamics of relativistic, low angular momentum, inviscid, and advective hot accretion flow onto a galactic SMBH. Modeling the spacetime geometry as a black hole embedded within various DM distributions, including those with a central density spike, we demonstrate that the presence of a DM halo, particularly one that is massive and compact, enhances the luminosity of the accretion disk. The dominant contribution to this luminosity originates from the inner regions of the flow, suggesting that luminosity measurements could serve as a valuable observational probe for the dense DM environments expected near galactic centers.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [19] [Microscopic theory of quantum physics](https://arxiv.org/abs/2511.13748)
*Dennis M. Heim*

Main category: quant-ph

TL;DR: 量子现象可以从牛顿第二定律支配的粒子相互作用中自然涌现，包括定态、能量量子化、双缝干涉条纹，并能推导出薛定谔方程


<details>
  <summary>Details</summary>
Motivation: 探索量子现象是否可以从经典物理框架中自然涌现，建立量子力学与经典力学的联系

Method: 构建基于牛顿第二定律的微观框架，通过粒子-粒子相互作用来模拟量子行为

Result: 成功重现了无限深势阱中的定态和量子化能谱，再现了双缝实验中的干涉条纹，并推导出了薛定谔方程

Conclusion: 量子现象可以从经典牛顿力学的粒子相互作用中自然产生，为理解量子力学与经典物理的统一提供了新视角

Abstract: I present a microscopic framework in which quantum phenomena emerge from particle-particle interactions governed by Newton's second law of motion. Within this approach, stationary states and quantized energy spectra arise naturally for the particle in a box. The same dynamics reproduces interference fringes in the double-slit experiment. Finally, I derive the Schrödinger equation from the underlying principles.

</details>


### [20] [Hybrid Predictive Quantum Feedback: Extending Qubit Lifetimes Beyond the Wiseman-Milburn Limit](https://arxiv.org/abs/2511.13774)
*Ali Abu-Nada,Aryan Iliat,Russell Ceballo*

Main category: quant-ph

TL;DR: 提出了一种结合辅助量子比特和预测器的混合反馈方法，显著延长量子比特寿命，超越传统Wiseman-Milburn反馈的限制。


<details>
  <summary>Details</summary>
Motivation: 幅度阻尼通过不可逆地泄漏能量和信息到环境中，从根本上限制了量子比特的寿命。传统Wiseman-Milburn反馈仅作用于单个测量正交分量，且其校正驱动因环路延迟而退化，改进有限。

Method: 采用混合方法：(i) 相干耦合的辅助量子比特接收零差电流并量子相干地反馈到系统，从两个场正交分量恢复信息；(ii) 轻量级监督预测器预测近未来零差电流，相位对齐校正以克服硬件延迟。

Result: 使用IBM规模参数（基线T1=50μs），数值模拟显示寿命延长3-4倍，同时提高了布居数保持和积分能量。

Conclusion: 该方法模块化且与硬件兼容，可将泄漏信息转换为精确、时间提前的校正驱动，显著提升量子比特性能。

Abstract: Amplitude damping fundamentally limits qubit lifetimes by irreversibly leaking energy and information into the environment. Standard Wiseman--Milburn feedback offers only modest improvement because it acts on a single measured quadrature and its corrective drive is degraded by loop delay. We introduce a compact hybrid upgrade with two components: (i) a coherently coupled \emph{ancilla} qubit that receives the homodyne current and feeds back \emph{quantum-coherently} on the system, recovering information from \emph{both} field quadratures and intentionally engineered to decay much faster than the system; and (ii) a lightweight supervised predictor that forecasts the near-future homodyne current, phase-aligning the correction to overcome hardware latency. A Lindblad treatment yields closed-form effective decay rates: the ancilla suppresses the emission channel by a cooperativity factor, while the predictor further suppresses the residual decay in proportion to forecast quality. Using IBM-scale parameters (baseline \(T_1 = 50~μ\mathrm{s}\)), numerical simulations surpass the W--M limit, achieving \(\sim 3\!-\!4\times\) longer \(T_1\) together with improved population retention and integrated energy. The method is modular and hardware-compatible: ancilla coupling and supervised prediction can be added to existing W--M loops to convert leaked information into a precise, time-advanced corrective drive. We also include a detailed, student-friendly derivation of the effective rates for both ancilla-assisted and prediction-enhanced feedback, making the impact of each design element analytically transparent.

</details>


### [21] [Skeleton of isometric Tensor Network States for Abelian String-Net Models](https://arxiv.org/abs/2511.13821)
*Julian Boesl,Yu-Jie Liu,Frank Pollmann,Michael Knap*

Main category: quant-ph

TL;DR: 构建参数化的等距张量网络状态（骨架），用于探索阿贝尔拓扑序的相变，并可在量子处理器上高效实现。这些状态连接不同的拓扑相，提供超越任意子凝聚的相变解析例子。


<details>
  <summary>Details</summary>
Motivation: 为阿贝尔拓扑序提供一个组织原则，并创建可在量子处理器上高效实现的非平凡测试平台，同时探索超越任意子凝聚的相变机制。

Method: 通过保持张量的虚拟对称性和施加局部等距约束，构建具有有限关联长度变形的弦网固定点，并将2D张量网络映射到具有局部更新规则的1D随机自动机。

Result: 获得了连接不同拓扑相的稳定变形状态，可通过共享临界点实现相变，且任意权重的广义泡利弦期望值可用经典方法高效计算。

Conclusion: 这些骨架状态不仅为阿贝尔拓扑序提供了组织框架，还为量子处理器提供了重要的测试平台，同时展示了超越传统任意子凝聚的相变机制。

Abstract: We construct parametrized isometric tensor network states -- referred to as skeletons -- that allow us to explore phases of abelian topological order and can be efficiently implemented on quantum processors. We obtain stable finite correlation length deformations of string-net fixed points, which are constructed both by conserving virtual symmetries of the tensor and by imposing local isometry constraints. They connect distinct topological phases via a shared critical point, thereby providing analytically tractable examples of phase transitions beyond anyon condensation. By mapping such classes of 2D tensor networks to 1D stochastic automata with local update rules, we show that expectation values of generalized Pauli strings of arbitrary weight can be efficiently computed using classical methods. Therefore these skeletons not only serve as an organizing principle for abelian topological order but also provide a non-trivial testbed for quantum processors.

</details>


### [22] [Many-Body Time Evolution from a Correlation-Efficient Quantum Algorithm](https://arxiv.org/abs/2511.13871)
*Michael Rose,David A. Mazziotti*

Main category: quant-ph

TL;DR: 提出CETE算法用于模拟量子多体动力学，通过将时间演化步骤重新表述为时间无关的相关性问题，显著减少量子电路深度，扩展近量子设备的可访问模拟时间。


<details>
  <summary>Details</summary>
Motivation: 传统的时间演化方法需要反复相关和解相关状态，电路深度较大，限制了近量子设备的模拟能力。CETE算法旨在通过一次性相关来减少电路深度。

Method: CETE算法将每个时间演化步骤重新表述为时间无关的相关问题：从平均场单Slater行列式开始，然后通过相关捕获真实时间演化状态。该方法基于时间相关薛定谔方程在双电子空间上的收缩推导得出。

Result: 通过模拟氢分子电子波函数的时间演化，证明了CETE算法在近量子设备上模拟强关联系统的潜力。

Conclusion: CETE算法通过减少电路深度，显著扩展了近量子设备可访问的模拟时间，为强关联系统的模拟提供了有前景的方法。

Abstract: We introduce the correlation-efficient time-evolution (CETE) algorithm for simulating quantum many-body dynamics. CETE recasts each step of time evolution as a time-independent correlation problem: the ansatz begins from a mean-field single Slater determinant and is then correlated to capture the true time-evolved state. We derive this exact ansatz from a contraction of the time-dependent Schrödinger equation onto the space of two electrons. Unlike conventional evolution by sequential short-time propagators, which must both correlate and decorrelate the state as the degree of correlation fluctuates in time, CETE correlates only once. This substantially reduces circuit depth, extending accessible simulation times on near-term quantum devices. We demonstrate the approach by simulating the time evolution of the hydrogen molecule's electronic wavefunction, highlighting the potential for the CETE algorithm to simulate strongly correlated systems on near-term devices.

</details>


### [23] [Detection of many-body entanglement partitions in a quantum computer](https://arxiv.org/abs/2511.13822)
*Albert Rico,Dmitry Grinko,Robin Krebs,Lin Htoo Zaw*

Main category: quant-ph

TL;DR: 提出一种利用量子系统固有对称性检测多体量子系统纠缠分区的方法，能够检测真正多体纠缠、m-可分性和纠缠深度等结构。


<details>
  <summary>Details</summary>
Motivation: 现有的多体量子系统纠缠检测方法往往局限于特定类型的纠缠结构，缺乏一个统一框架来系统性地检测所有可能的纠缠分区。

Method: 利用弱Schur采样和投影测量，结合酉对称性和置换对称性来检测纠缠分区。该方法可在量子计算机上实现。

Result: 完整刻画了所有三体和四体系统的纠缠分区，发现并参数化了其中的束缚纠缠态集合。对于更大系统，提供了一族解析见证子来检测任意规模的多体态。

Conclusion: 该方法为多体量子系统纠缠检测提供了统一框架，同时为数学领域建立了新的矩阵不变式不等式，并完整刻画了三阶和四阶矩阵的不等式集合。

Abstract: We present a method to detect entanglement partitions of multipartite quantum systems, by exploiting their inherent symmetries. Structures like genuinely multipartite entanglement, $m$-separability and entanglement depth are detected as very special cases. This formulation enables us to characterize all the entanglement partitions of all three- and four- partite states and witnesses with unitary and permutation symmetry. In particular, we find and parametrize a complete set of bound entangled states therein. For larger systems, we provide a large family of analytical witnesses detecting many-body states of arbitrary size where none of the parties is separable from the rest. This method relies on weak Schur sampling with projective measurements, and thus can be implemented in a quantum computer. Beyond physics, our results extend to the mathematical literature: we establish new inequalities between matrix immanants, and characterize the set of such inequalities for matrices of size three and four.

</details>


### [24] [Optimizing two-dimensional isometric tensor networks with quantum computers](https://arxiv.org/abs/2511.13827)
*Sebastian Leontica,Alberto Baiardi,Julian Schuhmacher,Francesco Tacchino,Ivano Tavernelli*

Main category: quant-ph

TL;DR: 提出了一种混合量子-经典算法，使用等距张量网络近似二维量子系统的基态，该方法可自然映射到量子电路，显著降低了量子开销。


<details>
  <summary>Details</summary>
Motivation: 克服经典方法在处理二维量子系统时面临的指数复杂度问题，利用量子计算机实现精确解而无需依赖近似收缩。

Method: 基于密度矩阵重整化群思想，通过对角化一系列有效哈密顿量来顺序优化张量，使用基于断层扫描的方法在量子比特子集上构建这些哈密顿量。

Result: 在二维横向场伊辛模型上验证了方法，在多达25个量子比特上实现了基态优化，量子开销显著低于基于变分量子本征求解器的标准解决方案。

Conclusion: 为在含噪和容错机制下实现可扩展的变分量子算法提供了一条可行路径。

Abstract: We propose a hybrid quantum-classical algorithm for approximating the ground state of two-dimensional quantum systems using an isometric tensor network ansatz, which maps naturally to quantum circuits. Inspired by the density matrix renormalization group, we optimize tensors sequentially by diagonalizing a series of effective Hamiltonians. These are constructed using a tomography-inspired method on a qubit subset whose size depends only on the bond dimension. Our approach leverages quantum computers to enable accurate solutions without relying on approximate contractions, circumventing the exponential complexity faced by classical techniques. We demonstrate our method on the two-dimensional (2D) transverse-field Ising model, achieving ground-state optimization on up to 25 qubits with modest quantum overhead -- significantly less than standard solutions based on variational quantum eigensolvers. Overall, our results offer a path towards scalable variational quantum algorithms in both noisy and fault-tolerant regimes.

</details>


### [25] [Realizing Unitary $k$-designs with a Single Quench](https://arxiv.org/abs/2511.13829)
*Yi-Neng Zhou,Robin Löwenberg,Julian Sonner*

Main category: quant-ph

TL;DR: 提出单淬火协议生成酉k-design，仅需一次控制操作，比连续随机化方案更简单。该协议通过切换哈密顿量打破残余谱关联，实现高阶设计。


<details>
  <summary>Details</summary>
Motivation: 传统时间无关混沌动力学因残余谱关联无法形成高阶设计，需要更简单的控制方案来生成酉k-design。

Method: 系统先在随机哈密顿量H1下演化至Thouless时间ts，然后淬火到独立抽取的H2继续演化，仅需一次控制操作。

Result: 该协议能接近酉k-design，提供操作性的Thouless时间定义和混沌性定量诊断，支持对称性分辨和开放系统扩展。

Conclusion: 单淬火协议为生成Haar类随机性提供了直接路径，在随机测量、基准测试和层析成像中有直接应用。

Abstract: We present a single-quench protocol that generates unitary $k$-designs with minimal control. A system first evolves under a random Hamiltonian $H_1$; at a switch time $t_s \geq t_{\mathrm{Th}}$ (the Thouless time), it is quenched to an independently drawn $H_2$ from the same ensemble and then evolves under $H_2$. This single quench breaks residual spectral correlations that prevent strictly time-independent chaotic dynamics from forming higher-order designs. The resulting ensemble approaches a unitary $k$-design using only a single control operation -- far simpler than Brownian schemes with continuously randomized couplings or protocols that apply random quenches at short time intervals. Beyond offering a direct route to Haar-like randomness, the protocol yields an operational, measurement-friendly definition of $t_{\mathrm{Th}}$ and provides a quantitative diagnostic of chaoticity. It further enables symmetry-resolved and open-system extensions, circuit-level single-quench analogs, and immediate applications to randomized measurements, benchmarking, and tomography.

</details>


### [26] [Trading athermality for nonstabiliserness](https://arxiv.org/abs/2511.13839)
*A. de Oliveira Junior,Rafael A. Macedo,Jakub Czartowski,Jonatan Bohr Brask,Rafael Chaves*

Main category: quant-ph

TL;DR: 本文研究了从稳定子态通过热浴耦合生成非稳定性的热力学极限，推导了该过程产生非稳定性的充要条件，并给出了非稳定性程度的定量界限。


<details>
  <summary>Details</summary>
Motivation: 非稳定性是实现量子优势的基本资源，本文旨在探索是否可以通过将稳定子态耦合到热浴来生成非稳定性。

Method: 在最小假设下探索非稳定性的热力学极限，推导生成非稳定性的充要条件，并提供分析性特征描述。

Result: 确定了可通过这种方式达到的非稳定子态，给出了非稳定性程度的定量界限，并识别了最大化非稳定性生成的最佳机制和临界温度。

Conclusion: 该框架提供了从稳定子态生成非稳定性的完整理论描述，包括可达状态的特征和最优生成条件。

Abstract: Nonstabiliserness is a fundamental resource for quantum advantage, capturing how much a quantum state breaks the symmetries that would make it classically simulable. Can nonstabiliserness be generated from stabiliser states simply by coupling them to a heat bath? We explore the thermodynamic limits of nonstabiliserness under minimal assumptions and derive a necessary and sufficient condition for when such a process can create it from an initial stabiliser state. This provides an analytic characterisation of the nonstabiliser states that are reachable in this way, together with quantitative bounds on their degree of nonstabiliserness. Our framework also identifies optimal regimes, specifying Hamiltonians that maximise nonstabiliserness generation and the critical temperatures at which it emerges.

</details>


### [27] [Fermionic Born Machines: Classical training of quantum generative models based on Fermion Sampling](https://arxiv.org/abs/2511.13844)
*Bence Bakó,Zoltán Kolarovszki,Zoltán Zimborás*

Main category: quant-ph

TL;DR: 该论文提出了费米子玻恩机，这是一种可经典训练的量子生成模型，使用参数化魔法态和费米子线性光学变换，通过高斯算子分解实现高效经典训练，同时保持量子采样的计算优势。


<details>
  <summary>Details</summary>
Motivation: 量子生成学习面临梯度估计困难等训练挑战，但对于某些结构化的量子生成模型，可以在经典计算机上高效计算局部可观测量期望值，从而实现无需量子梯度评估的经典训练。

Method: 使用参数化魔法态和可学习参数的费米子线性光学变换，通过将魔法态分解为高斯算子来高效估计期望值，并利用费米子到量子比特映射在量子设备上实现采样。

Result: 在高达160量子比特系统上的数值实验证明了该模型和训练框架的有效性，损失景观展现出有利于优化的特性。

Conclusion: 费米子玻恩机提供了一种可经典训练的量子生成模型，在保持量子采样计算优势的同时解决了训练挑战，为量子生成学习提供了实用方案。

Abstract: Quantum generative learning is a promising application of quantum computers, but faces several trainability challenges, including the difficulty in experimental gradient estimations. For certain structured quantum generative models, however, expectation values of local observables can be efficiently computed on a classical computer, enabling fully classical training without quantum gradient evaluations. Although training is classically efficient, sampling from these circuits is still believed to be classically hard, so inference must be carried out on a quantum device, potentially yielding a computational advantage. In this work, we introduce Fermionic Born Machines as an example of such classically trainable quantum generative models. The model employs parameterized magic states and fermionic linear optical (FLO) transformations with learnable parameters. The training exploits a decomposition of the magic states into Gaussian operators, which permits efficient estimation of expectation values. Furthermore, the specific structure of the ansatz induces a loss landscape that exhibits favorable characteristics for optimization. The FLO circuits can be implemented, via fermion-to-qubit mappings, on qubit architectures to sample from the learned distribution during inference. Numerical experiments on systems up to 160 qubits demonstrate the effectiveness of our model and training framework.

</details>


### [28] [Halving the Cost of Controlled Time-Evolution](https://arxiv.org/abs/2511.13855)
*William A. Simon,Peter J. Love*

Main category: quant-ph

TL;DR: 提出一种编译方案，将受控Trotter化时间演化的任意旋转门数量减半，降低容错量子模拟的成本


<details>
  <summary>Details</summary>
Motivation: 量子模拟算法需要控制时间演化幺正操作，传统方法会使所需计算资源显著增加，特别是单量子比特任意旋转门的数量翻倍，这在容错架构中会显著增加T成本

Method: 针对对称Trotter化（二阶及更高阶Suzuki-Trotter分解），设计了一种编译方案，不增加任意旋转门的数量

Result: 将受控Trotter演化的任意旋转门数量减少到与非受控Trotter演化相同，相比标准方法减少了一半

Conclusion: 该构造显著降低了容错量子模拟的成本，因为任意旋转门在容错实现中主导T成本

Abstract: Quantum simulation is a promising application for quantum computing. Quantum simulation algorithms may require the ability to control the time evolution unitary. Naive techniques to control a unitary can substantially increase the required computational resources. A standard approach to controlling Trotterized time evolution doubles the number of single-qubit arbitrary rotations. Here, we describe a compilation scheme that does not increase the number of arbitrary rotations for symmetric Trotterizations, which applies to second-order and higher Suzuki-Trotter decompositions. This halves the number of arbitrary rotations required to implement controlled, Trotterized time evolution compared to the standard approach. Arbitrary rotations contribute significantly to resource estimates in a fault-tolerant architecture due to the number of required magic states. Therefore, arbitrary rotations dominate the $T$-cost of fault-tolerant implementations of quantum simulation. This construction reduces the number of arbitrary rotations for controlled Trotter evolution to that of uncontrolled Trotter evolution, thereby reducing the cost of fault-tolerant quantum simulation.

</details>


### [29] [Linguistic Predictability and Search Complexity: How Linguistic Redundancy Constraints the Landscape of Classical and Quantum Search](https://arxiv.org/abs/2511.13867)
*Alessio Di Santo,Gabriella Lanziani*

Main category: quant-ph

TL;DR: 通过混合经典-量子框架分析文艺复兴意大利文本的语言规律与计算搜索复杂度的定量关系，发现语言冗余与搜索空间收缩之间的联系。


<details>
  <summary>Details</summary>
Motivation: 研究语言规律与计算搜索复杂度之间的定量关系，为经典、量子启发和理想量子搜索动态在统一语料驱动约束下的比较提供实证框架。

Method: 使用四部文艺复兴意大利文本构建字符n-gram模型，结合经典爬山算法、模拟退火与Grover风格量子启发估计，评估替换密码搜索过程。

Result: 实证结果确认了Grover预言调用与1/sqrt(pgood)的依赖关系，较长文本产生更尖锐的分数分布和更小的可行密钥区域。

Conclusion: 研究建立了语言冗余与搜索空间收缩之间的联系，为在统一语料驱动约束下比较经典、量子启发和理想量子搜索动态提供了实证框架。

Abstract: This study examines the quantitative relationship between linguistic regularities and computational search complexity through a hybrid classical-quantum framework applied to Renaissance Italian texts. Using four representative works from the fifteenth and sixteenth centuries-Il Principe (Machiavelli), Il Cortegiano (Castiglione), I Ricordi (Guicciardini), and Orlando Furioso (Ariosto)-we construct character-based n-gram models under both a historically grounded 25-letter orthography and the full modern Italian alphabet. These models provide corpus-derived probabilistic baselines for evaluating substitution-cipher search processes. Combining classical hill climbing and simulated annealing with Grover-style quantum-inspired estimates and a QUBO annealing formulation, we quantify how the probability that a key produces a linguistically plausible decryption (pgood) relates to expected computational effort. Across cipher lengths from 200 to 1000 characters, empirical results confirm the predicted dependence of Grover oracle calls on 1/sqrt(pgood) and show that longer texts yield sharper score distributions and smaller feasible key regions. Overall, the findings establish a link between linguistic redundancy and search-space contraction, providing an empirical framework for comparing classical, quantum-inspired, and idealized quantum search dynamics under unified corpus-driven constraints.

</details>


### [30] [Hybrid continuous-discrete-variable quantum computing: a guide to utility](https://arxiv.org/abs/2511.13882)
*A. F. Kemper,Antonios Alvertis,Muhammad Asaduzzaman,Bojko N. Bakalov,Dror Baron,Joel Bierman,Blake Burgstahler,Srikar Chundury,Elin Ranjan Das,Jim Furches,Fucheng Guo,Raghav G. Jha,Katherine Klymko,Arvin Kushwaha,Ang Li,Aishwarya Majumdar,Carlos Ortiz Marrero,Shubdeep Mohapatra,Christopher Mori,Frank Mueller,Doru Thom Popovici,Tim Stavenger,Mastawal Tirfe,Norm M. Tubman,Muqing Zheng,Huiyang Zhou,Yuan Liu*

Main category: quant-ph

TL;DR: 本文探讨了混合连续-离散变量量子计算的新范式，分析了其优势并概述了在物理、化学和计算机科学领域的潜在应用。


<details>
  <summary>Details</summary>
Motivation: 传统量子计算主要基于离散变量范式，但连续变量模式的引入和混合连续-离散方法为量子计算开辟了新方向，具有独特优势。

Method: 通过分析混合连续-离散变量量子计算的理论框架，讨论其在不同领域的应用潜力，并概述相关的算法和软件考虑因素。

Result: 识别了混合连续-离散变量量子计算在物理、化学和计算机科学等多个领域的应用可能性，并指出了该新范式的技术优势。

Conclusion: 混合连续-离散变量量子计算是一个有前景的新研究方向，具有广泛的应用潜力，需要进一步发展相关的算法和软件工具。

Abstract: Quantum computing has traditionally centered around the discrete variable paradigm. A new direction is the inclusion of continuous variable modes and the consideration of a hybrid continuous-discrete approach to quantum computing. In this paper, we discuss some of the advantages of this modality, and lay out a number of potential applications that can make use of it; these include applications from physics, chemistry, and computer science. We also briefly overview some of the algorithmic and software considerations for this new paradigm.

</details>


### [31] [Tunable quantum photonic routing using a coupled giant-atom-like array](https://arxiv.org/abs/2511.13992)
*Alexis R. Legón,Mario Miranda,P. A. Orellana*

Main category: quant-ph

TL;DR: 该研究提出了一种基于巨原子阵列的量子路由机制，通过一维波导耦合实现高效、可定向控制的单光子路由，在强原子-波导耦合和弱原子间相互作用条件下达到100%传输效率。


<details>
  <summary>Details</summary>
Motivation: 开发可重构和集成量子光子网络中的高效、可控单光子路由机制，利用巨原子阵列的量子干涉效应实现动态路由控制。

Method: 使用一维三能级系统阵列形成巨原子结构，耦合到两个一维波导，通过调节耦合点数量N、光子能量E和原子间耦合强度J来控制路由行为。

Result: 系统能够实现100%效率的完美光子传输，在宽能量范围内工作，并可通过内部参数动态控制输出通道，展现出鲁棒性和可扩展性。

Conclusion: 该巨原子阵列路由机制为可重构量子光子网络提供了有前景的实现方案，具有高效、可控和可扩展的特点。

Abstract: We examine a quantum routing mechanism utilizing a giant-atom-like array coupled to two one-dimensional waveguides. The giant-atom-like array is formed by a one-dimensional array of three-level-systems. In the regime of strong atom-waveguide coupling and weak inter-atomic interactions, this system functions as an efficient and directionally controllable single-photon router. Our analysis shows that the routing behavior is influenced by effective phase accumulation and interference effects, which can be adjusted by varying the number of coupling sites $N$, the photon energy $E$, and the inter-atomic coupling strength $J$. Importantly, we identify configurations that enable perfect photon transfer ($100 \%$ efficiency) over a wide range of energies and that provide dynamic control over the output channel. In addition, we investigate how the system responds to changes in its internal parameters, demonstrating the robustness and scalability of routing performance. These findings underscore the potential of this setup for implementation in reconfigurable and integrated quantum photonic networks.

</details>


### [32] [Postselected Entangled States by Photon Detection](https://arxiv.org/abs/2511.14000)
*Pedro Rosario,A. Cidrim,R. Bachelard*

Main category: quant-ph

TL;DR: 该论文展示了通过光子检测在高激发态二能级发射器系综中产生后选择纠缠的方法，利用连续光子检测作为纯化过程来恢复自旋压缩。


<details>
  <summary>Details</summary>
Motivation: 后选择是一种非确定性机制，通常用于弱激发系统来纠缠子系统。本研究旨在探索在高激发态系综中通过光子检测产生纠缠的可能性。

Method: 通过光子检测在高激发态二能级发射器系综中形成集体自旋，其特征由远场测量检测的自旋压缩参数表征。使用连续光子检测作为纯化过程来对抗退相干效应。

Result: 研究发现虽然退相干对条件纠缠有害，但连续光子检测能够作为纯化过程，恢复自旋压缩。

Conclusion: 这项工作为在开放量子系统中生成后选择纠缠开辟了新途径。

Abstract: Postselection is a non-deterministic mechanism to entangle subsystems, often used in weakly-excited systems. We here show how highly-excited ensembles of two-level emitters can be entangled by photon detection. A collective spin is formed, characterized by a squeezing parameter detected by far-field measurements. While decoherence is detrimental to this conditional entanglement, successive photon detections act as a purification process and restores the spin squeezing. Our work opens up new avenues for the generation of postselected entanglement in open quantum systems.

</details>


### [33] [Enhancing Non-classical Properties of Entangled Coherent States via Post-Selected von Neumann Measurements](https://arxiv.org/abs/2511.14079)
*Janarbek Yuanbek,Bruno Tenorio*

Main category: quant-ph

TL;DR: 本文系统研究了后选择弱测量对纠缠相干态非经典性质的调制机制，通过调节测量耦合强度实现量子资源（如纠缠和压缩）的可控增强，同时最小化对量子态的扰动。


<details>
  <summary>Details</summary>
Motivation: 主要目标是实现量子资源（如纠缠和压缩）的可控增强，同时最小化对量子态的扰动，为量子计量学和基于测量的态工程提供理论路径。

Method: 采用冯·诺依曼测量模型理论分析后选择弱测量过程，使用联合Wigner函数分析相空间结构，通过Hillery-Zubairy准则量化纠缠，量子Fisher信息评估相位估计精度。

Result: 通过调节测量耦合强度可显著增强压缩效应；随着耦合强度增加，态结构从对称双峰演化为多分支量子干涉条纹；纠缠和相位估计精度均随耦合增强而系统提升。

Conclusion: 建立了一个可调谐的弱测量框架，用于精确操控连续变量纠缠态，为增强量子计量学和测量基态工程提供了可行的理论途径。

Abstract: The present study systematically investigates the modulation mechanism of post-selected weak measurement (WM) on the non-classical properties of entangled coherent states (ECSs). The primary goal is achieving controllable enhancement of quantum resources such as entanglement and squeezing, while minimising disturbance to the quantum state. We theoretically analyze the post-selected weak measurement process, and its effectiveness in amplifying the non-classical features of ECSs. The von Neumann measurement model is employed to analytically describe the weak-value amplification of the pointer state. It is demonstrated that a significant enhancement of squeezing can be achieved by tuning the measurement coupling strength. The joint Wigner function analysis in phase space further reveals that, as the coupling strength increases, the coherent structure of the state evolves from symmetric double peaks to multi-branch quantum interference fringes. The entanglement, quantified by the Hillery-Zubairy criterion, exhibits a pronounced increase with stronger coupling, while the quantum Fisher information indicates a systematic improvement in phase estimation precision. The results obtained establish a tunable weak measurement framework for precise manipulation of continuous-variable entangled states. This provides a feasible theoretical pathway for enhancing quantum metrology and measurement-based state engineering.

</details>


### [34] [Canonical quantization for Equilibrium Thermodynamics](https://arxiv.org/abs/2511.14121)
*Luis F. Santos,Victor Hugo M. Ramos,Danilo Cius,Mario C. Baldiotti,Bárbara Amaral*

Main category: quant-ph

TL;DR: 本文通过狄拉克约束系统理论对平衡热力学进行正则量子化，将热力学变量视为坐标和动量的共轭对，在希尔伯特空间中实现广延量和强度量的算符化。该方法应用于理想气体、范德瓦尔斯气体和光子气体，展示了第一类和第二类量子化程序。


<details>
  <summary>Details</summary>
Motivation: 将量子力学形式体系应用于热力学系统，建立热力学变量的算符表示，探索热力学与量子理论之间的深刻联系，为理解热力学不确定性关系和相变提供新视角。

Method: 应用狄拉克约束系统理论，将热力学变量处理为坐标和动量的共轭对，在希尔伯特空间中实现广延量和强度量的算符化，采用伪厄米框架恢复温度算符的厄米性。

Result: 在理想气体中得到了类似薛定谔方程的形式，其中熵扮演时间角色，波函数相位由内能决定；建立了热力学不确定性关系；证明了不同约束实现的等价性。

Conclusion: 该方法为热力学提供了量子化框架，可扩展到量子相变、拓扑相变、黑洞热力学和非平衡热力学等领域，揭示了热力学与量子理论之间的深刻联系。

Abstract: We formulate a canonical quantization of Equilibrium Thermodynamics by applying Dirac's theory of constrained systems. Thermodynamic variables are treated as conjugate pairs of coordinates and momenta, allowing extensive and intensive quantities to be promoted to operators in a Hilbert space. The formalism is applied to the ideal gas, the van der Waals gas, and the photon gas, illustrating both first- and second-class quantization procedures. For the ideal gas, a Schrödinger-like equation emerges in which entropy plays the role of time, and the wave function acquires a phase determined by the internal energy. A pseudo-Hermitian framework restores Hermiticity of the temperature operator and establishes the equivalence among constraint realizations. The approach naturally leads to thermodynamic uncertainty relations and suggests extensions to quantum and topological phase transitions, as well as black-hole and non-equilibrium thermodynamics.

</details>


### [35] [Spectrotemporal processing in a dual gradient echo and electromagnetically-induced transparency memory](https://arxiv.org/abs/2511.14156)
*Jesse L Everett*

Main category: quant-ph

TL;DR: 本文模拟了基于双量子存储器的分数傅里叶变换，展示了电磁感应透明系统在光谱时间信息处理方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 光谱时间编码在量子信息技术中日益重要，需要开发能够处理光谱时间信息的量子存储器系统。

Method: 使用基于梯度回波存储器和电磁感应透明操作的双量子存储器系统，模拟分数傅里叶变换过程。

Result: 成功模拟了分数傅里叶变换，验证了电磁感应透明系统处理光谱时间信息的能力。

Conclusion: 电磁感应透明系统在光谱时间量子信息处理方面具有重要应用前景。

Abstract: Spectrotemporal encoding of optical quantum information is emerging as a powerful tool in quantum information technology. Processing of spectrotemporal information has recently been demonstrated in multi-mode quantum memories, based on extensions to memory protocols. We simulate one such process, the fractional Fourier transform, in a system based on a dual quantum memory composed of successive gradient echo memory and electromagnetically-induced transparency operations. We demonstrate the potential of electromagnetically-induced transparency systems for spectrotemporal processing.

</details>


### [36] [Entropic uncertainty under indefinite causal order and input-output direction](https://arxiv.org/abs/2511.14192)
*Göktuğ Karpat*

Main category: quant-ph

TL;DR: 本文研究了在量子存储器经历噪声动力学时，通过量子开关和量子时间翻转等高阶控制过程来降低总熵不确定性的方法。


<details>
  <summary>Details</summary>
Motivation: 探索在量子存储器受到噪声影响的情况下，如何利用不确定因果顺序和输入输出方向作为资源来减轻MA-EUR中的噪声效应。

Method: 使用量子开关和量子时间翻转等高阶控制过程来处理Pauli通道，将控制量子比特作为测量系统，目标量子比特作为噪声量子存储器。

Result: 与直接应用相比，通过量子开关和量子时间翻转可以显著降低总熵不确定性。

Conclusion: 不确定因果顺序和输入输出方向可以作为资源来减轻MA-EUR及其应用中的噪声影响。

Abstract: Entropic uncertainty relations quantify the limits on the predictability of quantum measurements. When the measured system is correlated with a quantum memory, these limits are described by the memory-assisted entropic uncertainty relation (MA-EUR). We examine the behavior of MA-EUR when the memory qubit undergoes noisy dynamics implemented via high-order controlled processes, namely, the quantum switch and the quantum time-flip. We consider a setting in which the control qubit is the very system on which the measurements are performed, while the target qubit serves as a noisy quantum memory. Focusing on Pauli channels, we show that feeding them into the quantum switch and the quantum time-flip can significantly reduce the total entropic uncertainty as compared to their direct application. Our results reveal that indefinite causal order and input-output direction can serve as resources to mitigate the effects of noise in the context of MA-EUR and its applications.

</details>


### [37] [Semi-device-independent channel identification with communication matrices](https://arxiv.org/abs/2511.14273)
*Samgeeth Puliyil,Leevi Leppäjärvi,Mário Ziman*

Main category: quant-ph

TL;DR: 本文研究了在实验设置信息有限的情况下区分和重构量子通道的任务，使用通信矩阵形式化方法，证明了信息完备性对于区分量子通道的必要性和充分性，并提出了半设备无关的量子通道识别方法。


<details>
  <summary>Details</summary>
Motivation: 研究在实验设置信息有限的情况下如何区分和重构量子通道，探索在缺乏完整实验描述时仍能有效识别量子通道的方法。

Method: 采用通信矩阵形式化方法，将准备-测量场景的测量统计表示为随机通信矩阵，通过分析通信矩阵的秩和信息存储能力来推断实验设置的信息完备性。

Result: 证明了信息完备性对于区分任意两个量子通道是必要且充分的，而要唯一表征量子通道还需要实验设置的完整描述；发现可以通过通信矩阵的秩推断信息完备性，通过信息存储能力自测试实验设置。

Conclusion: 提供了一种半设备无关的方法来从准备-测量统计中识别量子通道，并在拥有额外信息或资源时可以放宽某些假设条件。

Abstract: We look into the task of differentiating between any two quantum channels and reconstructing them from the obtained measurement statistics with possibly limited information about the experimental set-up. We employ the communication matrix formalism where the measurement statistics of a prepare-and-measure scenario is represented as a stochastic communication matrix. In order to differentiate between any two quantum channels, the informational completeness of the set-up is both necessary and sufficient. On the other hand, if we want to uniquely characterize any quantum channel, in addition we also need to have a complete description of the set-up. We show that in many important cases we can deduce this information directly from the communication matrix of the set-up before applying the channel. Given that we trust the dimension of the system, we show that we can deduce the information completeness of the set-up directly from the rank of the communication matrix. Furthermore, we show that another quantity of the communication matrix, called the information storability, can be used to self-test the set-up (up to unitary or antiunitary freedom) for an important class of states and measurements. This provides us a semi-device-independent way to identify quantum channels from the prepare-and-measure statistics. Lastly, we consider scenarios where we might have some additional information about the channels or additional resources at our disposal which could help us relax some of the assumptions of the proposed scenario.

</details>


### [38] [Generating spatially separated correlated multiphoton states in nonlinear waveguide quantum electrodynamics](https://arxiv.org/abs/2511.14281)
*Jia-Qi Li,Anton Frisk Kockum,Xin Wang*

Main category: quant-ph

TL;DR: 提出了一种通过级联非弹性散射在非线性波导中生成相关多光子纠缠态的可扩展架构，利用伪巨型原子概念实现无反向散射的单向可控光子转换。


<details>
  <summary>Details</summary>
Motivation: 强关联多光子态是先进量子技术的关键资源，但由于大多数光学系统的固有弱非线性，其确定性生成仍然具有挑战性。

Method: 通过级联非弹性散射过程：单光子与远失谐激发二能级发射器散射相干转换为传播的双光子对（doublon），该双光子对可进一步与下游激发发射器散射转换为三光子（triplon），形成光子数放大级联。引入伪巨型原子概念捕获束缚态波函数产生的非局域散射势。

Result: 使用具有多个工程耦合点的真实巨型原子实现无反向散射的单向全可控光子转换，输出态形成空间和时间隔离的光子数分量的可编程叠加，通过不同的群速度自动分类。

Conclusion: 这项工作开启了量子态工程的新范式，能够按需生成复杂多光子资源，用于量子模拟、计量学和可扩展量子网络。

Abstract: Strongly correlated multi-photon states are indispensable resources for advanced quantum technologies, yet their deterministic generation remains challenging due to the inherent weak nonlinearity in most optical systems. Here, we propose a scalable architecture for producing correlated few-photon entangled states via cascaded inelastic scattering in a nonlinear waveguide. When a single photon scatters off a far detuned excited two-level emitter, it coherently converts into a propagating doublon, a bound photon pair with anomalous dispersion. This doublon can subsequently scatter off a downstream excited emitter to further convert into a triplon, and so on, thereby establishing a photon-number amplification cascade $|\cdot \rangle \!\! \rightarrow \!\! |\!\!: \rangle \!\! \rightarrow \! \! |\!\!\therefore \rangle \!\! \to \!\! ...$ Central to this process is the concept of a pseudo-giant atom, which we introduce here to capture the non-local scattering potential emergent from the wave functions of bound states. By implementing this scheme using a real giant atom with multiple engineered coupling points, we achieve unidirectional and full controllable photon conversion without backscattering. The resulting output state forms a programmable superposition of spatially and temporally isolated photon-number components, automatically sorted by their distinct group velocities. This work opens a new paradigm in quantum state engineering, enabling on-demand generation of complex multi-photon resources for quantum simulation, metrology, and scalable quantum networks.

</details>


### [39] [Parallelizing Program Execution on Distributed Quantum Systems via Compiler/Hardware Co-Design](https://arxiv.org/abs/2511.14306)
*Folkert de Ronde,Alexander Knapen,Stephan Wong,Sebastian Feld*

Main category: quant-ph

TL;DR: 提出了一种增强分布式量子系统上量子算法执行的新方法，包括支持并行指令执行的硬件设计和智能重排指令的编译器，实现了最高16.5倍的平均加速比。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算机支持更复杂计算，需要智能控制硬件和编译器来高效利用系统能力。

Method: 开发支持并行指令执行的硬件设计，以及利用硬件约束智能重排和分解指令的编译器。

Result: 实现了最高16.5倍平均加速比和56.2倍单基准测试加速比，所有基准测试均获得加速效果。

Conclusion: 这是实现高性能量子计算系统的重要一步。

Abstract: As quantum computers continue to improve and support larger, more complex computations, smart control hardware and compilers are needed to efficiently leverage the capabilities of these systems.
  This paper introduces a novel approach to enhance the execution of quantum algorithms on distributed quantum systems. The proposed method involves the development of a hardware design that supports parallel instruction execution and a compiler that modifies the order of instructions to increase parallelism opportunities. The hardware design can be flexibly configured to facilitate parallel execution of instructions that have identical parameters. Furthermore, the compiler uses the underlying hardware constraints to intelligently reorder and decompose instructions to avoid dependencies.
  The compiler, hardware, and their combination are evaluated using a runtime calculator and a benchmark quantum algorithm set. The results demonstrate a significant speedup, achieving a maximum average speedup of 16.5x and a maximum single-benchmark speedup of 56.2x relative to a baseline, serial execution model. Furthermore, we show a speedup can be obtained across all benchmarks using any of the proposed hardware schemes, although the degree of speedup is largely dependent on the type of quantum algorithm. Taken together, the results of this paper represent a significant step towards realizing high-performance quantum computing systems.

</details>


### [40] [Compiler design for hardware specific decomposition optimizations, tailored to diamond NV centers](https://arxiv.org/abs/2511.14339)
*Folkert de Ronde,Stephan Wong,Sebastian Feld*

Main category: quant-ph

TL;DR: 开发了针对金刚石NV中心量子计算机的专用编译器，利用金刚石特有的指令来减少执行时间和门数量，并支持经典指令进行状态层析和基于测量的操作。


<details>
  <summary>Details</summary>
Motivation: 目前针对金刚石NV中心量子计算机没有专门的编译器，需要将量子电路转换为特定指令集架构的指令，由控制硬件执行。

Method: 设计了一个针对金刚石NV中心特定指令的编译器，支持直接碳控制和部分交换等特有指令，并集成经典指令用于状态层析和测量操作。

Result: 与通用编译器相比，在应用退相干和退极化噪声时，金刚石专用分解减少了噪声影响；状态层析和测量操作功能正常。

Conclusion: 成功创建了支持经典和量子指令集成的编译器，通过金刚石特定优化提高了电路执行保真度。

Abstract: Advances in quantum algorithms as well as in control hardware designs are continuously being made. These quantum algorithms, expressed as quantum circuits, need to be translated to a set of instructions from a defined quantum instruction-set architecture (ISA), which are executed by the control hardware. These translations can be done by a compiler, targeting different qubit technologies. Specifically for diamond NV centers, no compiler exists to perform this translation. Therefore, in this paper we present a compiler designed for quantum computers utilizing diamond NV center specific instructions, such as direct carbon control and partial swaps, to reduce execution times and gate count. Additionally, our compiler adds on top of general compilers by allowing classical instructions to perform state tomography and measurement-based operations. The output of the compiler is tested in a diamond NV center specific simulator. Comparing a general compiler output with the diamond NV center specific output of our compiler while applying decoherence and depolarization noise showed reduced noise effects due to diamond specific decomposition. The compiler was also tested to perform state tomography and measurement-based operations, which showed to be functional. Our results show that we have successfully created a compiler with integrated classical and quantum instructions support, which can improve circuit execution fidelity by utilizing diamond specific optimizations.

</details>


### [41] [Quantum Biology, Quantum Simulation and Quantum Coherent Devices](https://arxiv.org/abs/2511.14363)
*Rong-Hang Chen,Jing Dong,Wen Yang,Qing Ai,Gui-Lu Long*

Main category: quant-ph

TL;DR: 本文综述了光合作用和鸟类导航中的量子相干效应研究进展，包括相关理论方法、量子模拟方法和量子相干器件研究。


<details>
  <summary>Details</summary>
Motivation: 许多生物体利用量子力学效应获得生物学优势，如光合作用中的量子相干实现近100%能量转移效率，鸟类利用地磁场和自旋相关化学反应导航。研究这些量子生物现象有助于设计高效能量传输的相干器件。

Method: 使用二维电子光谱技术揭示系统内相干性和耦合的动态过程；采用广义Bloch-Redfield理论和层次运动方程等理论方法建模；通过多种平台的量子模拟研究这些系统。

Result: 研究表明量子相干可以显著提高能量转移效率，近年来已成功将量子相干引入人工系统增强能量传输；鸟类导航的量子机制研究推动了量子传感和导航任务的发展。

Conclusion: 量子相干在生物系统中发挥重要作用，相关研究为设计高效能量传输的相干器件和量子传感技术奠定了基础，量子模拟为研究这些复杂系统提供了高效低复杂度的途径。

Abstract: Many living organisms can exploit quantum mechanical effects to gain distinct biological advantages. In plants, photosynthesis uses quantum coherence to achieve near 100% efficiency in energy transfer. With advances in experimental techniques, two-dimensional electronic spectroscopy can reveal dynamic processes such as coherence and coupling within a system, and it plays an important role in studying energy transfer in photosynthesis. On the theory side, methods such as the generalized Bloch-Redfield theory and the hierarchical equations of motion are used to model photosynthetic systems. Quantum simulation, as a high-efficiency and low-complexity approach, has also made progress across various platforms in the study of photosynthesis. In recent years, a series of studies has introduced quantum coherence into artificial systems to enhance energy transfer efficiency, laying the groundwork for the design of coherent devices with efficient energy transport. Birds can use the weak geomagnetic field and spin-dependent chemical reactions to detect direction. Theoretical frameworks for animal navigation include magnetite-based mechanisms, magnetoreceptor genes, and the radical-pair mechanism. Quantum simulations of navigation have also advanced on multiple platforms. Inspired by animal navigation, diverse quantum effects have been applied to improve sensing and to support navigation tasks. This paper presents a comprehensive review of progress on quantum coherence in photosynthesis and avian navigation, along with related theoretical methods, quantum simulation approaches, and research on quantum coherent devices.

</details>


### [42] [Robust Two-Qubit Geometric Phase Gates using Amplitude and Frequency Ramping](https://arxiv.org/abs/2511.14364)
*Christina Bowers,Deviprasath Palani,John Barta,Tyler Guglielmo,Stephen Libby,Dietrich Leibfried,Daniel Slichter*

Main category: quant-ph

TL;DR: 提出了一种基于绝热状态依赖力产生囚禁离子纠缠的方法，该技术对运动模式占据数和频率漂移具有鲁棒性，无需基态冷却即可实现高保真度纠缠操作。


<details>
  <summary>Details</summary>
Motivation: 开发一种对运动模式占据数和频率漂移具有鲁棒性的纠缠产生方法，减少校准开销，适用于量子逻辑光谱学和可扩展量子计算架构。

Method: 通过绝热地调节状态依赖力的振幅和运动模式频率，实现纠缠操作。该方法对运动模式占据数和模式频率漂移具有鲁棒性。

Result: 在广泛的斜坡参数范围内测量到贝尔态保真度高于0.99，运动占据数高达10个声子。

Conclusion: 该技术无需基态冷却即可实现高保真度纠缠操作，校准开销小，适用于量子逻辑光谱学和可扩展量子计算架构。

Abstract: We demonstrate a method for generating entanglement between trapped atomic ions based on adiabatically ramped state-dependent forces. By ramping both the amplitude of the state-dependent force and the motional mode frequencies, we realize an entangling operation that is robust to motional mode occupation and drifts in the mode frequencies. We measure Bell state fidelities above 0.99 across a broad range of ramp parameters and with motional occupations up to 10 phonons. This technique enables high-fidelity entangling operations without ground-state cooling, has a reduced calibration overhead, and is well suited for both quantum logic spectroscopy applications and scalable quantum computing architectures.

</details>


### [43] [Quantum speed-ups for solving semidefinite relaxations of polynomial optimization](https://arxiv.org/abs/2511.14389)
*Daniel Stilck França,Ngoc Hoang Anh Mai*

Main category: quant-ph

TL;DR: 该论文提出了一种基于矩阵乘性权重的量子算法，用于近似多项式优化的Lasserre层次值，在固定层次k下实现了比经典方法更快的运行时间。


<details>
  <summary>Details</summary>
Motivation: 经典矩阵乘性权重方法在多项式优化中计算Lasserre松弛值的复杂度为O(n^{3k}poly(1/ε))，即使是无约束情况也很高。需要开发更高效的量子算法来加速这一过程。

Method: 使用基于矩阵乘性权重的量子算法，在适当系数缩放后，通过块编码实现来近似Lasserre层次值，无需QRAM支持。

Result: 在固定层次k下，量子算法运行时间为O(n^kε^{-4}+n^{k/2}ε^{-5})，相比经典方法实现了超二次加速。例如在投资组合优化中，量子算法为O(nε^{-4}+√nε^{-5})，优于经典的O(n^{ω+1}log(1/ε))。

Conclusion: 该方法在计算Lasserre松弛值时实现了问题维度上的超二次加速，为多项式优化问题提供了更高效的量子解决方案。

Abstract: We study quantum algorithms for approximating Lasserre's hierarchy values for polynomial optimization. Let $f,g_1,\ldots,g_m$ be real polynomials in $n$ variables and $f^\star$ the infimum of $f$ over the semialgebraic set $S(g)=\{x: g_i(x)\ge 0\}$. Let $λ_k$ be the value of the order-$k$ Lasserre relaxation. Assume either (i) $f^\star=λ_k$ and the optimum is attained in the $\ell_1$-ball of radius $1/2$, or (ii) $S(g)$ lies in the simplex $\{x\ge 0: \sum_j x_j\le 1/2\}$, and the constraints define this simplex. After an appropriate coefficient rescaling, we give a quantum algorithm based on matrix multiplicative weights that approximates $λ_k$ to accuracy $\varepsilon>0$ with runtime, for fixed $k$, \[ O(n^k\varepsilon^{-4}+n^{k/2}\varepsilon^{-5}),\qquad O\!\left(s_g\!\left[n^k\varepsilon^{-4}+\!\left(n^{k}+\!\sum_{i=1}^m n^{k-d_i}\right)^{1/2}\!\varepsilon^{-5}\right]\right), \] where $s_g$ bounds the sparsity of the coefficient-matching matrices associated with the constraints. Classical matrix multiplicative-weights methods scale as $O(n^{3k}\mathrm{poly}(1/\varepsilon))$ even in the unconstrained case. As an example, we obtain an $O(n\varepsilon^{-4}+\sqrt{n}\varepsilon^{-5})$ quantum algorithm for portfolio optimization, improving over the classical $O(n^{ω+1}\log(1/\varepsilon))$ bound with $ω\approx2.373$.
  Our approach builds on and sharpens the analysis of Apeldoorn and Gilyén for the SDPs arising in polynomial optimization. We also show how to implement the required block encodings without QRAM. Under the stated assumptions, our method achieves a super-quadratic speedup in the problem dimension for computing Lasserre relaxations.

</details>


### [44] [Lecture Notes on Information Scrambling, Quantum Chaos, and Haar-Random States](https://arxiv.org/abs/2511.14397)
*Marcin Płodzień*

Main category: quant-ph

TL;DR: 这些讲义介绍了量子信息扰动的静态和动态视角，通过随机矩阵理论和幺正群几何来研究纠缠和谱统计的普适特征，并探讨了量子混沌、信息动力学与量子计算之间的联系。


<details>
  <summary>Details</summary>
Motivation: 量子信息扰动是现代量子统计物理和量子混沌的核心概念，旨在理解量子信息如何传播并变得不可访问，为量子混沌、信息动力学和量子计算提供理论基础。

Method: 通过幺正群的几何结构和随机矩阵理论的普适结果，分析从Haar随机态产生的约化密度矩阵的谱性质，并利用谱形状因子和时序无序关联函数等动态诊断工具。

Result: 该几何框架产生了对纠缠和谱统计的普适、模型无关的预测，捕捉了量子混沌的通用特征，无需参考微观细节。

Conclusion: 相同的数学框架支撑着现代量子设备基准测试，其中近似幺正设计和随机电路将几何思想转化为评估实际量子处理器保真度、噪声和扰动效率的定量工具。

Abstract: Information scrambling, the process by which quantum information spreads and becomes effectively inaccessible, is central to modern quantum statistical physics and quantum chaos. These lecture notes provide an introduction to information scrambling from both static and dynamical perspectives. The spectral properties of reduced density matrices arising from Haar-random states are developed through the geometry of the unitary group and the universal results of random matrix theory. This geometric framework yields universal, model-independent predictions for entanglement and spectral statistics, capturing generic features of quantum chaos without reference to microscopic details. Dynamical diagnostics such as the spectral form factor and out-of-time-ordered correlators further reveal the onset of chaos in time-dependent evolution.
  The notes are aimed at advanced undergraduate and graduate students in physics, mathematics, and computer science who are interested in the connections between quantum chaos, information dynamics, and quantum computing. Concepts such as entanglement growth, Haar randomness, random-matrix statistics, and unitary t-designs are introduced through their realization in random quantum circuits and circuit complexity. The same mathematical framework also underpins modern quantum-device benchmarking, where approximate unitary designs and random circuits translate geometric ideas into quantitative tools for assessing fidelity, noise, and scrambling efficiency in real quantum processors.

</details>


### [45] [Explicit block-encoding for partial differential equation-constrained optimization](https://arxiv.org/abs/2511.14420)
*Yuki Sato,Jumpei Kato,Hiroshi Yano,Kosuke Ito,Naoki Yamamoto*

Main category: quant-ph

TL;DR: 提出了一种完全相干的量子算法来解决PDE约束优化问题，通过组合量子PDE求解器和量子优化器，避免量子态层析带来的开销，实现无瓶颈的量子加速。


<details>
  <summary>Details</summary>
Motivation: PDE约束优化在设计和控制等应用中很重要，但计算成本高昂。现有方法需要重复求解PDE，而量子方法可能因量子态层析而抵消量子加速优势。

Method: 将量子PDE求解器与量子优化器结合，通过块编码形式显式构造目标函数的oracle，相干地使用量子PDE求解器的输出。

Result: 推导了算法整体计算复杂度，数值验证了方法在Black-Scholes方程参数校准和波动方程材料参数设计问题中的有效性。

Conclusion: 通过组合量子子程序，利用一个子程序的优势（相干oracle访问）抵消另一个的弱点（读取开销），实现了无瓶颈的量子算法。

Abstract: Partial differential equation (PDE)-constrained optimization, where an optimization problem is subject to PDE constraints, arises in various applications such as design, control, and inference. Solving such problems is computationally demanding because it requires repeatedly solving a PDE and using its solution within an optimization process. In this paper, we first propose a fully coherent quantum algorithm for solving PDE-constrained optimization problems. The proposed method combines a quantum PDE solver that prepares the solution vector as a quantum state, and a quantum optimizer that assumes oracle access to a quantized objective function. The central idea is the explicit construction of the oracle in a form of block-encoding for the objective function, which coherently uses the output of a quantum PDE solver. This enables us to avoid classical access to the full solution that requires quantum state tomography canceling out the potential quantum speedups. We also derive the overall computational complexity of the proposed method with respect to parameters for optimization and PDE simulation, where quantum speedup is inherited from the underlying quantum PDE solver. We numerically demonstrate the validity of the proposed method by applications, including a parameter calibration problem in the Black-Scholes equation and a material parameter design problem in the wave equation. This work presents the concept of composing quantum subroutines so that the weakness of one (i.e., prohibitive readout overhead) is neutralized by the strength of another (i.e., coherent oracle access), toward a bottleneck-free quantum algorithm.

</details>


### [46] [Self-interacting quantum particles and the Dirac delta potential](https://arxiv.org/abs/2511.14424)
*Sergio Giardino*

Main category: quant-ph

TL;DR: 在实希尔伯特空间方法中研究狄拉克δ函数势对复波函数和四元数波函数的影响，发现自相互作用导致无法形成束缚态和非定态量子态，这些现象在复量子力学中无法观察到。


<details>
  <summary>Details</summary>
Motivation: 探索四元数量子力学与复数量子力学之间的根本差异，特别是在实希尔伯特空间框架下研究狄拉克δ函数势的独特性质。

Method: 采用实希尔伯特空间方法分析狄拉克δ函数势，分别处理复波函数和四元数波函数的情况。

Result: 发现自相互作用排除了束缚态的可能性，并强制量子态处于非定态，这些现象在传统复波函数量子力学中无法实现。

Conclusion: 研究结果突显了四元数量子力学与复数量子力学的显著差异，并建立了一种可应用于多种不同情况的波方程求解方法。

Abstract: The Dirac delta function potential is considered within the real Hilbert space approach for complex wave functions, as well as quaternionic wave functions. As has been previously determined, the real Hilbert space approach enables the possibility of self-interacting physical systems. The self-interaction precludes confining states, and also imposes non-stationary quantum states, both of them representing novel situations that cannot be observed in terms of quantum wave functions. These results remark the differences between quaternionic quantum mechanics ($\mathbbm H$QM) and complex quantum mechanics ($\mathbbm C$QM), and also establish a method of solving the wave equation that may be applied to a variety of different cases.

</details>


### [47] [Simulating quantum electrodynamics in 2+1 dimensions with qubits and qumodes](https://arxiv.org/abs/2511.14506)
*Victor Ale,Tommaso Rainaldi,Enrique Rico,Felix Ringer,George Siopsis*

Main category: quant-ph

TL;DR: 提出了一个混合量子比特-量子模式框架来模拟2+1维量子电动力学，其中费米子物质场用量子比特表示，U(1)规范场用量子模式编码，并比较了两种约束执行策略来确保规范对称性。


<details>
  <summary>Details</summary>
Motivation: 开发一个可扩展的混合量子计算框架来模拟阿贝尔规范场论与费米子物质的耦合，为近期混合量子架构上的规范场论模拟提供可行路径。

Method: 使用量子比特编码费米子场，量子模式编码规范场；提出两种约束执行策略：基于压缩的投影方法和动态惩罚哈密顿量方法；构建混合哈密顿量并分解为实验可实现的量子门；使用连续变量量子虚时演化算法进行基态制备。

Result: 混合框架成功再现了正确的规范不变动力学，在单格点极限下分析了能谱，证明了基态制备和收敛性，为格点规范理论的混合离散-连续量子模拟建立了通用框架。

Conclusion: 该混合量子比特-量子模式方法为在近期混合量子设备上模拟阿贝尔格点规范理论提供了一条可扩展的路径，能够正确处理规范对称性和费米子-规范场耦合。

Abstract: We develop a hybrid qubit-qumode framework for simulating quantum electrodynamics in 2+1 dimensions. In this approach, fermionic matter fields are represented by qubits, while U(1) gauge fields are encoded in continuous-variable bosonic modes whose canonical quadratures capture the electric and vector-potential components of the theory. To reconcile the non-compact phase space of the qumodes with the compact U(1) gauge symmetry, we introduce and compare two complementary constraint-enforcement strategies: (i) a squeezing-based projection that confines qumode states to the unit circle through an effective modification of the inner product, and (ii) a method that dynamically enforces compactness via a penalty Hamiltonian term. We construct the corresponding hybrid Hamiltonian, derive its decomposition into experimentally accessible qubit-qumode gates, and analyze its spectrum in the analytically tractable single-plaquette limit. The hybrid formulation reproduces the correct gauge-invariant dynamics and provides a scalable route toward simulating Abelian lattice gauge theories coupled to fermionic matter on near-term hybrid quantum architectures. Ground-state preparation and convergence are demonstrated using a continuous-variable extension of the Quantum Imaginary Time Evolution (QITE) algorithm, establishing a general framework for hybrid discrete-continuous quantum simulations of lattice gauge theories.

</details>


### [48] [Coherent regime of Kapitza-Dirac effect with electrons](https://arxiv.org/abs/2511.14508)
*Kamila Moriová,Petr Koutenský,Neli Laštovičková Streshkova,Marius Constantin Chirita Mihaila,Zbyněk Šobáň,Jaromír Kopeček,Andreas Schertel,Martin Kozák*

Main category: quant-ph

TL;DR: 首次在扫描电子显微镜中观察到高能电子（20 keV和30 keV）的Kapitza-Dirac效应，通过空间滤波检测电子横向动量谱中的光子边带，展示了电子与光场耦合强度增加时的相干可逆振荡。


<details>
  <summary>Details</summary>
Motivation: 由于可见光子的动量远小于高能电子的动量，导致衍射角度极小（10^(-4) rad或更小），此前Kapitza-Dirac效应仅能在低能电子中观察到。本研究旨在突破这一限制，在高能电子中实现该效应。

Method: 在扫描电子显微镜中使用高能电子（20 keV和30 keV），通过两束干涉光波形成周期性光结构，利用会聚束衍射几何和空间滤波检测电子横向动量谱中的光子边带。

Result: 成功观察到高能电子的Kapitza-Dirac效应，随着电子与光场耦合强度的增加，边带布居在不同衍射级之间表现出相干、可逆的振荡。

Conclusion: 该效应可作为相干电子束分离器或相位板应用于各种类型的电子显微镜中。

Abstract: Electron matter waves coherently diffract when passing through a periodic structure of light formed by two interfering light waves. In this so-called Kapitza-Dirac effect, the electron momentum changes due to absorption and emission of photons via stimulated Compton scattering. Until now, the effect has only been observed with low energy electrons due to the small momentum of a visible photon compared to the momentum of high energy electron leading to diffraction angles of 10^(-4) rad or smaller. We report on the observation of the Kapitza-Dirac effect in a scanning electron microscope using high energy (20 keV and 30 keV) electrons with de-Broglie wavelengths of 9 pm and 7 pm, respectively. The photon sidebands in the electron transverse momentum spectrum are detected in the convergent beam diffraction geometry using spatial filtering. As the coupling strength between the electrons and the light field increases, the sideband populations exhibit coherent, reversible oscillations among diffraction orders. The effect can serve as a coherent electron beam-splitter or a phase-plate in various types of electron microscopes.

</details>


### [49] [Efficient Hamiltonian-aware Quantum Natural Gradient Descent for Variational Quantum Eigensolvers](https://arxiv.org/abs/2511.14511)
*Chenyu Shi,Hao Wang*

Main category: quant-ph

TL;DR: 提出了哈密顿量感知量子自然梯度下降(H-QNG)方法，结合了传统梯度下降的低计算成本和量子自然梯度下降的参数不变性优势，在分子哈密顿量上实现了更快的收敛速度和更少的量子计算资源需求。


<details>
  <summary>Details</summary>
Motivation: 量子自然梯度下降(QNG)虽然收敛更快，但需要额外量子资源估计Fubini-Study度量张量，且该度量张量与整个量子态空间相关，未利用目标哈密顿量的结构信息。

Method: 使用从哈密顿量项张成的低维子空间到参数空间的黎曼拉回度量，构建哈密顿量感知的量子自然梯度下降方法。

Result: 数值实验表明，H-QNG在分子哈密顿量上能够更快达到化学精度，同时需要更少的量子计算资源。

Conclusion: H-QNG继承了传统梯度下降的低量子计算成本和量子自然梯度下降的参数不变性优点，是变分量子本征求解器优化中的有效方法。

Abstract: The Variational Quantum Eigensolver (VQE) is one of the most promising algorithms for current quantum devices. It employs a classical optimizer to iteratively update the parameters of a variational quantum circuit in order to search for the ground state of a given Hamiltonian. The efficacy of VQEs largely depends on the optimizer employed. Recent studies suggest that Quantum Natural Gradient Descent (QNG) can achieve faster convergence than vanilla gradient descent (VG), but at the cost of additional quantum resources to estimate Fubini-Study metric tensor in each optimization step. The Fubini-Study metric tensor used in QNG is related to the entire quantum state space and does not incorporate information about the target Hamiltonian. To take advantage of the structure of the Hamiltonian and address the limitation of additional computational cost in QNG, we propose Hamiltonian-aware Quantum Natural Gradient Descent (H-QNG). In H-QNG, we propose to use the Riemannian pullback metric induced from the lower-dimensional subspace spanned by the Hamiltonian terms onto the parameter space. We show that H-QNG inherits the desirable features of both approaches: the low quantum computational cost of VG and the reparameterization-invariance of QNG. We also validate its performance through numerical experiments on molecular Hamiltonians, showing that H-QNG achieves faster convergence to chemical accuracy while requiring fewer quantum computational resources.

</details>


### [50] [Link prediction with swarms of chiral quantum walks](https://arxiv.org/abs/2511.14513)
*Gaia Forghieri,Viacheslav Dubovitskii,Matteo A. C. Rossi,Matteo G. A. Paris*

Main category: quant-ph

TL;DR: 提出手性量子行走方法，通过引入随机相位增强蛋白质相互作用网络预测的鲁棒性和准确性


<details>
  <summary>Details</summary>
Motivation: 蛋白质相互作用网络重构是网络医学的核心挑战，量子行走方法在此任务中展现出潜力，但现有方法对演化时间超参数敏感

Method: 在哈密顿量生成器中引入随机相位实现手性，使用手性量子行走群进行网络探索，分析多种相位采样策略

Result: 相比非手性算法，手性版本具有更好的鲁棒性，性能对最优演化时间的依赖性降低，同时保持高预测准确性

Conclusion: 手性量子行走在复杂网络上具有优势，能在现实场景中超越经典和非手性量子方法

Abstract: Reconstructing protein-protein interaction networks is a central challenge in network medicine, often addressed using link prediction algorithms. Recent studies suggest that quantum walk-based approaches hold promise for this task. In this paper, we build on these algorithms by introducing chirality through the addition of random phases in the Hamiltonian generators. The resulting additional degrees of freedom enable a more diverse exploration of the network, which we exploit by employing a swarm of chiral quantum walks. Thus, we enhance the predictive power of quantum walks on complex networks. Indeed, compared to a non-chiral algorithm, the chiral version exhibits greater robustness, making its performance less dependent on the optimal evolution time--a critical hyperparameter of the non-chiral model. This improvement arises from complementary dynamics introduced by chirality within the swarm. By analyzing multiple phase-sampling strategies, we identify configurations that achieve a practical trade-off: retaining the high predictive accuracy of the non-chiral algorithm at its optimal time while gaining the robustness typical of chirality. Our findings highlight the versatility of chiral quantum walks and their potential to outperform both classical and non-chiral quantum methods in realistic scenarios, including comparisons between successive versions of evolving databases.

</details>


### [51] [Perturbative nonlinear J-matrix method of scattering in two dimensions](https://arxiv.org/abs/2511.14519)
*T. J. Taiwo,A. D. Alhaidari,U. Al Khawaja*

Main category: quant-ph

TL;DR: 提出了二维非线性薛定谔方程散射问题的微扰形式，基于J矩阵方法扩展，适用于ψ^{2n+1}非线性项，展示了立方和五次非线性情况下的分岔现象。


<details>
  <summary>Details</summary>
Motivation: 将J矩阵散射方法扩展到非线性领域，解决二维圆对称非线性薛定谔方程的散射问题，探索非线性效应在散射过程中的表现。

Method: 利用正交多项式乘积的线性化，结合J矩阵方法工具，通过高斯求积积分近似进行数值实现，适用于一般ψ^{2n+1}非线性形式。

Result: 在特定能量值观察到分岔现象，出现两个稳定解，这是非线性效应的明确标志和表现。

Conclusion: 成功建立了非线性J矩阵方法的微扰形式，揭示了非线性散射中分岔这一有趣现象，为研究非线性散射问题提供了有效工具。

Abstract: We introduce a perturbative formulation for a nonlinear extension of the J-matrix method of scattering in two dimensions. That is, we obtain the scattering matrix for the time-independent nonlinear Schrödinger equation in two dimensions with circular symmetry. The formulation relies on the linearization of products of orthogonal polynomials and on the utilization of the tools of the J-matrix method. Gauss quadrature integral approximation is instrumental in the numerical implementation of the approach. We present the theory for a general ψ^{2n + 1} nonlinearity, where n is a natural number, and obtain results for the cubic and quintic nonlinearities, ψ^3 and ψ^5. At certain value(s) of the energy, we observe the occurrence of bifurcation with two stable solutions. This curious and interesting phenomenon is a clear signature and manifestation of the underlying nonlinearity.

</details>


### [52] [Systems with Quantum Dimensions](https://arxiv.org/abs/2511.14547)
*Mikołaj Myszkowski,Mattia Damia Paciarini,Francesco Sannino*

Main category: quant-ph

TL;DR: 提出将空间维度数量作为动态量子变量的量子力学系统，其中有效维度取决于系统的物理状态，并展现出比固定维度系统更强的对称性。


<details>
  <summary>Details</summary>
Motivation: 探索维度作为量子变量的物理系统，为从引力到凝聚态物理等领域构建维度量子化的新框架。

Method: 分析一个空间维度由量子算符表示的谐振子模型，通过计算配分函数来研究温度依赖的有效维度。

Result: 发现系统的有效维度随温度变化，这种系统比固定维度系统具有更强的对称性。

Conclusion: 该框架为构建维度量子化的物理系统开辟了新途径，其中维度概念本身成为量子化的。

Abstract: We propose quantum-mechanical systems in which the number of spatial dimensions is promoted to a dynamical quantum variable. As a consequence, the effective dimension depends on the physical state of the system. Interestingly, systems of this form exhibit enhanced symmetries compared to their fixed-dimensional counterparts. As an explicit example, we analyze a harmonic oscillator for which the spatial dimension is represented by a quantum operator. By evaluating the corresponding partition function, we uncover a temperature-dependent effective dimension. Our framework opens a new avenue for constructing physical systems, from gravity to condensed matter, where the very notion of dimensionality becomes quantum.

</details>


### [53] [Experimental observation and application of the genuine Quantum Mpemba Effect](https://arxiv.org/abs/2511.14552)
*Bruno P. Schnepper,Jefferson L. D. de Oliveira,Carlos H. S. Vieira,Krissia Zawadzki,Roberto M. Serra*

Main category: quant-ph

TL;DR: 实验研究量子Mpemba效应，展示了自旋系统从远离平衡态更快热化的现象，并将其应用于量子奥托制冷机提升冷却功率


<details>
  <summary>Details</summary>
Motivation: 研究量子相干性如何影响微观热化过程，特别是量子Mpemba效应这种反常弛豫现象

Method: 实验研究自旋-1/2系统与热沉相互作用，观察其热化动力学，并将量子Mpemba效应应用于量子奥托制冷机

Result: 成功观测到量子Mpemba效应，系统从远离平衡态更快热化，且在量子奥托制冷机中提高了冷却功率

Conclusion: 该概念验证实验揭示了改进量子热任务的新实用路径

Abstract: Coherence is an inherently quantum property that deeply affects microscopic processes, including thermalization phenomena. A striking example is the quantum Mpemba effect (QME), in which a system can exhibit anomalous relaxation, thermalizing faster from a state initially farther from equilibrium than from one closer. Here, we experimentally investigate the genuine QME and observe how the dynamics of a spin-1/2 system interacting with a heat sink can be sped-up to equilibrium. Furthermore, we apply the QME in a quantum Otto refrigerator, thereby increasing its cooling power. This proof-of-concept experiment unveils new practical paths for improving quantum thermal tasks.

</details>


### [54] [Gradient-descent methods for quantum detector tomography](https://arxiv.org/abs/2511.14579)
*Amanuel Anteneh,Olivier Pfister*

Main category: quant-ph

TL;DR: 提出一种基于梯度下降优化的量子探测器层析方法，用于重建相位不敏感量子探测器的POVM，相比传统约束凸优化方法具有更高保真度和更快速度，并可扩展到相位敏感情况。


<details>
  <summary>Details</summary>
Motivation: 传统量子探测器层析方法如约束凸优化计算成本高且效率有限，需要开发更高效的重建方法，特别是在噪声和有限探测态资源条件下。

Method: 使用梯度下降优化学习描述探测器数据的POVM，通过复数Stiefel流形上的参数化扩展到相位敏感情况。

Result: 数值基准测试显示该方法比约束凸优化达到更高或相当的保真度，且时间大幅减少，在噪声和有限资源下仍表现良好。

Conclusion: 梯度下降优化是量子探测器层析的有效方法，提供快速高保真重建，并可扩展到更复杂的相位敏感探测器。

Abstract: We present a technique for performing quantum detector tomography (QDT) of phase insensitive quantum detectors using gradient descent-based optimization to learn the positive operator-valued measure (POVM) that best describes the data collected using the detector under study. We numerically benchmark our method against constrained convex optimization (CCO) and show that it reaches higher or comparable reconstruction fidelity in much less time even in the presence of noise and limited probe state resources. We also present a possible extension of our approach to the phase sensitive case via a parametrization of POVMs on the complex Stiefel manifold which enables gradient based optimization restricted to this manifold.

</details>


### [55] [Logical Operators and Derived Automorphisms of Tile Codes](https://arxiv.org/abs/2511.14589)
*Nikolas P. Breuckmann,Shin Ho Choe,Jens Niklas Eberhardt,Francisco Revson Fernandes Pereira,Vincent Steffan*

Main category: quant-ph

TL;DR: 本文建立了tile codes逻辑算子的规范描述，证明了其存在沿晶格边界的规范辛基，开发了代数几何框架，并引入了衍生自同构概念，为tile codes作为容错量子计算构建块奠定基础。


<details>
  <summary>Details</summary>
Motivation: tile codes作为表面码的有前景替代方案，具有二维局域性和更高编码效率，但其逻辑算子和边界行为理解较少，需要建立系统理论框架。

Method: 使用细胞自动机生成逻辑算子基，通过平移不变Pauli稳定子模型解析tile codes，在ℙ¹×ℙ¹上建立Koszul复形框架，并引入衍生自同构概念。

Result: 证明了tile codes存在沿边界的规范辛基，建立了代数几何描述，展示了衍生自同构可实现低开销容错逻辑CNOT门操作。

Conclusion: 研究为tile codes提供了新的结构洞见，奠定了其作为容错量子计算构建块的理论基础，特别是衍生自同构概念扩展了量子码的对称性理解。

Abstract: The recently introduced tile codes are a promising alternative to surface codes, combining two-dimensional locality with higher encoding efficiency. While surface codes are well understood in terms of their logical operators and boundary behavior, much less is known about tile codes. In this work, we establish a natural and precise description of their logical operator space. We prove that, under mild assumptions, any tile code admits a canonical symplectic basis of logical operators supported along lattice boundaries, which can be generated efficiently by a simple cellular automaton with the number of update rules only depending on the non-locality of the tile code. Further, we develop algebraic and algebro-geometric frameworks for tile codes, by resolving them by translationally invariant Pauli stabilizer models and showing that they arise as derived sections of a Koszul complex on $\mathbb{P}^1 \times \mathbb{P}^1$. Finally, we introduce the concept of derived automorphisms for quantum codes. These are automorphism-like operations that can exist even for codes that do not have symmetries. We explain how derived automorphisms can be implemented for tile codes in a low-overhead and fault-tolerant manner by extending the lattice on one side and shrinking it on the other. While this operation is trivial for the surface code, it induces a product of logical CNOT gates on the encoded information. Our results provide new structural insights into tile codes and lay the groundwork for tile codes as building blocks for fault-tolerant quantum computation.

</details>


### [56] [Measuring Reactive-Load Impedance with Transmission-Line Resonators Beyond the Perturbative Limit](https://arxiv.org/abs/2511.14621)
*Xuanjing Chu,Jinho Park,Jesse Balgley,Sean Clemons,Ted S. Chung,Kenji Watanabe,Takashi Taniguchi,Leonardo Ranzani,Martin V. Gustafsson,Kin Chung Fong,James Hone*

Main category: quant-ph

TL;DR: 开发了分析框架从超导传输线谐振器中提取电路参数和损耗角正切，扩展了超出微扰范围的分析，通过闭合关系式连接谐振频率、参与比和内部品质因数，无需全波仿真。


<details>
  <summary>Details</summary>
Motivation: 扩展超导传输线谐振器的分析能力，使其能够处理非微扰情况下的参数提取，特别是针对端接反应性负载的情况，为材料计量提供更精确的方法。

Method: 通过电路仿真、有限元建模和实验测量验证框架，使用范德华平行板电容器作为测试案例，采用多参考谐振器统计分析和多模自校准方法。

Result: 成功提取了六方氮化硼的介电常数和损耗角正切，结果与文献值高度一致，展示了电容和损耗角正切的一致性和可重复性提取。

Conclusion: 该分析框架不仅能够精确提取材料参数，还为最大化负载能量参与比和提高谐振器基材料计量精度提供了实用的设计指导。

Abstract: We develop an analytic framework to extract circuit parameters and loss tangent from superconducting transmission-line resonators terminated by reactive loads, extending analysis beyond the perturbative regime. The formulation yields closed-form relations between resonant frequency, participation ratio, and internal quality factor, removing the need for full-wave simulations. We validate the framework through circuit simulations, finite-element modeling, and experimental measurements of van der Waals parallel-plate capacitors, using it to extract the dielectric constant and loss tangent of hexagonal boron nitride. Statistical analysis across multiple reference resonators, together with multimode self-calibration, demonstrates consistent and reproducible extraction of both capacitance and loss tangent in close agreement with literature values. In addition to parameter extraction, the analytic relations provide practical design guidelines for maximizing energy participation ratio in the load and improving the precision of resonator-based material metrology.

</details>


### [57] [PAC global optimization for VQE in low-curvature geometric regimes](https://arxiv.org/abs/2511.14628)
*Benjamin Asch*

Main category: quant-ph

TL;DR: 该论文为变分量子本征求解器(VQE)提供了噪声鲁棒的PAC保证，在特定几何条件下可实现全局ε最优性。当低能区域具有低曲率维度结构时，样本复杂度仅与曲率维度r相关而非参数维度p，使得高概率全局优化在存在噪声时仍可行。


<details>
  <summary>Details</summary>
Motivation: 解决变分量子本征求解器在噪声环境下的全局优化问题，特别是在高维参数空间中寻找全局最优解的挑战。

Method: 假设周期性ansatzes具有有界生成器，低能区域为Morse-Bott子流形，其法向Hessian矩阵的秩r=O(log p)，并满足多项式纤维正则性条件。

Result: 在置信度1-δ下，算法输出一个所有点都是ε最优的区域，且至少有一个点位于全局最小值的有限邻域内。样本复杂度与曲率维度r而非环境维度p成比例，复杂度为p和ε^{-1}的拟多项式及δ^{-1}的对数。

Conclusion: 识别了一个几何机制，其中尽管存在散粒噪声，高概率全局优化仍然可行，为VQE在噪声量子设备上的应用提供了理论保证。

Abstract: We give noise-robust, Probably Approximately Correct (PAC) guarantees of global $\varepsilon$-optimality for the Variational Quantum Eigensolver under explicit geometric conditions. For periodic ansatzes with bounded generators -- yielding a globally Lipschitz cost landscape on a toroidal parameter space -- we assume that the low-energy region containing the global minimum is a Morse--Bott submanifold whose normal Hessian has rank $r = O(\log p)$ for $p$ parameters, and which satisfies polynomial fiber regularity with respect to coordinate-aligned, embedded flats. This low-curvature-dimensional structure serves as a model for regimes in which only a small number of directions control energy variation, and is consistent with mechanisms such as strong parameter tying together with locality in specific multiscale and tied shallow architectures.
  Under this assumption, the sample complexity required to find an $\varepsilon$-optimal region with confidence $1-δ$ scales with the curvature dimension $r$ rather than the ambient dimension $p$. With probability at least $1-δ$, the algorithm outputs a region in which all points are $\varepsilon$-optimal, and at least one lies within a bounded neighborhood of the global minimum. The resulting complexity is quasi-polynomial in $p$ and $\varepsilon^{-1}$ and logarithmic in $δ^{-1}$. This identifies a geometric regime in which high-probability global optimization remains feasible despite shot noise.

</details>


### [58] [Divide-et-impera Heuristic-based Randomized Search for the Qubit Routing Problem](https://arxiv.org/abs/2511.14644)
*Marco Baioletti,Fabrizio Fagiolo,Angelo Oddi,Riccardo Rasconi*

Main category: quant-ph

TL;DR: DIRSH算法通过启发式引导的随机分治策略解决量子比特路由问题，在IBMQ Tokyo拓扑上优于LightSABRE变体，实现了更短的深度和更少的交换操作


<details>
  <summary>Details</summary>
Motivation: 解决NISQ设备上量子比特路由问题，优化量子电路在有限连接性硬件上的执行效率

Method: 使用分块策略将电路分割成块，通过随机选择门和交换操作优化每个块，结合全局搜索（重启和自适应调整bandit参数）与深度敏感的局部剪枝

Result: 在RevLib基准测试中，DIRSH在不同时间预算下均优于三个LightSABRE变体，实现了更短的电路深度和更少的交换操作

Conclusion: 分块分解与bandit驱动启发式相结合的方法对于NISQ设备上的量子电路路由是有效的

Abstract: This paper introduces the DIRSH algorithm for the Qubit Routing Problem (QRP), using a heuristic-guided randomized divide-and-conquer strategy. The method splits the circuit into chunks and optimizes each one with a stochastic selection of gates and swaps. It balances global search, via restarts and adaptive tuning of bandit parameters with depth-sensitive local pruning. Tested on RevLib benchmarks mapped to the 20-qubit IBMQ Tokyo topology, DIRSH outperformed three LightSABRE variants across different time budgets, achieving shorter depths and fewer swaps. These results confirm that combining chunk-based decomposition with bandit-driven heuristics is effective for routing quantum circuits on NISQ devices.

</details>


### [59] [Using the Schmidt Decomposition to Determine Quantum Entanglement](https://arxiv.org/abs/2511.14648)
*Lane Boswell,Ying Cao*

Main category: quant-ph

TL;DR: 本文介绍了量子信息理论中的量子纠缠概念，重点展示了判断系统是否纠缠的数学方法（施密特分解），并演示了量子纠缠在量子隐形传态中的应用。


<details>
  <summary>Details</summary>
Motivation: 量子纠缠是量子信息理论的核心概念，能够显著提升计算能力。本文旨在通过数学方法验证纠缠现象并展示其实际应用价值。

Method: 使用施密特分解这一数学方法来判定系统是否处于纠缠状态，并通过量子隐形传态实验来演示纠缠的实际应用。

Result: 成功展示了施密特分解在识别量子纠缠中的有效性，并通过量子隐形传态验证了纠缠现象的实际应用潜力。

Conclusion: 量子纠缠是量子信息理论的关键要素，施密特分解是分析纠缠状态的有效数学工具，量子隐形传态等应用证明了纠缠在量子计算中的重要作用。

Abstract: Quantum information theory is a rapidly growing area of math and physics that combines two independent theories, quantum mechanics and information theory. Quantum entanglement is a concept that was first proposed in the EPR paradox. In quantum mechanics, particles can be in superposition, meaning they are in multiple different states at once. It is not until the particle is measured that it is forced into a single state. However, it is possible that particles can be tied to other particles, meaning that the measurement of one particle will determine the measurement of the other particle. Entanglement is at the very core of quantum information theory. It is one of the core pieces that allows for the massive increase in computing power. For this paper, we decided to focus on demonstrating the mathematical method (the Schmidt decomposition) for determining if a system is entangled, and a demonstration of quantum entanglement's use (quantum teleportation) as well as a quick look at how to extend the uses of the Schmidt decomposition.

</details>


### [60] [Quantum State Preparation with Resolution Refinement](https://arxiv.org/abs/2511.14732)
*Scott Bogner,Heiko Hergert,Morten Hjorth-Jensen,Ryan LaRose,Dean Lee,Matthew Patkowski*

Main category: quant-ph

TL;DR: 提出了一种称为分辨率细化的方法，通过先准备低分辨率哈密顿量的本征态，然后将其提升到更高分辨率并绝热演化，来获得高保真哈密顿量的对应本征态。


<details>
  <summary>Details</summary>
Motivation: 为了在量子计算机上高效地准备本征态，解决直接在高分辨率哈密顿量上准备本征态的计算成本高的问题。

Method: 分辨率细化方法：首先使用任意方法准备低分辨率哈密顿量的本征态，然后将该本征态提升到更高分辨率，并通过绝热演化得到高保真哈密顿量的对应本征态。

Result: 该方法在多个系统中成功应用：一维谐振子陷阱中相互作用粒子的Busch模型基态、三维Woods-Saxon势的Hartree-Fock核态、以及一维多物种Hubbard模型的束缚态和连续态。

Conclusion: 分辨率细化方法高效且所需绝热演化时间与物理谱中能隙的倒数相当，为量子计算机上的本征态准备提供了一种有效的引导方法。

Abstract: We introduce a method called resolution refinement that allows one to bootstrap eigenstate preparation on a quantum computer. We first prepare an eigenstate of a low-resolution Hamiltonian using any method of choice. The eigenstate is then lifted to higher resolution and adiabatically evolved to produce the corresponding eigenstate of a higher-fidelity Hamiltonian. We give examples of resolution refinement applied to both single-particle basis states as well as a spatial lattice grid. For basis refinement, we compute few-body ground states of the Busch model for interacting particles in a harmonic trap in one dimension. For lattice refinement, we compute Hartree-Fock nuclear states for a central Woods-Saxon potential in three dimensions, and we compute bound states and continuum states in a multi-species Hubbard model of fermions in one dimension. In all cases, the method is efficient and requires an adiabatic evolution time comparable to the inverse of the energy gap in the physical spectrum.

</details>


### [61] [From Random Determinants to the Ground State](https://arxiv.org/abs/2511.14734)
*Hao Zhang,Matthew Otten*

Main category: quant-ph

TL;DR: TrimCI是一种无需先验知识的量子多体计算方法，通过从随机Slater行列式出发，迭代扩展和修剪变分空间，能够高效构建精确的基态波函数。


<details>
  <summary>Details</summary>
Motivation: 传统量子多体计算依赖可靠的参考态或人工设计的ansatz，但在强关联系统等困难问题中这些知识来源可能不可靠。

Method: TrimCI方法从随机Slater行列式出发，迭代扩展变分空间并修剪不重要态，使随机初始核心自优化为精确基态近似。

Result: 在多个挑战性基准测试中，TrimCI实现了最先进的精度，效率提升数个数量级。例如在[4Fe-4S]团簇中，用10^6倍更少的行列式和CPU小时匹配量子计算结果；在8×8 Hubbard模型中，仅使用希尔伯特空间的10^{-28}就恢复了超过99%的基态能量。

Conclusion: 结果表明高精度的多体基态可以直接从随机行列式发现，TrimCI为量子多体系统提供了一个无需先验知识、精确且高效的框架，其产生的紧凑显式波函数还能直接快速计算可观测量。

Abstract: Accurate quantum many-body calculations often depend on reliable reference states or good human-designed ansätze, yet these sources of knowledge can become unreliable in hard problems like strongly correlated systems. We introduce the Trimmed Configuration Interaction (TrimCI) method, a prior-knowledge-free algorithm that builds accurate ground states directly from random Slater determinants. TrimCI iteratively expands the variational space and trims away unimportant states, allowing a random initial core to self-refine into an accurate approximation of exact ground state. Across challenging benchmarks, TrimCI achieves state-of-the-art accuracy with strikingly efficiency gains of several orders of magnitude. For [4Fe-4S] cluster, it matches recent quantum computing results with $10^6$-fold fewer determinants and CPU-hours. For the nitrogenase P-cluster, it matches selected-CI accuracy using $10^5$-fold fewer determinants. For $8\times8$ Hubbard model, it recovers over $99\%$ of the ground-state energy using only $10^{-28}$ of the Hilbert space. In some regimes, TrimCI attains orders-of-magnitude higher accuracy than AFQMC method. These results demonstrate that high-accuracy many-body ground states can be discovered directly from random determinants, establishing TrimCI as a prior-knowledge-free, accurate and highly efficient framework for quantum many-body systems. The compact explicit wavefunctions it produces further enable direct and rapid evaluation of observables.

</details>


### [62] [Squeezing-Enhanced Photon-Number Measurements for GKP State Generation](https://arxiv.org/abs/2511.14737)
*Paul Renault,Patrick Yard,Raphael Pooser,Hussain Zaidi*

Main category: quant-ph

TL;DR: 提出了一种利用压缩操作控制高斯资源态光子数统计来生成GKP态的新架构，通过时间复用多模簇态和猫态生成高压缩GKP态，相比之前工作减少了测量次数和噪声


<details>
  <summary>Details</summary>
Motivation: 改进GKP态生成方法，减少阻尼和噪声，提高生成效率，降低对主动开关和光子数资源态的需求

Method: 采用基于量子隐形传态的压缩协议和多项式门应用，结合时间复用多模簇态架构生成高振幅猫态，进而生成高压缩GKP态，使用动态输入态重置和改进的breeding算法

Result: 实现了11.5 dB簇压缩的容错阈值，使用RHG表面码进行纠错，无需主动开关或光子数资源态

Conclusion: 该架构通过优化压缩资源利用和减少测量次数，显著提高了GKP态生成的效率和容错性能

Abstract: We present an architecture for the generation of GKP states in which quadrature squeezing operations are used to control the average photon number statistics of probabilistic photon number measurements on Gaussian resource states. Specifically, we present an architecture employing a teleportation-based squeezing protocol and polynomial-gate applications integrated into a time-multiplexed multi-mode cluster state to generate cat states with high amplitudes, which are consequently used to generate GKP states with high quadrature effective squeezing. Compared to our previous work, in addition to using squeezing as a resource, the present architecture reduces damping and noise by minimizing the number of homodyne measurements required in GKP state generation. We demonstrate the effectiveness of these improvements - including dynamic input-state resetting and an improved breeding algorithm - by achieving a fault-tolerance threshold of 11.5 dB cluster squeezing using the RHG surface code for error correction, without requiring active switching or photon-number resource states.

</details>


### [63] [Optimization of High-Fidelity Single-Qubit Gates for Fluxoniums Using Single-Flux Quantum Control](https://arxiv.org/abs/2511.14746)
*Maxime Lapointe-Major,Boyan Torosov,Bohdan Kulchytskyy,Pooya Ronagh*

Main category: quant-ph

TL;DR: 提出基于梯度的优化方法，为fluxonium量子比特构建内存高效、高保真度的单量子比特门，使用单磁通量子脉冲序列，通过电容或电感耦合实现。


<details>
  <summary>Details</summary>
Motivation: 开发更高效的量子门控制方法，减少内存使用同时保持高保真度，解决fluxonium量子比特门操作中的优化问题。

Method: 使用单磁通量子脉冲序列，包含斜坡段和脉冲串，通过松弛SFQ时钟离散化约束，采用Broyden-Fletcher-Goldfarb-Shanno优化器进行梯度优化。

Result: 电感耦合可达99.99%门保真度，电容耦合可达99.9%门保真度，泄漏是两种方法中相干误差的主要来源。

Conclusion: 该方法成功实现了高保真度的单量子比特门操作，为fluxonium量子比特的控制提供了有效的优化方案。

Abstract: We present a gradient-based method to construct memory-efficient, high-fidelity, single-qubit gates for fluxonium qubits. These gates are constructed using a sequence of single-flux quantum (SFQ) pulses that are sent to the qubit through either capacitive or inductive coupling. The schedule of SFQ pulses is constructed with an on-ramp and an off-ramp applied prior to and after a pulse train, where the pulses are spaced at intervals equal to the qubit period. We reduce the optimization problem to the scheduling of a fixed number of SFQ pulses in the on-ramp and solve it by relaxing the discretization constraint of the SFQ clock as an intermediate step, allowing the use of the Broyden-Fletcher-Goldfarb-Shanno optimizer. Using this approach, gate fidelities of 99.99 % can be achieved for inductive coupling and 99.9 % for capacitive coupling, with leakage being the main source of coherent errors for both approaches.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [64] [Extended Physics Informed Neural Network for Hyperbolic Two-Phase Flow in Porous Media](https://arxiv.org/abs/2511.13734)
*Saif Ur Rehman,Wajid Yousuf*

Main category: cs.LG

TL;DR: XPINN框架通过动态域分解和Rankine-Hugoniot跳跃条件，有效解决了非线性Buckley-Leverett方程中的陡峭梯度和不连续性问题，相比标准PINNs具有更好的稳定性和收敛性。


<details>
  <summary>Details</summary>
Motivation: 传统PINNs在处理非线性双曲PDEs时难以捕捉陡峭梯度、不连续性和复杂非线性波相互作用，特别是在多孔介质中两相不混溶流动的Buckley-Leverett方程中。

Method: 采用扩展物理信息神经网络(XPINN)框架，在空间和时间上动态分解计算域为冲击前和冲击后区域，使用局部子网络学习不同流动行为，并通过Rankine-Hugoniot跳跃条件实现子网络耦合。

Result: XPINN方法能够准确捕捉不连续饱和度前沿和复合波相互作用，无需人工扩散或熵修正，相比标准PINNs具有更好的稳定性、更快的收敛速度和更强的非线性波动力学分辨率。

Conclusion: XPINN框架是解决多相流问题中挑战性双曲PDEs的有效且可扩展工具，使用更小的领域特定模型和更少的可训练参数实现了优越性能。

Abstract: The accurate solution of nonlinear hyperbolic partial differential equations (PDEs) remains a central challenge in computational science due to the presence of steep gradients, discontinuities, and multiscale structures that make conventional discretization-based solvers computationally demanding. Physics-Informed Neural Networks (PINNs) embed the governing equations into the learning process, enabling mesh-free solution of PDEs, yet they often struggle to capture steep gradients, discontinuities, and complex nonlinear wave interactions. To address these limitations, this study employs the Extended Physics-Informed Neural Network (XPINN) framework to solve the nonlinear Buckley-Leverett equation with a nonconvex flux function, which models immiscible two-phase flow in porous media. The computational domain is dynamically decomposed in space and time into evolving pre-shock and post-shock regions, allowing localized subnetworks to efficiently learn distinct flow behaviors. Coupling between subnetworks is achieved through the Rankine-Hugoniot jump condition, which enforces physically consistent flux continuity across the moving shock interface. Numerical experiments demonstrate that the proposed XPINN approach accurately captures discontinuous saturation fronts and compound wave interactions without requiring artificial diffusion or entropy corrections. Compared to standard PINNs, the XPINN framework achieves superior stability, faster convergence, and enhanced resolution of nonlinear wave dynamics using smaller, domain-specific models with fewer trainable parameters, establishing it as an effective and scalable tool for solving challenging hyperbolic PDEs in multiphase flow problems. The code of this work is available on github.com/saifkhanengr/XPINN-for-Buckley-Leverett.

</details>


### [65] [Blurred Encoding for Trajectory Representation Learning](https://arxiv.org/abs/2511.13741)
*Silin Zhou,Yao Chen,Shuo Shang,Lisi Chen,Bingsheng He,Ryosuke Shibasaki*

Main category: cs.LG

TL;DR: BLUE是一种轨迹表示学习方法，通过逐步降低GPS坐标精度创建多层级补丁，在保持细粒度时空细节的同时捕获整体出行模式，在多个下游任务中平均比最佳基线方法提升30.90%的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有SOTA TRL方法将原始GPS轨迹转换为网格或道路轨迹以捕获高级出行语义，但会丢失细粒度时空细节，因为多个GPS点被分组到单个网格单元或道路段中。

Method: 提出BLUrred Encoding方法，逐步降低GPS坐标精度创建分层补丁，使用具有金字塔结构的编码器-解码器模型，每个补丁级别使用Transformer学习轨迹嵌入，通过池化和上采样在不同层级间互补。

Result: 与8种SOTA TRL方法在3个下游任务上比较，BLUE始终比所有基线方法获得更高准确率，平均比最佳基线方法提升30.90%。

Conclusion: BLUE通过分层补丁编码有效平衡了细粒度时空细节和整体出行模式的捕获，在轨迹表示学习任务中表现出色。

Abstract: Trajectory representation learning (TRL) maps trajectories to vector embeddings and facilitates tasks such as trajectory classification and similarity search. State-of-the-art (SOTA) TRL methods transform raw GPS trajectories to grid or road trajectories to capture high-level travel semantics, i.e., regions and roads. However, they lose fine-grained spatial-temporal details as multiple GPS points are grouped into a single grid cell or road segment. To tackle this problem, we propose the BLUrred Encoding method, dubbed BLUE, which gradually reduces the precision of GPS coordinates to create hierarchical patches with multiple levels. The low-level patches are small and preserve fine-grained spatial-temporal details, while the high-level patches are large and capture overall travel patterns. To complement different patch levels with each other, our BLUE is an encoder-decoder model with a pyramid structure. At each patch level, a Transformer is used to learn the trajectory embedding at the current level, while pooling prepares inputs for the higher level in the encoder, and up-resolution provides guidance for the lower level in the decoder. BLUE is trained using the trajectory reconstruction task with the MSE loss. We compare BLUE with 8 SOTA TRL methods for 3 downstream tasks, the results show that BLUE consistently achieves higher accuracy than all baselines, outperforming the best-performing baselines by an average of 30.90%. Our code is available at https://github.com/slzhou-xy/BLUE.

</details>


### [66] [DeepDefense: Layer-Wise Gradient-Feature Alignment for Building Robust Neural Networks](https://arxiv.org/abs/2511.13749)
*Ci Lin,Tet Yeap,Iluju Kiringa,Biwei Zhang*

Main category: cs.LG

TL;DR: 提出DeepDefense防御框架，通过梯度特征对齐(GFA)正则化来抑制对抗性漏洞，在多个攻击方法下显著提升模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络容易受到对抗性扰动的攻击，这些微小但精心设计的输入会导致错误预测。需要开发有效的防御方法来提高模型的安全性。

Method: 采用梯度特征对齐(GFA)正则化，在多个层面对齐输入梯度与内部特征表示，促进切线方向上更平滑的损失景观，从而减少模型对对抗性噪声的敏感性。

Result: 在CIFAR-10上，DeepDefense训练的CNN模型在APGD攻击下比标准对抗训练提升15.2%，在FGSM攻击下提升24.7%。对抗DeepFool和EADEN等优化攻击时，需要20-30倍更高的扰动幅度才能导致误分类。

Conclusion: DeepDefense是架构无关、易于实现且高效的防御方法，为提升深度学习模型的对抗鲁棒性提供了有前景的方向。

Abstract: Deep neural networks are known to be vulnerable to adversarial perturbations, which are small and carefully crafted inputs that lead to incorrect predictions. In this paper, we propose DeepDefense, a novel defense framework that applies Gradient-Feature Alignment (GFA) regularization across multiple layers to suppress adversarial vulnerability. By aligning input gradients with internal feature representations, DeepDefense promotes a smoother loss landscape in tangential directions, thereby reducing the model's sensitivity to adversarial noise.
  We provide theoretical insights into how adversarial perturbation can be decomposed into radial and tangential components and demonstrate that alignment suppresses loss variation in tangential directions, where most attacks are effective. Empirically, our method achieves significant improvements in robustness across both gradient-based and optimization-based attacks. For example, on CIFAR-10, CNN models trained with DeepDefense outperform standard adversarial training by up to 15.2% under APGD attacks and 24.7% under FGSM attacks. Against optimization-based attacks such as DeepFool and EADEN, DeepDefense requires 20 to 30 times higher perturbation magnitudes to cause misclassification, indicating stronger decision boundaries and a flatter loss landscape. Our approach is architecture-agnostic, simple to implement, and highly effective, offering a promising direction for improving the adversarial robustness of deep learning models.

</details>


### [67] [SCALEX: Scalable Concept and Latent Exploration for Diffusion Models](https://arxiv.org/abs/2511.13750)
*E. Zhixuan Zeng,Yuhao Chen,Alexander Wong*

Main category: cs.LG

TL;DR: SCALEX是一个用于扩散模型潜在空间可扩展自动化探索的框架，通过自然语言提示从H空间提取语义方向，实现零样本解释，无需重新训练或标注。


<details>
  <summary>Details</summary>
Motivation: 现有方法分析扩散模型中的社会偏见时，要么局限于预定义类别，要么依赖潜在方向的手动解释，限制了可扩展性并阻碍了发现细微或意外模式。

Method: 从H空间提取语义有意义的潜在方向，仅使用自然语言提示，实现零样本解释，无需重新训练或人工标注。

Result: SCALEX能够检测职业提示中的性别偏见，对身份描述符的语义对齐进行排序，并在无监督情况下揭示聚类概念结构。

Conclusion: 通过直接将提示与潜在方向关联，SCALEX使扩散模型中的偏见分析比先前方法更具可扩展性、可解释性和可扩展性。

Abstract: Image generation models frequently encode social biases, including stereotypes tied to gender, race, and profession. Existing methods for analyzing these biases in diffusion models either focus narrowly on predefined categories or depend on manual interpretation of latent directions. These constraints limit scalability and hinder the discovery of subtle or unanticipated patterns.
  We introduce SCALEX, a framework for scalable and automated exploration of diffusion model latent spaces. SCALEX extracts semantically meaningful directions from H-space using only natural language prompts, enabling zero-shot interpretation without retraining or labelling. This allows systematic comparison across arbitrary concepts and large-scale discovery of internal model associations. We show that SCALEX detects gender bias in profession prompts, ranks semantic alignment across identity descriptors, and reveals clustered conceptual structure without supervision. By linking prompts to latent directions directly, SCALEX makes bias analysis in diffusion models more scalable, interpretable, and extensible than prior approaches.

</details>


### [68] [Enforcing hidden physics in physics-informed neural networks](https://arxiv.org/abs/2511.14348)
*Nanxi Chen,Sifan Wang,Rujin Ma,Airong Chen,Chuanjie Cui*

Main category: cs.LG

TL;DR: 提出了一个简单、通用且鲁棒的不可逆性正则化策略，将热力学第二定律隐含的不可逆性作为软约束融入PINNs训练，显著提升物理一致性。


<details>
  <summary>Details</summary>
Motivation: 传统PINNs在训练过程中经常忽略热力学第二定律隐含的不可逆性，导致非物理解或训练失败，需要一种方法来强制遵守物理过程的单向本质。

Method: 引入不可逆性正则化策略，将隐藏的物理定律作为软约束在训练中强制执行，仅需对现有PINN框架进行最小修改。

Result: 在多种基准测试中，该方法将预测误差降低了一个数量级以上，确保学习到的解始终尊重不可逆物理过程的内在单向性。

Conclusion: 该框架广泛适用于PDE控制的物理系统，将在科学机器学习社区产生重要影响。

Abstract: Physics-informed neural networks (PINNs) represent a new paradigm for solving partial differential equations (PDEs) by integrating physical laws into the learning process of neural networks. However, despite their foundational role, the hidden irreversibility implied by the Second Law of Thermodynamics is often neglected during training, leading to unphysical solutions or even training failures in conventional PINNs. In this paper, we identify this critical gap and introduce a simple, generalized, yet robust irreversibility-regularized strategy that enforces hidden physical laws as soft constraints during training. This approach ensures that the learned solutions consistently respect the intrinsic one-way nature of irreversible physical processes. Across a wide range of benchmarks spanning traveling wave propagation, steady combustion, ice melting, corrosion evolution, and crack propagation, we demonstrate that our regularization scheme reduces predictive errors by more than an order of magnitude, while requiring only minimal modification to existing PINN frameworks. We believe that the proposed framework is broadly applicable to a wide class of PDE-governed physical systems and will have significant impact within the scientific machine learning community.

</details>


### [69] [Motor Imagery Classification Using Feature Fusion of Spatially Weighted Electroencephalography](https://arxiv.org/abs/2511.13752)
*Abdullah Al Shiam,Md. Khademul Islam Molla,Abu Saleh Musa Miah,Md. Abdus Samad Kamal*

Main category: cs.LG

TL;DR: 提出了一种基于脑区特定通道选择和多域特征融合的脑机接口方法，通过按功能脑区分组EEG通道，结合CSP、模糊C均值聚类和切线空间映射三种特征提取方法，使用SVM分类器在公开数据集上取得了90.77%和84.50%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 由于EEG信号的多通道特性，需要显式信息处理来降低BCI系统的计算复杂度，同时提高运动想象任务的分类准确性。

Method: 基于脑区功能相关性的通道选择策略，将EEG通道按脑功能区域分组，然后对每组通道分别应用CSP（空间模式）、模糊C均值聚类（数据聚类）和TSM（非线性模式）三种特征提取方法，最后使用SVM进行多分类。

Result: 在BCI竞赛III和IV的公开数据集IVA和I上验证，分别达到90.77%和84.50%的分类准确率，优于现有方法。

Conclusion: 该方法通过脑区特定通道选择和多种特征融合，有效提高了运动想象BCI系统的分类性能，同时降低了计算复杂度。

Abstract: A Brain Computer Interface (BCI) connects the human brain to the outside world, providing a direct communication channel. Electroencephalography (EEG) signals are commonly used in BCIs to reflect cognitive patterns related to motor function activities. However, due to the multichannel nature of EEG signals, explicit information processing is crucial to lessen computational complexity in BCI systems. This study proposes an innovative method based on brain region-specific channel selection and multi-domain feature fusion to improve classification accuracy. The novelty of the proposed approach lies in region-based channel selection, where EEG channels are grouped according to their functional relevance to distinct brain regions. By selecting channels based on specific regions involved in motor imagery (MI) tasks, this technique eliminates irrelevant channels, reducing data dimensionality and improving computational efficiency. This also ensures that the extracted features are more reflective of the brain actual activity related to motor tasks. Three distinct feature extraction methods Common Spatial Pattern (CSP), Fuzzy C-means clustering, and Tangent Space Mapping (TSM), are applied to each group of channels based on their brain region. Each method targets different characteristics of the EEG signal: CSP focuses on spatial patterns, Fuzzy C means identifies clusters within the data, and TSM captures non-linear patterns in the signal. The combined feature vector is used to classify motor imagery tasks (left hand, right hand, and right foot) using Support Vector Machine (SVM). The proposed method was validated on publicly available benchmark EEG datasets (IVA and I) from the BCI competition III and IV. The results show that the approach outperforms existing methods, achieving classification accuracies of 90.77% and 84.50% for datasets IVA and I, respectively.

</details>


### [70] [MiAD: Mirage Atom Diffusion for De Novo Crystal Generation](https://arxiv.org/abs/2511.14426)
*Andrey Okhotin,Maksim Nakhodnov,Nikita Kazeev,Andrey E Ustyuzhanin,Dmitry Vetrov*

Main category: cs.LG

TL;DR: 提出了Mirage Atom Diffusion (MiAD)模型，通过mirage infusion技术让扩散模型能够在晶体生成过程中改变原子数量，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型在晶体材料生成过程中无法改变原子数量，这限制了采样轨迹的多样性。

Method: 引入mirage infusion技术，允许原子状态在存在和非存在之间转换，构建了能够改变原子数量的等变联合扩散模型MiAD。

Result: 模型质量提升达2.5倍，在MP-20数据集上达到8.2%的S.U.N.率，大幅超越现有最优方法。

Conclusion: MiAD通过允许原子数量变化，显著提升了扩散模型在晶体材料生成中的性能，为材料发现提供了更强大的工具。

Abstract: In recent years, diffusion-based models have demonstrated exceptional performance in searching for simultaneously stable, unique, and novel (S.U.N.) crystalline materials. However, most of these models don't have the ability to change the number of atoms in the crystal during the generation process, which limits the variability of model sampling trajectories. In this paper, we demonstrate the severity of this restriction and introduce a simple yet powerful technique, mirage infusion, which enables diffusion models to change the state of the atoms that make up the crystal from existent to non-existent (mirage) and vice versa. We show that this technique improves model quality by up to $\times2.5$ compared to the same model without this modification. The resulting model, Mirage Atom Diffusion (MiAD), is an equivariant joint diffusion model for de novo crystal generation that is capable of altering the number of atoms during the generation process. MiAD achieves an $8.2\%$ S.U.N. rate on the MP-20 dataset, which substantially exceeds existing state-of-the-art approaches. The source code can be found at \href{https://github.com/andrey-okhotin/miad.git}{\texttt{github.com/andrey-okhotin/miad}}.

</details>


### [71] [Robustness of LLM-enabled vehicle trajectory prediction under data security threats](https://arxiv.org/abs/2511.13753)
*Feilong Wang,Fuqiang Liu*

Main category: cs.LG

TL;DR: 本文首次系统分析了基于大语言模型的车辆轨迹预测系统的对抗脆弱性，发现即使微小的物理可行扰动也能显著破坏模型输出，揭示了LLM驱动的自动驾驶系统在安全关键应用中的鲁棒性隐患。


<details>
  <summary>Details</summary>
Motivation: 尽管微调后的LLM在车辆轨迹预测方面表现出色，但其在安全关键驾驶系统中的鲁棒性尚未得到研究，而LLM的可信度问题日益受到关注。

Method: 提出单特征差分进化攻击方法，在黑盒设置下扰动周围车辆的单个运动学特征，使用highD数据集进行实验分析。

Result: 实验表明，即使微小且物理可行的扰动也能显著破坏模型输出，揭示了LLM预测器对对抗性操纵的敏感性，并发现准确性与鲁棒性之间存在权衡。

Conclusion: 研究首次揭示了LLM驱动自动驾驶模型在车辆交互场景中的对抗脆弱性，强调了未来基于LLM的智能交通系统需要面向鲁棒性进行设计。

Abstract: The integration of large language models (LLMs) into automated driving systems has opened new possibilities for reasoning and decision-making by transforming complex driving contexts into language-understandable representations. Recent studies demonstrate that fine-tuned LLMs can accurately predict vehicle trajectories and lane-change intentions by gathering and transforming data from surrounding vehicles. However, the robustness of such LLM-based prediction models for safety-critical driving systems remains unexplored, despite the increasing concerns about the trustworthiness of LLMs. This study addresses this gap by conducting a systematic vulnerability analysis of LLM-enabled vehicle trajectory prediction. We propose a one-feature differential evolution attack that perturbs a single kinematic feature of surrounding vehicles within the LLM's input prompts under a black-box setting. Experiments on the highD dataset reveal that even minor, physically plausible perturbations can significantly disrupt model outputs, underscoring the susceptibility of LLM-based predictors to adversarial manipulation. Further analyses reveal a trade-off between accuracy and robustness, examine the failure mechanism, and explore potential mitigation solutions. The findings provide the very first insights into adversarial vulnerabilities of LLM-driven automated vehicle models in the context of vehicular interactions and highlight the need for robustness-oriented design in future LLM-based intelligent transportation systems.

</details>


### [72] [Adaptive Redundancy Regulation for Balanced Multimodal Information Refinement](https://arxiv.org/abs/2511.13755)
*Zhe Yang,Wenrui Li,Hongtao Chen,Penghong Wang,Ruiqin Xiong,Xiaopeng Fan*

Main category: cs.LG

TL;DR: 提出RedReg方法解决多模态学习中模态偏差问题，通过自适应冗余调节实现平衡的多模态信息精炼


<details>
  <summary>Details</summary>
Motivation: 多模态学习中优势模态主导反向传播导致优化不平衡，现有方法存在两个问题：1）优势模态长期主导削弱表示-输出耦合，导致冗余信息积累；2）直接统一调整优势模态梯度，忽略模态间语义和方向性

Method: 基于信息瓶颈原理，构建冗余阶段监控器，结合有效增益增长率和冗余度触发干预；设计共信息门控机制评估优势模态贡献；将优势模态梯度投影到联合多模态梯度子空间的正交补空间，根据冗余度抑制梯度

Result: 实验表明该方法在大多数场景下优于当前主流方法，消融实验验证了方法的有效性

Conclusion: RedReg方法能有效解决多模态学习中的模态偏差问题，实现更平衡的多模态信息精炼

Abstract: Multimodal learning aims to improve performance by leveraging data from multiple sources. During joint multimodal training, due to modality bias, the advantaged modality often dominates backpropagation, leading to imbalanced optimization. Existing methods still face two problems: First, the long-term dominance of the dominant modality weakens representation-output coupling in the late stages of training, resulting in the accumulation of redundant information. Second, previous methods often directly and uniformly adjust the gradients of the advantaged modality, ignoring the semantics and directionality between modalities. To address these limitations, we propose Adaptive Redundancy Regulation for Balanced Multimodal Information Refinement (RedReg), which is inspired by information bottleneck principle. Specifically, we construct a redundancy phase monitor that uses a joint criterion of effective gain growth rate and redundancy to trigger intervention only when redundancy is high. Furthermore, we design a co-information gating mechanism to estimate the contribution of the current dominant modality based on cross-modal semantics. When the task primarily relies on a single modality, the suppression term is automatically disabled to preserve modality-specific information. Finally, we project the gradient of the dominant modality onto the orthogonal complement of the joint multimodal gradient subspace and suppress the gradient according to redundancy. Experiments show that our method demonstrates superiority among current major methods in most scenarios. Ablation experiments verify the effectiveness of our method. The code is available at https://github.com/xia-zhe/RedReg.git

</details>


### [73] [Multi-Horizon Time Series Forecasting of non-parametric CDFs with Deep Lattice Networks](https://arxiv.org/abs/2511.13756)
*Niklas Erdmann,Lars Bentsen,Roy Stenbro,Heine Nygard Riise,Narada Dilp Warakagoda,Paal E. Engelstad*

Main category: cs.LG

TL;DR: 提出了一种基于深度格网络的非参数概率预测方法，通过单调约束防止分位数交叉，实现隐式完整累积分布函数的预测。


<details>
  <summary>Details</summary>
Motivation: 概率预测能捕捉时间序列中的突变，而传统参数方法限制了CDF建模。本文旨在连接概率预测和单调网络领域，实现非参数CDF预测。

Method: 采用深度格网络(DLN)结合LSTM嵌入层，通过扩展输出尺寸和单调约束防止分位数交叉，实现多时间步长的隐式CDF预测。

Result: 在太阳辐照度预测实验中，该方法表现优于无约束方法和可扩展单调神经网络，性能相当或更好。

Conclusion: DLN的适应性改进为单调神经网络和概率预测技术的交叉研究开辟了新方向，具有良好应用前景。

Abstract: Probabilistic forecasting is not only a way to add more information to a prediction of the future, but it also builds on weaknesses in point prediction. Sudden changes in a time series can still be captured by a cumulative distribution function (CDF), while a point prediction is likely to miss it entirely. The modeling of CDFs within forecasts has historically been limited to parametric approaches, but due to recent advances, this no longer has to be the case. We aim to advance the fields of probabilistic forecasting and monotonic networks by connecting them and propose an approach that permits the forecasting of implicit, complete, and nonparametric CDFs. For this purpose, we propose an adaptation to deep lattice networks (DLN) for monotonically constrained simultaneous/implicit quantile regression in time series forecasting. Quantile regression usually produces quantile crossovers, which need to be prevented to achieve a legitimate CDF. By leveraging long short term memory units (LSTM) as the embedding layer, and spreading quantile inputs to all sub-lattices of a DLN with an extended output size, we can produce a multi-horizon forecast of an implicit CDF due to the monotonic constraintability of DLNs that prevent quantile crossovers. We compare and evaluate our approach's performance to relevant state of the art within the context of a highly relevant application of time series forecasting: Day-ahead, hourly forecasts of solar irradiance observations. Our experiments show that the adaptation of a DLN performs just as well or even better than an unconstrained approach. Further comparison of the adapted DLN against a scalable monotonic neural network shows that our approach performs better. With this adaptation of DLNs, we intend to create more interest and crossover investigations in techniques of monotonic neural networks and probabilistic forecasting.

</details>


### [74] [VitalBench: A Rigorous Multi-Center Benchmark for Long-Term Vital Sign Prediction in Intraoperative Care](https://arxiv.org/abs/2511.13757)
*Xiuding Cai,Xueyao Wang,Sen Wang,Yaoyao Zhu,Jiao Chen,Yu Yao*

Main category: cs.LG

TL;DR: VitalBench是一个专门用于术中生命体征预测的新基准，包含来自两个独立医疗中心的4000多例手术数据，提供完整数据、不完整数据和跨中心泛化三个评估轨道，旨在解决现有深度学习方法在标准化基准、数据不完整和跨中心验证方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决术中生命体征预测领域缺乏标准化基准、数据不完整和跨中心验证有限的问题，以提升患者安全和手术结果。

Method: 构建包含4000多例手术数据的VitalBench基准，提供三个评估轨道，采用掩码损失技术进行稳健和无偏的模型评估，最小化对广泛预处理的依赖。

Result: 开发了一个标准化和统一的平台，使研究人员能够专注于架构创新，同时确保数据处理的一致性，为推进术中生命体征预测模型奠定了基础。

Conclusion: VitalBench为术中生命体征预测提供了一个标准化基准，确保模型不仅准确，而且在多样化的临床环境中具有稳健性和适应性。

Abstract: Intraoperative monitoring and prediction of vital signs are critical for ensuring patient safety and improving surgical outcomes. Despite recent advances in deep learning models for medical time-series forecasting, several challenges persist, including the lack of standardized benchmarks, incomplete data, and limited cross-center validation. To address these challenges, we introduce VitalBench, a novel benchmark specifically designed for intraoperative vital sign prediction. VitalBench includes data from over 4,000 surgeries across two independent medical centers, offering three evaluation tracks: complete data, incomplete data, and cross-center generalization. This framework reflects the real-world complexities of clinical practice, minimizing reliance on extensive preprocessing and incorporating masked loss techniques for robust and unbiased model evaluation. By providing a standardized and unified platform for model development and comparison, VitalBench enables researchers to focus on architectural innovation while ensuring consistency in data handling. This work lays the foundation for advancing predictive models for intraoperative vital sign forecasting, ensuring that these models are not only accurate but also robust and adaptable across diverse clinical environments. Our code and data are available at https://github.com/XiudingCai/VitalBench.

</details>


### [75] [ChemFixer: Correcting Invalid Molecules to Unlock Previously Unseen Chemical Space](https://arxiv.org/abs/2511.13758)
*Jun-Hyoung Park,Ho-Jun Song,Seong-Whan Lee*

Main category: cs.LG

TL;DR: ChemFixer是一个基于transformer的框架，用于将深度学习分子生成模型产生的无效分子修正为有效分子，提高分子有效性同时保持化学和生物学分布特性。


<details>
  <summary>Details</summary>
Motivation: 深度学习分子生成模型经常产生化学无效分子，限制了学习到的化学空间的可使用范围，给实际应用带来挑战。

Method: 基于transformer架构，使用掩码技术进行预训练，并在构建的大规模有效/无效分子对数据集上进行微调。

Result: ChemFixer提高了分子有效性，有效保持了原始输出的化学和生物分布特性，在数据有限的药物-靶点相互作用预测任务中也表现良好。

Conclusion: ChemFixer有望成为深度学习药物发现各阶段的实用工具，增强分子有效性并扩展可访问的化学空间。

Abstract: Deep learning-based molecular generation models have shown great potential in efficiently exploring vast chemical spaces by generating potential drug candidates with desired properties. However, these models often produce chemically invalid molecules, which limits the usable scope of the learned chemical space and poses significant challenges for practical applications. To address this issue, we propose ChemFixer, a framework designed to correct invalid molecules into valid ones. ChemFixer is built on a transformer architecture, pre-trained using masking techniques, and fine-tuned on a large-scale dataset of valid/invalid molecular pairs that we constructed. Through comprehensive evaluations across diverse generative models, ChemFixer improved molecular validity while effectively preserving the chemical and biological distributional properties of the original outputs. This indicates that ChemFixer can recover molecules that could not be previously generated, thereby expanding the diversity of potential drug candidates. Furthermore, ChemFixer was effectively applied to a drug-target interaction (DTI) prediction task using limited data, improving the validity of generated ligands and discovering promising ligand-protein pairs. These results suggest that ChemFixer is not only effective in data-limited scenarios, but also extensible to a wide range of downstream tasks. Taken together, ChemFixer shows promise as a practical tool for various stages of deep learning-based drug discovery, enhancing molecular validity and expanding accessible chemical space.

</details>


### [76] [Multi-Agent VLMs Guided Self-Training with PNU Loss for Low-Resource Offensive Content Detection](https://arxiv.org/abs/2511.13759)
*Han Wang,Deyi Ji,Junyu Lu,Lanyun Zhu,Hailong Zhang,Haiyang Wu,Liqun Liu,Peng Shu,Roy Ka-Wei Lee*

Main category: cs.LG

TL;DR: 提出了一种自训练框架，通过多智能体视觉语言模型进行协作伪标注，利用大量未标注数据来解决社交媒体冒犯内容检测中的低资源问题。


<details>
  <summary>Details</summary>
Motivation: 社交媒体冒犯内容检测需要高质量标注数据，但由于冒犯实例稀少且人工标注成本高，这类数据往往稀缺。

Method: 使用轻量级分类器和多智能体视觉语言模型进行迭代伪标注，创建一致未知集和分歧未知集，采用正-负-未标注损失函数优化分类器。

Result: 在基准数据集上的实验表明，该框架在有限监督下显著优于基线方法，并接近大规模模型的性能。

Conclusion: 所提出的自训练框架有效解决了低资源场景下的冒犯内容检测问题，通过利用未标注数据和协作伪标注实现了接近大规模模型的性能。

Abstract: Accurate detection of offensive content on social media demands high-quality labeled data; however, such data is often scarce due to the low prevalence of offensive instances and the high cost of manual annotation. To address this low-resource challenge, we propose a self-training framework that leverages abundant unlabeled data through collaborative pseudo-labeling. Starting with a lightweight classifier trained on limited labeled data, our method iteratively assigns pseudo-labels to unlabeled instances with the support of Multi-Agent Vision-Language Models (MA-VLMs). Un-labeled data on which the classifier and MA-VLMs agree are designated as the Agreed-Unknown set, while conflicting samples form the Disagreed-Unknown set. To enhance label reliability, MA-VLMs simulate dual perspectives, moderator and user, capturing both regulatory and subjective viewpoints. The classifier is optimized using a novel Positive-Negative-Unlabeled (PNU) loss, which jointly exploits labeled, Agreed-Unknown, and Disagreed-Unknown data while mitigating pseudo-label noise. Experiments on benchmark datasets demonstrate that our framework substantially outperforms baselines under limited supervision and approaches the performance of large-scale models

</details>


### [77] [MoETTA: Test-Time Adaptation Under Mixed Distribution Shifts with MoE-LayerNorm](https://arxiv.org/abs/2511.13760)
*Xiao Fan,Jingyan Jiang,Zhaoru Chen,Fanding Huang,Xiao Chen,Qinting Jiang,Bowen Zhang,Xing Tang,Zhi Wang*

Main category: cs.LG

TL;DR: MoETTA是一种基于熵的测试时自适应框架，通过集成混合专家架构来处理混合分布偏移问题，在多个基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界部署中常遇到混合分布偏移，现有TTA方法依赖统一的适应路径，无法处理不同域间可能冲突的最优梯度方向，且当前基准测试仅关注合成或同质偏移。

Method: 提出MoETTA框架，集成混合专家架构，引入结构解耦的专家集合，使模型能够沿不同梯度方向进行适应，支持灵活和分离的参数更新。

Result: 在三个混合分布偏移设置下的广泛实验表明，MoETTA始终优于强基线方法，建立了最先进的性能。

Conclusion: 通过专家级多样性建模多个适应方向具有显著优势，MoETTA能够更好地适应异构偏移，提高在现实部署条件下的鲁棒性。

Abstract: Test-Time adaptation (TTA) has proven effective in mitigating performance drops under single-domain distribution shifts by updating model parameters during inference. However, real-world deployments often involve mixed distribution shifts, where test samples are affected by diverse and potentially conflicting domain factors, posing significant challenges even for SOTA TTA methods. A key limitation in existing approaches is their reliance on a unified adaptation path, which fails to account for the fact that optimal gradient directions can vary significantly across different domains. Moreover, current benchmarks focus only on synthetic or homogeneous shifts, failing to capture the complexity of real-world heterogeneous mixed distribution shifts. To address this, we propose MoETTA, a novel entropy-based TTA framework that integrates the Mixture-of-Experts (MoE) architecture. Rather than enforcing a single parameter update rule for all test samples, MoETTA introduces a set of structurally decoupled experts, enabling adaptation along diverse gradient directions. This design allows the model to better accommodate heterogeneous shifts through flexible and disentangled parameter updates. To simulate realistic deployment conditions, we introduce two new benchmarks: potpourri and potpourri+. While classical settings focus solely on synthetic corruptions, potpourri encompasses a broader range of domain shifts--including natural, artistic, and adversarial distortions--capturing more realistic deployment challenges. Additionally, potpourri+ further includes source-domain samples to evaluate robustness against catastrophic forgetting. Extensive experiments across three mixed distribution shifts settings show that MoETTA consistently outperforms strong baselines, establishing SOTA performance and highlighting the benefit of modeling multiple adaptation directions via expert-level diversity.

</details>


### [78] [Gene Incremental Learning for Single-Cell Transcriptomics](https://arxiv.org/abs/2511.13762)
*Jiaxin Qi,Yan Cui,Jianqiang Huang,Gaogang Xie*

Main category: cs.LG

TL;DR: 该研究首次在单细胞转录组学中构建了基因增量学习框架，将类别增量学习方法应用于基因标记，解决了基因遗忘问题并建立了完整基准。


<details>
  <summary>Details</summary>
Motivation: 虽然类别在计算机视觉的增量学习中已被广泛研究，但标记（如基因）的增量学习研究严重不足，主要因为语言标记的整体性特征给增量学习框架设计带来挑战。

Method: 转向生物学数据集中的基因标记，构建基因增量学习流程，并适配现有的类别增量学习方法来减轻基因遗忘问题。

Result: 通过大量实验验证了框架设计和评估的合理性，以及方法适配的有效性，证明基因增量学习中也存在遗忘问题。

Conclusion: 为单细胞转录组学中的基因增量学习提供了完整的基准，展示了框架设计的合理性和方法适配的有效性。

Abstract: Classes, as fundamental elements of Computer Vision, have been extensively studied within incremental learning frameworks. In contrast, tokens, which play essential roles in many research fields, exhibit similar characteristics of growth, yet investigations into their incremental learning remain significantly scarce. This research gap primarily stems from the holistic nature of tokens in language, which imposes significant challenges on the design of incremental learning frameworks for them. To overcome this obstacle, in this work, we turn to a type of token, gene, for a large-scale biological dataset--single-cell transcriptomics--to formulate a pipeline for gene incremental learning and establish corresponding evaluations. We found that the forgetting problem also exists in gene incremental learning, thus we adapted existing class incremental learning methods to mitigate the forgetting of genes. Through extensive experiments, we demonstrated the soundness of our framework design and evaluations, as well as the effectiveness of our method adaptations. Finally, we provide a complete benchmark for gene incremental learning in single-cell transcriptomics.

</details>


### [79] [Library Liberation: Competitive Performance Matmul Through Compiler-composed Nanokernels](https://arxiv.org/abs/2511.13764)
*Arun Thangamani,Md Asghar Ahmad Shahid,Adam Siemieniuk,Rolf Morel,Renato Golin,Alexander Heinecke*

Main category: cs.LG

TL;DR: 本文提出了一种基于MLIR的编译方案，能够自动生成可扩展的高性能微内核，无需依赖底层库，通过组合纳米内核实现接近最优的寄存器利用。


<details>
  <summary>Details</summary>
Motivation: AI和机器学习工作负载快速发展，导致高层领域操作与高效硬件利用之间存在差距。实现接近峰值性能需要深度硬件专业知识，这增加了复杂性并限制了大多数ML从业者的可扩展性。

Method: 利用MLIR方言桥接领域级操作和处理器能力，通过组合低层IR构造的纳米内核形成高效的微内核，支持向量和基于tile的CPU指令。

Result: 实验表明生成的纳米内核达到生产质量，与最先进的微内核库具有竞争力。

Conclusion: 该编译方案能够自动生成高性能微内核，减少对底层库的依赖，为ML从业者提供了更易用和可扩展的解决方案。

Abstract: The rapidly evolving landscape of AI and machine learning workloads has widened the gap between high-level domain operations and efficient hardware utilization. Achieving near-peak performance still demands deep hardware expertise-experts either handcraft target-specific kernels (e.g., DeepSeek) or rely on specialized libraries (e.g., CUTLASS)-both of which add complexity and limit scalability for most ML practitioners.
  This paper introduces a compilation scheme that automatically generates scalable, high-performance microkernels by leveraging the MLIR dialects to bridge domain-level operations and processor capabilities. Our approach removes dependence on low-level libraries by enabling the compiler to auto-generate near-optimal code directly. At its core is a mechanism for composing nanokernels from low-level IR constructs with near-optimal register utilization, forming efficient microkernels tailored to each target. We implement this technique in an MLIR-based compiler supporting both vector and tile based CPU instructions. Experiments show that the generated nanokernels are of production-quality, and competitive with state-of-the-art microkernel libraries.

</details>


### [80] [PROF: An LLM-based Reward Code Preference Optimization Framework for Offline Imitation Learning](https://arxiv.org/abs/2511.13765)
*Shengjie Sun,Jiafei Lyu,Runze Liu,Mengbei Yan,Bo Liu,Deheng Ye,Xiu Li*

Main category: cs.LG

TL;DR: PROF：利用LLM从自然语言描述和专家轨迹生成可执行奖励函数代码的离线模仿学习框架，通过奖励偏好排序自动选择和优化奖励函数。


<details>
  <summary>Details</summary>
Motivation: 现有离线IL方法假设轨迹与专家演示的相似度与奖励正相关，这过度简化了奖励结构。需要更准确地估计未标记数据集的奖励。

Method: 提出PROF框架：1) 使用LLM从自然语言和专家轨迹生成奖励函数代码；2) 提出RPR策略评估奖励函数质量；3) 交替进行RPR和基于文本的梯度优化，自动选择和优化奖励函数。

Result: 在D4RL基准测试中，PROF在多个数据集和领域上超越或匹配了最近的强基线方法。

Conclusion: PROF通过自动化奖励函数生成和优化，有效提升了离线模仿学习的性能，证明了该方法的有效性。

Abstract: Offline imitation learning (offline IL) enables training effective policies without requiring explicit reward annotations. Recent approaches attempt to estimate rewards for unlabeled datasets using a small set of expert demonstrations. However, these methods often assume that the similarity between a trajectory and an expert demonstration is positively correlated with the reward, which oversimplifies the underlying reward structure. We propose PROF, a novel framework that leverages large language models (LLMs) to generate and improve executable reward function codes from natural language descriptions and a single expert trajectory. We propose Reward Preference Ranking (RPR), a novel reward function quality assessment and ranking strategy without requiring environment interactions or RL training. RPR calculates the dominance scores of the reward functions, where higher scores indicate better alignment with expert preferences. By alternating between RPR and text-based gradient optimization, PROF fully automates the selection and refinement of optimal reward functions for downstream policy learning. Empirical results on D4RL demonstrate that PROF surpasses or matches recent strong baselines across numerous datasets and domains, highlighting the effectiveness of our approach.

</details>


### [81] [Credal Ensemble Distillation for Uncertainty Quantification](https://arxiv.org/abs/2511.13766)
*Kaizheng Wang,Fabio Cuzzolin,David Moens,Hans Hallez*

Main category: cs.LG

TL;DR: 提出了一种称为信用集成蒸馏（CED）的新框架，将深度集成压缩为单一模型CREDIT，用于分类任务中的不确定性量化，显著降低推理开销。


<details>
  <summary>Details</summary>
Motivation: 深度集成在不确定性量化方面表现出色，但其高计算和内存成本限制了实际部署。需要一种方法在保持不确定性估计质量的同时显著降低推理开销。

Method: 通过信用集成蒸馏将深度集成压缩为单一模型CREDIT。CREDIT预测类间概率区间而非单一softmax分布，这些区间定义了一个信用集（概率分布的凸集）用于不确定性量化。

Result: 在分布外检测基准测试中，CED实现了优于或可与多个现有基线相媲美的不确定性估计，同时相比深度集成显著降低了推理开销。

Conclusion: CED框架成功地将深度集成的优势压缩到单一模型中，在保持高质量不确定性估计的同时大幅减少了计算和内存需求，为实际部署提供了可行方案。

Abstract: Deep ensembles (DE) have emerged as a powerful approach for quantifying predictive uncertainty and distinguishing its aleatoric and epistemic components, thereby enhancing model robustness and reliability. However, their high computational and memory costs during inference pose significant challenges for wide practical deployment. To overcome this issue, we propose credal ensemble distillation (CED), a novel framework that compresses a DE into a single model, CREDIT, for classification tasks. Instead of a single softmax probability distribution, CREDIT predicts class-wise probability intervals that define a credal set, a convex set of probability distributions, for uncertainty quantification. Empirical results on out-of-distribution detection benchmarks demonstrate that CED achieves superior or comparable uncertainty estimation compared to several existing baselines, while substantially reducing inference overhead compared to DE.

</details>


### [82] [Dynamic Temperature Scheduler for Knowledge Distillation](https://arxiv.org/abs/2511.13767)
*Sibgat Ul Islam,Jawad Ibn Ahad,Fuad Rahman,Mohammad Ruhul Amin,Nabeel Mohammed,Shafin Rahman*

Main category: cs.LG

TL;DR: 提出动态温度调度器（DTS），根据师生模型之间的交叉熵损失差距动态调整知识蒸馏中的温度参数，优于传统的固定温度方法。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏使用固定温度参数，但师生模型架构差异导致logit幅度不匹配，且训练不同阶段需要不同软度的概率分布。

Method: DTS方法基于师生模型交叉熵损失差距动态调整温度，早期使用较软概率，后期使用较锐利概率，可与现有KD框架无缝集成。

Result: 在视觉（CIFAR-100、Tiny-ImageNet）和NLP（GLUE、Dolly等）任务上验证，DTS在多种KD策略中均优于静态温度基线。

Conclusion: DTS是首个基于师生分布差异自适应调整温度的调度方法，能有效提升知识蒸馏性能。

Abstract: Knowledge Distillation (KD) trains a smaller student model using a large, pre-trained teacher model, with temperature as a key hyperparameter controlling the softness of output probabilities. Traditional methods use a fixed temperature throughout training, which is suboptimal. Moreover, architectural differences between teacher and student often result in mismatched logit magnitudes. We demonstrate that students benefit from softer probabilities early in training but require sharper probabilities in later stages. We introduce Dynamic Temperature Scheduler (DTS), which adjusts temperature dynamically based on the cross-entropy loss gap between teacher and student. To our knowledge, this is the first temperature scheduling method that adapts based on the divergence between teacher and student distributions. Our method integrates seamlessly with existing KD frameworks. We validate DTS across multiple KD strategies on vision (CIFAR-100, Tiny-ImageNet) and NLP tasks (GLUE, Dolly, SelfIns, UnNI, S-NI), consistently outperforming static-temperature baselines. Code is available at https://github.com/Sibgat-Ul/DTS.

</details>


### [83] [Compiling to linear neurons](https://arxiv.org/abs/2511.13769)
*Joey Velez-Ginorio,Nada Amin,Konrad Kording,Steve Zdancewic*

Main category: cs.LG

TL;DR: Cajal是一个类型化、高阶线性编程语言，旨在直接编程神经网络，将离散算法编译为线性神经元，实现与基于梯度学习算法的兼容。


<details>
  <summary>Details</summary>
Motivation: 当前神经网络编程采用间接方式，依赖学习算法从数据中学习，但缺乏离散结构，无法将大多数算法编译到神经网络中，限制了算法与学习的结合。

Method: 开发Cajal编程语言，证明其程序可编译为线性神经元，使离散算法能以可微分形式表达，兼容基于梯度的学习算法。

Result: 实验表明，将线性神经元与其他神经网络链接，可在学习前确定部分函数，使网络学习更快、数据效率更高且更易调试。

Conclusion: 线性编程语言为直接编程神经网络提供了途径，实现了学习与普通编程离散结构之间的丰富交互。

Abstract: We don't program neural networks directly. Instead, we rely on an indirect style where learning algorithms, like gradient descent, determine a neural network's function by learning from data. This indirect style is often a virtue; it empowers us to solve problems that were previously impossible. But it lacks discrete structure. We can't compile most algorithms into a neural network -- even if these algorithms could help the network learn. This limitation occurs because discrete algorithms are not obviously differentiable, making them incompatible with the gradient-based learning algorithms that determine a neural network's function. To address this, we introduce $\textsf{Cajal}$: a typed, higher-order and linear programming language intended to be a minimal vehicle for exploring a direct style of programming neural networks. We prove $\textsf{Cajal}$ programs compile to linear neurons, allowing discrete algorithms to be expressed in a differentiable form compatible with gradient-based learning. With our implementation of $\textsf{Cajal}$, we conduct several experiments where we link these linear neurons against other neural networks to determine part of their function prior to learning. Linking with these neurons allows networks to learn faster, with greater data-efficiency, and in a way that's easier to debug. A key lesson is that linear programming languages provide a path towards directly programming neural networks, enabling a rich interplay between learning and the discrete structures of ordinary programming.

</details>


### [84] [Self-Attention as Distributional Projection: A Unified Interpretation of Transformer Architecture](https://arxiv.org/abs/2511.13780)
*Nihal Mehta*

Main category: cs.LG

TL;DR: 本文从分布语义学角度对自注意力机制进行数学解释，证明自注意力是从语料级共现统计到序列上下文的投影结果。


<details>
  <summary>Details</summary>
Motivation: 揭示Transformer架构中自注意力机制的理论基础，证明其特定代数形式来源于投影原理而非任意设计选择。

Method: 从GloVe嵌入的共现矩阵出发，展示投影如何自然捕获上下文影响，并推导出查询-键-值机制作为建模方向关系的自然非对称扩展。

Result: 证明了位置编码和多头注意力都是同一投影原理的结构化改进，自注意力机制是从语料统计到序列上下文的投影结果。

Conclusion: Transformer架构的特定代数形式遵循投影原理，而非任意设计选择，为自注意力机制提供了数学理论基础。

Abstract: This paper presents a mathematical interpretation of self-attention by connecting it to distributional semantics principles. We show that self-attention emerges from projecting corpus-level co-occurrence statistics into sequence context. Starting from the co-occurrence matrix underlying GloVe embeddings, we demonstrate how the projection naturally captures contextual influence, with the query-key-value mechanism arising as the natural asymmetric extension for modeling directional relationships. Positional encodings and multi-head attention then follow as structured refinements of this same projection principle. Our analysis demonstrates that the Transformer architecture's particular algebraic form follows from these projection principles rather than being an arbitrary design choice.

</details>


### [85] [Exploring Transferability of Self-Supervised Learning by Task Conflict Calibration](https://arxiv.org/abs/2511.13787)
*Huijie Guo,Jingyao Wang,Peizheng Guo,Xingchen Shen,Changwen Zheng,Wenwen Qiang*

Main category: cs.LG

TL;DR: 本文研究了自监督学习（SSL）的可迁移性，提出了任务冲突校准（TC²）方法来提升SSL表示的可迁移性，通过多任务构建、因果因子提取和样本权重分配来缓解任务冲突问题。


<details>
  <summary>Details</summary>
Motivation: 探索SSL表示的可迁移性，解决两个核心问题：(i) SSL表示的可迁移性是什么，(ii) 如何有效建模这种可迁移性。目标是提升从一项任务学到的表示支持另一项目标任务的能力。

Method: 提出任务冲突校准（TC²）方法：1）在训练批次内构建多个SSL任务，注入任务级信息；2）使用因子提取网络生成所有任务的因果生成因子，权重提取网络为每个样本分配专用权重；3）通过数据重构、正交性和稀疏性确保有效性；4）在SSL训练期间校准样本表示，通过两阶段双层优化框架集成到流程中。

Result: 在多个下游任务上的实验结果表明，该方法持续提升了SSL模型的可迁移性。

Conclusion: TC²方法通过缓解任务冲突，有效提升了自监督学习表示的可迁移性，为SSL的可迁移性建模提供了有效解决方案。

Abstract: In this paper, we explore the transferability of SSL by addressing two central questions: (i) what is the representation transferability of SSL, and (ii) how can we effectively model this transferability? Transferability is defined as the ability of a representation learned from one task to support the objective of another.
  Inspired by the meta-learning paradigm, we construct multiple SSL tasks within each training batch to support explicitly modeling transferability. Based on empirical evidence and causal analysis, we find that although introducing task-level information improves transferability, it is still hindered by task conflict. To address this issue, we propose a Task Conflict Calibration (TC$^2$) method to alleviate the impact of task conflict. Specifically, it first splits batches to create multiple SSL tasks, infusing task-level information. Next, it uses a factor extraction network to produce causal generative factors for all tasks and a weight extraction network to assign dedicated weights to each sample, employing data reconstruction, orthogonality, and sparsity to ensure effectiveness. Finally, TC$^2$ calibrates sample representations during SSL training and integrates into the pipeline via a two-stage bi-level optimization framework to boost the transferability of learned representations. Experimental results on multiple downstream tasks demonstrate that our method consistently improves the transferability of SSL models.

</details>


### [86] [Scaling Patterns in Adversarial Alignment: Evidence from Multi-LLM Jailbreak Experiments](https://arxiv.org/abs/2511.13788)
*Samuel Nathanson,Rebecca Williams,Cynthia Matuszek*

Main category: cs.LG

TL;DR: 研究发现大型语言模型在对抗性交互中，攻击者与目标模型的大小比例与有害行为发生率呈正相关，模型尺寸不对称影响对抗鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在多代理和安全关键环境中应用增多，需要了解模型在对抗性交互中的脆弱性如何随模型规模变化，特别是大模型是否能系统性地破解小模型的安全防护。

Method: 使用JailbreakBench标准化对抗任务，模拟超过6,000次多轮攻击者-目标交互，涵盖0.6B-120B参数的不同规模LLM，通过三个独立LLM法官评估伤害分数和拒绝行为。

Result: 攻击者与目标模型大小比例的对数与平均伤害分数呈强正相关（Pearson r=0.51），攻击者方的行为多样性对对抗结果影响更大，攻击者拒绝频率与伤害分数呈强负相关（rho=-0.93）。

Conclusion: 模型尺寸不对称影响鲁棒性，攻击者方的对齐程度能减轻有害响应，这为研究模型间对齐和安全性提供了探索性证据。

Abstract: Large language models (LLMs) increasingly operate in multi-agent and safety-critical settings, raising open questions about how their vulnerabilities scale when models interact adversarially. This study examines whether larger models can systematically jailbreak smaller ones - eliciting harmful or restricted behavior despite alignment safeguards. Using standardized adversarial tasks from JailbreakBench, we simulate over 6,000 multi-turn attacker-target exchanges across major LLM families and scales (0.6B-120B parameters), measuring both harm score and refusal behavior as indicators of adversarial potency and alignment integrity. Each interaction is evaluated through aggregated harm and refusal scores assigned by three independent LLM judges, providing a consistent, model-based measure of adversarial outcomes. Aggregating results across prompts, we find a strong and statistically significant correlation between mean harm and the logarithm of the attacker-to-target size ratio (Pearson r = 0.51, p < 0.001; Spearman rho = 0.52, p < 0.001), indicating that relative model size correlates with the likelihood and severity of harmful completions. Mean harm score variance is higher across attackers (0.18) than across targets (0.10), suggesting that attacker-side behavioral diversity contributes more to adversarial outcomes than target susceptibility. Attacker refusal frequency is strongly and negatively correlated with harm (rho = -0.93, p < 0.001), showing that attacker-side alignment mitigates harmful responses. These findings reveal that size asymmetry influences robustness and provide exploratory evidence for adversarial scaling patterns, motivating more controlled investigations into inter-model alignment and safety.

</details>


### [87] [ScoresActivation: A New Activation Function for Model Agnostic Global Explainability by Design](https://arxiv.org/abs/2511.13809)
*Emanuel Covaci,Fabian Galis,Radu Balan,Daniela Zaharie,Darian Onchis*

Main category: cs.LG

TL;DR: 提出一种可微分的全局可解释性方法，通过将特征重要性估计直接集成到模型训练中，使用ScoresActivation函数实现端到端的特征排序，在保持高预测性能的同时提供忠实稳定的特征重要性排名。


<details>
  <summary>Details</summary>
Motivation: 当前的事后解释方法与模型训练过程脱节，限制了其忠实性和实用性，需要一种将可解释性直接融入训练过程的方法。

Method: 引入ScoresActivation函数作为特征排序机制嵌入学习流程，使模型能够以可微分和端到端可训练的方式根据特征对预测性能的贡献进行优先级排序。

Result: 在基准数据集上评估显示，该方法产生与SHAP值和真实特征重要性一致的全局忠实、稳定的特征排名，特征评分速度比SHAP快150倍，分类准确率在10个特征（5个相关）时提高11.24%，在16个特征（5个相关、11个不相关）时提高29.33%。

Conclusion: 这项工作弥合了模型准确性和可解释性之间的差距，为固有可解释的机器学习提供了可扩展的框架。

Abstract: Understanding the decision of large deep learning models is a critical challenge for building transparent and trustworthy systems. Although the current post hoc explanation methods offer valuable insights into feature importance, they are inherently disconnected from the model training process, limiting their faithfulness and utility. In this work, we introduce a novel differentiable approach to global explainability by design, integrating feature importance estimation directly into model training. Central to our method is the ScoresActivation function, a feature-ranking mechanism embedded within the learning pipeline. This integration enables models to prioritize features according to their contribution to predictive performance in a differentiable and end-to-end trainable manner. Evaluations across benchmark datasets show that our approach yields globally faithful, stable feature rankings aligned with SHAP values and ground-truth feature importance, while maintaining high predictive performance. Moreover, feature scoring is 150 times faster than the classical SHAP method, requiring only 2 seconds during training compared to SHAP's 300 seconds for feature ranking in the same configuration. Our method also improves classification accuracy by 11.24% with 10 features (5 relevant) and 29.33% with 16 features (5 relevant, 11 irrelevant), demonstrating robustness to irrelevant inputs. This work bridges the gap between model accuracy and interpretability, offering a scalable framework for inherently explainable machine learning.

</details>


### [88] [Beat the long tail: Distribution-Aware Speculative Decoding for RL Training](https://arxiv.org/abs/2511.13841)
*Zelei Shao,Vikranth Srivatsa,Sanjana Srivastava,Qingyang Wu,Alpay Ariyak,Xiaoxia Wu,Ameen Patel,Jue Wang,Percy Liang,Tri Dao,Ce Zhang,Yiying Zhang,Ben Athiwaratkun,Chenfeng Xu,Junxiong Wang*

Main category: cs.LG

TL;DR: DAS是一个分布感知的推测解码框架，通过利用历史rollout数据构建自适应草稿器和长度感知推测策略，加速强化学习后训练中的rollout阶段，减少50%的rollout时间而不改变模型输出。


<details>
  <summary>Details</summary>
Motivation: 强化学习后训练的效率受到rollout阶段的限制，特别是长尾分布中少数长轨迹占据了大部分时间成本，同时历史rollout数据揭示了稳定的提示级别模式。

Method: DAS整合了基于最近rollout构建的自适应非参数草稿器（使用增量维护的后缀树）和长度感知推测策略，为支配总时长的长轨迹分配更激进的草稿预算。

Result: 在数学和代码推理任务上的实验表明，DAS将rollout时间减少高达50%，同时保持相同的训练曲线。

Conclusion: 分布感知的推测解码能够显著加速强化学习后训练，且不损害学习质量。

Abstract: Reinforcement learning(RL) post-training has become essential for aligning large language models (LLMs), yet its efficiency is increasingly constrained by the rollout phase, where long trajectories are generated token by token. We identify a major bottleneck:the long-tail distribution of rollout lengths, where a small fraction of long generations dominates wall clock time and a complementary opportunity; the availability of historical rollouts that reveal stable prompt level patterns across training epochs. Motivated by these observations, we propose DAS, a Distribution Aware Speculative decoding framework that accelerates RL rollouts without altering model outputs. DAS integrates two key ideas: an adaptive, nonparametric drafter built from recent rollouts using an incrementally maintained suffix tree, and a length aware speculation policy that allocates more aggressive draft budgets to long trajectories that dominate makespan. This design exploits rollout history to sustain acceptance while balancing base and token level costs during decoding. Experiments on math and code reasoning tasks show that DAS reduces rollout time up to 50% while preserving identical training curves, demonstrating that distribution-aware speculative decoding can significantly accelerate RL post training without compromising learning quality.

</details>


### [89] [AnaCP: Toward Upper-Bound Continual Learning via Analytic Contrastive Projection](https://arxiv.org/abs/2511.13880)
*Saleh Momeni,Changnan Xiao,Bing Liu*

Main category: cs.LG

TL;DR: 本文提出了AnaCP方法，用于解决类增量学习中的特征适应问题，通过分析对比投影实现无梯度训练的特征适应，达到接近联合训练的性能。


<details>
  <summary>Details</summary>
Motivation: 传统类增量学习方法存在灾难性遗忘问题，而基于预训练模型的方法虽然高效但无法持续适应特征表示，导致性能次优。

Method: 提出AnaCP方法，保持分析分类器效率的同时，通过分析对比投影实现增量特征适应，无需基于梯度的训练。

Result: 实验表明AnaCP不仅优于现有基线方法，还达到了联合训练的准确率水平，这是类增量学习的理论上界。

Conclusion: AnaCP成功解决了类增量学习中的特征适应问题，在保持效率的同时实现了接近最优的性能。

Abstract: This paper studies the problem of class-incremental learning (CIL), a core setting within continual learning where a model learns a sequence of tasks, each containing a distinct set of classes. Traditional CIL methods, which do not leverage pre-trained models (PTMs), suffer from catastrophic forgetting (CF) due to the need to incrementally learn both feature representations and the classifier. The integration of PTMs into CIL has recently led to efficient approaches that treat the PTM as a fixed feature extractor combined with analytic classifiers, achieving state-of-the-art performance. However, they still face a major limitation: the inability to continually adapt feature representations to best suit the CIL tasks, leading to suboptimal performance. To address this, we propose AnaCP (Analytic Contrastive Projection), a novel method that preserves the efficiency of analytic classifiers while enabling incremental feature adaptation without gradient-based training, thereby eliminating the CF caused by gradient updates. Our experiments show that AnaCP not only outperforms existing baselines but also achieves the accuracy level of joint training, which is regarded as the upper bound of CIL.

</details>


### [90] [Tractable Probabilistic Models for Investment Planning](https://arxiv.org/abs/2511.13888)
*Nicolas M. Cuadrado A.,Mohannad Takrouri,Jiří Němeček,Martin Takáč,Jakub Mareček*

Main category: cs.LG

TL;DR: 提出使用可处理概率模型（TPMs）特别是和积网络（SPNs）来改进电力系统投资规划中的长期不确定性预测，替代传统的有限场景方法。


<details>
  <summary>Details</summary>
Motivation: 电力系统投资规划需要数十年预测，面临深刻不确定性。传统有限场景方法限制了洞察场景特定波动性并阻碍稳健决策。

Method: 使用可处理概率模型（TPMs），特别是和积网络（SPNs），能够精确、可扩展地推断关键量如场景似然、边缘概率和条件概率。

Result: 通过代表性电力系统规划案例研究证明该方法在计算和可靠性方面优于传统基于场景的模型。

Conclusion: TPMs框架支持将机会约束优化直接嵌入投资规划，以规定置信水平强制执行安全性或可靠性要求，实现场景分析和波动性量化。

Abstract: Investment planning in power utilities, such as generation and transmission expansion, requires decade-long forecasts under profound uncertainty. Forecasting of energy mix and energy use decades ahead is nontrivial. Classical approaches focus on generating a finite number of scenarios (modeled as a mixture of Diracs in statistical theory terms), which limits insight into scenario-specific volatility and hinders robust decision-making. We propose an alternative using tractable probabilistic models (TPMs), particularly sum-product networks (SPNs). These models enable exact, scalable inference of key quantities such as scenario likelihoods, marginals, and conditional probabilities, supporting robust scenario expansion and risk assessment.
  This framework enables direct embedding of chance-constrained optimization into investment planning, enforcing safety or reliability with prescribed confidence levels. TPMs allow both scenario analysis and volatility quantification by compactly representing high-dimensional uncertainties. We demonstrate the approach's effectiveness through a representative power system planning case study, illustrating computational and reliability advantages over traditional scenario-based models.

</details>


### [91] [Beyond One-Size-Fits-All: Neural Networks for Differentially Private Tabular Data Synthesis](https://arxiv.org/abs/2511.13893)
*Kai Chen,Chen Gong,Tianhao Wang*

Main category: cs.LG

TL;DR: MargNet是一种结合统计模型和神经网络优势的差分隐私表格数据合成方法，在稀疏相关数据集上接近最佳统计方法的效用且速度提升7倍，在密集相关数据集上比之前最佳方法减少26%的保真度误差。


<details>
  <summary>Details</summary>
Motivation: 现有研究认为统计模型优于基于神经网络的方法，但这一结论忽略了密集相关数据集的挑战，其中复杂依赖关系会压倒统计模型。神经网络因其从样本直接学习复杂分布的能力，在复杂场景中更合适。

Method: MargNet将统计模型的成功算法设计融入神经网络，采用自适应边际选择策略，训练神经网络生成符合选定边际的数据。

Result: 在稀疏相关数据集上，效用接近最佳统计方法，平均速度提升7倍；在密集相关数据集上，建立了新的最先进水平，保真度误差比之前最佳方法减少高达26%。

Conclusion: MargNet证明了神经网络在复杂数据场景中的潜力，通过结合统计模型的优势设计，在保持高效的同时显著提升了数据合成质量。

Abstract: In differentially private (DP) tabular data synthesis, the consensus is that statistical models are better than neural network (NN)-based methods. However, we argue that this conclusion is incomplete and overlooks the challenge of densely correlated datasets, where intricate dependencies can overwhelm statistical models. In such complex scenarios, neural networks are more suitable due to their capacity to fit complex distributions by learning directly from samples. Despite this potential, existing NN-based algorithms still suffer from significant limitations. We therefore propose MargNet, incorporating successful algorithmic designs of statistical models into neural networks. MargNet applies an adaptive marginal selection strategy and trains the neural networks to generate data that conforms to the selected marginals. On sparsely correlated datasets, our approach achieves utility close to the best statistical method while offering an average 7$\times$ speedup over it. More importantly, on densely correlated datasets, MargNet establishes a new state-of-the-art, reducing fidelity error by up to 26\% compared to the previous best. We release our code on GitHub.\footnote{https://github.com/KaiChen9909/margnet}

</details>


### [92] [Weather Maps as Tokens: Transformers for Renewable Energy Forecasting](https://arxiv.org/abs/2511.13935)
*Federico Battini*

Main category: cs.LG

TL;DR: 提出一种将天气图作为transformer序列令牌的新方法，用于预测可再生能源发电量，相比现有方法显著降低了预测误差。


<details>
  <summary>Details</summary>
Motivation: 当前方法未能有效整合天气模式的空间背景与时间演变，而准确的可再生能源预测对减少化石燃料依赖和实现电网脱碳至关重要。

Method: 使用轻量级卷积神经网络将小时天气图编码为空间令牌，然后通过transformer处理以捕捉45小时预测范围内的时序动态。

Result: 与ENTSO-E运营预测相比，尽管输入初始化存在劣势，但风能和太阳能的RMSE分别降低了约60%和20%。

Conclusion: 该方法通过将天气图作为transformer令牌，成功整合了空间和时间信息，显著提升了可再生能源预测的准确性。

Abstract: Accurate renewable energy forecasting is essential to reduce dependence on fossil fuels and enabling grid decarbonization. However, current approaches fail to effectively integrate the rich spatial context of weather patterns with their temporal evolution. This work introduces a novel approach that treats weather maps as tokens in transformer sequences to predict renewable energy. Hourly weather maps are encoded as spatial tokens using a lightweight convolutional neural network, and then processed by a transformer to capture temporal dynamics across a 45-hour forecast horizon. Despite disadvantages in input initialization, evaluation against ENTSO-E operational forecasts shows a reduction in RMSE of about 60\% and 20\% for wind and solar respectively. A live dashboard showing daily forecasts is available at: https://www.sardiniaforecast.ifabfoundation.it.

</details>


### [93] [Complex-Weighted Convolutional Networks: Provable Expressiveness via Complex Diffusion](https://arxiv.org/abs/2511.13937)
*Cristina López Amado,Tassilo Schwarz,Yu Tian,Renaud Lambiotte*

Main category: cs.LG

TL;DR: 提出了一种复杂加权图神经网络框架，通过为边分配复数权重来驱动复杂域中的扩散过程，解决了GNN的过平滑和异配图性能差的问题。


<details>
  <summary>Details</summary>
Motivation: 图神经网络在异配图上的性能不佳且存在过平滑问题，需要更强大的表达能力来处理复杂的图结构。

Method: 引入复杂加权结构，为每条边分配复数权重，将随机游走扩展到复数域，并提出复杂加权卷积网络(CWCN)直接从数据中学习合适的复杂加权结构。

Result: CWCN在基准数据集上取得了有竞争力的性能，无需标准GNN之外的额外超参数，且易于实现。

Conclusion: 复杂加权扩散为增强GNN表达能力提供了理论依据和通用机制，开辟了既有理论支撑又实际有效的模型新途径。

Abstract: Graph Neural Networks (GNNs) have achieved remarkable success across diverse applications, yet they remain limited by oversmoothing and poor performance on heterophilic graphs. To address these challenges, we introduce a novel framework that equips graphs with a complex-weighted structure, assigning each edge a complex number to drive a diffusion process that extends random walks into the complex domain. We prove that this diffusion is highly expressive: with appropriately chosen complex weights, any node-classification task can be solved in the steady state of a complex random walk. Building on this insight, we propose the Complex-Weighted Convolutional Network (CWCN), which learns suitable complex-weighted structures directly from data while enriching diffusion with learnable matrices and nonlinear activations. CWCN is simple to implement, requires no additional hyperparameters beyond those of standard GNNs, and achieves competitive performance on benchmark datasets. Our results demonstrate that complex-weighted diffusion provides a principled and general mechanism for enhancing GNN expressiveness, opening new avenues for models that are both theoretically grounded and practically effective.

</details>


### [94] [The Impact of Bootstrap Sampling Rate on Random Forest Performance in Regression Tasks](https://arxiv.org/abs/2511.13952)
*Michał Iwaniuk,Mateusz Jarosz,Bartłomiej Borycki,Bartosz Jezierski,Jan Cwalina,Stanisław Kaźmierczak,Jacek Mańdziuk*

Main category: cs.LG

TL;DR: 研究表明，随机森林中调整bootstrap rate(BR)可以显著提升性能，最佳BR值取决于数据集特性：全局特征-目标关系强的数据集适合高BR，局部目标方差高的数据集适合低BR。


<details>
  <summary>Details</summary>
Motivation: 传统随机森林默认使用BR=1.0，但缺乏系统研究证明这是最优选择，需要探索不同BR值对性能的影响。

Method: 在39个回归数据集和16种RF配置上系统测试BR从0.2到5.0的变化，使用重复二折交叉验证和均方误差评估。

Result: 调优BR能显著改善性能：24个数据集最佳BR≤1.0，15个数据集最佳BR>1.0，仅4个数据集BR=1.0最优。合成数据集实验证实了偏差-方差权衡。

Conclusion: BR是一个重要的超参数，应该通过调优来优化随机森林回归模型。

Abstract: Random Forests (RFs) typically train each tree on a bootstrap sample of the same size as the training set, i.e., bootstrap rate (BR) equals 1.0. We systematically examine how varying BR from 0.2 to 5.0 affects RF performance across 39 heterogeneous regression datasets and 16 RF configurations, evaluating with repeated two-fold cross-validation and mean squared error. Our results demonstrate that tuning the BR can yield significant improvements over the default: the best setup relied on BR \leq 1.0 for 24 datasets, BR > 1.0 for 15, and BR = 1.0 was optimal in 4 cases only. We establish a link between dataset characteristics and the preferred BR: datasets with strong global feature-target relationships favor higher BRs, while those with higher local target variance benefit from lower BRs. To further investigate this relationship, we conducted experiments on synthetic datasets with controlled noise levels. These experiments reproduce the observed bias-variance trade-off: in low-noise scenarios, higher BRs effectively reduce model bias, whereas in high-noise settings, lower BRs help reduce model variance. Overall, BR is an influential hyperparameter that should be tuned to optimize RF regression models.

</details>


### [95] [Efficient reconstruction of multidimensional random field models with heterogeneous data using stochastic neural networks](https://arxiv.org/abs/2511.13977)
*Mingtao Xia,Qijing Shen*

Main category: cs.LG

TL;DR: 本文分析了基于Wasserstein距离训练随机神经网络重构多维随机场模型的可扩展性，证明了在有限训练数据下的泛化误差界，部分缓解了维度灾难问题。


<details>
  <summary>Details</summary>
Motivation: 研究多维随机场模型重构中的维度灾难问题，探索Wasserstein距离方法在训练随机神经网络时的可扩展性。

Method: 改进基于Wasserstein距离的随机神经网络训练方法，分析异质噪声条件下的泛化误差收敛率。

Result: 当噪声在维度间异质时，泛化误差收敛率可能不显式依赖于模型维度，部分缓解了维度灾难；数值实验验证了方法在多维不确定性量化任务中的有效性。

Conclusion: Wasserstein距离方法能够成功训练随机神经网络学习多维不确定性模型，并在异质噪声条件下展现出对维度灾难的部分缓解效果。

Abstract: In this paper, we analyze the scalability of a recent Wasserstein-distance approach for training stochastic neural networks (SNNs) to reconstruct multidimensional random field models. We prove a generalization error bound for reconstructing multidimensional random field models on training stochastic neural networks with a limited number of training data. Our results indicate that when noise is heterogeneous across dimensions, the convergence rate of the generalization error may not depend explicitly on the model's dimensionality, partially alleviating the "curse of dimensionality" for learning multidimensional random field models from a finite number of data points. Additionally, we improve the previous Wasserstein-distance SNN training approach and showcase the robustness of the SNN. Through numerical experiments on different multidimensional uncertainty quantification tasks, we show that our Wasserstein-distance approach can successfully train stochastic neural networks to learn multidimensional uncertainty models.

</details>


### [96] [Data Whitening Improves Sparse Autoencoder Learning](https://arxiv.org/abs/2511.13981)
*Ashwin Saraswatula,David Klindt*

Main category: cs.LG

TL;DR: PCA Whitening预处理技术能改善稀疏自编码器(SAE)的性能，通过使优化景观更凸化来提升特征可解释性，尽管重建质量略有下降。


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器在训练时面临输入数据相关性带来的优化挑战，需要改进训练方法来提升特征可解释性。

Method: 对输入激活应用PCA Whitening预处理，在SAEBench基准上评估ReLU和Top-K SAE在不同模型架构、宽度和稀疏度下的表现。

Result: 白化处理一致改善了可解释性指标（稀疏探测精度和特征解缠），但重建质量略有下降。

Conclusion: 白化应作为SAE训练的默认预处理步骤，特别是当优先考虑可解释性而非完美重建时。

Abstract: Sparse autoencoders (SAEs) have emerged as a promising approach for learning interpretable features from neural network activations. However, the optimization landscape for SAE training can be challenging due to correlations in the input data. We demonstrate that applying PCA Whitening to input activations -- a standard preprocessing technique in classical sparse coding -- improves SAE performance across multiple metrics. Through theoretical analysis and simulation, we show that whitening transforms the optimization landscape, making it more convex and easier to navigate. We evaluate both ReLU and Top-K SAEs across diverse model architectures, widths, and sparsity regimes. Empirical evaluation on SAEBench, a comprehensive benchmark for sparse autoencoders, reveals that whitening consistently improves interpretability metrics, including sparse probing accuracy and feature disentanglement, despite minor drops in reconstruction quality. Our results challenge the assumption that interpretability aligns with an optimal sparsity--fidelity trade-off and suggest that whitening should be considered as a default preprocessing step for SAE training, particularly when interpretability is prioritized over perfect reconstruction.

</details>


### [97] [Node-Level Uncertainty Estimation in LLM-Generated SQL](https://arxiv.org/abs/2511.13984)
*Hilaf Hasson,Ruocheng Guo*

Main category: cs.LG

TL;DR: 提出基于SQL抽象语法树节点级不确定性估计的错误检测框架，通过语义感知标签算法和模式感知特征训练分类器，显著优于基于token概率的方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于token概率的LLM生成SQL错误检测方法不够精确，需要更细粒度的、语义感知的检测机制来准确定位错误位置。

Method: 两阶段方法：1) 语义感知标签算法为AST节点分配正确性标签；2) 使用模式感知和词汇特征训练监督分类器预测节点错误概率。

Result: 在多个数据库和数据集上，平均AUC提升27.44%，在跨数据库评估中保持鲁棒性，显著优于token对数概率方法。

Conclusion: 节点中心、语义基础的不确定性估计是聚合序列级置信度度量的强大且可解释的替代方案，支持针对性修复和人机协同审查。

Abstract: We present a practical framework for detecting errors in LLM-generated SQL by estimating uncertainty at the level of individual nodes in the query's abstract syntax tree (AST). Our approach proceeds in two stages. First, we introduce a semantically aware labeling algorithm that, given a generated SQL and a gold reference, assigns node-level correctness without over-penalizing structural containers or alias variation. Second, we represent each node with a rich set of schema-aware and lexical features - capturing identifier validity, alias resolution, type compatibility, ambiguity in scope, and typo signals - and train a supervised classifier to predict per-node error probabilities. We interpret these probabilities as calibrated uncertainty, enabling fine-grained diagnostics that pinpoint exactly where a query is likely to be wrong. Across multiple databases and datasets, our method substantially outperforms token log-probabilities: average AUC improves by +27.44% while maintaining robustness under cross-database evaluation. Beyond serving as an accuracy signal, node-level uncertainty supports targeted repair, human-in-the-loop review, and downstream selective execution. Together, these results establish node-centric, semantically grounded uncertainty estimation as a strong and interpretable alternative to aggregate sequence level confidence measures.

</details>


### [98] [On the Gradient Complexity of Private Optimization with Private Oracles](https://arxiv.org/abs/2511.13999)
*Michael Menart,Aleksandar Nikolov*

Main category: cs.LG

TL;DR: 本文研究了差分隐私下Lipschitz凸损失函数经验/总体风险最小化的运行时间下界，揭示了差分隐私优化器需要付出维度相关的运行时间代价，并分析了梯度量化技术的基本局限性。


<details>
  <summary>Details</summary>
Motivation: 研究差分隐私优化算法的计算复杂度下界，理解隐私保护对优化效率的影响，特别是维度依赖的运行时间惩罚问题。

Method: 通过理论分析建立不同设置下的运行时间下界：非光滑损失下的私有代理oracle交互、光滑损失下的私有优化器设置，以及信息受限oracle下的梯度量化分析。

Result: 证明了非光滑损失下需要Ω(min{√d/α², d/log(1/α)})的oracle查询次数，光滑损失下需要Ω̃(√d/α + min{1/α², n})次查询，信息受限oracle下需要Ω(min{d/(α²Γ), d/log(1/α)})次查询。

Conclusion: 差分隐私优化器存在维度依赖的运行时间惩罚，梯度量化技术在优化中存在基本局限性，这些下界在相应设置下是紧的或接近紧的。

Abstract: We study the running time, in terms of first order oracle queries, of differentially private empirical/population risk minimization of Lipschitz convex losses. We first consider the setting where the loss is non-smooth and the optimizer interacts with a private proxy oracle, which sends only private messages about a minibatch of gradients. In this setting, we show that expected running time $Ω(\min\{\frac{\sqrt{d}}{α^2}, \frac{d}{\log(1/α)}\})$ is necessary to achieve $α$ excess risk on problems of dimension $d$ when $d \geq 1/α^2$. Upper bounds via DP-SGD show these results are tight when $d>\tildeΩ(1/α^4)$. We further show our lower bound can be strengthened to $Ω(\min\{\frac{d}{\bar{m}α^2}, \frac{d}{\log(1/α)} \})$ for algorithms which use minibatches of size at most $\bar{m} < \sqrt{d}$. We next consider smooth losses, where we relax the private oracle assumption and give lower bounds under only the condition that the optimizer is private. Here, we lower bound the expected number of first order oracle calls by $\tildeΩ\big(\frac{\sqrt{d}}α + \min\{\frac{1}{α^2}, n\}\big)$, where $n$ is the size of the dataset. Modifications to existing algorithms show this bound is nearly tight. Compared to non-private lower bounds, our results show that differentially private optimizers pay a dimension dependent runtime penalty. Finally, as a natural extension of our proof technique, we show lower bounds in the non-smooth setting for optimizers interacting with information limited oracles. Specifically, if the proxy oracle transmits at most $Γ$-bits of information about the gradients in the minibatch, then $Ω\big(\min\{\frac{d}{α^2Γ}, \frac{d}{\log(1/α)}\}\big)$ oracle calls are needed. This result shows fundamental limitations of gradient quantization techniques in optimization.

</details>


### [99] [How to Marginalize in Causal Structure Learning?](https://arxiv.org/abs/2511.14001)
*William Zhao,Guy Van den Broeck,Benjie Wang*

Main category: cs.LG

TL;DR: 提出了一种使用可处理概率电路的新方法，用于贝叶斯网络结构学习中的边缘化计算，相比传统动态规划方法能够提升性能。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯网络结构学习需要推断可能的无环图的后验分布，传统方法使用动态规划进行边缘化计算，但限制了每个节点的可能父节点集合。

Method: 利用可处理概率电路来规避传统限制，开发了新的学习例程，在原始分布和边缘查询上训练这些电路，利用概率电路架构实现快速精确的边缘化。

Result: 实验表明，使用该方法回答边缘查询能够让贝叶斯结构学习器相比当前方法提升性能。

Conclusion: 概率电路为贝叶斯网络结构学习提供了一种有效的边缘化计算方法，能够突破传统动态规划方法的限制并改善学习效果。

Abstract: Bayesian networks (BNs) are a widely used class of probabilistic graphical models employed in numerous application domains. However, inferring the network's graphical structure from data remains challenging. Bayesian structure learners approach this problem by inferring a posterior distribution over the possible directed acyclic graphs underlying the BN. The inference process often requires marginalizing over probability distributions, which is typically done using dynamic programming methods that restrict the set of possible parents for each node. Instead, we present a novel method that utilizes tractable probabilistic circuits to circumvent this restriction. This method utilizes a new learning routine that trains these circuits on both the original distribution and marginal queries. The architecture of probabilistic circuits then inherently allows for fast and exact marginalization on the learned distribution. We then show empirically that utilizing our method to answer marginals allows Bayesian structure learners to improve their performance compared to current methods.

</details>


### [100] [Certified but Fooled! Breaking Certified Defences with Ghost Certificates](https://arxiv.org/abs/2511.14003)
*Quoc Viet Vo,Tashreque M. Haq,Paul Montague,Tamas Abraham,Ehsan Abbasnejad,Damith C. Ranasinghe*

Main category: cs.LG

TL;DR: 该论文研究如何利用概率认证框架的漏洞，通过微小且难以察觉的扰动来欺骗认证防御系统，使其为对抗性输入生成虚假的鲁棒性保证。


<details>
  <summary>Details</summary>
Motivation: 研究认证防御系统的局限性，探索即使需要误导分类器并操纵认证过程生成错误类别的鲁棒性保证，所需的扰动是否仍能保持微小和不可察觉。

Method: 采用区域聚焦的对抗样本方法，精心设计微小扰动来欺骗认证系统，使其为目标类别生成虚假的大鲁棒性半径证书。

Result: 在ImageNet数据集上的广泛评估表明，该方法能够有效绕过最先进的认证防御系统如Densepure，生成比源类别幽灵证书更大的认证半径。

Conclusion: 这项工作强调了需要更好地理解鲁棒性认证方法的局限性，当前认证防御系统存在被欺骗的风险。

Abstract: Certified defenses promise provable robustness guarantees. We study the malicious exploitation of probabilistic certification frameworks to better understand the limits of guarantee provisions. Now, the objective is to not only mislead a classifier, but also manipulate the certification process to generate a robustness guarantee for an adversarial input certificate spoofing. A recent study in ICLR demonstrated that crafting large perturbations can shift inputs far into regions capable of generating a certificate for an incorrect class. Our study investigates if perturbations needed to cause a misclassification and yet coax a certified model into issuing a deceptive, large robustness radius for a target class can still be made small and imperceptible. We explore the idea of region-focused adversarial examples to craft imperceptible perturbations, spoof certificates and achieve certification radii larger than the source class ghost certificates. Extensive evaluations with the ImageNet demonstrate the ability to effectively bypass state-of-the-art certified defenses such as Densepure. Our work underscores the need to better understand the limits of robustness certification methods.

</details>


### [101] [From Narrow Unlearning to Emergent Misalignment: Causes, Consequences, and Containment in LLMs](https://arxiv.org/abs/2511.14017)
*Erum Mushtaq,Anil Ramakrishna,Satyapriya Krishna,Sattvik Sahai,Prasoon Goyal,Kai-Wei Chang,Tao Zhang,Rahul Gupta*

Main category: cs.LG

TL;DR: 研究发现，在特定领域进行拒绝遗忘（refusal unlearning）可能引发涌现性失准（EMA）现象，导致模型在其他无关领域也产生有害行为。安全概念的干预对其他领域影响更大，但可以通过在受影响领域添加保留数据的交叉熵损失来恢复对齐。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明，对不安全代码数据的微调会触发EMA现象，模型在无关提示下也生成恶意响应。需要更深入理解引发涌现性失准的算法、任务和数据集。

Method: 在网络安全和安全概念上进行拒绝遗忘，评估七个负责任AI领域的拒绝分数。分析概念向量在表示层面的纠缠，使用交叉熵损失函数在受影响领域添加保留数据来恢复对齐。

Result: 窄领域遗忘能产生目标概念的合规响应，但会将EMA传播到无关领域。安全概念对其他领域（如偏见）的EMA影响更大。通过添加保留数据的交叉熵损失可以大幅恢复受影响领域的对齐。

Conclusion: 概念在早期层表示相似度越高，在通过目标拒绝遗忘改变拒绝流后越容易受到EMA影响。窄领域遗忘可能引发跨域有害行为传播，需要谨慎处理。

Abstract: Recent work has shown that fine-tuning on insecure code data can trigger an emergent misalignment (EMA) phenomenon, where models generate malicious responses even to prompts unrelated to the original insecure code-writing task. Such cross-domain generalization of harmful behavior underscores the need for a deeper understanding of the algorithms, tasks, and datasets that induce emergent misalignment. In this work, we extend this study by demonstrating that emergent misalignment can also arise from narrow refusal unlearning in specific domains. We perform refusal unlearning on Cybersecurity and Safety concept, and evaluate EMA by monitoring refusal scores across seven responsible AI (RAI) domains, Cybersecurity, Safety, Toxicity, Bias, Sensitive Content, Medical/Legal, and Privacy. Our work shows that narrow domain unlearning can yield compliance responses for the targeted concept, however, it may also propagate EMA to unrelated domains. Among the two intervened concepts, Cybersecurity and Safety, we find that the safety concept can have larger EMA impact, i.e, causing lower refusal scores, across other unrelated domains such as bias. We observe this effect consistently across two model families, Mistral-7b-0.3v, and Qwen-7b-2.5. Further, we show that refusal unlearning augmented with cross-entropy loss function on a small set of retain data from the affected domains can largely, if not fully, restore alignment across the impacted domains while having lower refusal rate on the concept we perform unlearning on. To investigate the underlying causes of EMA, we analyze concept entanglements at the representation level via concept vectors. Our analysis reveals that concepts with higher representation similarity in earlier layers are more susceptible to EMA after intervention when the refusal stream is altered through targeted refusal unlearning.

</details>


### [102] [SmallML: Bayesian Transfer Learning for Small-Data Predictive Analytics](https://arxiv.org/abs/2511.14049)
*Semen Leontev*

Main category: cs.LG

TL;DR: SmallML是一个贝叶斯迁移学习框架，使中小企业在仅有50-200个观测数据的情况下也能达到企业级预测精度，解决了AI民主化中的关键障碍。


<details>
  <summary>Details</summary>
Motivation: 中小企业占美国企业的99.9%，但由于其运营规模与现代机器学习的数据需求不匹配，一直被系统性地排除在AI应用之外。

Method: 采用三层架构：第一层从22,673条公共记录中提取信息先验，使用SHAP方法将梯度提升的知识迁移到逻辑回归；第二层在5-50个中小企业间实现分层池化，平衡总体模式与个体特征；第三层提供具有有限样本覆盖保证的保形预测。

Result: 在客户流失数据验证中，每个企业100个观测数据时达到96.7%±4.2%的AUC，比独立逻辑回归提高24.2个百分点，p<0.000001。保形预测在90%目标下实现92%的经验覆盖率。标准CPU硬件上训练仅需33分钟。

Conclusion: SmallML为3300万家美国中小企业提供了企业级预测能力，填补了AI民主化的关键空白。

Abstract: Small and medium-sized enterprises (SMEs) represent 99.9% of U.S. businesses yet remain systematically excluded from AI due to a mismatch between their operational scale and modern machine learning's data requirements. This paper introduces SmallML, a Bayesian transfer learning framework achieving enterprise-level prediction accuracy with datasets as small as 50-200 observations.
  We develop a three-layer architecture integrating transfer learning, hierarchical Bayesian modeling, and conformal prediction. Layer 1 extracts informative priors from 22,673 public records using a SHAP-based procedure transferring knowledge from gradient boosting to logistic regression. Layer 2 implements hierarchical pooling across J=5-50 SMEs with adaptive shrinkage, balancing population patterns with entity-specific characteristics. Layer 3 provides conformal sets with finite-sample coverage guarantees P(y in C(x)) >= 1-alpha for distribution-free uncertainty quantification.
  Validation on customer churn data demonstrates 96.7% +/- 4.2% AUC with 100 observations per business -- a +24.2 point improvement over independent logistic regression (72.5% +/- 8.1%), with p < 0.000001. Conformal prediction achieves 92% empirical coverage at 90% target. Training completes in 33 minutes on standard CPU hardware. By enabling enterprise-grade predictions for 33 million U.S. SMEs previously excluded from machine learning, SmallML addresses a critical gap in AI democratization.
  Keywords: Bayesian transfer learning, hierarchical models, conformal prediction, small-data analytics, SME machine learning

</details>


### [103] [Radial Compensation: Stable and Semantically Decoupled Generative Models on Riemannian Manifolds](https://arxiv.org/abs/2511.14056)
*Marios Papamichals,Regina Ruane*

Main category: cs.LG

TL;DR: 提出径向补偿(RC)方法，通过选择切空间中的基础密度，使似然仅依赖于测地距离，将参数语义与曲率解耦。RC让径向参数保持测地单位意义，而图表可作为数值预处理器调节。


<details>
  <summary>Details</summary>
Motivation: 现有流形生成模型方法存在问题：指数映射保持测地线但具有刚性的半径相关雅可比矩阵，体积保持图表保持密度但扭曲测地距离。两种方法都将曲率与模型参数纠缠，增加梯度方差。

Method: 引入径向补偿(RC)信息几何方法，选择切空间基础密度使似然仅依赖于测地距离。推导平衡指数(bExp)图表族，平衡体积扭曲和测地误差。RC下所有bExp设置保持相同流形密度和Fisher信息。

Result: RC在密度、VAE、图像和图的流模型以及蛋白质模型中产生稳定的生成模型。RC改善似然，恢复清晰的测地半径，防止高维流中的半径爆炸。

Conclusion: RC-bExp成为流形上似然训练生成模型的稳健默认选择，解耦曲率与参数语义，降低梯度方差和流成本。

Abstract: Generative models on curved spaces rely on charts to map Euclidean spaces to manifolds. Exponential maps preserve geodesics but have stiff, radius-dependent Jacobians, while volume-preserving charts maintain densities but distort geodesic distances. Both approaches entangle curvature with model parameters, inflating gradient variance. In high-dimensional latent normalizing flows, the wrapped exponential prior can stretch radii far beyond the curvature scale, leading to poor test likelihoods and stiff solvers. We introduce Radial Compensation (RC), an information-geometric method that selects the base density in the tangent space so that the likelihood depends only on geodesic distance from a pole, decoupling parameter semantics from curvature. RC lets radial parameters retain their usual meaning in geodesic units, while the chart can be tuned as a numerical preconditioner. We extend RC to manifolds with known geodesic polar volume and show that RC is the only construction for geodesic-radial likelihoods with curvature-invariant Fisher information. We derive the Balanced-Exponential (bExp) chart family, balancing volume distortion and geodesic error. Under RC, all bExp settings preserve the same manifold density and Fisher information, with smaller dial values reducing gradient variance and flow cost. Empirically, RC yields stable generative models across densities, VAEs, flows on images and graphs, and protein models. RC improves likelihoods, restores clean geodesic radii, and prevents radius blow-ups in high-dimensional flows, making RC-bExp a robust default for likelihood-trained generative models on manifolds.

</details>


### [104] [A Machine Learning-Based Multimodal Framework for Wearable Sensor-Based Archery Action Recognition and Stress Estimation](https://arxiv.org/abs/2511.14057)
*Xianghe Liu,Jiajia Liu,Chuxian Xu,Minghan Wang,Hongbo Peng,Tao Sun,Jiaqi Xu*

Main category: cs.LG

TL;DR: 提出基于机器学习的多模态框架，集成可穿戴传感器数据同时进行动作识别和压力估计，在射箭运动中实现96.8%的动作识别准确率和80%的压力分类准确率。


<details>
  <summary>Details</summary>
Motivation: 传统运动分析系统昂贵且侵入性强，限制了在自然训练环境中的应用，需要开发非侵入式、可负担的解决方案来同时监测运动员的技术动作和心理状态。

Method: 使用自研腕戴设备收集加速度和PPG数据，提出平滑差分加速度特征和LSTM模型进行动作阶段识别，提取HRV特征并使用MLP分类器进行压力水平分类。

Result: 动作识别达到96.8%准确率和95.9% F1分数，压力估计达到80%准确率区分高低压力水平，证明了运动与生理传感集成的有效性。

Conclusion: 该框架为开发智能实时反馈系统奠定了基础，可用于射箭等精准运动的训练优化，通过整合技术和心理状态监测提供有意义的见解。

Abstract: In precision sports such as archery, athletes' performance depends on both biomechanical stability and psychological resilience. Traditional motion analysis systems are often expensive and intrusive, limiting their use in natural training environments. To address this limitation, we propose a machine learning-based multimodal framework that integrates wearable sensor data for simultaneous action recognition and stress estimation. Using a self-developed wrist-worn device equipped with an accelerometer and photoplethysmography (PPG) sensor, we collected synchronized motion and physiological data during real archery sessions. For motion recognition, we introduce a novel feature--Smoothed Differential Acceleration (SmoothDiff)--and employ a Long Short-Term Memory (LSTM) model to identify motion phases, achieving 96.8% accuracy and 95.9% F1-score. For stress estimation, we extract heart rate variability (HRV) features from PPG signals and apply a Multi-Layer Perceptron (MLP) classifier, achieving 80% accuracy in distinguishing high- and low-stress levels. The proposed framework demonstrates that integrating motion and physiological sensing can provide meaningful insights into athletes' technical and mental states. This approach offers a foundation for developing intelligent, real-time feedback systems for training optimization in archery and other precision sports.

</details>


### [105] [CafeMed: Causal Attention Fusion Enhanced Medication Recommendation](https://arxiv.org/abs/2511.14064)
*Kelin Ren,Chan-Yang Ju,Dong-Ho Lee*

Main category: cs.LG

TL;DR: CafeMed是一个整合动态因果推理和跨模态注意力的药物推荐框架，通过动态因果权重生成器和通道协调注意力精炼模块，解决了现有方法忽略医疗实体协同效应和静态因果关系的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有药物推荐系统存在两个基本限制：(i) 将医疗实体视为独立特征，未建模其对药物选择的协同效应；(ii) 使用静态因果关系，无法适应患者特定情境和健康状态。

Method: 提出CafeMed框架，包含两个关键组件：因果权重生成器(CWG)将静态因果效应转换为基于个体患者状态的动态调制权重；通道协调注意力精炼模块(CHARM)捕捉诊断和程序之间的复杂相互依赖关系。

Result: 在MIMIC-III和MIMIC-IV数据集上的广泛实验表明，CafeMed显著优于最先进的基线方法，在药物预测准确性方面表现优异，同时保持较低的药物-药物相互作用率。

Conclusion: 整合动态因果关系和跨模态协同效应能够产生更符合临床实践和个性化的药物推荐。

Abstract: Medication recommendation systems play a crucial role in assisting clinicians with personalized treatment decisions. While existing approaches have made significant progress in learning medication representations, they suffer from two fundamental limitations: (i) treating medical entities as independent features without modeling their synergistic effects on medication selection; (ii) employing static causal relationships that fail to adapt to patient-specific contexts and health states. To address these challenges, we propose CafeMed, a framework that integrates dynamic causal reasoning with cross-modal attention for safe and accurate medication recommendation. CafeMed introduces two key components: the Causal Weight Generator (CWG) that transforms static causal effects into dynamic modulation weights based on individual patient states, and the Channel Harmonized Attention Refinement Module (CHARM) that captures complex interdependencies between diagnoses and procedures. This design enables CafeMed to model how different medical conditions jointly influence treatment decisions while maintaining medication safety constraints. Extensive experiments on MIMIC-III and MIMIC-IV datasets demonstrate that CafeMed significantly outperforms state-of-the-art baselines, achieving superior accuracy in medication prediction while maintaining the lower drug--drug interaction rates. Our results indicate that incorporating dynamic causal relationships and cross-modal synergies leads to more clinically-aligned and personalized medication recommendations. Our code is released publicly at https://github.com/rkl71/CafeMed.

</details>


### [106] [CFG-EC: Error Correction Classifier-Free Guidance](https://arxiv.org/abs/2511.14075)
*Nakkyu Yang,Yechan Lee,SooJean Han*

Main category: cs.LG

TL;DR: 提出CFG-EC方法，通过修正无条件噪声预测来改进Classifier-Free Guidance (CFG)算法，减少训练与采样过程中的噪声估计不一致问题，提高生成质量和提示对齐度。


<details>
  <summary>Details</summary>
Motivation: CFG在训练和采样过程中存在噪声估计不一致的问题，导致生成质量受限。需要一种方法来减少这种误差，提高条件生成模型的性能。

Method: CFG-EC通过主动重新对齐无条件噪声误差分量，使其与条件误差分量正交，防止两个引导分量之间的干扰，从而约束采样误差的上界。

Result: 数值实验表明CFG-EC比CFG和CFG++更有效地处理无条件分量，在低引导采样机制下性能显著提升，整体提示对齐度更高。

Conclusion: CFG-EC是一种可增强任何基于CFG方法的通用校正方案，通过改进无条件噪声预测，为高保真图像生成提供更可靠的引导轨迹。

Abstract: Classifier-Free Guidance (CFG) has become a mainstream approach for simultaneously improving prompt fidelity and generation quality in conditional generative models. During training, CFG stochastically alternates between conditional and null prompts to enable both conditional and unconditional generation. However, during sampling, CFG outputs both null and conditional prompts simultaneously, leading to inconsistent noise estimates between the training and sampling processes. To reduce this error, we propose CFG-EC, a versatile correction scheme augmentable to any CFG-based method by refining the unconditional noise predictions. CFG-EC actively realigns the unconditional noise error component to be orthogonal to the conditional error component. This corrective maneuver prevents interference between the two guidance components, thereby constraining the sampling error's upper bound and establishing more reliable guidance trajectories for high-fidelity image generation. Our numerical experiments show that CFG-EC handles the unconditional component more effectively than CFG and CFG++, delivering a marked performance increase in the low guidance sampling regime and consistently higher prompt alignment across the board.

</details>


### [107] [Meta-SimGNN: Adaptive and Robust WiFi Localization Across Dynamic Configurations and Diverse Scenarios](https://arxiv.org/abs/2511.14076)
*Qiqi Xiao,Ziqi Ye,Yinghui He,Jianwei Liu,Guanding Yu*

Main category: cs.LG

TL;DR: Meta-SimGNN是一个基于图神经网络和元学习的WiFi定位系统，旨在解决设备配置变化（如带宽、AP数量、天线数量）对定位性能的影响，提高定位的泛化性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于元学习的定位研究主要关注环境布局变化，但忽略了设备配置变化对CSI维度的影响，这会损害神经网络的可用性。

Method: 提出细粒度CSI图构建方案（将AP作为图节点），振幅-相位融合方法构建CSI图像，维度一致特征提取方法，以及相似性引导的元学习策略。

Result: 在商用WiFi设备上的广泛实验表明，Meta-SimGNN在定位泛化性和准确性方面优于基线方法。

Conclusion: Meta-SimGNN通过图神经网络和元学习的结合，有效解决了设备配置变化带来的定位挑战，提高了系统的实用性和适应性。

Abstract: To promote the practicality of deep learning-based localization, existing studies aim to address the issue of scenario dependence through meta-learning. However, these studies primarily focus on variations in environmental layouts while overlooking the impact of changes in device configurations, such as bandwidth, the number of access points (APs), and the number of antennas used. Unlike environmental changes, variations in device configurations affect the dimensionality of channel state information (CSI), thereby compromising neural network usability. To address this issue, we propose Meta-SimGNN, a novel WiFi localization system that integrates graph neural networks with meta-learning to improve localization generalization and robustness. First, we introduce a fine-grained CSI graph construction scheme, where each AP is treated as a graph node, allowing for adaptability to changes in the number of APs. To structure the features of each node, we propose an amplitude-phase fusion method and a feature extraction method. The former utilizes both amplitude and phase to construct CSI images, enhancing data reliability, while the latter extracts dimension-consistent features to address variations in bandwidth and the number of antennas. Second, a similarity-guided meta-learning strategy is developed to enhance adaptability in diverse scenarios. The initial model parameters for the fine-tuning stage are determined by comparing the similarity between the new scenario and historical scenarios, facilitating rapid adaptation of the model to the new localization scenario. Extensive experimental results over commodity WiFi devices in different scenarios show that Meta-SimGNN outperforms the baseline methods in terms of localization generalization and accuracy.

</details>


### [108] [Observational Auditing of Label Privacy](https://arxiv.org/abs/2511.14084)
*Iden Kalemaj,Luca Melis,Maxime Boucher,Ilya Mironov,Saeed Mahloujifar*

Main category: cs.LG

TL;DR: 提出了一种无需修改训练数据集的差分隐私观测审计框架，利用数据分布固有随机性评估隐私保护效果，特别关注标签隐私审计。


<details>
  <summary>Details</summary>
Motivation: 现有差分隐私审计方法需要修改训练数据集（如注入离群样本或删除样本），在大规模系统中资源消耗大且工程开销高，需要一种无需干预数据管道的审计方法。

Method: 基于数据分布固有随机性的观测审计框架，无需修改原始数据集，将隐私审计从传统成员推理扩展到保护属性（特别是标签）的隐私评估。

Result: 在Criteo和CIFAR-10数据集上的实验证明了该方法在审计标签隐私保证方面的有效性。

Conclusion: 这项工作为大规模生产环境中的实用隐私审计开辟了新途径，解决了现有技术的关键空白。

Abstract: Differential privacy (DP) auditing is essential for evaluating privacy guarantees in machine learning systems. Existing auditing methods, however, pose a significant challenge for large-scale systems since they require modifying the training dataset -- for instance, by injecting out-of-distribution canaries or removing samples from training. Such interventions on the training data pipeline are resource-intensive and involve considerable engineering overhead. We introduce a novel observational auditing framework that leverages the inherent randomness of data distributions, enabling privacy evaluation without altering the original dataset. Our approach extends privacy auditing beyond traditional membership inference to protected attributes, with labels as a special case, addressing a key gap in existing techniques. We provide theoretical foundations for our method and perform experiments on Criteo and CIFAR-10 datasets that demonstrate its effectiveness in auditing label privacy guarantees. This work opens new avenues for practical privacy auditing in large-scale production environments.

</details>


### [109] [MoE-SpeQ: Speculative Quantized Decoding with Proactive Expert Prefetching and Offloading for Mixture-of-Experts](https://arxiv.org/abs/2511.14102)
*Wenfeng Wang,Jiacheng Liu,Xiaofeng Hou,Xinfeng Xia,Peng Tang,Mingxuan Zhang,Chao Li,Minyi Guo*

Main category: cs.LG

TL;DR: MoE-SpeQ通过推测执行和专家卸载的协同设计，使用小型草稿模型预测未来token所需的专家序列，通过预取机制将I/O操作与计算重叠，从而在内存受限设备上实现最高2.34倍的加速。


<details>
  <summary>Details</summary>
Motivation: 解决MoE模型推理时因专家选择的数据依赖性导致的PCIe总线I/O瓶颈问题，使MoE推理在普通硬件上更加可行。

Method: 采用推测执行和专家卸载的协同设计：使用小型草稿模型预测未来token的专家需求，运行时编排器预取专家，自适应调节器根据摊销屋顶线模型动态调整推测策略。

Result: 在内存受限设备上，对Phi-MoE模型实现了最高2.34倍的速度提升，相比最先进的卸载框架有显著改进。

Conclusion: 为资源受限环境中管理数据依赖性内存访问提供了一种新的原则性方法，使MoE推理在普通硬件上更加可行。

Abstract: The immense memory requirements of state-of-the-art Mixture-of-Experts (MoE) models present a significant challenge for inference, often exceeding the capacity of a single accelerator. While offloading experts to host memory is a common solution, it introduces a severe I/O bottleneck over the PCIe bus, as the data-dependent nature of expert selection places these synchronous transfers directly on the critical path of execution, crippling performance.
  This paper argues that the I/O bottleneck can be overcome by trading a small amount of cheap, on-device computation to hide the immense cost of data movement. We present MoE-SpeQ, a new inference system built on a novel co-design of speculative execution and expert offloading. MoE-SpeQ employs a small, on-device draft model to predict the sequence of required experts for future tokens. This foresight enables a runtime orchestrator to prefetch these experts from host memory, effectively overlapping the expensive I/O with useful computation and hiding the latency from the critical path. To maximize performance, an adaptive governor, guided by an Amortization Roofline Model, dynamically tunes the speculation strategy to the underlying hardware. Our evaluation on memory-constrained devices shows that for the Phi-MoE model, MoE-SpeQ achieves at most 2.34x speedup over the state-of-the-art offloading framework. Our work establishes a new, principled approach for managing data-dependent memory access in resource-limited environments, making MoE inference more accessible on commodity hardware.

</details>


### [110] [Soft-Label Training Preserves Epistemic Uncertainty](https://arxiv.org/abs/2511.14117)
*Agamdeep Singh,Ashish Tiwari,Hosein Hasanbeig,Priyanshu Gupta*

Main category: cs.LG

TL;DR: 论文主张将标注分布而非单一标签视为真实标签，通过软标签训练保留认知不确定性，在视觉和NLP任务中显著改善了模型与人类标注的一致性。


<details>
  <summary>Details</summary>
Motivation: 标准实践将多样的标注分布压缩为单一标签，这在模糊数据上存在认知偏差——标注分布本身应被视为真实情况。训练单一标签会迫使模型在本质上模糊的案例上表达错误信心。

Method: 使用软标签训练方法，将标注分布作为真实标签进行训练，而不是将多样的人类判断聚合为点估计。

Result: 在视觉和NLP任务中，软标签训练实现了32%更低的KL散度和61%更强的模型与标注熵相关性，同时保持了与硬标签训练相当的准确率。

Conclusion: 重新定位标注分布的角色——从需要被聚合的噪声信号，转变为模型应该学习复现的认知不确定性的忠实表示。

Abstract: Many machine learning tasks involve inherent subjectivity, where annotators naturally provide varied labels. Standard practice collapses these label distributions into single labels, aggregating diverse human judgments into point estimates. We argue that this approach is epistemically misaligned for ambiguous data--the annotation distribution itself should be regarded as the ground truth. Training on collapsed single labels forces models to express false confidence on fundamentally ambiguous cases, creating a misalignment between model certainty and the diversity of human perception. We demonstrate empirically that soft-label training, which treats annotation distributions as ground truth, preserves epistemic uncertainty. Across both vision and NLP tasks, soft-label training achieves 32% lower KL divergence from human annotations and 61% stronger correlation between model and annotation entropy, while matching the accuracy of hard-label training. Our work repositions annotation distributions from noisy signals to be aggregated away, to faithful representations of epistemic uncertainty that models should learn to reproduce.

</details>


### [111] [Synthetic Survival Control: Extending Synthetic Controls for "When-If" Decision](https://arxiv.org/abs/2511.14133)
*Jessy Xinyi Han,Devavrat Shah*

Main category: cs.LG

TL;DR: 提出Synthetic Survival Control (SSC)方法，用于在面板数据设置中估计反事实风险轨迹，解决观察性数据中因果推断的挑战。


<details>
  <summary>Details</summary>
Motivation: 在观察性数据中估计时间到事件结果的因果效应面临删失、样本量有限和非随机治疗分配的挑战，需要回答"如果-何时"问题。

Method: SSC通过将目标单元的反事实风险轨迹建模为其他单元观察轨迹的加权组合，引入具有低秩结构的面板框架进行因果生存分析。

Result: 在多国癌症治疗结果数据集上验证，发现新型治疗与改善生存相关，干预后风险轨迹相对于合成对应物更低。

Conclusion: 该框架为使用观察性数据进行反事实生存推断提供了一个通用且可解释的工具，在医学、经济学和公共政策领域具有广泛应用价值。

Abstract: Estimating causal effects on time-to-event outcomes from observational data is particularly challenging due to censoring, limited sample sizes, and non-random treatment assignment. The need for answering such "when-if" questions--how the timing of an event would change under a specified intervention--commonly arises in real-world settings with heterogeneous treatment adoption and confounding. To address these challenges, we propose Synthetic Survival Control (SSC) to estimate counterfactual hazard trajectories in a panel data setting where multiple units experience potentially different treatments over multiple periods. In such a setting, SSC estimates the counterfactual hazard trajectory for a unit of interest as a weighted combination of the observed trajectories from other units. To provide formal justification, we introduce a panel framework with a low-rank structure for causal survival analysis. Indeed, such a structure naturally arises under classical parametric survival models. Within this framework, for the causal estimand of interest, we establish identification and finite sample guarantees for SSC. We validate our approach using a multi-country clinical dataset of cancer treatment outcomes, where the staggered introduction of new therapies creates a quasi-experimental setting. Empirically, we find that access to novel treatments is associated with improved survival, as reflected by lower post-intervention hazard trajectories relative to their synthetic counterparts. Given the broad relevance of survival analysis across medicine, economics, and public policy, our framework offers a general and interpretable tool for counterfactual survival inference using observational data.

</details>


### [112] [Fair-GNE : Generalized Nash Equilibrium-Seeking Fairness in Multiagent Healthcare Automation](https://arxiv.org/abs/2511.14135)
*Promise Ekpo,Saesha Agarwal,Felix Grimm,Lekan Molu,Angelique Taylor*

Main category: cs.LG

TL;DR: Fair-GNE框架将多智能体强化学习建模为约束广义纳什均衡博弈，在医疗工作者需求侧设置中实现可证明的公平工作负载分配，显著提升公平性同时保持任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有MARL方法通过事后编排来塑造奖励以实现公平，缺乏运行时个体智能体不可改变的可证明自执行公平性。在共享资源的医疗环境中，需要确保工作负载公平分配以实现一致可靠的性能。

Method: 将MARL问题建模为约束广义纳什均衡博弈，通过自适应约束执行引导群体策略达到安全且局部有效的均衡状态，使任何智能体都无法通过单方面改变决策来改善其效用函数。

Result: 在高保真复苏模拟器中，Fair-GNE相比固定惩罚基线显著改善了工作负载平衡（0.89 vs 0.33 JFI，p < 0.01），同时保持86%的任务成功率。

Conclusion: Fair-GNE通过自适应约束执行为大型多智能体学习型医疗系统提供了清晰的制定、评估指标和均衡寻求创新，实现了原则性的公平执行。

Abstract: Enforcing a fair workload allocation among multiple agents tasked to achieve an objective in learning enabled demand side healthcare worker settings is crucial for consistent and reliable performance at runtime. Existing multi-agent reinforcement learning (MARL) approaches steer fairness by shaping reward through post hoc orchestrations, leaving no certifiable self-enforceable fairness that is immutable by individual agents at runtime. Contextualized within a setting where each agent shares resources with others, we address this shortcoming with a learning enabled optimization scheme among self-interested decision makers whose individual actions affect those of other agents. This extends the problem to a generalized Nash equilibrium (GNE) game-theoretic framework where we steer group policy to a safe and locally efficient equilibrium, so that no agent can improve its utility function by unilaterally changing its decisions. Fair-GNE models MARL as a constrained generalized Nash equilibrium-seeking (GNE) game, prescribing an ideal equitable collective equilibrium within the problem's natural fabric. Our hypothesis is rigorously evaluated in our custom-designed high-fidelity resuscitation simulator. Across all our numerical experiments, Fair-GNE achieves significant improvement in workload balance over fixed-penalty baselines (0.89 vs.\ 0.33 JFI, $p < 0.01$) while maintaining 86\% task success, demonstrating statistically significant fairness gains through adaptive constraint enforcement. Our results communicate our formulations, evaluation metrics, and equilibrium-seeking innovations in large multi-agent learning-based healthcare systems with clarity and principled fairness enforcement.

</details>


### [113] [A Comprehensive Study of Implicit and Explicit Biases in Large Language Models](https://arxiv.org/abs/2511.14153)
*Fatima Kazi,Alex Young,Yash Inani,Setareh Rafatirad*

Main category: cs.LG

TL;DR: 该研究开发了一个自动偏见识别框架，用于检测LLMs中的显性和隐性社会偏见，并通过微调和数据增强策略将模型在隐性偏见基准上的性能提升了20%。


<details>
  <summary>Details</summary>
Motivation: LLMs从训练数据中继承了显性和隐性偏见，这些偏见可能传播有害的刻板印象和错误信息，因此识别和减轻LLMs中的偏见对于确保公平输出至关重要。

Method: 采用双管齐下的方法检测文本数据中的显性和隐性偏见，使用StereoSet和CrowSPairs等偏见基准评估BERT和GPT 3.5等生成模型，并应用包含提示技术和数据增强的微调策略。

Result: 微调模型在性别偏见方面表现不佳，但在识别和避免种族偏见方面表现出色。LLMs往往过度依赖关键词，词汇分析揭示了隐性刻板印象的迹象。增强策略使模型在跨数据集测试中表现出良好的适应性，隐性偏见基准性能提升高达20%。

Conclusion: 尽管取得了一定成功，但LLMs在偏见检测方面仍有局限性，需要持续改进以确保公平性。微调和数据增强是提高模型偏见识别能力的有效策略。

Abstract: Large Language Models (LLMs) inherit explicit and implicit biases from their training datasets. Identifying and mitigating biases in LLMs is crucial to ensure fair outputs, as they can perpetuate harmful stereotypes and misinformation. This study highlights the need to address biases in LLMs amid growing generative AI. We studied bias-specific benchmarks such as StereoSet and CrowSPairs to evaluate the existence of various biases in multiple generative models such as BERT and GPT 3.5. We proposed an automated Bias-Identification Framework to recognize various social biases in LLMs such as gender, race, profession, and religion. We adopted a two-pronged approach to detect explicit and implicit biases in text data. Results indicated fine-tuned models struggle with gender biases but excelled at identifying and avoiding racial biases. Our findings illustrated that despite having some success, LLMs often over-relied on keywords. To illuminate the capability of the analyzed LLMs in detecting implicit biases, we employed Bag-of-Words analysis and unveiled indications of implicit stereotyping within the vocabulary. To bolster the model performance, we applied an enhancement strategy involving fine-tuning models using prompting techniques and data augmentation of the bias benchmarks. The fine-tuned models exhibited promising adaptability during cross-dataset testing and significantly enhanced performance on implicit bias benchmarks, with performance gains of up to 20%.

</details>


### [114] [Certified Signed Graph Unlearning](https://arxiv.org/abs/2511.14168)
*Junpeng Zhao,Lin Li,Kaixi Hu,Kaize Shi,Jingling Yuan*

Main category: cs.LG

TL;DR: 提出了CSGU方法，为符号图神经网络提供可证明的隐私保证，通过三阶段方法实现高效的节点删除，同时保持模型效用。


<details>
  <summary>Details</summary>
Motivation: 现有图遗忘方法针对传统GNN设计，忽略了符号图的异质特性，应用于符号图神经网络时会丢失关键符号信息，降低模型效用和遗忘效果。

Method: 三阶段方法：1) 通过三角结构高效识别最小影响邻域；2) 应用社会学理论量化节点重要性以优化隐私预算分配；3) 执行重要性加权的参数更新以实现认证修改。

Result: 广泛实验表明CSGU优于现有方法，在符号图神经网络上实现了效用保持和遗忘效果的优越性能。

Conclusion: CSGU方法成功解决了符号图神经网络中的隐私保护问题，提供了可证明的隐私保证，同时保持了模型性能。

Abstract: Signed graphs model complex relationships through positive and negative edges, with widespread real-world applications. Given the sensitive nature of such data, selective removal mechanisms have become essential for privacy protection. While graph unlearning enables the removal of specific data influences from Graph Neural Networks (GNNs), existing methods are designed for conventional GNNs and overlook the unique heterogeneous properties of signed graphs. When applied to Signed Graph Neural Networks (SGNNs), these methods lose critical sign information, degrading both model utility and unlearning effectiveness. To address these challenges, we propose Certified Signed Graph Unlearning (CSGU), which provides provable privacy guarantees while preserving the sociological principles underlying SGNNs. CSGU employs a three-stage method: (1) efficiently identifying minimal influenced neighborhoods via triangular structures, (2) applying sociological theories to quantify node importance for optimal privacy budget allocation, and (3) performing importance-weighted parameter updates to achieve certified modifications with minimal utility degradation. Extensive experiments demonstrate that CSGU outperforms existing methods, achieving superior performance in both utility preservation and unlearning effectiveness on SGNNs.

</details>


### [115] [N-GLARE: An Non-Generative Latent Representation-Efficient LLM Safety Evaluator](https://arxiv.org/abs/2511.14195)
*Zheyu Lin,Jirui Yang,Hengqi Guo,Yubing Bao,Yao Guan*

Main category: cs.LG

TL;DR: N-GLARE是一种基于潜在表征的LLM安全评估方法，通过分析隐藏层动态来评估模型安全性，无需生成完整文本，显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 主流红队测试方法依赖在线生成和黑盒输出分析，成本高且存在反馈延迟，不适合新模型训练的敏捷诊断需求。

Method: 提出N-GLARE方法，完全基于模型潜在表征，通过分析潜在表征的APT（角度-概率轨迹）和引入JSS（Jensen-Shannon可分离性）指标来表征隐藏层动态。

Result: 在40多个模型和20种红队策略上的实验表明，JSS指标与红队测试得出的安全排名具有高度一致性，仅需不到1%的token成本和运行时成本即可重现大规模红队测试的判别趋势。

Conclusion: N-GLARE提供了一种高效的免输出评估代理，可用于实时诊断LLM的安全鲁棒性。

Abstract: Evaluating the safety robustness of LLMs is critical for their deployment. However, mainstream Red Teaming methods rely on online generation and black-box output analysis. These approaches are not only costly but also suffer from feedback latency, making them unsuitable for agile diagnostics after training a new model. To address this, we propose N-GLARE (A Non-Generative, Latent Representation-Efficient LLM Safety Evaluator). N-GLARE operates entirely on the model's latent representations, bypassing the need for full text generation. It characterizes hidden layer dynamics by analyzing the APT (Angular-Probabilistic Trajectory) of latent representations and introducing the JSS (Jensen-Shannon Separability) metric. Experiments on over 40 models and 20 red teaming strategies demonstrate that the JSS metric exhibits high consistency with the safety rankings derived from Red Teaming. N-GLARE reproduces the discriminative trends of large-scale red-teaming tests at less than 1\% of the token cost and the runtime cost, providing an efficient output-free evaluation proxy for real-time diagnostics.

</details>


### [116] [Bridging the Gap Between Bayesian Deep Learning and Ensemble Weather Forecasts](https://arxiv.org/abs/2511.14218)
*Xinlei Xiong,Wenbo Hu,Shuxun Zhou,Kaifeng Bi,Lingxi Xie,Ying Liu,Richang Hong,Qi Tian*

Main category: cs.LG

TL;DR: 提出了一个统一的混合贝叶斯深度学习框架，将集合预报与贝叶斯深度学习相结合，显式分解预测不确定性为认知不确定性和偶然不确定性，在ERA5数据集上验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 天气预测面临大气混沌性的挑战，需要概率方法来量化不确定性。传统集合预报计算密集，而贝叶斯深度学习提供了有前景但往往分离的替代方案，需要桥接这两种范式。

Method: 通过变分推理学习认知不确定性，通过物理信息随机扰动方案建模流依赖大气动力学来学习偶然不确定性，建立了连接BDL和EPS的统一理论框架。

Result: 在ERA5数据集上的实验结果表明，该方法不仅提高了预测精度和不确定性量化校准度，而且相比最先进的概率扩散模型实现了更优的计算效率。

Conclusion: 提出的混合贝叶斯深度学习框架成功桥接了集合预报和贝叶斯深度学习，为天气预测提供了更准确、校准更好且计算高效的解决方案。

Abstract: Weather forecasting is fundamentally challenged by the chaotic nature of the atmosphere, necessitating probabilistic approaches to quantify uncertainty. While traditional ensemble prediction (EPS) addresses this through computationally intensive simulations, recent advances in Bayesian Deep Learning (BDL) offer a promising but often disconnected alternative. We bridge these paradigms through a unified hybrid Bayesian Deep Learning framework for ensemble weather forecasting that explicitly decomposes predictive uncertainty into epistemic and aleatoric components, learned via variational inference and a physics-informed stochastic perturbation scheme modeling flow-dependent atmospheric dynamics, respectively. We further establish a unified theoretical framework that rigorously connects BDL and EPS, providing formal theorems that decompose total predictive uncertainty into epistemic and aleatoric components under the hybrid BDL framework. We validate our framework on the large-scale 40-year ERA5 reanalysis dataset (1979-2019) with 0.25° spatial resolution. Experimental results show that our method not only improves forecast accuracy and yields better-calibrated uncertainty quantification but also achieves superior computational efficiency compared to state-of-the-art probabilistic diffusion models. We commit to making our code open-source upon acceptance of this paper.

</details>


### [117] [Parallelizing Tree Search with Twice Sequential Monte Carlo](https://arxiv.org/abs/2511.14220)
*Yaniv Oren,Joery A. de Vries,Pascal R. van der Vaart,Matthijs T. J. Spaan,Wendelin Böhmer*

Main category: cs.LG

TL;DR: 提出了TSMCTS算法来解决SMC方法的大方差和路径退化问题，在离散和连续环境中优于SMC基线和现代MCTS版本，能够更好地扩展搜索深度。


<details>
  <summary>Details</summary>
Motivation: 基于模型的强化学习方法中，SMC作为MCTS的替代方案更易于并行化和GPU加速，但存在大方差和路径退化问题，限制了其在深度搜索中的扩展能力。

Method: 提出了TSMCTS（两次序列蒙特卡洛树搜索）算法，通过方差减少和路径退化缓解技术来改进SMC方法。

Result: 在离散和连续环境中，TSMCTS优于SMC基线和现代MCTS版本，能够更好地随着顺序计算（搜索深度）的增加而扩展。

Conclusion: TSMCTS通过解决SMC的方差和路径退化问题，在保持SMC易于并行化特性的同时，实现了更好的搜索深度扩展性能。

Abstract: Model-based reinforcement learning (RL) methods that leverage search are responsible for many milestone breakthroughs in RL. Sequential Monte Carlo (SMC) recently emerged as an alternative to the Monte Carlo Tree Search (MCTS) algorithm which drove these breakthroughs. SMC is easier to parallelize and more suitable to GPU acceleration. However, it also suffers from large variance and path degeneracy which prevent it from scaling well with increased search depth, i.e., increased sequential compute. To address these problems, we introduce Twice Sequential Monte Carlo Tree Search (TSMCTS). Across discrete and continuous environments TSMCTS outperforms the SMC baseline as well as a popular modern version of MCTS. Through variance reduction and mitigation of path degeneracy, TSMCTS scales favorably with sequential compute while retaining the properties that make SMC natural to parallelize.

</details>


### [118] [EBind: a practical approach to space binding](https://arxiv.org/abs/2511.14229)
*Jim Broadbent,Felix Cohen,Frederik Hvilshøj,Eric Landau,Eren Sasoglu*

Main category: cs.LG

TL;DR: EBind是一种简单、以数据为中心且参数高效的方法，可将多种对比模型的嵌入空间绑定在一起。通过精心策划的数据集，仅用1.8B参数的图像-文本-视频-音频-3D模型就能超越4-17倍大小的模型，且可在单GPU上几小时内完成训练。


<details>
  <summary>Details</summary>
Motivation: 简化空间绑定过程，通过专注于单一编码器和高质量数据，实现在单GPU上快速训练最先进模型，而不需要多天时间。

Method: 使用三种互补数据源：670万全自动多模态五元组、100万人工标注的三元组（负匹配、部分匹配、正匹配）和340万现有标注数据项。采用13种不同评估方法验证每个数据源的价值。

Result: 1.8B参数模型在性能上超越4-17倍大小的模型，并引入了首个高质量、共识标注的音频与点云零样本分类基准。

Conclusion: EBind方法通过精心策划的数据集和参数高效的设计，实现了在多模态嵌入空间绑定方面的卓越性能，并将开源代码、模型权重和数据集。

Abstract: We simplify space binding by focusing on two core components, a single encoder per modality and high-quality data; enabling training state-of-the-art models on a single GPU in a few hours as opposed to multiple days. We present EBind, an Easy, data-centric, and parameter-efficient method to Bind the embedding spaces of multiple contrastive models. We demonstrate that a simple 1.8B-parameter image-text-video-audio-3D model can outperform models 4 to 17x the size. The key to achieving this is a carefully curated dataset of three complementary data sources: i) 6.7M fully-automated multimodal quintuples sourced via SOTA retrieval models, ii) 1M diverse, semi-automated triples annotated by humans as negative, partial, or positive matches, and iii) 3.4M pre-existing captioned data items. We use 13 different evaluations to demonstrate the value of each data source. Due to limitations with existing benchmarks, we further introduce the first high-quality, consensus-annotated zero-shot classification benchmark between audio and PCs. In contrast to related work, we will open-source our code, model weights, and datasets.

</details>


### [119] [Object-Centric World Models for Causality-Aware Reinforcement Learning](https://arxiv.org/abs/2511.14262)
*Yosuke Nishimoto,Takashi Matsubara*

Main category: cs.LG

TL;DR: STICA是一个统一的强化学习框架，使用对象为中心的Transformer作为世界模型，通过分解环境为离散对象来提升样本效率和性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有世界模型难以准确模拟高维、非平稳且包含多对象丰富交互的环境，而人类通过分解环境为离散对象来高效决策。

Method: 将观察表示为对象中心token集合，使用Transformer预测token级动态和交互，策略和价值网络估计token级因果关系并用于注意力层。

Result: 在对象丰富的基准测试中，STICA在样本效率和最终性能方面始终优于最先进的智能体。

Conclusion: 对象中心表示和因果感知机制能够有效提升强化学习智能体在复杂环境中的表现。

Abstract: World models have been developed to support sample-efficient deep reinforcement learning agents. However, it remains challenging for world models to accurately replicate environments that are high-dimensional, non-stationary, and composed of multiple objects with rich interactions since most world models learn holistic representations of all environmental components. By contrast, humans perceive the environment by decomposing it into discrete objects, facilitating efficient decision-making. Motivated by this insight, we propose \emph{Slot Transformer Imagination with CAusality-aware reinforcement learning} (STICA), a unified framework in which object-centric Transformers serve as the world model and causality-aware policy and value networks. STICA represents each observation as a set of object-centric tokens, together with tokens for the agent action and the resulting reward, enabling the world model to predict token-level dynamics and interactions. The policy and value networks then estimate token-level cause--effect relations and use them in the attention layers, yielding causality-guided decision-making. Experiments on object-rich benchmarks demonstrate that STICA consistently outperforms state-of-the-art agents in both sample efficiency and final performance.

</details>


### [120] [Algebraformer: A Neural Approach to Linear Systems](https://arxiv.org/abs/2511.14263)
*Pietro Sittoni,Francesco Tudisco*

Main category: cs.LG

TL;DR: 提出了Algebraformer，一种基于Transformer的架构，用于端到端学习求解线性系统，特别是病态系统，具有O(n²)内存复杂度，在谱方法插值和牛顿法加速等应用中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的数值方法求解病态线性系统需要精心调整参数、预处理或领域专业知识，而深度学习为使用端到端学习模型解决经典算法任务提供了新的可能性。

Method: 提出Algebraformer，一种基于Transformer的架构，采用新颖的编码方案高效表示矩阵和向量输入，支持可扩展推理。

Result: 在谱方法边界值问题的插值任务和牛顿法加速等应用驱动线性问题上，Algebraformer实现了竞争性精度，且测试时计算开销显著降低。

Conclusion: 通用神经网络架构可以有效降低传统科学计算流程的复杂度，为求解病态线性系统提供了新的解决方案。

Abstract: Recent work in deep learning has opened new possibilities for solving classical algorithmic tasks using end-to-end learned models. In this work, we investigate the fundamental task of solving linear systems, particularly those that are ill-conditioned. Existing numerical methods for ill-conditioned systems often require careful parameter tuning, preconditioning, or domain-specific expertise to ensure accuracy and stability. In this work, we propose Algebraformer, a Transformer-based architecture that learns to solve linear systems end-to-end, even in the presence of severe ill-conditioning. Our model leverages a novel encoding scheme that enables efficient representation of matrix and vector inputs, with a memory complexity of $O(n^2)$, supporting scalable inference. We demonstrate its effectiveness on application-driven linear problems, including interpolation tasks from spectral methods for boundary value problems and acceleration of the Newton method. Algebraformer achieves competitive accuracy with significantly lower computational overhead at test time, demonstrating that general-purpose neural architectures can effectively reduce complexity in traditional scientific computing pipelines.

</details>


### [121] [Unified Multimodal Vessel Trajectory Prediction with Explainable Navigation Intention](https://arxiv.org/abs/2511.14265)
*Rui Zhang,Chao Li,Kezhong Liu,Chen Wang,Bolong Zheng,Hongbo Jiang*

Main category: cs.LG

TL;DR: 提出了一种结合可解释导航意图的统一多模态轨迹预测框架，通过持续意图树和瞬态意图建模，在复杂海事环境中实现更准确和可解释的船舶轨迹预测。


<details>
  <summary>Details</summary>
Motivation: 现有船舶多模态轨迹预测方法存在场景适用性有限和可解释性不足的问题，特别是在复杂海事环境中预测快速行为变化时。

Method: 构建持续意图树从历史轨迹中提取信息，使用条件变分自编码器建模动态瞬态意图，并采用非局部注意力机制保持全局场景一致性。

Result: 在真实AIS数据集上的实验表明，该方法在多种场景下具有广泛适用性，在ADE和FDE指标上取得显著提升。

Conclusion: 该方法通过显式揭示每个预测轨迹背后的导航意图，提高了轨迹预测的可解释性，为智能海事系统提供了更可靠的预测能力。

Abstract: Vessel trajectory prediction is fundamental to intelligent maritime systems. Within this domain, short-term prediction of rapid behavioral changes in complex maritime environments has established multimodal trajectory prediction (MTP) as a promising research area. However, existing vessel MTP methods suffer from limited scenario applicability and insufficient explainability. To address these challenges, we propose a unified MTP framework incorporating explainable navigation intentions, which we classify into sustained and transient categories. Our method constructs sustained intention trees from historical trajectories and models dynamic transient intentions using a Conditional Variational Autoencoder (CVAE), while using a non-local attention mechanism to maintain global scenario consistency. Experiments on real Automatic Identification System (AIS) datasets demonstrates our method's broad applicability across diverse scenarios, achieving significant improvements in both ADE and FDE. Furthermore, our method improves explainability by explicitly revealing the navigational intentions underlying each predicted trajectory.

</details>


### [122] [Comparing Task-Agnostic Embedding Models for Tabular Data](https://arxiv.org/abs/2511.14276)
*Frederik Hoppe,Lars Kleinemeier,Astrid Franz,Udo Göbel*

Main category: cs.LG

TL;DR: 本文系统评估了表格基础模型（TabPFN和TabICL）与经典特征工程（TableVectorizer）在异常检测和监督学习任务中的表现，发现TableVectorizer在性能相当或更优的情况下比表格基础模型快三个数量级。


<details>
  <summary>Details</summary>
Motivation: 当前表格基础模型通过上下文学习实现强大的任务特定性能，但它们将表示学习和任务特定推理封装在单个资源密集型网络中。本文专注于表示学习，即研究可迁移、任务无关的嵌入表示。

Method: 系统评估表格基础模型（TabPFN和TabICL）和经典特征工程方法（TableVectorizer）在异常检测（ADBench）和监督学习（TabArena Lite）等多种应用任务中的表现。

Result: 发现简单的TableVectorizer特征在性能相当或更优的情况下，比表格基础模型快三个数量级。

Conclusion: 经典特征工程方法在表格数据表示学习中仍然具有竞争力，特别是在考虑计算效率的情况下。

Abstract: Recent foundation models for tabular data achieve strong task-specific performance via in-context learning. Nevertheless, they focus on direct prediction by encapsulating both representation learning and task-specific inference inside a single, resource-intensive network. This work specifically focuses on representation learning, i.e., on transferable, task-agnostic embeddings. We systematically evaluate task-agnostic representations from tabular foundation models (TabPFN and TabICL) alongside with classical feature engineering (TableVectorizer) across a variety of application tasks as outlier detection (ADBench) and supervised learning (TabArena Lite). We find that simple TableVectorizer features achieve comparable or superior performance while being up to three orders of magnitude faster than tabular foundation models. The code is available at https://github.com/ContactSoftwareAI/TabEmbedBench.

</details>


### [123] [Weight Variance Amplifier Improves Accuracy in High-Sparsity One-Shot Pruning](https://arxiv.org/abs/2511.14282)
*Vincent-Daniel Yun,Junhyuk Jo,Sunwoo Lee*

Main category: cs.LG

TL;DR: 提出一种方差放大正则器（VAR），通过增加模型参数的方差来提高剪枝鲁棒性，相比现有方法在减少计算开销的同时保持剪枝后的准确性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络参数量大，不利于实际应用。一次性剪枝是有效的模型压缩方法，但标准目标函数训练的模型在激进剪枝后准确率显著下降。现有剪枝鲁棒优化器如SAM、CrAM虽然能缓解这一问题，但会带来不可忽视的额外计算开销。

Method: 提出方差放大正则器（VAR），在训练过程中故意增加模型参数的方差。研究发现方差更高的参数表现出更好的剪枝鲁棒性，VAR利用这一特性通过促进权重分布的方差来减轻剪枝的不利影响。

Result: 提供了理论收敛性分析，并通过大量实证结果证明了VAR在剪枝鲁棒性方面的优越性能。

Conclusion: VAR是一种有效的剪枝鲁棒训练方法，能够在减少计算开销的同时保持模型在剪枝后的准确性。

Abstract: Deep neural networks achieve outstanding performance in visual recognition tasks, yet their large number of parameters makes them less practical for real-world applications. Recently, one-shot pruning has emerged as an effective strategy for reducing model size without additional training. However, models trained with standard objective functions often suffer a significant drop in accuracy after aggressive pruning. Some existing pruning-robust optimizers, such as SAM, and CrAM, mitigate this accuracy drop by guiding the model toward flatter regions of the parameter space, but they inevitably incur non-negligible additional computations. We propose a Variance Amplifying Regularizer (VAR) that deliberately increases the variance of model parameters during training. Our study reveals an intriguing finding that parameters with higher variance exhibit greater pruning robustness. VAR exploits this property by promoting such variance in the weight distribution, thereby mitigating the adverse effects of pruning. We further provide a theoretical analysis of its convergence behavior, supported by extensive empirical results demonstrating the superior pruning robustness of VAR.

</details>


### [124] [H-LDM: Hierarchical Latent Diffusion Models for Controllable and Interpretable PCG Synthesis from Clinical Metadata](https://arxiv.org/abs/2511.14312)
*Chenyang Xu,Siming Li,Hao Wang*

Main category: cs.LG

TL;DR: H-LDM是一个分层潜在扩散模型，用于从结构化元数据生成临床准确且可控的心音图信号，解决了病理数据稀缺问题，在数据增强和罕见疾病分类方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 心音图分析对心血管疾病诊断至关重要，但标记的病理数据稀缺限制了AI系统的能力。需要生成临床准确且可控的PCG信号来弥补数据不足。

Method: 采用多尺度VAE学习生理解缠的潜在空间，分离节律、心音和杂音；构建分层文本到生物信号管道，利用丰富的临床元数据对17种不同条件进行细粒度控制；使用医学注意力模块指导可解释的扩散过程。

Result: 在PhysioNet CirCor数据集上实现最先进性能：Fréchet音频距离9.7，属性解缠得分92%，临床有效性87.1%。使用合成数据增强诊断模型可将罕见疾病分类准确率提高11.3%。

Conclusion: H-LDM为心脏诊断中的数据增强开辟了新方向，通过可解释的临床洞察弥合了数据稀缺问题。

Abstract: Phonocardiogram (PCG) analysis is vital for cardiovascular disease diagnosis, yet the scarcity of labeled pathological data hinders the capability of AI systems. To bridge this, we introduce H-LDM, a Hierarchical Latent Diffusion Model for generating clinically accurate and controllable PCG signals from structured metadata. Our approach features: (1) a multi-scale VAE that learns a physiologically-disentangled latent space, separating rhythm, heart sounds, and murmurs; (2) a hierarchical text-to-biosignal pipeline that leverages rich clinical metadata for fine-grained control over 17 distinct conditions; and (3) an interpretable diffusion process guided by a novel Medical Attention module. Experiments on the PhysioNet CirCor dataset demonstrate state-of-the-art performance, achieving a Fréchet Audio Distance of 9.7, a 92% attribute disentanglement score, and 87.1% clinical validity confirmed by cardiologists. Augmenting diagnostic models with our synthetic data improves the accuracy of rare disease classification by 11.3\%. H-LDM establishes a new direction for data augmentation in cardiac diagnostics, bridging data scarcity with interpretable clinical insights.

</details>


### [125] [Intervention Efficiency and Perturbation Validation Framework: Capacity-Aware and Robust Clinical Model Selection under the Rashomon Effect](https://arxiv.org/abs/2511.14317)
*Yuwen Zhang,Viet Tran,Paul Weng*

Main category: cs.LG

TL;DR: 为解决临床机器学习中的Rashomon效应（多个模型性能相近难以选择的问题），提出了两种互补工具：干预效率(IE)和扰动验证框架(PVF)，用于在资源约束下选择更稳健且符合临床效用的模型。


<details>
  <summary>Details</summary>
Motivation: 临床机器学习中存在多个性能相近的模型（Rashomon效应），加上数据不平衡、噪声多、特征高维等问题，使传统验证方法不可靠，难以在资源约束下选择最优模型。

Method: 提出干预效率(IE)作为容量感知指标，量化模型在有限干预资源下识别可操作真阳性的效率；提出扰动验证框架(PVF)评估模型在数据扰动下的稳定性。

Result: 在合成和真实医疗数据集上的实验表明，使用这些工具能够选择出更稳健泛化且符合容量约束的模型。

Conclusion: IE和PVF为解决临床环境中的Rashomon效应提供了新方向，将预测性能与临床效用联系起来，支持在资源约束下做出更可靠的模型选择。

Abstract: In clinical machine learning, the coexistence of multiple models with comparable performance -- a manifestation of the Rashomon Effect -- poses fundamental challenges for trustworthy deployment and evaluation. Small, imbalanced, and noisy datasets, coupled with high-dimensional and weakly identified clinical features, amplify this multiplicity and make conventional validation schemes unreliable. As a result, selecting among equally performing models becomes uncertain, particularly when resource constraints and operational priorities are not considered by conventional metrics like F1 score. To address these issues, we propose two complementary tools for robust model assessment and selection: Intervention Efficiency (IE) and the Perturbation Validation Framework (PVF). IE is a capacity-aware metric that quantifies how efficiently a model identifies actionable true positives when only limited interventions are feasible, thereby linking predictive performance with clinical utility. PVF introduces a structured approach to assess the stability of models under data perturbations, identifying models whose performance remains most invariant across noisy or shifted validation sets. Empirical results on synthetic and real-world healthcare datasets show that using these tools facilitates the selection of models that generalize more robustly and align with capacity constraints, offering a new direction for tackling the Rashomon Effect in clinical settings.

</details>


### [126] [Learning with Statistical Equality Constraints](https://arxiv.org/abs/2511.14320)
*Aneesh Barthakur,Luiz F. O. Chamon*

Main category: cs.LG

TL;DR: 本文提出了针对包含等式约束的统计学习问题的泛化理论，并开发了一种实用的序列无约束优化算法，在公平学习、插值分类器和边值问题中展示了有效性。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习应用日益复杂，除了准确性外还需要满足各种要求。现有方法需要仔细调整超参数权重，对于包含等式约束（如公平性和边值问题）的情况尤其困难，且现有理论不适用于等式约束问题。

Method: 推导了等式约束统计学习问题的泛化理论，提出基于求解一系列无约束经验学习问题的实用算法。

Result: 证明了等式约束学习问题的解可以通过样本和丰富参数化来近似，提出的算法在公平学习、插值分类器和边值问题中展现出有效性。

Conclusion: 该工作为包含等式约束的机器学习问题提供了理论保证和实用算法，扩展了约束优化在机器学习中的应用范围。

Abstract: As machine learning applications grow increasingly ubiquitous and complex, they face an increasing set of requirements beyond accuracy. The prevalent approach to handle this challenge is to aggregate a weighted combination of requirement violation penalties into the training objective. To be effective, this approach requires careful tuning of these hyperparameters (weights), involving trial-and-error and cross-validation, which becomes ineffective even for a moderate number of requirements. These issues are exacerbated when the requirements involve parities or equalities, as is the case in fairness and boundary value problems. An alternative technique uses constrained optimization to formulate these learning problems. Yet, existing approximation and generalization guarantees do not apply to problems involving equality constraints. In this work, we derive a generalization theory for equality-constrained statistical learning problems, showing that their solutions can be approximated using samples and rich parametrizations. Using these results, we propose a practical algorithm based on solving a sequence of unconstrained, empirical learning problems. We showcase its effectiveness and the new formulations enabled by equality constraints in fair learning, interpolating classifiers, and boundary value problems.

</details>


### [127] [Watch Out for the Lifespan: Evaluating Backdoor Attacks Against Federated Model Adaptation](https://arxiv.org/abs/2511.14406)
*Bastien Vuillod,Pierre-Alain Moellic,Jean-Max Dutertre*

Main category: cs.LG

TL;DR: 本文分析了联邦学习中LoRA对后门攻击的影响，发现LoRA秩越低，后门持久性越长，并指出了FL中后门攻击评估的问题。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中的大模型适配面临安全威胁，特别是后门攻击，需要分析LoRA技术对这些攻击的影响。

Method: 通过实验分析LoRA在不同秩设置下对最先进后门攻击的影响，重点关注后门寿命这一关键特征。

Result: 关键发现：对于最优注入的后门，当LoRA的秩较低时，攻击后的后门持久性更长。

Conclusion: 研究揭示了FL中后门攻击评估的问题，有助于开发更稳健和公平的评估方法，提高关键FL系统风险评估的可靠性。

Abstract: Large models adaptation through Federated Learning (FL) addresses a wide range of use cases and is enabled by Parameter-Efficient Fine-Tuning techniques such as Low-Rank Adaptation (LoRA). However, this distributed learning paradigm faces several security threats, particularly to its integrity, such as backdoor attacks that aim to inject malicious behavior during the local training steps of certain clients. We present the first analysis of the influence of LoRA on state-of-the-art backdoor attacks targeting model adaptation in FL. Specifically, we focus on backdoor lifespan, a critical characteristic in FL, that can vary depending on the attack scenario and the attacker's ability to effectively inject the backdoor. A key finding in our experiments is that for an optimally injected backdoor, the backdoor persistence after the attack is longer when the LoRA's rank is lower. Importantly, our work highlights evaluation issues of backdoor attacks against FL and contributes to the development of more robust and fair evaluations of backdoor attacks, enhancing the reliability of risk assessments for critical FL systems. Our code is publicly available.

</details>


### [128] [Toward Robust and Harmonious Adaptation for Cross-modal Retrieval](https://arxiv.org/abs/2511.14416)
*Haobin Li,Mouxing Yang,Xi Peng*

Main category: cs.LG

TL;DR: 本文提出REST方法解决跨模态检索中的查询偏移问题，包括在线偏移和多样偏移，通过查询预测和梯度解耦实现在线鲁棒适应。


<details>
  <summary>Details</summary>
Motivation: 现有通用到定制化跨模态检索方法假设目标域数据完全可用，但现实场景中查询以在线方式到达且具有多样性，导致查询偏移问题，破坏通用空间结构并遗忘通用知识。

Method: REST方法：1）通过精炼检索结果生成查询预测，设计QS鲁棒目标函数在线保护通用空间；2）使用梯度解耦模块在适应过程中巧妙操纵梯度，防止模型遗忘通用知识。

Result: 在3个跨模态检索任务的20个基准测试上进行广泛实验，验证了该方法对抗查询偏移的有效性。

Conclusion: REST方法能够有效解决跨模态检索中的查询偏移问题，实现在线鲁棒适应，同时保持通用知识。

Abstract: Recently, the general-to-customized paradigm has emerged as the dominant approach for Cross-Modal Retrieval (CMR), which reconciles the distribution shift problem between the source domain and the target domain. However, existing general-to-customized CMR methods typically assume that the entire target-domain data is available, which is easily violated in real-world scenarios and thus inevitably suffer from the query shift (QS) problem. Specifically, query shift embraces the following two characteristics and thus poses new challenges to CMR. i) Online Shift: real-world queries always arrive in an online manner, rendering it impractical to access the entire query set beforehand for customization approaches; ii) Diverse Shift: even with domain customization, the CMR models struggle to satisfy queries from diverse users or scenarios, leaving an urgent need to accommodate diverse queries. In this paper, we observe that QS would not only undermine the well-structured common space inherited from the source model, but also steer the model toward forgetting the indispensable general knowledge for CMR. Inspired by the observations, we propose a novel method for achieving online and harmonious adaptation against QS, dubbed Robust adaptation with quEry ShifT (REST). To deal with online shift, REST first refines the retrieval results to formulate the query predictions and accordingly designs a QS-robust objective function on these predictions to preserve the well-established common space in an online manner. As for tackling the more challenging diverse shift, REST employs a gradient decoupling module to dexterously manipulate the gradients during the adaptation process, thus preventing the CMR model from forgetting the general knowledge. Extensive experiments on 20 benchmarks across three CMR tasks verify the effectiveness of our method against QS.

</details>


### [129] [FlowRoI A Fast Optical Flow Driven Region of Interest Extraction Framework for High-Throughput Image Compression in Immune Cell Migration Analysis](https://arxiv.org/abs/2511.14419)
*Xiaowei Xu,Justin Sonneck,Hongxiao Wang,Roman Burkard,Hendrik Wohrle,Anton Grabmasier,Matthias Gunzer,Jianxu Chen*

Main category: cs.LG

TL;DR: FlowRoI是一个基于光流的感兴趣区域提取框架，用于高通量免疫细胞迁移研究中的图像压缩，通过结合光流估计和JPEG2000编码实现高效压缩。


<details>
  <summary>Details</summary>
Motivation: 高通量成像平台如ComplexEye产生大量数据，给存储和传输带来巨大负担，需要高效的压缩方法。

Method: FlowRoI通过估计连续帧之间的光流来提取覆盖迁移细胞的RoI掩码，然后将原始图像和RoI掩码联合使用JPEG2000编码，实现RoI感知压缩。

Result: FlowRoI计算效率高，在现代笔记本电脑上达到约30帧/秒的处理速度，在细胞区域有更高的PSNR，在相同PSNR下比标准JPEG2000压缩率高2.0-2.2倍。

Conclusion: FlowRoI为高通量细胞迁移研究提供了一种高效的数据压缩解决方案，显著提高了压缩效率同时保持图像质量。

Abstract: Autonomous migration is essential for the function of immune cells such as neutrophils and plays a pivotal role in diverse diseases. Recently, we introduced ComplexEye, a multi-lens array microscope comprising 16 independent aberration-corrected glass lenses arranged at the pitch of a 96-well plate, capable of capturing high-resolution movies of migrating cells. This architecture enables high-throughput live-cell video microscopy for migration analysis, supporting routine quantification of autonomous motility with strong potential for clinical translation. However, ComplexEye and similar high-throughput imaging platforms generate data at an exponential rate, imposing substantial burdens on storage and transmission. To address this challenge, we present FlowRoI, a fast optical-flow-based region of interest (RoI) extraction framework designed for high-throughput image compression in immune cell migration studies. FlowRoI estimates optical flow between consecutive frames and derives RoI masks that reliably cover nearly all migrating cells. The raw image and its corresponding RoI mask are then jointly encoded using JPEG2000 to enable RoI-aware compression. FlowRoI operates with high computational efficiency, achieving runtimes comparable to standard JPEG2000 and reaching an average throughput of about 30 frames per second on a modern laptop equipped with an Intel i7-1255U CPU. In terms of image quality, FlowRoI yields higher peak signal-to-noise ratio (PSNR) in cellular regions and achieves 2.0-2.2x higher compression rates at matched PSNR compared to standard JPEG2000.

</details>


### [130] [Hybrid Modeling of Photoplethysmography for Non-invasive Monitoring of Cardiovascular Parameters](https://arxiv.org/abs/2511.14452)
*Emanuele Palumbo,Sorawit Saengkyongam,Maria R. Cervera,Jens Behrmann,Andrew C. Miller,Guillermo Sapiro,Christina Heinze-Deml,Antoine Wehenkel*

Main category: cs.LG

TL;DR: 提出了一种混合方法，通过血流动力学模拟和未标记的临床数据，直接从PPG信号估计心血管生物标志物，解决了从PPG预测关键心脏生物标志物的挑战。


<details>
  <summary>Details</summary>
Motivation: 连续心血管监测在精准健康中起关键作用，但关键心脏生物标志物如每搏输出量和心输出量需要侵入性测量。PPG作为非侵入性替代方案，但预测这些生物标志物仍面临挑战且缺乏标注数据。

Method: 结合条件变分自编码器和条件密度估计器的混合模型，使用配对PPG-APW数据和标记的模拟APW片段进行训练。

Result: 实验表明该方法能够检测心输出量和每搏输出量的波动，并在监测这些生物标志物时间变化方面优于监督基线。

Conclusion: 提出的混合方法能够直接从PPG信号有效估计心血管生物标志物，为非侵入性心血管监测提供了可行方案。

Abstract: Continuous cardiovascular monitoring can play a key role in precision health. However, some fundamental cardiac biomarkers of interest, including stroke volume and cardiac output, require invasive measurements, e.g., arterial pressure waveforms (APW). As a non-invasive alternative, photoplethysmography (PPG) measurements are routinely collected in hospital settings. Unfortunately, the prediction of key cardiac biomarkers from PPG instead of APW remains an open challenge, further complicated by the scarcity of annotated PPG measurements. As a solution, we propose a hybrid approach that uses hemodynamic simulations and unlabeled clinical data to estimate cardiovascular biomarkers directly from PPG signals. Our hybrid model combines a conditional variational autoencoder trained on paired PPG-APW data with a conditional density estimator of cardiac biomarkers trained on labeled simulated APW segments. As a key result, our experiments demonstrate that the proposed approach can detect fluctuations of cardiac output and stroke volume and outperform a supervised baseline in monitoring temporal changes in these biomarkers.

</details>


### [131] [Nonparametric estimation of conditional probability distributions using a generative approach based on conditional push-forward neural networks](https://arxiv.org/abs/2511.14455)
*Nicola Rares Franco,Lorenzo Tedesco*

Main category: cs.LG

TL;DR: CPFN是一种条件分布估计的生成框架，通过随机映射学习条件分布，支持高效的条件采样和蒙特卡洛统计估计，无需可逆性或对抗训练。


<details>
  <summary>Details</summary>
Motivation: 解决条件分布估计问题，提供高效的采样和统计估计方法，避免传统方法中的可逆性或对抗训练需求。

Method: 学习随机映射φ(x,u)，使得φ(x,U)与Y|X=x的分布近似相同，通过KL散度目标函数训练模型。

Result: 实验表明CPFN性能可与或优于最先进方法（包括核估计、树基算法和深度学习技术），同时保持轻量级和易训练特性。

Conclusion: CPFN提供了一个有效且实用的条件分布估计框架，在保持竞争力的同时简化了训练过程。

Abstract: We introduce conditional push-forward neural networks (CPFN), a generative framework for conditional distribution estimation. Instead of directly modeling the conditional density $f_{Y|X}$, CPFN learns a stochastic map $\varphi=\varphi(x,u)$ such that $\varphi(x,U)$ and $Y|X=x$ follow approximately the same law, with $U$ a suitable random vector of pre-defined latent variables. This enables efficient conditional sampling and straightforward estimation of conditional statistics through Monte Carlo methods. The model is trained via an objective function derived from a Kullback-Leibler formulation, without requiring invertibility or adversarial training. We establish a near-asymptotic consistency result and demonstrate experimentally that CPFN can achieve performance competitive with, or even superior to, state-of-the-art methods, including kernel estimators, tree-based algorithms, and popular deep learning techniques, all while remaining lightweight and easy to train.

</details>


### [132] [nnterp: A Standardized Interface for Mechanistic Interpretability of Transformers](https://arxiv.org/abs/2511.14465)
*Clément Dumas*

Main category: cs.LG

TL;DR: nnterp是一个轻量级的NNsight包装器，为transformer分析提供统一接口，同时保留原始HuggingFace实现，解决了现有工具在一致性和准确性之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 当前机制可解释性研究工具面临基本权衡：自定义实现（如TransformerLens）确保接口一致但需要为每个架构手动适配且存在数值不匹配，而直接使用HuggingFace（通过NNsight）保留精确行为但缺乏跨模型标准化。

Method: 开发nnterp作为NNsight的轻量级包装器，通过自动模块重命名和全面验证测试，提供统一的transformer分析接口，同时保留原始HuggingFace实现。

Result: nnterp使研究人员能够编写一次干预代码并在50+模型变体（涵盖16个架构家族）上部署，包含常见可解释性方法的内置实现，并提供对支持模型的注意力概率直接访问。

Conclusion: nnterp通过打包验证测试，在机制可解释性工具中弥合了正确性和可用性之间的差距。

Abstract: Mechanistic interpretability research requires reliable tools for analyzing transformer internals across diverse architectures. Current approaches face a fundamental tradeoff: custom implementations like TransformerLens ensure consistent interfaces but require coding a manual adaptation for each architecture, introducing numerical mismatch with the original models, while direct HuggingFace access through NNsight preserves exact behavior but lacks standardization across models. To bridge this gap, we develop nnterp, a lightweight wrapper around NNsight that provides a unified interface for transformer analysis while preserving original HuggingFace implementations. Through automatic module renaming and comprehensive validation testing, nnterp enables researchers to write intervention code once and deploy it across 50+ model variants spanning 16 architecture families. The library includes built-in implementations of common interpretability methods (logit lens, patchscope, activation steering) and provides direct access to attention probabilities for models that support it. By packaging validation tests with the library, researchers can verify compatibility with custom models locally. nnterp bridges the gap between correctness and usability in mechanistic interpretability tooling.

</details>


### [133] [Notes on Kernel Methods in Machine Learning](https://arxiv.org/abs/2511.14485)
*Diego Armando Pérez-Rosero,Danna Valentina Salazar-Dubois,Juan Camilo Lugo-Rojas,Andrés Marino Álvarez-Meza,Germán Castellanos-Dominguez*

Main category: cs.LG

TL;DR: 本文提供了核方法及其在机器学习中几何基础的自包含介绍，涵盖希尔伯特空间、正定核、再生核希尔伯特空间等核心概念，以及它们在统计估计和概率测度表示中的应用。


<details>
  <summary>Details</summary>
Motivation: 为机器学习中的核方法提供系统的几何基础，建立从希尔伯特空间构造到实际应用的完整理论框架，为高斯过程、核贝叶斯推断等高级主题奠定基础。

Method: 从希尔伯特空间构造出发，系统发展正定核、再生核希尔伯特空间和希尔伯特-施密特算子理论，通过希尔伯特空间几何重新审视协方差、回归和信息度量等经典概念。

Result: 建立了核密度估计、分布核嵌入和最大均值差异的理论基础，提供了统计估计和概率测度表示的几何视角。

Conclusion: 该介绍性工作为理解核方法在机器学习中的应用提供了坚实的数学基础，并为高斯过程、核贝叶斯推断等高级主题做好了理论准备。

Abstract: These notes provide a self-contained introduction to kernel methods and their geometric foundations in machine learning. Starting from the construction of Hilbert spaces, we develop the theory of positive definite kernels, reproducing kernel Hilbert spaces (RKHS), and Hilbert-Schmidt operators, emphasizing their role in statistical estimation and representation of probability measures. Classical concepts such as covariance, regression, and information measures are revisited through the lens of Hilbert space geometry. We also introduce kernel density estimation, kernel embeddings of distributions, and the Maximum Mean Discrepancy (MMD). The exposition is designed to serve as a foundation for more advanced topics, including Gaussian processes, kernel Bayesian inference, and functional analytic approaches to modern machine learning.

</details>


### [134] [Towards Stable and Structured Time Series Generation with Perturbation-Aware Flow Matching](https://arxiv.org/abs/2511.14488)
*Jintao Zhang,Mingyue Cheng,Zirui Liu,Xianquan Wang,Yitong Zhou,Qi Liu*

Main category: cs.LG

TL;DR: PAFM是一个扰动感知的流匹配框架，专门用于生成结构一致的时间序列，通过建模扰动轨迹来应对局部扰动带来的时间异质性挑战。


<details>
  <summary>Details</summary>
Motivation: 时间序列生成在分析决策中很重要，但局部扰动引起的时间异质性给生成结构一致的时间序列带来挑战。现有流匹配方法使用全局共享参数，无法充分捕捉扰动时间序列中的突变转换。

Method: 提出扰动感知流匹配框架(PAFM)，包含扰动引导训练模拟局部扰动，使用双路径速度场捕捉扰动下的轨迹偏差，并采用具有流路由的混合专家解码器动态分配建模能力。

Result: 在无条件和有条件生成任务上的大量实验表明，PAFM始终优于强基线方法。

Conclusion: PAFM通过建模扰动轨迹确保了稳定且结构一致的时间序列生成，有效解决了时间异质性挑战。

Abstract: Time series generation is critical for a wide range of applications, which greatly supports downstream analytical and decision-making tasks. However, the inherent temporal heterogeneous induced by localized perturbations present significant challenges for generating structurally consistent time series. While flow matching provides a promising paradigm by modeling temporal dynamics through trajectory-level supervision, it fails to adequately capture abrupt transitions in perturbed time series, as the use of globally shared parameters constrains the velocity field to a unified representation. To address these limitations, we introduce \textbf{PAFM}, a \textbf{P}erturbation-\textbf{A}ware \textbf{F}low \textbf{M}atching framework that models perturbed trajectories to ensure stable and structurally consistent time series generation. The framework incorporates perturbation-guided training to simulate localized disturbances and leverages a dual-path velocity field to capture trajectory deviations under perturbation, enabling refined modeling of perturbed behavior to enhance the structural coherence. In order to further improve sensitivity to trajectory perturbations while enhancing expressiveness, a mixture-of-experts decoder with flow routing dynamically allocates modeling capacity in response to different trajectory dynamics. Extensive experiments on both unconditional and conditional generation tasks demonstrate that PAFM consistently outperforms strong baselines. Code is available at https://anonymous.4open.science/r/PAFM-03B2.

</details>


### [135] [CLO: Efficient LLM Inference System with CPU-Light KVCache Offloading via Algorithm-System Co-Design](https://arxiv.org/abs/2511.14510)
*Jiawei Yi,Ping Gong,Youhui Bai,Jiaqi Ruan,Shengnan Wang,Pengcheng Wang,Haibo Wang,Weiguang Wang,Xia Zhu,Feng Wu,Cheng Li*

Main category: cs.LG

TL;DR: CLO是一个通过算法-系统协同设计的CPU轻量级KVCache卸载系统，解决了现有系统在CPU瓶颈方面的三个问题，显著提高了解码吞吐量。


<details>
  <summary>Details</summary>
Motivation: 随着百万token LLM的发展，推理系统的可扩展性面临KVCache内存使用和数据传输开销的挑战。现有卸载系统虽然将KVCache迁移到CPU内存并采用top-k注意力来减少数据传输量，但忽视了CPU瓶颈问题。

Method: CLO采用算法-系统协同设计，包括：粗粒度的头级近似GPU缓存策略、数据预取与GPU持久缓存的无缝结合、零拷贝传输引擎以充分利用PCIe带宽，以及GPU中心同步方法消除GPU停顿。

Result: 在两个广泛使用的LLM上的评估显示，CLO在保持与最先进系统相当准确度的同时，显著减少了CPU开销，充分利用了PCIe带宽，将解码吞吐量提高了9.3%-66.6%。

Conclusion: 算法-系统协同设计对于现代GPU平台上内存受限的LLM推理至关重要。CLO已开源。

Abstract: The growth of million-token LLMs exposes the scalability limits of inference systems, where the KVCache dominates memory usage and data transfer overhead. Recent offloading systems migrate the KVCache to CPU memory and incorporate top-k attention to reduce the volume of data transferred from the CPU, while further applying system-level optimizations such as on-GPU caching and prefetching to lower transfer overhead. However, they overlook the CPU bottleneck in three aspects: (1) substantial overhead of fine-grained dynamic cache management performed on the CPU side, (2) significant transfer overhead from poor PCIe bandwidth utilization caused by heavy gathering operations at the CPU side, and (3) GPU runtime bubbles introduced by coarse-grained CPU-centric synchronization. To address these challenges, we propose CLO, a CPU-light KVCache offloading system via algorithm-system co-design. CLO features: (1) a coarse-grained head-wise approximate on-GPU caching strategy with negligible cache management cost, (2) seamless combination of data prefetching and on-GPU persistent caching for lower transfer overhead, (3) a zero-copy transfer engine to fully exploit PCIe bandwidth, and a GPU-centric synchronization method to eliminate GPU stalls. Evaluation on two widely-used LLMs demonstrates that CLO achieves comparable accuracy to state-of-the-art systems, while substantially minimizing CPU overhead, fully utilizing PCIe bandwidth, thus improving decoding throughput by 9.3%-66.6%. Our results highlight that algorithm-system co-design is essential for memory-constrained LLM inference on modern GPU platforms. We open source CLO at https://github.com/CommediaJW/CLO.

</details>


### [136] [Full Atom Peptide Design via Riemannian Euclidean Bayesian Flow Networks](https://arxiv.org/abs/2511.14516)
*Hao Qian,Shikui Tu,Lei Xu*

Main category: cs.LG

TL;DR: PepBFN是首个用于全原子肽设计的贝叶斯流网络，通过在完全连续空间中建模参数分布来解决扩散和流匹配模型在肽结合物设计中的两个主要挑战：离散残基类型采样与连续参数更新的不匹配，以及侧链扭转角单模态假设与多模态旋转异构态本质的冲突。


<details>
  <summary>Details</summary>
Motivation: 当前扩散和流匹配模型在肽结合物设计中面临两个主要问题：1) 离散残基类型采样与连续参数更新的动态不匹配导致性能不佳；2) 侧链扭转角的单模态分布假设与旋转异构态的多模态本质相冲突，限制了预测准确性。

Method: PepBFN通过以下方法解决这些问题：1) 在完全连续空间中直接建模参数分布，通过学习离散残基类型的连续参数分布实现与其他连续结构参数的联合平滑贝叶斯更新；2) 使用基于高斯混合的贝叶斯流捕捉多模态侧链旋转异构态；3) 使用基于Matrix Fisher的黎曼流直接在SO(3)流形上建模残基方向。

Result: 在侧链堆积、反向折叠和结合物设计任务上的实验证明了PepBFN在计算肽设计中的强大潜力。

Conclusion: PepBFN通过贝叶斯更新逐步优化参数分布，实现了平滑且连贯的肽生成，为计算肽设计提供了有前景的新方法。

Abstract: Diffusion and flow matching models have recently emerged as promising approaches for peptide binder design. Despite their progress, these models still face two major challenges. First, categorical sampling of discrete residue types collapses their continuous parameters into onehot assignments, while continuous variables (e.g., atom positions) evolve smoothly throughout the generation process. This mismatch disrupts the update dynamics and results in suboptimal performance. Second, current models assume unimodal distributions for side-chain torsion angles, which conflicts with the inherently multimodal nature of side chain rotameric states and limits prediction accuracy. To address these limitations, we introduce PepBFN, the first Bayesian flow network for full atom peptide design that directly models parameter distributions in fully continuous space. Specifically, PepBFN models discrete residue types by learning their continuous parameter distributions, enabling joint and smooth Bayesian updates with other continuous structural parameters. It further employs a novel Gaussian mixture based Bayesian flow to capture the multimodal side chain rotameric states and a Matrix Fisher based Riemannian flow to directly model residue orientations on the $\mathrm{SO}(3)$ manifold. Together, these parameter distributions are progressively refined via Bayesian updates, yielding smooth and coherent peptide generation. Experiments on side chain packing, reverse folding, and binder design tasks demonstrate the strong potential of PepBFN in computational peptide design.

</details>


### [137] [MissHDD: Hybrid Deterministic Diffusion for Hetrogeneous Incomplete Data Imputation](https://arxiv.org/abs/2511.14543)
*Youran Zhou,Mohamed Reda Bouadjenek,Sunil Aryal*

Main category: cs.LG

TL;DR: 提出了一种混合确定性扩散框架，用于处理混合类型表格数据的不完整问题，通过分离连续和离散特征到不同的生成通道来提高插补准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现实表格数据中数值、分类和离散属性共存，现有扩散模型假设同质特征空间，难以保持条件一致性，导致分类变量信息崩溃或数值变量不稳定。

Method: 采用混合确定性扩散框架：连续DDIM通道处理数值变量，离散潜在路径扩散通道处理分类和离散特征，两个通道在统一条件插补目标下训练。

Result: 在多个真实数据集上实验表明，该方法在MCAR、MAR和MNAR设置下比现有扩散方法和经典方法具有更高的插补准确性、更稳定的采样轨迹和更好的鲁棒性。

Conclusion: 结构感知的扩散过程对于推进深度学习处理不完整表格数据的方法具有重要意义。

Abstract: Incomplete data are common in real-world tabular applications, where numerical, categorical, and discrete attributes coexist within a single dataset. This heterogeneous structure presents significant challenges for existing diffusion-based imputation models, which typically assume a homogeneous feature space and rely on stochastic denoising trajectories. Such assumptions make it difficult to maintain conditional consistency, and they often lead to information collapse for categorical variables or instability when numerical variables require deterministic updates. These limitations indicate that a single diffusion process is insufficient for mixed-type tabular imputation.
  We propose a hybrid deterministic diffusion framework that separates heterogeneous features into two complementary generative channels. A continuous DDIM-based channel provides efficient and stable deterministic denoising for numerical variables, while a discrete latent-path diffusion channel, inspired by loopholing-based discrete diffusion, models categorical and discrete features without leaving their valid sample manifolds. The two channels are trained under a unified conditional imputation objective, enabling coherent reconstruction of mixed-type incomplete data.
  Extensive experiments on multiple real-world datasets show that the proposed framework achieves higher imputation accuracy, more stable sampling trajectories, and improved robustness across MCAR, MAR, and MNAR settings compared with existing diffusion-based and classical methods. These results demonstrate the importance of structure-aware diffusion processes for advancing deep learning approaches to incomplete tabular data.

</details>


### [138] [Mind the Gaps: Measuring Visual Artifacts in Dimensionality Reduction](https://arxiv.org/abs/2511.14544)
*Jaume Ros,Alessio Arleo,Fernando Paulovich*

Main category: cs.LG

TL;DR: 提出了Warping Index (WI)这一新的降维投影质量度量指标，重点关注投影中空区域的正确保持，以避免视觉分析中的误导。


<details>
  <summary>Details</summary>
Motivation: 现有的投影质量度量主要关注数据全局或局部结构的保持，但忽略了视觉失真问题，特别是异常值和伪影可能误导视觉分析。

Method: 基于空区域正确保持对忠实视觉表示至关重要的假设，开发了Warping Index (WI)度量指标。

Result: 引入了一个新的度量指标来量化降维投影的质量，特别关注视觉失真问题。

Conclusion: Warping Index能够更好地评估降维投影的视觉质量，帮助避免因投影失真导致的误导性结论。

Abstract: Dimensionality Reduction (DR) techniques are commonly used for the visual exploration and analysis of high-dimensional data due to their ability to project datasets of high-dimensional points onto the 2D plane. However, projecting datasets in lower dimensions often entails some distortion, which is not necessarily easy to recognize but can lead users to misleading conclusions. Several Projection Quality Metrics (PQMs) have been developed as tools to quantify the goodness-of-fit of a DR projection; however, they mostly focus on measuring how well the projection captures the global or local structure of the data, without taking into account the visual distortion of the resulting plots, thus often ignoring the presence of outliers or artifacts that can mislead a visual analysis of the projection. In this work, we introduce the Warping Index (WI), a new metric for measuring the quality of DR projections onto the 2D plane, based on the assumption that the correct preservation of empty regions between points is of crucial importance towards a faithful visual representation of the data.

</details>


### [139] [Task Addition and Weight Disentanglement in Closed-Vocabulary Models](https://arxiv.org/abs/2511.14569)
*Adam Hazimeh,Alessandro Favero,Pascal Frossard*

Main category: cs.LG

TL;DR: 本文研究了任务算术在闭词汇图像分类模型中的应用，发现权重解缠是预训练模型的普遍特性，使得任务算术能够有效编辑这些模型，实现高效的多任务部署。


<details>
  <summary>Details</summary>
Motivation: 尽管任务算术在开放词汇模型中表现出色，但在没有语言监督预训练的闭词汇模型中的应用尚未探索。本文旨在填补这一空白，扩展任务算术的适用范围。

Method: 在闭词汇图像分类模型中部署和研究任务加法，考虑不同的预训练方案，分析权重解缠特性，并比较任务算术与简单线性探测的性能。

Result: 发现预训练闭词汇视觉变换器也可以通过任务算术进行编辑，实现高性能的任务加法，并且线性探测是与任务加法竞争性相当的基础方法。

Conclusion: 研究结果将任务算术的适用性扩展到更广泛的预训练模型类别，为在不同设置中更高效地使用预训练模型开辟了道路。

Abstract: Task arithmetic has recently emerged as a promising method for editing pre-trained \textit{open-vocabulary} models, offering a cost-effective alternative to standard multi-task fine-tuning. However, despite the abundance of \textit{closed-vocabulary} models that are not pre-trained with language supervision, applying task arithmetic to these models remains unexplored. In this paper, we deploy and study task addition in closed-vocabulary image classification models. We consider different pre-training schemes and find that \textit{weight disentanglement} -- the property enabling task arithmetic -- is a general consequence of pre-training, as it appears in different pre-trained closed-vocabulary models. In fact, we find that pre-trained closed-vocabulary vision transformers can also be edited with task arithmetic, achieving high task addition performance and enabling the efficient deployment of multi-task models. Finally, we demonstrate that simple linear probing is a competitive baseline to task addition. Overall, our findings expand the applicability of task arithmetic to a broader class of pre-trained models and open the way for more efficient use of pre-trained models in diverse settings.

</details>


### [140] [ReflexGrad: Three-Way Synergistic Architecture for Zero-Shot Generalization in LLM Agents](https://arxiv.org/abs/2511.14584)
*Ankush Kadu,Ashwanth Krishnan*

Main category: cs.LG

TL;DR: ReflexGrad是一个新颖的强化学习架构，通过结合分层任务分解、历史感知因果反思和梯度优化三种机制，实现了在ALFWorld基准任务上67%的零样本成功率，无需任务特定训练或演示。


<details>
  <summary>Details</summary>
Motivation: 解决智能体从经验中学习并在多样化任务中实现泛化的根本挑战，探索互补学习机制的协同整合潜力。

Method: 结合三种机制：1）基于LLM的分层TODO分解进行战略规划；2）历史感知因果反思分析最近行动模式以识别失败原因；3）梯度优化进行系统性改进。

Result: 在ALFWorld基准任务上实现67%的零样本成功率，无需任何先验任务经验或演示，有效性能在首次接触时即建立。

Conclusion: 互补学习机制的协同整合能够实现接近先前工作中少样本基线的稳健零样本泛化。

Abstract: Enabling agents to learn from experience and generalize across diverse tasks without task-specific training remains a fundamental challenge in reinforcement learning and decision-making. While recent approaches have explored episodic memory (Reflexion), gradient-based prompt optimization (TextGrad),and hierarchical task decomposition independently, their potential for synergistic integration remains unexplored. We introduce ReflexGrad, a novel architecture that tightly couples three complementary mechanisms: (1) LLM-based hierarchical TODO decomposition for strategic planning, (2) history-aware causal reflection that analyzes recent action patterns to identify failure root causes and enable within-trial learning, and (3) gradient-based optimization for systematic improvement. Unlike prior work relying on few-shot demonstrations, our system achieves true zero-shot generalization through pure LLM semantic reasoning,requiring no task-specific examples, fine-tuning, or hardcoded similarity metrics. Evaluated on ALFWorld benchmark tasks, ReflexGrad demonstrates 67% zero-shot success rate on Trial 0 without any prior task experience or demonstrations, establishing effective performance on first exposure. Through empirical analysis, we identify the architectural mechanisms underlying stable convergence (zero action loops) and effective cross-task transfer (67% to 78% improvement).Our work demonstrates that synergistic integration of complementary learning mechanisms enables robust zero-shot generalization that approaches few-shot baselines from prior work.

</details>


### [141] [Expert-Guided POMDP Learning for Data-Efficient Modeling in Healthcare](https://arxiv.org/abs/2511.14619)
*Marco Locatelli,Arjen Hommersom,Roberto Clemens Cerioli,Daniela Besozzi,Fabio Stella*

Main category: cs.LG

TL;DR: 提出Fuzzy MAP EM算法，通过将专家知识的模糊伪计数整合到EM框架中，解决有限数据下POMDP参数学习问题


<details>
  <summary>Details</summary>
Motivation: 在有限数据条件下学习部分可观测马尔可夫决策过程(POMDPs)的参数具有显著挑战，需要有效利用专家知识来指导学习

Method: 将专家定义的模糊模型生成的模糊伪计数融入期望最大化(EM)框架，自然地将问题重新表述为最大后验(MAP)估计

Result: 在合成医疗模拟中，该方法在低数据和高噪声条件下始终优于标准EM算法；重症肌无力案例研究表明能恢复临床一致的POMDP

Conclusion: Fuzzy MAP EM算法可作为医疗保健中数据高效建模的实用工具，在有限数据环境下有效利用专家知识

Abstract: Learning the parameters of Partially Observable Markov Decision Processes (POMDPs) from limited data is a significant challenge. We introduce the Fuzzy MAP EM algorithm, a novel approach that incorporates expert knowledge into the parameter estimation process by enriching the Expectation Maximization (EM) framework with fuzzy pseudo-counts derived from an expert-defined fuzzy model. This integration naturally reformulates the problem as a Maximum A Posteriori (MAP) estimation, effectively guiding learning in environments with limited data. In synthetic medical simulations, our method consistently outperforms the standard EM algorithm under both low-data and high-noise conditions. Furthermore, a case study on Myasthenia Gravis illustrates the ability of the Fuzzy MAP EM algorithm to recover a clinically coherent POMDP, demonstrating its potential as a practical tool for data-efficient modeling in healthcare.

</details>


### [142] [Failure to Mix: Large language models struggle to answer according to desired probability distributions](https://arxiv.org/abs/2511.14630)
*Ivy Yuqian Yang,David Yu Zhang*

Main category: cs.LG

TL;DR: 现代大型语言模型在生成概率分布输出时存在严重问题，无法按照要求的概率分布生成输出，而是几乎总是选择概率最高的选项。


<details>
  <summary>Details</summary>
Motivation: 科学创意生成和选择需要遵循目标概率分布进行探索，而当前AI基准测试有客观正确答案，通过强化学习训练LLM会抑制概率探索。

Method: 进行系统实验，要求LLM按照简单概率分布生成输出，测试其遵循分布的能力。

Result: 所有测试的现代LLM都严重无法遵循分布，例如要求以49%概率输出"1"时，几乎100%输出"0"，表现出类似阶跃函数的行为。

Conclusion: LLM倾向于几乎只生成概率最高的输出，这种行为甚至压倒了其内在的强烈偏见。

Abstract: Scientific idea generation and selection requires exploration following a target probability distribution. In contrast, current AI benchmarks have objectively correct answers, and training large language models (LLMs) via reinforcement learning against these benchmarks discourages probabilistic exploration. Here, we conducted systematic experiments requesting LLMs to produce outputs following simple probabilistic distributions, and found that all modern LLMs tested grossly fail to follow the distributions. For example, requesting a binary output of "1" 49% of the time produces an answer of "0" nearly 100% of the time. This step function-like behavior of near-exclusively generating the output with marginally highest probability even overrules even strong in-built LLM biases.

</details>


### [143] [Adapformer: Adaptive Channel Management for Multivariate Time Series Forecasting](https://arxiv.org/abs/2511.14632)
*Yuchen Luo,Xinyu Li,Liuhua Peng,Mingming Gong*

Main category: cs.LG

TL;DR: Adapformer是一个基于Transformer的多变量时间序列预测框架，通过自适应通道管理结合了通道独立和通道依赖方法的优点，解决了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统多变量时间序列预测方法存在通道独立方法无法利用通道间交互信息，而通道依赖方法容易引入过多噪声导致过拟合的问题。需要一种能够自适应选择关键依赖关系的方法。

Method: 提出双阶段编码器-解码器架构，包含自适应通道增强器(ACE)用于选择性丰富嵌入表示，自适应通道预测器(ACF)用于精简解码过程，聚焦最相关的协变量。

Result: 在多个数据集上的测试表明，Adapformer在预测精度和计算效率方面均优于现有模型，达到了最先进的性能水平。

Conclusion: Adapformer通过有效的通道管理策略，成功平衡了通道独立和通道依赖方法的优势，为多变量时间序列预测提供了更优的解决方案。

Abstract: In multivariate time series forecasting (MTSF), accurately modeling the intricate dependencies among multiple variables remains a significant challenge due to the inherent limitations of traditional approaches. Most existing models adopt either \textbf{channel-independent} (CI) or \textbf{channel-dependent} (CD) strategies, each presenting distinct drawbacks. CI methods fail to leverage the potential insights from inter-channel interactions, resulting in models that may not fully exploit the underlying statistical dependencies present in the data. Conversely, CD approaches often incorporate too much extraneous information, risking model overfitting and predictive inefficiency. To address these issues, we introduce the Adaptive Forecasting Transformer (\textbf{Adapformer}), an advanced Transformer-based framework that merges the benefits of CI and CD methodologies through effective channel management. The core of Adapformer lies in its dual-stage encoder-decoder architecture, which includes the \textbf{A}daptive \textbf{C}hannel \textbf{E}nhancer (\textbf{ACE}) for enriching embedding processes and the \textbf{A}daptive \textbf{C}hannel \textbf{F}orecaster (\textbf{ACF}) for refining the predictions. ACE enhances token representations by selectively incorporating essential dependencies, while ACF streamlines the decoding process by focusing on the most relevant covariates, substantially reducing noise and redundancy. Our rigorous testing on diverse datasets shows that Adapformer achieves superior performance over existing models, enhancing both predictive accuracy and computational efficiency, thus making it state-of-the-art in MTSF.

</details>


### [144] [Machine Learning Models for Predicting Smoking-Related Health Decline and Disease Risk](https://arxiv.org/abs/2511.14682)
*Vaskar Chakma,MD Jaheid Hasan Nerab,Abdur Rouf,Abu Sayed,Hossem MD Saim,Md. Nournabi Khan*

Main category: cs.LG

TL;DR: 本研究系统比较了三种机器学习算法（随机森林、XGBoost、LightGBM）在吸烟相关健康风险评估中的表现，发现随机森林模型表现最佳（AUC=0.926），并通过SHAP分析识别出血压、甘油三酯、肝酶和肾功能指标是预测吸烟风险的关键因素。


<details>
  <summary>Details</summary>
Motivation: 吸烟是全球主要的可预防死亡原因，但现有医疗筛查方法经常错过吸烟相关健康问题的早期预警信号，导致诊断延迟。本研究旨在开发基于机器学习的早期风险评估方法。

Method: 使用55,691名个体的健康筛查数据，包括身体测量、血液检测和人口统计信息。采用横断面设计，测试随机森林、XGBoost和LightGBM三种算法来分类当前吸烟状态。

Result: 随机森林模型表现最佳，AUC达到0.926，能够可靠区分高风险和低风险个体。SHAP分析显示血压水平、甘油三酯浓度、肝酶读数和肾功能指标（血清肌酐）是预测吸烟风险的最强信号。

Conclusion: 机器学习方法可以有效识别吸烟相关的健康风险，随机森林结合SHAP分析提供了临床可解释的预测模型，有助于早期发现吸烟相关的健康问题。

Abstract: Smoking continues to be a major preventable cause of death worldwide, affecting millions through damage to the heart, metabolism, liver, and kidneys. However, current medical screening methods often miss the early warning signs of smoking-related health problems, leading to late-stage diagnoses when treatment options become limited. This study presents a systematic comparative evaluation of machine learning approaches for smoking-related health risk assessment, emphasizing clinical interpretability and practical deployment over algorithmic innovation. We analyzed health screening data from 55,691 individuals, examining various health indicators, including body measurements, blood tests, and demographic information. We tested three advanced prediction algorithms - Random Forest, XGBoost, and LightGBM - to determine which could most accurately identify people at high risk. This study employed a cross-sectional design to classify current smoking status based on health screening biomarkers, not to predict future disease development. Our Random Forest model performed best, achieving an Area Under the Curve (AUC) of 0.926, meaning it could reliably distinguish between high-risk and lower-risk individuals. Using SHAP (SHapley Additive exPlanations) analysis to understand what the model was detecting, we found that key health markers played crucial roles in prediction: blood pressure levels, triglyceride concentrations, liver enzyme readings, and kidney function indicators (serum creatinine) were the strongest signals of declining health in smokers.

</details>


### [145] [\textit{FLARE}: Adaptive Multi-Dimensional Reputation for Robust Client Reliability in Federated Learning](https://arxiv.org/abs/2511.14715)
*Abolfazl Younesi,Leon Kiss,Zahra Najafabadi Samani,Juan Aznar Poveda,Thomas Fahringer*

Main category: cs.LG

TL;DR: FLARE是一个自适应信誉联邦学习框架，通过多维信誉评分、自适应阈值和软排除机制，有效防御拜占庭攻击，在多种攻击场景下保持高模型精度和快速收敛。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习防御机制依赖静态阈值和二元分类，无法适应现实部署中不断演变的客户端行为，需要更灵活的自适应防御方案。

Method: FLARE框架包含：多维信誉评分系统、自校准自适应阈值机制、信誉加权聚合与软排除、本地差分隐私机制，并引入了统计模仿攻击作为基准测试。

Result: 在MNIST、CIFAR-10和SVHN数据集上，FLARE在100个客户端环境下，相比最先进的拜占庭鲁棒方法，在多种攻击类型下保持高模型精度，收敛更快，鲁棒性提升达16%。

Conclusion: FLARE通过连续多维信任评估和自适应机制，显著提升了联邦学习在恶意攻击下的安全性和性能，为实际部署提供了有效的防御解决方案。

Abstract: Federated learning (FL) enables collaborative model training while preserving data privacy. However, it remains vulnerable to malicious clients who compromise model integrity through Byzantine attacks, data poisoning, or adaptive adversarial behaviors. Existing defense mechanisms rely on static thresholds and binary classification, failing to adapt to evolving client behaviors in real-world deployments. We propose FLARE, an adaptive reputation-based framework that transforms client reliability assessment from binary decisions to a continuous, multi-dimensional trust evaluation. FLARE integrates: (i) a multi-dimensional reputation score capturing performance consistency, statistical anomaly indicators, and temporal behavior, (ii) a self-calibrating adaptive threshold mechanism that adjusts security strictness based on model convergence and recent attack intensity, (iii) reputation-weighted aggregation with soft exclusion to proportionally limit suspicious contributions rather than eliminating clients outright, and (iv) a Local Differential Privacy (LDP) mechanism enabling reputation scoring on privatized client updates. We further introduce a highly evasive Statistical Mimicry (SM) attack, a benchmark adversary that blends honest gradients with synthetic perturbations and persistent drift to remain undetected by traditional filters. Extensive experiments with 100 clients on MNIST, CIFAR-10, and SVHN demonstrate that FLARE maintains high model accuracy and converges faster than state-of-the-art Byzantine-robust methods under diverse attack types, including label flipping, gradient scaling, adaptive attacks, ALIE, and SM. FLARE improves robustness by up to 16% and preserves model convergence within 30% of the non-attacked baseline, while achieving strong malicious-client detection performance with minimal computational overhead. https://github.com/Anonymous0-0paper/FLARE

</details>


### [146] [AdamHD: Decoupled Huber Decay Regularization for Language Model Pre-Training](https://arxiv.org/abs/2511.14721)
*Fu-Ming Guo,Yingfang Fan*

Main category: cs.LG

TL;DR: 提出了AdamHuberDecay作为AdamW的替代方案，用解耦的平滑Huber正则化器替代ℓ2惩罚，在保持相同计算成本的同时实现更快的收敛、更好的性能和更强的稀疏性。


<details>
  <summary>Details</summary>
Motivation: AdamW中ℓ2惩罚的二次性质使所有参数以相同速率向原点衰减，容易受到极端梯度方向的影响，并且经常过度惩罚条件良好的坐标。

Method: 将ℓ2惩罚替换为解耦的平滑Huber正则化器，当参数幅度低于阈值δ时进行二次衰减，超过δ时进行线性衰减，从而获得有界正则化梯度、对坐标二阶矩重缩放的鲁棒性以及对过度增长权重的更强稀疏压力。

Result: 在GPT-2和GPT-3预训练中，AdamHuberDecay收敛速度快10-15%，验证困惑度降低最多4点，下游任务性能提升2.5-4.7%，通过幅度剪枝可实现20-30%的内存节省。

Conclusion: AdamHuberDecay为下一代基础生成变换器的训练提供了一条简单、有原则的路径，实现更高效和更具韧性的训练。

Abstract: Adaptive optimizers with decoupled weight decay, such as AdamW, are the de facto standard for pre-training large transformer-based generative models. Yet the quadratic nature of the $\ell_2$ penalty embedded in weight decay drives all parameters toward the origin at the same rate, making the update vulnerable to rare but extreme gradient directions and often over-penalizing well-conditioned coordinates. We propose AdamHuberDecay, a drop-in replacement for AdamW that substitutes the $\ell_2$ penalty with a decoupled smooth Huber regularizer. The resulting update decays parameters quadratically while their magnitude remains below a threshold $δ$, and linearly ($\ell_1$-like) once they exceed $δ$, yielding (i) bounded regularization gradients, (ii) invariance to per-coordinate second-moment rescaling, and (iii) stronger sparsity pressure on overgrown weights.
  We derive the closed-form decoupled Huber decay step and show how to integrate it with any Adam-family optimizer at $O(1)$ extra cost. Extensive experiments on GPT-2 and GPT-3 pre-training demonstrate that AdamHuberDecay (a) converges 10-15% faster in wall-clock time, (b) reduces validation perplexity by up to 4 points, (c) delivers performance improvements of 2.5-4.7% across downstream tasks, and (d) yields visibly sparser weight histograms that translate into 20-30% memory savings after magnitude pruning, without tuning the decay coefficient beyond the default grid used for AdamW. Ablations confirm robustness to outlier gradients and large-batch regimes, together with theoretical analyses that bound the expected parameter norm under noisy updates. AdamHuberDecay therefore provides a simple, principled path toward more efficient and resilient training of next-generation foundational generative transformers.

</details>


### [147] [LAUD: Integrating Large Language Models with Active Learning for Unlabeled Data](https://arxiv.org/abs/2511.14738)
*Tzu-Hsuan Chou,Chun-Nan Chou*

Main category: cs.LG

TL;DR: LAUD框架通过结合大语言模型与主动学习，解决无标签数据场景下的冷启动问题，在商品名称分类任务中优于零样本或少样本学习。


<details>
  <summary>Details</summary>
Motivation: 现实场景中缺乏标注数据，导致只能依赖繁琐低效的提示工程方法，需要解决无标签数据下的模型性能问题。

Method: 提出LAUD学习框架，整合大语言模型与主动学习，通过零样本学习构建初始标签集来缓解冷启动问题。

Result: 实验结果显示，基于LAUD的大语言模型在商品名称分类任务中表现优于零样本或少样本学习方法。

Conclusion: LAUD框架有效解决了无标签数据场景下的模型训练问题，证明了整合主动学习与大语言模型的可行性。

Abstract: Large language models (LLMs) have shown a remarkable ability to generalize beyond their pre-training data, and fine-tuning LLMs can elevate performance to human-level and beyond. However, in real-world scenarios, lacking labeled data often prevents practitioners from obtaining well-performing models, thereby forcing practitioners to highly rely on prompt-based approaches that are often tedious, inefficient, and driven by trial and error. To alleviate this issue of lacking labeled data, we present a learning framework integrating LLMs with active learning for unlabeled dataset (LAUD). LAUD mitigates the cold-start problem by constructing an initial label set with zero-shot learning. Experimental results show that LLMs derived from LAUD outperform LLMs with zero-shot or few-shot learning on commodity name classification tasks, demonstrating the effectiveness of LAUD.

</details>


### [148] [Beyond Means: A Dynamic Framework for Predicting Customer Satisfaction](https://arxiv.org/abs/2511.14743)
*Christof Naumzik,Abdurahman Maarouf,Stefan Feuerriegel,Markus Weinmann*

Main category: cs.LG

TL;DR: 使用高斯过程模型进行在线评分聚合，相比样本均值方法减少10.2%的预测误差，能更好地捕捉评分动态变化和评论异质性。


<details>
  <summary>Details</summary>
Motivation: 传统评分聚合方法（如样本均值）无法适应质量随时间变化，且忽略了评论异质性（如情感、有用性），需要更智能的评分聚合方法。

Method: 提出定制化的高斯过程模型，捕捉评分随时间变化的动态特性，同时考虑评论异质性因素。

Result: 基于121,123条Yelp评分数据，高斯过程模型在预测未来评分方面显著更准确，平均绝对误差比样本均值减少10.2%。

Conclusion: 在线声誉系统应采用超越均值的方法，显示更具信息性和适应性的聚合评分，为营销从业者和客户提供更准确的服务质量信号。

Abstract: Online ratings influence customer decision-making, yet standard aggregation methods, such as the sample mean, fail to adapt to quality changes over time and ignore review heterogeneity (e.g., review sentiment, a review's helpfulness). To address these challenges, we demonstrate the value of using the Gaussian process (GP) framework for rating aggregation. Specifically, we present a tailored GP model that captures the dynamics of ratings over time while additionally accounting for review heterogeneity. Based on 121,123 ratings from Yelp, we compare the predictive power of different rating aggregation methods in predicting future ratings, thereby finding that the GP model is considerably more accurate and reduces the mean absolute error by 10.2% compared to the sample mean. Our findings have important implications for marketing practitioners and customers. By moving beyond means, designers of online reputation systems can display more informative and adaptive aggregated rating scores that are accurate signals of expected customer satisfaction.

</details>


### [149] [Measuring AI Progress in Drug Discovery: A Reproducible Leaderboard for the Tox21 Challenge](https://arxiv.org/abs/2511.14744)
*Antonia Ebner,Christoph Bartmann,Sonja Topf,Sohvi Luukkonen,Johannes Schimunek,Günter Klambauer*

Main category: cs.LG

TL;DR: 深度学习在药物发现领域的关键转折点是2015年Tox21数据挑战赛，但数据集在后续整合中被修改，导致研究结果难以比较。作者创建了可复现的排行榜，发现原始获胜方法和2017年的方法仍然具有竞争力，表明过去十年毒性预测可能没有显著进步。


<details>
  <summary>Details</summary>
Motivation: 由于Tox21数据集在后续基准测试中被修改和标签被估算，导致不同研究之间缺乏可比性，无法准确评估过去十年生物活性和毒性预测方法的实际进展程度。

Method: 创建了一个可复现的排行榜，使用原始Tox21挑战赛数据集，并包含基准方法和代表性方法，所有模型通过Hugging Face Spaces提供标准化API调用。

Result: 当前排行榜显示，原始的Tox21获胜方法（基于集成的DeepTox）和2017年引入的基于描述符的自归一化神经网络仍然具有竞争力，位列毒性预测的顶级方法之列。

Conclusion: 毒性预测在过去十年中可能没有取得实质性进展，原始方法和较早的方法仍然保持竞争力，这凸显了标准化基准和可复现性在评估方法进步中的重要性。

Abstract: Deep learning's rise since the early 2010s has transformed fields like computer vision and natural language processing and strongly influenced biomedical research. For drug discovery specifically, a key inflection - akin to vision's "ImageNet moment" - arrived in 2015, when deep neural networks surpassed traditional approaches on the Tox21 Data Challenge. This milestone accelerated the adoption of deep learning across the pharmaceutical industry, and today most major companies have integrated these methods into their research pipelines. After the Tox21 Challenge concluded, its dataset was included in several established benchmarks, such as MoleculeNet and the Open Graph Benchmark. However, during these integrations, the dataset was altered and labels were imputed or manufactured, resulting in a loss of comparability across studies. Consequently, the extent to which bioactivity and toxicity prediction methods have improved over the past decade remains unclear. To this end, we introduce a reproducible leaderboard, hosted on Hugging Face with the original Tox21 Challenge dataset, together with a set of baseline and representative methods. The current version of the leaderboard indicates that the original Tox21 winner - the ensemble-based DeepTox method - and the descriptor-based self-normalizing neural networks introduced in 2017, continue to perform competitively and rank among the top methods for toxicity prediction, leaving it unclear whether substantial progress in toxicity prediction has been achieved over the past decade. As part of this work, we make all baselines and evaluated models publicly accessible for inference via standardized API calls to Hugging Face Spaces.

</details>


### [150] [Look-Ahead Reasoning on Learning Platforms](https://arxiv.org/abs/2511.14745)
*Haiqing Zhu,Tijana Zrnic,Celestine Mendler-Dünner*

Main category: cs.LG

TL;DR: 该论文研究了学习平台中用户的战略行为，探讨了前瞻性推理和集体协调对模型预测的影响，并与自私行为进行对比。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注用户对已部署模型的战略响应，而忽略了用户行为之间的相互影响。论文旨在分析用户通过前瞻性推理和集体协调来影响平台预测的行为。

Method: 首先形式化了行为经济学中的k级思维概念，然后研究了集体推理，即用户通过协调行动来共同影响模型。

Result: 研究发现k级思维虽然加速了均衡收敛，但长期来看对个体没有额外收益；集体协调行为揭示了学习者效用与用户效用之间的对齐关系。

Conclusion: 用户战略行为与模型预测之间存在复杂的相互作用，集体协调能够带来新的效用对齐概念，这对学习平台设计具有重要意义。

Abstract: On many learning platforms, the optimization criteria guiding model training reflect the priorities of the designer rather than those of the individuals they affect. Consequently, users may act strategically to obtain more favorable outcomes, effectively contesting the platform's predictions. While past work has studied strategic user behavior on learning platforms, the focus has largely been on strategic responses to a deployed model, without considering the behavior of other users. In contrast, look-ahead reasoning takes into account that user actions are coupled, and -- at scale -- impact future predictions. Within this framework, we first formalize level-$k$ thinking, a concept from behavioral economics, where users aim to outsmart their peers by looking one step ahead. We show that, while convergence to an equilibrium is accelerated, the equilibrium remains the same, providing no benefit of higher-level reasoning for individuals in the long run. Then, we focus on collective reasoning, where users take coordinated actions by optimizing through their joint impact on the model. By contrasting collective with selfish behavior, we characterize the benefits and limits of coordination; a new notion of alignment between the learner's and the users' utilities emerges as a key concept. We discuss connections to several related mathematical frameworks, including strategic classification, performative prediction, and algorithmic collective action.

</details>


### [151] [SparseST: Exploiting Data Sparsity in Spatiotemporal Modeling and Prediction](https://arxiv.org/abs/2511.14753)
*Junfeng Wu,Hadjer Benmeziane,Kaoutar El Maghraoui,Liu Liu,Yinan Wang*

Main category: cs.LG

TL;DR: 提出了SparseST框架，利用时空数据中的稀疏性来开发高效的时空模型，并通过多目标复合损失函数探索模型性能与计算效率之间的帕累托前沿。


<details>
  <summary>Details</summary>
Motivation: ConvLSTM及其变体在时空数据挖掘中表现出色，但计算成本高昂，无法在计算资源有限的边缘设备上部署。现有高效AI方法主要关注减少模型容量冗余，但时空数据挖掘需要大量模型容量，而数据和特征冗余却带来了不必要的计算负担。

Method: 开发了SparseST框架，利用时空数据稀疏性构建高效模型，设计多目标复合损失函数来平衡性能与效率。

Result: 提出的方法能够显著降低计算成本，同时保持模型性能，为边缘计算环境下的时空数据挖掘提供了实用解决方案。

Conclusion: 通过利用数据稀疏性而非仅关注模型压缩，SparseST为资源受限环境下的高效时空数据挖掘开辟了新途径，并提供了调整模型以适应不同计算资源和性能需求的实用指南。

Abstract: Spatiotemporal data mining (STDM) has a wide range of applications in various complex physical systems (CPS), i.e., transportation, manufacturing, healthcare, etc. Among all the proposed methods, the Convolutional Long Short-Term Memory (ConvLSTM) has proved to be generalizable and extendable in different applications and has multiple variants achieving state-of-the-art performance in various STDM applications. However, ConvLSTM and its variants are computationally expensive, which makes them inapplicable in edge devices with limited computational resources. With the emerging need for edge computing in CPS, efficient AI is essential to reduce the computational cost while preserving the model performance. Common methods of efficient AI are developed to reduce redundancy in model capacity (i.e., model pruning, compression, etc.). However, spatiotemporal data mining naturally requires extensive model capacity, as the embedded dependencies in spatiotemporal data are complex and hard to capture, which limits the model redundancy. Instead, there is a fairly high level of data and feature redundancy that introduces an unnecessary computational burden, which has been largely overlooked in existing research. Therefore, we developed a novel framework SparseST, that pioneered in exploiting data sparsity to develop an efficient spatiotemporal model. In addition, we explore and approximate the Pareto front between model performance and computational efficiency by designing a multi-objective composite loss function, which provides a practical guide for practitioners to adjust the model according to computational resource constraints and the performance requirements of downstream tasks.

</details>


### [152] [$π^{*}_{0.6}$: a VLA That Learns From Experience](https://arxiv.org/abs/2511.14759)
*Ali Amin,Raichelle Aniceto,Ashwin Balakrishna,Kevin Black,Ken Conley,Grace Connors,James Darpinian,Karan Dhabalia,Jared DiCarlo,Danny Driess,Michael Equi,Adnan Esmail,Yunhao Fang,Chelsea Finn,Catherine Glossop,Thomas Godden,Ivan Goryachev,Lachy Groom,Hunter Hancock,Karol Hausman,Gashon Hussein,Brian Ichter,Szymon Jakubczak,Rowan Jen,Tim Jones,Ben Katz,Liyiming Ke,Chandra Kuchi,Marinda Lamb,Devin LeBlanc,Sergey Levine,Adrian Li-Bell,Yao Lu,Vishnu Mano,Mohith Mothukuri,Suraj Nair,Karl Pertsch,Allen Z. Ren,Charvi Sharma,Lucy Xiaoyang Shi,Laura Smith,Jost Tobias Springenberg,Kyle Stachowicz,Will Stoeckle,Alex Swerdlow,James Tanner,Marcel Torne,Quan Vuong,Anna Walling,Haohuan Wang,Blake Williams,Sukwon Yoo,Lili Yu,Ury Zhilinsky,Zhiyuan Zhou*

Main category: cs.LG

TL;DR: RECAP方法通过优势条件策略将异构数据（演示、在线收集数据、专家干预）整合到VLA模型的强化学习训练中，显著提升了机器人在真实环境中的任务性能。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过强化学习让视觉-语言-动作模型在真实世界部署中实现自我改进，解决复杂任务执行问题。

Method: RECAP方法：先通过离线RL预训练通用VLA模型π*0.6，然后通过在线机器人数据收集专门化模型，结合优势条件策略整合异构数据。

Result: 训练后的模型能在真实家庭中叠衣服、可靠组装盒子、使用专业咖啡机制作浓缩咖啡。在最困难任务上，任务吞吐量提高一倍以上，失败率减半。

Conclusion: RECAP方法有效提升了VLA模型在真实世界任务中的性能，证明了通过整合异构数据进行RL训练的重要性。

Abstract: We study how vision-language-action (VLA) models can improve through real-world deployments via reinforcement learning (RL). We present a general-purpose method, RL with Experience and Corrections via Advantage-conditioned Policies (RECAP), that provides for RL training of VLAs via advantage conditioning. Our method incorporates heterogeneous data into the self-improvement process, including demonstrations, data from on-policy collection, and expert teleoperated interventions provided during autonomous execution. RECAP starts by pre-training a generalist VLA with offline RL, which we call $π^{*}_{0.6}$, that can then be specialized to attain high performance on downstream tasks through on-robot data collection. We show that the $π^{*}_{0.6}$ model trained with the full RECAP method can fold laundry in real homes, reliably assemble boxes, and make espresso drinks using a professional espresso machine. On some of the hardest tasks, RECAP more than doubles task throughput and roughly halves the task failure rate.

</details>
